index,text
8540,hydrologic models are robust tools for estimating key parameters in the management of water resources including water inputs storage and pathway fluxes the selection of process based versus data driven modeling structure is an important consideration particularly as advancements in machine learning yield potential for improved model performance but at the cost of lacking physical analogues despite recent advancement there exists an absence of cross model comparison of the tradeoffs between process based and data driven model types in settings with varying hydrologic controls in this study we use physically based swat conceptually based lump and deep learning lstm models to simulate hydrologic pathway contributions for a fluvial watershed and a karst basin over a twenty year period we find that while all models are satisfactory the lstm model outperformed both the swat and lump models in simulating total discharge and that the improved performance was more evident in the groundwater dominated karst system than the surface dominated fluvial stream further the lstm model was able to achieve this improved performance with only 10 25 of the observed time series as training data regarding pathways the lstm model coupled with a recursive digital filter was able to successfully match the magnitude of process based estimates of quick intermediate and slow flow contributions for both basins ρ ranging from 0 58 to 0 71 however the process based models exhibited more realistic time fractal scaling of hydrologic flow pathways compared to the lstm model which depending on project objectives presents a potential drawback to the use of machine learning models for some hydrologic applications this study demonstrates the utility and potential extraction of physical analogues of lstm modeling which will be useful as deep learning approaches to hydrologic modeling become more prominent and modelers look for ways to infer physical information from data driven predictions keywords hydrologic modeling machine learning lstm rainfall runoff process based data driven data availability the data are stored in an online repository linked in the acknowledgements 1 introduction hydrologic modeling is a crucial tool for managing water resources and simulating water fluxes across and within the earth s surface mcmillan 2021 sit et al 2020 understanding the pathways by which rainfall inputs are routed to receiving waterbodies is a major goal for stakeholders and is crucial for managing water resources hammond et al 2021 numerous modeling approaches exist to tackle this problem including process driven and data driven models bai et al 2021 kratzert et al 2018 model selection is influenced by existing system knowledge availability of input data parameter uncertainty and access to computational resources shen 2018 sit et al 2020 questions remain regarding the tradeoffs of various modeling approaches for simulating hydrologic pathways and fluxes the prevailing paradigm of the last half century of hydrologic modeling has been the development of process driven conceptually and physically based numerical models fatichi et al 2016 razavi 2021 process driven models are constructed from empirical or analytical formulae that serve as proxies for physical phenomena such as runoff soil percolation and groundwater recharge however developing process based hydrologic models is exceptionally challenging as they are time data and computationally intensive shen 2018 in the last decade rapid advances in data driven machine learning models has provided a mechanism for equivalent or better simulation of hydrologic systems with a fraction of the overall required resources razavi 2021 shen 2018 sit et al 2020 in particular the deep learning long short term memory lstm approach has proven especially fruitful for simulation of watershed dynamics because of its ability to remember past system states kratzert et al 2018 a common refrain regarding machine learning models is that their internal workings are difficult to discern and lack physical analogues razavi 2021 to address this quite significant limitation substantial work is being done to advance our interpretation of internal deep learning states kratzert et al 2019a b read et al 2019 one particularly useful approach is to take existing calibrated process driven models and perform cross comparison with machine learning outputs bai et al 2021 kratzert et al 2018 razavi 2021 there exists the potential for developing approaches to benchmark data driven estimates of hydrologic flow pathway contribution against process driven outputs and overcome existing limitations of machine learning approaches hydrologic pathways fall into three broad classifications quick intermediate and slow flow husic et al 2019b madsen et al 2002 each pathway represents a collection of spatially and temporally distinct fluxes that connect a water store to a catchment outlet mcmillan 2022 quick flow pathways are often turbulent and spatially discrete respond rapidly to precipitation inputs and account for low long term storage of catchment water examples include surficial runoff flow in tile drains and underground caves and point source discharges slow flow is typically laminar and spatially diffuse represents significant catchment storage and sustains long term recharge to streams and springs examples of slow pathways include deep aquifer recharge and flow through bedrock pores intermediate flow components bridge the spatial and temporal scales of quick and slow flow pathways and represent the dynamic interception and routing of flow to the catchment outlet or long term storage examples of intermediate pathways include interflow and unsaturated flow in the vadose zone numerous methods exist for simulating the varying contribution of quick intermediate and slow flow to overall discharge ranging from recursive digital filters rdf and recession curves for data driven hydrograph separation singh and stenger 2018 stoelzle et al 2020 to conceptual or explicit numerical modeling al aamery et al 2021 vansteenkiste et al 2014 few studies however have assessed the uncertainty associated with the choice of method for pathway modeling which has implications for understanding the timing extent and connectivity of catchment fluxes the objective of this research was to assess the utility of deep learning models to simulate hydrologic flow path contributions in two neighboring systems a surface dominated fluvial stream and a subsurface dominated karst spring to compare outputs we use the same input data to calibrate four different models a conceptual model a physically based model and two lstm models one each for the stream and spring thereafter we tune and apply the models to a twenty year flow period at both locations we compare the quick intermediate and slow flow components generated from a modified lstm model to those of the two process driven numerical models we perform statistical evaluation of the flow components including auto correlation cross correlation and spectral analysis to understand their temporal persistence and time fractal scaling lastly we provide guidance on the applicability of deep learning models to simulate hydrologic flow path contributions in systems with varying surface subsurface dominance over hydrology 2 materials and methods 2 1 study site to meet the objectives of this study we selected two nearby basins in the inner bluegrass region of kentucky usa with similar land use and topography but vastly different hydrologic pathway controls fig 1 royal spring 58 km2 is a subsurface dominated karst system whereas south elkhorn 62 km2 is a surface dominated fluvial system the geology of the inner bluegrass region is comprised of phosphatic limestone of the middle ordovician period which experiences chemical dissolution and erosion spangler 1982 the variable dissolution of limestone bedrock results in the formation of karst features such as sinkholes caves and conduits in the royal spring basin a series of karst sinkholes and swallets redirect surface runoff into a subsurface conduit system approximately 20 m below the ground surface husic et al 2017a b which routes flow to a perennial spring for the most part these features are absent in south elkhorn mahoney et al 2018b thus its hydrology is largely unaffected by karst the climate in the region is temperate with a mean annual precipitation of 1 170 200 mm and temperature of 13 0 0 7 c land use is primarily pasture grassland with urbanized headwaters in both basins royal spring and south elkhorn have been subject to extensive field assessment and numerical modeling over the last two decades to ascertain hydrologic controls in the basins in royal spring dye tracing paylor and currens 2004 electrical resistivity testing sawyer et al 2015 zhu et al 2011 high frequency aquatic sensing husic et al 2017a water isotope tracing husic et al 2019a and numerical modeling husic et al 2019b have allowed us to develop a strong conceptual model of water storage and routing through the karst aquifer briefly event precipitation is initially captured by the basin as distributed recharge through the soil or concentrated recharge through sinkholes swallets and depressions thereafter distributed recharge percolates into the epikarst the near surface karst regolith where it can be dynamically routed to the spring or deeper aquifer during non event periods baseflow to the spring originates from both saturated and unsaturated zones of the aquifer in south elkhorn numerical modeling of hydrology al aamery et al 2018 2016 ford and fox 2014 and stable isotope tracing ford et al 2015 mahoney et al 2018a have revealed the influence of storm events to runoff dynamics and soil storage to baseflow generation hydrologic delivery in south elkhorn is largely unaffected by karst so the abstraction of surface runoff by karst holes is likely minimal thus intense precipitation events generate considerable runoff that drains into the stream network thereafter infiltrated water in the shallow and deep aquifers maintains elevated baseflow after event cessation 2 2 materials to investigate hydrologic pathway controls 20 years of daily discharge data were obtained from two united states geological survey gages south elkhorn usgs 03289000 and royal spring usgs 03288110 meteorological input data for both basins including precipitation and mean temperature were obtained from the bluegrass airport usw00093820 potential evapotranspiration was estimated using the penman monteith equation two existing calibrated numerical models were integrated into this study to serve as benchmarks for lstm model performance fig 2 these include a conceptually based model for the royal spring basin lump husic et al 2019b and a physically based model for the south elkhorn basin swat al aamery et al 2018 the lump model is a series of cascading linear reservoirs each representing an entire water storage area for the basin including the soil epikarst quickflow and phreatic zones fig 2a initially precipitation input is separated into concentrated x and diffuse 1 x fractions that contribute to quickflow and soil reservoirs respectively as these reservoirs overflow they contribute to spring discharge qspring as quick flow qq epikarst flow qe and phreatic flow qp we infer the qq qe and qp flow components to represent quick intermediate and slow recharge respectively to the subsurface dominated spring in its original study husic et al 2019b the lump model was calibrated to daily discharge from 10 2012 to 10 2014 2 years and validated from 10 2014 to 10 2016 2 years model uncertainty was estimated from millions of monte carlo realizations covering the full range of potential parametrizations in total 1 176 model realizations were deemed successful in the original study and are used in this study the simulation period in the original lump model paper covered 4 years but has been extended to 20 years here from 01 2000 to 01 2020 in summary 2 years were used for calibration 2 years for validation and 16 years for testing the swat model identifies several hydrologic response units hrus or parcels of the landscape with similar topography pedology and land use and simulates a water balance for each hru fig 2b the hru output qhru is a combination of surface runoff qs interflow qi and baseflow qb and contributes to a surface river network which routes the flow to the basin outlet qstream we infer the qs qi and qb flow components to represent quick intermediate and slow recharge respectively to the surface dominated stream in its original study al aamery et al 2018 the swat model was calibrated to daily discharge from 01 2006 to 01 2011 5 years and validated from 01 2011 to 01 2014 3 years model uncertainty was assessed using the swat calibration uncertainty program swat cup sufi 2 in total 260 successful swat cup realizations are integrated from the original study the simulation period in the original swat paper was 8 years but has been extended to 20 years from 01 2000 to 01 2020 thus 5 years were used for calibration 3 years for validation and 12 years for testing 2 3 methods 2 3 1 long short term memory model an lstm model is a subset of recurrent neural networks that have a dedicated memory cell state for long term learning fig 2c long term learning is useful in hydrologic systems that have seasonal flow patterns in particular snow hydrology but may be useful in simulating the memory of groundwater fed springs we follow the outline for lstm application to hydrology as laid out in kratzert and others 2018 the lstm model converts a network input sequence x x 1 x t with t time steps where each x element is a vector containing the model inputs at a particular time step t the forward pass through the lstm is described by the following set of equations 1 i t σ w i x t u i h t 1 b i 2 f t σ w f x t u f h t 1 b f 3 g t tanh w g x t u g h t 1 b g 4 o t σ w o x t u o h t 1 b o 5 c t f t c t 1 i t g t 6 h t tanh c t o t where w u and b are learnable parameters for each gate i t f t and o t are the input forget and output gates respectively g t is the cell input and h t 1 is the recurrent hidden state input c t 1 is the cell state from the previous step σ is the sigmoid function tanh is the hyperbolic tangent function is pointwise multiplication and is pointwise addition the outputs of the lstm model are the h t and c t for the next step the basic flow of the lstm network is that long term memory cell states c t are modified by the forget gate f t which can delete certain states and the input i t and cell update g t gates which can add new information lastly the output gate o t selects what information stored in the cell states is outputted the output at the final time step h t is fed through a traditional dense layer to compute final discharge q whether spring or stream as 7 q w d h t b d where w d is the learnable weight matrix of the dense layer and b d is the bias term the learnable parameters w u and b are optimized by the lstm model during the training period whereas the hyperparameters are defined prior to training a generally agreed upon method for configuring the hyperparameters presently does not exist in the literature our model was constructed within the matlab 2021 deep learning toolbox and we use many of the default hyperparameter values with slight modifications derived from published literature to prevent overfitting bai et al 2021 the customized hyperparameters are dropout rate 0 1 numhiddenunits 32 maxepochs 100 and minibatchsize 32 the input variables for the two lstm models one for royal spring and one for south elkhorn are the same as those of the numerical models daily precipitation mean temperature and potential evapotranspiration fig 3 the outputs for which the lstm models were trained on are the daily discharge from south elkhorn qse and royal spring qrs zero center normalization of training data was performed providing for faster learning process driven models are typically split into calibration validation and testing splits shen et al 2022 during calibration model parameters are tuned such that the error between modeled and observed outputs is minimized thereafter the model is validated to assess its performance during a period outside of its original calibration to evaluate the robustness of model fit model testing is the application of the model outside the original calibration and validation temporal space in the machine learning community the analogous terms for calibration validation and testing are training validation and testing typically over 70 of the dataset is used for training and validation with the remainder used for testing klotz et al 2022 kratzert et al 2019a in our case the training periods for the royal spring and south elkhorn lstm models were selected to match the existing calibration periods of the lump and swat models respectively to provide like for like cross model performance comparison likewise the validation and testing periods of the lstm models matched those of the lump and swat models thus the lstm models for south elkhorn and royal spring were trained on 25 and 10 of the total dataset respectively model performance for all periods and all models was evaluated using the modified kling gupta efficiency kge clark et al 2021 the kge is calculated as 8 k g e 1 β 2 α 1 2 ρ 1 2 where β α and ρ are the bias standard deviation correlation terms respectively β is defined as μ s μ o 2 σ o 2 where μ s is the simulated mean μ o is the observed mean and σ o is the observed standard deviation α is defined as σ s σ o where σ s is the simulated standard deviation ρ is the pearson correlation between the observed and simulated flow larger positive values of kge represent better model performance with a kge of 1 indicating a perfect match between observed and simulated flow uncertainty in lstm predictions was assessed by performing 1 000 realizations of the lstm model with dropout regularization enabled for each basin and recording output predictions and performance metrics althoff et al 2021 thereafter a prediction interval containing the inner 95th percentile was calculated from the 1 000 model realizations 2 3 2 hydrologic flow path analysis in this study we compare the hydrologic flow path estimates from process driven conceptual and physically based models to those of data driven lstm models broadly we conceptualize spring and stream flow to be a combination of three components quick intermediate and slow the three flow components are simulated continuously by the lump model for royal spring and the swat model for south elkhorn fig 2 in the fluvial south elkhorn these flow components represent runoff interflow and baseflow respectively in royal spring these components represent flow transported along conduit fracture and matrix karst features to estimate flow path contribution of the lstm models we apply an automated lyne hollick lh recursive digital filter to modeled outputs the lh filter applies signal processing techniques to a flow time series to separate high frequency signals inferred as quicker flower from low frequency signals inferred as slower flow ladson et al 2013 several passes of the lh filter can be performed with each subsequent pass separating the highest remaining frequency ladson et al 2013 for each forward pass of the lh filter the filtered high frequency flow q t h and low frequency flow q t l components can be calculated as 9 q t l a q t 1 l 1 a q t q t 1 2 10 q t h q t q t l where a is the dimensionless parameter 0 to 1 q t 1 l is the filtered low frequency flow for the previous timestep and q t 1 is the flow rate at the previous timestep larger values of a correspond with smaller values of baseflow and vice versa li et al 2014 we use a 0 925 for both royal spring and south elkhorn which is typically the default filter value li et al 2014 to separate the lstm output signal into three flow components i e quick intermediate and slow we perform multiple lh filter passes the first forward pass separates the bulk baseflow from the overall discharge eqn 9 the difference between the overall discharge and the first pass baseflow yields the quick flow magnitude eqn 10 subsequent passes further separate the baseflow into additional components i e intermediate and slow flow the number of passes needed to identify the lowest frequency component in our case slow flow can be calibrated to match results derived from alternate methods ladson et al 2013 such as numerical modeling for the royal spring and south elkhorn systems 3 and 8 forward passes respectively were required to accurately distinguish the slow flow pathway thereafter the intermediate flow was calculated as the difference between the 1st pass and the 3rd and 8th passes respectively lastly we investigated correlations between conceptual qlump and physically based qswat and lstm qlstm rdf pathway contribution estimates using a ρ value 0 50 to indicate strong correlation 2 3 3 statistical time series and frequency analyses we used auto correlation and cross correlation analyses to better understand the temporal persistence of each flow pathway and pathway response to rainfall inputs bennett et al 2013 the auto correlation function indicates the memory effect of the system and a value of 0 2 was used to represent the decorrelation lag time schuler et al 2020 cross correlation can indicate the relationship between an uncorrelated cause such as rainfall and a subsequent effect such as stream response bennett et al 2013 we determine the response time of a flow pathway as the duration between rainfall inputs and the time to peak cross correlation for the pathway the temporal structure of flow such as the dominant frequencies and self similarity of pathway contribution were investigated with spectral analysis thompson and katul 2012 to transform the flow time series into frequency space we calculated the power spectral density psd using welch s fast fourier transform algorithm if a fractal process exists in the time series it will follow a power law relationship between spectral power s and frequency f with temporal scaling of s f fβ where β is a scaling exponent that represents signal persistence or memory of a signal jiang et al 2020 this power law relationship may appear as one or more linear segments in the log log spectral density plot schuler et al 2020 we pay particular attention to the hydrologic regime portion of the psd which spans the daily to monthly return period thompson and katul 2012 and calculate β associated with that period we interpret the values of β in the following way duran et al 2020 schuler et al 2020 1 β 1 signal dominated by gaussian noise i e data pairs are independent from one another with β 0 indicating random noise 2 β 1 signal characterized by anti persistent brownian noise i e data pairs have poor correlation 3 β 2 signal characterized by persistent brownian noise i e data pairs have high correlation and a memory effect β 3 signal is structured rather than stochastic i e signal is strongly persistent we calculated β for daily total quick intermediate and slow flow for each swat lump and lstm model realization using matlab mathworks 2020 3 results 3 1 comparative model performance evaluation the lstm models performed similarly or better compared to the benchmark models swat and lump for predicting stream and spring discharge respectively over a 20 year period in the inner bluegrass region of kentucky usa fig 4 regarding the fluvial south elkhorn the median kge scores for the swat calibration validation and testing periods were 0 71 0 72 and 0 51 respectively the corresponding median lstm model scores were 0 65 0 85 and 0 58 respectively for the training validation and testing periods interestingly the south elkhorn lstm model validation metrics exceeded those of training one would expect the lstm model performance to degrade outside of the training period the reason this doesn t occur is because the storm intensity and streamflow variability were much greater during model training qmax 73 25 m3 s and σ 3 37 m3 s than validation qmax 26 45 m3 s and σ 2 77 m3 s allowing for the model to capture the mean behavior more easily during validation the out sized impact of a few extreme events to skew hydrologic model performance are commonly reported knoben et al 2019 regarding the karst royal spring the median kge scores for the lump model were 0 66 0 61 and 0 63 for the calibration validation and testing periods respectively correspondingly the royal spring median lstm model scores were 0 74 0 73 and 0 71 for the training validation and testing periods respectively while we constrained our training validation and testing periods to match the respective periods from the original lump and swat publications al aamery et al 2018 husic et al 2019b there is potential for a more complete assessment of model evaluation such as through a differential split sample test to vary evaluation periods to representatively cover hot dry cold and wet year variability in the dataset bai et al 2021 dakhlaoui et al 2020 this point notwithstanding all model structures swat lump and lstm nonetheless exhibited good performance kge 0 5 during all evaluation periods the south elkhorn and royal spring lstm models performed particularly well considering that they were trained on only 25 and 10 of the study period respectively these training durations were selected to match the original calibration periods of the hydrologic models typically over 70 of the evaluation period is chosen for training a hydrologic dataset kratzert et al 2018 even with the smaller training period the lstm models do not appear to suffer from over parameterization as their performance during the validation and training periods is similar to or exceeds that of the training period for both basins to test how well the lstm model for each basin would do under traditional training splits 80 training and 20 testing we conducted additional test runs for south elkhorn the training and testing kge values for the runs with more training data were 0 65 and 0 59 respectively and for royal spring they were 0 69 and 0 57 respectively these values are similar but not better than the shorter training validation testing splits discussed earlier ostensibly the kge values slightly worsen as more data are integrated into model training but this is primarily a result of how the kge metric is constructed where bias β standard deviation α and correlation ρ terms in equation 8 may differ depending on the window of values considered in training validation and testing some caution should be taken in directly comparing kge statistics when the duration and starting ending points of evaluation periods differ nonetheless our results suggest that to match the performance of a conceptually or physically based hydrologic model lstm models may be able to use shorter training periods than typically suggested 3 2 modeling hydrologic pathway contribution the hydrologic pathway that contributes most to streamflow in south elkhorn as indicated by swat modeling is the intermediate flow component fig 5 which constitutes 64 5 4 5 of total streamflow during the 20 year period intermediate flow for south elkhorn is most analogous to shallow lateral recharge from hillslopes to stream networks the next most prominent pathway for south elkhorn is quick flow which makes up 25 3 3 5 of total streamflow and represents surficial runoff to streams the least prominent pathway for the surface system is slow flow which represents deep aquifer recharge to the stream and accounts for 10 2 2 6 of total streamflow in royal spring lump modeling results show a differing importance of flow pathways for the karst dominated basin fig 5 intermediate flow is of second importance and contributes 33 5 21 5 of total spring discharge and represents the drainage of water through fractures in surficial epikarst slow flow representing deep recharge from matrix water storage is the dominant flow pathway in royal spring representing 46 0 20 6 of spring flow lastly quick flow or flow routed through sinkholes swallets and conduits is the pathway of least importance accounting for 20 5 8 4 of spring discharge it is important to note that while a pathway may deliver relatively less water when integrated over the 20 year period it can be temporally important during individual days weeks or seasons depending on spatiotemporal variability in recharge soil moisture and aquifer saturation for example in the south elkhorn basin runoff represents only 25 3 3 5 of total stream discharge but on the 50 wettest days of the 20 year period its contribution doubles to 53 7 13 9 likewise in the royal spring basin quickflow pathways drained only 20 5 8 4 of flow over the entire period but that number increased to 42 3 23 1 for the 50 wettest days indeed strong seasonal contributions are observed in both south elkhorn and royal spring despite their stark differences in hydrology both basins show slow flow contributions that grow during the wet season winter and spring diminish during the dry season summer and fall on the other hand intermediate flow connectivity remains high in both basins and is responsive to rainfall throughout the year and becomes relatively much more important in the dry season as deeper pathways are disconnected see apr 18 to oct 18 in south elkhorn swat in fig 5 the lstm model predictions coupled to recursive digital filtering qlstm rdf successfully simulated the hydrologic pathway contribution predicted by conceptually qlump and physically based qswat numerical models fig 5 for both basins only a single lh filter forward pass was required to accurately extract the quick and bulk baseflow fractions to further separate the bulk baseflow into intermediate and slow flow components two additional forward passes were required for royal spring and seven additional forward passes were required for south elkhorn south elkhorn requires more lh filter passes because its deeper slower baseflow is entirely disconnected from the stream for large parts of the year see south elkhorn swat in fig 5 recursive digital filters struggle representing flow components that vanish for large parts of the year and accurate characterization requires multiple additional passes royal spring on the other hand has some slow flow contribution even during periods of overall low flow magnitudes see summer before oct 18 in royal spring lump in fig 5 further the slow flow contribution in the groundwater fed spring 46 0 20 6 is more prominent than in the surface driven stream 10 2 2 6 thus the imprint of its signal is more prominent and easier for recursive digital filters to identify in the surface dominated south elkhorn lstm rdf flow contributions were strongly correlate to swat predicted contributions for quick ρ 0 59 intermediate ρ 0 61 and slow ρ 0 61 pathways likewise in royal spring lstm rdf predictions were even more correlated with lump predicted quick ρ 0 55 intermediate ρ 0 70 and slow ρ 0 71 contributions despite the relatively strong performance of the lstm rdf model for predicting flow path contribution there were some notable limitations and sources of error in the method in comparing qswat vs qlstm rdf it can be observed that on some days the lstm rdf model simulates 5 mm d 1 of quick flow contribution when the swat model predicts no runoff 0 mm d 1 this may occur because surface runoff quick flow in south elkhorn usually occurs over just a single day whereas the lstm rdf model artificially lengthens runoff duration due to how the lh filter is formulated to further understand how the various models represent the temporal structure of the flow time series we investigate fractal scaling and lag time correlation in the next section 3 3 temporal structure and response of hydrologic pathways the observed lag time for the flow time series to become de correlated was 8 days in south elkhorn compared to 64 days in royal spring fig 6 and table 1 these results were unsurprising as south elkhorn is a flashy runoff dominated stream whereas royal spring is a groundwater fed system that is primarily driven by baseflow regarding the model simulations the swat model 4 days indicated shorter decorrelation than observed in south elkhorn while the lstm model 8 days matched observations in royal spring both the modeled lump 68 and lstm 57 decorrelation generally agreed with observations with an understanding of the auto correlation of the overall flow time series we next investigated the decorrelation times for the individual flow components fig 6 and table 1 for quick intermediate and slow flow components in south elkhorn the lstm model 3 19 and 88 days respectively predicted longer median temporal persistence of flow pathways than the swat model 2 6 and 75 days respectively in royal spring the behavior was more varied as the lstm model 10 16 and 79 days respectively predicted longer persistence of quick flow but much shorter decorrelation timing of intermediate flow compared to the lump model 4 56 and 77 days respectively power spectral scaling was present in the observed and modeled flow time series for both south elkhorn and royal spring fig 7 and table 2 the scaling parameter β for the rainfall input was 0 20 not plotted indicating a generally noisy and unstructured signal however as this rainfall input is routed through physical watershed stores and discharged to basin outlets it begins to follow more organized scaling β 0 92 for south elkhorn observations and β 1 45 for royal spring observations the royal spring time series is likely more structured because the karst system attenuates the noisy rainfall input to a greater degree than the flashy south elkhorn system regarding the modeling outputs the swat model β 0 63 indicated less structure than observed in south elkhorn while the lstm model β 1 22 suggested greater structure in royal spring both the modeled lump β 1 33 and lstm β 1 94 scaling coefficients generally agreed with the observed anti persistent brownian noise we also investigated the time fractal processes of the flow components that comprise total discharge quick intermediate and slow fig 7 and table 2 in the process based south elkhorn model swat the quick intermediate and slow flow signals β 0 18 1 19 and 2 92 respectively became progressively more organized beginning at near gaussian noise then to anti persistent brownian noise and lastly to persistent brownian noise compared to the swat outputs the process based royal spring model lump showed greater coherence for all three pathways β 1 08 2 76 and 3 75 respectively in a somewhat unexpected result the corresponding lstm models had relatively similar signal coherence as the process based model outputs for the quick and intermediate pathways but not for slow flow in each basin the lstm estimated β parameter was noisier for slow flow than intermediate flow we would expect the opposite relationship to hold this result could be because of how the recursive digital filter which separates the flow paths in the lstm model is constructed while the lstm rdf estimates of flow magnitude match those of swat and lump models fig 5 the filter does not itself represent physical underlying processes ladson et al 2013 and thus may not follow scaling relationships though we tested only the lyne hollick rdf there is potential that other filtering methods could resolve this issue li et al 2014 4 discussion we used process based and data driven modeling along with correlation and spectral tools to gain insight into the contribution of multiple hydrologic flow paths to discharge generation in surface and subsurface dominated basins this section discusses our two major findings 1 we demonstrate the usefulness of data driven tools like lstm models and rdfs for approximating hydrologic flow pathway contribution and 2 we discuss the particular suitability of lstm models in settings where subsurface drainage dominates daily to monthly water fluxes 4 1 process based versus data driven modeling of hydrologic pathways in this study we assessed the utility of deep learning models to simulate hydrologic flow path contributions in two neighboring systems a surface dominated fluvial stream and a subsurface dominated karst spring using the same input data the contrasting hydrologic controls of the two systems allowed for broader inference on flow path behavior we found that the lstm models outperformed the process based swat and lump models in simulating total flow fig 4 the improved performance was more evident in the groundwater fed royal spring system than in the fluvial south elkhorn creek surprisingly this improved performance was achieved by using at most 25 of the time series for model training much less than the typical 70 split kratzert et al 2018 our results contrast recent findings that lstm network models need more training data than hydrologic models to obtain equivalent performance bai et al 2021 in bai and others 2021 the authors integrate 278 basins from the model parameter estimation experiment mopex which are much larger median 2358 km2 range 135 to 10 329 km2 than our study basins 60 km2 because our basins are smaller local heterogeneities if not properly accounted for may impact process based model performance more drastically than in larger basins which smooth heterogeneities over larger spatial scales hence the process based models in our study may slightly underperform due to unresolved physical processes that the deep learning model does not need to account for explicitly regarding the contribution of hydrologic flow pathways we found that the lstm models coupled to a lyne hollick rdf were able to match the general magnitude of quick intermediate and slow flow contributions but inadequately represented the temporal structure of the pathways despite the rdf lacking a physical basis ladson et al 2013 its predictions matched closely the process based swat lump predictions ρ between the model types ranged from 0 58 to 0 71 fig 5 the lstm rdf predictions struggled most with matching swat lump quick flow contributions this disagreement is likely a function of how the lh filter is constructed whereby increases in overall discharge propagate as increases of varying magnitude for each of the three modeled flow paths in reality time varying physical watershed conditions such as soil moisture vegetation density and land cover could convert the same precipitation input into predominantly quick flow under one set of conditions or primarily intermediate flow under another likewise a flow pathway may become deactivated despite the overall discharge increasing such as in the case of runoff quick ceasing but subsurface flow inter gaining in a stream with respect to the models the lstm simulations consistently over estimated the auto correlation of quick flow table 1 predicting longer durations of contribution than did the swat lump simulations however it is difficult to assess whether lstm or swat lump flow path estimates are more correct without additional tracers that can generate pathway contributions that are independent of flow such as isotopic e g δ2hh2o and δ18oh2o klaus and mcdonnell 2013 and chemical e g specific conductance cartwright and miller 2021 mass balance mixing models in this study we demonstrated the usefulness of data driven and statistical tools like lstm models and rdfs for approximating hydrologic flow pathway contribution despite the stated limitations these tools provide a useful first approximation of hydrologic fluxes from various components within a watershed without the need for extensive model parameterization and calibration as is the case for traditional process based numerical models moriasi et al 2012 a few additional points of consideration are how the lstm and rdf models are themselves constructed the rdf requires that a dimensionless parameter a be selected a priori which can be arbitrary unless other data are available to ascertain the value of a li et al 2014 further the number of forward and backward passes to separate flow compartments must be selected which can also be informed by other modeling estimates ladson et al 2013 in our case we use our process based numerical model to inform the likely number of passes further the lstm network requires the a priori selection of a set of hyperparameter values bai et al 2021 we select a combination of default values from the matlab deep learning toolbox and those published in previous work in a variety of hydrologic settings notwithstanding these uncertainties the presented lstm rdf model in this study provides useful modeling estimates that can be used in understanding water budgets and the timing extent and connectivity of catchment fluxes 4 2 fluvial versus groundwater control of hydrologic pathways the degree to which subsurface processes control the overall flow time series was a strong determinant in the ability of lstm models to achieve satisfactory model performance in the fluvial south elkhorn the lstm model σ 2 30 m3 s 1 was not able to match the variability in the data observations σ 3 08 m3 s 1 or swat simulations σ 3 05 m3 s 1 fig 4 for south elkhorn peak discharge is primarily driven by the amount and intensity of rainfall with larger peak rainfall generating larger extreme discharge values al aamery et al 2018 these extreme flow rates constitute a small fraction of the time series duration and are often several orders of magnitude higher than baseflow because extreme events are infrequent the lstm learning network is not able to adequately train to such infrequent extremes which results in an underestimation in the range of simulated flow values this limitation notwithstanding the lstm model still outperforms the swat model as its improved simulation of discharges within the inner quartile range makes up for its underestimation of peak flows on the other hand in the subsurface controlled royal spring both lstm σ 0 70 m3 s 1 and lump σ 0 71 m3 s 1 model simulations matched the variability in data observations σ 0 78 m3 s 1 because royal spring is groundwater fed there exists an upper limit to the maximum discharge that can be routed through underground conduits bonacci 2001 husic et al 2017a initial rainfall extremes are attenuated rather than immediately conveyed to the spring by the dynamic surficial epikarst and deeper matrix storages which put a soft upper limit on peak discharge once this upper limit to peak discharge is reached flow in the karst aquifer finds alternate energetically favorable routes of transport including by overtopping sinkholes in surface streams or by overflowing out of secondary springs the greater attenuation of the rainfall input β 0 20 at the monthly to daily hydrologic regime by royal spring β 1 45 compared to south elkhorn β 0 92 is also evident in the time fractal scaling of the basins fig 7 because the potential values of discharge in royal spring are clustered about the mean more closely the data used for training the lstm network is sufficient enough for simulating the full range of potential discharges this limited variability in the range of discharges seems particularly suited to estimation by lstm modeling frameworks the findings of our study suggest that lstm models are particularly suited to karst systems and potentially to other groundwater dominated systems in these basins precipitation inputs are highly attenuated by internal water stores an upper limit to peak discharge may exist and there exists a longer memory of previous system states due to gradual export of stored water these conditions are ideal for training a neural network while lstm models have rapidly become adopted by surface water hydrologists for studying runoff generation and streamflow bai et al 2021 fan et al 2020 klotz et al 2022 kratzert et al 2018 mao et al 2021 their application to karst systems is less extensive with the authors finding only a few studies in the literature an et al 2020 cheng et al 2021 thus there is a yet unrealized potential to simulate assess and understand karst groundwater dynamics using robust lstm modeling tools 5 conclusions in this work we compared hydrologic pathway contributions from physically based swat conceptually based lump and deep learning lstm models in a fluvial stream and a karst spring over a twenty year period the main findings were 1 all model types performed satisfactorily but the lstm model outperformed both the swat and lump models in simulating total daily discharge 2 the lstm model coupled with a recursive digital filter was able to successfully match the magnitude of process based estimates of quick intermediate and slow flow contributions for both basins 3 the process based models exhibited more realistic time fractal scaling of hydrologic flow pathways compared to the lstm models we demonstrate the utility and potential extraction of physical analogues of lstm modeling which will be useful as deep learning approaches to hydrologic modeling become more prominent and modelers look for ways to infer physical information from data driven predictions credit authorship contribution statement admin husic conceptualization investigation methodology software data curation formal analysis visualization writing original draft writing review editing nabil al aamery investigation data curation writing original draft writing review editing james f fox writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank an associate editor and two anonymous reviewers for their thorough review of our manuscript all input data code and model results are stored and publicly available via the open science framework at http www doi org 10 17605 osf io czw32 this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors the authors declare no competing financial or personal interests appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j hydroa 2022 100134 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
8540,hydrologic models are robust tools for estimating key parameters in the management of water resources including water inputs storage and pathway fluxes the selection of process based versus data driven modeling structure is an important consideration particularly as advancements in machine learning yield potential for improved model performance but at the cost of lacking physical analogues despite recent advancement there exists an absence of cross model comparison of the tradeoffs between process based and data driven model types in settings with varying hydrologic controls in this study we use physically based swat conceptually based lump and deep learning lstm models to simulate hydrologic pathway contributions for a fluvial watershed and a karst basin over a twenty year period we find that while all models are satisfactory the lstm model outperformed both the swat and lump models in simulating total discharge and that the improved performance was more evident in the groundwater dominated karst system than the surface dominated fluvial stream further the lstm model was able to achieve this improved performance with only 10 25 of the observed time series as training data regarding pathways the lstm model coupled with a recursive digital filter was able to successfully match the magnitude of process based estimates of quick intermediate and slow flow contributions for both basins ρ ranging from 0 58 to 0 71 however the process based models exhibited more realistic time fractal scaling of hydrologic flow pathways compared to the lstm model which depending on project objectives presents a potential drawback to the use of machine learning models for some hydrologic applications this study demonstrates the utility and potential extraction of physical analogues of lstm modeling which will be useful as deep learning approaches to hydrologic modeling become more prominent and modelers look for ways to infer physical information from data driven predictions keywords hydrologic modeling machine learning lstm rainfall runoff process based data driven data availability the data are stored in an online repository linked in the acknowledgements 1 introduction hydrologic modeling is a crucial tool for managing water resources and simulating water fluxes across and within the earth s surface mcmillan 2021 sit et al 2020 understanding the pathways by which rainfall inputs are routed to receiving waterbodies is a major goal for stakeholders and is crucial for managing water resources hammond et al 2021 numerous modeling approaches exist to tackle this problem including process driven and data driven models bai et al 2021 kratzert et al 2018 model selection is influenced by existing system knowledge availability of input data parameter uncertainty and access to computational resources shen 2018 sit et al 2020 questions remain regarding the tradeoffs of various modeling approaches for simulating hydrologic pathways and fluxes the prevailing paradigm of the last half century of hydrologic modeling has been the development of process driven conceptually and physically based numerical models fatichi et al 2016 razavi 2021 process driven models are constructed from empirical or analytical formulae that serve as proxies for physical phenomena such as runoff soil percolation and groundwater recharge however developing process based hydrologic models is exceptionally challenging as they are time data and computationally intensive shen 2018 in the last decade rapid advances in data driven machine learning models has provided a mechanism for equivalent or better simulation of hydrologic systems with a fraction of the overall required resources razavi 2021 shen 2018 sit et al 2020 in particular the deep learning long short term memory lstm approach has proven especially fruitful for simulation of watershed dynamics because of its ability to remember past system states kratzert et al 2018 a common refrain regarding machine learning models is that their internal workings are difficult to discern and lack physical analogues razavi 2021 to address this quite significant limitation substantial work is being done to advance our interpretation of internal deep learning states kratzert et al 2019a b read et al 2019 one particularly useful approach is to take existing calibrated process driven models and perform cross comparison with machine learning outputs bai et al 2021 kratzert et al 2018 razavi 2021 there exists the potential for developing approaches to benchmark data driven estimates of hydrologic flow pathway contribution against process driven outputs and overcome existing limitations of machine learning approaches hydrologic pathways fall into three broad classifications quick intermediate and slow flow husic et al 2019b madsen et al 2002 each pathway represents a collection of spatially and temporally distinct fluxes that connect a water store to a catchment outlet mcmillan 2022 quick flow pathways are often turbulent and spatially discrete respond rapidly to precipitation inputs and account for low long term storage of catchment water examples include surficial runoff flow in tile drains and underground caves and point source discharges slow flow is typically laminar and spatially diffuse represents significant catchment storage and sustains long term recharge to streams and springs examples of slow pathways include deep aquifer recharge and flow through bedrock pores intermediate flow components bridge the spatial and temporal scales of quick and slow flow pathways and represent the dynamic interception and routing of flow to the catchment outlet or long term storage examples of intermediate pathways include interflow and unsaturated flow in the vadose zone numerous methods exist for simulating the varying contribution of quick intermediate and slow flow to overall discharge ranging from recursive digital filters rdf and recession curves for data driven hydrograph separation singh and stenger 2018 stoelzle et al 2020 to conceptual or explicit numerical modeling al aamery et al 2021 vansteenkiste et al 2014 few studies however have assessed the uncertainty associated with the choice of method for pathway modeling which has implications for understanding the timing extent and connectivity of catchment fluxes the objective of this research was to assess the utility of deep learning models to simulate hydrologic flow path contributions in two neighboring systems a surface dominated fluvial stream and a subsurface dominated karst spring to compare outputs we use the same input data to calibrate four different models a conceptual model a physically based model and two lstm models one each for the stream and spring thereafter we tune and apply the models to a twenty year flow period at both locations we compare the quick intermediate and slow flow components generated from a modified lstm model to those of the two process driven numerical models we perform statistical evaluation of the flow components including auto correlation cross correlation and spectral analysis to understand their temporal persistence and time fractal scaling lastly we provide guidance on the applicability of deep learning models to simulate hydrologic flow path contributions in systems with varying surface subsurface dominance over hydrology 2 materials and methods 2 1 study site to meet the objectives of this study we selected two nearby basins in the inner bluegrass region of kentucky usa with similar land use and topography but vastly different hydrologic pathway controls fig 1 royal spring 58 km2 is a subsurface dominated karst system whereas south elkhorn 62 km2 is a surface dominated fluvial system the geology of the inner bluegrass region is comprised of phosphatic limestone of the middle ordovician period which experiences chemical dissolution and erosion spangler 1982 the variable dissolution of limestone bedrock results in the formation of karst features such as sinkholes caves and conduits in the royal spring basin a series of karst sinkholes and swallets redirect surface runoff into a subsurface conduit system approximately 20 m below the ground surface husic et al 2017a b which routes flow to a perennial spring for the most part these features are absent in south elkhorn mahoney et al 2018b thus its hydrology is largely unaffected by karst the climate in the region is temperate with a mean annual precipitation of 1 170 200 mm and temperature of 13 0 0 7 c land use is primarily pasture grassland with urbanized headwaters in both basins royal spring and south elkhorn have been subject to extensive field assessment and numerical modeling over the last two decades to ascertain hydrologic controls in the basins in royal spring dye tracing paylor and currens 2004 electrical resistivity testing sawyer et al 2015 zhu et al 2011 high frequency aquatic sensing husic et al 2017a water isotope tracing husic et al 2019a and numerical modeling husic et al 2019b have allowed us to develop a strong conceptual model of water storage and routing through the karst aquifer briefly event precipitation is initially captured by the basin as distributed recharge through the soil or concentrated recharge through sinkholes swallets and depressions thereafter distributed recharge percolates into the epikarst the near surface karst regolith where it can be dynamically routed to the spring or deeper aquifer during non event periods baseflow to the spring originates from both saturated and unsaturated zones of the aquifer in south elkhorn numerical modeling of hydrology al aamery et al 2018 2016 ford and fox 2014 and stable isotope tracing ford et al 2015 mahoney et al 2018a have revealed the influence of storm events to runoff dynamics and soil storage to baseflow generation hydrologic delivery in south elkhorn is largely unaffected by karst so the abstraction of surface runoff by karst holes is likely minimal thus intense precipitation events generate considerable runoff that drains into the stream network thereafter infiltrated water in the shallow and deep aquifers maintains elevated baseflow after event cessation 2 2 materials to investigate hydrologic pathway controls 20 years of daily discharge data were obtained from two united states geological survey gages south elkhorn usgs 03289000 and royal spring usgs 03288110 meteorological input data for both basins including precipitation and mean temperature were obtained from the bluegrass airport usw00093820 potential evapotranspiration was estimated using the penman monteith equation two existing calibrated numerical models were integrated into this study to serve as benchmarks for lstm model performance fig 2 these include a conceptually based model for the royal spring basin lump husic et al 2019b and a physically based model for the south elkhorn basin swat al aamery et al 2018 the lump model is a series of cascading linear reservoirs each representing an entire water storage area for the basin including the soil epikarst quickflow and phreatic zones fig 2a initially precipitation input is separated into concentrated x and diffuse 1 x fractions that contribute to quickflow and soil reservoirs respectively as these reservoirs overflow they contribute to spring discharge qspring as quick flow qq epikarst flow qe and phreatic flow qp we infer the qq qe and qp flow components to represent quick intermediate and slow recharge respectively to the subsurface dominated spring in its original study husic et al 2019b the lump model was calibrated to daily discharge from 10 2012 to 10 2014 2 years and validated from 10 2014 to 10 2016 2 years model uncertainty was estimated from millions of monte carlo realizations covering the full range of potential parametrizations in total 1 176 model realizations were deemed successful in the original study and are used in this study the simulation period in the original lump model paper covered 4 years but has been extended to 20 years here from 01 2000 to 01 2020 in summary 2 years were used for calibration 2 years for validation and 16 years for testing the swat model identifies several hydrologic response units hrus or parcels of the landscape with similar topography pedology and land use and simulates a water balance for each hru fig 2b the hru output qhru is a combination of surface runoff qs interflow qi and baseflow qb and contributes to a surface river network which routes the flow to the basin outlet qstream we infer the qs qi and qb flow components to represent quick intermediate and slow recharge respectively to the surface dominated stream in its original study al aamery et al 2018 the swat model was calibrated to daily discharge from 01 2006 to 01 2011 5 years and validated from 01 2011 to 01 2014 3 years model uncertainty was assessed using the swat calibration uncertainty program swat cup sufi 2 in total 260 successful swat cup realizations are integrated from the original study the simulation period in the original swat paper was 8 years but has been extended to 20 years from 01 2000 to 01 2020 thus 5 years were used for calibration 3 years for validation and 12 years for testing 2 3 methods 2 3 1 long short term memory model an lstm model is a subset of recurrent neural networks that have a dedicated memory cell state for long term learning fig 2c long term learning is useful in hydrologic systems that have seasonal flow patterns in particular snow hydrology but may be useful in simulating the memory of groundwater fed springs we follow the outline for lstm application to hydrology as laid out in kratzert and others 2018 the lstm model converts a network input sequence x x 1 x t with t time steps where each x element is a vector containing the model inputs at a particular time step t the forward pass through the lstm is described by the following set of equations 1 i t σ w i x t u i h t 1 b i 2 f t σ w f x t u f h t 1 b f 3 g t tanh w g x t u g h t 1 b g 4 o t σ w o x t u o h t 1 b o 5 c t f t c t 1 i t g t 6 h t tanh c t o t where w u and b are learnable parameters for each gate i t f t and o t are the input forget and output gates respectively g t is the cell input and h t 1 is the recurrent hidden state input c t 1 is the cell state from the previous step σ is the sigmoid function tanh is the hyperbolic tangent function is pointwise multiplication and is pointwise addition the outputs of the lstm model are the h t and c t for the next step the basic flow of the lstm network is that long term memory cell states c t are modified by the forget gate f t which can delete certain states and the input i t and cell update g t gates which can add new information lastly the output gate o t selects what information stored in the cell states is outputted the output at the final time step h t is fed through a traditional dense layer to compute final discharge q whether spring or stream as 7 q w d h t b d where w d is the learnable weight matrix of the dense layer and b d is the bias term the learnable parameters w u and b are optimized by the lstm model during the training period whereas the hyperparameters are defined prior to training a generally agreed upon method for configuring the hyperparameters presently does not exist in the literature our model was constructed within the matlab 2021 deep learning toolbox and we use many of the default hyperparameter values with slight modifications derived from published literature to prevent overfitting bai et al 2021 the customized hyperparameters are dropout rate 0 1 numhiddenunits 32 maxepochs 100 and minibatchsize 32 the input variables for the two lstm models one for royal spring and one for south elkhorn are the same as those of the numerical models daily precipitation mean temperature and potential evapotranspiration fig 3 the outputs for which the lstm models were trained on are the daily discharge from south elkhorn qse and royal spring qrs zero center normalization of training data was performed providing for faster learning process driven models are typically split into calibration validation and testing splits shen et al 2022 during calibration model parameters are tuned such that the error between modeled and observed outputs is minimized thereafter the model is validated to assess its performance during a period outside of its original calibration to evaluate the robustness of model fit model testing is the application of the model outside the original calibration and validation temporal space in the machine learning community the analogous terms for calibration validation and testing are training validation and testing typically over 70 of the dataset is used for training and validation with the remainder used for testing klotz et al 2022 kratzert et al 2019a in our case the training periods for the royal spring and south elkhorn lstm models were selected to match the existing calibration periods of the lump and swat models respectively to provide like for like cross model performance comparison likewise the validation and testing periods of the lstm models matched those of the lump and swat models thus the lstm models for south elkhorn and royal spring were trained on 25 and 10 of the total dataset respectively model performance for all periods and all models was evaluated using the modified kling gupta efficiency kge clark et al 2021 the kge is calculated as 8 k g e 1 β 2 α 1 2 ρ 1 2 where β α and ρ are the bias standard deviation correlation terms respectively β is defined as μ s μ o 2 σ o 2 where μ s is the simulated mean μ o is the observed mean and σ o is the observed standard deviation α is defined as σ s σ o where σ s is the simulated standard deviation ρ is the pearson correlation between the observed and simulated flow larger positive values of kge represent better model performance with a kge of 1 indicating a perfect match between observed and simulated flow uncertainty in lstm predictions was assessed by performing 1 000 realizations of the lstm model with dropout regularization enabled for each basin and recording output predictions and performance metrics althoff et al 2021 thereafter a prediction interval containing the inner 95th percentile was calculated from the 1 000 model realizations 2 3 2 hydrologic flow path analysis in this study we compare the hydrologic flow path estimates from process driven conceptual and physically based models to those of data driven lstm models broadly we conceptualize spring and stream flow to be a combination of three components quick intermediate and slow the three flow components are simulated continuously by the lump model for royal spring and the swat model for south elkhorn fig 2 in the fluvial south elkhorn these flow components represent runoff interflow and baseflow respectively in royal spring these components represent flow transported along conduit fracture and matrix karst features to estimate flow path contribution of the lstm models we apply an automated lyne hollick lh recursive digital filter to modeled outputs the lh filter applies signal processing techniques to a flow time series to separate high frequency signals inferred as quicker flower from low frequency signals inferred as slower flow ladson et al 2013 several passes of the lh filter can be performed with each subsequent pass separating the highest remaining frequency ladson et al 2013 for each forward pass of the lh filter the filtered high frequency flow q t h and low frequency flow q t l components can be calculated as 9 q t l a q t 1 l 1 a q t q t 1 2 10 q t h q t q t l where a is the dimensionless parameter 0 to 1 q t 1 l is the filtered low frequency flow for the previous timestep and q t 1 is the flow rate at the previous timestep larger values of a correspond with smaller values of baseflow and vice versa li et al 2014 we use a 0 925 for both royal spring and south elkhorn which is typically the default filter value li et al 2014 to separate the lstm output signal into three flow components i e quick intermediate and slow we perform multiple lh filter passes the first forward pass separates the bulk baseflow from the overall discharge eqn 9 the difference between the overall discharge and the first pass baseflow yields the quick flow magnitude eqn 10 subsequent passes further separate the baseflow into additional components i e intermediate and slow flow the number of passes needed to identify the lowest frequency component in our case slow flow can be calibrated to match results derived from alternate methods ladson et al 2013 such as numerical modeling for the royal spring and south elkhorn systems 3 and 8 forward passes respectively were required to accurately distinguish the slow flow pathway thereafter the intermediate flow was calculated as the difference between the 1st pass and the 3rd and 8th passes respectively lastly we investigated correlations between conceptual qlump and physically based qswat and lstm qlstm rdf pathway contribution estimates using a ρ value 0 50 to indicate strong correlation 2 3 3 statistical time series and frequency analyses we used auto correlation and cross correlation analyses to better understand the temporal persistence of each flow pathway and pathway response to rainfall inputs bennett et al 2013 the auto correlation function indicates the memory effect of the system and a value of 0 2 was used to represent the decorrelation lag time schuler et al 2020 cross correlation can indicate the relationship between an uncorrelated cause such as rainfall and a subsequent effect such as stream response bennett et al 2013 we determine the response time of a flow pathway as the duration between rainfall inputs and the time to peak cross correlation for the pathway the temporal structure of flow such as the dominant frequencies and self similarity of pathway contribution were investigated with spectral analysis thompson and katul 2012 to transform the flow time series into frequency space we calculated the power spectral density psd using welch s fast fourier transform algorithm if a fractal process exists in the time series it will follow a power law relationship between spectral power s and frequency f with temporal scaling of s f fβ where β is a scaling exponent that represents signal persistence or memory of a signal jiang et al 2020 this power law relationship may appear as one or more linear segments in the log log spectral density plot schuler et al 2020 we pay particular attention to the hydrologic regime portion of the psd which spans the daily to monthly return period thompson and katul 2012 and calculate β associated with that period we interpret the values of β in the following way duran et al 2020 schuler et al 2020 1 β 1 signal dominated by gaussian noise i e data pairs are independent from one another with β 0 indicating random noise 2 β 1 signal characterized by anti persistent brownian noise i e data pairs have poor correlation 3 β 2 signal characterized by persistent brownian noise i e data pairs have high correlation and a memory effect β 3 signal is structured rather than stochastic i e signal is strongly persistent we calculated β for daily total quick intermediate and slow flow for each swat lump and lstm model realization using matlab mathworks 2020 3 results 3 1 comparative model performance evaluation the lstm models performed similarly or better compared to the benchmark models swat and lump for predicting stream and spring discharge respectively over a 20 year period in the inner bluegrass region of kentucky usa fig 4 regarding the fluvial south elkhorn the median kge scores for the swat calibration validation and testing periods were 0 71 0 72 and 0 51 respectively the corresponding median lstm model scores were 0 65 0 85 and 0 58 respectively for the training validation and testing periods interestingly the south elkhorn lstm model validation metrics exceeded those of training one would expect the lstm model performance to degrade outside of the training period the reason this doesn t occur is because the storm intensity and streamflow variability were much greater during model training qmax 73 25 m3 s and σ 3 37 m3 s than validation qmax 26 45 m3 s and σ 2 77 m3 s allowing for the model to capture the mean behavior more easily during validation the out sized impact of a few extreme events to skew hydrologic model performance are commonly reported knoben et al 2019 regarding the karst royal spring the median kge scores for the lump model were 0 66 0 61 and 0 63 for the calibration validation and testing periods respectively correspondingly the royal spring median lstm model scores were 0 74 0 73 and 0 71 for the training validation and testing periods respectively while we constrained our training validation and testing periods to match the respective periods from the original lump and swat publications al aamery et al 2018 husic et al 2019b there is potential for a more complete assessment of model evaluation such as through a differential split sample test to vary evaluation periods to representatively cover hot dry cold and wet year variability in the dataset bai et al 2021 dakhlaoui et al 2020 this point notwithstanding all model structures swat lump and lstm nonetheless exhibited good performance kge 0 5 during all evaluation periods the south elkhorn and royal spring lstm models performed particularly well considering that they were trained on only 25 and 10 of the study period respectively these training durations were selected to match the original calibration periods of the hydrologic models typically over 70 of the evaluation period is chosen for training a hydrologic dataset kratzert et al 2018 even with the smaller training period the lstm models do not appear to suffer from over parameterization as their performance during the validation and training periods is similar to or exceeds that of the training period for both basins to test how well the lstm model for each basin would do under traditional training splits 80 training and 20 testing we conducted additional test runs for south elkhorn the training and testing kge values for the runs with more training data were 0 65 and 0 59 respectively and for royal spring they were 0 69 and 0 57 respectively these values are similar but not better than the shorter training validation testing splits discussed earlier ostensibly the kge values slightly worsen as more data are integrated into model training but this is primarily a result of how the kge metric is constructed where bias β standard deviation α and correlation ρ terms in equation 8 may differ depending on the window of values considered in training validation and testing some caution should be taken in directly comparing kge statistics when the duration and starting ending points of evaluation periods differ nonetheless our results suggest that to match the performance of a conceptually or physically based hydrologic model lstm models may be able to use shorter training periods than typically suggested 3 2 modeling hydrologic pathway contribution the hydrologic pathway that contributes most to streamflow in south elkhorn as indicated by swat modeling is the intermediate flow component fig 5 which constitutes 64 5 4 5 of total streamflow during the 20 year period intermediate flow for south elkhorn is most analogous to shallow lateral recharge from hillslopes to stream networks the next most prominent pathway for south elkhorn is quick flow which makes up 25 3 3 5 of total streamflow and represents surficial runoff to streams the least prominent pathway for the surface system is slow flow which represents deep aquifer recharge to the stream and accounts for 10 2 2 6 of total streamflow in royal spring lump modeling results show a differing importance of flow pathways for the karst dominated basin fig 5 intermediate flow is of second importance and contributes 33 5 21 5 of total spring discharge and represents the drainage of water through fractures in surficial epikarst slow flow representing deep recharge from matrix water storage is the dominant flow pathway in royal spring representing 46 0 20 6 of spring flow lastly quick flow or flow routed through sinkholes swallets and conduits is the pathway of least importance accounting for 20 5 8 4 of spring discharge it is important to note that while a pathway may deliver relatively less water when integrated over the 20 year period it can be temporally important during individual days weeks or seasons depending on spatiotemporal variability in recharge soil moisture and aquifer saturation for example in the south elkhorn basin runoff represents only 25 3 3 5 of total stream discharge but on the 50 wettest days of the 20 year period its contribution doubles to 53 7 13 9 likewise in the royal spring basin quickflow pathways drained only 20 5 8 4 of flow over the entire period but that number increased to 42 3 23 1 for the 50 wettest days indeed strong seasonal contributions are observed in both south elkhorn and royal spring despite their stark differences in hydrology both basins show slow flow contributions that grow during the wet season winter and spring diminish during the dry season summer and fall on the other hand intermediate flow connectivity remains high in both basins and is responsive to rainfall throughout the year and becomes relatively much more important in the dry season as deeper pathways are disconnected see apr 18 to oct 18 in south elkhorn swat in fig 5 the lstm model predictions coupled to recursive digital filtering qlstm rdf successfully simulated the hydrologic pathway contribution predicted by conceptually qlump and physically based qswat numerical models fig 5 for both basins only a single lh filter forward pass was required to accurately extract the quick and bulk baseflow fractions to further separate the bulk baseflow into intermediate and slow flow components two additional forward passes were required for royal spring and seven additional forward passes were required for south elkhorn south elkhorn requires more lh filter passes because its deeper slower baseflow is entirely disconnected from the stream for large parts of the year see south elkhorn swat in fig 5 recursive digital filters struggle representing flow components that vanish for large parts of the year and accurate characterization requires multiple additional passes royal spring on the other hand has some slow flow contribution even during periods of overall low flow magnitudes see summer before oct 18 in royal spring lump in fig 5 further the slow flow contribution in the groundwater fed spring 46 0 20 6 is more prominent than in the surface driven stream 10 2 2 6 thus the imprint of its signal is more prominent and easier for recursive digital filters to identify in the surface dominated south elkhorn lstm rdf flow contributions were strongly correlate to swat predicted contributions for quick ρ 0 59 intermediate ρ 0 61 and slow ρ 0 61 pathways likewise in royal spring lstm rdf predictions were even more correlated with lump predicted quick ρ 0 55 intermediate ρ 0 70 and slow ρ 0 71 contributions despite the relatively strong performance of the lstm rdf model for predicting flow path contribution there were some notable limitations and sources of error in the method in comparing qswat vs qlstm rdf it can be observed that on some days the lstm rdf model simulates 5 mm d 1 of quick flow contribution when the swat model predicts no runoff 0 mm d 1 this may occur because surface runoff quick flow in south elkhorn usually occurs over just a single day whereas the lstm rdf model artificially lengthens runoff duration due to how the lh filter is formulated to further understand how the various models represent the temporal structure of the flow time series we investigate fractal scaling and lag time correlation in the next section 3 3 temporal structure and response of hydrologic pathways the observed lag time for the flow time series to become de correlated was 8 days in south elkhorn compared to 64 days in royal spring fig 6 and table 1 these results were unsurprising as south elkhorn is a flashy runoff dominated stream whereas royal spring is a groundwater fed system that is primarily driven by baseflow regarding the model simulations the swat model 4 days indicated shorter decorrelation than observed in south elkhorn while the lstm model 8 days matched observations in royal spring both the modeled lump 68 and lstm 57 decorrelation generally agreed with observations with an understanding of the auto correlation of the overall flow time series we next investigated the decorrelation times for the individual flow components fig 6 and table 1 for quick intermediate and slow flow components in south elkhorn the lstm model 3 19 and 88 days respectively predicted longer median temporal persistence of flow pathways than the swat model 2 6 and 75 days respectively in royal spring the behavior was more varied as the lstm model 10 16 and 79 days respectively predicted longer persistence of quick flow but much shorter decorrelation timing of intermediate flow compared to the lump model 4 56 and 77 days respectively power spectral scaling was present in the observed and modeled flow time series for both south elkhorn and royal spring fig 7 and table 2 the scaling parameter β for the rainfall input was 0 20 not plotted indicating a generally noisy and unstructured signal however as this rainfall input is routed through physical watershed stores and discharged to basin outlets it begins to follow more organized scaling β 0 92 for south elkhorn observations and β 1 45 for royal spring observations the royal spring time series is likely more structured because the karst system attenuates the noisy rainfall input to a greater degree than the flashy south elkhorn system regarding the modeling outputs the swat model β 0 63 indicated less structure than observed in south elkhorn while the lstm model β 1 22 suggested greater structure in royal spring both the modeled lump β 1 33 and lstm β 1 94 scaling coefficients generally agreed with the observed anti persistent brownian noise we also investigated the time fractal processes of the flow components that comprise total discharge quick intermediate and slow fig 7 and table 2 in the process based south elkhorn model swat the quick intermediate and slow flow signals β 0 18 1 19 and 2 92 respectively became progressively more organized beginning at near gaussian noise then to anti persistent brownian noise and lastly to persistent brownian noise compared to the swat outputs the process based royal spring model lump showed greater coherence for all three pathways β 1 08 2 76 and 3 75 respectively in a somewhat unexpected result the corresponding lstm models had relatively similar signal coherence as the process based model outputs for the quick and intermediate pathways but not for slow flow in each basin the lstm estimated β parameter was noisier for slow flow than intermediate flow we would expect the opposite relationship to hold this result could be because of how the recursive digital filter which separates the flow paths in the lstm model is constructed while the lstm rdf estimates of flow magnitude match those of swat and lump models fig 5 the filter does not itself represent physical underlying processes ladson et al 2013 and thus may not follow scaling relationships though we tested only the lyne hollick rdf there is potential that other filtering methods could resolve this issue li et al 2014 4 discussion we used process based and data driven modeling along with correlation and spectral tools to gain insight into the contribution of multiple hydrologic flow paths to discharge generation in surface and subsurface dominated basins this section discusses our two major findings 1 we demonstrate the usefulness of data driven tools like lstm models and rdfs for approximating hydrologic flow pathway contribution and 2 we discuss the particular suitability of lstm models in settings where subsurface drainage dominates daily to monthly water fluxes 4 1 process based versus data driven modeling of hydrologic pathways in this study we assessed the utility of deep learning models to simulate hydrologic flow path contributions in two neighboring systems a surface dominated fluvial stream and a subsurface dominated karst spring using the same input data the contrasting hydrologic controls of the two systems allowed for broader inference on flow path behavior we found that the lstm models outperformed the process based swat and lump models in simulating total flow fig 4 the improved performance was more evident in the groundwater fed royal spring system than in the fluvial south elkhorn creek surprisingly this improved performance was achieved by using at most 25 of the time series for model training much less than the typical 70 split kratzert et al 2018 our results contrast recent findings that lstm network models need more training data than hydrologic models to obtain equivalent performance bai et al 2021 in bai and others 2021 the authors integrate 278 basins from the model parameter estimation experiment mopex which are much larger median 2358 km2 range 135 to 10 329 km2 than our study basins 60 km2 because our basins are smaller local heterogeneities if not properly accounted for may impact process based model performance more drastically than in larger basins which smooth heterogeneities over larger spatial scales hence the process based models in our study may slightly underperform due to unresolved physical processes that the deep learning model does not need to account for explicitly regarding the contribution of hydrologic flow pathways we found that the lstm models coupled to a lyne hollick rdf were able to match the general magnitude of quick intermediate and slow flow contributions but inadequately represented the temporal structure of the pathways despite the rdf lacking a physical basis ladson et al 2013 its predictions matched closely the process based swat lump predictions ρ between the model types ranged from 0 58 to 0 71 fig 5 the lstm rdf predictions struggled most with matching swat lump quick flow contributions this disagreement is likely a function of how the lh filter is constructed whereby increases in overall discharge propagate as increases of varying magnitude for each of the three modeled flow paths in reality time varying physical watershed conditions such as soil moisture vegetation density and land cover could convert the same precipitation input into predominantly quick flow under one set of conditions or primarily intermediate flow under another likewise a flow pathway may become deactivated despite the overall discharge increasing such as in the case of runoff quick ceasing but subsurface flow inter gaining in a stream with respect to the models the lstm simulations consistently over estimated the auto correlation of quick flow table 1 predicting longer durations of contribution than did the swat lump simulations however it is difficult to assess whether lstm or swat lump flow path estimates are more correct without additional tracers that can generate pathway contributions that are independent of flow such as isotopic e g δ2hh2o and δ18oh2o klaus and mcdonnell 2013 and chemical e g specific conductance cartwright and miller 2021 mass balance mixing models in this study we demonstrated the usefulness of data driven and statistical tools like lstm models and rdfs for approximating hydrologic flow pathway contribution despite the stated limitations these tools provide a useful first approximation of hydrologic fluxes from various components within a watershed without the need for extensive model parameterization and calibration as is the case for traditional process based numerical models moriasi et al 2012 a few additional points of consideration are how the lstm and rdf models are themselves constructed the rdf requires that a dimensionless parameter a be selected a priori which can be arbitrary unless other data are available to ascertain the value of a li et al 2014 further the number of forward and backward passes to separate flow compartments must be selected which can also be informed by other modeling estimates ladson et al 2013 in our case we use our process based numerical model to inform the likely number of passes further the lstm network requires the a priori selection of a set of hyperparameter values bai et al 2021 we select a combination of default values from the matlab deep learning toolbox and those published in previous work in a variety of hydrologic settings notwithstanding these uncertainties the presented lstm rdf model in this study provides useful modeling estimates that can be used in understanding water budgets and the timing extent and connectivity of catchment fluxes 4 2 fluvial versus groundwater control of hydrologic pathways the degree to which subsurface processes control the overall flow time series was a strong determinant in the ability of lstm models to achieve satisfactory model performance in the fluvial south elkhorn the lstm model σ 2 30 m3 s 1 was not able to match the variability in the data observations σ 3 08 m3 s 1 or swat simulations σ 3 05 m3 s 1 fig 4 for south elkhorn peak discharge is primarily driven by the amount and intensity of rainfall with larger peak rainfall generating larger extreme discharge values al aamery et al 2018 these extreme flow rates constitute a small fraction of the time series duration and are often several orders of magnitude higher than baseflow because extreme events are infrequent the lstm learning network is not able to adequately train to such infrequent extremes which results in an underestimation in the range of simulated flow values this limitation notwithstanding the lstm model still outperforms the swat model as its improved simulation of discharges within the inner quartile range makes up for its underestimation of peak flows on the other hand in the subsurface controlled royal spring both lstm σ 0 70 m3 s 1 and lump σ 0 71 m3 s 1 model simulations matched the variability in data observations σ 0 78 m3 s 1 because royal spring is groundwater fed there exists an upper limit to the maximum discharge that can be routed through underground conduits bonacci 2001 husic et al 2017a initial rainfall extremes are attenuated rather than immediately conveyed to the spring by the dynamic surficial epikarst and deeper matrix storages which put a soft upper limit on peak discharge once this upper limit to peak discharge is reached flow in the karst aquifer finds alternate energetically favorable routes of transport including by overtopping sinkholes in surface streams or by overflowing out of secondary springs the greater attenuation of the rainfall input β 0 20 at the monthly to daily hydrologic regime by royal spring β 1 45 compared to south elkhorn β 0 92 is also evident in the time fractal scaling of the basins fig 7 because the potential values of discharge in royal spring are clustered about the mean more closely the data used for training the lstm network is sufficient enough for simulating the full range of potential discharges this limited variability in the range of discharges seems particularly suited to estimation by lstm modeling frameworks the findings of our study suggest that lstm models are particularly suited to karst systems and potentially to other groundwater dominated systems in these basins precipitation inputs are highly attenuated by internal water stores an upper limit to peak discharge may exist and there exists a longer memory of previous system states due to gradual export of stored water these conditions are ideal for training a neural network while lstm models have rapidly become adopted by surface water hydrologists for studying runoff generation and streamflow bai et al 2021 fan et al 2020 klotz et al 2022 kratzert et al 2018 mao et al 2021 their application to karst systems is less extensive with the authors finding only a few studies in the literature an et al 2020 cheng et al 2021 thus there is a yet unrealized potential to simulate assess and understand karst groundwater dynamics using robust lstm modeling tools 5 conclusions in this work we compared hydrologic pathway contributions from physically based swat conceptually based lump and deep learning lstm models in a fluvial stream and a karst spring over a twenty year period the main findings were 1 all model types performed satisfactorily but the lstm model outperformed both the swat and lump models in simulating total daily discharge 2 the lstm model coupled with a recursive digital filter was able to successfully match the magnitude of process based estimates of quick intermediate and slow flow contributions for both basins 3 the process based models exhibited more realistic time fractal scaling of hydrologic flow pathways compared to the lstm models we demonstrate the utility and potential extraction of physical analogues of lstm modeling which will be useful as deep learning approaches to hydrologic modeling become more prominent and modelers look for ways to infer physical information from data driven predictions credit authorship contribution statement admin husic conceptualization investigation methodology software data curation formal analysis visualization writing original draft writing review editing nabil al aamery investigation data curation writing original draft writing review editing james f fox writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank an associate editor and two anonymous reviewers for their thorough review of our manuscript all input data code and model results are stored and publicly available via the open science framework at http www doi org 10 17605 osf io czw32 this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors the authors declare no competing financial or personal interests appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j hydroa 2022 100134 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
8541,water temperature plays a primary role in driving ecological processes in streams due to its direct impact on biogeochemical cycles and the physiological processes of stream fauna such as growth development and the timing of life history events streams influenced by snowpack melt are generally cooler in the summer and demonstrate less sensitivity to climate variability in what is commonly referred to as climate buffering despite the substantial influence of snowpack on stream temperature and expected changes in snowpack accumulation and melt timing with climate change methods for representing snowpack in statistical models for stream temperature have not been well explored in this investigation we quantified the extent of stream temperature buffering in free flowing streams across a geographically diverse region in the pacific northwest usa we demonstrated that statistical models of daily mean stream temperature can be improved by explicitly accounting for temporal variability in a small number of climate covariates believed to be mechanistically related to stream temperature our novel statistical approach included as predictors combinations and interactions between the following variables 1 air temperature 2 lagged air temperature where the lag duration varied according to its relationship with flow on a given day at that site 3 flow 4 snowpack in the upstream catchment and 5 day of year we found that sites with substantial snow influence were associated with increased air temperature buffering during the warm season and longer air temperature lags 30 days during spring high flows and 10 days during late summer low flows compared to sites where precipitation predominantly fell as rain 6 days year round by accounting for snowpack and temporal variation in lagged heat transfer processes our models were able to accurately predict seasonal patterns and interannual variability in stream temperature in validation data from years not used in model fits using publicly available data sources average rmpse 0 80 keywords stream temperature snowpack hydrology climate change salmon pacific northwest climate buffering headwaters modeling data availability data are available from zenodo org communities riverscapes 1 introduction stream temperatures in headwater streams that are influenced by snowpack are generally less sensitive to variation in climate and demonstrate larger differences between air and water temperature during the warm season mayer 2012 luce et al 2014a lisi et al 2015 snowmelt leads to a direct input of cold water and a corresponding increase in flow rates and depths which mitigates the impact of surface heat exchanges by increasing thermal inertia van vliet et al 2011 in addition snowpack accumulation shifts runoff from the cold season towards the warm season and snowmelt can recharge groundwater leading to higher flows in the summer even after the disappearance of the snowpack safeeq et al 2013 however the buffering effect of snowpack varies with interannual variation in accumulation and the continuation of climate buffering depends on the future of the snowpack lisi et al 2015 yan et al 2021 there is evidence that spring snowpack has already declined as a result of increases in air temperature throughout the northern hemisphere stewart 2009 and in the pacific northwest in particular stoelinga et al 2010 mote et al 2018 zeng et al 2018 climate models suggest that declines in snowpack accumulation and trends towards earlier melt in the pacific northwest are likely to accelerate with climate change as winter air temperatures continue to increase sridhar et al 2012 chegwidden et al 2019 marshall et al 2019 future declines in snowpack are predicted to lead to decreases in streamflow during the warm season vano et al 2015 particularly in slow draining streams with substantial snowpack and groundwater exchange tague and grant 2009 in addition more frequent high flow events during the winter are also expected chegwidden et al 2019 chegwidden et al 2020 queen et al 2021 in regions where winter air temperatures currently average just below freezing such as in the cascade mountain range the resulting reduction in snowpack accumulation and shifts towards earlier peak flows from spring melt are likely to be substantial stewart 2009 minder 2010 sproles et al 2013 luce et al 2014b chegwidden et al 2019 as warming continues colder and higher elevation regions will also likely experience similar declines in snowpack accumulation and shifts in streamflow timing increases in stream temperature with climate change are likely to be greatest in watersheds that transition from snow dominated most precipitation falling as snow to rain dominated precipitation predominantly falling as rain yan et al 2021 these streams will not only be impacted by increases in air temperature but will also lose the stream temperature buffering created by the direct influx of cool snowpack melt and increased thermal inertia with higher warm season flows ficklin et al 2014 this will result in higher peak summer stream temperatures and a longer seasonal duration of warm stream temperatures jones et al 2017 in addition the loss of snowpack is likely to lead to more homogenous stream temperatures in mountainous basins cline et al 2020 which could have impacts on biota through a reduction in stream temperature controlled habitat mosaics stanford et al 2017 brennan et al 2019 statistical models are commonly used to estimate spatial and temporal patterns in stream temperatures most statistical models use air temperature data which is widely available as a proxy for physical net heat exchanges driven by solar radiation e g mohseni et al 1998 however the relationship between stream temperature and air temperature varies seasonally and across years with the accumulation of snowpack lisi et al 2015 consequently models that are dependent on air temperature but do not account for the mitigating impact of direct cooling and increased thermal inertia created by snowpack and groundwater are not likely to produce accurate predictions across interannual environmental variability and may greatly underestimate changes in stream temperature with climate change arismendi et al 2014 leach and moore 2019 accordingly there is a need to produce statistical models that better account for mechanistic processes such as groundwater and snowpack influence that interact with air temperature arismendi et al 2012 while the need to incorporate the influence of snowpack and resulting patterns in discharge into stream temperature models is clear the best ways to parameterize this impact for statistical models has not been well examined in the literature ouellet et al 2020 additionally most statistical stream temperature modeling approaches do not use variables and interactions that are capable of representing time varying mechanistic climatic controls on stream temperature siegel and volk 2019 ouellet et al 2020 as a consequence many modeling techniques reduce the temporal scope of predictions to simplified metrics e g mean august temperature as opposed to continuous daily predictions isaak et al 2017 greatly limiting their utility however recent work has shown that by incorporating important interactions between climate and spatial variables statistical models can produce continuous precise and accurate predictions of daily stream temperature jackson et al 2018 siegel and volk 2019 these spatiotemporal models were able to extend predictions to years outside the fitted data demonstrating an ability to capture interannual environmental variability by incorporating the climatic influences of air temperature snowpack flow and their interdependence our first objective in this study was to examine how variation in snowpack accumulation relates to stream temperature lags and warm season air temperature buffering at sites throughout the pacific northwest usa our second objective was to build on the generalized additive modeling gams approach demonstrated by siegel and volk 2019 to explore two potential improvements to the parameterization of climate impacts on stream temperature in statistical models 1 we incorporated publicly available temporally and spatially comprehensive data to parameterize the interacting impacts of air temperature snowpack and flow and 2 we tested the ability of a flow predicted flexible lag period air temperature metric to better capture how the impact of air temperature is modulated by thermal inertia and other lag inducing processes we hypothesized that snowpack influenced sites would demonstrate longer air temperature lag periods and stronger warm season buffering compared to rain dominated sites and that while incorporating a flexible lag air temperature metric would improve the model predictions for all sites it would be particularly beneficial in snow dominated sites 2 methods 2 1 study region and spatial network our study focused on the free flowing streams in the pacific northwest of the united states this region encompasses diverse topography and climates including coastal rainforest high mountain ranges and interior deserts stream temperature is of particular concern in this region given the potential impacts of climate change on pacific salmon and resident trout many populations of which are listed under the endangered species act wenger et al 2011 beechie et al 2012 crozier et al 2019 we defined free flowing streams as those upstream of the influence of major dams we defined major dams in the global reservoir and dam database grand v1 3 lehner et al 2011 as those with capacity 0 1 km3 and dams 15 24 m 50 ft from the national inventory of dams 2018 https nid usace army mil that were not included in grand and omitting 43 off channel dams n 299 specifically our spatial scope included sites throughout region 17 from the national hydrography dataset 1 100 k nhdplus version 2 usgs network of stream reaches provided by the us geological survey mckay et al 2012 this region is primarily composed of the columbia river basin but also includes puget sound coastal washington and coastal oregon from the rogue river basin north 2 2 data stream temperature and climate predictor data sources are summarized in table 1 and described in more detail in the following sections 2 2 1 and 2 2 2 2 2 1 stream temperature we analyzed stream temperature data from two sources the norwest raw stream temperature dataset 1993 2011 and from regional u s geological survey usgs stream gages with paired flow and stream temperature data 1993 2017 the norwest dataset represents data collated and quality controlled from a variety of sources isaak et al 2017 we used mean daily values from both datasets because we wanted to compare our methods using measured flow data from usgs sites to modeled flow data from the national water model which we used in lieu of available flow measurements at norwest sites see section 2 2 2 climate predictor data because the norwest and usgs datasets produced similar results we discuss relevant differences in the results section we henceforth focused on the larger and more spatially comprehensive norwest dataset and provided results from the usgs dataset in the text and supplementary materials to parameterize air temperature lags and fit models we used sites with full or nearly full years of data accordingly we subset our dataset to include only years of data at sites with 320 days and four or more years of data to capture interannual climate variability the resulting 389 norwest sites and 59 usgs sites used in this analysis were spread throughout the pacific northwest with watershed areas ranging from 2 1 to 14 271 km2 table 1 and fig 1 2 2 2 predictors we incorporated modeled spatiotemporal climate data for air temperature snowpack and stream flow from publicly available sources fig 2 and table 1 we obtained air temperature data from the 4 km 16 km2 prism dataset of modeled daily air temperature for the contiguous united states prism climate group oregon state university http prism oregonstate edu and downloaded raster files for each day of the 1993 2017 study period di luzio et al 2008 we acquired snow water equivalent data swe from the 4 km 16 km2 gridded modeled dataset provided by the national snow and ice data center broxton et al 2019 swe represents the quantity of water present in the snowpack as a depth mm if it was liquid annual netcdf files for swe which contain information on daily values were downloaded for the study period https nsidc org data nsidc 0719 versions 1 finally for flow data at norwest sites we used retrospective estimates of daily streamflow m3 s from the national water model nwm version 2 0 office of water prediction 2021 the nwm is a hydrologic model that incorporates weather data a land surface model and water routing to estimate instream flows for the continental united states the nwm flow predictions are produced for the nhdplus version 2 network for our metric of flow q we downloaded instream flows for 12 00 gmt for all reaches for each day in the study period qualitative comparisons between the nwm predictions and usgs measured flow data suggested that the nwm generally captured hydrologic patterns in free flowing streams in the pacific northwest and the overlapping data was highly correlated pearson s product moment correlation 0 90 however the nwm demonstrated some inconsistency in capturing the magnitude and exact timing of flow events and some spatial biases we summarized daily means values of prism air temperature ta by reach contributing areas rcas defined as the area that drains directly into a stream reach most rcas were smaller than the 4x4km prism grid cells and thus we applied the air temperature value of the centroid point of the rca for larger rcas 32 km2 we used the mean value of all prism grid cells that had their centroid point within the rca lagged values of air temperature were also produced by averaging ta over a range of time periods ending on the day of interest including 3 6 9 12 15 20 25 30 40 50 and 60 days we summarized daily values of snowpack on the watershed scale sws by taking the mean value of snow water equivalent swe of all rcas including and upstream of the reach of interest weighted by the rca areas thus sws represents the mean swe of the entire area draining into a site on the day of interest allowing for the influence of snowpack upstream to be captured even if there is no snowpack present at the site 2 3 objective 1 thermal lags and air water temperature differences 2 3 1 thermal lag quantification we created a new air temperature metric to test as a variable in modeling to account for temporal variation in stream temperature lags defined as the time period it takes a stream to come to equilibrium with the ambient environment this metric aims to directly account for variation in thermal inertia as a consequence of flow which alters the rate of temperature change and transportation rates in streams in addition it indirectly accounts for direct cooling from snowpack melt and the temperature mitigating impact of groundwater these direct influences increase the duration of lags by creating larger differences in temperatures between the environment and the stream we hypothesized that rain dominated sites would demonstrate shorter air temperature lag periods than snow dominated sites due to a lower influence of snowpack melt and groundwater in these streams accordingly we processed rain and snow dominated sites independently rain dominated sites in the pacific northwest generally receive infrequent snowfall and thus generally record small but positive average snowpacks averaging 20 mm thus we defined rain dominated sites as those from 1993 to 2017 that had average annual sws 20 mm and snow dominated sites as those 20 mm to distinguish them from sites that regularly receive snowfall our norwest and usgs datasets contained 287 and 36 snow dominated sites and 102 and 23 rain dominated sites respectively rain dominated sites tended to be at lower elevations and demonstrated higher mean stream temperatures than snow dominated sites fig 3 and supfig 1 while norwest rain and snow dominated sites had similar distributions of precipitation and flow usgs rain dominated sites were substantially drier on average than snow dominated sites fig 3b and d norwest and supfig 1b and d usgs to create our thermal lag period metric we first calculated a flow anomaly by fitting a linear model to all sites with the average annual log transformed flow as the response variable and the log transformed drainage area as the predictor variable we subtracted daily flows from the expected drainage area mean annual flow predicted by the linear model to produce a log scale flow anomaly metric we split the daily data for snow and rain dominated sites independently into 500 groups separated by 0 2 quantiles of the resulting flow anomaly metric 200 groups and 0 5 quantiles for the usgs dataset due to lower sample sizes second we calculated correlations between stream temperature in each of the groups and all air temperature metrics including each of the lagged periods 1 3 6 9 12 15 20 25 30 40 50 and 60 days we recorded the lag period with the highest correlation and the correlation value for each quantile next we fit generalized additive models gams wood 2006 with knots limited to 4 using r package mgcv wood 2018 for rain and snow dominated sites independently using the lag period length i e 1 3 6 9 etc with the highest correlation value as the response variable and the mean log scale flow anomaly in each quantile as the explanatory variable these gam models were used to predict the best lag period number of days for each daily value of air temperature based on the log scale daily flow residual finally we rounded the predicted air temperature lag period to the nearest tested lag period number of days and created the flexible day air temperature lag metric tla by choosing the local air temperature averaged over the selected lag period for each day 2 3 2 seasonal air water temperature differences for all sites we calculated air water temperature differences td for the spring march 20th june 20st and summer seasons june 21nd september 22nd with the following equation where t a is the mean air temperature during the season and t w is the mean stream temperature td t a t w we used gams knots restricted to 4 to describe the relationship between average mean annual sws and average spring and summer td across all sites 2 4 objective 2 stream temperature modeling 2 4 1 modeling methods we used multivariable gam models fit to each site independently to predict daily mean stream temperature for all available data we compared the performance of 16 candidate gam models with different combinations of environmental variables and interactions table 2 we categorized these 16 models into four groups of similar models with different parameterizations for air temperature the first group included a smoothing function for the mean air temperature on the day of interest for modeling s ta the second group included this same air temperature variable but also included a smoothing function for day of year and an interaction between air temperature and day of year s t s d s t xd interactions were fit using the by function in package mgcv wood 2018 which allowed the slope and shape of the air temperature relationship to shift across the year groups 3 and 4 were analogous to the first two groups but included the flexible lagged air temperature variable s tla in place of single day air temperature in addition groups 3 and 4 included a smoothing function with an interaction with air temperature delta tδ which was calculated as ta tla this variable accounted for whether air temperature increased or decreased on the day of interest compared to the lag period allowing the model to represent the higher influence of the air temperature on the day of interest while simultaneously accounting for the influence over the entire lag period in addition to the air temperature and day of year variables each group considered models with no other variables a smoothing function for flow s q a smoothing function for the mean daily swe in the watershed s sws and both flow and swe flow and swe were also allowed to independently interact with the relevant air temperature variable using the by function this allowed the models to better capture the non linear nature of the relationship between air temperature and stream temperature i e when stream temperatures approached freezing and when high stream temperatures were decreased by evaporative cooling e g mohseni et al 1998 2 4 2 modeling validation for each site we performed a leave one year out cross validation method loyocv to compare prediction error between all tested models accordingly model training data included all available data except the single year left out which was predicted as the validation dataset we repeated this process of fitting and predicting until all available years of data had been left out and predicted we assert that this is a truer test of model performance than conventional crossfold validation methods which leave out a randomly sampled selection of the data due to the seasonal patterns in stream temperature and the associated environmental covariates model fits are not likely to change much when leaving out a small subset of random days if the general seasonal pattern remains present in the testing data resulting in artificially high validation prediction error however leaving out entire years tests the model s capability of predicting complete periods outside the temporal range of the fitting data and thus is more likely to represent the ability of the model to represent mechanistic controls we compared model performance by estimating the root mean squared prediction error rmspe using all daily loyocv predictions for each site we also explored in more detail the ability of models to capture air water temperature differences in the spring and summer we calculated residuals in model predictions t w t w for the entire dataset and the average bias for each site by taking the mean residual for the spring and summer periods respectively to visualize examples of relationships fit in models we show conditional effect plots for selected models at sites with representative predictive accuracy as in jackson et al 2018 we display how interactions impact the effect of each variable by month across the year fig 9 variable effects for each month are displayed conditioned on the 15th day of the selected month and the median value for all other variables at the site for the data within the month the extent of the variable effect shown for each month represents the 95 central range of values within that month this plotting technique highlights the relationships captured by the models within the extent of the data while highlighting seasonal variation in explanatory variable values 3 results 3 1 seasonal patterns and air temperature lags we found strong linear relationships between watershed size and average flow at norwest sites f 1 387 1778 p 0 001 r2 0 82 and usgs sites f 1 58 69 5 p 0 001 r2 0 55 fig 4 a and supfig 2a predicted slopes 0 93 and 0 94 and intercepts 4 10 and 4 10 were also very similar for norwest and usgs sites respectively while both rain and snow dominated sites tended to show similar mean flows for the same area at norwest sites relationships between flow and predicted air temperature lags were distinct fig 4b snow dominated sites demonstrated a strong increase in the estimated air temperature lag period with increasing flows particularly above mean flows the smoothing function estimated that lags grew to 30 days at the highest flow residuals and declined to 6 days at negative flow residuals edf 3 20 p 0 01 in contrast we found minimal variation between flow residuals and the best lag periods in norwest rain dominated sites and the predicted lag periods were much shorter across all flows ranging from 3 to 6 days edf 3 60 p 0 54 in the usgs dataset lags were also predicted to increase at the highest flow residuals for rain dominated sites however these positive residuals were somewhat rare due to the dry nature of most of these streams and snow dominated sites maintained longer lags at lower flows supfig 2b the flows with the longest predicted lags and rain dominated sites in general had lower maximum correlations with the tested set of air temperature lag metrics in both datasets fig 4c and supfig 2c both average daily air and stream temperatures peaked in the mid summer in snow and rain dominated sites fig 5 a and b supfig 3a and b however seasonal patterns in flow were distinct while both types of sites demonstrated the lowest average flows in late summer early fall snow dominated sites demonstrated a distinct flow peak in late spring whereas rain dominated sites demonstrated a flatter pattern of elevated flows throughout the winter and early spring more representative of seasonal precipitation patterns the timing of peak flows in norwest snow dominated sites may 23rd aligned with the rapid melting of the snowpack which lagged the peak in snowpack by over 5 weeks march 26th norwest snow dominated sites retained positive flow residuals on average three weeks later into the summer july 17th compared to rain dominated sites june 26th due to the drier rain dominated sites in the usgs dataset this difference was much larger at approximately 100 days supfig 3a and b estimated average air temperature lags at snow dominated sites were consistently higher throughout the year peaking on average during the spring snowmelt at 30 days or longer and decreasing to 10 days during late summer in both datasets in contrast predicted lags were relatively flat at 6 days for the entire year at norwest rain sites at usgs rain dominated sites predicted lags increased to 10 days during the winter high flow period but remained well below those predicted for usgs snow dominated sites supfig 3b differences between air temperature and stream temperature varied with average annual snowpack in both the spring and summer in the spring stream temperatures in rain dominated sites matched air temperatures on average but air water temperature differences grew to over 2 5 c with increasing swe before plateauing above 100 mm fig 5c and supfig 3c in the summer air water temperature differences were generally larger averaging around 2 4 c for norwest rain dominated sites and nearing 6 c on average at snow dominated sites above 150 mm swe fig 5d at usgs sites summer air water temperature differences were lower with maximum values just over 4 c on average supfig 3d we note that sites with 20 100 mm average annual swe tended to be intermediate in their behavior between higher snowpack sites and rain sites and thus refer to them as transitional sites hereafter 3 2 model performance and prediction bias we tested 16 different models at 389 norwest and 59 usgs sites respectively and present cross validated loyocv prediction accuracy results table 3 in addition we compared the performance of models using a tukey s honestly significant difference test suptable 3 model 14 which included the smoothing function for flexible day lagged air temperature tla delta air temperature tδa day of year d and flow q produced the best mean predictions for all norwest sites despite the lack of a snowpack variable fig 6 improvements in cross validation prediction error of model 14 over the simplest air temperature model model 1 were consistent and substantial across sites supfig 4 mean rmspe improvement 0 66 while model 14 produced relatively accurate and precise predictions across the range of site characteristics tested rmspe generally between 0 5 and 1 5 prediction error was higher on average at the sites with the lowest precipitation the largest drainage areas and at sites labeled as snow dominated with 100 mm of average swe supfig 5 for usgs sites model 16 which included the snowpack variable sws in addition to those in model 14 provided the best predictions suptable 1 in both datasets model 16 produced the lowest median prediction errors but also produced higher error at site year combinations with anomolously high snowpack well outside the range of other years sites with high snowpack 100 mm were generally better predicted than their lower snowpack and rain dominated counterparts demonstrating the lowest prediction error on average in all models except model 1 table 3 models including a flexible day air temperature lag tla groups 3 and 4 uniformly outperformed analogous models with the single day air temperature variable ta groups 1 and 2 the difference was on average larger for models without the day of year interactions groups 1 vs 3 0 35 and 0 33 improvement in rmspe for norwest and usgs respectively than for models that included the day of year interaction group 2 vs 4 0 05 and 0 08 respectively model 1 predictions were significantly worse than all other models and all model predictions in group 1 were significantly worse than from all other models in all cases supfig 2 comparing the performance of models that considered only air temperature parameters and not day of year model 1 vs 9 including tla and tδa substantially reduced rmspe for all sites 1 54 to 1 06 but was particularly impactful for sites with high snowpack 1 59 to 0 93 excluding transitional sites including a day of year effect s d and an interaction with air temperature s d xt consistently further improved model validation predictions models in groups 2 and 4 outperformed analogous models in groups 1 and 3 irrespective of snowpack characteristics in both datasets and these differences were significant in all cases for group 2 but less consistently for group 4 including a specific variable for snowpack sws consistently improved models with the single day air temperature variable ta but improvements in models containing the lagged air temperature variable tla were not consistent and were smaller where they did occur the simple air temperature model model 1 was not able to capture seasonal air water temperature differences in the spring and summer particularly at sites with high snow influence fig 7 a and e this led to over predicting stream temperatures in the spring and under predicting stream temperatures in the summer by about 1 c on average fig 8 a and e supfig 6 models incorporating an interaction with day of year demonstrated reduced seasonal bias in predictions fig 8 and supfig 7 model 10 which included lagged air temperature but not an interaction with day of year also removed most seasonal bias in models for high snowpack sites but not for rain dominated sites the addition of both lagged air temperature and an interaction with day of year greatly reduced this remaining seasonal bias in predictions model group 4 however in all models stream temperatures were cooler than predicted on average for year site combinations with anomalously high snowpack supfigs 8 and 9 in models that had an interaction term between day of year and the single day air temperature metric ta much of the effect of snowpack on stream temperatures was accounted for by a change to a flatter slope in the relationship with air temperature during months with consistent snowmelt e g april june in fig 9b in contrast in the analogous model with the lagged air temperature variable tla the slope was generally more consistent across months compare to fig 8h though some variability did still occur this suggests that some of the buffering impact of snowmelt was accounted for by the flexible air temperature lag in models for rain dominated sites there was only a slight difference between the models with ta and those with tl supfig 10 this is because the air temperature lags were predicted to be much smaller 3 10 days in rain dominated sites compared to snow dominated sites and thus the air temperature metrics were more similar although the models were similar tla models still consistently outperformed analogous ta models suggesting a single day air temperature lag the use of which is commonly reported in the literature might be shorter than ideal even in rain dominated systems 4 discussion 4 1 seasonal patterns in air water temperature differences and lags our results suggest that snowpack buffers stream temperature against climate throughout the year even long after the snowpack has melted we found that snowpack dominated streams generally demonstrated substantially higher stream temperature inertia or memory compared to sites that had limited or no snowpack influence making them less responsive to short term changes in air temperature this occurred for two reasons 1 air temperature lags were found to consistently increase with flow in snow dominated streams whereas rain dominated streams did not consistently demonstrate this trait and 2 flows remained higher during the summer in snow dominated sites the combined result is that air temperature lags at snow dominated sites were predicted to peak at over 30 days on average during the spring snowpack melt and remained at or above 10 days during the summer low water months in contrast predicted lags at rain dominated sites were shorter on average 3 10 days throughout the year consistent with our results on thermal lags we observed substantially larger air water temperature differences through the summer in streams with average swe over 100 mm compared to rain fed streams 2 3 c cooler although this difference was relatively steady above 100 mm it quickly diminished at transitional sites with snowpack 100 mm since most of the snowpack melts in the spring these results suggest that snowpack continues to have an impact on flows and stream temperatures in the summer through groundwater connectivity long after it has melted snowmelt is likely to contribute disproportionately to groundwater and provides a direct influx of cool water in contrast rainwater travels through the atmosphere as it enters a watershed and thus rain driven high water events are more likely to reflect the short term weather while temporal lags may also occur from rainwater infiltrating through land surface groundwater connections these lags tend to be shorter in comparison these results suggest that watersheds that maintain their snowpack with climate change are likely to continue to be buffered from climate variability and expected increases in air temperatures luce et al 2014a however in contrast the biggest increases in stream temperature with climate change are likely to occur in watersheds that lose their snowpack these watersheds will not only be influenced by increases in air temperature but are also likely to lose much of their climate buffering from the direct cooling influence of snowpack and from the increase in summer flows created through groundwater connectivity yan et al 2021 this may be particularly impactful in watersheds that currently experience marginally freezing winter air temperatures and demonstrate substantial groundwater influence due to porous bedrock such as in much of the cascade mountains chegwidden et al 2020 and in the appalachians in the eastern usa johnson et al 2017 climate change predictions that do not account for these impacts are likely to underestimate increases in spring and summer stream temperatures in such streams there is evidence that snowpack has already declined in volume and begun melting earlier in the pacific northwest as snowpack has begun to diminish the ratio of summer flows to annual flows has declined fastest in snow and groundwater influenced sites safeeq et al 2013 slow draining snow fed watersheds with high groundwater exchange are generally less sensitive to summer conditions but as their snowpack disappears they are expected to see the biggest declines in summer flows and thus may be the most impacted tague and grant 2009 minder 2010 predicted a future loss of 14 8 18 1 in cascade mountain snowpack accumulation with each degree c of warming this loss of snowpack is lessened by a predicted increase in winter precipitation however the loss in area covered by snowpack accumulation i e due to an increase in air temperature has a larger impact on snowpack accumulation than the positive impacts from increased precipitation although we found that snowpack accumulation was strongly related to larger spring and summer air water temperature differences and longer air temperature lags in our dataset we note that it is likely not the only factor for example geology can play a large role in determining spatial variation in groundwater influence which generally mutes seasonal variation in stream temperature while groundwater can be difficult to quantify tague and grant 2009 found that geology was a useful proxy for predicting stream thermal behavior they identified streams in the young volcanic rock of the high cascades of western oregon as generally demonstrating more muted seasonal variations in stream temperature consistent with heavy groundwater influence in addition snow dominated sites tended to be at higher elevations in more forested catchments which likely contained higher levels of riparian shading riparian stream shading prevents stream temperatures from warming because it directly blocks solar radiation wondzell et al 2018 as with snowpack and groundwater riparian shading also mitigates the sensitivity of streams to variation in air temperature seixas et al 2018 consequently riparian restoration has been suggested as a potential tool to mitigate climate change impacts in streams with impacted riparian zones sun et al 2015 justice et al 2017 wondzell et al 2018 however warming air temperatures are also leading to an increased frequency of large scale fires throughout the western united states and the expansion of regular fires into higher elevations as a consequence of increased vapor pressure deficits in the summer alizadeh et al 2021 fires are difficult to predict and have the potential to dramatically reduce riparian shading in large areas over short timespans generally leading to more high stream temperature events koontz et al 2018 the loss of vegetation cover with forest fires is also likely to hasten the spring snow melt sun et al 2022 consequently potential fire impacts should be considered in conjunction with the loss of snowpack when assessing the impacts of climate change 4 2 modeling 4 2 1 accounting for climate influences through our modeling efforts we show that not accounting for the impact of snowpack and resulting variation in thermal lag inducing processes as described above in statistical stream temperature models leads to a substantial seasonal bias in predictions and an inability to capture the impact of interannual climate variability other modeling studies in snow influenced watersheds have reduced the period of model fitting to the warm season when air temperatures tend to be more synchronized with stream temperatures e g letcher et al 2016 or simply predicted summer stream temperature metrics e g isaak et al 2017 however we demonstrate that the same model can simultaneously capture freezing periods and warm periods using only statistical variables and interactions if the variables are able to capture climatic influences and the model is given the flexibility to reflect interactions based on mechanistic principles our methods were able to predict daily stream temperature for all seasons in years outside those used to fit the data with good precision and accuracy rmspe 1 0 fitting data to the entire year allows for a better assessment of how seasonal patterns in stream temperature shift with environmental variability in air temperature snowpack and flow in addition it allows stream ecologists to ask a wider range of questions regarding how changes in stream temperatures will impact ecological interactions and various life history events for sensitive species such as salmon e g to inform life cycle models such as in honea et al 2016 beechie et al 2021 crozier et al 2021 these results validate our methods of using spatially comprehensive and publicly available modeled products to parameterize our air temperature flow and snowpack climate variables such data are available for the entire continental united states and thus allow our methods to be reproduced in other regions our predictions at norwest sites made using the national water model predictions of flow were more accurate on average than our predictions at usgs sites made using measured flow data while we believe that the poorer performance of the usgs models on average is likely a consequence of that dataset containing some particularly dry sites that are difficult to model our findings suggest that the national water model which is publicly available for the entire contiguous united states can successfully be used to parameterize flow metrics and air temperature lags at free flowing sites in the pacific northwest given that the pacific northwest is a geographically complex and diverse region these methods are likely to work at least as well in other regions however to achieve the best results care must be taken to ensure that the variables included in models represent mechanistic controls on stream temperature and that the model maintains the flexibility to reflect interactions between climate influences to represent snow influence we suggest using a watershed level area weighted metric that captures the influence of snowpack upstream of sites even if there is no snowpack present locally at a stream reach because of the potential for percolation into and transport through groundwater as has been shown in other studies jackson et al 2018 siegel and volk 2019 we found that gams provide a useful framework for incorporating flexible and non linear relationships in stream temperature models for example gams can easily capture the non linear relationship between air temperature and stream temperature improving a model s ability to fit across all seasons however the flexibility of gams leads to the potential to over fit models and thus we recommend limiting the number of knots based on the shape of expected relationships including interactions between other variables and air temperature is also important to improve fits across seasons this helps the model to better reflect the non linear relationship between air temperature and water temperature mohseni et al 1998 by allowing variable effects to diminish as air temperatures approach zero and streams freeze and at high air temperatures where evaporative cooling becomes more important siegel and volk 2019 it also allows the impact of variables that mitigate stream temperatrue such as groundwater represented here by the baseflow index bfi to seasonally switch the direction of their influence as would be expected finally the flow dependent flexible day air temperature lag universally improved model predictions this suggests that temporal variation in stream thermal inertia with flow and other lag inducing processes such as direct cooling from snowpack melt and snow associated groundwater can be partially accounted for in statistical models for stream temperature models using our novel methodology the sensitivity of streams to air temperature not only varies spatially with geology but also seasonally and from year to year with variation in the accumulation of snowpack lisi et al 2015 yan et al 2021 snowmelt leads to a direct input of cold water and a corresponding increase in flow rates depths which mitigates the impact of surface heat exchanges van vliet et al 2011 the variable lag period allows the model to continually adjust the temporal sensitivity to air temperature as flow conditions change this flexibility improves the model s ability to capture seasonal patterns and interannual variability 4 2 2 choice of model we emphasize that the chosen modeling formula should depend on the goals of an investigation in our analysis models that included an adaptable effect of air temperature by day of year resulted in substantially better validation dataset predictions and demonstrated less bias in spring and summer e g models 14 and 16 thus these models proved to be the best choice for performing retrospective analyses within the scope of environmental variability seen within the spatiotemporal scope of the fitting dataset the flexibility of this modeling approach allows for representation of groundwater snowpack and other seasonal influences indirectly via parameterization of the air temperature relationship which proved superior to including these factors directly as independent variables for example in sites heavily influenced by snowpack the relationship between air temperature and stream temperature tends to be flatter in the spring when snowmelt is high however we note that day of year is not a mechanistic variable if we consider a future climate where snowpack is absent or heavily reduced for such a site a flat relationship with air temperature would likely produce inaccurate predictions accordingly we suggest using a model without the day of year interaction which thus more explicitly accounts for the effect of flow and snowpack in distinct variables to be used for long term climate predictions e g models 10 or 12 we saw major improvements when incorporating our flexible lag air temperature variable to account for differences in stream temperature lags in models without the day of year term this metric more directly accounts for mechanisms creating lags in stream temperature responses than day of year and will change with variation in snowpack and flow for example if spring snowpack declines it will lead to lower flows and thus a shorter predicted air temperature lag period accordingly we recommend incorporating a flexible lag air temperature metric instead of a simple air temperature metric when making predictions across long periods encompassing climate variability 4 2 3 next steps although our models produced good fits we believe that there is room for future improvement in the ability of explanatory variables to capture climate influences on stream temperature for example the parameterization of the period of air temperature lag could potentially be improved with more predictive information while we showed that lag periods were dependent on flow and distinct in snow dominated versus rain dominated basins further explorations could examine the impact of other factors on lags such as channel form and size riparian shading geology and the characteristics of the watershed s groundwater hydrology e g tague and grant 2009 chang and psaris 2013 johnson and wilby 2015 in addition replacing the day of year variable with more mechanistic variables would make the models more reliable for climate change predictions beyond improving the air temperature lag parameterization exploring factors such as day length solar radiation and a lagged influence of snowpack could potentially achieve this goal e g chen and li 2012 the direct impact of snowpack melt could potentially be more accurately captured by using a metric that measures changes in swe over time though inputs from new precipitation would need to be accounted for finally the loss of snowpack will eventually lead snow dominated sites to behave more like rain dominated sites how stream sensitivity will respond at different time scales at sites that transition from snow to rain dominated flow regimes is an area of uncertainty we plan to expand on this research to continue to address the broad interest in understanding how climate change and the loss of snowpack will impact stream temperatures and subsequently biota in this study we fit distinct models for each site physical differences between sites which can impact stream temperature such as topography channel morphology groundwater influence and riparian cover create variation in the statistically parameterized relationships with climate variables across models thus while our methods improved predictions at individual sites models are only valid for the locations at which they were fit in future analyses we will include spatial variables and climate spatial variable interactions to fit a single model to describe spatiotemporal patterns in stream temperature across the entire pacific northwest usa to achieve this we will incorporate the lessons presented here regarding parameterizing climate influences using spatially explicit variables into a similar spatiotemporal framework as presented in siegel and volk 2019 we believe that including spatially comprehensive climate variables versus discrete data points will allow for spatiotemporal models that are generally applicable across wide spatial scales and not limited only to the basins for which models were fit 5 conclusions in this investigation we demonstrated that free flowing snow influenced streams demonstrated substantially larger air water temperature differences during the spring and summer 2 5 to 3 5 c larger on average and maintained higher thermal lags 10 to 30 days throughout the year compared to their rain dominated counterparts 3 to 10 days we then showed that climate influences on stream temperature including air temperature snowpack and flow can be well parameterized in statistical stream temperature models for daily mean temperatures if variables are produced that can better account for seasonal variation in drivers and models are given flexibility to account for non linear relationships and interactions we presented methods to account for variation in thermal lags using a flow predicted flexible air temperature lag period these methods allowed single models to capture seasonal patterns and to predict interannual variability in stream temperature for validation data from years outside the model fit with good accuracy and precision average rmspe 0 80 we successfully replicated our methods across numerous sites in a geographically diverse region using publicly available data sources suggesting that our methods are reproducible finally we provide code and data to assist others in similar investigations in the supplementary materials credit authorship contribution statement jared e siegel conceptualization investigation data curation formal analysis methodology visualization aimee h fullerton methodology investigation validation visualization writing review editing chris jordan supervision funding acquisition methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements thanks to marc weber and ryan hill for helping with spatial data processing thanks to morgan bond for providing access to computing power and for providing the national water model data thanks to martin liermann kevin see beth sanderson and two anonymous reviewers for providing useful comments on previous drafts appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j hydroa 2022 100136 appendix a supplementary data the following are the supplementary data to this article supplementary figure 1 supplementary figure 2 supplementary figure 3 supplementary figure 4 supplementary figure 5 supplementary figure 6 supplementary figure 7 supplementary figure 8 supplementary figure 9 supplementary figure 10 supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 supplementary data 5 
8541,water temperature plays a primary role in driving ecological processes in streams due to its direct impact on biogeochemical cycles and the physiological processes of stream fauna such as growth development and the timing of life history events streams influenced by snowpack melt are generally cooler in the summer and demonstrate less sensitivity to climate variability in what is commonly referred to as climate buffering despite the substantial influence of snowpack on stream temperature and expected changes in snowpack accumulation and melt timing with climate change methods for representing snowpack in statistical models for stream temperature have not been well explored in this investigation we quantified the extent of stream temperature buffering in free flowing streams across a geographically diverse region in the pacific northwest usa we demonstrated that statistical models of daily mean stream temperature can be improved by explicitly accounting for temporal variability in a small number of climate covariates believed to be mechanistically related to stream temperature our novel statistical approach included as predictors combinations and interactions between the following variables 1 air temperature 2 lagged air temperature where the lag duration varied according to its relationship with flow on a given day at that site 3 flow 4 snowpack in the upstream catchment and 5 day of year we found that sites with substantial snow influence were associated with increased air temperature buffering during the warm season and longer air temperature lags 30 days during spring high flows and 10 days during late summer low flows compared to sites where precipitation predominantly fell as rain 6 days year round by accounting for snowpack and temporal variation in lagged heat transfer processes our models were able to accurately predict seasonal patterns and interannual variability in stream temperature in validation data from years not used in model fits using publicly available data sources average rmpse 0 80 keywords stream temperature snowpack hydrology climate change salmon pacific northwest climate buffering headwaters modeling data availability data are available from zenodo org communities riverscapes 1 introduction stream temperatures in headwater streams that are influenced by snowpack are generally less sensitive to variation in climate and demonstrate larger differences between air and water temperature during the warm season mayer 2012 luce et al 2014a lisi et al 2015 snowmelt leads to a direct input of cold water and a corresponding increase in flow rates and depths which mitigates the impact of surface heat exchanges by increasing thermal inertia van vliet et al 2011 in addition snowpack accumulation shifts runoff from the cold season towards the warm season and snowmelt can recharge groundwater leading to higher flows in the summer even after the disappearance of the snowpack safeeq et al 2013 however the buffering effect of snowpack varies with interannual variation in accumulation and the continuation of climate buffering depends on the future of the snowpack lisi et al 2015 yan et al 2021 there is evidence that spring snowpack has already declined as a result of increases in air temperature throughout the northern hemisphere stewart 2009 and in the pacific northwest in particular stoelinga et al 2010 mote et al 2018 zeng et al 2018 climate models suggest that declines in snowpack accumulation and trends towards earlier melt in the pacific northwest are likely to accelerate with climate change as winter air temperatures continue to increase sridhar et al 2012 chegwidden et al 2019 marshall et al 2019 future declines in snowpack are predicted to lead to decreases in streamflow during the warm season vano et al 2015 particularly in slow draining streams with substantial snowpack and groundwater exchange tague and grant 2009 in addition more frequent high flow events during the winter are also expected chegwidden et al 2019 chegwidden et al 2020 queen et al 2021 in regions where winter air temperatures currently average just below freezing such as in the cascade mountain range the resulting reduction in snowpack accumulation and shifts towards earlier peak flows from spring melt are likely to be substantial stewart 2009 minder 2010 sproles et al 2013 luce et al 2014b chegwidden et al 2019 as warming continues colder and higher elevation regions will also likely experience similar declines in snowpack accumulation and shifts in streamflow timing increases in stream temperature with climate change are likely to be greatest in watersheds that transition from snow dominated most precipitation falling as snow to rain dominated precipitation predominantly falling as rain yan et al 2021 these streams will not only be impacted by increases in air temperature but will also lose the stream temperature buffering created by the direct influx of cool snowpack melt and increased thermal inertia with higher warm season flows ficklin et al 2014 this will result in higher peak summer stream temperatures and a longer seasonal duration of warm stream temperatures jones et al 2017 in addition the loss of snowpack is likely to lead to more homogenous stream temperatures in mountainous basins cline et al 2020 which could have impacts on biota through a reduction in stream temperature controlled habitat mosaics stanford et al 2017 brennan et al 2019 statistical models are commonly used to estimate spatial and temporal patterns in stream temperatures most statistical models use air temperature data which is widely available as a proxy for physical net heat exchanges driven by solar radiation e g mohseni et al 1998 however the relationship between stream temperature and air temperature varies seasonally and across years with the accumulation of snowpack lisi et al 2015 consequently models that are dependent on air temperature but do not account for the mitigating impact of direct cooling and increased thermal inertia created by snowpack and groundwater are not likely to produce accurate predictions across interannual environmental variability and may greatly underestimate changes in stream temperature with climate change arismendi et al 2014 leach and moore 2019 accordingly there is a need to produce statistical models that better account for mechanistic processes such as groundwater and snowpack influence that interact with air temperature arismendi et al 2012 while the need to incorporate the influence of snowpack and resulting patterns in discharge into stream temperature models is clear the best ways to parameterize this impact for statistical models has not been well examined in the literature ouellet et al 2020 additionally most statistical stream temperature modeling approaches do not use variables and interactions that are capable of representing time varying mechanistic climatic controls on stream temperature siegel and volk 2019 ouellet et al 2020 as a consequence many modeling techniques reduce the temporal scope of predictions to simplified metrics e g mean august temperature as opposed to continuous daily predictions isaak et al 2017 greatly limiting their utility however recent work has shown that by incorporating important interactions between climate and spatial variables statistical models can produce continuous precise and accurate predictions of daily stream temperature jackson et al 2018 siegel and volk 2019 these spatiotemporal models were able to extend predictions to years outside the fitted data demonstrating an ability to capture interannual environmental variability by incorporating the climatic influences of air temperature snowpack flow and their interdependence our first objective in this study was to examine how variation in snowpack accumulation relates to stream temperature lags and warm season air temperature buffering at sites throughout the pacific northwest usa our second objective was to build on the generalized additive modeling gams approach demonstrated by siegel and volk 2019 to explore two potential improvements to the parameterization of climate impacts on stream temperature in statistical models 1 we incorporated publicly available temporally and spatially comprehensive data to parameterize the interacting impacts of air temperature snowpack and flow and 2 we tested the ability of a flow predicted flexible lag period air temperature metric to better capture how the impact of air temperature is modulated by thermal inertia and other lag inducing processes we hypothesized that snowpack influenced sites would demonstrate longer air temperature lag periods and stronger warm season buffering compared to rain dominated sites and that while incorporating a flexible lag air temperature metric would improve the model predictions for all sites it would be particularly beneficial in snow dominated sites 2 methods 2 1 study region and spatial network our study focused on the free flowing streams in the pacific northwest of the united states this region encompasses diverse topography and climates including coastal rainforest high mountain ranges and interior deserts stream temperature is of particular concern in this region given the potential impacts of climate change on pacific salmon and resident trout many populations of which are listed under the endangered species act wenger et al 2011 beechie et al 2012 crozier et al 2019 we defined free flowing streams as those upstream of the influence of major dams we defined major dams in the global reservoir and dam database grand v1 3 lehner et al 2011 as those with capacity 0 1 km3 and dams 15 24 m 50 ft from the national inventory of dams 2018 https nid usace army mil that were not included in grand and omitting 43 off channel dams n 299 specifically our spatial scope included sites throughout region 17 from the national hydrography dataset 1 100 k nhdplus version 2 usgs network of stream reaches provided by the us geological survey mckay et al 2012 this region is primarily composed of the columbia river basin but also includes puget sound coastal washington and coastal oregon from the rogue river basin north 2 2 data stream temperature and climate predictor data sources are summarized in table 1 and described in more detail in the following sections 2 2 1 and 2 2 2 2 2 1 stream temperature we analyzed stream temperature data from two sources the norwest raw stream temperature dataset 1993 2011 and from regional u s geological survey usgs stream gages with paired flow and stream temperature data 1993 2017 the norwest dataset represents data collated and quality controlled from a variety of sources isaak et al 2017 we used mean daily values from both datasets because we wanted to compare our methods using measured flow data from usgs sites to modeled flow data from the national water model which we used in lieu of available flow measurements at norwest sites see section 2 2 2 climate predictor data because the norwest and usgs datasets produced similar results we discuss relevant differences in the results section we henceforth focused on the larger and more spatially comprehensive norwest dataset and provided results from the usgs dataset in the text and supplementary materials to parameterize air temperature lags and fit models we used sites with full or nearly full years of data accordingly we subset our dataset to include only years of data at sites with 320 days and four or more years of data to capture interannual climate variability the resulting 389 norwest sites and 59 usgs sites used in this analysis were spread throughout the pacific northwest with watershed areas ranging from 2 1 to 14 271 km2 table 1 and fig 1 2 2 2 predictors we incorporated modeled spatiotemporal climate data for air temperature snowpack and stream flow from publicly available sources fig 2 and table 1 we obtained air temperature data from the 4 km 16 km2 prism dataset of modeled daily air temperature for the contiguous united states prism climate group oregon state university http prism oregonstate edu and downloaded raster files for each day of the 1993 2017 study period di luzio et al 2008 we acquired snow water equivalent data swe from the 4 km 16 km2 gridded modeled dataset provided by the national snow and ice data center broxton et al 2019 swe represents the quantity of water present in the snowpack as a depth mm if it was liquid annual netcdf files for swe which contain information on daily values were downloaded for the study period https nsidc org data nsidc 0719 versions 1 finally for flow data at norwest sites we used retrospective estimates of daily streamflow m3 s from the national water model nwm version 2 0 office of water prediction 2021 the nwm is a hydrologic model that incorporates weather data a land surface model and water routing to estimate instream flows for the continental united states the nwm flow predictions are produced for the nhdplus version 2 network for our metric of flow q we downloaded instream flows for 12 00 gmt for all reaches for each day in the study period qualitative comparisons between the nwm predictions and usgs measured flow data suggested that the nwm generally captured hydrologic patterns in free flowing streams in the pacific northwest and the overlapping data was highly correlated pearson s product moment correlation 0 90 however the nwm demonstrated some inconsistency in capturing the magnitude and exact timing of flow events and some spatial biases we summarized daily means values of prism air temperature ta by reach contributing areas rcas defined as the area that drains directly into a stream reach most rcas were smaller than the 4x4km prism grid cells and thus we applied the air temperature value of the centroid point of the rca for larger rcas 32 km2 we used the mean value of all prism grid cells that had their centroid point within the rca lagged values of air temperature were also produced by averaging ta over a range of time periods ending on the day of interest including 3 6 9 12 15 20 25 30 40 50 and 60 days we summarized daily values of snowpack on the watershed scale sws by taking the mean value of snow water equivalent swe of all rcas including and upstream of the reach of interest weighted by the rca areas thus sws represents the mean swe of the entire area draining into a site on the day of interest allowing for the influence of snowpack upstream to be captured even if there is no snowpack present at the site 2 3 objective 1 thermal lags and air water temperature differences 2 3 1 thermal lag quantification we created a new air temperature metric to test as a variable in modeling to account for temporal variation in stream temperature lags defined as the time period it takes a stream to come to equilibrium with the ambient environment this metric aims to directly account for variation in thermal inertia as a consequence of flow which alters the rate of temperature change and transportation rates in streams in addition it indirectly accounts for direct cooling from snowpack melt and the temperature mitigating impact of groundwater these direct influences increase the duration of lags by creating larger differences in temperatures between the environment and the stream we hypothesized that rain dominated sites would demonstrate shorter air temperature lag periods than snow dominated sites due to a lower influence of snowpack melt and groundwater in these streams accordingly we processed rain and snow dominated sites independently rain dominated sites in the pacific northwest generally receive infrequent snowfall and thus generally record small but positive average snowpacks averaging 20 mm thus we defined rain dominated sites as those from 1993 to 2017 that had average annual sws 20 mm and snow dominated sites as those 20 mm to distinguish them from sites that regularly receive snowfall our norwest and usgs datasets contained 287 and 36 snow dominated sites and 102 and 23 rain dominated sites respectively rain dominated sites tended to be at lower elevations and demonstrated higher mean stream temperatures than snow dominated sites fig 3 and supfig 1 while norwest rain and snow dominated sites had similar distributions of precipitation and flow usgs rain dominated sites were substantially drier on average than snow dominated sites fig 3b and d norwest and supfig 1b and d usgs to create our thermal lag period metric we first calculated a flow anomaly by fitting a linear model to all sites with the average annual log transformed flow as the response variable and the log transformed drainage area as the predictor variable we subtracted daily flows from the expected drainage area mean annual flow predicted by the linear model to produce a log scale flow anomaly metric we split the daily data for snow and rain dominated sites independently into 500 groups separated by 0 2 quantiles of the resulting flow anomaly metric 200 groups and 0 5 quantiles for the usgs dataset due to lower sample sizes second we calculated correlations between stream temperature in each of the groups and all air temperature metrics including each of the lagged periods 1 3 6 9 12 15 20 25 30 40 50 and 60 days we recorded the lag period with the highest correlation and the correlation value for each quantile next we fit generalized additive models gams wood 2006 with knots limited to 4 using r package mgcv wood 2018 for rain and snow dominated sites independently using the lag period length i e 1 3 6 9 etc with the highest correlation value as the response variable and the mean log scale flow anomaly in each quantile as the explanatory variable these gam models were used to predict the best lag period number of days for each daily value of air temperature based on the log scale daily flow residual finally we rounded the predicted air temperature lag period to the nearest tested lag period number of days and created the flexible day air temperature lag metric tla by choosing the local air temperature averaged over the selected lag period for each day 2 3 2 seasonal air water temperature differences for all sites we calculated air water temperature differences td for the spring march 20th june 20st and summer seasons june 21nd september 22nd with the following equation where t a is the mean air temperature during the season and t w is the mean stream temperature td t a t w we used gams knots restricted to 4 to describe the relationship between average mean annual sws and average spring and summer td across all sites 2 4 objective 2 stream temperature modeling 2 4 1 modeling methods we used multivariable gam models fit to each site independently to predict daily mean stream temperature for all available data we compared the performance of 16 candidate gam models with different combinations of environmental variables and interactions table 2 we categorized these 16 models into four groups of similar models with different parameterizations for air temperature the first group included a smoothing function for the mean air temperature on the day of interest for modeling s ta the second group included this same air temperature variable but also included a smoothing function for day of year and an interaction between air temperature and day of year s t s d s t xd interactions were fit using the by function in package mgcv wood 2018 which allowed the slope and shape of the air temperature relationship to shift across the year groups 3 and 4 were analogous to the first two groups but included the flexible lagged air temperature variable s tla in place of single day air temperature in addition groups 3 and 4 included a smoothing function with an interaction with air temperature delta tδ which was calculated as ta tla this variable accounted for whether air temperature increased or decreased on the day of interest compared to the lag period allowing the model to represent the higher influence of the air temperature on the day of interest while simultaneously accounting for the influence over the entire lag period in addition to the air temperature and day of year variables each group considered models with no other variables a smoothing function for flow s q a smoothing function for the mean daily swe in the watershed s sws and both flow and swe flow and swe were also allowed to independently interact with the relevant air temperature variable using the by function this allowed the models to better capture the non linear nature of the relationship between air temperature and stream temperature i e when stream temperatures approached freezing and when high stream temperatures were decreased by evaporative cooling e g mohseni et al 1998 2 4 2 modeling validation for each site we performed a leave one year out cross validation method loyocv to compare prediction error between all tested models accordingly model training data included all available data except the single year left out which was predicted as the validation dataset we repeated this process of fitting and predicting until all available years of data had been left out and predicted we assert that this is a truer test of model performance than conventional crossfold validation methods which leave out a randomly sampled selection of the data due to the seasonal patterns in stream temperature and the associated environmental covariates model fits are not likely to change much when leaving out a small subset of random days if the general seasonal pattern remains present in the testing data resulting in artificially high validation prediction error however leaving out entire years tests the model s capability of predicting complete periods outside the temporal range of the fitting data and thus is more likely to represent the ability of the model to represent mechanistic controls we compared model performance by estimating the root mean squared prediction error rmspe using all daily loyocv predictions for each site we also explored in more detail the ability of models to capture air water temperature differences in the spring and summer we calculated residuals in model predictions t w t w for the entire dataset and the average bias for each site by taking the mean residual for the spring and summer periods respectively to visualize examples of relationships fit in models we show conditional effect plots for selected models at sites with representative predictive accuracy as in jackson et al 2018 we display how interactions impact the effect of each variable by month across the year fig 9 variable effects for each month are displayed conditioned on the 15th day of the selected month and the median value for all other variables at the site for the data within the month the extent of the variable effect shown for each month represents the 95 central range of values within that month this plotting technique highlights the relationships captured by the models within the extent of the data while highlighting seasonal variation in explanatory variable values 3 results 3 1 seasonal patterns and air temperature lags we found strong linear relationships between watershed size and average flow at norwest sites f 1 387 1778 p 0 001 r2 0 82 and usgs sites f 1 58 69 5 p 0 001 r2 0 55 fig 4 a and supfig 2a predicted slopes 0 93 and 0 94 and intercepts 4 10 and 4 10 were also very similar for norwest and usgs sites respectively while both rain and snow dominated sites tended to show similar mean flows for the same area at norwest sites relationships between flow and predicted air temperature lags were distinct fig 4b snow dominated sites demonstrated a strong increase in the estimated air temperature lag period with increasing flows particularly above mean flows the smoothing function estimated that lags grew to 30 days at the highest flow residuals and declined to 6 days at negative flow residuals edf 3 20 p 0 01 in contrast we found minimal variation between flow residuals and the best lag periods in norwest rain dominated sites and the predicted lag periods were much shorter across all flows ranging from 3 to 6 days edf 3 60 p 0 54 in the usgs dataset lags were also predicted to increase at the highest flow residuals for rain dominated sites however these positive residuals were somewhat rare due to the dry nature of most of these streams and snow dominated sites maintained longer lags at lower flows supfig 2b the flows with the longest predicted lags and rain dominated sites in general had lower maximum correlations with the tested set of air temperature lag metrics in both datasets fig 4c and supfig 2c both average daily air and stream temperatures peaked in the mid summer in snow and rain dominated sites fig 5 a and b supfig 3a and b however seasonal patterns in flow were distinct while both types of sites demonstrated the lowest average flows in late summer early fall snow dominated sites demonstrated a distinct flow peak in late spring whereas rain dominated sites demonstrated a flatter pattern of elevated flows throughout the winter and early spring more representative of seasonal precipitation patterns the timing of peak flows in norwest snow dominated sites may 23rd aligned with the rapid melting of the snowpack which lagged the peak in snowpack by over 5 weeks march 26th norwest snow dominated sites retained positive flow residuals on average three weeks later into the summer july 17th compared to rain dominated sites june 26th due to the drier rain dominated sites in the usgs dataset this difference was much larger at approximately 100 days supfig 3a and b estimated average air temperature lags at snow dominated sites were consistently higher throughout the year peaking on average during the spring snowmelt at 30 days or longer and decreasing to 10 days during late summer in both datasets in contrast predicted lags were relatively flat at 6 days for the entire year at norwest rain sites at usgs rain dominated sites predicted lags increased to 10 days during the winter high flow period but remained well below those predicted for usgs snow dominated sites supfig 3b differences between air temperature and stream temperature varied with average annual snowpack in both the spring and summer in the spring stream temperatures in rain dominated sites matched air temperatures on average but air water temperature differences grew to over 2 5 c with increasing swe before plateauing above 100 mm fig 5c and supfig 3c in the summer air water temperature differences were generally larger averaging around 2 4 c for norwest rain dominated sites and nearing 6 c on average at snow dominated sites above 150 mm swe fig 5d at usgs sites summer air water temperature differences were lower with maximum values just over 4 c on average supfig 3d we note that sites with 20 100 mm average annual swe tended to be intermediate in their behavior between higher snowpack sites and rain sites and thus refer to them as transitional sites hereafter 3 2 model performance and prediction bias we tested 16 different models at 389 norwest and 59 usgs sites respectively and present cross validated loyocv prediction accuracy results table 3 in addition we compared the performance of models using a tukey s honestly significant difference test suptable 3 model 14 which included the smoothing function for flexible day lagged air temperature tla delta air temperature tδa day of year d and flow q produced the best mean predictions for all norwest sites despite the lack of a snowpack variable fig 6 improvements in cross validation prediction error of model 14 over the simplest air temperature model model 1 were consistent and substantial across sites supfig 4 mean rmspe improvement 0 66 while model 14 produced relatively accurate and precise predictions across the range of site characteristics tested rmspe generally between 0 5 and 1 5 prediction error was higher on average at the sites with the lowest precipitation the largest drainage areas and at sites labeled as snow dominated with 100 mm of average swe supfig 5 for usgs sites model 16 which included the snowpack variable sws in addition to those in model 14 provided the best predictions suptable 1 in both datasets model 16 produced the lowest median prediction errors but also produced higher error at site year combinations with anomolously high snowpack well outside the range of other years sites with high snowpack 100 mm were generally better predicted than their lower snowpack and rain dominated counterparts demonstrating the lowest prediction error on average in all models except model 1 table 3 models including a flexible day air temperature lag tla groups 3 and 4 uniformly outperformed analogous models with the single day air temperature variable ta groups 1 and 2 the difference was on average larger for models without the day of year interactions groups 1 vs 3 0 35 and 0 33 improvement in rmspe for norwest and usgs respectively than for models that included the day of year interaction group 2 vs 4 0 05 and 0 08 respectively model 1 predictions were significantly worse than all other models and all model predictions in group 1 were significantly worse than from all other models in all cases supfig 2 comparing the performance of models that considered only air temperature parameters and not day of year model 1 vs 9 including tla and tδa substantially reduced rmspe for all sites 1 54 to 1 06 but was particularly impactful for sites with high snowpack 1 59 to 0 93 excluding transitional sites including a day of year effect s d and an interaction with air temperature s d xt consistently further improved model validation predictions models in groups 2 and 4 outperformed analogous models in groups 1 and 3 irrespective of snowpack characteristics in both datasets and these differences were significant in all cases for group 2 but less consistently for group 4 including a specific variable for snowpack sws consistently improved models with the single day air temperature variable ta but improvements in models containing the lagged air temperature variable tla were not consistent and were smaller where they did occur the simple air temperature model model 1 was not able to capture seasonal air water temperature differences in the spring and summer particularly at sites with high snow influence fig 7 a and e this led to over predicting stream temperatures in the spring and under predicting stream temperatures in the summer by about 1 c on average fig 8 a and e supfig 6 models incorporating an interaction with day of year demonstrated reduced seasonal bias in predictions fig 8 and supfig 7 model 10 which included lagged air temperature but not an interaction with day of year also removed most seasonal bias in models for high snowpack sites but not for rain dominated sites the addition of both lagged air temperature and an interaction with day of year greatly reduced this remaining seasonal bias in predictions model group 4 however in all models stream temperatures were cooler than predicted on average for year site combinations with anomalously high snowpack supfigs 8 and 9 in models that had an interaction term between day of year and the single day air temperature metric ta much of the effect of snowpack on stream temperatures was accounted for by a change to a flatter slope in the relationship with air temperature during months with consistent snowmelt e g april june in fig 9b in contrast in the analogous model with the lagged air temperature variable tla the slope was generally more consistent across months compare to fig 8h though some variability did still occur this suggests that some of the buffering impact of snowmelt was accounted for by the flexible air temperature lag in models for rain dominated sites there was only a slight difference between the models with ta and those with tl supfig 10 this is because the air temperature lags were predicted to be much smaller 3 10 days in rain dominated sites compared to snow dominated sites and thus the air temperature metrics were more similar although the models were similar tla models still consistently outperformed analogous ta models suggesting a single day air temperature lag the use of which is commonly reported in the literature might be shorter than ideal even in rain dominated systems 4 discussion 4 1 seasonal patterns in air water temperature differences and lags our results suggest that snowpack buffers stream temperature against climate throughout the year even long after the snowpack has melted we found that snowpack dominated streams generally demonstrated substantially higher stream temperature inertia or memory compared to sites that had limited or no snowpack influence making them less responsive to short term changes in air temperature this occurred for two reasons 1 air temperature lags were found to consistently increase with flow in snow dominated streams whereas rain dominated streams did not consistently demonstrate this trait and 2 flows remained higher during the summer in snow dominated sites the combined result is that air temperature lags at snow dominated sites were predicted to peak at over 30 days on average during the spring snowpack melt and remained at or above 10 days during the summer low water months in contrast predicted lags at rain dominated sites were shorter on average 3 10 days throughout the year consistent with our results on thermal lags we observed substantially larger air water temperature differences through the summer in streams with average swe over 100 mm compared to rain fed streams 2 3 c cooler although this difference was relatively steady above 100 mm it quickly diminished at transitional sites with snowpack 100 mm since most of the snowpack melts in the spring these results suggest that snowpack continues to have an impact on flows and stream temperatures in the summer through groundwater connectivity long after it has melted snowmelt is likely to contribute disproportionately to groundwater and provides a direct influx of cool water in contrast rainwater travels through the atmosphere as it enters a watershed and thus rain driven high water events are more likely to reflect the short term weather while temporal lags may also occur from rainwater infiltrating through land surface groundwater connections these lags tend to be shorter in comparison these results suggest that watersheds that maintain their snowpack with climate change are likely to continue to be buffered from climate variability and expected increases in air temperatures luce et al 2014a however in contrast the biggest increases in stream temperature with climate change are likely to occur in watersheds that lose their snowpack these watersheds will not only be influenced by increases in air temperature but are also likely to lose much of their climate buffering from the direct cooling influence of snowpack and from the increase in summer flows created through groundwater connectivity yan et al 2021 this may be particularly impactful in watersheds that currently experience marginally freezing winter air temperatures and demonstrate substantial groundwater influence due to porous bedrock such as in much of the cascade mountains chegwidden et al 2020 and in the appalachians in the eastern usa johnson et al 2017 climate change predictions that do not account for these impacts are likely to underestimate increases in spring and summer stream temperatures in such streams there is evidence that snowpack has already declined in volume and begun melting earlier in the pacific northwest as snowpack has begun to diminish the ratio of summer flows to annual flows has declined fastest in snow and groundwater influenced sites safeeq et al 2013 slow draining snow fed watersheds with high groundwater exchange are generally less sensitive to summer conditions but as their snowpack disappears they are expected to see the biggest declines in summer flows and thus may be the most impacted tague and grant 2009 minder 2010 predicted a future loss of 14 8 18 1 in cascade mountain snowpack accumulation with each degree c of warming this loss of snowpack is lessened by a predicted increase in winter precipitation however the loss in area covered by snowpack accumulation i e due to an increase in air temperature has a larger impact on snowpack accumulation than the positive impacts from increased precipitation although we found that snowpack accumulation was strongly related to larger spring and summer air water temperature differences and longer air temperature lags in our dataset we note that it is likely not the only factor for example geology can play a large role in determining spatial variation in groundwater influence which generally mutes seasonal variation in stream temperature while groundwater can be difficult to quantify tague and grant 2009 found that geology was a useful proxy for predicting stream thermal behavior they identified streams in the young volcanic rock of the high cascades of western oregon as generally demonstrating more muted seasonal variations in stream temperature consistent with heavy groundwater influence in addition snow dominated sites tended to be at higher elevations in more forested catchments which likely contained higher levels of riparian shading riparian stream shading prevents stream temperatures from warming because it directly blocks solar radiation wondzell et al 2018 as with snowpack and groundwater riparian shading also mitigates the sensitivity of streams to variation in air temperature seixas et al 2018 consequently riparian restoration has been suggested as a potential tool to mitigate climate change impacts in streams with impacted riparian zones sun et al 2015 justice et al 2017 wondzell et al 2018 however warming air temperatures are also leading to an increased frequency of large scale fires throughout the western united states and the expansion of regular fires into higher elevations as a consequence of increased vapor pressure deficits in the summer alizadeh et al 2021 fires are difficult to predict and have the potential to dramatically reduce riparian shading in large areas over short timespans generally leading to more high stream temperature events koontz et al 2018 the loss of vegetation cover with forest fires is also likely to hasten the spring snow melt sun et al 2022 consequently potential fire impacts should be considered in conjunction with the loss of snowpack when assessing the impacts of climate change 4 2 modeling 4 2 1 accounting for climate influences through our modeling efforts we show that not accounting for the impact of snowpack and resulting variation in thermal lag inducing processes as described above in statistical stream temperature models leads to a substantial seasonal bias in predictions and an inability to capture the impact of interannual climate variability other modeling studies in snow influenced watersheds have reduced the period of model fitting to the warm season when air temperatures tend to be more synchronized with stream temperatures e g letcher et al 2016 or simply predicted summer stream temperature metrics e g isaak et al 2017 however we demonstrate that the same model can simultaneously capture freezing periods and warm periods using only statistical variables and interactions if the variables are able to capture climatic influences and the model is given the flexibility to reflect interactions based on mechanistic principles our methods were able to predict daily stream temperature for all seasons in years outside those used to fit the data with good precision and accuracy rmspe 1 0 fitting data to the entire year allows for a better assessment of how seasonal patterns in stream temperature shift with environmental variability in air temperature snowpack and flow in addition it allows stream ecologists to ask a wider range of questions regarding how changes in stream temperatures will impact ecological interactions and various life history events for sensitive species such as salmon e g to inform life cycle models such as in honea et al 2016 beechie et al 2021 crozier et al 2021 these results validate our methods of using spatially comprehensive and publicly available modeled products to parameterize our air temperature flow and snowpack climate variables such data are available for the entire continental united states and thus allow our methods to be reproduced in other regions our predictions at norwest sites made using the national water model predictions of flow were more accurate on average than our predictions at usgs sites made using measured flow data while we believe that the poorer performance of the usgs models on average is likely a consequence of that dataset containing some particularly dry sites that are difficult to model our findings suggest that the national water model which is publicly available for the entire contiguous united states can successfully be used to parameterize flow metrics and air temperature lags at free flowing sites in the pacific northwest given that the pacific northwest is a geographically complex and diverse region these methods are likely to work at least as well in other regions however to achieve the best results care must be taken to ensure that the variables included in models represent mechanistic controls on stream temperature and that the model maintains the flexibility to reflect interactions between climate influences to represent snow influence we suggest using a watershed level area weighted metric that captures the influence of snowpack upstream of sites even if there is no snowpack present locally at a stream reach because of the potential for percolation into and transport through groundwater as has been shown in other studies jackson et al 2018 siegel and volk 2019 we found that gams provide a useful framework for incorporating flexible and non linear relationships in stream temperature models for example gams can easily capture the non linear relationship between air temperature and stream temperature improving a model s ability to fit across all seasons however the flexibility of gams leads to the potential to over fit models and thus we recommend limiting the number of knots based on the shape of expected relationships including interactions between other variables and air temperature is also important to improve fits across seasons this helps the model to better reflect the non linear relationship between air temperature and water temperature mohseni et al 1998 by allowing variable effects to diminish as air temperatures approach zero and streams freeze and at high air temperatures where evaporative cooling becomes more important siegel and volk 2019 it also allows the impact of variables that mitigate stream temperatrue such as groundwater represented here by the baseflow index bfi to seasonally switch the direction of their influence as would be expected finally the flow dependent flexible day air temperature lag universally improved model predictions this suggests that temporal variation in stream thermal inertia with flow and other lag inducing processes such as direct cooling from snowpack melt and snow associated groundwater can be partially accounted for in statistical models for stream temperature models using our novel methodology the sensitivity of streams to air temperature not only varies spatially with geology but also seasonally and from year to year with variation in the accumulation of snowpack lisi et al 2015 yan et al 2021 snowmelt leads to a direct input of cold water and a corresponding increase in flow rates depths which mitigates the impact of surface heat exchanges van vliet et al 2011 the variable lag period allows the model to continually adjust the temporal sensitivity to air temperature as flow conditions change this flexibility improves the model s ability to capture seasonal patterns and interannual variability 4 2 2 choice of model we emphasize that the chosen modeling formula should depend on the goals of an investigation in our analysis models that included an adaptable effect of air temperature by day of year resulted in substantially better validation dataset predictions and demonstrated less bias in spring and summer e g models 14 and 16 thus these models proved to be the best choice for performing retrospective analyses within the scope of environmental variability seen within the spatiotemporal scope of the fitting dataset the flexibility of this modeling approach allows for representation of groundwater snowpack and other seasonal influences indirectly via parameterization of the air temperature relationship which proved superior to including these factors directly as independent variables for example in sites heavily influenced by snowpack the relationship between air temperature and stream temperature tends to be flatter in the spring when snowmelt is high however we note that day of year is not a mechanistic variable if we consider a future climate where snowpack is absent or heavily reduced for such a site a flat relationship with air temperature would likely produce inaccurate predictions accordingly we suggest using a model without the day of year interaction which thus more explicitly accounts for the effect of flow and snowpack in distinct variables to be used for long term climate predictions e g models 10 or 12 we saw major improvements when incorporating our flexible lag air temperature variable to account for differences in stream temperature lags in models without the day of year term this metric more directly accounts for mechanisms creating lags in stream temperature responses than day of year and will change with variation in snowpack and flow for example if spring snowpack declines it will lead to lower flows and thus a shorter predicted air temperature lag period accordingly we recommend incorporating a flexible lag air temperature metric instead of a simple air temperature metric when making predictions across long periods encompassing climate variability 4 2 3 next steps although our models produced good fits we believe that there is room for future improvement in the ability of explanatory variables to capture climate influences on stream temperature for example the parameterization of the period of air temperature lag could potentially be improved with more predictive information while we showed that lag periods were dependent on flow and distinct in snow dominated versus rain dominated basins further explorations could examine the impact of other factors on lags such as channel form and size riparian shading geology and the characteristics of the watershed s groundwater hydrology e g tague and grant 2009 chang and psaris 2013 johnson and wilby 2015 in addition replacing the day of year variable with more mechanistic variables would make the models more reliable for climate change predictions beyond improving the air temperature lag parameterization exploring factors such as day length solar radiation and a lagged influence of snowpack could potentially achieve this goal e g chen and li 2012 the direct impact of snowpack melt could potentially be more accurately captured by using a metric that measures changes in swe over time though inputs from new precipitation would need to be accounted for finally the loss of snowpack will eventually lead snow dominated sites to behave more like rain dominated sites how stream sensitivity will respond at different time scales at sites that transition from snow to rain dominated flow regimes is an area of uncertainty we plan to expand on this research to continue to address the broad interest in understanding how climate change and the loss of snowpack will impact stream temperatures and subsequently biota in this study we fit distinct models for each site physical differences between sites which can impact stream temperature such as topography channel morphology groundwater influence and riparian cover create variation in the statistically parameterized relationships with climate variables across models thus while our methods improved predictions at individual sites models are only valid for the locations at which they were fit in future analyses we will include spatial variables and climate spatial variable interactions to fit a single model to describe spatiotemporal patterns in stream temperature across the entire pacific northwest usa to achieve this we will incorporate the lessons presented here regarding parameterizing climate influences using spatially explicit variables into a similar spatiotemporal framework as presented in siegel and volk 2019 we believe that including spatially comprehensive climate variables versus discrete data points will allow for spatiotemporal models that are generally applicable across wide spatial scales and not limited only to the basins for which models were fit 5 conclusions in this investigation we demonstrated that free flowing snow influenced streams demonstrated substantially larger air water temperature differences during the spring and summer 2 5 to 3 5 c larger on average and maintained higher thermal lags 10 to 30 days throughout the year compared to their rain dominated counterparts 3 to 10 days we then showed that climate influences on stream temperature including air temperature snowpack and flow can be well parameterized in statistical stream temperature models for daily mean temperatures if variables are produced that can better account for seasonal variation in drivers and models are given flexibility to account for non linear relationships and interactions we presented methods to account for variation in thermal lags using a flow predicted flexible air temperature lag period these methods allowed single models to capture seasonal patterns and to predict interannual variability in stream temperature for validation data from years outside the model fit with good accuracy and precision average rmspe 0 80 we successfully replicated our methods across numerous sites in a geographically diverse region using publicly available data sources suggesting that our methods are reproducible finally we provide code and data to assist others in similar investigations in the supplementary materials credit authorship contribution statement jared e siegel conceptualization investigation data curation formal analysis methodology visualization aimee h fullerton methodology investigation validation visualization writing review editing chris jordan supervision funding acquisition methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements thanks to marc weber and ryan hill for helping with spatial data processing thanks to morgan bond for providing access to computing power and for providing the national water model data thanks to martin liermann kevin see beth sanderson and two anonymous reviewers for providing useful comments on previous drafts appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j hydroa 2022 100136 appendix a supplementary data the following are the supplementary data to this article supplementary figure 1 supplementary figure 2 supplementary figure 3 supplementary figure 4 supplementary figure 5 supplementary figure 6 supplementary figure 7 supplementary figure 8 supplementary figure 9 supplementary figure 10 supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 supplementary data 5 
8542,river water temperature measurement networks suffer from an inadequate spatial coverage and a lack of data no methods exist for the regional estimation of river water temperature at ungauged sites based on data series from gauged sites the development of such methods is hence of significant importance it is proposed in this study to develop a temperature duration curve tdc based method to estimate river water temperature at ungauged sites on a real time basis a generalised additive model gam based method is used to estimate tdcs at ungauged sites the estimated tdcs are then used in combination with a spatial interpolation method to obtain daily temperature estimates at ungauged sites results are compared with a simple method based on the geographical distance weighted average of neighboring stations the approaches are applied to 126 river thermal stations located on atlantic salmon rivers in eastern canada leave one out cross validation results indicate that the tdc based methods are robust and outperform the geographical distance weighted method keywords river water temperature regionalization temperature duration curve gam spatial interpolation ungauged site data availability data will be made available on request 1 introduction water temperature is recognized as an important and highly sensitive variable that affects physical chemical and biological processes in flowing waters hannah et al 2008 changes in the thermal regime of rivers affect the distribution heinle et al 2020 growth coulter et al 2016 and spawning tornabene et al 2020 of many fish species in rivers that host atlantic salmon salmo salar populations the risk of reaching the critical temperature range that triggers stressful reaction 22 23 c jonsson and jonsson 2009 is likely increasing according to most climate change scenarios e g daigle et al 2015 this has led to recent efforts to incorporate water temperature in atlantic salmon habitat models beaupré et al 2020 however implementation of these improved habitat models is often difficult because long historical river temperature time series are not available in many atlantic salmon rivers several water temperature metrics have been identified as important indicators of the thermal health of a river and can be useful for the management and conservation of aquatic species temperature metrics such as the maximum weekly mean temperature mwmt e g gallice et al 2015 and thermal sensitivity the slope of the air water temperature regression kelleher et al 2012 have been used for many years more recently daigle et al 2019 used the three parameters of a gaussian function to characterize lotic thermal regime and beaufort et al 2021 have proposed the thermal peak as an indicator of summer temperature extremes souaissi et al 2021 analysed the regional distributions of river water temperature in swiss rivers to adequately estimate water temperature quantiles as thermal stress indicators in all cases relatively long time series of water temperature are required to calculate such indices for instance in daigle et al 2019 eight years were considered to be necessary to estimate the daily interannual variability although water temperature monitoring efforts are on the rise in eastern canada boyer et al 2016 the quality of thermal data from atlantic canada s salmon rivers suffers from a highly inhomogeneous spatial distribution of the measurement sites a limited number of years of measurements and an inconsistent availability of data within the annual time series to compensate for the limited availability of high quality data it is essential to develop regional models to estimate water temperature at sites where thermal data are limited or inexistent a number of publications dealt with the regional estimation of other water quality characteristics e g khalil et al 2011 several studies concentrated on river water temperature modeling and forecasting e g st hilaire et al 2012 hague and patterson 2014 but systematically in gauged sites and rarely extended to the estimation at ungauged sites the few studies that focused on regional temperature modelling include the seminal work of gallice et al 2015 who developed a hybrid deterministic statistical model to estimate temperatures at ungauged sites in switzerland one of the first steps in classic regional analysis is to define homogenous regions this has been attempted at different spatial scales by a few authors for instance wehrly et al 2003 used fish community patterns to define thermal regimes and classify rivers accordingly maheu et al 2016 classified u s rivers using the parameters of a sinusoidal function fitted to interannual daily mean temperatures beaufort et al 2020 used hydrological and physiographic features to classify rivers in france boyer et al 2021 used thermal sensitivity to classify rivers in québec canada however these authors did not include estimation of temperature metrics at ungauged sites in their studies a substantial amount of literature has dealt with the development of regional models for streamflow prediction at ungauged basins e g smith et al 2015 ouarda et al 2018 rahman et al 2018 sung et al 2018 morabbi et al 2021 generally regionalization consists in the identification of groups of hydrologically homogeneous basins and the application of a regional estimation re method within each delineated region ouarda 2016 homogeneous regions are defined either as geographically contiguous regions geographically non contiguous regions or as hydrological neighbourhoods for the delineation of geographically non contiguous regions clustering methods such as hierarchical cluster analysis hca are often used grehys 1996a b on the other hand neighbourhood approaches identify hydrologically similar sites for each target site separately the neighborhood approach has often been shown to be superior to the fixed set of regions approach ouarda et al 2008 several re methods have been adopted in regional streamflow transfer studies e g desai and ouarda 2021 multiple linear regression mlr or generalized linear models glm are commonly used in streamflow regionalisation however these approaches have been shown to be limited in their ability to model the non linear relationships that often exist between response variables and environmental predictors msilini et al 2020 the generalized additive models gams hastie and tibshirani 1990 which are non linear regression models using non parametric smoothing functions represent a more flexible avenue for re they have been used in several regional frequency analysis studies applied to hydro meteorological variables e g msilini et al 2021 and for the modeling of the thermal regime of rivers e g saadi et al 2021 a flow duration curve fdc provides a graphical relationship between any discharge value and the percentage of time that this discharge is equaled or exceeded fennessey and vogel 1990 vogel and fennessey 1994 a number of variations of the fdc model have been proposed for the estimation of streamflows at gauged and ungauged sites see for instance hughes and smakhtin 1996 smakhtin and masse 2000 yu et al 2002 castellarin et al 2007 2013 requena et al 2018 and for the statistical downscaling of global climate model results chen et al 2013 shu and ouarda 2012 developed a fdc approach that is based on multiple source sites and in which the sites are weighted according to their geographical distance to the target site they also showed that the proposed approach leads to an improved performance in comparison to other methods proposed in the literature requena et al 2017 showed that this approach can be used as a basis for the regional estimation of streamflow quantiles at ungauged basins and that it leads to comparable performances to traditional regionalization methods with a significantly smaller effort the main objective of the present work is to develop a method for the regional estimation of mean daily water temperatures at ungauged sites from river water temperature at neighboring gauged sites and a set of physio meteo characteristics that are used to establish similarity between sites the proposed approach named temperature duration curve tdc is statistical in nature and would provide a summary of temperature variability at a given site the tdc approach can be used for the estimation of past water thermal series at ungauged sites or the real time estimation of water temperature at ungauged locations once temperature series are estimated at an ungauged location it is possible to carry out a local frequency analysis to estimate thermal quantiles the tdc approach would then represent the basis for the regionalisation of thermal quantiles 2 data the water temperature data used in this study are extracted from the rivtemp database https rivtemp ca boyer et al 2016 the rivtemp database is the result of a partnership between universities provincial and federal governments watershed organizations and organizations dedicated to the conservation of atlantic salmon the rivtemp database contains daily water temperature measurements for 433 monitoring stations installed on 158 rivers in quebec and the atlantic provinces of canada newfoundland new brunswick and nova scotia all data used in rivtemp have gone through strict quality control procedures all time series were verified and if an hourly value is missing the whole day is considered missing data were also verified for outliers outliers occur often when thermographs are exposed to air instead of water the operational period of stations varies from 1 year to 35 years between 1985 and 2019 the present study uses data from 123 water temperature monitoring stations in eastern canada for which at least four years of data are available in this study stations are selected such that only one station per stream channel within a same drainage network is allowed while maintaining a good distribution of basin sizes this helps ensure the independence of the data and avoids easy transfer of river temperature data from stations upstream when more than one site is in the same river stem the site with the longest record is conserved fig 1 presents the geographical distribution of the selected stations stations are located in the provinces of newfoundland labrador nova scotia new brunswick and quebec in the latter province stations are mostly located in the gaspé peninsula the saguenay region and the quebec north shore region delineation of regions before analysis is common in regional models in this study the characteristics of the analysed area have particularities that allow clear delineation of regions indeed the presence of an island newfoundland and peninsulas gaspé nova scotia and new brunswick creates distinct regions that are more likely to have climatic and physiographic similarities three regions are thus defined here based on these land characteristics newfoundland nf region new brunswick and nova scotia nb ns region and quebec and labrador qc region with respectively 38 29 and 56 stations for the prediction of river water temperature a set of explanatory variables which can have a significant influence on the dynamics of the thermal regime were selected based on specific previous studies st hilaire et al 2019 charron et al 2020 a more general literature review for instance caissie 2006 caissie et al 2007 webb et al 2008 makarowski 2009 lisi et al 2015 bray et al 2017 dugdale et al 2017 piotrowski and napiorkowski 2019 ouellet et al 2020 and a correlation analysis with water temperature data the physiographic data originate from different public sources e g the geological survey of canada and the consortium for spatial information cgiar csi and databases from the provincial departments of natural resources charron et al 2020 the meteorological data used in this study are extracted from the anusplin data base hutchinson et al 2009 and are also available online table 1 presents a list of the explanatory variables retained with some descriptive statistics for all stations in the study area the physiographic land use and surface deposit variables characterize the drainage basin with an outlet at the location of the thermal measurement station the water at the station drains the entire basin the basin characteristics have therefore an influence on the river water temperature at the outlet of the basin the following basin physiographic variables are used the basin area basinarea the longitude and the latitude of the basin centroid xcentroid ycentroid the percentage of lake area lakearea the drainage density of the hydrological network drainagedensity the maximum and the mean elevation of the basin maxelevation meanelevation the station elevation elevationstation and the slope of the river slope a large drainage basin typically shows greater thermal variability than a small one as temperature usually rises with stream order caissie 2006 the station location especially latitude will determine the relative strength of atmospheric forcings at the air water interface e g incoming solar radiation air temperature etc vary with latitude lake area is most often highly positively correlated with river temperature because large lake areas with slow moving water and high exposure to solar radiation increase surface lake temperature which subsequently drains in the river downstream abidi et al 2022 drainage density also has a strong impact on the thermal regime with highly dendritic networks being characterized by a larger number of typically cold water tributaries than low dendritic networks see for instance the difference between tributaries and main stem temperature in jeong et al 2013 slope is also indicative of water travel time from upstream to downstream low slope and slow travel time typically indicate that water will be subjected to greater heat exchange with the atmosphere than high gradient streams caissie 2006 finally station elevation is usually negatively correlated with air and water temperature e g souaissi et al 2021 table 2 presents the correlations between all the explanatory variables in the current study the meteorological data used were extracted from the anusplin database and are interpolated into a 10 km 10 km grid derived from observations made at canadian meteorological stations the available interpolated data are the maximum and the minimum daily air temperature airtmax airtmin and the daily precipitation precip air temperature is of course highly correlated with water temperature and it plays a role in defining heat fluxes such as longwave radiation latent and sensible heat fluxes caissie 2006 precipitation can lead to positive or negative heat fluxes into the river depending on its own temperature and it is also indicative of days with lower incoming solar radiation the following meteorological variables were defined from the daily values the summer mean of airtmax meanairtmax summer maximum of airtmax maxairtmax summer mean of airtmin meanairtmin summer minimum of airtmin minairtmin and total summer precipitation totprecip daily meteorological data were extracted using the anusplin grid point closest to each thermal station the landcover variables are representative of the major landcover types over the study area they consist in the needleleaf forest needleleafforest broadleaf forest broadleafforest mixed forest mixedforest shrubland shrubland and wetland wetland stream shading is proportional to streamside canopy density and height presence of vegetation elsewhere on the drainage basin determines interception and evapotranspiration but also has an impact on the temperature of surface runoff and interflow st hilaire et al 2000 the type of soil is characterized by the type of surface deposits which can be classified into glacial deposits glacialdeposits rock rock fluvioglacial deposits fluvioglacialdeposits organic deposits organicdeposits residual residualdeposits and ablation drift ablationdrift the type of surface deposits partly defines hydraulic conductivity which has an impact on runoff groundwater recharge and their subsequent contribution to stream discharge and temperature kurylyk et al 2014 landcover and surface deposit variables are defined by the percentage of area occupied within the drainage area of the basins note that all landcover predictors are not used they do not sum to 100 and there is a level of collinearity between these predictors 3 methodology the elements and steps of the proposed methodology are illustrated in the present section the first two subsections illustrate the detailed main steps of the proposed new approach and the last subsection subsection 3 3 presents the validation method adopted in this study throughout this paper the term destination site refers to the ungauged site in which mean daily water temperatures are required and are estimated using regional information the term source site refers to any neighboring gauged site from which this information is being transferred to the destination site 3 1 estimation of temperature duration curves tdc at ungauged sites 3 1 1 construction of temperature duration curves tdc at gauged sites in order to construct the tdcs at a gauged site the observed mean daily temperatures t i i 1 n where n is the number of recorded data at a give site are sorted in descending order thus i is the rank of an event and t 1 and t n are the largest and smallest recorded temperatures respectively the probability of exceedance p i for the ith event is obtained using the weibull plotting position 1 p i p t t i i n 1 this formula has the advantage of always giving an unbiased estimate of the cumulative probability and the probability of t n the highest possible probability is inferior to 1 i e p t n 1 morgan et al 2011 tdcs are obtained by plotting the sorted values of t i against their corresponding plotting positions p i 3 1 2 regional tdc estimation at ungauged sites tdcs are available at gauged sites from the observations but need to be estimated at ungauged sites to obtain the complete tdcs at ungauged sites a regression approach is used with temperature percentiles t p estimated at a number of fixed percentage points p along the tdc in this paper 17 fixed percentage points 0 05 0 1 0 5 1 5 10 20 30 40 50 60 70 80 90 95 99 and 99 95 are selected the number of percentage points and values are selected arbitrarily to be representative of the whole curve for a gauged site the quantiles at these fixed percentage points are obtained with eq 1 the equivalent quantiles are obtained at an ungauged site with a regression method that is applied to establish the link between predictors and t p the multiple linear regression mlr is given by 2 t p a 0 a 1 x 1 a 2 x 2 a q x q ε where x 1 x 2 x q are the q selected independent variables used for the estimation of the quantile t p independent variables are the physiographical and meteorological variables characterizing the basins at the measurement sites once the parameters in eq 2 are estimated exclusively from gauged sites estimates of percentiles at ungauged sites can be obtained by injecting the values of the independent variables at ungauged sites in eq 2 physiographical and meteorological variables are easily available at gauged and ungauged sites equally it is proposed in this study to also apply the gam approach hastie and tibshirani 1990 instead of mlr gams extend the generalized linear models glms by replacing the linear predictor by a set of smooth functions of the explanatory variables gams can be expressed by 3 g t p α f 1 x 1 f 2 x 2 ε where f j is an unspecified non parametric smooth function of the j th explanatory variable x j α is an intercept and g is a monotonic link function gams are more flexible than glms by allowing a non linear relation between the response variable and each of the explanatory variables the link function is used to establish an additive relationship between the response variable and explanatory variables the link function is assumed here to be identity g μ μ e t p and a gaussian distribution is assumed for the response variable these are assumptions that are usually made in water temperature modelling hrachowitz et al 2010 imholt et al 2013 rivers moore et al 2012 the smooth functions used here are the natural cubic smoothing splines spline functions are optimized with the r package mgcv wood 2006 the number of knots is an important parameter in this package as it sets an upper limit of the wiggliness of splines however each knot corresponds to a model parameter that needs to be estimated since the number of basins thus amount of information is limited in this study the number of knots is set to the value of 4 the default value is 10 model parameters are estimated by maximizing the penalized log likelihood and the smoothing parameter is estimated using the generalized cross validation gcv approach a stepwise regression technique is used to identify the explanatory variables that are most influential for the estimation of t p the stepwise regression method used is a forward algorithm that starts with the simplest model a constant and adds in turn the variable that minimizes the akaike information criterion aic it ends when the aic cannot be further minimized or when the maximum allowed number of variables is reached in the present study a maximum number of variables is set because several predictors are available for a limited number of stations the forward version of the stepwise method is necessary here because the number of variables is too large compared to the number of stations once the optimal independent variables and t p obtained at each percentage point the whole tdc needs to be estimated this implies the estimation of the percentiles for every probability p 0 1 shu and ouarda 2012 used a logarithmic interpolation based method to obtain estimates of the percentiles between the fixed percentage points this represents a simple method that may present problems for the extrapolation and the percentiles are not guarantied to strictly decrease as the exceeding probability increases a parametric model was also proposed in requena et al 2017 in this study a non parametric approach is proposed where the tdc is fitted with a cubic spline the model takes then the form 4 t p α f p ε this is equivalent to the model of eq 3 but with a single smooth function the difference is that the decreasing monotony of the function is guarantied through the use of a penalized fitting subject to inequality constraints consider the natural cubic spline passing through the points x i p i i 1 n then it is possible to find a set of linear constraints on p sufficient to ensure monotonicity i e a p b the function mono con in the mgcv package is used in this work to obtain a and b the reader is referred to wood 1994 for more details 3 2 spatial interpolation technique for the daily estimation of river water temperature at ungauged sites the spatial interpolation algorithm proposed by hughes and smakhtin 1996 to patch missing data and extend observed records of the variable of interest water temperature in our case is used in this study this method is based on the assumption that the source site site from which data is transferred and the destination site have an equivalent exceedance probability for a given daily event fig 2 explains the spatial interpolation method used to estimate the temperature t d at a destination site for a given date first the corresponding temperature t s for the selected date at the source site is identified fig 2a with the record data then the exceedance probability p that corresponds to t s is identified using the observed tdc s at the source site fig 2b finally the estimated temperature t d for the destination site corresponding to the exceedance probability p can be obtained from the regionally estimated tdc d at the destination site fig 2d this operation is repeated for each day of the record to obtain the whole curve fig 2c for the prediction of streamflow a source site close to the destination site on the same river or on the main tributary upstream of the river is normally sufficient for the application of the spatial interpolation technique smakhtin 1999 nevertheless hughes and smakhtin 1996 and smakhtin 1999 advocated the use of multiple source sites since the flow at the destination site is generally the result of input from multiple sources they suggested using as source sites the closest gauged sites on the same river its tributaries or adjacent streams in this study the source sites are selected based on their geographic distance from the destination sites as it is assumed that the temperature series are correlated for nearby sites in the present study the river water temperature estimate at the ungauged site for a given day is computed as the weighted average of the values at the source sites suppose there are m source sites the temperature estimate t d at the destination site from the m source sites can be obtained using the following equation 5 t d j 1 m w j t j j 1 m w j where t j is the estimate from the gauged source site j and w j is the weight associated to the source site j a number of weighting schemes can be proposed for the transfer of streamflow information to the ungauged site based on site similarity measures such as the geographical distance weighted drainage area weighted and physiographical descriptor weighted schemes the geographical distance weighted scheme is assumed to be more appropriate for river water temperature and is used in this study a simple justification is that air temperature is strongly correlated with water temperature and is spatially continuous in the present study the geographical weight is defined by the inverse of the distance from the source site to the target site due to the partially gauged nature of sites it is common for the nearest stations to have missing data for concurrent days in this study the closest m stations with an available observation are considered for each day this implies that the weights in eq 5 may change from one day to the next this method makes it possible to fully exploit all available data in the territory fig 3 illustrates the availability of water temperature data across the sites in this study where monthly data availability is presented for each station if one or more daily data within a month are present they are represented by the color mark it can be noticed that daily records are not evenly distributed temporally the tdc based approach is compared with a simple method that consists in taking the average of the daily river temperature values at the nearest stations weighted by the inverse of their distance to the destination site this is equivalent to eq 5 where t j is the recorded daily water temperature at the gauged source site j equivalently the closest m stations with an available observation are considered for each day it is also important to note that after the estimation of the tdc at all sites for the ungauged case the spatial interpolation method is applied tdc estimation at the ungauged sites is carried out through a regression on the independent explanatory variables physiographical and meteorological characteristics and hence it uses regional characteristics on the other hand the spatial interpolation step uses local information only i e daily temperature from nearby donor sites and does not involve the use of physiographical and meteorological information in this study donor sites can include any sites of the data set but they are restricted to being from the same region since a daily temperature estimation method is applied for the first time to the study area comparison with previous studies is not possible instead an approach that uses less information is used to give a benchmark against which the proposed approach is compared here gam is used to regress the average daily water temperature of all sites in a region against the day of the year thus a regional water temperature forecast is obtained from a single day of the year with the site as a random effect the tdc approach can be considered inadequate if it does not perform better than this default regional model 3 3 validation method the performance of the models is evaluated using a leave one out cross validation procedure the validation procedure is applied to t p the percentile estimates of the tdc at the percentage points and to t i the daily river water temperature estimates at the destination sites with this method each gauged site is successively considered ungauged removed from the database and considered as the target site the model is then applied to the remaining gauged sites to obtain an estimate at the removed target site this operation is repeated for all sites of the database this allows ensuring that models are tested on data that are different from the calibration data this approach has been adopted in numerous studies dealing with the regionalisation of hydro meteorological variables e g ouarda et al 2001 han et al 2020 a set of three indices are used for method evaluation the coefficient of determination r 2 the mean absolute relative error mare the root mean squared error rmse and the bias bias for the validation of the percentiles at a given percentage point p the following equations are used 6 r p 2 1 i 1 n t p i t p i 2 i 1 n t p i t p 2 7 mar e p 1 n i 1 n t p i t p i t p 8 rms e p 1 n i 1 n t p i t p i 2 9 bia s p 1 n i 1 n t p i t p i where n is the total number of sites t p i and t p i are respectively the i th measured and estimated river water temperature at percent point p and t p is the mean of t p for the validation of the daily temperature estimates at a given destination site d the following equations are used 10 r d 2 1 i 1 n t i t i 2 i 1 n t i t 2 11 mar e d 1 n i 1 n t i t i t 12 rms e d 1 n i 1 n t i t i 2 13 bia s d 1 n i 1 n t i t i where n is the total number of daily observations at site d t i and t i are respectively the ith measured and estimated daily value and t is the mean of the observed daily values note that r 2 is equivalent to the nash suttcliffe efficiency nash and sutcliffe 1970 commonly used in streamflow modeling negative values of r 2 indicate inadequate models models that lead to predictions that are worse than a model that predicts only the mean value for all instances mare represents the bias with respect to the mean temperature the methodology presented in section 3 1 is applied to the study area to estimate the tdc at ungauged sites for each of the 17 fixed percentage points a stepwise regression technique is used to select the optimal independent variables among the explanatory variables of table 1 for this the tdcs were fitted from sites in all regions whole region and from sites in each region separately subsequently the results are evaluated without delimitation of the regions and within each region separately considering that the number of stations is relatively low for the number of independent variables 123 for the whole area and 38 29 and 56 stations respectively for the regions nf nb ns and qc a maximum number of independent variables to be selected is imposed thus models for the whole study and the large region of qc are limited to eight independent variables while for the small regions of nb ns and nf they are limited to six independent variables in the present study a total of 3 methods are applied and compared 1 the full proposed tdc approach which includes the spatial interpolation method 2 a simpler method based on the geographical distance weighted average of neighboring stations and 3 a benchmark approach that relies on a simple regression of water temperature against day of year 4 results fig 4 presents bar graphs describing the occurrence of each predictor selected with mlr and gams for the estimation of the tdc percentiles for the tdc models fitted within each region separately on these graphs a count indicates any occurrence of an explanatory variable in one of the regression models associated with percentage points such graphs allow us to understand which variables are most important in explaining the shape of the tdcs it is common in this type of figure that a given predictor would have no predictive power in some cases in fig 4 it can be observed that some physio meteo variables do not appear in the final list of explanatory variables of the tdc model such as meanelevation for newfoundland in panel a it can be seen that the most important variables are different for mlr and gams variables having a nonlinear relationship with temperature are favored in gams slope and lakearea are important predictors for mlr while relatively less important with respect to gams broadleafforest and shrubland are important for mlr but not for gams fluvioglacialdeposit and xcentroids are important variable according to gam but not with respect to mlr elevation variables are generally not important variables describing air temperature are generally important but neither one of these variables was found to stand out from the others this may be caused by the fact that all air temperature variables are related also variables other than air temperature such as ycentroid which is related to the latitudinal temperature gradient can act as proxies for air temperature deposits are generally not important for mlr but significantly more important with respect to gam this may be due to the non linear nature of the thermal impact of surface runoff and discharge on rivers the relative importance of variables is not consistent through out the different regions due to the differences in their characteristics for instance basinarea is important for the nf region and rock is important for qc but not for the other regions basin areas have greater variance in nf than in any other regions e g a coefficient of variation of 400 in nf vs 164 in nb presence of rock is more variable for qc rivers while it is always present in significant proportion in nf additionally land cover and some soil deposit types are not present in certain regions for instance residualcoat is only present in the qc region and ablationdrift and organic deposit are not present in the nf region as stated before the latter region is known to have more bedrock at the surface and hence less organic deposit than all other regions in eastern canada fig 5 illustrates an example of gams for the 40 percentile in the qc region where each smoothing function is displayed complex relationships that deviate from linearity can be observed for most variables while the relationship with variables such as slope and minairtmin is rather linear the negative relationship between water temperature and slope is explained by the fact that an increase in the river slope leads to faster flow which favors a lower temperature streams with low strahler order also tend to have higher slopes than large rivers and they tend to be cooler alternatively an increase in minairtmin and a decrease in ycentroid means higher air temperatures and therefore higher water temperature this example shows that the water temperature is correlated with several explanatory variables which influence both streamflow such as the slope variables and air temperature minairtmin ycentroid fig 6 illustrates an example of a monotonic constrained spline fitted to the estimated percentiles as the estimates are obtained at percentage points using separate regression models the estimated temperatures may not be strictly decreasing with decreasing temperature it can thus be observed that the estimated percentiles are sometimes larger and sometimes lower than the observed curve the smoothed curve respects the property of a constantly decreasing curve and is generally more in adequacy with the observed curve than the estimated one while this problem is rather not frequent it is important to address it properly for consistency purposes the illustrated case east metchin river was selected for illustrative purposes because it represents one of the worst cases with the presence of two jumps in the estimated tdc curve the smoothed curve allows to correct this problem tables 3 and 4 present respectively the r 2 and mare statistics obtained from the application of the cross validation method from the sites within each region separately r 2 indicates the percentage of the variance that is explained by the model results show that gam generally provides models that are more in adequacy with the observed data than mlr general performances usually improve when the sub regions are considered in comparison to adopting the whole study area model performance decreases for the extreme high and low percentiles fig 7 presents a graph of the estimated versus observed percentiles for the percent point 1 and illustrates the relatively poor performance of the model for extreme percentiles table 5 presents the results of the cross validation applied to the daily estimates of the water temperature the tdc approach is compared with the weighted average method the mean value of each validation statistic is presented in the table in general the performances increase with the number of donor sites however there is little difference between the use of three and four donors results are presented in table 5 and show that better performances are systematically obtained with the tdc approach boxplots for the case of four donors are presented in fig 8 all the sites in the nb ns regions show better performance indices than most of the sites in the nf and qc regions among the sites with the worst performances there is one site in the nf region with coordinates 46 878 n 55 776 w and four sites in the qc region with coordinates 48 275 n 69 919 w 48 438 n 65 683 w 50 025 n 66 871 w and 47 700 n 70 229 w results of the application of the spatial interpolation method with 4 donors and with the tdc based approach are illustrated in fig 9 for the matapedia river in 2009 and for the conne river in 2013 these two cases represent extreme cases for the performance of the proposed approach the matapedia river is selected because the method performs well in this station on the other hand the conne river presents a case with missing data and in which the proposed approach did not perform as well in fig 9a it can be observed that temperature is very well estimated for a station on the matapedia river qc region fig 9b illustrates the case of a year with partially censored data at a station on the conne river nf region in the latter case observed data are missing when the estimated values show that the highest temperatures occurred this last example shows how spatial interpolation can use data from another site to improve the data length of observed censored data the results obtained with the regional approach using only the day of the year benchmark method are presented in table 6 it can be seen that the benchmark approach gives fairly similar performances regardless of the region it leads to r 2 values around 0 5 rmse around 3 c mare around 0 15 and biases less than 0 04 c in terms of r 2 rmse and mare benchmark results are outperformed for all regions by the tdc spatial interpolation method even when only one donor is used and by the weighted average method with two donors the biases of the benchmark method are lower than those obtained with interpolation methods however the errors obtained with the benchmark method are high in terms of the other indices indicating that the dispersion of estimates around the observed temperatures is high overall the benchmark method is inferior to the spatial interpolation methods and especially the tdc approach 5 discussion the proposed procedure leads to positive results bias values are low as the largest absolute value is 0 19 mare values are also low with the largest value being 0 123 r 2 values are relatively high for a regional estimation procedure the lowest r 2 value for this case study is 0 65 and goes up to 0 91 these values are systematically better than the weighted average approach it is important to note that r 2 values in the range of 0 6 are common in regional transfer studies even for variables for which there is a very large body of literature and a large number of methods for instance values in this range are reported in desai and ouarda 2021 for flood flows and represent an improvement over other existing methods the data base adopted in the present work is also far from being perfect the number of stations is not very high and the data series are not long this allows to evaluate the robustness of the method by testing it in less than perfect conditions the tdc based approach presents some important advantages over classical regionalisation approaches first while the classical approach requires that the temperature metrics be calculated before the regional analysis they are calculated a posteriori with the daily estimates in the case of the tdc approach in a context where the definitions of temperature metrics may change or be adapted to different species repeating the complete regional analysis is not necessary secondly water temperature records are often short and missing data are frequent within annual series locally computed temperature metrics are thus based on incomplete data which affects their reliability the tdc based method allows to combine daily data from several sources and as such acts like a data augmentation method see for instance wang 2001 the estimated temperature metrics at the ungauged site should hence be more robust than the ones obtained through the regionalisation of locally computed temperature metrics deposits were found to be significantly less important for mlr than gam this is likely due to the presence of zeros for the deposits variable for several sites making linear models less able to adequately fit these data it was indicated that a number of physio meteo variables do not appear in the final list of explanatory variables of the tdc model this is due to the strong correlations between several of the explanatory variables model performance was found to decrease for extremely high and low percentiles this may be explained by the fact that time series record lengths are generally small sometimes 4 years and hence there is often not enough data to adequately represent the extreme cases of the distribution the results associated to these extreme percentiles are presented for illustrative purposes and to point out the limits of the method for these percentiles this would not be a unique feature of the proposed approach and any approach would suffer from the unavailability of data for these extreme tails of the distribution similar issues were raised in previous studies dealing with the fdc approach see for instance shu and ouarda 2012 the comparison of the results of the gam and mlr approaches shows that the former generally leads to models that are more in adequacy with the observed data this is especially true for the largest datasets which are the whole region and the qc region the reason is probably the availability of sufficient data to better estimate the numerous parameters in the case of gam this is an important point to be considered when selecting the appropriate approach in a region with a small data set the performances obtained with the proposed approach for the nf and qc regions are significantly lower than for the nb ns region spatial and temporal data availability is likely responsible for the difference in performance from fig 3 it can be observed that for the nb ns region the record duration of the sites 13 years on average is considerably and systematically longer than the other two regions 8 and 9 years on average for nf and qc region respectively for the nf region the records are mainly concentrated between the years 2012 and 2016 and for the qc region between 2013 and 2017 with certain sites having very short records 7 sites with only 3 or 4 years also in the qc region sites are more geographically dispersed resulting in a significantly larger variability the standard deviation of the temperatures is 1 5 1 8 and 3 6 for the nf nb ns and qc regions respectively it can therefore be seen that the performance of the method is highly dependent on data availability both temporally and spatially for the region nb ns where these two conditions are met longer series and lower geographic dispersion the results show a good performance the efficiency of the method seems hence highly dependent on the quality of the data set being used one site in the nf region and four sites in the qc region were found to have poor performances which affected the overall performance of the proposed approach these problematic sites are quite isolated and located far from the nearest source stations due to missing data and low network density source sites can be located quite far from the target locations resulting in poor performances the proximity of the source stations has therefore a significant influence on the reliability of the tdc based river water temperature estimates however this is also even more the case for the simple weighted average method the approach presented herein can represent a pertinent tool for the conservation and management of stocks of atlantic salmon and other aquatic species by providing badly needed information concerning the thermal regime of rivers at all sites of interest 6 conclusions and future work in this work the fdc approach is adapted for the estimation of daily river water temperatures streamflow and river water temperature are correlated variables and the spatial continuity characteristic required in the spatial interpolation step is potentially higher for air temperature than for streamflow results show that the proposed temperature duration curve tdc based interpolation method is effective for the prediction of daily river water temperatures at ungauged sites this study also offers improvements over other fdc based approaches presented in the literature e g shu and ouarda 2012 requena et al 2017 first the nonlinear gam approach is used to estimate the percentiles of tdc instead of mlr second the tdcs at the ungauged sites are modeled with monotonic constrained splines which allows effective prediction for all probabilities and ensures a decreasing curve with the exceedance probability the network of measuring stations used in this study has a low density is inhomogeneous and is characterised by short series this poses difficulties for regionalization methods and may explain the relatively poor results in a number of sites results indicate clearly that the performance of the method is superior for the region with longer series and lower geographic dispersion region nb ns the efficiency of the method seems hence highly dependent on the quality of the data set being used which should limit its application for some case studies the application of the developed approach to a moderate quality data base allows testing its robustness nevertheless the approach needs also to be applied to other data bases representing a variety of climates overall data quality and general conditions needless to say the results of this study serve also to advocate for denser river water temperature networks and longer measurement records it would be possible to design methods for the estimation of river water temperature metrics at ungauged sites by first estimating the metrics locally at the gauged sites and then proceeding to the regionalisation of these temperature metrics the approach presented in this study has some advantages over such methods in the tdc approach the definition of the temperature metrics is not required before the analyzes this gives more flexibility in defining the temperature metrics as they are calculated after the regional transfer procedure indeed once the whole data series is available at the target ungauged site it is possible to estimate any river water temperature metric without the need for any new regional estimation analysis also since record data is often of short duration the spatial interpolation approach can be considered as a data extension method for partially gauged sites thus the proposed method can be used to estimate temperature for ungauged periods during which donor sites would have measurements the temperature metric calculated with a longer period will then be more robust additionally indices important to aquatic life are often defined by a number of consecutive days of temperature measurements requiring hence complete data time series several variables are strongly correlated with water temperature such as air temperature laanaya et al 2017 caissie et al 2020 or river flow van vliet et al 2011 toffolon and piccolroaz 2015 booker and whitehead 2022 it is possible to build models to estimate water temperature at ungauged sites from the time series of these hydro climatic variables when they are available this type of model would fall under a different category nevertheless future work should deal with the development of predictive time series models which use these variables as exogenous variables and their comparison with the model presented in the present work conclusions can then be drawn concerning the advantages of adding these variables as predictors and using more complex time series models in addition to the selected predictors in this study and the variables listed above several other variables which impact the spatial and temporal variability of river water temperature e g garner et al 2017 irvine et al 2017 piotrowski et al 2021 should be investigated in future work to evaluate the value of each type of information while keeping in mind parsimony issues future work should focus on the comparison of temperature metrics computed from the estimated daily river water temperatures and metrics computed with regionalization methods it will also be important to investigate the potential benefits from the integration in the tdc of new physiographical variables that characterise the basin and the river at the measurement site such as stream order stream frequency bifurcation ratio and river width and depth and the impact of the collinearity between explanatory variables on the performance of the method future research should also adopt a database in which stations located on the same stream are retained in the database this would represent a situation that better characterises real world conditions and should result in improved estimation results as the similarity between the target site and stations from which information transfer is carried out would be improved future work should also investigate the impact of data normalisation on the performance of the method and on the shape of the spline functions although the proposed approach does not require normality efforts should also be dedicated to the development of regional estimation methods for the specific case of partially gauged sites and for the combination of local and regional information when limited data is available at the site of interest see seidou et al 2006 for instance the integration of information concerning the multivariate nature of most temperature metrics and concerning climate change in regional river water temperature modeling should also be considered the proposed approach was applied to mean daily temperatures in the present work future work should also focus on the application of the approach to other temperature variables such as maximum daily temperatures which are of interest for different applications such as those related to ecological stress it would also be useful to develop procedures that take into consideration regulated rivers which can be thermally different from natural rivers hester and doyle 2011 credit authorship contribution statement taha b m j ouarda conceptualization investigation methodology formal analysis writing original draft writing review editing chrisitian charron software investigation data curation visualization writing original draft writing review editing andré st hilaire resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank the natural sciences and engineering research council of canada nserc and the canada research chairs program for funding this research the authors wish to express their appreciation to the editors professors andras bardossy and shailesh kumar singh and three anonymous reviewers for their thorough review and invaluable comments and suggestions which helped considerably improve the quality of the paper 
8542,river water temperature measurement networks suffer from an inadequate spatial coverage and a lack of data no methods exist for the regional estimation of river water temperature at ungauged sites based on data series from gauged sites the development of such methods is hence of significant importance it is proposed in this study to develop a temperature duration curve tdc based method to estimate river water temperature at ungauged sites on a real time basis a generalised additive model gam based method is used to estimate tdcs at ungauged sites the estimated tdcs are then used in combination with a spatial interpolation method to obtain daily temperature estimates at ungauged sites results are compared with a simple method based on the geographical distance weighted average of neighboring stations the approaches are applied to 126 river thermal stations located on atlantic salmon rivers in eastern canada leave one out cross validation results indicate that the tdc based methods are robust and outperform the geographical distance weighted method keywords river water temperature regionalization temperature duration curve gam spatial interpolation ungauged site data availability data will be made available on request 1 introduction water temperature is recognized as an important and highly sensitive variable that affects physical chemical and biological processes in flowing waters hannah et al 2008 changes in the thermal regime of rivers affect the distribution heinle et al 2020 growth coulter et al 2016 and spawning tornabene et al 2020 of many fish species in rivers that host atlantic salmon salmo salar populations the risk of reaching the critical temperature range that triggers stressful reaction 22 23 c jonsson and jonsson 2009 is likely increasing according to most climate change scenarios e g daigle et al 2015 this has led to recent efforts to incorporate water temperature in atlantic salmon habitat models beaupré et al 2020 however implementation of these improved habitat models is often difficult because long historical river temperature time series are not available in many atlantic salmon rivers several water temperature metrics have been identified as important indicators of the thermal health of a river and can be useful for the management and conservation of aquatic species temperature metrics such as the maximum weekly mean temperature mwmt e g gallice et al 2015 and thermal sensitivity the slope of the air water temperature regression kelleher et al 2012 have been used for many years more recently daigle et al 2019 used the three parameters of a gaussian function to characterize lotic thermal regime and beaufort et al 2021 have proposed the thermal peak as an indicator of summer temperature extremes souaissi et al 2021 analysed the regional distributions of river water temperature in swiss rivers to adequately estimate water temperature quantiles as thermal stress indicators in all cases relatively long time series of water temperature are required to calculate such indices for instance in daigle et al 2019 eight years were considered to be necessary to estimate the daily interannual variability although water temperature monitoring efforts are on the rise in eastern canada boyer et al 2016 the quality of thermal data from atlantic canada s salmon rivers suffers from a highly inhomogeneous spatial distribution of the measurement sites a limited number of years of measurements and an inconsistent availability of data within the annual time series to compensate for the limited availability of high quality data it is essential to develop regional models to estimate water temperature at sites where thermal data are limited or inexistent a number of publications dealt with the regional estimation of other water quality characteristics e g khalil et al 2011 several studies concentrated on river water temperature modeling and forecasting e g st hilaire et al 2012 hague and patterson 2014 but systematically in gauged sites and rarely extended to the estimation at ungauged sites the few studies that focused on regional temperature modelling include the seminal work of gallice et al 2015 who developed a hybrid deterministic statistical model to estimate temperatures at ungauged sites in switzerland one of the first steps in classic regional analysis is to define homogenous regions this has been attempted at different spatial scales by a few authors for instance wehrly et al 2003 used fish community patterns to define thermal regimes and classify rivers accordingly maheu et al 2016 classified u s rivers using the parameters of a sinusoidal function fitted to interannual daily mean temperatures beaufort et al 2020 used hydrological and physiographic features to classify rivers in france boyer et al 2021 used thermal sensitivity to classify rivers in québec canada however these authors did not include estimation of temperature metrics at ungauged sites in their studies a substantial amount of literature has dealt with the development of regional models for streamflow prediction at ungauged basins e g smith et al 2015 ouarda et al 2018 rahman et al 2018 sung et al 2018 morabbi et al 2021 generally regionalization consists in the identification of groups of hydrologically homogeneous basins and the application of a regional estimation re method within each delineated region ouarda 2016 homogeneous regions are defined either as geographically contiguous regions geographically non contiguous regions or as hydrological neighbourhoods for the delineation of geographically non contiguous regions clustering methods such as hierarchical cluster analysis hca are often used grehys 1996a b on the other hand neighbourhood approaches identify hydrologically similar sites for each target site separately the neighborhood approach has often been shown to be superior to the fixed set of regions approach ouarda et al 2008 several re methods have been adopted in regional streamflow transfer studies e g desai and ouarda 2021 multiple linear regression mlr or generalized linear models glm are commonly used in streamflow regionalisation however these approaches have been shown to be limited in their ability to model the non linear relationships that often exist between response variables and environmental predictors msilini et al 2020 the generalized additive models gams hastie and tibshirani 1990 which are non linear regression models using non parametric smoothing functions represent a more flexible avenue for re they have been used in several regional frequency analysis studies applied to hydro meteorological variables e g msilini et al 2021 and for the modeling of the thermal regime of rivers e g saadi et al 2021 a flow duration curve fdc provides a graphical relationship between any discharge value and the percentage of time that this discharge is equaled or exceeded fennessey and vogel 1990 vogel and fennessey 1994 a number of variations of the fdc model have been proposed for the estimation of streamflows at gauged and ungauged sites see for instance hughes and smakhtin 1996 smakhtin and masse 2000 yu et al 2002 castellarin et al 2007 2013 requena et al 2018 and for the statistical downscaling of global climate model results chen et al 2013 shu and ouarda 2012 developed a fdc approach that is based on multiple source sites and in which the sites are weighted according to their geographical distance to the target site they also showed that the proposed approach leads to an improved performance in comparison to other methods proposed in the literature requena et al 2017 showed that this approach can be used as a basis for the regional estimation of streamflow quantiles at ungauged basins and that it leads to comparable performances to traditional regionalization methods with a significantly smaller effort the main objective of the present work is to develop a method for the regional estimation of mean daily water temperatures at ungauged sites from river water temperature at neighboring gauged sites and a set of physio meteo characteristics that are used to establish similarity between sites the proposed approach named temperature duration curve tdc is statistical in nature and would provide a summary of temperature variability at a given site the tdc approach can be used for the estimation of past water thermal series at ungauged sites or the real time estimation of water temperature at ungauged locations once temperature series are estimated at an ungauged location it is possible to carry out a local frequency analysis to estimate thermal quantiles the tdc approach would then represent the basis for the regionalisation of thermal quantiles 2 data the water temperature data used in this study are extracted from the rivtemp database https rivtemp ca boyer et al 2016 the rivtemp database is the result of a partnership between universities provincial and federal governments watershed organizations and organizations dedicated to the conservation of atlantic salmon the rivtemp database contains daily water temperature measurements for 433 monitoring stations installed on 158 rivers in quebec and the atlantic provinces of canada newfoundland new brunswick and nova scotia all data used in rivtemp have gone through strict quality control procedures all time series were verified and if an hourly value is missing the whole day is considered missing data were also verified for outliers outliers occur often when thermographs are exposed to air instead of water the operational period of stations varies from 1 year to 35 years between 1985 and 2019 the present study uses data from 123 water temperature monitoring stations in eastern canada for which at least four years of data are available in this study stations are selected such that only one station per stream channel within a same drainage network is allowed while maintaining a good distribution of basin sizes this helps ensure the independence of the data and avoids easy transfer of river temperature data from stations upstream when more than one site is in the same river stem the site with the longest record is conserved fig 1 presents the geographical distribution of the selected stations stations are located in the provinces of newfoundland labrador nova scotia new brunswick and quebec in the latter province stations are mostly located in the gaspé peninsula the saguenay region and the quebec north shore region delineation of regions before analysis is common in regional models in this study the characteristics of the analysed area have particularities that allow clear delineation of regions indeed the presence of an island newfoundland and peninsulas gaspé nova scotia and new brunswick creates distinct regions that are more likely to have climatic and physiographic similarities three regions are thus defined here based on these land characteristics newfoundland nf region new brunswick and nova scotia nb ns region and quebec and labrador qc region with respectively 38 29 and 56 stations for the prediction of river water temperature a set of explanatory variables which can have a significant influence on the dynamics of the thermal regime were selected based on specific previous studies st hilaire et al 2019 charron et al 2020 a more general literature review for instance caissie 2006 caissie et al 2007 webb et al 2008 makarowski 2009 lisi et al 2015 bray et al 2017 dugdale et al 2017 piotrowski and napiorkowski 2019 ouellet et al 2020 and a correlation analysis with water temperature data the physiographic data originate from different public sources e g the geological survey of canada and the consortium for spatial information cgiar csi and databases from the provincial departments of natural resources charron et al 2020 the meteorological data used in this study are extracted from the anusplin data base hutchinson et al 2009 and are also available online table 1 presents a list of the explanatory variables retained with some descriptive statistics for all stations in the study area the physiographic land use and surface deposit variables characterize the drainage basin with an outlet at the location of the thermal measurement station the water at the station drains the entire basin the basin characteristics have therefore an influence on the river water temperature at the outlet of the basin the following basin physiographic variables are used the basin area basinarea the longitude and the latitude of the basin centroid xcentroid ycentroid the percentage of lake area lakearea the drainage density of the hydrological network drainagedensity the maximum and the mean elevation of the basin maxelevation meanelevation the station elevation elevationstation and the slope of the river slope a large drainage basin typically shows greater thermal variability than a small one as temperature usually rises with stream order caissie 2006 the station location especially latitude will determine the relative strength of atmospheric forcings at the air water interface e g incoming solar radiation air temperature etc vary with latitude lake area is most often highly positively correlated with river temperature because large lake areas with slow moving water and high exposure to solar radiation increase surface lake temperature which subsequently drains in the river downstream abidi et al 2022 drainage density also has a strong impact on the thermal regime with highly dendritic networks being characterized by a larger number of typically cold water tributaries than low dendritic networks see for instance the difference between tributaries and main stem temperature in jeong et al 2013 slope is also indicative of water travel time from upstream to downstream low slope and slow travel time typically indicate that water will be subjected to greater heat exchange with the atmosphere than high gradient streams caissie 2006 finally station elevation is usually negatively correlated with air and water temperature e g souaissi et al 2021 table 2 presents the correlations between all the explanatory variables in the current study the meteorological data used were extracted from the anusplin database and are interpolated into a 10 km 10 km grid derived from observations made at canadian meteorological stations the available interpolated data are the maximum and the minimum daily air temperature airtmax airtmin and the daily precipitation precip air temperature is of course highly correlated with water temperature and it plays a role in defining heat fluxes such as longwave radiation latent and sensible heat fluxes caissie 2006 precipitation can lead to positive or negative heat fluxes into the river depending on its own temperature and it is also indicative of days with lower incoming solar radiation the following meteorological variables were defined from the daily values the summer mean of airtmax meanairtmax summer maximum of airtmax maxairtmax summer mean of airtmin meanairtmin summer minimum of airtmin minairtmin and total summer precipitation totprecip daily meteorological data were extracted using the anusplin grid point closest to each thermal station the landcover variables are representative of the major landcover types over the study area they consist in the needleleaf forest needleleafforest broadleaf forest broadleafforest mixed forest mixedforest shrubland shrubland and wetland wetland stream shading is proportional to streamside canopy density and height presence of vegetation elsewhere on the drainage basin determines interception and evapotranspiration but also has an impact on the temperature of surface runoff and interflow st hilaire et al 2000 the type of soil is characterized by the type of surface deposits which can be classified into glacial deposits glacialdeposits rock rock fluvioglacial deposits fluvioglacialdeposits organic deposits organicdeposits residual residualdeposits and ablation drift ablationdrift the type of surface deposits partly defines hydraulic conductivity which has an impact on runoff groundwater recharge and their subsequent contribution to stream discharge and temperature kurylyk et al 2014 landcover and surface deposit variables are defined by the percentage of area occupied within the drainage area of the basins note that all landcover predictors are not used they do not sum to 100 and there is a level of collinearity between these predictors 3 methodology the elements and steps of the proposed methodology are illustrated in the present section the first two subsections illustrate the detailed main steps of the proposed new approach and the last subsection subsection 3 3 presents the validation method adopted in this study throughout this paper the term destination site refers to the ungauged site in which mean daily water temperatures are required and are estimated using regional information the term source site refers to any neighboring gauged site from which this information is being transferred to the destination site 3 1 estimation of temperature duration curves tdc at ungauged sites 3 1 1 construction of temperature duration curves tdc at gauged sites in order to construct the tdcs at a gauged site the observed mean daily temperatures t i i 1 n where n is the number of recorded data at a give site are sorted in descending order thus i is the rank of an event and t 1 and t n are the largest and smallest recorded temperatures respectively the probability of exceedance p i for the ith event is obtained using the weibull plotting position 1 p i p t t i i n 1 this formula has the advantage of always giving an unbiased estimate of the cumulative probability and the probability of t n the highest possible probability is inferior to 1 i e p t n 1 morgan et al 2011 tdcs are obtained by plotting the sorted values of t i against their corresponding plotting positions p i 3 1 2 regional tdc estimation at ungauged sites tdcs are available at gauged sites from the observations but need to be estimated at ungauged sites to obtain the complete tdcs at ungauged sites a regression approach is used with temperature percentiles t p estimated at a number of fixed percentage points p along the tdc in this paper 17 fixed percentage points 0 05 0 1 0 5 1 5 10 20 30 40 50 60 70 80 90 95 99 and 99 95 are selected the number of percentage points and values are selected arbitrarily to be representative of the whole curve for a gauged site the quantiles at these fixed percentage points are obtained with eq 1 the equivalent quantiles are obtained at an ungauged site with a regression method that is applied to establish the link between predictors and t p the multiple linear regression mlr is given by 2 t p a 0 a 1 x 1 a 2 x 2 a q x q ε where x 1 x 2 x q are the q selected independent variables used for the estimation of the quantile t p independent variables are the physiographical and meteorological variables characterizing the basins at the measurement sites once the parameters in eq 2 are estimated exclusively from gauged sites estimates of percentiles at ungauged sites can be obtained by injecting the values of the independent variables at ungauged sites in eq 2 physiographical and meteorological variables are easily available at gauged and ungauged sites equally it is proposed in this study to also apply the gam approach hastie and tibshirani 1990 instead of mlr gams extend the generalized linear models glms by replacing the linear predictor by a set of smooth functions of the explanatory variables gams can be expressed by 3 g t p α f 1 x 1 f 2 x 2 ε where f j is an unspecified non parametric smooth function of the j th explanatory variable x j α is an intercept and g is a monotonic link function gams are more flexible than glms by allowing a non linear relation between the response variable and each of the explanatory variables the link function is used to establish an additive relationship between the response variable and explanatory variables the link function is assumed here to be identity g μ μ e t p and a gaussian distribution is assumed for the response variable these are assumptions that are usually made in water temperature modelling hrachowitz et al 2010 imholt et al 2013 rivers moore et al 2012 the smooth functions used here are the natural cubic smoothing splines spline functions are optimized with the r package mgcv wood 2006 the number of knots is an important parameter in this package as it sets an upper limit of the wiggliness of splines however each knot corresponds to a model parameter that needs to be estimated since the number of basins thus amount of information is limited in this study the number of knots is set to the value of 4 the default value is 10 model parameters are estimated by maximizing the penalized log likelihood and the smoothing parameter is estimated using the generalized cross validation gcv approach a stepwise regression technique is used to identify the explanatory variables that are most influential for the estimation of t p the stepwise regression method used is a forward algorithm that starts with the simplest model a constant and adds in turn the variable that minimizes the akaike information criterion aic it ends when the aic cannot be further minimized or when the maximum allowed number of variables is reached in the present study a maximum number of variables is set because several predictors are available for a limited number of stations the forward version of the stepwise method is necessary here because the number of variables is too large compared to the number of stations once the optimal independent variables and t p obtained at each percentage point the whole tdc needs to be estimated this implies the estimation of the percentiles for every probability p 0 1 shu and ouarda 2012 used a logarithmic interpolation based method to obtain estimates of the percentiles between the fixed percentage points this represents a simple method that may present problems for the extrapolation and the percentiles are not guarantied to strictly decrease as the exceeding probability increases a parametric model was also proposed in requena et al 2017 in this study a non parametric approach is proposed where the tdc is fitted with a cubic spline the model takes then the form 4 t p α f p ε this is equivalent to the model of eq 3 but with a single smooth function the difference is that the decreasing monotony of the function is guarantied through the use of a penalized fitting subject to inequality constraints consider the natural cubic spline passing through the points x i p i i 1 n then it is possible to find a set of linear constraints on p sufficient to ensure monotonicity i e a p b the function mono con in the mgcv package is used in this work to obtain a and b the reader is referred to wood 1994 for more details 3 2 spatial interpolation technique for the daily estimation of river water temperature at ungauged sites the spatial interpolation algorithm proposed by hughes and smakhtin 1996 to patch missing data and extend observed records of the variable of interest water temperature in our case is used in this study this method is based on the assumption that the source site site from which data is transferred and the destination site have an equivalent exceedance probability for a given daily event fig 2 explains the spatial interpolation method used to estimate the temperature t d at a destination site for a given date first the corresponding temperature t s for the selected date at the source site is identified fig 2a with the record data then the exceedance probability p that corresponds to t s is identified using the observed tdc s at the source site fig 2b finally the estimated temperature t d for the destination site corresponding to the exceedance probability p can be obtained from the regionally estimated tdc d at the destination site fig 2d this operation is repeated for each day of the record to obtain the whole curve fig 2c for the prediction of streamflow a source site close to the destination site on the same river or on the main tributary upstream of the river is normally sufficient for the application of the spatial interpolation technique smakhtin 1999 nevertheless hughes and smakhtin 1996 and smakhtin 1999 advocated the use of multiple source sites since the flow at the destination site is generally the result of input from multiple sources they suggested using as source sites the closest gauged sites on the same river its tributaries or adjacent streams in this study the source sites are selected based on their geographic distance from the destination sites as it is assumed that the temperature series are correlated for nearby sites in the present study the river water temperature estimate at the ungauged site for a given day is computed as the weighted average of the values at the source sites suppose there are m source sites the temperature estimate t d at the destination site from the m source sites can be obtained using the following equation 5 t d j 1 m w j t j j 1 m w j where t j is the estimate from the gauged source site j and w j is the weight associated to the source site j a number of weighting schemes can be proposed for the transfer of streamflow information to the ungauged site based on site similarity measures such as the geographical distance weighted drainage area weighted and physiographical descriptor weighted schemes the geographical distance weighted scheme is assumed to be more appropriate for river water temperature and is used in this study a simple justification is that air temperature is strongly correlated with water temperature and is spatially continuous in the present study the geographical weight is defined by the inverse of the distance from the source site to the target site due to the partially gauged nature of sites it is common for the nearest stations to have missing data for concurrent days in this study the closest m stations with an available observation are considered for each day this implies that the weights in eq 5 may change from one day to the next this method makes it possible to fully exploit all available data in the territory fig 3 illustrates the availability of water temperature data across the sites in this study where monthly data availability is presented for each station if one or more daily data within a month are present they are represented by the color mark it can be noticed that daily records are not evenly distributed temporally the tdc based approach is compared with a simple method that consists in taking the average of the daily river temperature values at the nearest stations weighted by the inverse of their distance to the destination site this is equivalent to eq 5 where t j is the recorded daily water temperature at the gauged source site j equivalently the closest m stations with an available observation are considered for each day it is also important to note that after the estimation of the tdc at all sites for the ungauged case the spatial interpolation method is applied tdc estimation at the ungauged sites is carried out through a regression on the independent explanatory variables physiographical and meteorological characteristics and hence it uses regional characteristics on the other hand the spatial interpolation step uses local information only i e daily temperature from nearby donor sites and does not involve the use of physiographical and meteorological information in this study donor sites can include any sites of the data set but they are restricted to being from the same region since a daily temperature estimation method is applied for the first time to the study area comparison with previous studies is not possible instead an approach that uses less information is used to give a benchmark against which the proposed approach is compared here gam is used to regress the average daily water temperature of all sites in a region against the day of the year thus a regional water temperature forecast is obtained from a single day of the year with the site as a random effect the tdc approach can be considered inadequate if it does not perform better than this default regional model 3 3 validation method the performance of the models is evaluated using a leave one out cross validation procedure the validation procedure is applied to t p the percentile estimates of the tdc at the percentage points and to t i the daily river water temperature estimates at the destination sites with this method each gauged site is successively considered ungauged removed from the database and considered as the target site the model is then applied to the remaining gauged sites to obtain an estimate at the removed target site this operation is repeated for all sites of the database this allows ensuring that models are tested on data that are different from the calibration data this approach has been adopted in numerous studies dealing with the regionalisation of hydro meteorological variables e g ouarda et al 2001 han et al 2020 a set of three indices are used for method evaluation the coefficient of determination r 2 the mean absolute relative error mare the root mean squared error rmse and the bias bias for the validation of the percentiles at a given percentage point p the following equations are used 6 r p 2 1 i 1 n t p i t p i 2 i 1 n t p i t p 2 7 mar e p 1 n i 1 n t p i t p i t p 8 rms e p 1 n i 1 n t p i t p i 2 9 bia s p 1 n i 1 n t p i t p i where n is the total number of sites t p i and t p i are respectively the i th measured and estimated river water temperature at percent point p and t p is the mean of t p for the validation of the daily temperature estimates at a given destination site d the following equations are used 10 r d 2 1 i 1 n t i t i 2 i 1 n t i t 2 11 mar e d 1 n i 1 n t i t i t 12 rms e d 1 n i 1 n t i t i 2 13 bia s d 1 n i 1 n t i t i where n is the total number of daily observations at site d t i and t i are respectively the ith measured and estimated daily value and t is the mean of the observed daily values note that r 2 is equivalent to the nash suttcliffe efficiency nash and sutcliffe 1970 commonly used in streamflow modeling negative values of r 2 indicate inadequate models models that lead to predictions that are worse than a model that predicts only the mean value for all instances mare represents the bias with respect to the mean temperature the methodology presented in section 3 1 is applied to the study area to estimate the tdc at ungauged sites for each of the 17 fixed percentage points a stepwise regression technique is used to select the optimal independent variables among the explanatory variables of table 1 for this the tdcs were fitted from sites in all regions whole region and from sites in each region separately subsequently the results are evaluated without delimitation of the regions and within each region separately considering that the number of stations is relatively low for the number of independent variables 123 for the whole area and 38 29 and 56 stations respectively for the regions nf nb ns and qc a maximum number of independent variables to be selected is imposed thus models for the whole study and the large region of qc are limited to eight independent variables while for the small regions of nb ns and nf they are limited to six independent variables in the present study a total of 3 methods are applied and compared 1 the full proposed tdc approach which includes the spatial interpolation method 2 a simpler method based on the geographical distance weighted average of neighboring stations and 3 a benchmark approach that relies on a simple regression of water temperature against day of year 4 results fig 4 presents bar graphs describing the occurrence of each predictor selected with mlr and gams for the estimation of the tdc percentiles for the tdc models fitted within each region separately on these graphs a count indicates any occurrence of an explanatory variable in one of the regression models associated with percentage points such graphs allow us to understand which variables are most important in explaining the shape of the tdcs it is common in this type of figure that a given predictor would have no predictive power in some cases in fig 4 it can be observed that some physio meteo variables do not appear in the final list of explanatory variables of the tdc model such as meanelevation for newfoundland in panel a it can be seen that the most important variables are different for mlr and gams variables having a nonlinear relationship with temperature are favored in gams slope and lakearea are important predictors for mlr while relatively less important with respect to gams broadleafforest and shrubland are important for mlr but not for gams fluvioglacialdeposit and xcentroids are important variable according to gam but not with respect to mlr elevation variables are generally not important variables describing air temperature are generally important but neither one of these variables was found to stand out from the others this may be caused by the fact that all air temperature variables are related also variables other than air temperature such as ycentroid which is related to the latitudinal temperature gradient can act as proxies for air temperature deposits are generally not important for mlr but significantly more important with respect to gam this may be due to the non linear nature of the thermal impact of surface runoff and discharge on rivers the relative importance of variables is not consistent through out the different regions due to the differences in their characteristics for instance basinarea is important for the nf region and rock is important for qc but not for the other regions basin areas have greater variance in nf than in any other regions e g a coefficient of variation of 400 in nf vs 164 in nb presence of rock is more variable for qc rivers while it is always present in significant proportion in nf additionally land cover and some soil deposit types are not present in certain regions for instance residualcoat is only present in the qc region and ablationdrift and organic deposit are not present in the nf region as stated before the latter region is known to have more bedrock at the surface and hence less organic deposit than all other regions in eastern canada fig 5 illustrates an example of gams for the 40 percentile in the qc region where each smoothing function is displayed complex relationships that deviate from linearity can be observed for most variables while the relationship with variables such as slope and minairtmin is rather linear the negative relationship between water temperature and slope is explained by the fact that an increase in the river slope leads to faster flow which favors a lower temperature streams with low strahler order also tend to have higher slopes than large rivers and they tend to be cooler alternatively an increase in minairtmin and a decrease in ycentroid means higher air temperatures and therefore higher water temperature this example shows that the water temperature is correlated with several explanatory variables which influence both streamflow such as the slope variables and air temperature minairtmin ycentroid fig 6 illustrates an example of a monotonic constrained spline fitted to the estimated percentiles as the estimates are obtained at percentage points using separate regression models the estimated temperatures may not be strictly decreasing with decreasing temperature it can thus be observed that the estimated percentiles are sometimes larger and sometimes lower than the observed curve the smoothed curve respects the property of a constantly decreasing curve and is generally more in adequacy with the observed curve than the estimated one while this problem is rather not frequent it is important to address it properly for consistency purposes the illustrated case east metchin river was selected for illustrative purposes because it represents one of the worst cases with the presence of two jumps in the estimated tdc curve the smoothed curve allows to correct this problem tables 3 and 4 present respectively the r 2 and mare statistics obtained from the application of the cross validation method from the sites within each region separately r 2 indicates the percentage of the variance that is explained by the model results show that gam generally provides models that are more in adequacy with the observed data than mlr general performances usually improve when the sub regions are considered in comparison to adopting the whole study area model performance decreases for the extreme high and low percentiles fig 7 presents a graph of the estimated versus observed percentiles for the percent point 1 and illustrates the relatively poor performance of the model for extreme percentiles table 5 presents the results of the cross validation applied to the daily estimates of the water temperature the tdc approach is compared with the weighted average method the mean value of each validation statistic is presented in the table in general the performances increase with the number of donor sites however there is little difference between the use of three and four donors results are presented in table 5 and show that better performances are systematically obtained with the tdc approach boxplots for the case of four donors are presented in fig 8 all the sites in the nb ns regions show better performance indices than most of the sites in the nf and qc regions among the sites with the worst performances there is one site in the nf region with coordinates 46 878 n 55 776 w and four sites in the qc region with coordinates 48 275 n 69 919 w 48 438 n 65 683 w 50 025 n 66 871 w and 47 700 n 70 229 w results of the application of the spatial interpolation method with 4 donors and with the tdc based approach are illustrated in fig 9 for the matapedia river in 2009 and for the conne river in 2013 these two cases represent extreme cases for the performance of the proposed approach the matapedia river is selected because the method performs well in this station on the other hand the conne river presents a case with missing data and in which the proposed approach did not perform as well in fig 9a it can be observed that temperature is very well estimated for a station on the matapedia river qc region fig 9b illustrates the case of a year with partially censored data at a station on the conne river nf region in the latter case observed data are missing when the estimated values show that the highest temperatures occurred this last example shows how spatial interpolation can use data from another site to improve the data length of observed censored data the results obtained with the regional approach using only the day of the year benchmark method are presented in table 6 it can be seen that the benchmark approach gives fairly similar performances regardless of the region it leads to r 2 values around 0 5 rmse around 3 c mare around 0 15 and biases less than 0 04 c in terms of r 2 rmse and mare benchmark results are outperformed for all regions by the tdc spatial interpolation method even when only one donor is used and by the weighted average method with two donors the biases of the benchmark method are lower than those obtained with interpolation methods however the errors obtained with the benchmark method are high in terms of the other indices indicating that the dispersion of estimates around the observed temperatures is high overall the benchmark method is inferior to the spatial interpolation methods and especially the tdc approach 5 discussion the proposed procedure leads to positive results bias values are low as the largest absolute value is 0 19 mare values are also low with the largest value being 0 123 r 2 values are relatively high for a regional estimation procedure the lowest r 2 value for this case study is 0 65 and goes up to 0 91 these values are systematically better than the weighted average approach it is important to note that r 2 values in the range of 0 6 are common in regional transfer studies even for variables for which there is a very large body of literature and a large number of methods for instance values in this range are reported in desai and ouarda 2021 for flood flows and represent an improvement over other existing methods the data base adopted in the present work is also far from being perfect the number of stations is not very high and the data series are not long this allows to evaluate the robustness of the method by testing it in less than perfect conditions the tdc based approach presents some important advantages over classical regionalisation approaches first while the classical approach requires that the temperature metrics be calculated before the regional analysis they are calculated a posteriori with the daily estimates in the case of the tdc approach in a context where the definitions of temperature metrics may change or be adapted to different species repeating the complete regional analysis is not necessary secondly water temperature records are often short and missing data are frequent within annual series locally computed temperature metrics are thus based on incomplete data which affects their reliability the tdc based method allows to combine daily data from several sources and as such acts like a data augmentation method see for instance wang 2001 the estimated temperature metrics at the ungauged site should hence be more robust than the ones obtained through the regionalisation of locally computed temperature metrics deposits were found to be significantly less important for mlr than gam this is likely due to the presence of zeros for the deposits variable for several sites making linear models less able to adequately fit these data it was indicated that a number of physio meteo variables do not appear in the final list of explanatory variables of the tdc model this is due to the strong correlations between several of the explanatory variables model performance was found to decrease for extremely high and low percentiles this may be explained by the fact that time series record lengths are generally small sometimes 4 years and hence there is often not enough data to adequately represent the extreme cases of the distribution the results associated to these extreme percentiles are presented for illustrative purposes and to point out the limits of the method for these percentiles this would not be a unique feature of the proposed approach and any approach would suffer from the unavailability of data for these extreme tails of the distribution similar issues were raised in previous studies dealing with the fdc approach see for instance shu and ouarda 2012 the comparison of the results of the gam and mlr approaches shows that the former generally leads to models that are more in adequacy with the observed data this is especially true for the largest datasets which are the whole region and the qc region the reason is probably the availability of sufficient data to better estimate the numerous parameters in the case of gam this is an important point to be considered when selecting the appropriate approach in a region with a small data set the performances obtained with the proposed approach for the nf and qc regions are significantly lower than for the nb ns region spatial and temporal data availability is likely responsible for the difference in performance from fig 3 it can be observed that for the nb ns region the record duration of the sites 13 years on average is considerably and systematically longer than the other two regions 8 and 9 years on average for nf and qc region respectively for the nf region the records are mainly concentrated between the years 2012 and 2016 and for the qc region between 2013 and 2017 with certain sites having very short records 7 sites with only 3 or 4 years also in the qc region sites are more geographically dispersed resulting in a significantly larger variability the standard deviation of the temperatures is 1 5 1 8 and 3 6 for the nf nb ns and qc regions respectively it can therefore be seen that the performance of the method is highly dependent on data availability both temporally and spatially for the region nb ns where these two conditions are met longer series and lower geographic dispersion the results show a good performance the efficiency of the method seems hence highly dependent on the quality of the data set being used one site in the nf region and four sites in the qc region were found to have poor performances which affected the overall performance of the proposed approach these problematic sites are quite isolated and located far from the nearest source stations due to missing data and low network density source sites can be located quite far from the target locations resulting in poor performances the proximity of the source stations has therefore a significant influence on the reliability of the tdc based river water temperature estimates however this is also even more the case for the simple weighted average method the approach presented herein can represent a pertinent tool for the conservation and management of stocks of atlantic salmon and other aquatic species by providing badly needed information concerning the thermal regime of rivers at all sites of interest 6 conclusions and future work in this work the fdc approach is adapted for the estimation of daily river water temperatures streamflow and river water temperature are correlated variables and the spatial continuity characteristic required in the spatial interpolation step is potentially higher for air temperature than for streamflow results show that the proposed temperature duration curve tdc based interpolation method is effective for the prediction of daily river water temperatures at ungauged sites this study also offers improvements over other fdc based approaches presented in the literature e g shu and ouarda 2012 requena et al 2017 first the nonlinear gam approach is used to estimate the percentiles of tdc instead of mlr second the tdcs at the ungauged sites are modeled with monotonic constrained splines which allows effective prediction for all probabilities and ensures a decreasing curve with the exceedance probability the network of measuring stations used in this study has a low density is inhomogeneous and is characterised by short series this poses difficulties for regionalization methods and may explain the relatively poor results in a number of sites results indicate clearly that the performance of the method is superior for the region with longer series and lower geographic dispersion region nb ns the efficiency of the method seems hence highly dependent on the quality of the data set being used which should limit its application for some case studies the application of the developed approach to a moderate quality data base allows testing its robustness nevertheless the approach needs also to be applied to other data bases representing a variety of climates overall data quality and general conditions needless to say the results of this study serve also to advocate for denser river water temperature networks and longer measurement records it would be possible to design methods for the estimation of river water temperature metrics at ungauged sites by first estimating the metrics locally at the gauged sites and then proceeding to the regionalisation of these temperature metrics the approach presented in this study has some advantages over such methods in the tdc approach the definition of the temperature metrics is not required before the analyzes this gives more flexibility in defining the temperature metrics as they are calculated after the regional transfer procedure indeed once the whole data series is available at the target ungauged site it is possible to estimate any river water temperature metric without the need for any new regional estimation analysis also since record data is often of short duration the spatial interpolation approach can be considered as a data extension method for partially gauged sites thus the proposed method can be used to estimate temperature for ungauged periods during which donor sites would have measurements the temperature metric calculated with a longer period will then be more robust additionally indices important to aquatic life are often defined by a number of consecutive days of temperature measurements requiring hence complete data time series several variables are strongly correlated with water temperature such as air temperature laanaya et al 2017 caissie et al 2020 or river flow van vliet et al 2011 toffolon and piccolroaz 2015 booker and whitehead 2022 it is possible to build models to estimate water temperature at ungauged sites from the time series of these hydro climatic variables when they are available this type of model would fall under a different category nevertheless future work should deal with the development of predictive time series models which use these variables as exogenous variables and their comparison with the model presented in the present work conclusions can then be drawn concerning the advantages of adding these variables as predictors and using more complex time series models in addition to the selected predictors in this study and the variables listed above several other variables which impact the spatial and temporal variability of river water temperature e g garner et al 2017 irvine et al 2017 piotrowski et al 2021 should be investigated in future work to evaluate the value of each type of information while keeping in mind parsimony issues future work should focus on the comparison of temperature metrics computed from the estimated daily river water temperatures and metrics computed with regionalization methods it will also be important to investigate the potential benefits from the integration in the tdc of new physiographical variables that characterise the basin and the river at the measurement site such as stream order stream frequency bifurcation ratio and river width and depth and the impact of the collinearity between explanatory variables on the performance of the method future research should also adopt a database in which stations located on the same stream are retained in the database this would represent a situation that better characterises real world conditions and should result in improved estimation results as the similarity between the target site and stations from which information transfer is carried out would be improved future work should also investigate the impact of data normalisation on the performance of the method and on the shape of the spline functions although the proposed approach does not require normality efforts should also be dedicated to the development of regional estimation methods for the specific case of partially gauged sites and for the combination of local and regional information when limited data is available at the site of interest see seidou et al 2006 for instance the integration of information concerning the multivariate nature of most temperature metrics and concerning climate change in regional river water temperature modeling should also be considered the proposed approach was applied to mean daily temperatures in the present work future work should also focus on the application of the approach to other temperature variables such as maximum daily temperatures which are of interest for different applications such as those related to ecological stress it would also be useful to develop procedures that take into consideration regulated rivers which can be thermally different from natural rivers hester and doyle 2011 credit authorship contribution statement taha b m j ouarda conceptualization investigation methodology formal analysis writing original draft writing review editing chrisitian charron software investigation data curation visualization writing original draft writing review editing andré st hilaire resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank the natural sciences and engineering research council of canada nserc and the canada research chairs program for funding this research the authors wish to express their appreciation to the editors professors andras bardossy and shailesh kumar singh and three anonymous reviewers for their thorough review and invaluable comments and suggestions which helped considerably improve the quality of the paper 
8543,ecological values of water have gained increasing attention over the past decades in both eco hydrological research and water resources management water quality is an important ecological steering variable and graphical water quality diagrams may aid in rapid interpretation of the hydrochemical status of a site traditionally used water quality diagrams for showing multiple variables e g stiff maucha were developed primarily for hydrogeological purposes with limited information on ecologically relevant nutrient parameters this paper presents adapted classical water quality diagrams that retain the traditional information on ions for hydrogeological characterization and additionally provide information on nutrients for ecological water quality characterization a scaling factor is used for the minor ions to visually get them across more equally compared to the macro ion ions in the water quality diagram scaling of minor ions is presented based on average concentrations as well as on water quality policy norms four different water quality diagrams are presented all with the same ions included but with different appearances to suit different preferences of individual users regional national and continental scale data are used to illustrate how the different diagrams show spatial and temporal water quality characteristics the adapted diagrams are innovative with respect to adding comprehensive visual information on the four ecohydrologically relevant nutrient species levels no3 nh4 po4 k advanced insight in redox status from the combination of four redox sensitive parameters fe no3 so4 nh4 and the option to scale minor ions relative to average measured concentrations or to water quality policy norms using policy norms for scaling has the advantage of providing an alarm function of exceedance of norms when concentrations surpass the ring used in the diagram we discuss possible standardisation of scaling factors to enable comparability between sites keywords ecohydrology water quality diagram nutrients geohydrology characterization hydrochemistry data availability data will be made available on request 1 introduction over the past decades the importance of ecological values in water resources management has been steadily increasing growing populations lack of sanitation and increased industrial and agricultural production have led to large scale pollution of both surface water and groundwater e g millennium ecosystem assessment 2005 mateo sagasta et al 2017 high concentrations of nutrients caused eutrophication of aquatic ecosystems leading to decreases in biodiversity and recreational values as well as economic damages cowx et al 2010 rosset et al 2014 dodds et al 2009 from the 1970 s onwards surface water pollution gave rise to national legislation especially in the usa and europe also international treaties were being drafted in europe to regulate water pollution of transboundary rivers e g for the rivers rhine dieperink 2000 and danube sommerwerk et al 2010 this international cooperation culminated in the water framework directive wfd of the european union in 2000 directive 2000 which aims for a good status of water quantity as well as chemical and ecological quality for all groundwater and surface water in the eu especially the strong focus on ecological quality on the scale of the european union was a novel aspect of this directive the increased attention for ecological values in water resources management was paralleled by an increased attention in scientific research on the interface between hydrology and ecology this interdisciplinary field of ecohydrology is referred to by different names e g ecohydrology hydroecology and definitions hannah et al 2004 it is basically concerned with how hydrology steers ecological processes and vice versa kundzewicz 2002 zalewski 2000 here we employ a broad interpretation of the term ecohydrology encompassing both aquatic and terrestrial ecology ecohydrological site variables reflect the relation between the hydrologic cycle and ecological processes it can be subdivided into a water availability part and a water quality part water availability is related to climate and topographical position in the landscape and steers selection of ecosystem communities adapted to different degrees of water stress porporato rodriguez iturbe 2002 water quality is related to geological setting soil type land use composition of contributing water sources and local biogeochemical interactions between organisms water soil and atmosphere water quality steers selection of species mainly with respect to their tolerances for concentrations in salinity acidity and nutrients herbert et al 2015 wassen et al 1988 ertsen et al 1998 determination and interpretation of water quality is notably complicated as it may be defined by many different parameters e g acidity macro ions nutrients trace elements microorganics these are often interlinked as they are subject to biogeochemical processes like oxidation reduction dissolution precipitation adsorption cation exchange and complexation domenico schwartz 1998 appelo and postma 2004 to facilitate interpretation of water quality measurements graphical multi parameter water quality diagrams may be useful they enable transferring information on a number of selected parameters into visual water quality types summarizing the hydrochemical status of a site well known diagrams are those described by stiff 1951 piper 1944 schoeller 1955 collins 1923 and maucha 1932 which all provide an overview of the main ions sodium na chloride cl calcium ca or bicarbonate hco3 actually often as alkalinity magnesium mg and sulfate so4 these diagrams have been applied for characterization of geological environments prol ledesma et al 2004 heikkinen et al 2009 hydrochemical evolution and mixing processes cloutier et al 2008 kumar et al 2006 freeze and cherry 1979 effects of land use and water sources jeong 2001 schot and van der wal 1992 suitability for drinking water agriculture and fen ecosystems yidana et al 2010 subramani et al 2005 silberbauer and king 1991 wassen et al 1990 and water resources monitoring silberbauer 2009 frapporti et al 1993 multi parameter water quality diagrams in general have a twofold function one is to determine the suitability of the water quality for a certain utilisation e g for drinking water or vegetation communities the other is to determine the origin and or evolution of the water sampled at a certain location in relation to its flow path the latter function may provide managers with information on the quality of the source water e g infiltrating precipitation or surface water alterations in water quality along the flow path due to biogeochemical processes and possible changes in flow paths feeding a site e g where groundwater seepage is replaced by infiltration of local precipitation van loon et al 2009 schot et al 2004 such information provides reference points for conservation and restoration policies and measures such as protection of water quality from pollution at the source or restoring groundwater seepage the shortcoming with currently most used water quality diagrams e g stiff piper maucha is that they were developed primarily for hydrogeological purposes information is presented mainly on macro ions like na cl ca hco3 mg and so4 from this the major ecological steering factors salinity and acidity can be deduced using na and cl for salinity and ca and hco3 for alkalinity or acidity however the existing diagrams lack adequate information on the third main ecological steering factor nutrients the nutrients nitrate no3 and potassium k are sometimes presented as single parameter potassium more often as the sum of na k however comprehensive nutrient information notably on the pivotal nutrients nitrogen and phosphorus is not commonly represented this makes the diagrams unsuitable for evaluating primary ecologically relevant parameters and processes or for comparing observed concentrations with water quality standards some attempts have been made to design water quality diagrams specifically for ecohydrological use in relation to wetland vegetation van wirdum 1991 developed the ionic ratio ir on the basis of calcium and chloride characterising water samples by their position relative to three main water types called atmotrophic precipitation lithothrophic groundwater and thalassotrophic seawater although widely used in especially dutch ecohydrological literature the method only provides a very general distinction for samples as a mixture of the three main water types remarkably it does not provide any information on nutrients wassen et al 1988 used an adapted stiff diagram with concentrations of nitrate no3 ammonium nh4 and phosphate po4 presented as three additional separate lines below the diagram however characteristic shapes representative of certain water types are not easily discerned some authors added a nutrient parameter like no3 to the classical water quality diagrams e g schot and van der wal 1992 but we found no water quality diagrams that encompass all the main eco hydro logically relevant nutrients no3 nh4 po4 and k despite the fact that a plea was made already in the early 1990 s for an internationally applicable composite classification adapted to ecohydrological research pedroli 1990 we postulate that more ecohydrologically relevant water quality diagrams may aid the work of academic ecohydrologists and water and nature managers such diagrams on a map or timeline may provide rapid insight on ecohydrological and biogeochemical processes affecting water quality on a landscape scale helping formulation of policies and measures for ecological and water quality conservation or restoration this paper aims to present ecohydrologically relevant water quality diagrams that provide information on both hydrogeological and ecological processes of interest to academic ecohydrologists and water and nature managers we focus on freshwater systems as defined by chloride concentrations 300 mg l thus including polluted freshwater but excluding brackish and saline waters cf stuyfzand 1988 griffioen et al 2013 2 method 2 1 selection of parameters the selection of parameters for an ecohydrologically relevant water quality diagram was based on its envisaged ability to provide information on the following factors ecological site conditions indicating the suitability of local water quality for flora and fauna development hydrological drivers of the site conditions on a landscape scale providing indications on the origin of water sources replenishing the site and on the processes driving water quality evolution along the flow path selection was also directed to parameters which are commonly analysed in eco hydrological monitoring or research programmes such as macro ions nutrients and common metals the number of parameters to include in the diagram was kept as low as possible to keep the diagrams comprehensible while still providing maximum relevant ecological and hydrological information the selected parameters are detailed below see table 1 nutrients are of prime importance for organisms but not included in commonly used water quality diagrams we included po4 no3 nh4 and k in our water quality diagrams to enhance relevance for ecohydrological studies both no3 and nh4 are considered because these are the forms most present and analysed in water samples they provide information on redox conditions and they differ as to their availability to plants boudsocq et al 2012 chloride was selected as indicator of one of the primary water quality determinants for ecosystems being salinity herbert et al 2015 chloride is also a conservative ion not engaged in hydrochemical processes except under hypersaline conditions appelo and postma 2004 and thus suitable as a natural tracer indicating the principal water source e g precipitation waste water seawater or mixing and pollution processes when dissolution of rock salts is insignificant calcium was selected for multiple reasons in most freshwater environments calcium is the main cation which virtually always comes up in statistical analyses as a principal component explaining variance in water quality samples low calcium also functions as indirect indicator for relatively high natural acidity e g in bogs where acidic precipitation recharges the organic soil devoid of calcium minerals gorham et al 1985 increasing calcium usually indicates decreasing acidity and increased alkalinity following dissolution of ca carbonates along the flow path appelo and postma 2004 calcium may further indicate agricultural pollution or cation exchange following aquifer salinisation or freshening martínez and bocanegra 2002 naus et al 2019 ecologically calcium may be important by limiting phosphorus nutrient availability through precipitation of ca phosphate minerals like hydroxyapatite griffioen 2006 dunne and reddy 2005 or complexation with ca carbonates avnimelech 1980 iron dissolution is an indicator of reduced conditions at near neutral and slightly alkaline ph drever 1997 appelo and postma 2004 redox processes steer the concentrations of many ecohydrologically relevant parameters e g nitrogen through denitrification and ammonification hefting et al 2004 sulphate versus sulphite smolders et al 2006 and toxic heavy metals through dissolution borg et al 2010 reduction processes are commonly fueled by degradation of organic matter leading to increased alkalinity mattson and likens 1992 iron may also control phosphorus nutrient availability through precipitation of iron fe ii phosphates vivianite and iron hydr oxides as sorbent gächter and müller 2003 house and denison 2002 sulfate may indicate human pollution at the origin of the water sources geohydrological processes like dissolution of sulfur bearing minerals pyrite gypsum or mixing with seawater in an ecological sense sulfate in wetlands may increase nutrient availability though oxidation of organic matter releasing ammonium and phosphate lamers et al 1998 smolders et al 2006 sodium was initially not selected as it does not add pivotal ecohydrological information and usually shows trends comparable to chloride stemming from dissolution of halite rock salt nacl or seawater as origin it was nevertheless added to enhance comparability of the visual appearance of the adapted diagrams with existing diagrams which all show the major ion couple na cl as an added value sodium may indicate feldspar dissolution while sodium chloride ratios may indicate cation exchange processes related to e g salinisation and freshening of aquifers magaritz luzier 1985 appelo willemsen 1987 bicarbonate which may often be equalised to alkalinity was likewise only selected to enhance visual comparability with existing diagrams showing the major ions couple ca hco3 bicarbonate usually shows concentrations similar to calcium stemming from dissolution of ca carbonates it may have an added value by indicating silicate weathering and the occurrence of reduction processes manifested through increased bicarbonate concentrations following oxidation of organic matter it also serves as an indirect indicator for acidity 2 2 definition of diagrams 2 2 1 selection of diagram form initially we opted to present one adapted water quality diagram fit for ecohydrological studies during our research it appeared personal preferences on diagram types may differ so we decided to present a number of different diagrams all using the same selected parameters we started by using the maucha and stiff diagrams as a basis for adapted diagrams both show cations on the left and anions on the right side of a vertical center line enabling insight in their mutual balance the original maucha diagram maucha 1932 used the 4 anions co3 hco3 cl so4 left and the 4 cations k na ca mg right stiff diagrams basically consist of 3 cations usually na ca mg and 3 anions usually cl hco3 so4 but many variations have been presented e g with 4 4 ions changed ion sequence from top to bottom or ion sums instead of a single ion e g na k instead of na we changed part of the above parameters to include all of our selected 10 parameters we paired na and cl as main representatives for salinity ca and hco3 for carbonates and alkalinity and indirect acidity and fe and so4 for information on redox conditions ammonium and no3 were paired as indicator of the redox status of the nutrient nitrogen potassium and po4 were paired to show the two remaining important nutrients although they usually behave independently of each other in contrast to the other 4 pairs we defined two adapted diagrams based on the maucha diagram and two on the stiff diagram in the maucha based diagrams we put the macro ions at the bottom fe so4 in the middle and the nutrients on top the latter was intended to emphasize the nutrient information we used the adapted maucha diagram as described by broch yake 1969 that allows for scaling of concentrations with the length of the arrows indicating ionic concentrations we call this form a jester diagram after some trials we felt the inward pointing arrows used for the minor concentrations in the maucha and jester diagram presented a visually distorted view on the actual concentrations we redesigned the diagram by using an arc starting from the diagram centre delineating a surface area proportional to the concentration we call this form a sector diagram in both diagrams a circle is used to indicate a standardised concentration per parameter which will be explained in the next section the ion pairs na cl and ca hco3 are presented in different grey scales indicating a sort of basic reference to salinity and alkalinity while the other ions have distinct colours for emphasis in the stiff based diagrams we kept the top part presenting na cl and ca hco3 to resemble the original stiff diagram beneath these we added fe so4 followed by the nutrients at the bottom we eliminated k from the na row as in the original stiff diagram to express the nutrient k as a separate ecological relevant parameter both new stiff based diagrams were developed with the top showing macro ions but differ with respect to the minor ions below the stiff a diagram shows the minor ions separated by a small spacing from the macro ions to emphasize the different individual scaling used for the minor ions see next section the stiff b diagram shows the minor ions depicted as separate bars similar to wassen et al 1988 but with broader bars and different colour for the minor ions both stiff based diagrams present the classical macro ions in grey scales and the minor ions in orange for emphasis the length of the horizontal parameter axes are in meq l but with a scaling factor for fe so4 and the nutrients see below 2 2 2 scaling of the minor ions essentially the selected ions are considered equally important with respect to their information value this implies they should come across in a visually balanced way in the diagram with concentrations presented in meq l as done for most current water quality diagrams this generally leads to overemphasis of the major ions ca and hco3 fresh systems and or na and cl more brackish systems to get all ions across visually more equal in the water quality diagram we introduced a scaling factor for each of the minor ions consisting of fe so4 and the nutrients a scaling factor is defined as the enlargement of concentrations of minor ions to get them displayed in the water quality diagram with comparable sizes to the macro ions the range of concentrations of minor ions as found in natural groundwater was the basis for establishing a scaling of the different parameters for this purpose a reference dataset was used consisting of over 6000 fresh groundwater analyses cl 300 mg l from a well studied 20 25 km region in the netherlands with many wetlands containing different water types having varying degrees of salinity acidity redox conditions and nutrient concentrations schot van der wal 1992 it appeared this reference dataset was useful as a basis for our scaling of the minor ions at least for all examples regional national continental temporal we present in this paper the major ions of fresh groundwater from the reference dataset showed median and average concentrations from 0 8 to 2 2 meq l and 1 4 2 6 meq l respectively to make the minor ions roughly comparable in size in the diagrams we decided to scale the minor ions to 1 meq l meaning the average concentration of the ion in the dataset will plot equal to 1 meq l the scaling factor for a minor ion x was defined as 1 average concentration ion x of the dataset to be visualised for an average minor ion concentration in the dataset used of e g 0 05 meq l the scaling factor becomes 1 0 05 20 which will then plot at 0 05 20 1 meq l in the diagram a measured concentration of 0 1 meq l would then be plotted as 0 1 20 2 meq l in the diagram in the stiff type diagrams the meq l are visualised by a scale bar above the diagram with a vertical line indicating 1 meq l as a reference for the scaled average concentration of the minor ions in the jester and sector diagrams a circle is used that signifies 1 meq l and denotes the average concentration of the minor ions these 1 meq l lines thus indicate whether the respective minor ion concentrations of a sample are below or above the average concentration in the dataset they do not represent true concentrations but scaled relative concentrations for the major ions the diagrams indicate the true concentration in meq l for two of our examples national scale and temporal variation we also used scaling of ions relative to particular water quality norms not only for the minor ions but also for the major ions since each ion may have an individual norm the scaling factor in this case for parameter y is defined as 1 norm concentration for parameter y for example a no3 concentration of 60 mg l relative to the european union drinking water norm of 50 mg l would be plotted as 60 1 50 1 2 which in the diagram would be visible as a length jester or area sector equal to 1 2 times the length area for the norm of 50 mg l the latter which is defined as equal to 1 and indicated by a circle in this way the diagram directly shows which parameters exceed the norm length of parameter surpasses the circle indicating the norm in this case all ions represent relative concentrations relative to norm 2 2 3 evaluation of diagrams on spatial and temporal scales we evaluated our approach for both spatial and temporal applications to demonstrate their wide applicability for both groundwater and surface water selection of demonstration sites was based on 1 areas for which we had access to water quality databases containing the necessary 10 parameters and 2 which have been described previously in peer reviewed scientific papers so readers can look up specifics of each area when needed we used groundwater data on 3 nested spatial scales ranging from regional via national to continental primarily based on access of the authors to suitable databases regional scale data from a 20 25 km area in the netherlands displaying a wide range of different water types from rainwater like to brackish schot van der wal 1992 national scale data of shallow groundwater down to 30 m in the netherlands as described by griffioen et al 2013 continental scale data of european groundwater from wendland et al 2008 for a temporal application we used surface water data from the vaal river in south africa showing water type variation over a monitoring period from january to november 2004 silberbauer 2009 for each of these databases a different adapted diagram type is used to illustrate spatial and temporal variation in water quality their relation to natural biogeochemical and human processes and value for monitoring and policy development background information on the respective areas can be obtained from the papers cited above 3 results 3 1 the stiff a diagram regional scale the new stiff a diagram in fig 1 graphically presents the main groundwater quality types in the central part of the netherlands as described by schot and van der wal 1992 these groundwater types were determined by cluster analysis of a set of 1349 fresh groundwater samples cl 300 mg l containing 12 different water quality variables including the 10 used in our adapted diagrams flow directions and flow system boundaries indicated in fig 1 are based on extensive hydrological system analysis studies in the area a o using flow path modelling isotope tracers and hydrochemical interpretation schot et al 1988 schot 1990 schot and molenaar 1992 the comprehensive diagrams allow for a detailed hydrogeological and ecohydrological interpretation hydrogeologically recharge by precipitation on the sandy ridge in the east is reflected in groundwater type a showing rather low hco3 and increased na cl ca so4 no3 and k concentrations indicating pollution by human activities in agricultural and urban areas low fe together with high no3 and so4 concentrations indicate the groundwater is still oxic or suboxic further down the flow path groundwater types b and c indicate 1 less pollution as water down the stream line is older and less affected by pollution 2 slightly increased fe and nh4 suggesting some reduction processes 3 increasing hco3 from dissolution of carbonates and possibly redox processes at the river plain we observe three distinct types of groundwater type d is shallow groundwater stemming from local precipitation that passes the confining peat layer during recharge it is relatively acidic and unpolluted and shows reduced conditions fe nh4 common to peat layers and some k enrichment type e results from the infiltration of surface water in lakes and canals that have become polluted as a result of suppletion with river rhine water during dry summer periods pollution signs are visible in the elevated na and cl and possibly po4 concentrations high fe and nh4 and low no3 and so4 concentrations indicate low redox potentials stemming from passage of the confining largely saturated peat or humic clay layers also leading to very high ca and hco3 concentrations schot wassen 1993 type f stems from holocene transgressions flooding the river plain with brackish saline water then infiltrating deep down into the main aquifer through density driven flow post 2004 due to mixing with fresh water in the aquifer the infiltrating water attains a decreased brackish character but still shows relatively high na cl and so4 these concentrations currently indicate upward flow of transgression affected water towards the surface in deep polders with low artificially controlled surface water levels schot and molenaar 1992 ecohydrologically groundwater exfiltrating at the margin of the ridge type c is relevant it has an unpolluted alkaline mesotrophic character feeding protected so called rich fens with high biodiversity which include many rare and endangered plant species wassen et al 1988 conservation of this type of seepage is therefore a main aim of nature management type a indicates groundwater that is more recently infiltrated on the ridge and became polluted which potentially may affect the rare rich fen plant communities in future when it exfiltrates on the river plain shallow peat water type d is also unpolluted and will likely become more alkaline during further flow providing favorable conditions for species rich fens when the water exfiltrates in adjacent lower lying polders although nutrient concentrations nh4 k are somewhat higher than in groundwater originating from the ridge schot and wassen 1993 types e and f are less suited for species rich fens due to their more saline and nutrient rich character 3 2 the jester diagram national scale the jester diagram in fig 2 presents main fresh cl 300 mg l groundwater quality types in the netherlands as based on griffioen et al 2013 the netherlands shows two distinctly different hydrogeological parts roughly demarcated by the ne sw directed mean sea level line in fig 2 a pleistocene part in the east and south with thick phreatic aquifers consisting mainly of fluvial sands and a holocene part in the north west and central riverine part with a confining top layer of predominantly clay and peat overlying pleistocene sandy aquifers and a coastal dune belt along the shore fig 2a shows major ions in grey in absolute concentrations in meq l while minor ions have been scaled relative to their average concentration over all areas salinity as indicated by na and cl concentrations is highest in areas i and ii in the coastal marine influenced holocene part in the west note only fresh groundwater samples cl 300 mg l were considered in this analysis the higher cl concentration for this fresh groundwater is due to mixing of fresh and saline groundwater as well as infiltration of river water with elevated cl concentrations stuyfzand 1993 area i also shows highest so4 concentration pointing to the same origins griffioen et al 2008 in the pleistocene part shallow groundwater typically originates from infiltration of rain and no marine influences are present in the shallow aquifers this causes low cl concentrations redox conditions as indicated by fe point to non reduced conditions in the most elevated areas with deep groundwater tables x vi and predominantly reduced conditions elsewhere despite extensive no3 in parts of the netherlands so4 concentrations are highest in the marine influenced area i as well as in the southern sandy pleistocene area vii and chalkstone area x which are subject to intense agricultural leaching of nitrates in the subsurface denitrification takes place by pyrite dissolution giving rise to increased so4 and relatively low no3 concentrations van beek and puffelen 1987 zhang et al 2009 this process does not take place in area x where no3 remains high the newly added nutrients k and po4 display highest concentrations in the western coastal areas i and ii while nh4 is highest in area ii these high nutrient concentrations have been linked to the degradation of marine sedimentary organic matter present in the holocene confining top layer mastrocicco et al 2013 griffioen et al 2013 nutrient no3 is highest in area x where this agriculturally derived compound remains in an oxic state due to deep groundwater tables and absence of degradable organic matter in the chalkstone aquifer nitrate is low in the western part where the groundwater table is permanently close to the surface and the confining peat and clay layers provide degradable organic material for denitrification calcium and hco3 concentrations are highest in areas i ii iii and x pointing to dissolution of ca carbonates from marine i lagoonal ii and fluvial iii sediments and from chalkstone in the most southern part x and eventually na hco3 type groundwater in relation to freshening of saline aquifers with associated cation exchange appelo willemsen 1987 areas i and ii show relatively low ca versus relatively high na concentrations indicating na hco3 water types resulting from cation exchange processes with ca replacing na from the cation exchange complex that was formerly in equilibrium with na rich marine water hco3 increases upon cation exchange due to enhanced ca carbonate dissolution griffioen et al 2013 area x shows highest ca concentrations related to chalkstone dissolution but relatively low hco3 with high no3 and so4 contributing significantly to total anion concentrations the diagrams and their differences also confirm that the geochemical control is stronger than the anthropogenic control despite large contamination of infiltrating rain and river water due to intensive agricultural and industrial activities in the netherlands van den brink et al 2007 the jester diagrams make clear a number of issues not well known to most water managers and ecohydrologists such as the naturally high nutrient concentrations k po4 nh4 in the coastal areas likewise high no3 leaching from intense agriculture in the eastern pleistocene areas is well known but less known is that by far the highest concentrations are in the southern chalkstone area due to lack of denitrification capacity while pyrite dissolution shown by high so4 denitrifies groundwater to a considerable extent in areas vii and iv also less known is the predominantly reduced character of shallow groundwater in the northern area ix and viii as evidenced by presence of dissolved fe when concentrations are plotted relative to drinking water health norms fig 2b it becomes clear that fe and nh4 are above drinking water norms in most of the areas this would entail treatment before the water can be used for drinking water 3 3 the stiff b diagram continental scale the new stiff b diagram is demonstrated for a selected number of major groundwater composition types at european scale fig 3 the diagrams are based on the paper by wendland et al 2008 who made a european aquifer typology as a practical framework to assess major groundwater composition at continental scale the typology included major classes of aquifers with comparable petrographic properties the various classes were expected to show similar groundwater compositions in comparable hydrodynamical and hydrogeological conditions major groundwater compositions were determined for aquifer types sands and gravels with subtypes limestones and crystalline rocks in the original paper results on groundwater compositions for each type were shown in the form of extensive tables covering 2 5 pages this hampers quick comparison between different types we therefore selected a number of groundwater composition types and plotted them using our new stiff b diagram to enable more rapid visual comparison fig 3 for clarity we only plotted a limited number of types for the sands and gravels 7 out of 10 limestones 2 out of 4 and crystalline rocks 1 out of 2 the diagrams indicate that groundwater composition varies across europe for similar aquifer types for the fluvial sands and gravels salinity is quite comparable whereas differences are visible for ca and hco3 in the order of a factor 3 and 10 respectively nitrate and phosphate are above average in bulgaria sofia valley while ammonium is highest in belgium pleistocene the glacial sands and gravels show relatively low ca and hco3 and high fe and nh4 concentrations in netherlands fluvioglacial deposits compared to denmark odense area and germany northern lowlands limestone in bulgaria sofia mountains shows a naca hco3 water type with high k and po4 concentrations differing significantly from germany midlands crystalline rocks groundwater from germany black forest and ore mountains clearly shows lowest mineralization of all groundwater types the diagrams of fig 3 indicate that contrary to the assumption of wendland et al 2008 groundwater composition in aquifers from the same typology may differ considerably between and within different countries notably in redox conditions as well as alkalinity concentration depending on regional petrographic and hydrogeological conditions it is also apparent that in different geological settings the newly added nutrient parameters may differ significantly thus adding significant ecohydrological water quality information 3 4 the sector diagram temporal scale fig 4 a presents changes in surface water quality in the form of sector diagrams over the period jan nov 2004 at an ambient water quality monitoring site of the department of water and sanitation on the rietspruit river south africa the rietspruit river is a tributary of the vaal river in gauteng province land use types in the rietspruit catchment include gold mines dryland agriculture and high density residential silberbauer and moolman 1993 showalter et al 2000 the changes in water quality during 2004 reflect pollution sources that include acid mine drainage so4 e g silberbauer 2011 and treated sewage cl po4 no3 and nh4 dzwairo and otieno 2014 summer rainfall in january to april appears to dilute the pollutant load concentrations then increase in the dry months until the rains begin again in late august or september fig 4b displays all ions relative to a set of norms based on values for good quality water in the south african water quality guidelines dwaf 1996 and the prescribed resource quality objectives dws 2016 for this part of the upper vaal catchment fig 4b makes clear that po4 concentrations exceed the norm set by water quality guidelines more than threefold in every sample suggesting a constant source of partly untreated effluent may have been entering the rietspruit from january to april nh4 is low and no3 is high while from august till november this somewhat reverses to low no3 and high nh4 the latter also exceeding the norm whether this is related to changes in nutrient inputs or to oxygen concentrations in the water is not clear from the data measured by dws changes in fe concentration between rainy and dry periods may be related to runoff from mines lowering the ph which increases the solubility of metal ions generally the addition of nutrients to the diagrams in both figures provide insights that go clearly beyond those obtained from classical diagrams restricted to major ions notably since the nutrients are the prominent parameters exceeding water quality policy guidelines 3 5 intercomparison of adapted diagrams fig 5 presents a comparison of the 4 adapted water quality diagrams for a number of samples taken from the four datasets used the figure shows how identical samples lead to visually distinctly different diagrams showing the different diagrams to colleagues during the preparation of this paper indicated that the favored diagram differs between people and may even differ between studied areas showing relatively low or relatively high salinity carbonates or minor ions since there is apparently no one size fits all diagram we present all 4 diagrams so readers can decide themselves which type suits their needs best the maucha based diagrams have macro ions at the bottom while the stiff based diagrams have macro ions at the top colouring in the jester and sector is much more pronounced than the two colours of the stiff a and b also the jester diagram may become quite spiky and take considerable plotting space when individual concentrations become relatively high the sector appears somewhat more compact the stiff based diagrams are characterized mainly by their typical grey and orange appearances 4 discussion four adapted water quality diagrams have been presented and demonstrated on both spatial regional national continental and temporal scales the regional example showed how the additional ions allow for a more profound ecohydrological analysis leading to insights in redox processes in water infiltrating through the peat clay layer on the river plain and to a lesser extent in deeper groundwater in the sandy hill ridge for nature conservation helpful insight is provided in possible nutrient pollution to seepage dependent fens at the ridge edge by no3 or to polders on the river plain by nh4 and k the national example provided new insight in high po4 nh4 and or k nutrient concentrations in the coastal regions as well as in exceptionally high no3 concentrations in the southern chalkstone area due to lack of denitrification capacity the continental example made clear similar aquifer types not necessarily present similar water qualities as was postulated and may differ considerably in nutrient concentrations depending on local human activities or possibly minor geological differences the temporal example of vaal river water in south africa showed high po4 concentrations consistently surpassing water quality standards more than threefold as well as possible seasonal differences in high no3 and nh4 and fe concentrations scaling concentrations relative to water quality policy guidelines proved useful for quick visual insight in exceedance of norms relevant for the areas at stake since water quality is a function of many parameters the adapted diagrams with 10 parameters now provide a user friendly visual presentation enabling a more holistic analysis of hydrogeological and ecological processes of interest to ecohydrologists and water and nature managers with respect to hydrogeological processes the information value of the existing and commonly used stiff and maucha diagrams is retained all major anions used in the classical diagrams cl hco3 so4 are also included in the adapted diagrams for the cations na and ca have been retained while k is displayed as a separate value whereas the classical stiff and piper diagrams display k as the sum of na k the concentration of mg has been left out of the new diagrams as this was considered less important from an ecohydrological perspective this may be seen as a drawback when hardness or mg itself is of significant interest for example in seawater intrusion processes with cation exchange however our parameter ca is also roughly indicative of total hardness as well as in cation exchange processes following seawater intrusion instead fe has been added as an important indicator of reduced hydrochemical conditions as redox conditions are strongly steering concentrations of many water quality variables by means of hydrochemical processes by adding the nutrients of which no3 and nh4 are particularly redox sensitive more advanced insight in redox conditions is offered by mutually comparing concentrations of fe no3 so4 and nh4 with respect to ecological processes the adapted diagrams add considerable extra information compared to classical water quality diagrams they present comprehensive information on the four most common environmental nutrients both nitrogen compounds no3 and nh4 phosphorus as po4 and k as a separate variable nitrate has been used in some variations of the classical stiff diagram eg nyenje et al 2013 but not regularly potassium is included in the piper and often in stiff diagrams as a summed value of na k but never as separate value ammonium and po4 are not used at all in classical water quality diagrams the only known exception is an adapted stiff diagram by wassen et al 1988 showing separate concentrations of no3 nh4 and po4 as three additional separate lines but the diagram lacked a clear shape to discern and characterize different water types therefore the adapted water quality diagrams presented may be considered as a response to the plea made by pedroli 1990 for an internationally applicable composite classification adapted to ecohydrological research finally using policy norms for scaling of ions has the advantage of providing an alarm function of exceedance of norms i e when concentrations surpass the ring in the diagram fig 2b and 4b we could not find any published application to the stiff or maucha diagrams such alarm functions may be useful in monitoring efforts on local regional or even continental scale e g in light of the eu water framework directive a number of choices were made during the creation of the adapted diagrams first the number of selected water quality parameters has been a trade off between supplying as much information as possible and keeping the number of parameters low enough to retain a comprehensible diagram we used 10 parameters to define our diagrams this is somewhat higher than the classical diagrams that commonly use between 6 and 8 parameters we have tried to facilitate interpretation of the stiff a and stiff b diagrams by using different colours for the macro ions grey and the minor ions orange for the jester and sector we used grey tones for the macro ions and different bright colours for each minor ion emphasizing our focus on ecohydrological purposes next the choice for a diagram form was not that unequivocal as initially envisaged although we initially aimed at defining only one adapted diagram discussions with multiple colleagues led to the insight that form preferences may differ between different people for all sorts of reasons this led to the decision not to try to devise one type of diagram but to present multiple diagram forms from which professionals may pick their own favorite by presenting multiple forms we have tried to make available a set of diagrams based on the same assumptions as to the ions to be included but different appearances that may suit different needs and preferences likewise we presented two forms of scaling of minor ions based on average concentrations or on policy norms time will tell which forms and scaling will be applied and for what kind of specific applications or reasons an important point of discussion pertains to the scaling of the minor ions we examined both using average and using median values of the 6 selected minor ions as a basis for scaling it appeared average values presented visually more informative diagrams than median values this is probably due to the skewed distribution of most minor ions which often display many values below or just above the detection limit this implies median concentrations may be relatively low leading to high scaling factors and subsequent extreme long points or bars in the diagrams for samples that are well above the median concentrations by using averages as a basis for scaling there are much less extremes the choice of using averages of concentrations for the minor ions has another important implication by using averages of concentrations found in a certain dataset the scaling basically becomes dataset or area specific since concentrations found in area a may be significantly different from those in area b the resulting average concentrations per area will also differ this then leads to different scaling factors per minor ion per area this implies that diagrams as to the minor ions are basically incomparable between different datasets of different areas for the macro ions they are in principle comparable as these are displayed by their true concentration in meq l although the scaling of the meq l axes may still differ between areas depending on the maximum values observed per area even within the same area one should consider what averages to use when sampling occurs at different moments in time e g for monitoring two approaches can be followed either one keeps the scaling based on the first sampling in which case concentrations of new samples can be directly compared with the old samples as scaling is the same in terms of increased decreased concentrations over time another approach is to calculate averages for each minor ion based on the complete dataset of all samplings over time and then scale samples of each monitoring event relative to these overall averages as long as the same scaling is used for different moments in time old and new samples can be directly compared to enable 1 1 comparison of the diagrams between datasets from different areas a uniform scaling of the minor ions should be applied we tried to find such a scaling based on comparing ranges and averages of different datasets from different areas within the netherlands and within europe we could however not find a one size fits all scaling method per parameter this is because different geological areas have different water quality characteristics with different average concentrations and thus different optimal scaling factors we tried to determine a sort of average overall scaling factor for each minor ion that could be applied uniformly for all areas this however had too much of a compromising effect on the information value of the diagrams per specific area we therefore decided to use area specific scaling factors there are simply too many differences between areas with respect to the different minor ion concentrations as a result of differences in geology human interventions etc a similar effect occurs when water quality norms are used for scaling of minor ions since water quality norms may differ per country or area considered they also differ between policy fields or intended use e g different norms for drinking water industrial use or natural ecosystems for example the ecohydrological standards for no3 are much lower than e g the drinking water limit of 50 mg l of the european union moreover depending on the type of ecosystem one is aiming to protect or restore different nitrate concentrations may be relevant depending on the tolerance of specific ecosystems to nitrates similarly the norms for other water quality parameters may differ between ecosystem types e g bogs need acidic oligotrophic water while fens need more alkaline mesotrophic water the same obviously applies to all other minor ions comparability of diagrams based on policy norms between different areas therefore necessitates a uniform norm e g the eu drinking water standard of 50 mg l for nitrate our adapted water quality diagrams were devised to be used by researchers and water managers alike we offer free access to our codes which enables users to modify them when needed e g add or replace certain parameters that are of particular interest to them we are curious to see which of the adapted ecohydrological water quality diagrams will be applied in future studies and whether a more uniform scaling of part of the minor ions will develop note on accessing diagram plotting scripts the code used to plot the adapted diagrams is openly accessible and freely usable by the community at large your own data can be inputted into a data entry sheet and plotted by running a single click r script the r project featuring code and data entry sheet is available at the following location https github com jebeard watertype diagrams 5 conclusion this paper sets out to present water quality diagrams that are relevant for ecohydrological research and related policy applications classical water quality diagrams being mainly developed for geohydrological purposes miss comprehensive information on nutrients which is pivotal to ecological functioning ecological considerations are on the forefront of present day policy efforts directed at achieving sustainable development which results in associated information needs we developed water quality diagrams which include all four ecohydrologically relevant nutrient species no3 nh4 po4 k the diagrams largely retain the traditional information on ions for hydrogeological characterization and additionally offer advanced insight in redox status from the combination of four redox sensitive parameters fe no3 so4 nh4 for ions that usually make up the bulk of the dissolved solids na cl ca hco3 concentrations are displayed in absolute meq l for the ions that are usually less dominant in meq l no3 nh4 po4 k fe so4 the concentrations can be scaled in two ways 1 relative to the average concentration of the ion at hand for the given dataset with the average plotted at 1 meq l 2 relative to an established policy norm for the minor ion eg nutrients or iron with the norm plotted at 1 meq l the diagrams may be used to compare water quality samples in a spatial mode or a temporal mode depending on the chosen scaling of the redox sensitive ions and nutrients the diagrams show at what location or time their concentrations are higher resp lower than the average concentration or than the policy norm concentration set for a particular ion parameter four different diagram appearances are developed on the basis of classical maucha and stiff diagrams the stiff a diagram resembles the classical stiff diagram with connection lines between the concentrations of the different ions this gives them a characteristic form that may be attributed to certain water quality types stiff b diagrams present concentrations as bars making it somewhat easier to distinguish separate relative concentrations jester diagrams have a pronounced spiky form that highlights large relative concentrations of samples the sector diagrams are more condensed showing a less outpointing appearance than the jester we envisage application of scaling to averages amongst ecohydrological researchers to highlight the main differences in an area or timeframe scaling relative to norms is likely more relevant for policy makers and evaluation of routine monitoring efforts policy norms scaling has the advantage of providing an alarm function of exceedance of norms eg those used for the eu water framework directive we made our r scripts publicly available which enables users to modify the r script to their particular needs credit authorship contribution statement paul schot conceptualization methodology investigation writing original draft writing review editing supervision jack beard software visualization riki hissink software validation michael silberbauer investigation writing review editing visualization software jasper griffioen investigation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
8543,ecological values of water have gained increasing attention over the past decades in both eco hydrological research and water resources management water quality is an important ecological steering variable and graphical water quality diagrams may aid in rapid interpretation of the hydrochemical status of a site traditionally used water quality diagrams for showing multiple variables e g stiff maucha were developed primarily for hydrogeological purposes with limited information on ecologically relevant nutrient parameters this paper presents adapted classical water quality diagrams that retain the traditional information on ions for hydrogeological characterization and additionally provide information on nutrients for ecological water quality characterization a scaling factor is used for the minor ions to visually get them across more equally compared to the macro ion ions in the water quality diagram scaling of minor ions is presented based on average concentrations as well as on water quality policy norms four different water quality diagrams are presented all with the same ions included but with different appearances to suit different preferences of individual users regional national and continental scale data are used to illustrate how the different diagrams show spatial and temporal water quality characteristics the adapted diagrams are innovative with respect to adding comprehensive visual information on the four ecohydrologically relevant nutrient species levels no3 nh4 po4 k advanced insight in redox status from the combination of four redox sensitive parameters fe no3 so4 nh4 and the option to scale minor ions relative to average measured concentrations or to water quality policy norms using policy norms for scaling has the advantage of providing an alarm function of exceedance of norms when concentrations surpass the ring used in the diagram we discuss possible standardisation of scaling factors to enable comparability between sites keywords ecohydrology water quality diagram nutrients geohydrology characterization hydrochemistry data availability data will be made available on request 1 introduction over the past decades the importance of ecological values in water resources management has been steadily increasing growing populations lack of sanitation and increased industrial and agricultural production have led to large scale pollution of both surface water and groundwater e g millennium ecosystem assessment 2005 mateo sagasta et al 2017 high concentrations of nutrients caused eutrophication of aquatic ecosystems leading to decreases in biodiversity and recreational values as well as economic damages cowx et al 2010 rosset et al 2014 dodds et al 2009 from the 1970 s onwards surface water pollution gave rise to national legislation especially in the usa and europe also international treaties were being drafted in europe to regulate water pollution of transboundary rivers e g for the rivers rhine dieperink 2000 and danube sommerwerk et al 2010 this international cooperation culminated in the water framework directive wfd of the european union in 2000 directive 2000 which aims for a good status of water quantity as well as chemical and ecological quality for all groundwater and surface water in the eu especially the strong focus on ecological quality on the scale of the european union was a novel aspect of this directive the increased attention for ecological values in water resources management was paralleled by an increased attention in scientific research on the interface between hydrology and ecology this interdisciplinary field of ecohydrology is referred to by different names e g ecohydrology hydroecology and definitions hannah et al 2004 it is basically concerned with how hydrology steers ecological processes and vice versa kundzewicz 2002 zalewski 2000 here we employ a broad interpretation of the term ecohydrology encompassing both aquatic and terrestrial ecology ecohydrological site variables reflect the relation between the hydrologic cycle and ecological processes it can be subdivided into a water availability part and a water quality part water availability is related to climate and topographical position in the landscape and steers selection of ecosystem communities adapted to different degrees of water stress porporato rodriguez iturbe 2002 water quality is related to geological setting soil type land use composition of contributing water sources and local biogeochemical interactions between organisms water soil and atmosphere water quality steers selection of species mainly with respect to their tolerances for concentrations in salinity acidity and nutrients herbert et al 2015 wassen et al 1988 ertsen et al 1998 determination and interpretation of water quality is notably complicated as it may be defined by many different parameters e g acidity macro ions nutrients trace elements microorganics these are often interlinked as they are subject to biogeochemical processes like oxidation reduction dissolution precipitation adsorption cation exchange and complexation domenico schwartz 1998 appelo and postma 2004 to facilitate interpretation of water quality measurements graphical multi parameter water quality diagrams may be useful they enable transferring information on a number of selected parameters into visual water quality types summarizing the hydrochemical status of a site well known diagrams are those described by stiff 1951 piper 1944 schoeller 1955 collins 1923 and maucha 1932 which all provide an overview of the main ions sodium na chloride cl calcium ca or bicarbonate hco3 actually often as alkalinity magnesium mg and sulfate so4 these diagrams have been applied for characterization of geological environments prol ledesma et al 2004 heikkinen et al 2009 hydrochemical evolution and mixing processes cloutier et al 2008 kumar et al 2006 freeze and cherry 1979 effects of land use and water sources jeong 2001 schot and van der wal 1992 suitability for drinking water agriculture and fen ecosystems yidana et al 2010 subramani et al 2005 silberbauer and king 1991 wassen et al 1990 and water resources monitoring silberbauer 2009 frapporti et al 1993 multi parameter water quality diagrams in general have a twofold function one is to determine the suitability of the water quality for a certain utilisation e g for drinking water or vegetation communities the other is to determine the origin and or evolution of the water sampled at a certain location in relation to its flow path the latter function may provide managers with information on the quality of the source water e g infiltrating precipitation or surface water alterations in water quality along the flow path due to biogeochemical processes and possible changes in flow paths feeding a site e g where groundwater seepage is replaced by infiltration of local precipitation van loon et al 2009 schot et al 2004 such information provides reference points for conservation and restoration policies and measures such as protection of water quality from pollution at the source or restoring groundwater seepage the shortcoming with currently most used water quality diagrams e g stiff piper maucha is that they were developed primarily for hydrogeological purposes information is presented mainly on macro ions like na cl ca hco3 mg and so4 from this the major ecological steering factors salinity and acidity can be deduced using na and cl for salinity and ca and hco3 for alkalinity or acidity however the existing diagrams lack adequate information on the third main ecological steering factor nutrients the nutrients nitrate no3 and potassium k are sometimes presented as single parameter potassium more often as the sum of na k however comprehensive nutrient information notably on the pivotal nutrients nitrogen and phosphorus is not commonly represented this makes the diagrams unsuitable for evaluating primary ecologically relevant parameters and processes or for comparing observed concentrations with water quality standards some attempts have been made to design water quality diagrams specifically for ecohydrological use in relation to wetland vegetation van wirdum 1991 developed the ionic ratio ir on the basis of calcium and chloride characterising water samples by their position relative to three main water types called atmotrophic precipitation lithothrophic groundwater and thalassotrophic seawater although widely used in especially dutch ecohydrological literature the method only provides a very general distinction for samples as a mixture of the three main water types remarkably it does not provide any information on nutrients wassen et al 1988 used an adapted stiff diagram with concentrations of nitrate no3 ammonium nh4 and phosphate po4 presented as three additional separate lines below the diagram however characteristic shapes representative of certain water types are not easily discerned some authors added a nutrient parameter like no3 to the classical water quality diagrams e g schot and van der wal 1992 but we found no water quality diagrams that encompass all the main eco hydro logically relevant nutrients no3 nh4 po4 and k despite the fact that a plea was made already in the early 1990 s for an internationally applicable composite classification adapted to ecohydrological research pedroli 1990 we postulate that more ecohydrologically relevant water quality diagrams may aid the work of academic ecohydrologists and water and nature managers such diagrams on a map or timeline may provide rapid insight on ecohydrological and biogeochemical processes affecting water quality on a landscape scale helping formulation of policies and measures for ecological and water quality conservation or restoration this paper aims to present ecohydrologically relevant water quality diagrams that provide information on both hydrogeological and ecological processes of interest to academic ecohydrologists and water and nature managers we focus on freshwater systems as defined by chloride concentrations 300 mg l thus including polluted freshwater but excluding brackish and saline waters cf stuyfzand 1988 griffioen et al 2013 2 method 2 1 selection of parameters the selection of parameters for an ecohydrologically relevant water quality diagram was based on its envisaged ability to provide information on the following factors ecological site conditions indicating the suitability of local water quality for flora and fauna development hydrological drivers of the site conditions on a landscape scale providing indications on the origin of water sources replenishing the site and on the processes driving water quality evolution along the flow path selection was also directed to parameters which are commonly analysed in eco hydrological monitoring or research programmes such as macro ions nutrients and common metals the number of parameters to include in the diagram was kept as low as possible to keep the diagrams comprehensible while still providing maximum relevant ecological and hydrological information the selected parameters are detailed below see table 1 nutrients are of prime importance for organisms but not included in commonly used water quality diagrams we included po4 no3 nh4 and k in our water quality diagrams to enhance relevance for ecohydrological studies both no3 and nh4 are considered because these are the forms most present and analysed in water samples they provide information on redox conditions and they differ as to their availability to plants boudsocq et al 2012 chloride was selected as indicator of one of the primary water quality determinants for ecosystems being salinity herbert et al 2015 chloride is also a conservative ion not engaged in hydrochemical processes except under hypersaline conditions appelo and postma 2004 and thus suitable as a natural tracer indicating the principal water source e g precipitation waste water seawater or mixing and pollution processes when dissolution of rock salts is insignificant calcium was selected for multiple reasons in most freshwater environments calcium is the main cation which virtually always comes up in statistical analyses as a principal component explaining variance in water quality samples low calcium also functions as indirect indicator for relatively high natural acidity e g in bogs where acidic precipitation recharges the organic soil devoid of calcium minerals gorham et al 1985 increasing calcium usually indicates decreasing acidity and increased alkalinity following dissolution of ca carbonates along the flow path appelo and postma 2004 calcium may further indicate agricultural pollution or cation exchange following aquifer salinisation or freshening martínez and bocanegra 2002 naus et al 2019 ecologically calcium may be important by limiting phosphorus nutrient availability through precipitation of ca phosphate minerals like hydroxyapatite griffioen 2006 dunne and reddy 2005 or complexation with ca carbonates avnimelech 1980 iron dissolution is an indicator of reduced conditions at near neutral and slightly alkaline ph drever 1997 appelo and postma 2004 redox processes steer the concentrations of many ecohydrologically relevant parameters e g nitrogen through denitrification and ammonification hefting et al 2004 sulphate versus sulphite smolders et al 2006 and toxic heavy metals through dissolution borg et al 2010 reduction processes are commonly fueled by degradation of organic matter leading to increased alkalinity mattson and likens 1992 iron may also control phosphorus nutrient availability through precipitation of iron fe ii phosphates vivianite and iron hydr oxides as sorbent gächter and müller 2003 house and denison 2002 sulfate may indicate human pollution at the origin of the water sources geohydrological processes like dissolution of sulfur bearing minerals pyrite gypsum or mixing with seawater in an ecological sense sulfate in wetlands may increase nutrient availability though oxidation of organic matter releasing ammonium and phosphate lamers et al 1998 smolders et al 2006 sodium was initially not selected as it does not add pivotal ecohydrological information and usually shows trends comparable to chloride stemming from dissolution of halite rock salt nacl or seawater as origin it was nevertheless added to enhance comparability of the visual appearance of the adapted diagrams with existing diagrams which all show the major ion couple na cl as an added value sodium may indicate feldspar dissolution while sodium chloride ratios may indicate cation exchange processes related to e g salinisation and freshening of aquifers magaritz luzier 1985 appelo willemsen 1987 bicarbonate which may often be equalised to alkalinity was likewise only selected to enhance visual comparability with existing diagrams showing the major ions couple ca hco3 bicarbonate usually shows concentrations similar to calcium stemming from dissolution of ca carbonates it may have an added value by indicating silicate weathering and the occurrence of reduction processes manifested through increased bicarbonate concentrations following oxidation of organic matter it also serves as an indirect indicator for acidity 2 2 definition of diagrams 2 2 1 selection of diagram form initially we opted to present one adapted water quality diagram fit for ecohydrological studies during our research it appeared personal preferences on diagram types may differ so we decided to present a number of different diagrams all using the same selected parameters we started by using the maucha and stiff diagrams as a basis for adapted diagrams both show cations on the left and anions on the right side of a vertical center line enabling insight in their mutual balance the original maucha diagram maucha 1932 used the 4 anions co3 hco3 cl so4 left and the 4 cations k na ca mg right stiff diagrams basically consist of 3 cations usually na ca mg and 3 anions usually cl hco3 so4 but many variations have been presented e g with 4 4 ions changed ion sequence from top to bottom or ion sums instead of a single ion e g na k instead of na we changed part of the above parameters to include all of our selected 10 parameters we paired na and cl as main representatives for salinity ca and hco3 for carbonates and alkalinity and indirect acidity and fe and so4 for information on redox conditions ammonium and no3 were paired as indicator of the redox status of the nutrient nitrogen potassium and po4 were paired to show the two remaining important nutrients although they usually behave independently of each other in contrast to the other 4 pairs we defined two adapted diagrams based on the maucha diagram and two on the stiff diagram in the maucha based diagrams we put the macro ions at the bottom fe so4 in the middle and the nutrients on top the latter was intended to emphasize the nutrient information we used the adapted maucha diagram as described by broch yake 1969 that allows for scaling of concentrations with the length of the arrows indicating ionic concentrations we call this form a jester diagram after some trials we felt the inward pointing arrows used for the minor concentrations in the maucha and jester diagram presented a visually distorted view on the actual concentrations we redesigned the diagram by using an arc starting from the diagram centre delineating a surface area proportional to the concentration we call this form a sector diagram in both diagrams a circle is used to indicate a standardised concentration per parameter which will be explained in the next section the ion pairs na cl and ca hco3 are presented in different grey scales indicating a sort of basic reference to salinity and alkalinity while the other ions have distinct colours for emphasis in the stiff based diagrams we kept the top part presenting na cl and ca hco3 to resemble the original stiff diagram beneath these we added fe so4 followed by the nutrients at the bottom we eliminated k from the na row as in the original stiff diagram to express the nutrient k as a separate ecological relevant parameter both new stiff based diagrams were developed with the top showing macro ions but differ with respect to the minor ions below the stiff a diagram shows the minor ions separated by a small spacing from the macro ions to emphasize the different individual scaling used for the minor ions see next section the stiff b diagram shows the minor ions depicted as separate bars similar to wassen et al 1988 but with broader bars and different colour for the minor ions both stiff based diagrams present the classical macro ions in grey scales and the minor ions in orange for emphasis the length of the horizontal parameter axes are in meq l but with a scaling factor for fe so4 and the nutrients see below 2 2 2 scaling of the minor ions essentially the selected ions are considered equally important with respect to their information value this implies they should come across in a visually balanced way in the diagram with concentrations presented in meq l as done for most current water quality diagrams this generally leads to overemphasis of the major ions ca and hco3 fresh systems and or na and cl more brackish systems to get all ions across visually more equal in the water quality diagram we introduced a scaling factor for each of the minor ions consisting of fe so4 and the nutrients a scaling factor is defined as the enlargement of concentrations of minor ions to get them displayed in the water quality diagram with comparable sizes to the macro ions the range of concentrations of minor ions as found in natural groundwater was the basis for establishing a scaling of the different parameters for this purpose a reference dataset was used consisting of over 6000 fresh groundwater analyses cl 300 mg l from a well studied 20 25 km region in the netherlands with many wetlands containing different water types having varying degrees of salinity acidity redox conditions and nutrient concentrations schot van der wal 1992 it appeared this reference dataset was useful as a basis for our scaling of the minor ions at least for all examples regional national continental temporal we present in this paper the major ions of fresh groundwater from the reference dataset showed median and average concentrations from 0 8 to 2 2 meq l and 1 4 2 6 meq l respectively to make the minor ions roughly comparable in size in the diagrams we decided to scale the minor ions to 1 meq l meaning the average concentration of the ion in the dataset will plot equal to 1 meq l the scaling factor for a minor ion x was defined as 1 average concentration ion x of the dataset to be visualised for an average minor ion concentration in the dataset used of e g 0 05 meq l the scaling factor becomes 1 0 05 20 which will then plot at 0 05 20 1 meq l in the diagram a measured concentration of 0 1 meq l would then be plotted as 0 1 20 2 meq l in the diagram in the stiff type diagrams the meq l are visualised by a scale bar above the diagram with a vertical line indicating 1 meq l as a reference for the scaled average concentration of the minor ions in the jester and sector diagrams a circle is used that signifies 1 meq l and denotes the average concentration of the minor ions these 1 meq l lines thus indicate whether the respective minor ion concentrations of a sample are below or above the average concentration in the dataset they do not represent true concentrations but scaled relative concentrations for the major ions the diagrams indicate the true concentration in meq l for two of our examples national scale and temporal variation we also used scaling of ions relative to particular water quality norms not only for the minor ions but also for the major ions since each ion may have an individual norm the scaling factor in this case for parameter y is defined as 1 norm concentration for parameter y for example a no3 concentration of 60 mg l relative to the european union drinking water norm of 50 mg l would be plotted as 60 1 50 1 2 which in the diagram would be visible as a length jester or area sector equal to 1 2 times the length area for the norm of 50 mg l the latter which is defined as equal to 1 and indicated by a circle in this way the diagram directly shows which parameters exceed the norm length of parameter surpasses the circle indicating the norm in this case all ions represent relative concentrations relative to norm 2 2 3 evaluation of diagrams on spatial and temporal scales we evaluated our approach for both spatial and temporal applications to demonstrate their wide applicability for both groundwater and surface water selection of demonstration sites was based on 1 areas for which we had access to water quality databases containing the necessary 10 parameters and 2 which have been described previously in peer reviewed scientific papers so readers can look up specifics of each area when needed we used groundwater data on 3 nested spatial scales ranging from regional via national to continental primarily based on access of the authors to suitable databases regional scale data from a 20 25 km area in the netherlands displaying a wide range of different water types from rainwater like to brackish schot van der wal 1992 national scale data of shallow groundwater down to 30 m in the netherlands as described by griffioen et al 2013 continental scale data of european groundwater from wendland et al 2008 for a temporal application we used surface water data from the vaal river in south africa showing water type variation over a monitoring period from january to november 2004 silberbauer 2009 for each of these databases a different adapted diagram type is used to illustrate spatial and temporal variation in water quality their relation to natural biogeochemical and human processes and value for monitoring and policy development background information on the respective areas can be obtained from the papers cited above 3 results 3 1 the stiff a diagram regional scale the new stiff a diagram in fig 1 graphically presents the main groundwater quality types in the central part of the netherlands as described by schot and van der wal 1992 these groundwater types were determined by cluster analysis of a set of 1349 fresh groundwater samples cl 300 mg l containing 12 different water quality variables including the 10 used in our adapted diagrams flow directions and flow system boundaries indicated in fig 1 are based on extensive hydrological system analysis studies in the area a o using flow path modelling isotope tracers and hydrochemical interpretation schot et al 1988 schot 1990 schot and molenaar 1992 the comprehensive diagrams allow for a detailed hydrogeological and ecohydrological interpretation hydrogeologically recharge by precipitation on the sandy ridge in the east is reflected in groundwater type a showing rather low hco3 and increased na cl ca so4 no3 and k concentrations indicating pollution by human activities in agricultural and urban areas low fe together with high no3 and so4 concentrations indicate the groundwater is still oxic or suboxic further down the flow path groundwater types b and c indicate 1 less pollution as water down the stream line is older and less affected by pollution 2 slightly increased fe and nh4 suggesting some reduction processes 3 increasing hco3 from dissolution of carbonates and possibly redox processes at the river plain we observe three distinct types of groundwater type d is shallow groundwater stemming from local precipitation that passes the confining peat layer during recharge it is relatively acidic and unpolluted and shows reduced conditions fe nh4 common to peat layers and some k enrichment type e results from the infiltration of surface water in lakes and canals that have become polluted as a result of suppletion with river rhine water during dry summer periods pollution signs are visible in the elevated na and cl and possibly po4 concentrations high fe and nh4 and low no3 and so4 concentrations indicate low redox potentials stemming from passage of the confining largely saturated peat or humic clay layers also leading to very high ca and hco3 concentrations schot wassen 1993 type f stems from holocene transgressions flooding the river plain with brackish saline water then infiltrating deep down into the main aquifer through density driven flow post 2004 due to mixing with fresh water in the aquifer the infiltrating water attains a decreased brackish character but still shows relatively high na cl and so4 these concentrations currently indicate upward flow of transgression affected water towards the surface in deep polders with low artificially controlled surface water levels schot and molenaar 1992 ecohydrologically groundwater exfiltrating at the margin of the ridge type c is relevant it has an unpolluted alkaline mesotrophic character feeding protected so called rich fens with high biodiversity which include many rare and endangered plant species wassen et al 1988 conservation of this type of seepage is therefore a main aim of nature management type a indicates groundwater that is more recently infiltrated on the ridge and became polluted which potentially may affect the rare rich fen plant communities in future when it exfiltrates on the river plain shallow peat water type d is also unpolluted and will likely become more alkaline during further flow providing favorable conditions for species rich fens when the water exfiltrates in adjacent lower lying polders although nutrient concentrations nh4 k are somewhat higher than in groundwater originating from the ridge schot and wassen 1993 types e and f are less suited for species rich fens due to their more saline and nutrient rich character 3 2 the jester diagram national scale the jester diagram in fig 2 presents main fresh cl 300 mg l groundwater quality types in the netherlands as based on griffioen et al 2013 the netherlands shows two distinctly different hydrogeological parts roughly demarcated by the ne sw directed mean sea level line in fig 2 a pleistocene part in the east and south with thick phreatic aquifers consisting mainly of fluvial sands and a holocene part in the north west and central riverine part with a confining top layer of predominantly clay and peat overlying pleistocene sandy aquifers and a coastal dune belt along the shore fig 2a shows major ions in grey in absolute concentrations in meq l while minor ions have been scaled relative to their average concentration over all areas salinity as indicated by na and cl concentrations is highest in areas i and ii in the coastal marine influenced holocene part in the west note only fresh groundwater samples cl 300 mg l were considered in this analysis the higher cl concentration for this fresh groundwater is due to mixing of fresh and saline groundwater as well as infiltration of river water with elevated cl concentrations stuyfzand 1993 area i also shows highest so4 concentration pointing to the same origins griffioen et al 2008 in the pleistocene part shallow groundwater typically originates from infiltration of rain and no marine influences are present in the shallow aquifers this causes low cl concentrations redox conditions as indicated by fe point to non reduced conditions in the most elevated areas with deep groundwater tables x vi and predominantly reduced conditions elsewhere despite extensive no3 in parts of the netherlands so4 concentrations are highest in the marine influenced area i as well as in the southern sandy pleistocene area vii and chalkstone area x which are subject to intense agricultural leaching of nitrates in the subsurface denitrification takes place by pyrite dissolution giving rise to increased so4 and relatively low no3 concentrations van beek and puffelen 1987 zhang et al 2009 this process does not take place in area x where no3 remains high the newly added nutrients k and po4 display highest concentrations in the western coastal areas i and ii while nh4 is highest in area ii these high nutrient concentrations have been linked to the degradation of marine sedimentary organic matter present in the holocene confining top layer mastrocicco et al 2013 griffioen et al 2013 nutrient no3 is highest in area x where this agriculturally derived compound remains in an oxic state due to deep groundwater tables and absence of degradable organic matter in the chalkstone aquifer nitrate is low in the western part where the groundwater table is permanently close to the surface and the confining peat and clay layers provide degradable organic material for denitrification calcium and hco3 concentrations are highest in areas i ii iii and x pointing to dissolution of ca carbonates from marine i lagoonal ii and fluvial iii sediments and from chalkstone in the most southern part x and eventually na hco3 type groundwater in relation to freshening of saline aquifers with associated cation exchange appelo willemsen 1987 areas i and ii show relatively low ca versus relatively high na concentrations indicating na hco3 water types resulting from cation exchange processes with ca replacing na from the cation exchange complex that was formerly in equilibrium with na rich marine water hco3 increases upon cation exchange due to enhanced ca carbonate dissolution griffioen et al 2013 area x shows highest ca concentrations related to chalkstone dissolution but relatively low hco3 with high no3 and so4 contributing significantly to total anion concentrations the diagrams and their differences also confirm that the geochemical control is stronger than the anthropogenic control despite large contamination of infiltrating rain and river water due to intensive agricultural and industrial activities in the netherlands van den brink et al 2007 the jester diagrams make clear a number of issues not well known to most water managers and ecohydrologists such as the naturally high nutrient concentrations k po4 nh4 in the coastal areas likewise high no3 leaching from intense agriculture in the eastern pleistocene areas is well known but less known is that by far the highest concentrations are in the southern chalkstone area due to lack of denitrification capacity while pyrite dissolution shown by high so4 denitrifies groundwater to a considerable extent in areas vii and iv also less known is the predominantly reduced character of shallow groundwater in the northern area ix and viii as evidenced by presence of dissolved fe when concentrations are plotted relative to drinking water health norms fig 2b it becomes clear that fe and nh4 are above drinking water norms in most of the areas this would entail treatment before the water can be used for drinking water 3 3 the stiff b diagram continental scale the new stiff b diagram is demonstrated for a selected number of major groundwater composition types at european scale fig 3 the diagrams are based on the paper by wendland et al 2008 who made a european aquifer typology as a practical framework to assess major groundwater composition at continental scale the typology included major classes of aquifers with comparable petrographic properties the various classes were expected to show similar groundwater compositions in comparable hydrodynamical and hydrogeological conditions major groundwater compositions were determined for aquifer types sands and gravels with subtypes limestones and crystalline rocks in the original paper results on groundwater compositions for each type were shown in the form of extensive tables covering 2 5 pages this hampers quick comparison between different types we therefore selected a number of groundwater composition types and plotted them using our new stiff b diagram to enable more rapid visual comparison fig 3 for clarity we only plotted a limited number of types for the sands and gravels 7 out of 10 limestones 2 out of 4 and crystalline rocks 1 out of 2 the diagrams indicate that groundwater composition varies across europe for similar aquifer types for the fluvial sands and gravels salinity is quite comparable whereas differences are visible for ca and hco3 in the order of a factor 3 and 10 respectively nitrate and phosphate are above average in bulgaria sofia valley while ammonium is highest in belgium pleistocene the glacial sands and gravels show relatively low ca and hco3 and high fe and nh4 concentrations in netherlands fluvioglacial deposits compared to denmark odense area and germany northern lowlands limestone in bulgaria sofia mountains shows a naca hco3 water type with high k and po4 concentrations differing significantly from germany midlands crystalline rocks groundwater from germany black forest and ore mountains clearly shows lowest mineralization of all groundwater types the diagrams of fig 3 indicate that contrary to the assumption of wendland et al 2008 groundwater composition in aquifers from the same typology may differ considerably between and within different countries notably in redox conditions as well as alkalinity concentration depending on regional petrographic and hydrogeological conditions it is also apparent that in different geological settings the newly added nutrient parameters may differ significantly thus adding significant ecohydrological water quality information 3 4 the sector diagram temporal scale fig 4 a presents changes in surface water quality in the form of sector diagrams over the period jan nov 2004 at an ambient water quality monitoring site of the department of water and sanitation on the rietspruit river south africa the rietspruit river is a tributary of the vaal river in gauteng province land use types in the rietspruit catchment include gold mines dryland agriculture and high density residential silberbauer and moolman 1993 showalter et al 2000 the changes in water quality during 2004 reflect pollution sources that include acid mine drainage so4 e g silberbauer 2011 and treated sewage cl po4 no3 and nh4 dzwairo and otieno 2014 summer rainfall in january to april appears to dilute the pollutant load concentrations then increase in the dry months until the rains begin again in late august or september fig 4b displays all ions relative to a set of norms based on values for good quality water in the south african water quality guidelines dwaf 1996 and the prescribed resource quality objectives dws 2016 for this part of the upper vaal catchment fig 4b makes clear that po4 concentrations exceed the norm set by water quality guidelines more than threefold in every sample suggesting a constant source of partly untreated effluent may have been entering the rietspruit from january to april nh4 is low and no3 is high while from august till november this somewhat reverses to low no3 and high nh4 the latter also exceeding the norm whether this is related to changes in nutrient inputs or to oxygen concentrations in the water is not clear from the data measured by dws changes in fe concentration between rainy and dry periods may be related to runoff from mines lowering the ph which increases the solubility of metal ions generally the addition of nutrients to the diagrams in both figures provide insights that go clearly beyond those obtained from classical diagrams restricted to major ions notably since the nutrients are the prominent parameters exceeding water quality policy guidelines 3 5 intercomparison of adapted diagrams fig 5 presents a comparison of the 4 adapted water quality diagrams for a number of samples taken from the four datasets used the figure shows how identical samples lead to visually distinctly different diagrams showing the different diagrams to colleagues during the preparation of this paper indicated that the favored diagram differs between people and may even differ between studied areas showing relatively low or relatively high salinity carbonates or minor ions since there is apparently no one size fits all diagram we present all 4 diagrams so readers can decide themselves which type suits their needs best the maucha based diagrams have macro ions at the bottom while the stiff based diagrams have macro ions at the top colouring in the jester and sector is much more pronounced than the two colours of the stiff a and b also the jester diagram may become quite spiky and take considerable plotting space when individual concentrations become relatively high the sector appears somewhat more compact the stiff based diagrams are characterized mainly by their typical grey and orange appearances 4 discussion four adapted water quality diagrams have been presented and demonstrated on both spatial regional national continental and temporal scales the regional example showed how the additional ions allow for a more profound ecohydrological analysis leading to insights in redox processes in water infiltrating through the peat clay layer on the river plain and to a lesser extent in deeper groundwater in the sandy hill ridge for nature conservation helpful insight is provided in possible nutrient pollution to seepage dependent fens at the ridge edge by no3 or to polders on the river plain by nh4 and k the national example provided new insight in high po4 nh4 and or k nutrient concentrations in the coastal regions as well as in exceptionally high no3 concentrations in the southern chalkstone area due to lack of denitrification capacity the continental example made clear similar aquifer types not necessarily present similar water qualities as was postulated and may differ considerably in nutrient concentrations depending on local human activities or possibly minor geological differences the temporal example of vaal river water in south africa showed high po4 concentrations consistently surpassing water quality standards more than threefold as well as possible seasonal differences in high no3 and nh4 and fe concentrations scaling concentrations relative to water quality policy guidelines proved useful for quick visual insight in exceedance of norms relevant for the areas at stake since water quality is a function of many parameters the adapted diagrams with 10 parameters now provide a user friendly visual presentation enabling a more holistic analysis of hydrogeological and ecological processes of interest to ecohydrologists and water and nature managers with respect to hydrogeological processes the information value of the existing and commonly used stiff and maucha diagrams is retained all major anions used in the classical diagrams cl hco3 so4 are also included in the adapted diagrams for the cations na and ca have been retained while k is displayed as a separate value whereas the classical stiff and piper diagrams display k as the sum of na k the concentration of mg has been left out of the new diagrams as this was considered less important from an ecohydrological perspective this may be seen as a drawback when hardness or mg itself is of significant interest for example in seawater intrusion processes with cation exchange however our parameter ca is also roughly indicative of total hardness as well as in cation exchange processes following seawater intrusion instead fe has been added as an important indicator of reduced hydrochemical conditions as redox conditions are strongly steering concentrations of many water quality variables by means of hydrochemical processes by adding the nutrients of which no3 and nh4 are particularly redox sensitive more advanced insight in redox conditions is offered by mutually comparing concentrations of fe no3 so4 and nh4 with respect to ecological processes the adapted diagrams add considerable extra information compared to classical water quality diagrams they present comprehensive information on the four most common environmental nutrients both nitrogen compounds no3 and nh4 phosphorus as po4 and k as a separate variable nitrate has been used in some variations of the classical stiff diagram eg nyenje et al 2013 but not regularly potassium is included in the piper and often in stiff diagrams as a summed value of na k but never as separate value ammonium and po4 are not used at all in classical water quality diagrams the only known exception is an adapted stiff diagram by wassen et al 1988 showing separate concentrations of no3 nh4 and po4 as three additional separate lines but the diagram lacked a clear shape to discern and characterize different water types therefore the adapted water quality diagrams presented may be considered as a response to the plea made by pedroli 1990 for an internationally applicable composite classification adapted to ecohydrological research finally using policy norms for scaling of ions has the advantage of providing an alarm function of exceedance of norms i e when concentrations surpass the ring in the diagram fig 2b and 4b we could not find any published application to the stiff or maucha diagrams such alarm functions may be useful in monitoring efforts on local regional or even continental scale e g in light of the eu water framework directive a number of choices were made during the creation of the adapted diagrams first the number of selected water quality parameters has been a trade off between supplying as much information as possible and keeping the number of parameters low enough to retain a comprehensible diagram we used 10 parameters to define our diagrams this is somewhat higher than the classical diagrams that commonly use between 6 and 8 parameters we have tried to facilitate interpretation of the stiff a and stiff b diagrams by using different colours for the macro ions grey and the minor ions orange for the jester and sector we used grey tones for the macro ions and different bright colours for each minor ion emphasizing our focus on ecohydrological purposes next the choice for a diagram form was not that unequivocal as initially envisaged although we initially aimed at defining only one adapted diagram discussions with multiple colleagues led to the insight that form preferences may differ between different people for all sorts of reasons this led to the decision not to try to devise one type of diagram but to present multiple diagram forms from which professionals may pick their own favorite by presenting multiple forms we have tried to make available a set of diagrams based on the same assumptions as to the ions to be included but different appearances that may suit different needs and preferences likewise we presented two forms of scaling of minor ions based on average concentrations or on policy norms time will tell which forms and scaling will be applied and for what kind of specific applications or reasons an important point of discussion pertains to the scaling of the minor ions we examined both using average and using median values of the 6 selected minor ions as a basis for scaling it appeared average values presented visually more informative diagrams than median values this is probably due to the skewed distribution of most minor ions which often display many values below or just above the detection limit this implies median concentrations may be relatively low leading to high scaling factors and subsequent extreme long points or bars in the diagrams for samples that are well above the median concentrations by using averages as a basis for scaling there are much less extremes the choice of using averages of concentrations for the minor ions has another important implication by using averages of concentrations found in a certain dataset the scaling basically becomes dataset or area specific since concentrations found in area a may be significantly different from those in area b the resulting average concentrations per area will also differ this then leads to different scaling factors per minor ion per area this implies that diagrams as to the minor ions are basically incomparable between different datasets of different areas for the macro ions they are in principle comparable as these are displayed by their true concentration in meq l although the scaling of the meq l axes may still differ between areas depending on the maximum values observed per area even within the same area one should consider what averages to use when sampling occurs at different moments in time e g for monitoring two approaches can be followed either one keeps the scaling based on the first sampling in which case concentrations of new samples can be directly compared with the old samples as scaling is the same in terms of increased decreased concentrations over time another approach is to calculate averages for each minor ion based on the complete dataset of all samplings over time and then scale samples of each monitoring event relative to these overall averages as long as the same scaling is used for different moments in time old and new samples can be directly compared to enable 1 1 comparison of the diagrams between datasets from different areas a uniform scaling of the minor ions should be applied we tried to find such a scaling based on comparing ranges and averages of different datasets from different areas within the netherlands and within europe we could however not find a one size fits all scaling method per parameter this is because different geological areas have different water quality characteristics with different average concentrations and thus different optimal scaling factors we tried to determine a sort of average overall scaling factor for each minor ion that could be applied uniformly for all areas this however had too much of a compromising effect on the information value of the diagrams per specific area we therefore decided to use area specific scaling factors there are simply too many differences between areas with respect to the different minor ion concentrations as a result of differences in geology human interventions etc a similar effect occurs when water quality norms are used for scaling of minor ions since water quality norms may differ per country or area considered they also differ between policy fields or intended use e g different norms for drinking water industrial use or natural ecosystems for example the ecohydrological standards for no3 are much lower than e g the drinking water limit of 50 mg l of the european union moreover depending on the type of ecosystem one is aiming to protect or restore different nitrate concentrations may be relevant depending on the tolerance of specific ecosystems to nitrates similarly the norms for other water quality parameters may differ between ecosystem types e g bogs need acidic oligotrophic water while fens need more alkaline mesotrophic water the same obviously applies to all other minor ions comparability of diagrams based on policy norms between different areas therefore necessitates a uniform norm e g the eu drinking water standard of 50 mg l for nitrate our adapted water quality diagrams were devised to be used by researchers and water managers alike we offer free access to our codes which enables users to modify them when needed e g add or replace certain parameters that are of particular interest to them we are curious to see which of the adapted ecohydrological water quality diagrams will be applied in future studies and whether a more uniform scaling of part of the minor ions will develop note on accessing diagram plotting scripts the code used to plot the adapted diagrams is openly accessible and freely usable by the community at large your own data can be inputted into a data entry sheet and plotted by running a single click r script the r project featuring code and data entry sheet is available at the following location https github com jebeard watertype diagrams 5 conclusion this paper sets out to present water quality diagrams that are relevant for ecohydrological research and related policy applications classical water quality diagrams being mainly developed for geohydrological purposes miss comprehensive information on nutrients which is pivotal to ecological functioning ecological considerations are on the forefront of present day policy efforts directed at achieving sustainable development which results in associated information needs we developed water quality diagrams which include all four ecohydrologically relevant nutrient species no3 nh4 po4 k the diagrams largely retain the traditional information on ions for hydrogeological characterization and additionally offer advanced insight in redox status from the combination of four redox sensitive parameters fe no3 so4 nh4 for ions that usually make up the bulk of the dissolved solids na cl ca hco3 concentrations are displayed in absolute meq l for the ions that are usually less dominant in meq l no3 nh4 po4 k fe so4 the concentrations can be scaled in two ways 1 relative to the average concentration of the ion at hand for the given dataset with the average plotted at 1 meq l 2 relative to an established policy norm for the minor ion eg nutrients or iron with the norm plotted at 1 meq l the diagrams may be used to compare water quality samples in a spatial mode or a temporal mode depending on the chosen scaling of the redox sensitive ions and nutrients the diagrams show at what location or time their concentrations are higher resp lower than the average concentration or than the policy norm concentration set for a particular ion parameter four different diagram appearances are developed on the basis of classical maucha and stiff diagrams the stiff a diagram resembles the classical stiff diagram with connection lines between the concentrations of the different ions this gives them a characteristic form that may be attributed to certain water quality types stiff b diagrams present concentrations as bars making it somewhat easier to distinguish separate relative concentrations jester diagrams have a pronounced spiky form that highlights large relative concentrations of samples the sector diagrams are more condensed showing a less outpointing appearance than the jester we envisage application of scaling to averages amongst ecohydrological researchers to highlight the main differences in an area or timeframe scaling relative to norms is likely more relevant for policy makers and evaluation of routine monitoring efforts policy norms scaling has the advantage of providing an alarm function of exceedance of norms eg those used for the eu water framework directive we made our r scripts publicly available which enables users to modify the r script to their particular needs credit authorship contribution statement paul schot conceptualization methodology investigation writing original draft writing review editing supervision jack beard software visualization riki hissink software validation michael silberbauer investigation writing review editing visualization software jasper griffioen investigation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
8544,while nonstationary flood frequency analysis nsffa methods have proliferated few studies have rigorously compared them for modeling changes in both the central tendency and variability of annual peak flow series also known as the annual maximum series ams in hydrologically diverse areas through monte carlo experiments we appraise five methods for updating estimates of 10 and 100 year floods at gauged sites using synthetic records based on sample moments and change trajectories of observed ams in the conterminous united states conus we compare two methods that consider changes in both central tendency and variability a gamma generalized linear model estimated with weighted least squares and the generalized additive model for location scale shape gamlss with a distribution free approach quantile regression and baseline cases assuming stationarity or only changes in central tendency trend space plots identify realistic ams changes for which modeling trends in both central tendency and variability were warranted based on fractional root mean squared errors frmse they also reveal statistical properties of ams under which nsffa models perform especially well or poorly for instance quantile regression performed especially well poorly under strong negative positive skewness although the nonstationary lp3 distribution accommodates most ams with trends well the sensitivity of nsffa model performance to different sample moments and trends suggests the need for more flexibility in prescribing design flood adjustments in the conus a follow up comparison of regional nsffa models pooling at site ams would further illuminate nsffa guidance especially for ams with properties less conducive to nsffa modeling such as positive skewness and increasing variability abbreviations ams annual maximum series conus conterminous united states nsffa nonstationary flood frequency analysis 1 introduction worldwide floods annually cause an estimated 24 billion in damage and the loss of thousands of lives kundzewicz et al 2014 moreover winsemius et al 2016 have projected a 20 fold increase in global flood risk by 2100 for many decades hydrologists have recommended that engineers and planners consider observed and anticipated changes in flood frequency when estimating design flood events bureau of public roads 1956 federal highway administration 2016 mounting evidence demonstrating the impacts of changes in climate land use and water resources management on floods has prompted myriad efforts to adjust design floods for these changing environmental conditions milly et al 2008 yan et al 2017 yet despite the proliferation of this research including numerous reviews khaliq et al 2006 hall et al 2014 madsen et al 2014 bayazit 2015 villarini et al 2018 salas et al 2018 coelho et al 2019 françois et al 2019 slater et al 2020 wasko et al 2021 relatively few studies have compared different design flood adjustment methods at multiple sites strupczewski et al 2001b delgado et al 2010 kochanek et al 2014 šraj et al 2016 debele et al 2017b schlef et al 2021 far fewer have compared them across continental scale regions with diverse hydrologic regimes moreover while national agencies are increasingly recommending adjustment methods including general safety factors and climate model simulations see wasko et al 2021 and references cited therein few best practices have been established through comparative studies indeed the recently updated federal guidelines for performing flood frequency analysis ffa in the united states bulletin 17c plainly state that such adjustments require more research england et al 2019 p 23 on the other hand numerous studies have criticized the mere premise of nonstationary flood frequency analysis nsffa especially when causes of observed changes cannot be attributed to changes in physical phenomena easily or when shorter term fluctuations in these physical phenomena are mistakenly treated as deterministic signals of long term change e g cohn and lins 2005 villarini et al 2009 montanari and koutsoyiannis 2014 serinaldi and kilsby 2015 indeed attributing trends to physical phenomena is often challenging merz et al 2012 especially given the prospect of omitted variable bias and the frequent paucity of environmental data for untangling competing hypotheses regarding drivers of trends yet in practice analysts may have enough confidence in the cause s of an at site trend to conduct a nonstationary analysis requiring more parameters which can increase the uncertainty of estimates this brings us to one pivotal nsffa modeling decision for what trend magnitudes is the reduced bias of a nonstationary model worth the increased uncertainty that comes with additional model parameters monte carlo simulation experiments which have a long tradition in ffa e g wallis et al 1974 markiewicz et al 2010 renard et al 2013 provide a tool for identifying trend magnitude thresholds above which nonstationary models become worthwhile based on root mean squared errors or other criteria for flood series with different stationary moments and change trajectories delgado et al 2010 faulkner et al 2020 hecht and vogel 2020 konrad and restivo 2021 luke et al 2017 mallakpour and villarini 2016 sankarasubramanian and lall 2003 strupczewski et al 2001a yu et al 2018 recent and ongoing efforts to improve both stationary and nonstationary ffa motivated our choices of methods to include in the monte carlo experiment these efforts include the updated guidelines for performing stationary ffa in the united states in bulletin 17c england et al 2019 using the annual maximum series ams comprised of annual maximum instantaneous peak flows as well as research from earlier stages of the flood frequency estimation for hydraulic design project sponsored by the u s federal highways administration dickinson et al 2019 dudley et al 2019 hodgkins et al 2019 ryberg et al 2020 blum et al 2020 york et al 2020 aimed to address the open questions regarding nsffa methods that bulletin 17c posed researchers in many other countries have also been tackling these challenges for both block maxima and peaks over threshold pot flood series strupczewski et al 2001b madsen et al 2014 durocher et al 2018 faulkner et al 2020 bartiko et al 2019 wasko et al 2021 while more comparisons of nsffa models applied to both these types of flood series are needed we focus on modeling changes to the annual maximum series due to its widespread use in the us and other countries along with the much greater accessibility of ams in addition practical flood frequency analysis often involves censored data such as imprecise historical flood observations in conjunction with systematically observed flood peaks cohn et al 1997 xiong et al 2020 bulletin 17c utilizes the expected moments algorithm ema cohn et al 1997 to incorporate censored data in stationary flood frequency analysis ffa this motivated us to consider nsffa methods based on the method of moments mom additional factors motivating our focus on moment based methods included the poor performance of maximum likelihood in monte carlo studies evaluating robustness to incorrect distribution type assumptions markiewicz et al 2010 strupczewski et al 2016 along with the need to de trend ams prior to applying l moments gado and nguyen 2016 another popular parameter estimation method for ffa however before evaluating how to incorporate censored data into a mom based nsffa framework it is important to identify nsffa modeling approaches that are conducive to moments based design flood estimates while we recognize the importance of nsffa approaches that can easily accommodate both gradual and abrupt changes bates et al 2012 we have focused our initial appraisal on methods that estimate changes following two more commonly modeled gradual change trajectories i linear changes in the conditional mean of log transformed ams and ii exponential changes in their conditional standard deviation and variance we designed monte carlo experiments using recent regression based conditional moments approaches for nsffa that consider the coupled nature of trends in the mean standard deviation and skewness serago and vogel 2018 hecht and vogel 2020 however neither of these studies explored the effect of skewed log transformed ams on nsffa estimates using monte carlo simulation experiments despite known limitations with modeling trends in variability with symmetric two parameter lognormal ln2 distributions when changes in variability are asymmetric hecht and vogel 2020 this is especially crucial in urbanizing basins where expanding impervious cover and other hydrologic changes often magnify smaller peak flows more than larger ones this motivates the use of three parameter distributions for which the skewness can be adjusted for trends in the mean and variance other recent monte carlo experiments have partially addressed these nsffa method appraisal gaps through simulations using parameter values based on a single site or a small number of sites in relatively homogeneous hydrologic regions these studies compare i the sensitivity of a nonlinear least absolute deviation model of exponential variance trends to data originating from log pearson type iii lp3 distributions with different skewness coefficients yu et al 2018 ii maximum likelihood estimation a two stage regression procedure based on weighted least squares assuming linear trends in the mean and variance and gamlss for several distributions debele et al 2017b and iii gamlss with cubic b splines and quantile regression qu et al 2020 in addition these studies did not adjust skewness coefficients to reflect trends in the mean and variance this study contributes a monte carlo experiment parameterized using statistical properties of observed ams in hydrologically diverse basins throughout the conterminous united states conus to identify the circumstances under which different nsffa models including two variability trend models iwls glm and gamlss are most viable following the suggestion of debele et al 2017 we also compare these moment based approaches to quantile regression an increasingly applied hydroclimatic frequency analysis method over et al 2016 qu et al 2020 sankarasubramanian and lall 2003 tramblay et al 2019 villarini and slater 2018 this enables us to identify circumstances under which methods targeting specific quantiles of interest could outperform ones assuming symmetric changes in variability as nonstationary probability plot correlation coefficient ppcc tests demonstrate the adequacy of a nonstationary lp3 distribution at over 98 of 50 year ams sampled at sites in the conterminous us see section 3 for information on records and section c5 for more information on the goodness of fit analysis we primarily evaluate the performance of these methods when applied to simulated data arising from this distribution however to evaluate the potential consequences of distribution type misspecification our monte carlo experiments also include a robustness study examining implications of incorrect distributional assumptions section 2 introduces the monte carlo experiments that assess the internal consistency of methods for estimating changes in ams distributions section 3 describes the estimation of experiment parameters from observed annual peak flow series in the conus section 4 presents experiment results section 5 appraises the nsffa methods we investigated with an eye for opportunities for future improvements section 6 concludes 2 monte carlo simulation experiments 2 1 experiment design we used monte carlo experiments to evaluate the accuracy of estimates of 10 and 100 year floods annual maximum instantaneous peak flows with a 10 and a 1 percent chance of exceedance in any given year with hypothetical 30 and 100 year records in basins with different stylized annual flood distributions and change trajectories fig 1 these are common design flood quantiles in transportation infrastructure design and floodplain management aashto 2014 this assessment required the generation of true values computed with a quantile function using known population moments and change trajectories which were selected based on observations at 1898 conus stations see section 3 we assumed that quantile functions produced unbiased estimates whenever distribution parameters were estimated correctly consequently we did not address general sampling issues that can cause common quantile estimators to produce downward biased quantile estimates stedinger 1983 ball et al 2019 while many metrics are useful for evaluating design flood estimates with candidate nsffa models a choice which depends on the problem at hand we evaluated our experiments primarily using relative percent error distributions percent bias pbias and fractional a k a normalized or relative root mean squared errors frmse first relative percent errors for each simulated quantile are computed as follows 1 re s t t 100 where s indicates a simulated quantile estimate and t indicates the true quantile computed with known parameters meanwhile the percent bias states the overall tendency for estimates from a set of simulations to be lower or higher than true quantiles 2 pbias i 1 n s i t t 100 where s i indicates the ith quantile estimate from a set of n simulations next we computed the frmse by normalizing the rmse using the true value t instead of the standard deviation s d or range of t because we only have a single true value for each quantile we estimate 3 frmse 1 n i 1 n s i t 2 t 100 implementing the experiments involved the selection of probability distribution functions along with plausible combinations of moments and trends from observed ams from which to simulate ams fig 1 we then compared 10 and 100 year design flood estimates from these simulated ams with ones computed using quantile functions with the known conditonal moments 5000 random uniform variates between 0 and 1 were generated to obtain annual non exceedance probabilities with which to compute simulated annual peak flow time series using known stationary moments and trends for each simulated ams the same set of random uniform variates was applied to all combinations of sample moments trends and distribution types the remainder of section 2 describes the computation of true and simulated quantiles while section c3 contains further details regarding experiment implementation using r statistical software version 3 6 3 r core team 2020 on the united states geological survey s yeti high performance computer hpc falgout et al 2015 and verified on the united states geological survey s tallgrass hpc using r version 4 1 3 falgout et al 2019 2 2 generating the truth with known conditional moments one can analytically derive parameters for theoretical distributions as functions of conditional moments we created true design flood values by using moments of the log transformed ams conditioned on covariate values 4 y ω f μ y ω σ y ω γ y ω where y ω is a time series of the log transformed ams y μ y ω σ y ω and γ y ω are the mean standard deviation and skewness coefficient respectively of y conditioned on a design matrix of hypothesized covariates ω to provide a baseline for comparing nsffa models we conducted simulation experiments for cases with a single covariate ω which can represent a discrete time index where ω 1 2 n or a physical covariate changing at a constant rate over time this linearly changing physical covariate may include a deterministic covariate such as impervious cover or a stochastic one such as a precipitation metric whose annual expected values increase linearly over time our goal is to compare design flood estimates conditioned on the last year of a synthetic series representing current conditions additional adjustments to the procedures detailed below are needed if any covariates change nonuniformly over time or if peak flow observations are missing while the nsffa models we evaluated can often accommodate these more complex cases some features of them such as the trend adjusted skewness coefficient require extensions meriting separate studies these models can also be extended to include multiple covariates including ones where different covariates drive trends in different moments e g xiong et al 2020 provided that correlations among covariates are considered to determine true values of conditional moments we needed to specify both sample moments computed assuming stationarity and trends in the mean and s d we consulted observed values of these sample moments and trends from log transformed ams at unregulated conus sites identified in a prior phase of our project dudley et al 2019 distributions and spatial patterns of these values are described in section 3 we henceforth use the terms log transformed and log space to describe natural logarithm transformations importantly a change in the log space mean corresponds to a change in the real space median and a change in the log space s d corresponds to a change in the square root of the real space coefficient of variation cv hecht and vogel 2020 first we assume that the value of the mean log transformed peak flow conditioned on a covariate ω exhibits a linear relationship with ω as follows 5 μ y ω μ y β μ 1 ω μ ω where μ y ω is the mean of natural logarithms of an ams conditional upon covariate ω μ y is the mean of log transformed ams conditional upon the covariate mean μ ω and β μ 1 is the rate at which μ y ω is changing with respect to ω we also recognize that trends in the mean impact the conditional variance when a record with a trend in the mean exhibits a constant variance the conditional variance σ y ω 2 equals the error variance σ ε 2 σ y ω 2 can be deduced by subtracting the explained variance β μ 1 2 σ ω 2 from the total variance of the log transformed peak flows σ y 2 hecht 2017 serago and vogel 2018 6 σ y ω 2 σ ε 2 σ y 2 β μ 1 2 σ ω 2 yet in some cases the variance of log transformed ams changes over time numerous hydroclimatic studies have characterized these changes with exponential functions partly since they retain positive variance values villarini et al 2012 panagoulia et al 2014 yu et al 2018 šraj and bezak 2020 xiong et al 2020 while alternative variance functions have also been applied in nsffa hecht and vogel 2020 strupczewski and kaczmarek 2001 yu et al 2018 we focused on appraising the following exponential variance model 7a σ y ω 2 σ ε ω 2 σ y 2 β μ 1 2 σ ω 2 exp β σ 2 1 ω μ ω where β σ 2 1 represents the regression coefficient associated with the exponential variance trend in response to a linear change in ω and σ ε ω 2 indicates the non constant error variance see section 2 4 for two methods for estimating these values we can also express 7a in terms of the s d trend magnitude β σ 1 7b σ y ω 2 σ ε ω 2 σ y 2 β μ 1 2 σ ω 2 exp 2 β σ 1 ω μ ω next we considered the effects that trends in the mean and s d had on skewness coefficients we obtained a single trend adjusted coefficient for an annual peak flow series by deriving the expectation of the skewness conditional upon the covariate ω 8 e γ y ω e e y μ y ω i σ y ω i 3 ω i where the expected value of the conditional skewness e γ y ω is the expectation of the log transformed ams y computed using their respective conditional mean and s d μ y ω and σ y ω expanding 8 and substituting in previously defined relationships yields the following expression 9 e γ y ω 1 e σ y ω i 3 ω i e σ y 3 γ y ω i e 3 σ y 2 β μ 1 ω i μ ω ω i e β μ 1 3 ω i μ ω 3 ω i where i is an index running from 1 to n see section 2 4 1 for estimation methods section c2 contains a complete derivation of this population equation and the sample estimators used in this study we also used magnification factors m vogel et al 2011 to express percent changes in annual flood quantiles attributable to changes in the mean and s d of annual floods β μ 1 and β σ 1 for a given covariate change δ ω for log linear trends in the mean the magnification factor m μ δ ω was computed as follows 10 m μ δ ω e x p μ y ω μ ω δ ω μ y ω μ ω exp β μ 1 δ ω for instance with a time index covariate setting δ ω 10 in 10 computes the percent change in the mean annual flood per decade percent changes can also be computed i e δ ω m μ δ ω 1 100 next we extended the work of vogel et al 2011 by computing magnification factors m σ δ ω for s d trends β σ 1 11 m σ δ ω e x p σ y ω μ ω δ ω σ y ω μ ω when computing m σ δ ω we centered the covariate ω so μ ω 0 see section c1 this set the s d at the midpoint of ω equal to the sample s d of the ams we then expanded 11 using 7 leading to 12 m σ δ ω e x p e x p β σ 1 δ ω 1 σ y 2 β μ 1 2 σ ω 2 m σ δ ω depends on the rates of change in the s d β σ for a given change in the covariate δ ω along with the conditional s d adjusted for the trend in the mean from 7 i e σ y 2 β μ 1 2 σ ω 2 see section c1 for derivations in the monte carlo experiments the values of the percent changes in the s d displayed on axes of the trend space plots e g fig 6 only consider the s d trend from 7 i e the exponent in 12 becomes σy ω so that the known s d trend is not confounded with the known trend in the mean however when computing flood magnification due to the s d trend one must consider the joint effects of trends in the mean and s d as shown in 12 finally we computed magnification factors for quantiles of interest as a function of both m μ δ ω and m σ δ ω in 11 and 12 respectively 13 m q p δ ω q p μ ω δ ω q p μ ω m μ δ ω m σ δ ω k 1 p where q p μ ω indicates the quantile computed with the covariate mean μ ω while q p μ ω δ ω indicates the quantile following a change in the covariate equal to δ ω and k γ y ω 1 p is a frequency factor commonly used with the lp3 distribution that is a function of the exceedance probability p and skewness kirby 1972 interagency advisory committee on water data 1982 frequency factors for other distributions can also be used e g z scores for normal distributions 2 3 generating annual maximum series from the log pearson type iii distribution we simulated ams originating from the three parameter lp3 probability distribution which the united states bulletins 17b interagency advisory committee on water data 1982 and 17c england et al 2019 have recommended for computing design flood estimates throughout the united states numerous countries and other political jurisdictions have also recommended the distribution which is simply the logarithmic transformation of a series arising from a pearson type iii p3 distribution e g cunnane 1989 rahman et al 2013 zhang et al 2020 in addition the p3 distribution is widely used with untransformed ams in china e g xiong et al 2014 ke et al 2018 while the strong goodness of fit of the lp3 distribution in the united states has been established under the assumption of stationarity beard 1974 vogel and wilson 1996 hu et al 2020 its adequacy as a conditional distribution for nonstationary conus sites has not been vetted previously we conducted a goodness of fit assessment that corroborated its adequacy for estimating conditional quantiles in diverse hydrologic regions of the conus this distributional hypothesis could not be rejected at the 95 level p 0 05 at 98 of 1900 sites with 50 year records using the nonstationary probability plot correlation coefficient test serago and vogel 2018 overall sites with an inadequate nonstationary lp3 fit p 0 05 only registered trends slightly more often than sites with adequate nonstationary lp3 fits 34 vs 31 for trends in the mean and 34 vs 29 for trends in the s d see section c5 for details including spatial patterns the lp3 distribution is a shifted two parameter gamma distribution e g stasinopoulos et al 2020 with a third non negative bound parameter τ instead of a fixed lower bound of zero e g griffis and stedinger 2007 when the skewness γ y is positive negative τ equals the lower upper bound of the distribution england et al 2019 we parameterized the lp3 distribution conditioned on a covariate ω using method of moments mom equations adapted from bulletin 17c england et al 2019 14a α y ω 4 γ y ω 2 14b θ y ω s i g n γ y ω σ y ω 2 α y ω 1 2 14c τ y ω μ y ω α y ω θ y ω 14d f y α y ω θ y ω τ y ω 1 θ y ω γ α y ω y τ y ω θ y α y ω 1 exp y τ y ω θ y ω where α is a positive shape parameter θ is a scale parameter often denoted as β instead of θ whose sign reflects the skewness and τ is a non negative location parameter equation 14d is the conditional probability distribution function for the nonstationary lp3 distribution in which γ α y ω represents the gamma function of the conditional shape parameter α y ω we used the lmomco r package asquith 2020 to estimate the three parameters as functions of conditional moments of log transformed ams its quape3 function computes quantiles based on known analytical relationships between lp3 distribution parameters and the first three moments this distribution does not have a closed form quantile function although approximations using frequency factors k γ y ω 1 p are instructive for illustrating the effects of skewness and exceedance probabilities on lp3 quantile estimates 15 q p ω exp μ y ω k γ y ω 1 p σ y ω while the lp3 distribution s shape parameter α incorporates skewness into the distribution the range of skewness the distribution can accommodate is bounded griffis and stedinger 2007a showed that when γ y 2 γ y 2 the distribution s density reaches infinity at its lower upper bound τ y which unrealistically implies that flows below above the mode of the distribution are impossible we considered these bounds in our interpretation of simulation results but did not apply any lower bounds on sample skewness estimates at γ y 1 414 buckett and oliver 1977 griffis and stedinger 2007b england et al 2019 because we wanted to compare nsffa models without this imposed constraint 2 4 nonstationary adjustment methods this section introduces the four nsffa methods that we compared to a stationary baseline through the monte carlo experiments assuming i a linear relationship between a time index covariate and log transformed ams and ii an exponential relationship between the same time index covariate and the residual variance of the first model the latter from which s d trends are inferred table 1 we demonstrated these methods assuming ams arise from nonstationary lp3 distributions although these general modeling approaches can accommodate other theoretical probability distributions as well 2 4 1 definitions and notation first we establish some key definitions and notation for describing trends estimated from samples of limited lengths for the first four models in table 1 all of which were based on covariate conditional sample moments we modified 15 to include estimated sample moments μ y σ y and γ y along with coefficients representing estimated trends in the mean and s d β μ 1 and β σ 1 these trend coefficients represent the rate at which moments change in response to linear changes in a covariate in this illustrative case each year we also adjusted the sample skewness for trends in the mean and s d see section c2 for more details with these estimated moments and trends we estimated floods with a given exceedance probability p for a given covariate value ω i as follows 16 q p i e x p μ y β μ 1 ω i μ ω k γ y ω 1 p σ y ω exp β σ 1 ω i μ ω table 2 summarizes formulas used to adjust the mean and s d for trends in each of our moment based models with the e1071 r package meyer et al 2019 we estimated the sample skewness with the g estimator which performs better in non normal samples joanes and gill 1998 and is used in the u s geological survey s peakfq software version 7 3 veilleux et al 2019a we also used the 1 6 n bias correction factor that tasker and stedinger 1986 recommended for the lp3 distribution below we provide more details on trend coefficients estimated from each nsffa model 2 4 2 estimating trends with constant variance ols mean first we examined ordinary least squares ols regression a well established nsffa method for modeling trends with a constant variance in log space while numerous papers have eschewed ols regression for its limiting assumptions such as linearity others have demonstrated its effectiveness for i addressing nonlinear flood response functions through various linearizing transformations see mosteller and tukey 1977 ii producing decision relevant information through relatively simple analytical expressions hecht 2017 iii corrections for short and long term persistence matalas and sankarasubramanian 2003 and iv estimating conditional moments for common ffa distributions common serago and vogel 2018 we chose ols over more outlier robust nonparametric alternatives helsel et al 2020 because it can model coupled trends in the mean and s d more easily and handle incomplete ams better we employed the following ols model 17a ln q i y i μ y β μ 1 ω i μ ω ε i 17b μ y ω μ y β μ 1 ω i μ ω 17c σ y ω n n 2 σ ε 2 n n 2 σ y 2 β μ 1 2 σ ω 2 first we established the ols model for the log transformed ams as a linear function of the covariate ω i where ε i are the model residuals next using 17b we estimated the mean conditional upon ω using the ols estimate β μ 1 which is a best linear unbiased estimator if the residual variance σ ε 2 is constant over ω helsel et al 2020 this estimator is still unbiased albeit not a minimum variance estimator even when the variance is not constant then using 17c we estimated the constant s d adjusted for the trend in the mean σ y ω n n 2 is a degrees of freedom adjustment factor to correct biased estimates of the residual variance σ ε 2 montgomery et al 2001 we then used these conditional moments to estimate design floods for specific exceedance probabilities note that olsrequires normally distributed residuals for hypothesis testing or computing confidence and prediction intervals but not for trend estimation helsel et al 2020 2 4 3 estimating trends with nonconstant variance i next we considered the iteratively weighted least squares gamma generalized linear model iwls glm an iterative two stage approach that accommodates non normal response variables well approximated by other exponential family distributions to investigate changes in variability from heteroscedastic residuals when residuals from a first stage conditional mean model follow a normal distribution its squared normal residuals useful for modeling variance trends follow a highly non normal chi square χ 2 distribution with one degree of freedom in turn this χ 2 distribution is a special case of the gamma distribution another exponential family member recent monte carlo experiments employing data generated from ln2 distributions and realistic variance trends have shown that iwls glm registers lower frmses than ols mean models hecht and vogel 2020 when their respective variance trend trajectories have been correctly specified aitkin 1987 demonstrated that iwls yielded asymptotic maximum likelihood estimates of the standard errors of an exponential variance model using this iterative approach previously implemented in hecht and vogel 2020 we estimated the conditional mean using a weighted least squares regression with variances estimated with a second stage gamma generalized linear model glm see appendix a next since iwls glm uses a natural log link function that directly exponentiates the variance change trajectory without requiring a transformation of the dependent variable s d trend estimates β σ 1 are easy to deduce from the estimated variance trend β σ 2 1 18a σ y ω exp 0 5 β σ 2 1 ω i μ ω then we can define β σ as follows 18b β σ 1 0 5 β σ 2 1 we can then insert β σ 1 into the magnification factors to quantify the s d trend and its effect on flood quantile estimates in percent terms meanwhile a trend adjusted skewness coefficient can be computed from moment and trend estimates using an equation similar to 9 19 e γ y ω 1 6 n n n 1 n 2 1 n i 1 n y i μ y ω 3 3 β μ 1 σ y 2 β μ 1 2 σ ω 2 1 n 1 i 1 n exp 2 β σ 1 ω i μ ω ω i μ ω σ y 2 β μ 1 2 σ ω 2 3 2 n n 1 n n 2 i 1 n exp 3 β σ 1 ω i μ ω see section c2 for a complete derivation of 19 2 4 4 estimating trends with nonconstant variance ii the generalized additive model for location scale and shape gamlss rigby and stasinopoulos 2005 flexibly simulates changes in the parameters of ams probability distributions villarini et al 2009 unlike the other regression based models introduced above gamlss can accommodate highly nonlinear parametric and nonparametric functions and response variables from highly skewed and kurtotic distributions of both continuous and discrete variables rigby and stasinopoulos 2005 yet its information theoretic model selection criteria with penalty terms for each parameter e g the akaike information criterion akaike 1974 encourages parsimonious models however the gamlss r package stasinopoulos et al 2020 does not enable users to specify the p3 or lp3 distribution while one can manually enter this distribution into gamlss xiong et al 2014 debele et al 2017a we applied an alternative approach that recognizes that the lp3 and p3 distribution is essentially a shifted two parameter gamma distribution a distribution which gamlss can readily model see appendix b one risk with this approach is that design flood adjustments cannot be performed on records with any values below above the lower bound upper bound parameter τy see 14c this is a common ffa problem when extreme skewness causes three parameter distributions to become bounded including with lp3 griffis and stedinger 2007a and gev zaghloul et al 2020 distributions we computed this error rate in simulations with different combinations of moments and trends see section 4 and section c6 1 for more details and results 2 4 5 estimating trends in quantiles quantile regression qr estimates ams quantiles as a function of hypothesized covariates without making any distribution type assumptions this method first introduced by koenker and bassett 1978 and previously implemented in numerous ffa studies see section 1 estimates quantiles for a non exceedance probability p as follows 20a q p i exp β p 0 β p 1 ω i υ p i 20b q p i exp β p 0 β p 1 ω i while qr enables one to investigate nonlinear change trajectories in estimated quantiles with a given exceedance probability q p we assumed for simplicity that estimated quantiles changed linearly with ω where β p 0 and β p 1 are the estimated intercept and slope terms respectively qr also assumes quantile specific asymmetric laplacian error distributions ν p i sankarasubramanian and lall 2003 which we assumed were homoscedastic for simplicity we used the rq function with the frisch newton interior point method from the quantreg r package koenker et al 2020 to estimate 10 year floods for records of 30 50 and 100 years we limited our analysis of qr for the 100 year event to 100 year records because it only estimated quantiles up to the exceedance probability of the largest observation a known limitation in qr applications to ffa qu et al 2020 we also assessed the frequency of the crossing quantile problem in which a quantile of a higher exceedance probability is greater than a lower exceedance probability el adlouni et al 2018 over et al 2016 in our case when the 10 year flood exceeded the 100 year flood we did not discard results with this violation given our focus on single quantile design flood estimates but we compared the frequency of this violation for different combinations of moments and trends to identify circumstances under which more sophisticated qr models capable of preventing this such as restricted quantile regression geraci and farcomeni 2020 2 5 robustness analysis with gev distribution finally since it is difficult to ascertain the true distribution of an ams we must evaluate the performance of nsffa estimation methods when the distribution type is mis specified markiewicz et al 2010 debele et al 2017b for this reason we also conducted a robustness study also with a uniformly distributed time index as the lone covariate to examine possible consequences of assuming the lp3 distribution when the ams arises from the generalized extreme value gev distribution and vice versa this robustness study also enabled us to assess the extent to which quantile regression becomes preferable when theoretical probability distributions are mis specified although the gev distribution is predicated upon the routinely violated assumption of independently and identically distributed i i d daily flows it is widely used for ffa in many places especially europe salinas et al 2014 and it often fits observed ams well e g cunnane 1989 xiong et al 2020 zhang et al 2020 contrary to many contemporary studies we estimated covariate conditional gev parameters using log transformed ams instead of untransformed ones to be consistent with our lp3 based estimation procedures first we applied the uniroot function in r statistical software r core team 2020 to estimate its shape parameter κ with this value we could then solve simultaneous analytical equations for the location and scale parameters ξ and α respectively see stedinger et al 1993 for gamlss we used the gumbel and reverse gumbel distribution in the gamlss r package stasinopoulos et al 2020 which does not have a built in gev distribution function this enabled us to test gamlss for ams generated from gev distributions with γ y 1 1396 1 14 the skewness coefficients of the gumbel γ y 1 1396 1 14 and reverse gumbel γ y 1 1396 1 14 distributions respectively meanwhile for γ y 0 we used gamlss to model trends in the mean and s d of log transformed ams assuming a normal distribution and then estimated gev parameters with mom future work could also examine the two parameter weibull distribution a member of the gev family given its recent success in regions with changing floods slater et al 2021 3 parameter estimation informed by observed floods to parameterize the monte carlo experiment we examined moments and trends of observed ams at sites subject to both minimal and substantial anthropogenic perturbations throughout the conus recently dudley et al 2019 identified 2683 stations in the united states with peak flow records covering a 50 year period 1966 2015 and 257 records encompassing a 100 year period 1916 2015 however since we focus on gradual trends we removed stations used in dudley et al 2019 with national water information system nwis peak flow qualification codes of 6 indicating known regulations and diversions we also omitted stations with any water years oct 1 sep 30 without any flow where one would need to apply a compound approach considering the probability of any flow during a given water year as well as a continuous probability distribution describing wet year peak flows e g kuczera and franks 2019 we also removed individual peak flow observations with qualification codes of 3 dam failure 4 below minimum recordable discharge 7 estimated historical peak from period outside of systematic gaging record and 8 above indicated value next we applied the 80 record coverage per decade criterion from dudley et al 2019 our final sample contained 1900 50 year records and 146 100 year records on perennial streams see https nwis waterdata usgs gov usa nwis peak help codes help for a list of qualification special condition codes and ryberg et al 2017 for additional discussion about them fig 2 illustrates the combinations of all moments and trends we estimated from the 50 year log transformed ams black dots regressed on a time index where ω 1 2 50 the red points show the combinations of sample moments and decadal percent changes in the mean δ μ y and s d δ σ y considered in the monte carlo experiments here these trends were modeled with iwls glm since it performed more consistently than gamlss in the monte carlo experiment although not better for all moment and trend combinations investigated fig 3 maps these decadal changes for 50 year records while section c4 contains maps of them for the 100 year records our overarching goal with the observed ams was to identify a broad range of apparent gradual trends in the mean and s d for our monte carlo experiment and leave the attribution of these trends to future work this makes our analysis of observed ams different than many recent investigations aiming to disentangle long term trends from abrupt changes and long term persistence e g villarini et al 2009 thus we opted to parameterize the experiment with moments and trend magnitudes encountered in 50 year records since there were far fewer 100 year records in small urbanizing basins and in arid regions even though trends in 50 year records are prone to being overestimated due to inter decadal climatic cycles moreover the design life of some infrastructure can match the decadal to centennial timescale over which longer term fluctuations appear as shorter term trends observed changes in ams variability in urbanizing basins including ones without significant trends in precipitation hecht and vogel 2020 also motivated our consideration of 10 decadal s d trends despite numerous differences in periods of record and methods our analysis produced spatial patterns of change in the means of ams observed in other studies including increases in the north central and northeastern united states e g mallakpour and villarini 2015 dethier et al 2020 the concentration of decreasing trends in the western conus reflects an abnormally strong aridity gradient between the east wet and west dry in recent decades bishop et al 2021 groundwater depletion also drives some decreasing streamflow trends in agricultural regions of the great plains kustu et al 2010 which may explain the absence of such a cluster in studies encompassing only minimally altered sites archfield et al 2016 droughts at the start and end of the 50 year period exacerbate increasing peak flow trends in the northeast hayhoe et al 2007 and decreasing ones in parts of the southwest barth et al 2017 respectively the paucity of trends in variability in our 100 year records concords with the lack of variability trends that villarini et al 2009 observed at sites with records of 100 years or longer next we estimated sample skewness coefficients using the g estimator from the e1071 r package meyer et al 2019 we selected true skewness coefficients of 0 6 and 1 1396 for the monte carlo experiment for specific reasons first we selected 0 6 because conus studies to date have found regional skewness coefficients within this range see https acwi gov hydrology frequency b17c supplementary materials reports html however since bulletin 17c recommends a weighted skewness coefficient comprised of both at site and regional skewness values england et al 2019 we also examined skewness coefficients of 1 1396 values well within the range of conus at site skewness coefficients in fig 2 gev distributions with a skewness of 1 1396 are equivalent to the two parameter gumbel distribution for which functions in the gamlss r package stasinopoulos et al 2020 are readily available we also examined differences between product moments and moments estimated using the ema recommended under current u s guidance in bulletin 17c england et al 2019 the latter which makes additional adjustments for low outliers a k a potentially influential low floods pilfs and other censored flow data section c7 shows that using ema instead of conventional product moments with pilfs can produce substantially different moment estimates at sites with higher s d s and negative skewness coefficients many of which are in more arid regions 4 results 4 1 simulations with correct lp3 distribution assumption this section presents results from the monte carlo simulations in which the nonstationary lp3 quantile function in 15 was used to estimate design floods arising from lp3 distributions to emphasize the effects of different trend combinations and skewness coefficients many figures focus on design flood estimates from simulated ams in which μ y 5 and σ y 1 were used we also compared runs with different σ y values to highlight its important influence on simulation results see section c6 for detailed results for other combinations of μ y and σ y 4 1 1 screening out infeasible estimates before comparing model estimates we inspected simulated ams for na values signaling synthetic observations outside of distribution bounds non convergence and other estimation errors first we compared the error rate for 100 year flood estimates from 100 year records for which μ y 5 and σ y 1 in these runs gamlss generated by far the most na values 26 for 100 year flood estimates followed by iwls glm 2 the other three models did not generate any errors gamlss na values principally arose from synthetic observations outside of lp3 distribution bounds whereas iwls glm occasionally failed to converge for δ μ 25 when using the glm2 r package marschner and donoghue 2018 for gamlss runs na s were much more frequent when synthetic observations were generated from strongly skewed distributions 55 of runs when γ y 1 14 figure c6 1 shows that these na rates were very high for records with s d trends when γ y 1 14 above 90 for several trend combinations with s d trends of 25 and ranging widely from 5 to 80 for trend combinations with s d trends of 10 meanwhile simulated ams with trends in the mean without concurrent s d trends had considerably lower na rates ranging from 9 to 24 in contrast when γ y 0 gamlss only produced one single na observation when δ μ 25 δ σ 25 overall high low outliers were more likely to yield na s for negatively positively skewed ams among the gamlss runs additional sensitivity analyses demonstrated that strong skewness γ y 1 14 produced high error rates 37 with gamlss even when σ y 0 5 the most common value at conus stations see fig 2 moreover runs with either δ μ 25 or δ σ 25 were removed for σ y 0 5 due to the implausible correlations these trends implied we considered the limitations of our shifted gamma adaptation of gamlss for the lp3 distribution under strong skewness in our interpretations of gamlss estimates from skewed distributions see section c6 for na rates obtained with different moment trend combinations in addition we observed crossing quantiles in qr results with 100 year records overall when μ y 5 and σ y 1 the qr 10 year flood exceeded the qr 100 year flood in 5 5 of all runs overall this crossing quantile rate was higher 10 for decreasing s d trends and even more so when combined with positive skewness negative trends in the mean aggravated crossing quantile rates when s d trends decreased but alleviated them when they increased while this crossing quantiles analysis identified circumstances under which a constrained qr procedure might be necessary for estimating design floods with different recurrence intervals see sec 2 4 5 we did not remove runs with crossing quantiles to avoid biasing our assessments of qr s performance for individual design flood estimates section c6 details crossing quantile rates for different moment trend combinations finally only some cases with extreme decadal trends in the mean 25 yielded γ y ω 2 a threshold above which the lp3 distribution becomes implausible for ams stedinger and griffis 2007a fig 2 demonstrates that most observed ams exhibited trends within 10 even during the short 50 year period we considered 4 1 2 stationary series generated from symmetric distributions next we established a baseline for how well the nsffa models performed with simulated ams originating from 100 year long stationary lp3 distributions we selected true moments for these distributions based on sample moments encountered in observed 50 year records see fig 2 since past monte carlo studies have consistently shown that design event estimates are much more sensitive to differences in variability than central tendency e g beard 1974 markiewicz et al 2010 we focused this initial analysis on s d effects on 10 year and 100 year floods fig 4 the probability distributions in the second row from the top and second column from the left in fig 2 shows that the mode of s d values observed at 1900 stations is roughly 0 5 that the base of the falling limb of the main peak lies at roughly 1 0 and that 1 5 represents values in conus regions with the greatest interannual flood variability such as the southwest and the great plains see fig 3 to isolate the effects of the sample s d on model performance we kept the mean and skewness constant μ y 5 γ y 0 note lp3 distributions with γ y 0 are equivalent to two parameter lognormal ln2 ones first these simulations confirmed that i estimators with more parameters were less efficient i e had greater error variance under stationary conditions ii estimates of 10 year floods were more efficient than estimates of 100 year floods and iii estimates from records with lower s d s were more efficient all models except qr exhibited median relative errors near 0 suggesting a roughly equal likelihood of overestimating and underestimating design floods in contrast qr registered a high mean bias 38 when σ y 1 0 due to some gross overestimates as its median is downward biased 13 when σ y 1 0 in practice this means that the greatest risk in using a qr design flood estimate is severe overdesign even when under design is more likely than overdesign the upward bias increased most when σ y rose from 1 0 to 1 5 furthermore stations with high s d s are also more likely to have pilfs see section c7 which cause disparities between design flood estimates made with conventional product moments and ema therefore in practice one should examine the effects of low outliers potentially influential low floods on records with high values of σ y before selecting nsffa models 4 1 3 sensitivity to trends in the mean and standard deviation next we examined the impacts of 10 decadal trends in the mean and s d of the log transformed ams on the relative errors re of 100 year flood estimates generated from lp3 distributions with the same combination of sample moments μ y 5 σ y 1 γ y 0 analyzed in section 4 1 2 as expected fig 5 shows that stationarity was often a problematic assumption for estimating design floods when trends were present and that ols mean also did not perform well when there were s d trends this effect became greater as the s d increased see section c6 2 for results with σ y 0 5 1 5 stationary models performed better when there were opposing trends in the mean and s d than when only one moment had a trend or when they exhibited concordant trends fig 5 demonstrates that the stationary model overestimated underestimated the 100 year flood at sites with decreasing increasing trends in the mean even when the s d changed at the same percent rate in the opposite direction this happened because the absolute change in the mean μ y 5 resulting from a 10 change was much greater than the absolute change in the s d σ y 1 resulting from the same percent change equation 15 shows that s d trends can fully offset opposing trends in the mean when δ μ y ω k γ y ω 1 p δ σ y ω 0 or when δ μ y ω δ σ y ω k γ y ω 1 p while this threshold ratio varies with skewness and exceedance probabilities for a 100 year flood at a site with a zero skew lp3 distribution where k 1 p 2 326 this offset happens when δ μ y ω δ σ y ω 2 326 if the ratio is below k 1 p the s d trend has a greater effect whereas the mean has a greater effect if it exceeds k 1 p in fig 5 this ratio equals five i e δ μ y ω δ σ y ω 0 5 0 1 5 this suggests that stationary estimators which have fewer parameters might perform better at sites with opposing trends close to this ratio fig 5 shows that the three models explicitly examining trends in variability or specific quantiles tended to attenuate the bias incurred in design flood estimates from ams with s d trends when only trends in the mean were modeled overall 100 year flood estimates from models explicitly examining trends in variability or specific quantiles were less efficient for increasing s d trends than decreasing ones because the consequence of errors in increasing trends modeled in log space becomes greater when exponentiated into real space during quantile estimation the relative performance of these three models varied by trend combination when only trends in the mean were present both iwls glm and gamlss exhibited a lower bias and greater efficiency than qr however for s d trends qr and iwls glm yielded more efficient and less biased estimates than gamlss when the directions of trends in the mean and s d were concordant while gamlss was most efficient and least biased when they were discordant interestingly iwls glm yielded downward biased estimates under concordant trends while it produced upward biased ones when trends were discordant whereas gamlss exhibited the opposite tendency these two models assume the same exponential change trajectory and gamlss did not register any na errors for the trend combinations in fig 5 when γ y 0 overall model performance depended substantially on trend directions for both moments next we produced trend space plots for each nsffa model fig 6 featuring contour surfaces of the design flood frmse for simulated ams arising from lp3 distributed ams of 100 years with different trend combinations we performed this procedure for different combinations of sample moments and estimated design floods with different recurrence intervals 10 and 100 years for this analysis we increased the magnitude of decadal trends from 10 to 25 to examine a broader range of trends altogether we examined 25 different combinations of trends in the mean and s d for which δ μ y 25 10 0 10 25 and δ σ y 25 10 0 10 25 as stated previously we limited this analysis to trends of 10 for σ y 0 5 since 25 decadal increases yielded implausible correlation coefficients when σ y 0 5 we bilinearly interpolated frmse values between points representing these trend combinations using the akima r package akima et al 2020 these values are displayed using a dark blue light gray dichromatic spectrum with the light gray endmember indicating a 0 frmse and dark blue indicating frmse 250 fig 6 shows results for simulated ams generated from lp3 distributions with μ y 5 σ y 1 γ y 0 the greater prominence of lighter shades of blue in the trend space plots in the left hand column of fig 6 shows that 10 year flood estimates registered lower frmse values than 100 year ones as expected qr also performed much better relative to other models for 10 year floods most frmse below 50 all frmse below 75 but generally worse than other models for 100 year floods because the density of synthetic observations is greater around the 90th percentile than the 99th percentile for an ams with a symmetric lp3 distribution fig 6 also demonstrates that each model estimated some trend combinations more accurately than others lightly colored zones running from the upper left to lower right quadrant of the stationary trend space plots top row corroborated the insight from fig 5 that stationary models performed better when δ μ y ω δ σ y ω k 1 p as k 1 p increased a larger change in the mean was necessary to offset a given s d change this explains why the lightly colored zone in the stationary 100 year plot has a more horizontal orientation than in the 10 year plot the second row in fig 6 shows that ols mean performed similarly for both increasing and decreasing trends in the mean but that its performance worsened more rapidly as s d trends decreased than as they increased iwls glm yielded much lower frmses when s d trends were decreasing often below 50 one reason iwls glm performed better for decreasing s d trends than increasing ones is because errors from an increasing exponential s d trend model are much larger in real space for similar reasons gamlss performed well for negative s d trends up to 10 bilinear interpolation made gamlss appear to perform extremely poorly as soon as s d trends exceeded 10 because it produced extremely unreliable estimates for s d trends of 25 within the 10 decadal s d trend range iwls glm gamlss performed better when trends were concordant discordant echoing fig 5 we then overlaid the trend space plots to indicate which of the five nsffa models yielded the lowest frmse for both 10 and 100 year flood estimates under different trend combinations see fig 7 panels a and b they were useful for identifying whether observed sites with a given range of sample moments exhibited trends warranting different nsffa models for instance these plots elucidated trend combinations under which models with just a trend in the mean yielded lower frmses than a stationary one or when models considering trends in both moments were worthwhile we overlaid trend combinations modeled with iwls glm observed at stations red diamonds with sample moments similar to simulated values μ y 4 6 σ y 0 8 1 2 and γ y 0 25 0 25 panels a and b of fig 7 indicate which model registered the lowest frmse for 10 and 100 year flood estimates for different trend combinations they are useful for identifying whether observed sites with a given range of sample moments exhibited trends warranting different nsffa models panel c maps these stations to provide a general sense of the conus regions where these results might be more relevant however these findings do not constitute nsffa recommendations for individual sites since more detailed studies that examine long term climate variability and potential anthropogenic perturbations would be necessary prerequisites as would goodness of fit analyses with observed ams panel c suggests that there are stations with trend combinations warranting ols mean iwls glm and gamlss if these trends were to represent deterministic changes in these basins in contrast there were not any sites with sample moments close to simulated values for which qr blue yielded the lowest frmse finally many ams lie near boundaries between preferred model zones in the trend space plots for such sites it is especially important to consider i trend space plots for all models considered as the model with the second best frmse may have other advantages and ii complementary model performance criteria including data based goodness of fit assessments renard et al 2013 fig 7 also contains many patterns discernible in figs 5 and 6 again stationarity green not only yielded the lowest frmse when both trends were near zero but also for some offsetting trend combinations especially ones with decreasing means and increasing s d the stationary model was also preferred more often for this combination of offsetting trends because s d trend models did not estimate design floods for increases in s d as well as they estimated them for decreasing s d their poor performance under increasing s d trends also explains the preference for the ols mean model purple for decreasing trends in the mean with strong increasing s d trends especially for 10 year floods yet the second row of fig 6 clearly shows ols mean did not perform especially well for such strong increasing s d trends either while models considering trends in variability or specific quantiles were more critical for 100 year flood estimates iwls glm orange occupies a large area in trend space plots for both recurrence intervals especially for decreasing s d trends 4 1 4 sensitivity to skewness coefficients we then examined how nsffa model performance varied among simulated ams arising from lp3 distributions with different population skewness coefficients we first examined a stationary base case in which μ y 5 and σ y 1 by comparing a symmetric distribution γ y 0 with ones having strong negative and positive skews γ y 1 14 for 100 year records arising from lp3 distributions fig 8 shows that the efficiency of both 10 and 100 year flood estimates worsened as the skewness increased from 1 14 to 1 14 since the distance between upper quantile values becomes greater as the skewness increases this effect was most pronounced for qr which had the most efficient and least biased estimates for all models except for stationarity when γ y 1 14 in contrast when γ y 1 14 qr was slightly less efficient than iwls glm and gamlss for the 10 year floods and much less efficient than them for 100 year floods while iwls glm and gamlss tended to exhibit similar efficiencies iwls glm estimated 100 year floods more efficiently from negatively skewed ams whereas gamlss performed better for positively skewed ones overall 100 year flood estimates were upward biased for the negative and positive skewness values considered despite applying an attenuation bias adjustment factor of 6 from the lp3 distribution study by tasker and stedinger 1986 to sample skewness coefficients estimated from synthetic observations this adjustment factor exacerbated the already considerable upward bias in 100 year floods for ams with γ y 1 14 while na rates for gamlss simulations with γ y 1 14 and without trends were relatively low 6 see section 4 1 1 figure c6 1 the possibility that removing simulations with low outliers below lp3 distribution bounds biases gamlss 100 year flood estimates merits further study next we examined the effects of strong skewness coefficients γ y 1 14 on current design flood estimates of ams with trends fig 9 due to the extremely high na rate for gamlss with decadal s d trends for γ y 1 14 stemming from synthetic observations outside estimated distribution bounds we limited this analysis to decadal trends of 10 these estimates tended to be more efficient for records with strong negative skew gray than for positively skewed ones turquoise albeit with some exceptions for iwls glm and gamlss design flood estimates from negatively skewed distributions also tended to exhibit higher median re relative errors than estimates from positively skewed ones the performance of the five models also differed between these extreme skewness cases in particular the performance of iwls glm and gamlss for a given trend combination was somewhat skewness dependent for example for concordant decreasing trends iwls glm was less more biased than gamlss under negative positive skewness gamlss exhibited the greatest upward bias for increasing s d trends a circumstance under which it would be more likely to yield na estimates caused by high outliers above its upper bound τ y while further study is needed the removal of simulated series with high outliers suggests removing na runs may in fact attenuate another source of upward bias meanwhile qr performed best for most trend combinations when γ y 1 14 especially when trends in the mean and s d concorded fig 10 also showcases qr s blue superior performance for stations whose sample moments are close to the simulation values of μ y 5 σ y 1 and γ y 1 14 4 1 5 sensitivity to record length while our comparisons up until now have focused on simulated 100 year records most observed ams are much shorter fig 11 demonstrates that stationary models green occupied more area in the trend space plots for 30 year records when μ y 5 σ y 1 γ y 0 see fig 7 and when μ y 5 σ y 1 γ y 1 14 this happened because design flood estimates from models incorporating trends in variability or specific quantiles are so much more variable for short records while models explicitly accounting for s d trends produced more accurate estimates under many strong negative s d trends when γ y 0 few stations with sample moments close to μ y 5 σ y 1 γ y 0 had such strong negative s d trends fig 11a meanwhile qr blue occupied a much larger portion of the trend space plot for γ y 1 14 4 2 robustness to incorrect distributional assumptions fig 12 illustrates trend space plots that examine possible consequences of assuming an lp3 distribution instead of a gev one panel b and vice versa panel c when true trend trajectories are known all four panels including ones illustrating correctly assumed lp3 panel a and gev panel d distributions demonstrate many similar model preferences meaning that nsffa model choices are quite robust to choices between these two distributions the greatest difference between them is the preference for iwls glm when lp3 is assumed and the preference for gamlss when gev is assumed these two models assume the same change trajectories in both the mean and s d and primarily differ in their estimation methods again regardless of the combination of true and assumed distributions stationarity green was the best model not only for ams without trends but also for ones with some combinations of offsetting trends especially ones where s d increases offset decreases in the mean ols mean purple performed much better for sites with trends in the mean and s d decadal increases from 0 to 10 than for ones with commensurate decreases models considering trends in variability performed better than ols mean for s d decreases including very mild ones qr blue performed better for records with extreme concordant trends qr also performed better with ams arising from gev distributions than lp3 distributions however the trend combinations for which qr performed best depended primarily on the true distribution the mis specification of true distribution types did not make qr preferable compared to simulations with correctly specified distribution types section c6 contains gev results analogous to many lp3 results shown in this section including ones demonstrating their overall robustness to the misspecification of lp3 and gev distributions with γ y 1 14 5 discussion 5 1 synthesizing our appraisal of nsffa methods our monte carlo simulations corroborated other recent studies showing that variability trends can substantially impact design flood estimates e g strupczewski et al 2001b delgado et al 2012 debele et al 2017b hecht and vogel 2020 moreover while the estimation errors introduced when s d trends were modeled were often large they produced lower frmse values than models only considering trends in the mean for realistic cases especially for decreasing s d trends due to the log transformation of the ams in contrast the stationary model was more efficient than nsffa models for some combinations of offsetting trends in the mean and s d in addition our regression based nsffa models were largely robust to incorrect distributional assumptions while the lp3 and gev distributions have reasonably similar upper tails compared to other ffa distributions asquith et al 2017 prior simulation studies have also shown that regression based estimates are more robust to distribution misspecification than distribution specific maximum likelihood ones markiewicz et al 2010 strupczewski et al 2016 we also reconciled our results with a recent climate oriented conference paper yu et al 2018 featuring monte carlo simulations that examined adjustments of design flood estimates for variability trends when ams arose from lp3 distributions at first our results may appear to contradict their finding that modeling variability trends seldom improved frmse however they drew their conclusions from an ams based on one station in the humid northeastern us with a moderate s d σ y 0 5 in contrast our results drawn from a continental scale sampling of observed ams including stations in regions with greater interannual variability demonstrated the value of modeling gradual variability trends a comparison of their nonlinear least absolute deviation models of variance change with the models tested in this study would illuminate the importance of considering variability trends further our monte carlo experiments also revealed other important guidance regarding our nsffa models including circumstances under which qr performed well and poorly compared to the moment based models it performed exceptionally well under strong trends for 10 year flood estimates when the skewness was strongly negative for 100 year floods i e when upper quantile values were closer together on the downside it performed quite poorly for positively skewed data and produced exceptionally high outliers even when γ y 0 which makes its use for at site flood frequency riskier the contributions of high outlier floods to severe estimation errors including their timing in the record merits further exploration the robustness study did not demonstrate that qr became preferable when theoretical distributions were incorrectly assumed however future studies with data generated from more divergent distributions would shed more light on qr s potential for at site nsffa future work should also explore nonlinear qr models using quadratic or cubic terms to better approximate exponential variance trends along with extremal qr approaches for estimating quantiles associated with recurrence intervals exceeding record lengths chernozhukov 2005 finally preferred model trend space plots provided a useful visualization for comparing nsffa model performance criteria such as frmse at sites with different trend combinations moments and record lengths it is important to identify models that perform almost as well as the preferred model for a given combination of trends in the mean and s d of ams since they may be more desirable for other reasons see fig 6 trend space plots for evaluating nsffa models for individual sites could also be generated from monte carlo experiments that consider statistical properties of their ams such as sample moments and record length they could provide an important line of evidence for model selection and complement goodness of fit assessments with observed data nicely such site specific applications could also be customized further by sampling plausible trend combinations more densely around trend estimates obtained from candidate nsffa models 5 2 limitations and future directions in nsffa modeling this study evaluated nsffa models using covariates representing gradual changes that transpired at fixed rates over time while a similar experimental design could assess these nsffa models when other deterministic or stochastic covariates with temporally varying rates of change are used numerous adaptations would be necessary most notably the trend adjusted skewness in 9 and 19 requires a uniformly distributed covariate without any missing data see section c2 other distributional assumptions are needed to represent deterministically changing covariates with varying rates of change stochastic covariates also require procedures for untangling deterministic trends from stochastic variability equations 9 and 19 also highlight the sensitivity of trend adjusted skewness coefficients to the sample skewness of covariates since a linear transformation of a random variables with a given skewness yields an output variable with the same skewness one must consider transforming covariates whose skewness varies markedly from that of an ams next the simulation experiments evaluated the internal consistency of nsffa models applicable to continuous ams with all peak flows above zero notably these experiments also did not include i historical floods outside of systematic gauging periods ii censored measurements iii adjustments for low outliers and iv systematic records with mising years in addition we treated all discharges as point estimates despite peak flow gauging uncertainties see kiang et al 2018 the expected moments algorithm ema which accommodates imprecise discharge estimates falling within a specified interval could be extended to incorporate these uncertainties evaluating nsffa models with a conditional moments based approach is an essential precursor to extending the interval data accommodations of ema to nonstationary ams ams generated from a wider range of realistic theoretical probability distributions such as three parameter lognormal e g vogel and wilson 1996 generalized logistic e g ekeu wei et al 2020 metastatistical extreme value miniussi et al 2020 and burr zaghloul et al 2020 distributions along with mixedpopulation approaches hirschboeck 1987 barth et al 2019 could illuminate other benefits of the nsffa models as could multi model estimates derived from them e g debele et al 2017a b finally comparing suitable nsffa models for other flood characteristics besides peak flow such as frequency duration and volume would provide a more complete picture of conus flood changes archfield et al 2016 there are also many opportunities to improve variability trend modeling including modeling changes in variability driven by covariates different than ones used for modeling changes in the mean e g xiong et al 2020 bertola et al 2021 slater et al 2021 we also only examined an exponential variance change trajectory prevalent in the nsffa literature e g strupczewski et al 2001a delgado et al 2010 villarini et al 2012 xiong et al 2020 that both iwls glm and gamlss accommodate readily additional research should evaluate other change trajectories such as gamlss nonlinear spline functions e g qu et al 2020 at sites with deterministic drivers of variability change such as urbanization abrupt and non monotonic changes in the mean and s d also merit consideration including disturbance recovery sequences from wildfires e g saxe et al 2018 climate oscillations e g kwon et al 2008 dickinson et al 2019 glacial melt shah et al 2020 and stormwater management mcphillips et al 2019 further work on disentangling step changes from trends bates et al 2012 rougé et al 2013 ryberg et al 2020 and using more recent subsets of ams vogel and kroll 2020 instead of trend adjusted design floods is also warranted finally advantages of covariate based statistical models over gcm forced simulations of future flood changes performed with process based hydrologic models e g schlef et al 2021 motivates the continued development of nsffa models indeed changes in flood trend trajectories over time make evaluating changes in future flood risk especially challenging through a split sample experiment luke et al 2017 demonstrated risks associated with extrapolating observed trends into the future even when deterministic changes in watershed characteristics could be identified future simulation experiments building upon our work could also assess consequences of making incorrect assumptions about future flood trajectories using different methods for assessing changes in them over specific project lifespans see yan et al 2017 next further research could also determine whether at site nsffa model preferences based on monte carlo simulations change when estimating design floods at ungauged sites with regional models o brien and burn 2014 showed that regionalization is especially beneficial under nonstationarity since more information is available to reduce the greater parameter uncertainty of nonstationary models some studies have demonstrated the benefits of regional applications of models that yield highly variable estimates when applied to single site records including a qr based approach for estimating urbanization induced changes in the chicago metropolitan area over et al 2016 finally deep learning methods for predicting flows e g kratzert et al 2019 also merit attention in any case our results highlight the need for a customizable nsffa modeling approach reflecting the hydrologic diversity of the conus future studies should assess alternative nsffa models in regions with ams exhibiting statistical properties for which our models did not perform well such as positive skewness and increasing trends in both the mean and s d populous regions of the northeastern us have positively skewed ams watson and schopp 2009 veilleux et al 2019b while a strong regional signal of change in peak flow variability has not been detected there see fig 2 ongoing increases in mean and extreme precipitation e g huang et al 2017 suggest future increases in both moments are possible 6 conclusions monte carlo simulations enabled us to appraise the performance of five nsffa models for considering the effects of gradual trends on estimates of 10 and 100 year floods a range of design events commonly used in infrastructure design and floodplain management in the united states aashto 2014 while numerous studies have compared nsffa models through monte carlo simulations strupczewski and kaczmarek 2001 delgado et al 2010 debele et al 2017b yu et al 2018 hecht and vogel 2020 qu et al 2020 vogel and kroll 2020 our experiments were distinct in their parameterization using combinations of sample moments and trends observed in a continental scale set of ams while the lp3 distribution is an adequate assumption under nonstationarity in most conus locations our experiments highlight the diversity of nsffa modeling approaches needed to adjust design floods to current conditions at sites throughout the conus including sites where additional models may be needed to compare candidate nsffa models we developed trend space plots displaying monte carlo experiment performance metrics frmse in our example for different trend combinations however while these plots elucidated trend combinations for which different nsffa models perform best when their distributions are correctly and incorrectly specified these experiments have not evaluated how well different models approximate observed change trajectories at sites with different statistical properties future research that compares the goodness of fit of different assumed change trajectories and distributional assumptions is essential for advancing nsffa this must include out of sample testing to avoid confounding short term fluctuations with long term trends luke et al 2017 diffenbaugh 2020 iliopoulou and koutsoyiannis 2020 and assess the stability of results to choices of calibration and validation periods renard et al 2013 kochanek et al 2014 guo et al 2020 as renard et al 2013 state both internal consistency and out of sample evaluations are essential for any comprehensive evaluation of flood frequency analysis models credit authorship contribution statement jory s hecht conceptualization methodology software formal analysis investigation data curation writing original draft visualization nancy a barth conceptualization methodology software formal analysis investigation writing review editing karen r ryberg conceptualization writing review editing supervision project administration angela e gregory investigation software visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the federal highway administration fhwa interagency agreement iaa dtfh6116x30020 flood frequency estimation for hydraulic design it also benefitted from preliminary discussions with the fhwa brian beucler joseph krolak kornel kerenyi rob kalafenos and rebecca lupes reviews from aldo vecchia jared smith and anonymous referees improved the paper as did earlier discussions with stacey archfield john england jr richard vogel and thomas over natalya rapstine from the u s geological survey s advanced computing resources group guided the implementation of the monte carlo experiments on the usgs yeti high performance computer https www usgs gov advanced research computing usgs yeti supercomputer and lopaka lee assisted with verification on the usgs tallgrass high performance computer four u s geological survey employees contributed to the data release associated with this manuscript hecht et al 2022 which includes an archive of code used to run the analyses conducted in this study sarah fiala and amy russell central midwest water science center assisted with the documentation of input and output data from the monte carlo experiments which tara williams sether dakota water science center reviewed amanda whaling lower mississippi gulf water science center reviewed the model archive and verified the reproducibility of the results and figures in the manuscript any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government data availability the u s geological survey data release hecht et al 2022 associated with this publication contains both the simulated data and r statistical software code used in this study the simulated data were created based on moments and trends from 1900 annual instanteanous peak flow series selected from 2683 observed series with lengths ranging from 50 to 100 years 1916 2015 1966 2015 identified during a prior phase of the flood frequency estimation for hydraulic design project see dudley et al 2019 in turn these 2683 peak flow series were obtained from the national water information system nwis at https nwis waterdata usgs gov usa nwis peak appendix a estimating trends in the mean and standard deviation with iwls glm building off hecht and vogel 2020 we implemented iwls glm using the following iterative four step procedure to produce convergent trend estimates step 1 we estimated the conditional mean μ y ω using weighted least squares wls a 1 μ y ω μ y β μ 1 ω i μ ω ε ω for just the first iteration we assumed equal weights equivalent to ols regression step 2 we squared the residuals of a 1 to estimate the conditional variance and scaled them using the same n n 2 degrees of freedom correction factor applied in 17 a 2 σ y ω 2 σ ε ω 2 n n 2 ε ω 2 step 3 our second stage model relating gamma distributed squared residuals ε ω 2 to ω is a 3 σ y ω 2 σ ε ω 2 ε ω 2 exp β σ 2 1 ω i μ ω υ ω to estimate σ y ω 2 we first estimated β σ 2 1 the slope of this centered variance trend model by fitting a second stage gamma glm with a log link function using the glm2 r package marschner and donoghue 2018 a 4 σ y ω 2 σ ε ω 2 n n 2 ε ω 2 exp β σ 2 1 ω i μ ω step 4 we used reciprocals of fitted values of step 3 as weights when fitting the conditional mean model in 17 in the next iteration repeating these steps until convergence the trend in the variance β σ 2 is then converted to a s d trend using 18 appendix b estimating lp3 distribution trends in the mean and standard deviation with gamlss the shifted gamma distribution approach we implemented our shifted gamma distribution method for estimating trends in the mean and s d of ams arising from an lp3 distribution in response to a uniformly distributed time index ω using the gamlss r package stasinopoulos et al 2020 as follows step 1 we computed the lower bound upper bound parameter τ y for positively negatively skewed distributions using mom as shown in 14c we used the known moments of the true distribution specified in the monte carlo experiment to compute τ y so that errors in moment estimation did not confound our assessment of the trend modeling ability of the nsffa methods step 2 procedures for adjusting a log transformed ams y using τ y also depended on its skewness if y was symmetric then we applied gamlss assuming a normal distribution an extreme case of the gamma distribution as there is no finite bound τ y in this special case in contrast when y was skewed we transformed lp3 distributions with either finite positive lower or upper bounds to produce a positively skewed gamma distributed variable y adj with a 0 support if y was positively skewed this transformation amounted to a simple downward translation of the distribution s location by subtracting τ y a lower bound parameter in this case from all values b 1a in contrast if y was negatively skewed then we had to flip the distribution into a positively skewed one by subtracting all observations from τ y which in this case is an upper bound parameter b 1b b 1a y adj y τ y γ y 0 τ y y adj m i n b 1b y adj τ y y γ y 0 τ y y adj m a x these equations could only be applied if all y adj values fell within estimated distribution bounds a known ffa challenge when using the lp3 distribution griffis and stedinger 2007a along with other bounded distributions such as the gev zaghloul et al 2020 otherwise estimates were recorded as na we also examined the combinations of trends and moments under which these bounds were most problematic step 3 we estimated changes in the mean and s d of log transformed ams using the gamma distribution as parameterized in gamlss b 2 f y adj φ ϕ y adj 1 ϕ 1 exp y adj ϕ 2 φ ϕ 2 φ 1 ϕ 2 γ 1 ϕ 2 where the parameters φ and ϕ are related to the mean and s d of y adj as follows b 3a μ y adj φ y adj b 3b σ y adj φ y adj ϕ y adj step 4 then we estimated covariate conditional values of φ and ϕ with gamlss b 4a φ y adj ω exp β α 0 β α 1 ω i b 4b ϕ y adj ω exp β θ 0 β θ 1 ω i the subscripts 0 and 1 refer to intercept and slope coefficients of the regression models step 5 next using b 1 b 4 we estimated conditional values of the mean and s d for γ y 0 b 5a μ y ω φ y adj ω τ y b 5b σ y ω φ y adj ω ϕ y adj ω and for γ y 0 b 6a μ y ω τ y φ y adj ω b 6b σ y ω φ y adj ω ϕ y adj ω step 6 we computed the trend adjusted skewness using 19 step 7 finally we used the analytical equations in 14 from the lmomco r package asquith 2020 to estimate lp3 distribution parameters as a function of estimated moments appendix c supplementary data supplementary data to this article can be found online at https doi org 10 1016 j hydroa 2021 100115 appendix c supplementary data the following are the supplementary data to this article supplementary data 1 
8544,while nonstationary flood frequency analysis nsffa methods have proliferated few studies have rigorously compared them for modeling changes in both the central tendency and variability of annual peak flow series also known as the annual maximum series ams in hydrologically diverse areas through monte carlo experiments we appraise five methods for updating estimates of 10 and 100 year floods at gauged sites using synthetic records based on sample moments and change trajectories of observed ams in the conterminous united states conus we compare two methods that consider changes in both central tendency and variability a gamma generalized linear model estimated with weighted least squares and the generalized additive model for location scale shape gamlss with a distribution free approach quantile regression and baseline cases assuming stationarity or only changes in central tendency trend space plots identify realistic ams changes for which modeling trends in both central tendency and variability were warranted based on fractional root mean squared errors frmse they also reveal statistical properties of ams under which nsffa models perform especially well or poorly for instance quantile regression performed especially well poorly under strong negative positive skewness although the nonstationary lp3 distribution accommodates most ams with trends well the sensitivity of nsffa model performance to different sample moments and trends suggests the need for more flexibility in prescribing design flood adjustments in the conus a follow up comparison of regional nsffa models pooling at site ams would further illuminate nsffa guidance especially for ams with properties less conducive to nsffa modeling such as positive skewness and increasing variability abbreviations ams annual maximum series conus conterminous united states nsffa nonstationary flood frequency analysis 1 introduction worldwide floods annually cause an estimated 24 billion in damage and the loss of thousands of lives kundzewicz et al 2014 moreover winsemius et al 2016 have projected a 20 fold increase in global flood risk by 2100 for many decades hydrologists have recommended that engineers and planners consider observed and anticipated changes in flood frequency when estimating design flood events bureau of public roads 1956 federal highway administration 2016 mounting evidence demonstrating the impacts of changes in climate land use and water resources management on floods has prompted myriad efforts to adjust design floods for these changing environmental conditions milly et al 2008 yan et al 2017 yet despite the proliferation of this research including numerous reviews khaliq et al 2006 hall et al 2014 madsen et al 2014 bayazit 2015 villarini et al 2018 salas et al 2018 coelho et al 2019 françois et al 2019 slater et al 2020 wasko et al 2021 relatively few studies have compared different design flood adjustment methods at multiple sites strupczewski et al 2001b delgado et al 2010 kochanek et al 2014 šraj et al 2016 debele et al 2017b schlef et al 2021 far fewer have compared them across continental scale regions with diverse hydrologic regimes moreover while national agencies are increasingly recommending adjustment methods including general safety factors and climate model simulations see wasko et al 2021 and references cited therein few best practices have been established through comparative studies indeed the recently updated federal guidelines for performing flood frequency analysis ffa in the united states bulletin 17c plainly state that such adjustments require more research england et al 2019 p 23 on the other hand numerous studies have criticized the mere premise of nonstationary flood frequency analysis nsffa especially when causes of observed changes cannot be attributed to changes in physical phenomena easily or when shorter term fluctuations in these physical phenomena are mistakenly treated as deterministic signals of long term change e g cohn and lins 2005 villarini et al 2009 montanari and koutsoyiannis 2014 serinaldi and kilsby 2015 indeed attributing trends to physical phenomena is often challenging merz et al 2012 especially given the prospect of omitted variable bias and the frequent paucity of environmental data for untangling competing hypotheses regarding drivers of trends yet in practice analysts may have enough confidence in the cause s of an at site trend to conduct a nonstationary analysis requiring more parameters which can increase the uncertainty of estimates this brings us to one pivotal nsffa modeling decision for what trend magnitudes is the reduced bias of a nonstationary model worth the increased uncertainty that comes with additional model parameters monte carlo simulation experiments which have a long tradition in ffa e g wallis et al 1974 markiewicz et al 2010 renard et al 2013 provide a tool for identifying trend magnitude thresholds above which nonstationary models become worthwhile based on root mean squared errors or other criteria for flood series with different stationary moments and change trajectories delgado et al 2010 faulkner et al 2020 hecht and vogel 2020 konrad and restivo 2021 luke et al 2017 mallakpour and villarini 2016 sankarasubramanian and lall 2003 strupczewski et al 2001a yu et al 2018 recent and ongoing efforts to improve both stationary and nonstationary ffa motivated our choices of methods to include in the monte carlo experiment these efforts include the updated guidelines for performing stationary ffa in the united states in bulletin 17c england et al 2019 using the annual maximum series ams comprised of annual maximum instantaneous peak flows as well as research from earlier stages of the flood frequency estimation for hydraulic design project sponsored by the u s federal highways administration dickinson et al 2019 dudley et al 2019 hodgkins et al 2019 ryberg et al 2020 blum et al 2020 york et al 2020 aimed to address the open questions regarding nsffa methods that bulletin 17c posed researchers in many other countries have also been tackling these challenges for both block maxima and peaks over threshold pot flood series strupczewski et al 2001b madsen et al 2014 durocher et al 2018 faulkner et al 2020 bartiko et al 2019 wasko et al 2021 while more comparisons of nsffa models applied to both these types of flood series are needed we focus on modeling changes to the annual maximum series due to its widespread use in the us and other countries along with the much greater accessibility of ams in addition practical flood frequency analysis often involves censored data such as imprecise historical flood observations in conjunction with systematically observed flood peaks cohn et al 1997 xiong et al 2020 bulletin 17c utilizes the expected moments algorithm ema cohn et al 1997 to incorporate censored data in stationary flood frequency analysis ffa this motivated us to consider nsffa methods based on the method of moments mom additional factors motivating our focus on moment based methods included the poor performance of maximum likelihood in monte carlo studies evaluating robustness to incorrect distribution type assumptions markiewicz et al 2010 strupczewski et al 2016 along with the need to de trend ams prior to applying l moments gado and nguyen 2016 another popular parameter estimation method for ffa however before evaluating how to incorporate censored data into a mom based nsffa framework it is important to identify nsffa modeling approaches that are conducive to moments based design flood estimates while we recognize the importance of nsffa approaches that can easily accommodate both gradual and abrupt changes bates et al 2012 we have focused our initial appraisal on methods that estimate changes following two more commonly modeled gradual change trajectories i linear changes in the conditional mean of log transformed ams and ii exponential changes in their conditional standard deviation and variance we designed monte carlo experiments using recent regression based conditional moments approaches for nsffa that consider the coupled nature of trends in the mean standard deviation and skewness serago and vogel 2018 hecht and vogel 2020 however neither of these studies explored the effect of skewed log transformed ams on nsffa estimates using monte carlo simulation experiments despite known limitations with modeling trends in variability with symmetric two parameter lognormal ln2 distributions when changes in variability are asymmetric hecht and vogel 2020 this is especially crucial in urbanizing basins where expanding impervious cover and other hydrologic changes often magnify smaller peak flows more than larger ones this motivates the use of three parameter distributions for which the skewness can be adjusted for trends in the mean and variance other recent monte carlo experiments have partially addressed these nsffa method appraisal gaps through simulations using parameter values based on a single site or a small number of sites in relatively homogeneous hydrologic regions these studies compare i the sensitivity of a nonlinear least absolute deviation model of exponential variance trends to data originating from log pearson type iii lp3 distributions with different skewness coefficients yu et al 2018 ii maximum likelihood estimation a two stage regression procedure based on weighted least squares assuming linear trends in the mean and variance and gamlss for several distributions debele et al 2017b and iii gamlss with cubic b splines and quantile regression qu et al 2020 in addition these studies did not adjust skewness coefficients to reflect trends in the mean and variance this study contributes a monte carlo experiment parameterized using statistical properties of observed ams in hydrologically diverse basins throughout the conterminous united states conus to identify the circumstances under which different nsffa models including two variability trend models iwls glm and gamlss are most viable following the suggestion of debele et al 2017 we also compare these moment based approaches to quantile regression an increasingly applied hydroclimatic frequency analysis method over et al 2016 qu et al 2020 sankarasubramanian and lall 2003 tramblay et al 2019 villarini and slater 2018 this enables us to identify circumstances under which methods targeting specific quantiles of interest could outperform ones assuming symmetric changes in variability as nonstationary probability plot correlation coefficient ppcc tests demonstrate the adequacy of a nonstationary lp3 distribution at over 98 of 50 year ams sampled at sites in the conterminous us see section 3 for information on records and section c5 for more information on the goodness of fit analysis we primarily evaluate the performance of these methods when applied to simulated data arising from this distribution however to evaluate the potential consequences of distribution type misspecification our monte carlo experiments also include a robustness study examining implications of incorrect distributional assumptions section 2 introduces the monte carlo experiments that assess the internal consistency of methods for estimating changes in ams distributions section 3 describes the estimation of experiment parameters from observed annual peak flow series in the conus section 4 presents experiment results section 5 appraises the nsffa methods we investigated with an eye for opportunities for future improvements section 6 concludes 2 monte carlo simulation experiments 2 1 experiment design we used monte carlo experiments to evaluate the accuracy of estimates of 10 and 100 year floods annual maximum instantaneous peak flows with a 10 and a 1 percent chance of exceedance in any given year with hypothetical 30 and 100 year records in basins with different stylized annual flood distributions and change trajectories fig 1 these are common design flood quantiles in transportation infrastructure design and floodplain management aashto 2014 this assessment required the generation of true values computed with a quantile function using known population moments and change trajectories which were selected based on observations at 1898 conus stations see section 3 we assumed that quantile functions produced unbiased estimates whenever distribution parameters were estimated correctly consequently we did not address general sampling issues that can cause common quantile estimators to produce downward biased quantile estimates stedinger 1983 ball et al 2019 while many metrics are useful for evaluating design flood estimates with candidate nsffa models a choice which depends on the problem at hand we evaluated our experiments primarily using relative percent error distributions percent bias pbias and fractional a k a normalized or relative root mean squared errors frmse first relative percent errors for each simulated quantile are computed as follows 1 re s t t 100 where s indicates a simulated quantile estimate and t indicates the true quantile computed with known parameters meanwhile the percent bias states the overall tendency for estimates from a set of simulations to be lower or higher than true quantiles 2 pbias i 1 n s i t t 100 where s i indicates the ith quantile estimate from a set of n simulations next we computed the frmse by normalizing the rmse using the true value t instead of the standard deviation s d or range of t because we only have a single true value for each quantile we estimate 3 frmse 1 n i 1 n s i t 2 t 100 implementing the experiments involved the selection of probability distribution functions along with plausible combinations of moments and trends from observed ams from which to simulate ams fig 1 we then compared 10 and 100 year design flood estimates from these simulated ams with ones computed using quantile functions with the known conditonal moments 5000 random uniform variates between 0 and 1 were generated to obtain annual non exceedance probabilities with which to compute simulated annual peak flow time series using known stationary moments and trends for each simulated ams the same set of random uniform variates was applied to all combinations of sample moments trends and distribution types the remainder of section 2 describes the computation of true and simulated quantiles while section c3 contains further details regarding experiment implementation using r statistical software version 3 6 3 r core team 2020 on the united states geological survey s yeti high performance computer hpc falgout et al 2015 and verified on the united states geological survey s tallgrass hpc using r version 4 1 3 falgout et al 2019 2 2 generating the truth with known conditional moments one can analytically derive parameters for theoretical distributions as functions of conditional moments we created true design flood values by using moments of the log transformed ams conditioned on covariate values 4 y ω f μ y ω σ y ω γ y ω where y ω is a time series of the log transformed ams y μ y ω σ y ω and γ y ω are the mean standard deviation and skewness coefficient respectively of y conditioned on a design matrix of hypothesized covariates ω to provide a baseline for comparing nsffa models we conducted simulation experiments for cases with a single covariate ω which can represent a discrete time index where ω 1 2 n or a physical covariate changing at a constant rate over time this linearly changing physical covariate may include a deterministic covariate such as impervious cover or a stochastic one such as a precipitation metric whose annual expected values increase linearly over time our goal is to compare design flood estimates conditioned on the last year of a synthetic series representing current conditions additional adjustments to the procedures detailed below are needed if any covariates change nonuniformly over time or if peak flow observations are missing while the nsffa models we evaluated can often accommodate these more complex cases some features of them such as the trend adjusted skewness coefficient require extensions meriting separate studies these models can also be extended to include multiple covariates including ones where different covariates drive trends in different moments e g xiong et al 2020 provided that correlations among covariates are considered to determine true values of conditional moments we needed to specify both sample moments computed assuming stationarity and trends in the mean and s d we consulted observed values of these sample moments and trends from log transformed ams at unregulated conus sites identified in a prior phase of our project dudley et al 2019 distributions and spatial patterns of these values are described in section 3 we henceforth use the terms log transformed and log space to describe natural logarithm transformations importantly a change in the log space mean corresponds to a change in the real space median and a change in the log space s d corresponds to a change in the square root of the real space coefficient of variation cv hecht and vogel 2020 first we assume that the value of the mean log transformed peak flow conditioned on a covariate ω exhibits a linear relationship with ω as follows 5 μ y ω μ y β μ 1 ω μ ω where μ y ω is the mean of natural logarithms of an ams conditional upon covariate ω μ y is the mean of log transformed ams conditional upon the covariate mean μ ω and β μ 1 is the rate at which μ y ω is changing with respect to ω we also recognize that trends in the mean impact the conditional variance when a record with a trend in the mean exhibits a constant variance the conditional variance σ y ω 2 equals the error variance σ ε 2 σ y ω 2 can be deduced by subtracting the explained variance β μ 1 2 σ ω 2 from the total variance of the log transformed peak flows σ y 2 hecht 2017 serago and vogel 2018 6 σ y ω 2 σ ε 2 σ y 2 β μ 1 2 σ ω 2 yet in some cases the variance of log transformed ams changes over time numerous hydroclimatic studies have characterized these changes with exponential functions partly since they retain positive variance values villarini et al 2012 panagoulia et al 2014 yu et al 2018 šraj and bezak 2020 xiong et al 2020 while alternative variance functions have also been applied in nsffa hecht and vogel 2020 strupczewski and kaczmarek 2001 yu et al 2018 we focused on appraising the following exponential variance model 7a σ y ω 2 σ ε ω 2 σ y 2 β μ 1 2 σ ω 2 exp β σ 2 1 ω μ ω where β σ 2 1 represents the regression coefficient associated with the exponential variance trend in response to a linear change in ω and σ ε ω 2 indicates the non constant error variance see section 2 4 for two methods for estimating these values we can also express 7a in terms of the s d trend magnitude β σ 1 7b σ y ω 2 σ ε ω 2 σ y 2 β μ 1 2 σ ω 2 exp 2 β σ 1 ω μ ω next we considered the effects that trends in the mean and s d had on skewness coefficients we obtained a single trend adjusted coefficient for an annual peak flow series by deriving the expectation of the skewness conditional upon the covariate ω 8 e γ y ω e e y μ y ω i σ y ω i 3 ω i where the expected value of the conditional skewness e γ y ω is the expectation of the log transformed ams y computed using their respective conditional mean and s d μ y ω and σ y ω expanding 8 and substituting in previously defined relationships yields the following expression 9 e γ y ω 1 e σ y ω i 3 ω i e σ y 3 γ y ω i e 3 σ y 2 β μ 1 ω i μ ω ω i e β μ 1 3 ω i μ ω 3 ω i where i is an index running from 1 to n see section 2 4 1 for estimation methods section c2 contains a complete derivation of this population equation and the sample estimators used in this study we also used magnification factors m vogel et al 2011 to express percent changes in annual flood quantiles attributable to changes in the mean and s d of annual floods β μ 1 and β σ 1 for a given covariate change δ ω for log linear trends in the mean the magnification factor m μ δ ω was computed as follows 10 m μ δ ω e x p μ y ω μ ω δ ω μ y ω μ ω exp β μ 1 δ ω for instance with a time index covariate setting δ ω 10 in 10 computes the percent change in the mean annual flood per decade percent changes can also be computed i e δ ω m μ δ ω 1 100 next we extended the work of vogel et al 2011 by computing magnification factors m σ δ ω for s d trends β σ 1 11 m σ δ ω e x p σ y ω μ ω δ ω σ y ω μ ω when computing m σ δ ω we centered the covariate ω so μ ω 0 see section c1 this set the s d at the midpoint of ω equal to the sample s d of the ams we then expanded 11 using 7 leading to 12 m σ δ ω e x p e x p β σ 1 δ ω 1 σ y 2 β μ 1 2 σ ω 2 m σ δ ω depends on the rates of change in the s d β σ for a given change in the covariate δ ω along with the conditional s d adjusted for the trend in the mean from 7 i e σ y 2 β μ 1 2 σ ω 2 see section c1 for derivations in the monte carlo experiments the values of the percent changes in the s d displayed on axes of the trend space plots e g fig 6 only consider the s d trend from 7 i e the exponent in 12 becomes σy ω so that the known s d trend is not confounded with the known trend in the mean however when computing flood magnification due to the s d trend one must consider the joint effects of trends in the mean and s d as shown in 12 finally we computed magnification factors for quantiles of interest as a function of both m μ δ ω and m σ δ ω in 11 and 12 respectively 13 m q p δ ω q p μ ω δ ω q p μ ω m μ δ ω m σ δ ω k 1 p where q p μ ω indicates the quantile computed with the covariate mean μ ω while q p μ ω δ ω indicates the quantile following a change in the covariate equal to δ ω and k γ y ω 1 p is a frequency factor commonly used with the lp3 distribution that is a function of the exceedance probability p and skewness kirby 1972 interagency advisory committee on water data 1982 frequency factors for other distributions can also be used e g z scores for normal distributions 2 3 generating annual maximum series from the log pearson type iii distribution we simulated ams originating from the three parameter lp3 probability distribution which the united states bulletins 17b interagency advisory committee on water data 1982 and 17c england et al 2019 have recommended for computing design flood estimates throughout the united states numerous countries and other political jurisdictions have also recommended the distribution which is simply the logarithmic transformation of a series arising from a pearson type iii p3 distribution e g cunnane 1989 rahman et al 2013 zhang et al 2020 in addition the p3 distribution is widely used with untransformed ams in china e g xiong et al 2014 ke et al 2018 while the strong goodness of fit of the lp3 distribution in the united states has been established under the assumption of stationarity beard 1974 vogel and wilson 1996 hu et al 2020 its adequacy as a conditional distribution for nonstationary conus sites has not been vetted previously we conducted a goodness of fit assessment that corroborated its adequacy for estimating conditional quantiles in diverse hydrologic regions of the conus this distributional hypothesis could not be rejected at the 95 level p 0 05 at 98 of 1900 sites with 50 year records using the nonstationary probability plot correlation coefficient test serago and vogel 2018 overall sites with an inadequate nonstationary lp3 fit p 0 05 only registered trends slightly more often than sites with adequate nonstationary lp3 fits 34 vs 31 for trends in the mean and 34 vs 29 for trends in the s d see section c5 for details including spatial patterns the lp3 distribution is a shifted two parameter gamma distribution e g stasinopoulos et al 2020 with a third non negative bound parameter τ instead of a fixed lower bound of zero e g griffis and stedinger 2007 when the skewness γ y is positive negative τ equals the lower upper bound of the distribution england et al 2019 we parameterized the lp3 distribution conditioned on a covariate ω using method of moments mom equations adapted from bulletin 17c england et al 2019 14a α y ω 4 γ y ω 2 14b θ y ω s i g n γ y ω σ y ω 2 α y ω 1 2 14c τ y ω μ y ω α y ω θ y ω 14d f y α y ω θ y ω τ y ω 1 θ y ω γ α y ω y τ y ω θ y α y ω 1 exp y τ y ω θ y ω where α is a positive shape parameter θ is a scale parameter often denoted as β instead of θ whose sign reflects the skewness and τ is a non negative location parameter equation 14d is the conditional probability distribution function for the nonstationary lp3 distribution in which γ α y ω represents the gamma function of the conditional shape parameter α y ω we used the lmomco r package asquith 2020 to estimate the three parameters as functions of conditional moments of log transformed ams its quape3 function computes quantiles based on known analytical relationships between lp3 distribution parameters and the first three moments this distribution does not have a closed form quantile function although approximations using frequency factors k γ y ω 1 p are instructive for illustrating the effects of skewness and exceedance probabilities on lp3 quantile estimates 15 q p ω exp μ y ω k γ y ω 1 p σ y ω while the lp3 distribution s shape parameter α incorporates skewness into the distribution the range of skewness the distribution can accommodate is bounded griffis and stedinger 2007a showed that when γ y 2 γ y 2 the distribution s density reaches infinity at its lower upper bound τ y which unrealistically implies that flows below above the mode of the distribution are impossible we considered these bounds in our interpretation of simulation results but did not apply any lower bounds on sample skewness estimates at γ y 1 414 buckett and oliver 1977 griffis and stedinger 2007b england et al 2019 because we wanted to compare nsffa models without this imposed constraint 2 4 nonstationary adjustment methods this section introduces the four nsffa methods that we compared to a stationary baseline through the monte carlo experiments assuming i a linear relationship between a time index covariate and log transformed ams and ii an exponential relationship between the same time index covariate and the residual variance of the first model the latter from which s d trends are inferred table 1 we demonstrated these methods assuming ams arise from nonstationary lp3 distributions although these general modeling approaches can accommodate other theoretical probability distributions as well 2 4 1 definitions and notation first we establish some key definitions and notation for describing trends estimated from samples of limited lengths for the first four models in table 1 all of which were based on covariate conditional sample moments we modified 15 to include estimated sample moments μ y σ y and γ y along with coefficients representing estimated trends in the mean and s d β μ 1 and β σ 1 these trend coefficients represent the rate at which moments change in response to linear changes in a covariate in this illustrative case each year we also adjusted the sample skewness for trends in the mean and s d see section c2 for more details with these estimated moments and trends we estimated floods with a given exceedance probability p for a given covariate value ω i as follows 16 q p i e x p μ y β μ 1 ω i μ ω k γ y ω 1 p σ y ω exp β σ 1 ω i μ ω table 2 summarizes formulas used to adjust the mean and s d for trends in each of our moment based models with the e1071 r package meyer et al 2019 we estimated the sample skewness with the g estimator which performs better in non normal samples joanes and gill 1998 and is used in the u s geological survey s peakfq software version 7 3 veilleux et al 2019a we also used the 1 6 n bias correction factor that tasker and stedinger 1986 recommended for the lp3 distribution below we provide more details on trend coefficients estimated from each nsffa model 2 4 2 estimating trends with constant variance ols mean first we examined ordinary least squares ols regression a well established nsffa method for modeling trends with a constant variance in log space while numerous papers have eschewed ols regression for its limiting assumptions such as linearity others have demonstrated its effectiveness for i addressing nonlinear flood response functions through various linearizing transformations see mosteller and tukey 1977 ii producing decision relevant information through relatively simple analytical expressions hecht 2017 iii corrections for short and long term persistence matalas and sankarasubramanian 2003 and iv estimating conditional moments for common ffa distributions common serago and vogel 2018 we chose ols over more outlier robust nonparametric alternatives helsel et al 2020 because it can model coupled trends in the mean and s d more easily and handle incomplete ams better we employed the following ols model 17a ln q i y i μ y β μ 1 ω i μ ω ε i 17b μ y ω μ y β μ 1 ω i μ ω 17c σ y ω n n 2 σ ε 2 n n 2 σ y 2 β μ 1 2 σ ω 2 first we established the ols model for the log transformed ams as a linear function of the covariate ω i where ε i are the model residuals next using 17b we estimated the mean conditional upon ω using the ols estimate β μ 1 which is a best linear unbiased estimator if the residual variance σ ε 2 is constant over ω helsel et al 2020 this estimator is still unbiased albeit not a minimum variance estimator even when the variance is not constant then using 17c we estimated the constant s d adjusted for the trend in the mean σ y ω n n 2 is a degrees of freedom adjustment factor to correct biased estimates of the residual variance σ ε 2 montgomery et al 2001 we then used these conditional moments to estimate design floods for specific exceedance probabilities note that olsrequires normally distributed residuals for hypothesis testing or computing confidence and prediction intervals but not for trend estimation helsel et al 2020 2 4 3 estimating trends with nonconstant variance i next we considered the iteratively weighted least squares gamma generalized linear model iwls glm an iterative two stage approach that accommodates non normal response variables well approximated by other exponential family distributions to investigate changes in variability from heteroscedastic residuals when residuals from a first stage conditional mean model follow a normal distribution its squared normal residuals useful for modeling variance trends follow a highly non normal chi square χ 2 distribution with one degree of freedom in turn this χ 2 distribution is a special case of the gamma distribution another exponential family member recent monte carlo experiments employing data generated from ln2 distributions and realistic variance trends have shown that iwls glm registers lower frmses than ols mean models hecht and vogel 2020 when their respective variance trend trajectories have been correctly specified aitkin 1987 demonstrated that iwls yielded asymptotic maximum likelihood estimates of the standard errors of an exponential variance model using this iterative approach previously implemented in hecht and vogel 2020 we estimated the conditional mean using a weighted least squares regression with variances estimated with a second stage gamma generalized linear model glm see appendix a next since iwls glm uses a natural log link function that directly exponentiates the variance change trajectory without requiring a transformation of the dependent variable s d trend estimates β σ 1 are easy to deduce from the estimated variance trend β σ 2 1 18a σ y ω exp 0 5 β σ 2 1 ω i μ ω then we can define β σ as follows 18b β σ 1 0 5 β σ 2 1 we can then insert β σ 1 into the magnification factors to quantify the s d trend and its effect on flood quantile estimates in percent terms meanwhile a trend adjusted skewness coefficient can be computed from moment and trend estimates using an equation similar to 9 19 e γ y ω 1 6 n n n 1 n 2 1 n i 1 n y i μ y ω 3 3 β μ 1 σ y 2 β μ 1 2 σ ω 2 1 n 1 i 1 n exp 2 β σ 1 ω i μ ω ω i μ ω σ y 2 β μ 1 2 σ ω 2 3 2 n n 1 n n 2 i 1 n exp 3 β σ 1 ω i μ ω see section c2 for a complete derivation of 19 2 4 4 estimating trends with nonconstant variance ii the generalized additive model for location scale and shape gamlss rigby and stasinopoulos 2005 flexibly simulates changes in the parameters of ams probability distributions villarini et al 2009 unlike the other regression based models introduced above gamlss can accommodate highly nonlinear parametric and nonparametric functions and response variables from highly skewed and kurtotic distributions of both continuous and discrete variables rigby and stasinopoulos 2005 yet its information theoretic model selection criteria with penalty terms for each parameter e g the akaike information criterion akaike 1974 encourages parsimonious models however the gamlss r package stasinopoulos et al 2020 does not enable users to specify the p3 or lp3 distribution while one can manually enter this distribution into gamlss xiong et al 2014 debele et al 2017a we applied an alternative approach that recognizes that the lp3 and p3 distribution is essentially a shifted two parameter gamma distribution a distribution which gamlss can readily model see appendix b one risk with this approach is that design flood adjustments cannot be performed on records with any values below above the lower bound upper bound parameter τy see 14c this is a common ffa problem when extreme skewness causes three parameter distributions to become bounded including with lp3 griffis and stedinger 2007a and gev zaghloul et al 2020 distributions we computed this error rate in simulations with different combinations of moments and trends see section 4 and section c6 1 for more details and results 2 4 5 estimating trends in quantiles quantile regression qr estimates ams quantiles as a function of hypothesized covariates without making any distribution type assumptions this method first introduced by koenker and bassett 1978 and previously implemented in numerous ffa studies see section 1 estimates quantiles for a non exceedance probability p as follows 20a q p i exp β p 0 β p 1 ω i υ p i 20b q p i exp β p 0 β p 1 ω i while qr enables one to investigate nonlinear change trajectories in estimated quantiles with a given exceedance probability q p we assumed for simplicity that estimated quantiles changed linearly with ω where β p 0 and β p 1 are the estimated intercept and slope terms respectively qr also assumes quantile specific asymmetric laplacian error distributions ν p i sankarasubramanian and lall 2003 which we assumed were homoscedastic for simplicity we used the rq function with the frisch newton interior point method from the quantreg r package koenker et al 2020 to estimate 10 year floods for records of 30 50 and 100 years we limited our analysis of qr for the 100 year event to 100 year records because it only estimated quantiles up to the exceedance probability of the largest observation a known limitation in qr applications to ffa qu et al 2020 we also assessed the frequency of the crossing quantile problem in which a quantile of a higher exceedance probability is greater than a lower exceedance probability el adlouni et al 2018 over et al 2016 in our case when the 10 year flood exceeded the 100 year flood we did not discard results with this violation given our focus on single quantile design flood estimates but we compared the frequency of this violation for different combinations of moments and trends to identify circumstances under which more sophisticated qr models capable of preventing this such as restricted quantile regression geraci and farcomeni 2020 2 5 robustness analysis with gev distribution finally since it is difficult to ascertain the true distribution of an ams we must evaluate the performance of nsffa estimation methods when the distribution type is mis specified markiewicz et al 2010 debele et al 2017b for this reason we also conducted a robustness study also with a uniformly distributed time index as the lone covariate to examine possible consequences of assuming the lp3 distribution when the ams arises from the generalized extreme value gev distribution and vice versa this robustness study also enabled us to assess the extent to which quantile regression becomes preferable when theoretical probability distributions are mis specified although the gev distribution is predicated upon the routinely violated assumption of independently and identically distributed i i d daily flows it is widely used for ffa in many places especially europe salinas et al 2014 and it often fits observed ams well e g cunnane 1989 xiong et al 2020 zhang et al 2020 contrary to many contemporary studies we estimated covariate conditional gev parameters using log transformed ams instead of untransformed ones to be consistent with our lp3 based estimation procedures first we applied the uniroot function in r statistical software r core team 2020 to estimate its shape parameter κ with this value we could then solve simultaneous analytical equations for the location and scale parameters ξ and α respectively see stedinger et al 1993 for gamlss we used the gumbel and reverse gumbel distribution in the gamlss r package stasinopoulos et al 2020 which does not have a built in gev distribution function this enabled us to test gamlss for ams generated from gev distributions with γ y 1 1396 1 14 the skewness coefficients of the gumbel γ y 1 1396 1 14 and reverse gumbel γ y 1 1396 1 14 distributions respectively meanwhile for γ y 0 we used gamlss to model trends in the mean and s d of log transformed ams assuming a normal distribution and then estimated gev parameters with mom future work could also examine the two parameter weibull distribution a member of the gev family given its recent success in regions with changing floods slater et al 2021 3 parameter estimation informed by observed floods to parameterize the monte carlo experiment we examined moments and trends of observed ams at sites subject to both minimal and substantial anthropogenic perturbations throughout the conus recently dudley et al 2019 identified 2683 stations in the united states with peak flow records covering a 50 year period 1966 2015 and 257 records encompassing a 100 year period 1916 2015 however since we focus on gradual trends we removed stations used in dudley et al 2019 with national water information system nwis peak flow qualification codes of 6 indicating known regulations and diversions we also omitted stations with any water years oct 1 sep 30 without any flow where one would need to apply a compound approach considering the probability of any flow during a given water year as well as a continuous probability distribution describing wet year peak flows e g kuczera and franks 2019 we also removed individual peak flow observations with qualification codes of 3 dam failure 4 below minimum recordable discharge 7 estimated historical peak from period outside of systematic gaging record and 8 above indicated value next we applied the 80 record coverage per decade criterion from dudley et al 2019 our final sample contained 1900 50 year records and 146 100 year records on perennial streams see https nwis waterdata usgs gov usa nwis peak help codes help for a list of qualification special condition codes and ryberg et al 2017 for additional discussion about them fig 2 illustrates the combinations of all moments and trends we estimated from the 50 year log transformed ams black dots regressed on a time index where ω 1 2 50 the red points show the combinations of sample moments and decadal percent changes in the mean δ μ y and s d δ σ y considered in the monte carlo experiments here these trends were modeled with iwls glm since it performed more consistently than gamlss in the monte carlo experiment although not better for all moment and trend combinations investigated fig 3 maps these decadal changes for 50 year records while section c4 contains maps of them for the 100 year records our overarching goal with the observed ams was to identify a broad range of apparent gradual trends in the mean and s d for our monte carlo experiment and leave the attribution of these trends to future work this makes our analysis of observed ams different than many recent investigations aiming to disentangle long term trends from abrupt changes and long term persistence e g villarini et al 2009 thus we opted to parameterize the experiment with moments and trend magnitudes encountered in 50 year records since there were far fewer 100 year records in small urbanizing basins and in arid regions even though trends in 50 year records are prone to being overestimated due to inter decadal climatic cycles moreover the design life of some infrastructure can match the decadal to centennial timescale over which longer term fluctuations appear as shorter term trends observed changes in ams variability in urbanizing basins including ones without significant trends in precipitation hecht and vogel 2020 also motivated our consideration of 10 decadal s d trends despite numerous differences in periods of record and methods our analysis produced spatial patterns of change in the means of ams observed in other studies including increases in the north central and northeastern united states e g mallakpour and villarini 2015 dethier et al 2020 the concentration of decreasing trends in the western conus reflects an abnormally strong aridity gradient between the east wet and west dry in recent decades bishop et al 2021 groundwater depletion also drives some decreasing streamflow trends in agricultural regions of the great plains kustu et al 2010 which may explain the absence of such a cluster in studies encompassing only minimally altered sites archfield et al 2016 droughts at the start and end of the 50 year period exacerbate increasing peak flow trends in the northeast hayhoe et al 2007 and decreasing ones in parts of the southwest barth et al 2017 respectively the paucity of trends in variability in our 100 year records concords with the lack of variability trends that villarini et al 2009 observed at sites with records of 100 years or longer next we estimated sample skewness coefficients using the g estimator from the e1071 r package meyer et al 2019 we selected true skewness coefficients of 0 6 and 1 1396 for the monte carlo experiment for specific reasons first we selected 0 6 because conus studies to date have found regional skewness coefficients within this range see https acwi gov hydrology frequency b17c supplementary materials reports html however since bulletin 17c recommends a weighted skewness coefficient comprised of both at site and regional skewness values england et al 2019 we also examined skewness coefficients of 1 1396 values well within the range of conus at site skewness coefficients in fig 2 gev distributions with a skewness of 1 1396 are equivalent to the two parameter gumbel distribution for which functions in the gamlss r package stasinopoulos et al 2020 are readily available we also examined differences between product moments and moments estimated using the ema recommended under current u s guidance in bulletin 17c england et al 2019 the latter which makes additional adjustments for low outliers a k a potentially influential low floods pilfs and other censored flow data section c7 shows that using ema instead of conventional product moments with pilfs can produce substantially different moment estimates at sites with higher s d s and negative skewness coefficients many of which are in more arid regions 4 results 4 1 simulations with correct lp3 distribution assumption this section presents results from the monte carlo simulations in which the nonstationary lp3 quantile function in 15 was used to estimate design floods arising from lp3 distributions to emphasize the effects of different trend combinations and skewness coefficients many figures focus on design flood estimates from simulated ams in which μ y 5 and σ y 1 were used we also compared runs with different σ y values to highlight its important influence on simulation results see section c6 for detailed results for other combinations of μ y and σ y 4 1 1 screening out infeasible estimates before comparing model estimates we inspected simulated ams for na values signaling synthetic observations outside of distribution bounds non convergence and other estimation errors first we compared the error rate for 100 year flood estimates from 100 year records for which μ y 5 and σ y 1 in these runs gamlss generated by far the most na values 26 for 100 year flood estimates followed by iwls glm 2 the other three models did not generate any errors gamlss na values principally arose from synthetic observations outside of lp3 distribution bounds whereas iwls glm occasionally failed to converge for δ μ 25 when using the glm2 r package marschner and donoghue 2018 for gamlss runs na s were much more frequent when synthetic observations were generated from strongly skewed distributions 55 of runs when γ y 1 14 figure c6 1 shows that these na rates were very high for records with s d trends when γ y 1 14 above 90 for several trend combinations with s d trends of 25 and ranging widely from 5 to 80 for trend combinations with s d trends of 10 meanwhile simulated ams with trends in the mean without concurrent s d trends had considerably lower na rates ranging from 9 to 24 in contrast when γ y 0 gamlss only produced one single na observation when δ μ 25 δ σ 25 overall high low outliers were more likely to yield na s for negatively positively skewed ams among the gamlss runs additional sensitivity analyses demonstrated that strong skewness γ y 1 14 produced high error rates 37 with gamlss even when σ y 0 5 the most common value at conus stations see fig 2 moreover runs with either δ μ 25 or δ σ 25 were removed for σ y 0 5 due to the implausible correlations these trends implied we considered the limitations of our shifted gamma adaptation of gamlss for the lp3 distribution under strong skewness in our interpretations of gamlss estimates from skewed distributions see section c6 for na rates obtained with different moment trend combinations in addition we observed crossing quantiles in qr results with 100 year records overall when μ y 5 and σ y 1 the qr 10 year flood exceeded the qr 100 year flood in 5 5 of all runs overall this crossing quantile rate was higher 10 for decreasing s d trends and even more so when combined with positive skewness negative trends in the mean aggravated crossing quantile rates when s d trends decreased but alleviated them when they increased while this crossing quantiles analysis identified circumstances under which a constrained qr procedure might be necessary for estimating design floods with different recurrence intervals see sec 2 4 5 we did not remove runs with crossing quantiles to avoid biasing our assessments of qr s performance for individual design flood estimates section c6 details crossing quantile rates for different moment trend combinations finally only some cases with extreme decadal trends in the mean 25 yielded γ y ω 2 a threshold above which the lp3 distribution becomes implausible for ams stedinger and griffis 2007a fig 2 demonstrates that most observed ams exhibited trends within 10 even during the short 50 year period we considered 4 1 2 stationary series generated from symmetric distributions next we established a baseline for how well the nsffa models performed with simulated ams originating from 100 year long stationary lp3 distributions we selected true moments for these distributions based on sample moments encountered in observed 50 year records see fig 2 since past monte carlo studies have consistently shown that design event estimates are much more sensitive to differences in variability than central tendency e g beard 1974 markiewicz et al 2010 we focused this initial analysis on s d effects on 10 year and 100 year floods fig 4 the probability distributions in the second row from the top and second column from the left in fig 2 shows that the mode of s d values observed at 1900 stations is roughly 0 5 that the base of the falling limb of the main peak lies at roughly 1 0 and that 1 5 represents values in conus regions with the greatest interannual flood variability such as the southwest and the great plains see fig 3 to isolate the effects of the sample s d on model performance we kept the mean and skewness constant μ y 5 γ y 0 note lp3 distributions with γ y 0 are equivalent to two parameter lognormal ln2 ones first these simulations confirmed that i estimators with more parameters were less efficient i e had greater error variance under stationary conditions ii estimates of 10 year floods were more efficient than estimates of 100 year floods and iii estimates from records with lower s d s were more efficient all models except qr exhibited median relative errors near 0 suggesting a roughly equal likelihood of overestimating and underestimating design floods in contrast qr registered a high mean bias 38 when σ y 1 0 due to some gross overestimates as its median is downward biased 13 when σ y 1 0 in practice this means that the greatest risk in using a qr design flood estimate is severe overdesign even when under design is more likely than overdesign the upward bias increased most when σ y rose from 1 0 to 1 5 furthermore stations with high s d s are also more likely to have pilfs see section c7 which cause disparities between design flood estimates made with conventional product moments and ema therefore in practice one should examine the effects of low outliers potentially influential low floods on records with high values of σ y before selecting nsffa models 4 1 3 sensitivity to trends in the mean and standard deviation next we examined the impacts of 10 decadal trends in the mean and s d of the log transformed ams on the relative errors re of 100 year flood estimates generated from lp3 distributions with the same combination of sample moments μ y 5 σ y 1 γ y 0 analyzed in section 4 1 2 as expected fig 5 shows that stationarity was often a problematic assumption for estimating design floods when trends were present and that ols mean also did not perform well when there were s d trends this effect became greater as the s d increased see section c6 2 for results with σ y 0 5 1 5 stationary models performed better when there were opposing trends in the mean and s d than when only one moment had a trend or when they exhibited concordant trends fig 5 demonstrates that the stationary model overestimated underestimated the 100 year flood at sites with decreasing increasing trends in the mean even when the s d changed at the same percent rate in the opposite direction this happened because the absolute change in the mean μ y 5 resulting from a 10 change was much greater than the absolute change in the s d σ y 1 resulting from the same percent change equation 15 shows that s d trends can fully offset opposing trends in the mean when δ μ y ω k γ y ω 1 p δ σ y ω 0 or when δ μ y ω δ σ y ω k γ y ω 1 p while this threshold ratio varies with skewness and exceedance probabilities for a 100 year flood at a site with a zero skew lp3 distribution where k 1 p 2 326 this offset happens when δ μ y ω δ σ y ω 2 326 if the ratio is below k 1 p the s d trend has a greater effect whereas the mean has a greater effect if it exceeds k 1 p in fig 5 this ratio equals five i e δ μ y ω δ σ y ω 0 5 0 1 5 this suggests that stationary estimators which have fewer parameters might perform better at sites with opposing trends close to this ratio fig 5 shows that the three models explicitly examining trends in variability or specific quantiles tended to attenuate the bias incurred in design flood estimates from ams with s d trends when only trends in the mean were modeled overall 100 year flood estimates from models explicitly examining trends in variability or specific quantiles were less efficient for increasing s d trends than decreasing ones because the consequence of errors in increasing trends modeled in log space becomes greater when exponentiated into real space during quantile estimation the relative performance of these three models varied by trend combination when only trends in the mean were present both iwls glm and gamlss exhibited a lower bias and greater efficiency than qr however for s d trends qr and iwls glm yielded more efficient and less biased estimates than gamlss when the directions of trends in the mean and s d were concordant while gamlss was most efficient and least biased when they were discordant interestingly iwls glm yielded downward biased estimates under concordant trends while it produced upward biased ones when trends were discordant whereas gamlss exhibited the opposite tendency these two models assume the same exponential change trajectory and gamlss did not register any na errors for the trend combinations in fig 5 when γ y 0 overall model performance depended substantially on trend directions for both moments next we produced trend space plots for each nsffa model fig 6 featuring contour surfaces of the design flood frmse for simulated ams arising from lp3 distributed ams of 100 years with different trend combinations we performed this procedure for different combinations of sample moments and estimated design floods with different recurrence intervals 10 and 100 years for this analysis we increased the magnitude of decadal trends from 10 to 25 to examine a broader range of trends altogether we examined 25 different combinations of trends in the mean and s d for which δ μ y 25 10 0 10 25 and δ σ y 25 10 0 10 25 as stated previously we limited this analysis to trends of 10 for σ y 0 5 since 25 decadal increases yielded implausible correlation coefficients when σ y 0 5 we bilinearly interpolated frmse values between points representing these trend combinations using the akima r package akima et al 2020 these values are displayed using a dark blue light gray dichromatic spectrum with the light gray endmember indicating a 0 frmse and dark blue indicating frmse 250 fig 6 shows results for simulated ams generated from lp3 distributions with μ y 5 σ y 1 γ y 0 the greater prominence of lighter shades of blue in the trend space plots in the left hand column of fig 6 shows that 10 year flood estimates registered lower frmse values than 100 year ones as expected qr also performed much better relative to other models for 10 year floods most frmse below 50 all frmse below 75 but generally worse than other models for 100 year floods because the density of synthetic observations is greater around the 90th percentile than the 99th percentile for an ams with a symmetric lp3 distribution fig 6 also demonstrates that each model estimated some trend combinations more accurately than others lightly colored zones running from the upper left to lower right quadrant of the stationary trend space plots top row corroborated the insight from fig 5 that stationary models performed better when δ μ y ω δ σ y ω k 1 p as k 1 p increased a larger change in the mean was necessary to offset a given s d change this explains why the lightly colored zone in the stationary 100 year plot has a more horizontal orientation than in the 10 year plot the second row in fig 6 shows that ols mean performed similarly for both increasing and decreasing trends in the mean but that its performance worsened more rapidly as s d trends decreased than as they increased iwls glm yielded much lower frmses when s d trends were decreasing often below 50 one reason iwls glm performed better for decreasing s d trends than increasing ones is because errors from an increasing exponential s d trend model are much larger in real space for similar reasons gamlss performed well for negative s d trends up to 10 bilinear interpolation made gamlss appear to perform extremely poorly as soon as s d trends exceeded 10 because it produced extremely unreliable estimates for s d trends of 25 within the 10 decadal s d trend range iwls glm gamlss performed better when trends were concordant discordant echoing fig 5 we then overlaid the trend space plots to indicate which of the five nsffa models yielded the lowest frmse for both 10 and 100 year flood estimates under different trend combinations see fig 7 panels a and b they were useful for identifying whether observed sites with a given range of sample moments exhibited trends warranting different nsffa models for instance these plots elucidated trend combinations under which models with just a trend in the mean yielded lower frmses than a stationary one or when models considering trends in both moments were worthwhile we overlaid trend combinations modeled with iwls glm observed at stations red diamonds with sample moments similar to simulated values μ y 4 6 σ y 0 8 1 2 and γ y 0 25 0 25 panels a and b of fig 7 indicate which model registered the lowest frmse for 10 and 100 year flood estimates for different trend combinations they are useful for identifying whether observed sites with a given range of sample moments exhibited trends warranting different nsffa models panel c maps these stations to provide a general sense of the conus regions where these results might be more relevant however these findings do not constitute nsffa recommendations for individual sites since more detailed studies that examine long term climate variability and potential anthropogenic perturbations would be necessary prerequisites as would goodness of fit analyses with observed ams panel c suggests that there are stations with trend combinations warranting ols mean iwls glm and gamlss if these trends were to represent deterministic changes in these basins in contrast there were not any sites with sample moments close to simulated values for which qr blue yielded the lowest frmse finally many ams lie near boundaries between preferred model zones in the trend space plots for such sites it is especially important to consider i trend space plots for all models considered as the model with the second best frmse may have other advantages and ii complementary model performance criteria including data based goodness of fit assessments renard et al 2013 fig 7 also contains many patterns discernible in figs 5 and 6 again stationarity green not only yielded the lowest frmse when both trends were near zero but also for some offsetting trend combinations especially ones with decreasing means and increasing s d the stationary model was also preferred more often for this combination of offsetting trends because s d trend models did not estimate design floods for increases in s d as well as they estimated them for decreasing s d their poor performance under increasing s d trends also explains the preference for the ols mean model purple for decreasing trends in the mean with strong increasing s d trends especially for 10 year floods yet the second row of fig 6 clearly shows ols mean did not perform especially well for such strong increasing s d trends either while models considering trends in variability or specific quantiles were more critical for 100 year flood estimates iwls glm orange occupies a large area in trend space plots for both recurrence intervals especially for decreasing s d trends 4 1 4 sensitivity to skewness coefficients we then examined how nsffa model performance varied among simulated ams arising from lp3 distributions with different population skewness coefficients we first examined a stationary base case in which μ y 5 and σ y 1 by comparing a symmetric distribution γ y 0 with ones having strong negative and positive skews γ y 1 14 for 100 year records arising from lp3 distributions fig 8 shows that the efficiency of both 10 and 100 year flood estimates worsened as the skewness increased from 1 14 to 1 14 since the distance between upper quantile values becomes greater as the skewness increases this effect was most pronounced for qr which had the most efficient and least biased estimates for all models except for stationarity when γ y 1 14 in contrast when γ y 1 14 qr was slightly less efficient than iwls glm and gamlss for the 10 year floods and much less efficient than them for 100 year floods while iwls glm and gamlss tended to exhibit similar efficiencies iwls glm estimated 100 year floods more efficiently from negatively skewed ams whereas gamlss performed better for positively skewed ones overall 100 year flood estimates were upward biased for the negative and positive skewness values considered despite applying an attenuation bias adjustment factor of 6 from the lp3 distribution study by tasker and stedinger 1986 to sample skewness coefficients estimated from synthetic observations this adjustment factor exacerbated the already considerable upward bias in 100 year floods for ams with γ y 1 14 while na rates for gamlss simulations with γ y 1 14 and without trends were relatively low 6 see section 4 1 1 figure c6 1 the possibility that removing simulations with low outliers below lp3 distribution bounds biases gamlss 100 year flood estimates merits further study next we examined the effects of strong skewness coefficients γ y 1 14 on current design flood estimates of ams with trends fig 9 due to the extremely high na rate for gamlss with decadal s d trends for γ y 1 14 stemming from synthetic observations outside estimated distribution bounds we limited this analysis to decadal trends of 10 these estimates tended to be more efficient for records with strong negative skew gray than for positively skewed ones turquoise albeit with some exceptions for iwls glm and gamlss design flood estimates from negatively skewed distributions also tended to exhibit higher median re relative errors than estimates from positively skewed ones the performance of the five models also differed between these extreme skewness cases in particular the performance of iwls glm and gamlss for a given trend combination was somewhat skewness dependent for example for concordant decreasing trends iwls glm was less more biased than gamlss under negative positive skewness gamlss exhibited the greatest upward bias for increasing s d trends a circumstance under which it would be more likely to yield na estimates caused by high outliers above its upper bound τ y while further study is needed the removal of simulated series with high outliers suggests removing na runs may in fact attenuate another source of upward bias meanwhile qr performed best for most trend combinations when γ y 1 14 especially when trends in the mean and s d concorded fig 10 also showcases qr s blue superior performance for stations whose sample moments are close to the simulation values of μ y 5 σ y 1 and γ y 1 14 4 1 5 sensitivity to record length while our comparisons up until now have focused on simulated 100 year records most observed ams are much shorter fig 11 demonstrates that stationary models green occupied more area in the trend space plots for 30 year records when μ y 5 σ y 1 γ y 0 see fig 7 and when μ y 5 σ y 1 γ y 1 14 this happened because design flood estimates from models incorporating trends in variability or specific quantiles are so much more variable for short records while models explicitly accounting for s d trends produced more accurate estimates under many strong negative s d trends when γ y 0 few stations with sample moments close to μ y 5 σ y 1 γ y 0 had such strong negative s d trends fig 11a meanwhile qr blue occupied a much larger portion of the trend space plot for γ y 1 14 4 2 robustness to incorrect distributional assumptions fig 12 illustrates trend space plots that examine possible consequences of assuming an lp3 distribution instead of a gev one panel b and vice versa panel c when true trend trajectories are known all four panels including ones illustrating correctly assumed lp3 panel a and gev panel d distributions demonstrate many similar model preferences meaning that nsffa model choices are quite robust to choices between these two distributions the greatest difference between them is the preference for iwls glm when lp3 is assumed and the preference for gamlss when gev is assumed these two models assume the same change trajectories in both the mean and s d and primarily differ in their estimation methods again regardless of the combination of true and assumed distributions stationarity green was the best model not only for ams without trends but also for ones with some combinations of offsetting trends especially ones where s d increases offset decreases in the mean ols mean purple performed much better for sites with trends in the mean and s d decadal increases from 0 to 10 than for ones with commensurate decreases models considering trends in variability performed better than ols mean for s d decreases including very mild ones qr blue performed better for records with extreme concordant trends qr also performed better with ams arising from gev distributions than lp3 distributions however the trend combinations for which qr performed best depended primarily on the true distribution the mis specification of true distribution types did not make qr preferable compared to simulations with correctly specified distribution types section c6 contains gev results analogous to many lp3 results shown in this section including ones demonstrating their overall robustness to the misspecification of lp3 and gev distributions with γ y 1 14 5 discussion 5 1 synthesizing our appraisal of nsffa methods our monte carlo simulations corroborated other recent studies showing that variability trends can substantially impact design flood estimates e g strupczewski et al 2001b delgado et al 2012 debele et al 2017b hecht and vogel 2020 moreover while the estimation errors introduced when s d trends were modeled were often large they produced lower frmse values than models only considering trends in the mean for realistic cases especially for decreasing s d trends due to the log transformation of the ams in contrast the stationary model was more efficient than nsffa models for some combinations of offsetting trends in the mean and s d in addition our regression based nsffa models were largely robust to incorrect distributional assumptions while the lp3 and gev distributions have reasonably similar upper tails compared to other ffa distributions asquith et al 2017 prior simulation studies have also shown that regression based estimates are more robust to distribution misspecification than distribution specific maximum likelihood ones markiewicz et al 2010 strupczewski et al 2016 we also reconciled our results with a recent climate oriented conference paper yu et al 2018 featuring monte carlo simulations that examined adjustments of design flood estimates for variability trends when ams arose from lp3 distributions at first our results may appear to contradict their finding that modeling variability trends seldom improved frmse however they drew their conclusions from an ams based on one station in the humid northeastern us with a moderate s d σ y 0 5 in contrast our results drawn from a continental scale sampling of observed ams including stations in regions with greater interannual variability demonstrated the value of modeling gradual variability trends a comparison of their nonlinear least absolute deviation models of variance change with the models tested in this study would illuminate the importance of considering variability trends further our monte carlo experiments also revealed other important guidance regarding our nsffa models including circumstances under which qr performed well and poorly compared to the moment based models it performed exceptionally well under strong trends for 10 year flood estimates when the skewness was strongly negative for 100 year floods i e when upper quantile values were closer together on the downside it performed quite poorly for positively skewed data and produced exceptionally high outliers even when γ y 0 which makes its use for at site flood frequency riskier the contributions of high outlier floods to severe estimation errors including their timing in the record merits further exploration the robustness study did not demonstrate that qr became preferable when theoretical distributions were incorrectly assumed however future studies with data generated from more divergent distributions would shed more light on qr s potential for at site nsffa future work should also explore nonlinear qr models using quadratic or cubic terms to better approximate exponential variance trends along with extremal qr approaches for estimating quantiles associated with recurrence intervals exceeding record lengths chernozhukov 2005 finally preferred model trend space plots provided a useful visualization for comparing nsffa model performance criteria such as frmse at sites with different trend combinations moments and record lengths it is important to identify models that perform almost as well as the preferred model for a given combination of trends in the mean and s d of ams since they may be more desirable for other reasons see fig 6 trend space plots for evaluating nsffa models for individual sites could also be generated from monte carlo experiments that consider statistical properties of their ams such as sample moments and record length they could provide an important line of evidence for model selection and complement goodness of fit assessments with observed data nicely such site specific applications could also be customized further by sampling plausible trend combinations more densely around trend estimates obtained from candidate nsffa models 5 2 limitations and future directions in nsffa modeling this study evaluated nsffa models using covariates representing gradual changes that transpired at fixed rates over time while a similar experimental design could assess these nsffa models when other deterministic or stochastic covariates with temporally varying rates of change are used numerous adaptations would be necessary most notably the trend adjusted skewness in 9 and 19 requires a uniformly distributed covariate without any missing data see section c2 other distributional assumptions are needed to represent deterministically changing covariates with varying rates of change stochastic covariates also require procedures for untangling deterministic trends from stochastic variability equations 9 and 19 also highlight the sensitivity of trend adjusted skewness coefficients to the sample skewness of covariates since a linear transformation of a random variables with a given skewness yields an output variable with the same skewness one must consider transforming covariates whose skewness varies markedly from that of an ams next the simulation experiments evaluated the internal consistency of nsffa models applicable to continuous ams with all peak flows above zero notably these experiments also did not include i historical floods outside of systematic gauging periods ii censored measurements iii adjustments for low outliers and iv systematic records with mising years in addition we treated all discharges as point estimates despite peak flow gauging uncertainties see kiang et al 2018 the expected moments algorithm ema which accommodates imprecise discharge estimates falling within a specified interval could be extended to incorporate these uncertainties evaluating nsffa models with a conditional moments based approach is an essential precursor to extending the interval data accommodations of ema to nonstationary ams ams generated from a wider range of realistic theoretical probability distributions such as three parameter lognormal e g vogel and wilson 1996 generalized logistic e g ekeu wei et al 2020 metastatistical extreme value miniussi et al 2020 and burr zaghloul et al 2020 distributions along with mixedpopulation approaches hirschboeck 1987 barth et al 2019 could illuminate other benefits of the nsffa models as could multi model estimates derived from them e g debele et al 2017a b finally comparing suitable nsffa models for other flood characteristics besides peak flow such as frequency duration and volume would provide a more complete picture of conus flood changes archfield et al 2016 there are also many opportunities to improve variability trend modeling including modeling changes in variability driven by covariates different than ones used for modeling changes in the mean e g xiong et al 2020 bertola et al 2021 slater et al 2021 we also only examined an exponential variance change trajectory prevalent in the nsffa literature e g strupczewski et al 2001a delgado et al 2010 villarini et al 2012 xiong et al 2020 that both iwls glm and gamlss accommodate readily additional research should evaluate other change trajectories such as gamlss nonlinear spline functions e g qu et al 2020 at sites with deterministic drivers of variability change such as urbanization abrupt and non monotonic changes in the mean and s d also merit consideration including disturbance recovery sequences from wildfires e g saxe et al 2018 climate oscillations e g kwon et al 2008 dickinson et al 2019 glacial melt shah et al 2020 and stormwater management mcphillips et al 2019 further work on disentangling step changes from trends bates et al 2012 rougé et al 2013 ryberg et al 2020 and using more recent subsets of ams vogel and kroll 2020 instead of trend adjusted design floods is also warranted finally advantages of covariate based statistical models over gcm forced simulations of future flood changes performed with process based hydrologic models e g schlef et al 2021 motivates the continued development of nsffa models indeed changes in flood trend trajectories over time make evaluating changes in future flood risk especially challenging through a split sample experiment luke et al 2017 demonstrated risks associated with extrapolating observed trends into the future even when deterministic changes in watershed characteristics could be identified future simulation experiments building upon our work could also assess consequences of making incorrect assumptions about future flood trajectories using different methods for assessing changes in them over specific project lifespans see yan et al 2017 next further research could also determine whether at site nsffa model preferences based on monte carlo simulations change when estimating design floods at ungauged sites with regional models o brien and burn 2014 showed that regionalization is especially beneficial under nonstationarity since more information is available to reduce the greater parameter uncertainty of nonstationary models some studies have demonstrated the benefits of regional applications of models that yield highly variable estimates when applied to single site records including a qr based approach for estimating urbanization induced changes in the chicago metropolitan area over et al 2016 finally deep learning methods for predicting flows e g kratzert et al 2019 also merit attention in any case our results highlight the need for a customizable nsffa modeling approach reflecting the hydrologic diversity of the conus future studies should assess alternative nsffa models in regions with ams exhibiting statistical properties for which our models did not perform well such as positive skewness and increasing trends in both the mean and s d populous regions of the northeastern us have positively skewed ams watson and schopp 2009 veilleux et al 2019b while a strong regional signal of change in peak flow variability has not been detected there see fig 2 ongoing increases in mean and extreme precipitation e g huang et al 2017 suggest future increases in both moments are possible 6 conclusions monte carlo simulations enabled us to appraise the performance of five nsffa models for considering the effects of gradual trends on estimates of 10 and 100 year floods a range of design events commonly used in infrastructure design and floodplain management in the united states aashto 2014 while numerous studies have compared nsffa models through monte carlo simulations strupczewski and kaczmarek 2001 delgado et al 2010 debele et al 2017b yu et al 2018 hecht and vogel 2020 qu et al 2020 vogel and kroll 2020 our experiments were distinct in their parameterization using combinations of sample moments and trends observed in a continental scale set of ams while the lp3 distribution is an adequate assumption under nonstationarity in most conus locations our experiments highlight the diversity of nsffa modeling approaches needed to adjust design floods to current conditions at sites throughout the conus including sites where additional models may be needed to compare candidate nsffa models we developed trend space plots displaying monte carlo experiment performance metrics frmse in our example for different trend combinations however while these plots elucidated trend combinations for which different nsffa models perform best when their distributions are correctly and incorrectly specified these experiments have not evaluated how well different models approximate observed change trajectories at sites with different statistical properties future research that compares the goodness of fit of different assumed change trajectories and distributional assumptions is essential for advancing nsffa this must include out of sample testing to avoid confounding short term fluctuations with long term trends luke et al 2017 diffenbaugh 2020 iliopoulou and koutsoyiannis 2020 and assess the stability of results to choices of calibration and validation periods renard et al 2013 kochanek et al 2014 guo et al 2020 as renard et al 2013 state both internal consistency and out of sample evaluations are essential for any comprehensive evaluation of flood frequency analysis models credit authorship contribution statement jory s hecht conceptualization methodology software formal analysis investigation data curation writing original draft visualization nancy a barth conceptualization methodology software formal analysis investigation writing review editing karen r ryberg conceptualization writing review editing supervision project administration angela e gregory investigation software visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the federal highway administration fhwa interagency agreement iaa dtfh6116x30020 flood frequency estimation for hydraulic design it also benefitted from preliminary discussions with the fhwa brian beucler joseph krolak kornel kerenyi rob kalafenos and rebecca lupes reviews from aldo vecchia jared smith and anonymous referees improved the paper as did earlier discussions with stacey archfield john england jr richard vogel and thomas over natalya rapstine from the u s geological survey s advanced computing resources group guided the implementation of the monte carlo experiments on the usgs yeti high performance computer https www usgs gov advanced research computing usgs yeti supercomputer and lopaka lee assisted with verification on the usgs tallgrass high performance computer four u s geological survey employees contributed to the data release associated with this manuscript hecht et al 2022 which includes an archive of code used to run the analyses conducted in this study sarah fiala and amy russell central midwest water science center assisted with the documentation of input and output data from the monte carlo experiments which tara williams sether dakota water science center reviewed amanda whaling lower mississippi gulf water science center reviewed the model archive and verified the reproducibility of the results and figures in the manuscript any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government data availability the u s geological survey data release hecht et al 2022 associated with this publication contains both the simulated data and r statistical software code used in this study the simulated data were created based on moments and trends from 1900 annual instanteanous peak flow series selected from 2683 observed series with lengths ranging from 50 to 100 years 1916 2015 1966 2015 identified during a prior phase of the flood frequency estimation for hydraulic design project see dudley et al 2019 in turn these 2683 peak flow series were obtained from the national water information system nwis at https nwis waterdata usgs gov usa nwis peak appendix a estimating trends in the mean and standard deviation with iwls glm building off hecht and vogel 2020 we implemented iwls glm using the following iterative four step procedure to produce convergent trend estimates step 1 we estimated the conditional mean μ y ω using weighted least squares wls a 1 μ y ω μ y β μ 1 ω i μ ω ε ω for just the first iteration we assumed equal weights equivalent to ols regression step 2 we squared the residuals of a 1 to estimate the conditional variance and scaled them using the same n n 2 degrees of freedom correction factor applied in 17 a 2 σ y ω 2 σ ε ω 2 n n 2 ε ω 2 step 3 our second stage model relating gamma distributed squared residuals ε ω 2 to ω is a 3 σ y ω 2 σ ε ω 2 ε ω 2 exp β σ 2 1 ω i μ ω υ ω to estimate σ y ω 2 we first estimated β σ 2 1 the slope of this centered variance trend model by fitting a second stage gamma glm with a log link function using the glm2 r package marschner and donoghue 2018 a 4 σ y ω 2 σ ε ω 2 n n 2 ε ω 2 exp β σ 2 1 ω i μ ω step 4 we used reciprocals of fitted values of step 3 as weights when fitting the conditional mean model in 17 in the next iteration repeating these steps until convergence the trend in the variance β σ 2 is then converted to a s d trend using 18 appendix b estimating lp3 distribution trends in the mean and standard deviation with gamlss the shifted gamma distribution approach we implemented our shifted gamma distribution method for estimating trends in the mean and s d of ams arising from an lp3 distribution in response to a uniformly distributed time index ω using the gamlss r package stasinopoulos et al 2020 as follows step 1 we computed the lower bound upper bound parameter τ y for positively negatively skewed distributions using mom as shown in 14c we used the known moments of the true distribution specified in the monte carlo experiment to compute τ y so that errors in moment estimation did not confound our assessment of the trend modeling ability of the nsffa methods step 2 procedures for adjusting a log transformed ams y using τ y also depended on its skewness if y was symmetric then we applied gamlss assuming a normal distribution an extreme case of the gamma distribution as there is no finite bound τ y in this special case in contrast when y was skewed we transformed lp3 distributions with either finite positive lower or upper bounds to produce a positively skewed gamma distributed variable y adj with a 0 support if y was positively skewed this transformation amounted to a simple downward translation of the distribution s location by subtracting τ y a lower bound parameter in this case from all values b 1a in contrast if y was negatively skewed then we had to flip the distribution into a positively skewed one by subtracting all observations from τ y which in this case is an upper bound parameter b 1b b 1a y adj y τ y γ y 0 τ y y adj m i n b 1b y adj τ y y γ y 0 τ y y adj m a x these equations could only be applied if all y adj values fell within estimated distribution bounds a known ffa challenge when using the lp3 distribution griffis and stedinger 2007a along with other bounded distributions such as the gev zaghloul et al 2020 otherwise estimates were recorded as na we also examined the combinations of trends and moments under which these bounds were most problematic step 3 we estimated changes in the mean and s d of log transformed ams using the gamma distribution as parameterized in gamlss b 2 f y adj φ ϕ y adj 1 ϕ 1 exp y adj ϕ 2 φ ϕ 2 φ 1 ϕ 2 γ 1 ϕ 2 where the parameters φ and ϕ are related to the mean and s d of y adj as follows b 3a μ y adj φ y adj b 3b σ y adj φ y adj ϕ y adj step 4 then we estimated covariate conditional values of φ and ϕ with gamlss b 4a φ y adj ω exp β α 0 β α 1 ω i b 4b ϕ y adj ω exp β θ 0 β θ 1 ω i the subscripts 0 and 1 refer to intercept and slope coefficients of the regression models step 5 next using b 1 b 4 we estimated conditional values of the mean and s d for γ y 0 b 5a μ y ω φ y adj ω τ y b 5b σ y ω φ y adj ω ϕ y adj ω and for γ y 0 b 6a μ y ω τ y φ y adj ω b 6b σ y ω φ y adj ω ϕ y adj ω step 6 we computed the trend adjusted skewness using 19 step 7 finally we used the analytical equations in 14 from the lmomco r package asquith 2020 to estimate lp3 distribution parameters as a function of estimated moments appendix c supplementary data supplementary data to this article can be found online at https doi org 10 1016 j hydroa 2021 100115 appendix c supplementary data the following are the supplementary data to this article supplementary data 1 
