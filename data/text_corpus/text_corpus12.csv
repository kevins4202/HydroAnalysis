index,text
60,in this work we provide a physically consistent modeling approach for two phase porous media flow by including percolating interfacial area and saturation as state variables for this purpose we combine two continuum theories for two phase flow which have been individually proven to be conditionally valid this means the potential use of the connected to the flow interfacial area as a state variable is tested utilizing time resolved microfluidic experiments for various flux boundary conditions moreover we observe and study a linear relation between the percolating saturation and interfacial area which is persistent for the tested boundary conditions in our microfluidic experiments we employ optical microscopy to perform cyclic immiscible displacement experiments our results show that a continuum model where capillary pressure saturation and specific interfacial area of the clusters connected to the flow are considered is closer to a universal description of two phase flow than the common approaches where the only state variable is saturation keywords microfluidic experiments two phase flow phase percolation interfacial area image processing optical microscopy data availability the data has been published on the depository of university of stuttgart the link is provided in the article 1 introduction defining the physical properties of a multi phase displacement process in a porous medium is a fundamental prerequisite in many porous media fluid flow applications such applications include but are not limited to many natural phenomena such as water infiltration parr and bertrand 1960 lipiec et al 2006 or saline water intrusion todd 1974 choudhury et al 2001 and those of industrial interest these include enhanced oil recovery eor muggeridge et al 2014 alvarado and manrique 2010 or fuel cells abdelkareem et al 2021 sharaf and orhan 2014 among others however the theoretical frameworks under which the underlying physical processes are attempted to be described and modeled have been efficient to a specific extent with the overall image still incomplete the empirical closure equations in common continuum theories such as leverett 1941 brooks and corey 1964 land 1968 or van genuchten 1980 include saturation or effective residual trapped saturation as the only state variable for example land 1968 obtains expressions for trapped and mobile non wetting saturation and shows that they can be used in the calculation of wet rock fluid properties such as relative permeability in these approaches the equations for saturation vs capillary pressure must have different coefficients for different displacement events to capture the history dependent characteristics of two phase flow in porous media given that the aforementioned macroscale i e continuum approaches are case and history dependent substantial theoretical numerical and experimental efforts have been made to come up with more physically based and representative modeling approaches these efforts mostly involve adding state variables other than saturation to the continuum scale models among the list of proposed new state variables are the area of the interfaces between the phases hassanizadeh and gray 1990 1993 a topological measure known as euler characteristic number herring et al 2013 schlüter et al 2016 miller et al 2019 mcclure et al 2020 and connection of the phases to the flow path hilfer 2006a b armstrong et al 2012 herring et al 2017 moreover several researchers identify and include more than one state variable at once osei bonsu et al 2020 vahid dastjerdi et al 2022a for example osei bonsu et al 2020 have experimentally shown that parameters such as the euler characteristic number the percolating volume fraction of the fluids and the fraction of the wetted solid surface are adequate to describe the phases state in their microfluidic experiments these parameters have been shown to provide practical solutions towards making reservoir simulations more efficient khorsandi et al 2021 however a practical approach based on continuum theories and their applications are yet to be identified in this study we are focusing on the approaches of hassanizadeh and gray 1990 1993 who introduce specific interfacial area as a separate state variable and hilfer 2006a b where percolating and non percolating volume fractions for each fluid phase are included as one can see the additional state variables in these two approaches are conceptually different in hassanziadeh gray s approach a new measure that accounts for the existence of interfaces is introduced hilfer s approach focuses on the connectivity of fluid phases and still works with the traditional volumetric measure namely saturation thus they take different phenomena in multi phase flow into account and can potentially be complementary we hypothesize that their combination can improve our description of multi phase flow in porous media hilfer points out challenges such as the inclusion of hysteresis and multivaluedness mirroring the dynamic effects in a process and the association of pore scale parameters with macroscale averages as the reasons behind the inefficiency of the common macroscopic theories he tries to overcome them by obtaining the capillary pressure function as an outcome of his theoretical framework and not as an input in this context he considers residual saturation as non percolating saturation which depends on the process and the initial boundary conditions he also differentiates between percolating and non percolating saturation in general in other words he introduces four saturation fields percolating and non percolating fractions of wetting and non wetting saturations instead of only wetting and non wetting a few numerical and experimental investigations have shown the potential of this theory hilfer and doster 2010 doster and hilfer 2014 hilfer et al 2015 however the extent of its validity under non equilibrium conditions has not been shown yet in the extended continuum mixture theory for porous media developed by hassanizadeh and gray 1990 1993 balance equations are developed for bulk phases for interfaces and for exchange processes over interfaces compared to classical continuum scale theories of porous media the interfaces per unit volume between the three phases wetting non wetting and solid as the locus of any potential phase energy exchange complement classical bulk state variables through safe assumptions for the fluid solid interfaces they reduce the essential state variables in their continuum theory to saturation and fluid fluid specific interfacial area many numerical and experimental investigations have shown that including this extra state variable improves the modeling of the apparent hysteresis in quasi static displacement events held and celia 2001 cheng et al 2004 joekar niasar et al 2008 niessner and hassanizadeh 2008 porter et al 2009 zhuang et al 2017 however the validity of this approach under transient flow conditions and for a wide range of capillary numbers has been questioned joekar niasar and hassanizadeh 2011 shokri et al 2022 for example karadimitriou et al 2014 investigate the theory under transient conditions experimentally with the use of microfluidics and direct real time visualization they show that the inclusion of the specific interfacial area between the two fluids can improve the hysteretic behavior during cyclic drainage and imbibition events they show capillary pressure saturation specific interfacial area creates a unique surface under given boundary conditions however different surfaces for different boundary conditions are needed this raises the question of whether another state variable in addition to specific interfacial area is needed to account for the effective complex pore scale fluid configurations on the macroscale motivated by the results of karadimitriou et al 2014 and inspired by the theoretical approach of hilfer 2006a b vahid dastjerdi et al 2022a perform a set of two phase displacement experiments to investigate the role of disconnections in the evolution of the flow they follow the extended continuum theory for two phase flow where specific interfacial area between the wetting and the non wetting phase is brought into the constitutive equations their experiments include flow controlled cyclic drainage and imbibition with three orders of magnitude variation in the volumetric fluxes and the corresponding ca number 10 7 to 10 5 they conclude that considering both interfacial area and percolating saturation of the invading phase in two phase porous media flow models can model the apparent hysteresis more efficiently this signifies that describing two phase flow with a single model is more feasible when both percolating saturation and interfacial area are considered as state variables however in their experiments the microfluidic cell they use facilitates strong corner film flow by construction the extent of the corner film flow is not observable and quantifiable with their experimental procedure and therefore a reliable saturation for the connected wetting phase is not measurable thus they only resolve the drainage events in terms of saturation capillary pressure and specific interfacial area between the wetting and the non wetting phase during the flow both on the micro and macro scale they imply that further studying of imbibition processes needs to be carried out in a microfluidic cell with very well defined connectivity of the wetting phase the cell should also allow for the precise calculation of the wetting phase saturation since the shadow caused by curved channel walls in glass microfluidic cells prevents the wetting phase occupancy from being captured thus the most feasible solution to take their investigations further is a microfluidic cell in which the permeability of the corners and the extent of films of the wetting phase is negligible taking advantage of the capabilities of soft lithography xia and whitesides 1998 karadimitriou et al 2013 and optical microscopy karadimitriou et al 2013 in the current contribution we are presenting a set of microfluidic experiments in a porous domain made of poly di methyl siloxane pdms the primary motivation behind these experiments is to investigate our hypothesis during imbibition while excluding the corner film flow effect for the wetting phase the structure of the pores of the pdms microfluidic cells along with pdms wetting properties prohibits the pronounced connection between the wetting clusters and allows us to define connectivity reliably from the images and address the imbibition processes as well however by shifting to pdms micromodels other aspects of the experiments are also changed and included for instance the geometry of the porous domain is slightly different in the pdms microfluidic cell in comparison to the glass micromodel used in vahid dastjerdi et al 2022a the pore throat pore depth ratio in the pdms cells differs from this in the glass microfluidic cells thus the corresponding entry capillary pressure for the same planar location is different in the two cells moreover due to the different manufacturing procedures the channel shapes differ the curved walls in the glass cell are replaced with almost perfect rectangular channels in cross section in the pdms microfluidic cell another aspect that is different in these experiments is the wetting properties of the employed fluid solid fluid system a concept known as lenormand s phase diagram lenormand et al 1988 should be mentioned to elaborate further on this matter lenormand et al 1988 perform drainage experiments with various viscosity ratios m between the non wetting phase as the invading fluid and the wetting phase as the defending fluid and different capillary numbers ca where 1 m μ n w μ w 2 c a μ n w q σ w n here μ n w and μ w are the dynamic viscosities of the non wetting and wetting phase pa s respectively σ w n is the interfacial tension between the non wetting and wetting phase n m and q is the darcy velocity m s in the experiments they categorize primary drainage processes into three distinguished regimes known through the shape of the displacement front based on the combination of the viscosity ratio and the ca number in a water pdms fluorinert system where fluorinert section 2 is the wetting phase and water is the non wetting one the viscosity ratio between the invading and the defending fluid during a drainage process is m 0 21 log m 0 7 in a glass porous medium however the wetting properties are inverse meaning that in a water glass fluorinert system water is the wetting phase in lenormand s phase diagram one can see that reversing the viscosity ratio can affect the displacement regime hence we are putting our hypothesis of a unique surface for all data points of saturation capillary pressure and specific interfacial area for connected clusters to the test for a precisely defined geometry in a hydrophobic microfluidic cell and for both drainage and imbibition a set of flow controlled microfluidic experiments consisting of six drainage and six imbibition events are carried out images from the displacement processes are recorded at fixed time intervals the images are processed with an in house developed tool based on matlab 2019 and the desired parameters such as saturation capillary pressure and interfacial area are extracted then eq 3 is employed to fit the data points from all terminal menisci between the wetting and non wetting phases for all displacement processes 3 a w n α s i n v β 1 s i n v γ p c r e v p a t m δ where a w n is the specific interfacial area 1 m defined as the total interfacial area of all wetting non wetting interfaces normalized over the bulk volume of the porous medium s i n v is the saturation of the invading fluid non wetting during drainage and wetting during imbibition and p c r e v is the rev scale capillary pressure p a t m is the atmospheric pressure assumed as constant in all experiments 1 0 5 pa parameter α has units of 1 m and parameters β γ and δ are dimensionless further the same fitting process is applied to the same dataset for the percolating phases only comparing the two fits through r 2 the coefficient of determination shows how significant the consideration of only the percolating saturation of a phase is in the attempt to uniquely model capillary pressure hysteresis we also observe a linear relationship between the saturation and the interfacial area in percolating clusters we show that this relationship is persistent characteristic of flow rates and independent of the number of displacement events the highly temporally and spatially resolved microfluidic experiments and their results presented here are complementary to the investigations published in vahid dastjerdi et al 2022a through these results we are able to complete our studies for a broader range of boundary conditions displacement types flow rates viscosity ratios and geometrical factors we show that a combination of two continuum theories theories from hassanizadeh and gray 1990 and hilfer 2006a has less dependency on the boundary conditions in comparison to each theory alone displacement types flow rates or viscosity ratios clearly and concisely 2 materials and methods the experimental methods are similar to the ones described in vahid dastjerdi et al 2022a minor differences are explained in the following sections 2 1 experimental setup the experimental setup consists of a customized optical microscope a microfluidic cell and a syringe pump apart from the microfluidic cell and the visualization settings the rest of the setup is similar to the one used in vahid dastjerdi et al 2022a in the following the varying characteristics of the setup are presented 2 1 1 microfluidic cell a micromodel made of pdms with cylindrical pillars serves as the porous medium in microfluidic experiments pdms micromodels are widely used in microfluidic experiments since they are flexibly producible by photo and soft lithography xia and whitesides 1998 karadimitriou et al 2013 in this work the depth of the cell is 55 μm and its pore size distribution varies between 75 μm and 250 μm with a mean size of 180 μm the cad design of the cell is available in vahid dastjerdi et al 2022b the total pore volume of the cell is 3 7 μl with a porosity of 50 the channels cross section is very close to perfect rectangles 2 1 2 visualization a basler aca2440 20gm monochrome camera is used in this work with a sensor size of 5 mpx and an acquisition rate ranging from 0 07 to 23 fps a 1 w led light source emitting at 590 nm mounted on an f 3 2 135 mm canon objective lens serves as the collimated illumination of the microscope the light is then redirected and collected through an edmund optics prism and a sigma f 1 8 135 mm tele lens towards the camera the region of interest is cut out from the full sensor size 2448 2050 for further processing the visualization as well as the acquisition properties of the experiments such as image acquisition rates and image size are listed in table 1 the spatial resolution in the experiments is 9 1 μ m p i x e l a detailed sketch of the setup can be found in vahid dastjerdi et al 2022a 2 2 two phase flow experiments the wetting and the non wetting phases are fluorinert 3m fluorinert fc 43 liquid viscosity 4 71 pa s density 1860 k g m 3 and water viscosity 1 pa s density 997 k g m 3 respectively since the two fluids are colorless water is dyed with a water soluble ink talens ecoline 578 liquid watercolor at a concentration of 50 the experiments are flow controlled and the volumetric flux is chosen to maintain the desired ca numbers for primary drainage the ca numbers are 10 5 10 6 and 10 7 and this is achieved through volumetric fluxes of 0 18 μ l m i n 1 8 μ l m i n and 18 μ l m i n as listed in table 1 starting with primary drainage micromodel initially fully saturated with fluorinert twelve sequential displacement processes of drainage and imbibition are performed in the micromodel by injecting 18 μl of each fluid into the microfluidic cell the volume of the fluids is chosen to be large enough ca five times the pore volume to establish a steady state flow after the breakthrough of the injected fluid both fluids are injected from one side of the cell through an inlet tube which is filled with fluid pulses before being connected to the micromodel fig 1 the twelve displacement processes primary drainage main imbibition and ten scanning curves are imaged at fixed time intervals as listed in table 1 moreover the inlet pressure is logged while having a constant head of a water column of 10 cm 1 kpa at the outlet as a back pressure the experiment with the largest ca number ca 1 0 5 has been carried out twice experiments 3 and 4 once with twelve displacement events and once with twenty four to investigate the role of system history on the variables investigated in this work 2 3 image processing details about image processing can be found in vahid dastjerdi et al 2022a the main difference between the two procedures image processing in the current work and in vahid dastjerdi et al 2022a is the mask used for segmentation as mentioned in 2 2 the pdms microfluidic cell is first saturated with fluorinert which is transparent similar to the solid phase thus segmenting the image into three phases is done with a mask where the pore space in an image from a fully saturated cell is colored and separated from the solid skeleton the rev size in the investigations is calculated as the smallest volume above which any changes in the average value of the considered parameter are negligible we investigate the rev size for porosity interfacial area and mean curvature the domain size which is an rev for all these parameters is in the order of 1120 1120 pixels 10 mm 10 mm as the imaged porous domain in our experiments is ca 2150 1300 pixels 11 mm 20 mm the middle part of the micromodel qualifies as at least one rev 2 4 post processing proceeding with the image processing techniques which yield parameters such as length curvature and contact angle of each interface rev scale parameters such as saturation total interfacial area and average capillary pressure are computed eqs 4 to 6 are employed to calculate the interfacial area of an interface i a i w n the local capillary pressure based on the three dimensional young laplace equation p i c and the macroscale capillary pressure p rev c 4 a i w n l i d cos α π 2 α where l i is the length of interface i m α is the contact angle in e z direction 56 during drainage and 58 during imbibition and d is the depth of the cell 55 μm the collective interfacial area of all interfaces in one image is the rev scale interfacial area associated with one image 5 p i c σ w n κ i 2 cos α d where p i c is the local capillary pressure at interface i σ w n is the surface tension between fluorinert and water which is equal to 55 m n m 2 κ i is the curvature of each interface in the e x e y plane 1 m the contact angle α in the e y e z direction is assumed to be equal to the mean value of the contact angles calculated in the e x e y plane for all interfaces fig 1 averaging the local capillary pressures over the interfacial area eq 6 delivers the macroscale rev capillary pressure 6 p r e v c σ p i c a i w n σ a i w n where a i w n is the area of interface i m 2 triplets of data containing the saturation of the invading phase the total specific area of the wetting non wetting interfaces and the rev scaled capillary pressure are formed for all clusters in the porous domain during flow the same procedure is carried out to extract the data for only the flowing clusters to quantify the affiliation of the data point with a single surface as we hypothesize a function as eq 3 is used to fit the data the goodness of fit in the form of r 2 is presented in section 3 3 results the first step in our investigations is to ensure that the pdms micromodels serve the purpose of this study for which we need to determine the connectivity of the clusters to the flow precisely to ensure the compatibility of the cell we observe the volume of several clusters detected as disconnected from the images for both phases during drainage and imbibition if a significant change is detected in their volume a connection that is not detectable with our image processing procedure for example through corner flow can be assumed if the volume of a cluster which visually looks disconnected from its neighbors does not change during flow it is considered an isolated cluster in fig 2 four wetting phase clusters are marked with red circles at different locations the images show the configuration of phase clusters in the micromodel at the end of a drainage event fig 2a and an imbibition event fig 2b the volume change of the four clusters during those drainage and imbibition events is studied since their volume changes only by 0 2 to 0 7 we assume the clusters are disconnected the same analysis is carried out for the non wetting clusters and as expected the volume change is in the order of the processing error given the above the connectivity of wetting and non wetting clusters at the scales relevant to this work is detectable from the images thus the recorded images during both imbibition and drainage are processed and the derived quantities are analyzed and presented in the following with the use of the image processing procedures described in vahid dastjerdi et al 2022a specific interfacial area capillary pressure and saturation are calculated for each image initially for all clusters and then only for the connected ones plots of specific interfacial area versus saturation gathered from the experiments are shown in figs 3a and 3b for all clusters and connected clusters respectively similarly figs 3c and 3d show the capillary pressure saturation data pairs from all clusters and connected clusters respectively it is evident that the data for connected clusters show better behaving trends the apparent linear dependency of the specific interfacial area on the saturation for the connected clusters the increase in the slope of this linear dependency and the reduction in the variability motivate us to look into their relationship more thoroughly in fig 4 this relation is investigated in the experiment with ca equal to 10 5 and for drainage and imbibition separately during primary drainage the specific interfacial area grows linearly with saturation with a slope of 675 1 m however the slope increases as the experiment evolves and reaches 1540 1 m for the eleventh scanning curve for imbibition the corresponding slope steadily increases from the minimum value of 610 1 m for the main imbibition to the maximum value of 1370 1 m for the last imbibition process in addition it is noteworthy that the difference between the two processes reduces as the number of displacements history of the system increases observations of the other two experiments also reveal the same pattern the slope is always between 230 1 m to 1540 1 m with the lowest value being associated with the main imbibition of the slowest experiment ca 1 0 7 and the highest value corresponding to the last drainage of the fastest experiment ca 1 0 5 the slope of the fitted line for connected clusters seems to stop increasing after some scanning events resulting in a unique domain that accommodates all the specific interfacial area values to verify this hypothesis the experiment with the ca number 10 5 is repeated with 24 cycles instead of 12 in fig 5 one can see the specific interfacial area generated between the wetting and the non wetting phase for clusters connected to the inlet during both sets of experiments thus the domain of the set of state variables a wn s seems to be well defined for a single ca number and a given porous medium with this second experiment we also investigate the dependence of the interfacial area on the pore structure in an experiment where the capillary forces are not dominant the ca numbers for the experiments are chosen so that a transition between capillary fingering and viscous fingering is expected based on lenormand s phase diagram our results show that even in an experiment that is not fully capillary dominated log ca 5 and log m 0 7 the generation of interfacial area is the same as long as the porous medium stays the same we also observe that the more displacement events happen in the microfluidic cell the less the change in the produced interfacial area is which implies the formation of preferential flow paths after some cycles the formation of preferential paths could be interpreted as forming an effective porous medium slightly different during drainage and imbibition events although the displacement events are executed 24 times in the second trial with ca 1 0 5 the specific interfacial area stays in the range of the first trial investigating this observation in other case studies can help us estimate the s a w n curves in various phenomena where the displacement events happen repeatedly fig 6 examples are the cyclic wetting and drying of soil zhao et al 2018 fluids displacement in fuel cells andersson et al 2016 niblett et al 2020 subsurface storage of compressed air caes zhang et al 2020 or hydrogen tarkowski 2019 following the procedure described in section 1 eq 3 is fitted to the data point triplets from one displacement process this work s main interest is finding the state variables of a two phase porous medium flow independent of the viscosity ratio of the fluids the displacement process drainage or imbibition and the ca number putting all the data points from drainage and imbibition during one experiment together serves the purpose of studying our hypothesis on the type of displacement process moreover the results from analyzing the combination of the data from the experiments with various ca numbers indicate the dependency of the hypothesis on the ca number in other words the data from experiments with ca numbers 10 7 and 10 6 are combined and the same fitting process is applied similarly combinations of the experiments with ca numbers 10 6 and 10 5 as well as the experiments with ca numbers 10 7 10 6 and 10 5 are studied the experiment with ca number 10 5 is chosen as an example and the goodness of fit in the form of r 2 is presented in table 2 the experiment with the capillary number of 10 5 is chosen as a more representative example since a significant viscous contribution to the flow regime is expected thus there is a larger number of disconnections and consecutively increasing the probability of establishing preferential flow paths for fewer cyclic events the r 2 values illustrate the nearly perfect fitting of eq 3 to the single displacement processes when only the clusters connected to the flow are accounted for the r 2 values in the last row of table 2 show how much the fitting is improved for connected clusters for a dataset containing drainage and imbibition displacements the effect of ca number on the fitting is presented in table 3 the r 2 values listed in table 3 make it clear that the fitting improves when only the data from connected clusters are considered this is especially of interest for the most transient experiment where the fitting for all clusters is bad the better fit in the case of connected clusters supports the hypothesis that connectedness and specific interfacial area should both be involved in theories related to two phase flow furthermore a glance at the results presented in vahid dastjerdi et al 2022a for a viscosity ratio of 0 21 see table 4 is an indication of the validity of the theory independent of the viscosity ratio comparing tables 3 and 4 one can see that the fit improves for the connected clusters in comparison to all clusters for both viscosity ratios of 4 7 and 0 21 in addition to the ca number viscosity ratio and displacement process there is evidence in our results that this hypothesis holds for various geometries the evidence comes from the fact that the hypothesis is consistent in two relatively different geometries as the geometry the pore throat pore depth ratio and shape of the channels of the pdms cell used in this study is different from the glass micromodel used in vahid dastjerdi et al 2022a however the effects of the geometry on the fitting parameters must be addressed thoroughly in future research as described in section 1 in this work the existence of a single surface for p c s a w n is investigated in particular we have fitted eq 3 to various datasets with different ca numbers and or their combinations and have obtained values for the parameters α β γ and δ the resulting equations for all clusters and connected clusters are given in eqs 7 and 8 respectively these equations are formed by substituting the values of parameters α β γ and δ as calculated for all data from the three experiments in eq 3 7 a w n 0 034 s i n v 1 11 1 s i n v 0 485 p c r e v p a t m 2 53 8 a w n 14 53 s i n v 1 17 1 s i n v 0 38 p c r e v p a t m 1 we use these equations to calculate specific interfacial area for all experimentally measured values of saturation and capillary pressure and compare the calculated values with the corresponding measured values of specific interfacial area in fig 7 it can be clearly seen that eq 8 for connected clusters only does a better job in predicting measured values of specific interfacial area than eq 7 for all clusters note that the data from the three experiments are not distributed in the same pattern one can see that the experiments with ca numbers 10 6 and 10 7 are better captured by eq 8 than the experiment with ca number 10 5 this could again be associated with the growing viscous effects in the experiments and the corresponding pore scale velocity fields 4 discussion and conclusion the linear relation between the saturation of the invading fluid and the specific interfacial area is characteristic of almost all displacement regimes the data points include pairs of specific interfacial area and saturation from four experiments two of which with ca numbers 10 7 and 10 6 seem to be in the capillary regime based on the work from lenormand et al 1988 and fall on top of each other the other two experiments with ca number 10 5 are also similar regardless of the number of displacement events fig 6 these observations imply that the specific interfacial area associated with the connected clusters in a porous medium fall within a domain boundary by two straight lines one corresponding to the main imbibition and the other to the last scanning drainage event one can see in fig 5 that the rate of change of the specific interfacial area vs saturation in the clusters connected to the inlet stays almost constant after the main events main drainage and main imbibition this is regardless of the number of displacement events and happens for both experiments 3 and 4 moreover in some processes the re connection of some disconnected clusters causes discontinuities in the data points however the slope of the linear relation of the specific interfacial area and saturation is preserved see main drainage in fig 4a or main imbibition in fig 4b moreover with the results presented here we show that the description of a two phase system can be drastically improved from a continuum perspective when specific interfacial area and at the same time discrimination between connected and disconnected clusters are considered for a range of ca numbers all triplet data points of saturation capillary pressure and interfacial area can be fitted with a surface although for increasing boundary flux conditions considering only the interfacial area seems to reach a conceptual limitation see r 2 values for all clusters in table 3 the r 2 values for connected clusters show a much smaller dependency on flow rates there is however a strong deviation from an ideal fitting when combining various ca numbers thus to be able to find a single description for two phase flow that fits all boundary conditions additional parameters or even state variables are needed nevertheless there is an essential improvement in the fitting when in addition to interfacial area the connectivity of the phases is also considered the r 2 increases from 0 33 to 0 70 still not ideal when all experiments are analyzed as one dataset table 3 given the results of this work the logical next step would be to evaluate our proposed combination of two continuum scale theories for the effect of the geometrical factors this includes the investigation on the pore scale of how local constrictions favor or not disconnections due to the interplay between capillary and viscous forces thus further research with a variety of pore scale geometries and also the corresponding pore and throat size distributions as well as the networks correlation lengths and coordination factors should be carried out in correlation to the work from vahid dastjerdi et al 2022a we need to emphasize the cross sectional shape s comparative effect on flow evolution mainly regarding the connectivity of the wetting phase the channel properties of the pdms microfluidic cell and its wetting properties restrict the connection of the wetting phase and thus allow for the inclusion of imbibition in the results without any biasing the addition of imbibition allows us to create a dataset that represents better a real life situation or even better a more realistic displacement scenario in terms of case completeness moreover in the case of pdms where a rectangular cross sectional shape can safely be assumed there is an increased certainty in how the contact angle is calculated and accounted for especially for the in plane direction which is not optically visible the experiments in the pdms cell make it even possible to emphasize more the potential effect of the pore scale geometry and its correlation to an increasing deviation of the proposed fitting function for combining ca numbers as manifested in tables 3 and 4 5 research data the datasets are available in the data repository of the university of stuttgart darus the datasets vahid dastjerdi et al 2022b provide images of optical microscopy tif together with the pressure data csv moreover the cad design of the microfluidic cell is available credit authorship contribution statement samaneh vahid dastjerdi conceptualization methodology software validation formal analysis investigation resources data curation writing original draft visualisation nikolaos karadimitriou conceptualization methodology formal analysis investigation resources data curation writing original draft s majid hassanizadeh conceptualization formal analysis writing review editing supervision holger steeb conceptualization formal analysis writing review editing supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is funded by deutsche forschungsgemeinschaft dfg german research foundation under germany s excellence strategy exc 2075 390740016 we acknowledge the support by the stuttgart center for simulation science simtech hs and nk would like to thank the deutsche forschungsgemeinschaft dfg german research foundation for supporting this work by funding sfb 1313 project number 327154368 
60,in this work we provide a physically consistent modeling approach for two phase porous media flow by including percolating interfacial area and saturation as state variables for this purpose we combine two continuum theories for two phase flow which have been individually proven to be conditionally valid this means the potential use of the connected to the flow interfacial area as a state variable is tested utilizing time resolved microfluidic experiments for various flux boundary conditions moreover we observe and study a linear relation between the percolating saturation and interfacial area which is persistent for the tested boundary conditions in our microfluidic experiments we employ optical microscopy to perform cyclic immiscible displacement experiments our results show that a continuum model where capillary pressure saturation and specific interfacial area of the clusters connected to the flow are considered is closer to a universal description of two phase flow than the common approaches where the only state variable is saturation keywords microfluidic experiments two phase flow phase percolation interfacial area image processing optical microscopy data availability the data has been published on the depository of university of stuttgart the link is provided in the article 1 introduction defining the physical properties of a multi phase displacement process in a porous medium is a fundamental prerequisite in many porous media fluid flow applications such applications include but are not limited to many natural phenomena such as water infiltration parr and bertrand 1960 lipiec et al 2006 or saline water intrusion todd 1974 choudhury et al 2001 and those of industrial interest these include enhanced oil recovery eor muggeridge et al 2014 alvarado and manrique 2010 or fuel cells abdelkareem et al 2021 sharaf and orhan 2014 among others however the theoretical frameworks under which the underlying physical processes are attempted to be described and modeled have been efficient to a specific extent with the overall image still incomplete the empirical closure equations in common continuum theories such as leverett 1941 brooks and corey 1964 land 1968 or van genuchten 1980 include saturation or effective residual trapped saturation as the only state variable for example land 1968 obtains expressions for trapped and mobile non wetting saturation and shows that they can be used in the calculation of wet rock fluid properties such as relative permeability in these approaches the equations for saturation vs capillary pressure must have different coefficients for different displacement events to capture the history dependent characteristics of two phase flow in porous media given that the aforementioned macroscale i e continuum approaches are case and history dependent substantial theoretical numerical and experimental efforts have been made to come up with more physically based and representative modeling approaches these efforts mostly involve adding state variables other than saturation to the continuum scale models among the list of proposed new state variables are the area of the interfaces between the phases hassanizadeh and gray 1990 1993 a topological measure known as euler characteristic number herring et al 2013 schlüter et al 2016 miller et al 2019 mcclure et al 2020 and connection of the phases to the flow path hilfer 2006a b armstrong et al 2012 herring et al 2017 moreover several researchers identify and include more than one state variable at once osei bonsu et al 2020 vahid dastjerdi et al 2022a for example osei bonsu et al 2020 have experimentally shown that parameters such as the euler characteristic number the percolating volume fraction of the fluids and the fraction of the wetted solid surface are adequate to describe the phases state in their microfluidic experiments these parameters have been shown to provide practical solutions towards making reservoir simulations more efficient khorsandi et al 2021 however a practical approach based on continuum theories and their applications are yet to be identified in this study we are focusing on the approaches of hassanizadeh and gray 1990 1993 who introduce specific interfacial area as a separate state variable and hilfer 2006a b where percolating and non percolating volume fractions for each fluid phase are included as one can see the additional state variables in these two approaches are conceptually different in hassanziadeh gray s approach a new measure that accounts for the existence of interfaces is introduced hilfer s approach focuses on the connectivity of fluid phases and still works with the traditional volumetric measure namely saturation thus they take different phenomena in multi phase flow into account and can potentially be complementary we hypothesize that their combination can improve our description of multi phase flow in porous media hilfer points out challenges such as the inclusion of hysteresis and multivaluedness mirroring the dynamic effects in a process and the association of pore scale parameters with macroscale averages as the reasons behind the inefficiency of the common macroscopic theories he tries to overcome them by obtaining the capillary pressure function as an outcome of his theoretical framework and not as an input in this context he considers residual saturation as non percolating saturation which depends on the process and the initial boundary conditions he also differentiates between percolating and non percolating saturation in general in other words he introduces four saturation fields percolating and non percolating fractions of wetting and non wetting saturations instead of only wetting and non wetting a few numerical and experimental investigations have shown the potential of this theory hilfer and doster 2010 doster and hilfer 2014 hilfer et al 2015 however the extent of its validity under non equilibrium conditions has not been shown yet in the extended continuum mixture theory for porous media developed by hassanizadeh and gray 1990 1993 balance equations are developed for bulk phases for interfaces and for exchange processes over interfaces compared to classical continuum scale theories of porous media the interfaces per unit volume between the three phases wetting non wetting and solid as the locus of any potential phase energy exchange complement classical bulk state variables through safe assumptions for the fluid solid interfaces they reduce the essential state variables in their continuum theory to saturation and fluid fluid specific interfacial area many numerical and experimental investigations have shown that including this extra state variable improves the modeling of the apparent hysteresis in quasi static displacement events held and celia 2001 cheng et al 2004 joekar niasar et al 2008 niessner and hassanizadeh 2008 porter et al 2009 zhuang et al 2017 however the validity of this approach under transient flow conditions and for a wide range of capillary numbers has been questioned joekar niasar and hassanizadeh 2011 shokri et al 2022 for example karadimitriou et al 2014 investigate the theory under transient conditions experimentally with the use of microfluidics and direct real time visualization they show that the inclusion of the specific interfacial area between the two fluids can improve the hysteretic behavior during cyclic drainage and imbibition events they show capillary pressure saturation specific interfacial area creates a unique surface under given boundary conditions however different surfaces for different boundary conditions are needed this raises the question of whether another state variable in addition to specific interfacial area is needed to account for the effective complex pore scale fluid configurations on the macroscale motivated by the results of karadimitriou et al 2014 and inspired by the theoretical approach of hilfer 2006a b vahid dastjerdi et al 2022a perform a set of two phase displacement experiments to investigate the role of disconnections in the evolution of the flow they follow the extended continuum theory for two phase flow where specific interfacial area between the wetting and the non wetting phase is brought into the constitutive equations their experiments include flow controlled cyclic drainage and imbibition with three orders of magnitude variation in the volumetric fluxes and the corresponding ca number 10 7 to 10 5 they conclude that considering both interfacial area and percolating saturation of the invading phase in two phase porous media flow models can model the apparent hysteresis more efficiently this signifies that describing two phase flow with a single model is more feasible when both percolating saturation and interfacial area are considered as state variables however in their experiments the microfluidic cell they use facilitates strong corner film flow by construction the extent of the corner film flow is not observable and quantifiable with their experimental procedure and therefore a reliable saturation for the connected wetting phase is not measurable thus they only resolve the drainage events in terms of saturation capillary pressure and specific interfacial area between the wetting and the non wetting phase during the flow both on the micro and macro scale they imply that further studying of imbibition processes needs to be carried out in a microfluidic cell with very well defined connectivity of the wetting phase the cell should also allow for the precise calculation of the wetting phase saturation since the shadow caused by curved channel walls in glass microfluidic cells prevents the wetting phase occupancy from being captured thus the most feasible solution to take their investigations further is a microfluidic cell in which the permeability of the corners and the extent of films of the wetting phase is negligible taking advantage of the capabilities of soft lithography xia and whitesides 1998 karadimitriou et al 2013 and optical microscopy karadimitriou et al 2013 in the current contribution we are presenting a set of microfluidic experiments in a porous domain made of poly di methyl siloxane pdms the primary motivation behind these experiments is to investigate our hypothesis during imbibition while excluding the corner film flow effect for the wetting phase the structure of the pores of the pdms microfluidic cells along with pdms wetting properties prohibits the pronounced connection between the wetting clusters and allows us to define connectivity reliably from the images and address the imbibition processes as well however by shifting to pdms micromodels other aspects of the experiments are also changed and included for instance the geometry of the porous domain is slightly different in the pdms microfluidic cell in comparison to the glass micromodel used in vahid dastjerdi et al 2022a the pore throat pore depth ratio in the pdms cells differs from this in the glass microfluidic cells thus the corresponding entry capillary pressure for the same planar location is different in the two cells moreover due to the different manufacturing procedures the channel shapes differ the curved walls in the glass cell are replaced with almost perfect rectangular channels in cross section in the pdms microfluidic cell another aspect that is different in these experiments is the wetting properties of the employed fluid solid fluid system a concept known as lenormand s phase diagram lenormand et al 1988 should be mentioned to elaborate further on this matter lenormand et al 1988 perform drainage experiments with various viscosity ratios m between the non wetting phase as the invading fluid and the wetting phase as the defending fluid and different capillary numbers ca where 1 m μ n w μ w 2 c a μ n w q σ w n here μ n w and μ w are the dynamic viscosities of the non wetting and wetting phase pa s respectively σ w n is the interfacial tension between the non wetting and wetting phase n m and q is the darcy velocity m s in the experiments they categorize primary drainage processes into three distinguished regimes known through the shape of the displacement front based on the combination of the viscosity ratio and the ca number in a water pdms fluorinert system where fluorinert section 2 is the wetting phase and water is the non wetting one the viscosity ratio between the invading and the defending fluid during a drainage process is m 0 21 log m 0 7 in a glass porous medium however the wetting properties are inverse meaning that in a water glass fluorinert system water is the wetting phase in lenormand s phase diagram one can see that reversing the viscosity ratio can affect the displacement regime hence we are putting our hypothesis of a unique surface for all data points of saturation capillary pressure and specific interfacial area for connected clusters to the test for a precisely defined geometry in a hydrophobic microfluidic cell and for both drainage and imbibition a set of flow controlled microfluidic experiments consisting of six drainage and six imbibition events are carried out images from the displacement processes are recorded at fixed time intervals the images are processed with an in house developed tool based on matlab 2019 and the desired parameters such as saturation capillary pressure and interfacial area are extracted then eq 3 is employed to fit the data points from all terminal menisci between the wetting and non wetting phases for all displacement processes 3 a w n α s i n v β 1 s i n v γ p c r e v p a t m δ where a w n is the specific interfacial area 1 m defined as the total interfacial area of all wetting non wetting interfaces normalized over the bulk volume of the porous medium s i n v is the saturation of the invading fluid non wetting during drainage and wetting during imbibition and p c r e v is the rev scale capillary pressure p a t m is the atmospheric pressure assumed as constant in all experiments 1 0 5 pa parameter α has units of 1 m and parameters β γ and δ are dimensionless further the same fitting process is applied to the same dataset for the percolating phases only comparing the two fits through r 2 the coefficient of determination shows how significant the consideration of only the percolating saturation of a phase is in the attempt to uniquely model capillary pressure hysteresis we also observe a linear relationship between the saturation and the interfacial area in percolating clusters we show that this relationship is persistent characteristic of flow rates and independent of the number of displacement events the highly temporally and spatially resolved microfluidic experiments and their results presented here are complementary to the investigations published in vahid dastjerdi et al 2022a through these results we are able to complete our studies for a broader range of boundary conditions displacement types flow rates viscosity ratios and geometrical factors we show that a combination of two continuum theories theories from hassanizadeh and gray 1990 and hilfer 2006a has less dependency on the boundary conditions in comparison to each theory alone displacement types flow rates or viscosity ratios clearly and concisely 2 materials and methods the experimental methods are similar to the ones described in vahid dastjerdi et al 2022a minor differences are explained in the following sections 2 1 experimental setup the experimental setup consists of a customized optical microscope a microfluidic cell and a syringe pump apart from the microfluidic cell and the visualization settings the rest of the setup is similar to the one used in vahid dastjerdi et al 2022a in the following the varying characteristics of the setup are presented 2 1 1 microfluidic cell a micromodel made of pdms with cylindrical pillars serves as the porous medium in microfluidic experiments pdms micromodels are widely used in microfluidic experiments since they are flexibly producible by photo and soft lithography xia and whitesides 1998 karadimitriou et al 2013 in this work the depth of the cell is 55 μm and its pore size distribution varies between 75 μm and 250 μm with a mean size of 180 μm the cad design of the cell is available in vahid dastjerdi et al 2022b the total pore volume of the cell is 3 7 μl with a porosity of 50 the channels cross section is very close to perfect rectangles 2 1 2 visualization a basler aca2440 20gm monochrome camera is used in this work with a sensor size of 5 mpx and an acquisition rate ranging from 0 07 to 23 fps a 1 w led light source emitting at 590 nm mounted on an f 3 2 135 mm canon objective lens serves as the collimated illumination of the microscope the light is then redirected and collected through an edmund optics prism and a sigma f 1 8 135 mm tele lens towards the camera the region of interest is cut out from the full sensor size 2448 2050 for further processing the visualization as well as the acquisition properties of the experiments such as image acquisition rates and image size are listed in table 1 the spatial resolution in the experiments is 9 1 μ m p i x e l a detailed sketch of the setup can be found in vahid dastjerdi et al 2022a 2 2 two phase flow experiments the wetting and the non wetting phases are fluorinert 3m fluorinert fc 43 liquid viscosity 4 71 pa s density 1860 k g m 3 and water viscosity 1 pa s density 997 k g m 3 respectively since the two fluids are colorless water is dyed with a water soluble ink talens ecoline 578 liquid watercolor at a concentration of 50 the experiments are flow controlled and the volumetric flux is chosen to maintain the desired ca numbers for primary drainage the ca numbers are 10 5 10 6 and 10 7 and this is achieved through volumetric fluxes of 0 18 μ l m i n 1 8 μ l m i n and 18 μ l m i n as listed in table 1 starting with primary drainage micromodel initially fully saturated with fluorinert twelve sequential displacement processes of drainage and imbibition are performed in the micromodel by injecting 18 μl of each fluid into the microfluidic cell the volume of the fluids is chosen to be large enough ca five times the pore volume to establish a steady state flow after the breakthrough of the injected fluid both fluids are injected from one side of the cell through an inlet tube which is filled with fluid pulses before being connected to the micromodel fig 1 the twelve displacement processes primary drainage main imbibition and ten scanning curves are imaged at fixed time intervals as listed in table 1 moreover the inlet pressure is logged while having a constant head of a water column of 10 cm 1 kpa at the outlet as a back pressure the experiment with the largest ca number ca 1 0 5 has been carried out twice experiments 3 and 4 once with twelve displacement events and once with twenty four to investigate the role of system history on the variables investigated in this work 2 3 image processing details about image processing can be found in vahid dastjerdi et al 2022a the main difference between the two procedures image processing in the current work and in vahid dastjerdi et al 2022a is the mask used for segmentation as mentioned in 2 2 the pdms microfluidic cell is first saturated with fluorinert which is transparent similar to the solid phase thus segmenting the image into three phases is done with a mask where the pore space in an image from a fully saturated cell is colored and separated from the solid skeleton the rev size in the investigations is calculated as the smallest volume above which any changes in the average value of the considered parameter are negligible we investigate the rev size for porosity interfacial area and mean curvature the domain size which is an rev for all these parameters is in the order of 1120 1120 pixels 10 mm 10 mm as the imaged porous domain in our experiments is ca 2150 1300 pixels 11 mm 20 mm the middle part of the micromodel qualifies as at least one rev 2 4 post processing proceeding with the image processing techniques which yield parameters such as length curvature and contact angle of each interface rev scale parameters such as saturation total interfacial area and average capillary pressure are computed eqs 4 to 6 are employed to calculate the interfacial area of an interface i a i w n the local capillary pressure based on the three dimensional young laplace equation p i c and the macroscale capillary pressure p rev c 4 a i w n l i d cos α π 2 α where l i is the length of interface i m α is the contact angle in e z direction 56 during drainage and 58 during imbibition and d is the depth of the cell 55 μm the collective interfacial area of all interfaces in one image is the rev scale interfacial area associated with one image 5 p i c σ w n κ i 2 cos α d where p i c is the local capillary pressure at interface i σ w n is the surface tension between fluorinert and water which is equal to 55 m n m 2 κ i is the curvature of each interface in the e x e y plane 1 m the contact angle α in the e y e z direction is assumed to be equal to the mean value of the contact angles calculated in the e x e y plane for all interfaces fig 1 averaging the local capillary pressures over the interfacial area eq 6 delivers the macroscale rev capillary pressure 6 p r e v c σ p i c a i w n σ a i w n where a i w n is the area of interface i m 2 triplets of data containing the saturation of the invading phase the total specific area of the wetting non wetting interfaces and the rev scaled capillary pressure are formed for all clusters in the porous domain during flow the same procedure is carried out to extract the data for only the flowing clusters to quantify the affiliation of the data point with a single surface as we hypothesize a function as eq 3 is used to fit the data the goodness of fit in the form of r 2 is presented in section 3 3 results the first step in our investigations is to ensure that the pdms micromodels serve the purpose of this study for which we need to determine the connectivity of the clusters to the flow precisely to ensure the compatibility of the cell we observe the volume of several clusters detected as disconnected from the images for both phases during drainage and imbibition if a significant change is detected in their volume a connection that is not detectable with our image processing procedure for example through corner flow can be assumed if the volume of a cluster which visually looks disconnected from its neighbors does not change during flow it is considered an isolated cluster in fig 2 four wetting phase clusters are marked with red circles at different locations the images show the configuration of phase clusters in the micromodel at the end of a drainage event fig 2a and an imbibition event fig 2b the volume change of the four clusters during those drainage and imbibition events is studied since their volume changes only by 0 2 to 0 7 we assume the clusters are disconnected the same analysis is carried out for the non wetting clusters and as expected the volume change is in the order of the processing error given the above the connectivity of wetting and non wetting clusters at the scales relevant to this work is detectable from the images thus the recorded images during both imbibition and drainage are processed and the derived quantities are analyzed and presented in the following with the use of the image processing procedures described in vahid dastjerdi et al 2022a specific interfacial area capillary pressure and saturation are calculated for each image initially for all clusters and then only for the connected ones plots of specific interfacial area versus saturation gathered from the experiments are shown in figs 3a and 3b for all clusters and connected clusters respectively similarly figs 3c and 3d show the capillary pressure saturation data pairs from all clusters and connected clusters respectively it is evident that the data for connected clusters show better behaving trends the apparent linear dependency of the specific interfacial area on the saturation for the connected clusters the increase in the slope of this linear dependency and the reduction in the variability motivate us to look into their relationship more thoroughly in fig 4 this relation is investigated in the experiment with ca equal to 10 5 and for drainage and imbibition separately during primary drainage the specific interfacial area grows linearly with saturation with a slope of 675 1 m however the slope increases as the experiment evolves and reaches 1540 1 m for the eleventh scanning curve for imbibition the corresponding slope steadily increases from the minimum value of 610 1 m for the main imbibition to the maximum value of 1370 1 m for the last imbibition process in addition it is noteworthy that the difference between the two processes reduces as the number of displacements history of the system increases observations of the other two experiments also reveal the same pattern the slope is always between 230 1 m to 1540 1 m with the lowest value being associated with the main imbibition of the slowest experiment ca 1 0 7 and the highest value corresponding to the last drainage of the fastest experiment ca 1 0 5 the slope of the fitted line for connected clusters seems to stop increasing after some scanning events resulting in a unique domain that accommodates all the specific interfacial area values to verify this hypothesis the experiment with the ca number 10 5 is repeated with 24 cycles instead of 12 in fig 5 one can see the specific interfacial area generated between the wetting and the non wetting phase for clusters connected to the inlet during both sets of experiments thus the domain of the set of state variables a wn s seems to be well defined for a single ca number and a given porous medium with this second experiment we also investigate the dependence of the interfacial area on the pore structure in an experiment where the capillary forces are not dominant the ca numbers for the experiments are chosen so that a transition between capillary fingering and viscous fingering is expected based on lenormand s phase diagram our results show that even in an experiment that is not fully capillary dominated log ca 5 and log m 0 7 the generation of interfacial area is the same as long as the porous medium stays the same we also observe that the more displacement events happen in the microfluidic cell the less the change in the produced interfacial area is which implies the formation of preferential flow paths after some cycles the formation of preferential paths could be interpreted as forming an effective porous medium slightly different during drainage and imbibition events although the displacement events are executed 24 times in the second trial with ca 1 0 5 the specific interfacial area stays in the range of the first trial investigating this observation in other case studies can help us estimate the s a w n curves in various phenomena where the displacement events happen repeatedly fig 6 examples are the cyclic wetting and drying of soil zhao et al 2018 fluids displacement in fuel cells andersson et al 2016 niblett et al 2020 subsurface storage of compressed air caes zhang et al 2020 or hydrogen tarkowski 2019 following the procedure described in section 1 eq 3 is fitted to the data point triplets from one displacement process this work s main interest is finding the state variables of a two phase porous medium flow independent of the viscosity ratio of the fluids the displacement process drainage or imbibition and the ca number putting all the data points from drainage and imbibition during one experiment together serves the purpose of studying our hypothesis on the type of displacement process moreover the results from analyzing the combination of the data from the experiments with various ca numbers indicate the dependency of the hypothesis on the ca number in other words the data from experiments with ca numbers 10 7 and 10 6 are combined and the same fitting process is applied similarly combinations of the experiments with ca numbers 10 6 and 10 5 as well as the experiments with ca numbers 10 7 10 6 and 10 5 are studied the experiment with ca number 10 5 is chosen as an example and the goodness of fit in the form of r 2 is presented in table 2 the experiment with the capillary number of 10 5 is chosen as a more representative example since a significant viscous contribution to the flow regime is expected thus there is a larger number of disconnections and consecutively increasing the probability of establishing preferential flow paths for fewer cyclic events the r 2 values illustrate the nearly perfect fitting of eq 3 to the single displacement processes when only the clusters connected to the flow are accounted for the r 2 values in the last row of table 2 show how much the fitting is improved for connected clusters for a dataset containing drainage and imbibition displacements the effect of ca number on the fitting is presented in table 3 the r 2 values listed in table 3 make it clear that the fitting improves when only the data from connected clusters are considered this is especially of interest for the most transient experiment where the fitting for all clusters is bad the better fit in the case of connected clusters supports the hypothesis that connectedness and specific interfacial area should both be involved in theories related to two phase flow furthermore a glance at the results presented in vahid dastjerdi et al 2022a for a viscosity ratio of 0 21 see table 4 is an indication of the validity of the theory independent of the viscosity ratio comparing tables 3 and 4 one can see that the fit improves for the connected clusters in comparison to all clusters for both viscosity ratios of 4 7 and 0 21 in addition to the ca number viscosity ratio and displacement process there is evidence in our results that this hypothesis holds for various geometries the evidence comes from the fact that the hypothesis is consistent in two relatively different geometries as the geometry the pore throat pore depth ratio and shape of the channels of the pdms cell used in this study is different from the glass micromodel used in vahid dastjerdi et al 2022a however the effects of the geometry on the fitting parameters must be addressed thoroughly in future research as described in section 1 in this work the existence of a single surface for p c s a w n is investigated in particular we have fitted eq 3 to various datasets with different ca numbers and or their combinations and have obtained values for the parameters α β γ and δ the resulting equations for all clusters and connected clusters are given in eqs 7 and 8 respectively these equations are formed by substituting the values of parameters α β γ and δ as calculated for all data from the three experiments in eq 3 7 a w n 0 034 s i n v 1 11 1 s i n v 0 485 p c r e v p a t m 2 53 8 a w n 14 53 s i n v 1 17 1 s i n v 0 38 p c r e v p a t m 1 we use these equations to calculate specific interfacial area for all experimentally measured values of saturation and capillary pressure and compare the calculated values with the corresponding measured values of specific interfacial area in fig 7 it can be clearly seen that eq 8 for connected clusters only does a better job in predicting measured values of specific interfacial area than eq 7 for all clusters note that the data from the three experiments are not distributed in the same pattern one can see that the experiments with ca numbers 10 6 and 10 7 are better captured by eq 8 than the experiment with ca number 10 5 this could again be associated with the growing viscous effects in the experiments and the corresponding pore scale velocity fields 4 discussion and conclusion the linear relation between the saturation of the invading fluid and the specific interfacial area is characteristic of almost all displacement regimes the data points include pairs of specific interfacial area and saturation from four experiments two of which with ca numbers 10 7 and 10 6 seem to be in the capillary regime based on the work from lenormand et al 1988 and fall on top of each other the other two experiments with ca number 10 5 are also similar regardless of the number of displacement events fig 6 these observations imply that the specific interfacial area associated with the connected clusters in a porous medium fall within a domain boundary by two straight lines one corresponding to the main imbibition and the other to the last scanning drainage event one can see in fig 5 that the rate of change of the specific interfacial area vs saturation in the clusters connected to the inlet stays almost constant after the main events main drainage and main imbibition this is regardless of the number of displacement events and happens for both experiments 3 and 4 moreover in some processes the re connection of some disconnected clusters causes discontinuities in the data points however the slope of the linear relation of the specific interfacial area and saturation is preserved see main drainage in fig 4a or main imbibition in fig 4b moreover with the results presented here we show that the description of a two phase system can be drastically improved from a continuum perspective when specific interfacial area and at the same time discrimination between connected and disconnected clusters are considered for a range of ca numbers all triplet data points of saturation capillary pressure and interfacial area can be fitted with a surface although for increasing boundary flux conditions considering only the interfacial area seems to reach a conceptual limitation see r 2 values for all clusters in table 3 the r 2 values for connected clusters show a much smaller dependency on flow rates there is however a strong deviation from an ideal fitting when combining various ca numbers thus to be able to find a single description for two phase flow that fits all boundary conditions additional parameters or even state variables are needed nevertheless there is an essential improvement in the fitting when in addition to interfacial area the connectivity of the phases is also considered the r 2 increases from 0 33 to 0 70 still not ideal when all experiments are analyzed as one dataset table 3 given the results of this work the logical next step would be to evaluate our proposed combination of two continuum scale theories for the effect of the geometrical factors this includes the investigation on the pore scale of how local constrictions favor or not disconnections due to the interplay between capillary and viscous forces thus further research with a variety of pore scale geometries and also the corresponding pore and throat size distributions as well as the networks correlation lengths and coordination factors should be carried out in correlation to the work from vahid dastjerdi et al 2022a we need to emphasize the cross sectional shape s comparative effect on flow evolution mainly regarding the connectivity of the wetting phase the channel properties of the pdms microfluidic cell and its wetting properties restrict the connection of the wetting phase and thus allow for the inclusion of imbibition in the results without any biasing the addition of imbibition allows us to create a dataset that represents better a real life situation or even better a more realistic displacement scenario in terms of case completeness moreover in the case of pdms where a rectangular cross sectional shape can safely be assumed there is an increased certainty in how the contact angle is calculated and accounted for especially for the in plane direction which is not optically visible the experiments in the pdms cell make it even possible to emphasize more the potential effect of the pore scale geometry and its correlation to an increasing deviation of the proposed fitting function for combining ca numbers as manifested in tables 3 and 4 5 research data the datasets are available in the data repository of the university of stuttgart darus the datasets vahid dastjerdi et al 2022b provide images of optical microscopy tif together with the pressure data csv moreover the cad design of the microfluidic cell is available credit authorship contribution statement samaneh vahid dastjerdi conceptualization methodology software validation formal analysis investigation resources data curation writing original draft visualisation nikolaos karadimitriou conceptualization methodology formal analysis investigation resources data curation writing original draft s majid hassanizadeh conceptualization formal analysis writing review editing supervision holger steeb conceptualization formal analysis writing review editing supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is funded by deutsche forschungsgemeinschaft dfg german research foundation under germany s excellence strategy exc 2075 390740016 we acknowledge the support by the stuttgart center for simulation science simtech hs and nk would like to thank the deutsche forschungsgemeinschaft dfg german research foundation for supporting this work by funding sfb 1313 project number 327154368 
61,the morphological approach is a computationally attractive method for calculating relative permeability and capillary pressure saturation functions in the corresponding workflow morphological operations are used to calculate the fluid phase distribution in the pore space of a digital twin once the pore space is occupied the conductivity of the individual fluid phases and thus the relative permeability can be calculated by direct flow simulations it therefore combines computationally favorable geometric operations with direct flow simulations in contrast to pore network modeling all calculations are directly performed on the digital twin without abstraction of the pore space while the morphological operations conceptually correctly describe primary drainage processes and delivers good results the method so far failed to describe imbibition processes and the influence of wettability in this work we implement contact angle distributions in a deterministic and stochastic way in this manner we extend the simulated saturation range from purely spontaneous to forced imbibition resulting in a full range imbibition relative permeability furthermore by introducing stochastic contact angle distributions different fluid phase distributions are obtained which now allow for an uncertainty analysis to verify the simulation results we check a whether the simulation results agree with scal measurements and b compare morphologically and experimentally derived results on the pore scale with the newly introduced concepts the imbibition process behaves as physically expected and shows a good agreement with experimentally derived relative permeability curves and microscopic fluid phase distributions data availability data will be made available on request 1 introduction digital rock physics drp has become increasingly attractive for computing multiphase flow properties compared to classical special core analysis scal experiments drp appear to be less time and labor intensive and hence cost competitive furthermore only small rock samples are needed therefore dr analysis can be applied in situations in which there are no suitable scal samples available drp may be categorized by the way flow and displacement physics are implemented in full and reduced physics models full physics models provide deep insights into displacement physics and are performed on the actual rock structure the digital twin yet are typically computationally expensive and therefore have limited use in upstream developments pan et al 2004 chukwudozie and tyagi 2013 boek et al 2017 methods such as lattice boltzmann are able to model the actual visco capillary effects on the pore scale and therefore can reproduce experimental displacement results outside capillary limits alpak et al 2018 however their limitation lies within the possibility of varying petrophysical parameters such as the wetting state of a system as the simulations are highly time consuming reduced physics models on the other hand are often computationally attractive allowing for a larger number of simulations and hence for uncertainty analysis these models simplify or abstract reality in one way or the other prominent examples are pore network models pnms which handle displacement physics in a rule based fashion on idealized pore networks the phase conductivities are computed by solving specific analytical solutions rather than the underlying differential equations blunt 2001 zhao et al 2019 joekar niasar and majid hassanizadeh 2011 in pnms the idealized pore networks are extracted by calculating network properties pore volumes and pore throat sizes from digital rock structures with different authors using different algorithms dong and blunt 2009 gostick 2017 lindquist and venkatarangan 1999 silin and patzek 2006 however all these algorithms are in principle based on morphological operations the morphological method mm silin and patzek 2006 serra 1983 hilpert and miller 2001 as presented in the following makes use of morphological operations to directly calculate the fluid phase distribution in the digital twin rather than to extract an idealized network in this manner the mm bridges both worlds it makes use of morphological operations to populate the as measured pore space with the fluid phases and directly solves the navier stokes equation of the pore space to simulate effective permeability the morphological operations are applied in a rule based quasi static manner so that no time scale is associated with the displacement process since they are applied to the pore structure the modeled displacement processes refer to a capillary dominated flow viscous processes are not considered however the fact that the displacement processes are purely calculated on the basis of image processing makes the mm very time competitive when simulating drainage processes liquid invasion is controlled by the dilation of the mineral phase of the digital twin pore throats are then identified and connectivity to neighboring pores is tested for each dilation step assigning an interfacial tension to fluid fluid interfaces and a contact angle to mineral fluid fluid three phase contact lines allows the capillary pressure to be calculated for each dilatation step i e for different saturations by the young laplace equation comparison with experimental data shows close agreement for drainage processes while there are significant discrepancies reported for imbibition berg et al 2016 the relative permeability is then simulated by solving the navier stokes equation of the pore space connected by the individual fluid phase this limits the two phase flow to the connected phase volume dynamic effects such as ganglion dynamics which may contribute to the nonwetting phase mobility especially in the case of high wetting phase saturations are therefore not considered rücker et al 2015 armstrong et al 2016 to date the mm has delivered good results for drainage but has shown limitations in terms of imbibition processes and uncertainty modeling in particular imbibition processes were limited since only individual processes either forced drainage or spontaneous imbibition processes could be modeled the forced part of the imbibition was therefore not previously incorporated in this work we implement contact angle distributions in a deterministic and stochastic way in this manner we extend the imbibition process from purely spontaneous to forced imbibition resulting in full range imbibition capillary pressure pc swp and relative permeability kr swp saturation functions furthermore by introducing stochastic contact angle distributions different fluid phase distributions are obtained which allows for uncertainty analyses to verify the simulation results we check a whether the simulation results agree with those from scal measurements and b compare the morphological results with experimentally derived results 2 numerical methods and developments 2 1 morphological method the mm is based on mathematical morphology and applies morphological operations to pore scale rock images it was originally developed by matheron and serra in 1964 for serra s phd thesis and later published in serra et al 1983 serra 1983 the basic dilation and erosion operations applied to the rock s pore structure enable the quantitative analysis of pore geometries with regard to the drainage displacement thresholds the pore throats the morphological identification of thresholds links the pore structure to capillarity and hence to fluid displacement physics the mathematical fundamentals are discussed in detail in hilpert and miller s paper from 2001 hilpert and miller 2001 initially the approach was limited to binary images but it can also be applied to grayscale images heijmans 1995 a derivative the pore mm also known as maximum inscribed spheres silin and patzek 2006 predicts the distributions of a wetting phase wp and a nonwetting phase nwp inside a porous medium in general the mm predicts saturation changes on the basis of geometrical rock properties and therefore intrinsically assumes that capillary forces dominate compared to viscous forces i e it describes displacements at low capillary numbers the method therefore distributes the two fluid phases by using morphological operations rather than solving partial differential equations a criterion for a displacement event is the disconnection to the respective wetting and nonwetting reservoir attached to the system boundaries for imbibition and drainage we refer to the invasion of the wp and the nwp respectively the image operations change the topology of the fluid phases which corresponds to the physical event of a capillary pressure change where the extent of the dilation operation corresponds to the pore throat radius in the young laplace equation fig 1 shows the displacement of the wp blue by the nwp green for a single contact angle gray and two contact angles gray and brown respectively to the mineral phase the number of dilated voxels describes the radius r which corresponds to the pore throat size in a drainage process different contact angles are introduced after schulz by scaling the dilation radius with cos θ with θ being the contact angle schulz et al 2015 this method slightly overestimates the actual contact angle and does not work for contact angles close to 90 2 2 initial drainage and spontaneous imbibition implementations a primary drainage is defined as the displacement of the wp by the nwp the process is described by a sequence of equilibrium steps which mimic the invasion as a consequence of an applied differential pressure and flow restrictions the pore throats a sequence of three operations corresponding to a single displacement event is shown in fig 1 it illustrates a simplified 2d porous structure with circular grains shown in gray and the pore space filled with a wp blue in the steps from images a to b grains are dilated white to identify and close the narrowest pore throats defining the nwp reservoir on the left hand side of the image the invaded nwp is connected to the nwp reservoir and recolored dark green this step identifies the pore space filled with nwp the dilatation radius r corresponds to a critical pore throat radius and the corresponding capillary pressure which is given by the young laplace equation pc 2σ cos θ r where σ denotes the interfacial tension and θ the contact angle in the next step the nwp is dilated light green by the same voxel radius as the grains that were dilated in the prior step since in a drainage process the nw fluid first invades the larger pore throats the invading fluid green phase cannot overcome the first pore throat which is indicated in image c the right hand side of fig 1 d f shows that the approach can be modified by the introduction of a different mineral with a modified contact angle brown when applying multiple contact angles for the same scenario the invading phase can overcome the same pore throat since the dilation is scaled by cos θ light brown which results in different invasion pathways for the same applied pressure furthermore as observable in image f the contact angle of the nwp green is different for both materials in this process the invading nwp must in every step be connected to the inlet phase which is the nwp reservoir and the wp to the outlet the wp reservoir the algorithm of the above described morphological drainage process is schematically illustrated in fig 2 with a simple 2d pore structure the process consists of four steps 1 dilation 1 dilate grains into the wp saturated pore space by a voxel radius r which can be scaled by cos θ 2 connectivity 1 recolor the pore space that is connected to the nwp reservoir and label it nwp 3 dilation 2 dilate the nwp by the initial nonscaled voxel radius from step one 4 connectivity 2 identify all wp disconnected from the wp reservoir as residual it will no longer be considered for further displacement calculations the last step allows for residual saturation and may be ignored when simulating mercury injection capillary pressure experiments ahrenholz et al 2008 performing the drainage algorithm by gradually decreasing the radius r number of voxels results in a quasi stationary invasion of the nwp scaling the dilation radius in step 1 by cos θ alters the invasion pathway with regard to the wetting condition when contacting a nonwetting material the pore space would immediately be populated by the approaching nwp the interfacial tension is accounted for only in postprocessing for calculating pc and therefore results only in an up or down shift of the pc curves but does not influence the resulting fluid distribution a drainage process is either stopped when the wp is entirely disconnected from the outlet or the dilation reaches the voxel size the basic algorithm for drainage can be modified to simulate imbibition processes by interchanging steps 2 and 3 and by exchanging nwp and wp but in dilation step 2 the process is illustrated in fig 2 1 dilation 1 dilate grains into the nwp saturated pore space by a voxel radius r which can be scaled by cos θ 2 dilation 2 dilate the nwp by the initial nonscaled voxel radius from step one 3 connectivity 1 recolor the pore space that is connected to the wp reservoir and label it wp 4 connectivity 2 identify all nwp disconnected from the nwp reservoir as residual it will no longer be considered for further displacement calculations this new sequence of algorithm steps results in a displacement characteristic that is controlled by pore body dimensions rather than by the pore throat size for drainage the algorithm controls the retracting nwp which is predominantly located in larger structures such as pore bodies therefore the process is more controlled by the pore bodies than the pore throats the fluid fluid interfaces are located at positions at which the curvature corresponds to the dilation radius which corresponds to the simulated capillary pressure this defines the stopping criterion for the displacement by the curvature and properly defines an imbibition process an imbibition front stops when either the nwp is disconnected from the nwp reservoir or the dilation radius exceeds the size of the largest pores i e allowing no further fluid phase changes and nonwetting material cannot be bypassed anymore by the wp which means it acts as a barrier 2 3 simulation of effective permeability the pc swp saturation function is a direct result of the mm i e a purely structural property furthermore the mm delivers the fluid distribution in the pore space for each simulated saturation state and hence information on the connectivity of both phases the mm however does not directly deliver permeability and kr swp the absolute permeability k is simulated by solving the stokes equation of the total pore space assuming single phase flow for a small constant pressure drop in the flow direction in the present case δp 0 02 pa and periodic boundary conditions in the tangential direction due to our focus on very slow flows and the corresponding small pressure drops we solve the stokes equation instead of the navier stokes equation as it delivers the same results while being computationally less demanding the effective permeability kr swp k is simulated for each fluid phase separately considering the respective connected pathways only this means that kr swp simulations consider the respective other phase as immobile i e all internal boundaries as rigid and fixed with this we ignore viscous momentum transfer between the fluid phases which means that the movement of one phase is not affecting the respective other fluid phase blunt 2017 hence we ignore effects like ganglion dynamics furthermore kr swp can be calculated only in cases where the respective fluid phase is connected throughout the simulation domain at the given saturation state otherwise it is zero a snap off event can therefore lead to the loss of phase conductivity while the phase is still accessible for a displacement event as it is connected to the outlet fig 3 shows the general workflow on how the relative permeabilities are obtained from the morphological populated phases 2 4 limitations of the initial implementation as described earlier the mm is based on geometric operations on digital rock structures and is therefore entirely governed by the porous structure and if present the residual fluid phases this describes the nature of a primary drainage process quite well as the nwp intrusion is restricted by the pore throat radii which are inversely correlated to the capillary pressures however processes such as imbibition are partly spontaneous and driven by interfacial properties such as the wetting state and contact angle distribution how well does the mm capture these physical processes for a single contact angle the invading fluid always takes the pathway through the porous domain independent of the contact angle this means that a contact angle variation will not alter the invasion sequence and the resulting fluid distribution and therefore will not change the relative permeability curves the implementation of multiple contact angles was addressed by schulz et al schulz et al 2015 hereby the invasion process is altered by scaling the dilation radii with cos θ however limiting the system to contact angles below or above 90 as there the dilation goes to zero contact angles below 60 and above 120 show only minimal numerical errors the introduction of multiple contact angles allows for variating displacement pathways after all the imbibition process as given above is still limited to the spontaneous part of the capillary pressure curve i e to the positive p c range which results in a limited saturation range to date one of the stopping criteria is a disconnection of the nwp from the nwp reservoir we typically describe the flow in a single direction and therefore assign the lateral boundary conditions as periodic while the inlet is connected to a wp reservoir and the outlet is connected to an nwp reservoir hence the invasion process can result in an early snap off early disconnection of the nwp while leaving a larger part of the saturation as residual this results in a drastic reduction of the nwp effective permeabilities and an increase for the wp 2 5 full scale imbibition while the drainage process is defined as the invasion of the nwp i e indicated by an entirely positive capillary pressure imbibition processes can show an early saturation range of positive and a late saturation range of negative capillary pressure a negative capillary pressure indicates a forced process which can actually be understood as a drainage process therefore to simulate the full saturation range with the pore mm we first couple the imbibition process with a subsequent drainage process the stopping criteria of the spontaneous imbibition si process is the disconnection of the nwp from the outlet the nwp is trapped and cannot be displaced either by an imbibition or by a drainage algorithm to switch from a spontaneous to a forced process a nonwetting material must be introduced which prevents access to parts of the pore space by the spontaneous process this may be physically correct because it reflects the meaning of a negative capillary pressure a straightforward implementation is the introduction of nonwetting material before the start of si modeling depending on the topology and volume of the nonwetting material introduced the si stops at different saturation stages in this work the nonwetting material is introduced in two alternative ways 1 the introduction of a nonwetting material on the basis of a stochastic field before the drainage process this ensures that the nonwetting material is in contact with the nwp at the end of the drainage process 2 the introduction of nonwetting material at the end of the drainage process in nwp filled pores only prioritizing the largest pores first in the stochastic approach the volumetric percentage and region size considered for the stochastic field are defined the material is then implemented on the basis of an isotropic gaussian random field fig 4 shows the exemplary implementation of nonwetting materials with two different region sizes in both cases the same random seed was chosen whereas one region size was smaller and the other was larger than the average visible grain size depending on the region size and solid volume percentage svp considered unavoidably the introduced material can be interconnected throughout the structure the volume percentage of material changed equals the surface area percentage between the pore and solid materials with minor deviations the deterministic approach is based on the natural process of a wettability alteration during an aging process where mineral surfaces in contact with the nwp can change their initial wetting state rücker et al 2020 hirasaki et al 1990 abdallah et al 2007 it applies an algorithm at the end of a drainage process analyzing the pore size distribution and introducing nonwetting material in the largest pores first only where the mineral and nwp meet in the algorithm we define the volume of pores considered for the implementation the volume fraction considered does not equal the surface area fraction as only a part of the pore material is changed see fig 7 fig 5 illustrates the algorithm on a simplified structure the different pore sizes are displayed as volume fields scaled by a hue saturation lightness color legend where blue represents the smallest pores and red the largest pores in the second illustration the pore space which is considered by the algorithm is marked in red the pore space considered is currently a user input and can be varied between 1 and 99 the last two images show the resulting material changes where only material in contact with the previous marked pores is considered while prioritizing the material in the larger pores this algorithm has the advantage that different nonwetting contact angles can be introduced at the end of the drainage the forced imbibition fi part is then modeled with the drainage algorithm where the contact angles and the role of the phases are inverted this means that a nonwetting contact angle is considered to be wetting i e 180 α for the fi drainage process while swapping the roles of the wp and nwp this corresponds to a turnover of the menisci between the wp and nwp at the transition from the spontaneous to the forced displacement process 2 6 comparison to experimental data a steady state experimental data set berg et al 2016 was used as a reference for benchmarking the data set consists of a time series of pore scale resolved fluid distributions with which nwp and wp effective permeability can be simulated and directly compared to the respective results from the mm this benchmark was carried out by berg et al and is repeated in the present work with and without the described modifications in the mm while in the earlier study the relative permeability simulated on the numerical and experimental fluid distributions shows a substantial mismatch with the embedded innovations a close match could be achieved as discussed in the results section 2 7 simulation input the uncertainty analysis for the contact angle distributions was performed on berea sandstone with dimensions of 800 800 800 voxels and a voxel size of 1 84 µm 3 voxel the digital rock sample has a resolved porosity of 19 6 and a simulated permeability of 780 md the synchrotron mct based experiment by berg et al was conducted on gildehauser sandstone with an average resolved porosity of 20 and a permeability of 1 5 0 3 d for the comparison to simulations on the experimentally derived fluid distributions the presegmented data set from the digital rocks portal was used berg et al 2018 the digital twin has a resolution of 4 4 µm 3 voxel and consists of a cylindrical domain with dimensions of 830 830 566 voxels the digital twin has a porosity of 20 3 and a simulated permeability of 1 55 d 3 results to test the innovations introduced in this work we use the new degrees of freedom to define and vary the wetting state and simulate different scenarios first we simulate capillary pressure curves on a digital twin for berea sandstone with this we compare the results for the stochastic and deterministic implementation and for different wetting states to assess the trends in the pc swp on a physical basis second we compare the new approaches with experiments by simulating kr swp for experimentally and morphologically determined fluid distributions while varying the simulated wetting states 3 1 full scale imbibition and introduction of a nonwetting material in the previous section we introduced two principally different algorithms for the implementation of a nonwetting material a stochastic algorithm and a deterministic algorithm for the stochastic algorithm the nonwetting material is introduced prior to the drainage process which ensures that the nonwetting pores are filled with the nwp at connate wp saturation with regard to the subsequent imbibition process the higher the svp of the nonwetting region is the earlier the spontaneous imbibition is stopped and the larger the contribution of the forced part to the total imbibition process furthermore the region size chosen is critical as it influences drainage and imbibition in fig 6 left we can observe these changes whereby an increasing svp and decreasing region size resulted in a greater nonwetting state of the system the dark yellow symbols which partly overlap with the newly modeled data sets show the results of the initial drainage and spontaneous imbibition implementation in this case only one wetting contact angle was assigned and therefore only spontaneous imbibition was modeled to make the data comparable the same contact angle set of 40 for the wetting material and 140 for the nonwetting material was used three different nonwetting svp settings 10 20 30 with two different region sizes 10 and 100 μ m were modeled resulting in an additional 6 scenarios while the residual wp saturation was rather unaffected the residual nwp saturation decreased with increasing svp and decreasing region size which is consistent with the proportion of spontaneous to forced imbibition an increasing volumetric proportion svp of nonwetting material resulted in a greater nonwetting trend the region size on the other hand displayed an opposite trend where a decrease in the region size led to an earlier inhibition of spontaneous imbibition this is a result of the spatial distribution of the nonwetting material even though the surface area of the nonwetting material is approximately the same for both region sizes there were more pores that were affected by the nonwetting material consequently the available pore space for invasion during the spontaneous process was reduced the effects of the region size and the contact angle spatial distribution were large they determined whether the overall system was water wet or oil wet which was directly recognized by comparing the positive and negative areas under the imbibition p c curve indicated by the shaded areas for the svp 30 cases in fig 6 which is linked directly to the work the system does to the environment spontaneous and positive and the work the environment does to the system forced and negative the ratio corresponds to the wettability index when taking the logarithm of that ratio similar to the u s bureau of mines usbm wettability index positive values indicate wetting behavior as spontaneous work is larger than forced work and vice versa donaldson et al 1969 another indication is delivered by the amott water wetting index which compares the spontaneously imbibed saturation range to the total imbibed saturation amott 1959 the values range from 0 to 1 where an increasing value indicates more wetting behavior both indices deliver similar trends when plotted against the region size however when directly comparing them the amott wetting index shows less of a wetting trend than the above defined wettability index wi this results from the definition of the indices as we have a reduced threshold for the forced imbibition similar to the primary drainage as regions of nonwetting material are already assigned throughout the system therefore the work necessary for nwp displacement is reduced in fig 7 the wettability indices for different svp values are plotted against the region size assigned for the nonwetting material as well as the volume fraction of the pore throat diameter of the digital rock sample the 30 svp system with a 10 μm region size is characterized as nonwetting and the system with 100 μm as wetting as indicated by the wettability indices of 0 51 and 0 34 respectively which is in accordance with the amott wetting indices of 0 12 and 0 52 respectively furthermore it can be observed that both the svp and region size have a distinct influence on the wettability of the system the region size is correlated to the pore throat size when it is smaller or equal to the average pore throat size the introduced nonwetting material can deny access to a majority of the pores during the spontaneous imbibition process therefore for the same svp a smaller region size leads to lower wettability indices as the small patches are equally distributed throughout the system on the other hand larger region sizes allow bypassing while restricting entire areas for population overall qualitative changes in the indices clearly indicate the wettability changes of the system it is worth mentioning that the drainage curves are also affected for smaller region sizes more work is required to desaturate the system if the region size is smaller the reason for this may be that with larger region sizes some pores are wetting to the nwp and therefore a fraction of the volume can be easily invaded by the nwp in the deterministic approach the nonwetting material is implemented at the end of the drainage process which leaves the drainage process itself unaffected therefore unlike in the stochastic approach all imbibition scenarios start from the same point drainage endpoint despite the substantial differences of both algorithms their trends are similar with regard to forced imbibition and the residual nwp saturation however as discussed above the exact nwp distribution after drainage determines the nonwetting material distribution the right panel of fig 6 shows the results when assigning nonwetting material while considering 5 50 and 95 of the entire pore space the larger the pore space considered psc for turning into nonwetting material the more likely the systems are to behave in a nonwetting manner this is displayed by lower residual nwp saturations and larger areas under the negative p c branch when considering almost the entire pore space the 95 case in fig 6 there was not any spontaneous imbibition as the wp front does not have any available space for advancing spontaneously since it is immediately confronted with nonwetting material for systems with low psc the spontaneous imbibition follows the original trend as only a small portion of the system is unavailable for the invasion sequence generally both algorithms display similar trends with an increasing volume of nonwetting material introduced however the shape and p c quantity differ significantly as the deterministic population does not influence the required work for displacement as much as the stochastic approach the prioritized introduction within the larger pores restricts the wp from entering single pores whereas in the stochastic approach depending on the region size chosen entire areas might be restricted therefore the resulting p c values can differ greatly between the two processes in fig 7 the wi and amott wetting indices are plotted against the psc for the deterministic approach they show the same trends of less wetting behavior with regard to the volume of implemented nonwetting material however it can be observed that the trends for the indices differ as the work required for displacement correlates with the surface area volume of the nonwetting material while the saturation endpoints are rather a result of the psc an evident difference in the imbibition pc curves simulated with the mm and common laboratory pc curves is the abrupt pc drop at the transition from the spontaneous to the forced part of the curves across the pc 0 condition we believe that this discontinuity is physically correct and is a result of a a discrete contact angle distribution and b the finite size of the digital twin at the point at which imbibition changes from spontaneous to forced all the pore space that can be spontaneously invaded is invaded at that point the interfacial curvature locally flips from concave from the perspective of the wp to convex with only a negligible saturation change during the flip the system crosses the pc 0 condition therefore this discontinuity may be mitigated a by a continuous contact angle distribution and b by investigating macroscopic system sizes as for classical pc measurements with regard to a it depends very much on the reason for contact angle variation whether it is due to mineral to mineral variation or due to aging or both in all cases the contact angle distribution may be discontinuous with regard to b the mm and pc measurements are based on fluid invasion processes we assume that one process locally dominates i e spontaneous or forced imbibition however for larger sample domains at a given time and at different positions there are slightly different saturation states this smoothens experimentally derived pc curves for an average saturation state we observe that this point has no influence no discontinuity on the simulated relative permeabilities 3 2 sensitivity to the contact angle to study the sensitivities to the implemented contact angles of imbibition pc and kr the deterministic approach is used where the material is implemented at the end of the drainage process this guarantees better comparability as the drainage process is not affected by the nonwetting contact angle in contrast to the initial implementation two contact angles are assigned resulting in a material distribution with the initially assigned wetting contact angle and with a modified contact angle the modified areas are those prioritized by the primary drainage process to be in contact with the nwp material a certain volume percentage of the prioritized area is then assigned to nonwetting contact angles while drainage is determined by the wetting contact angle only imbibition is sensitive to both unless otherwise stated and for comparability the chosen pore space considered 50 is the same for all simulations the left panel of fig 8 shows the results by variation in the wp contact angle by leaving the nwp contact angle constant both curves drainage and imbibition are affected with increasing wp contact angle less pressure is required for the nwp to enter the pore space the pc curve is lowering regarding imbibition a contact angle increase lowers the saturation range for the si and decreases the residual nwp saturation these are clear indications of a lower wetting behavior of the system which is expected when applying a higher contact angle to the wp furthermore it can be observed that the shape of the forced imbibition curve is not influenced as it is governed entirely by the nonwetting contact angle the earlier the forced imbibition begins the larger the overall saturation range this behavior is expected from scal measurements and is also reflected in the subsequent simulation of the relative permeability curves the right panel of fig 8 shows the influence of the nonwetting contact angle as the wetting contact angle is kept constant only the forced imbibition is influenced it can be observed that not only residual saturations but also the shape of the curve change except for 120 an increasing nonwetting contact angle results in a lower residual nwp saturation however the effects are minor compared to those of the wetting contact angle which affect both parts of the curve as seen in fig 8 not only the crossover at pc 0 but also the saturation endpoints change which results from the nature of the spontaneous and forced imbibition algorithms since the forced imbibition algorithm is modeled like a drainage process the residual saturations are governed by the preexisting fluid phase distributions and the pore throat structure of the medium as the starting point namely the end of the si is the same for all configurations the curves are influenced only by scaling with cos θ during the dilation process this results in slightly altered pathways with similar final states generally we observe that the trends of the capillary pressure curves show physical trends with regard to contact angles and associated wettability index rücker et al 2020 abdallah et al 2007 anderson 1986 zhou et al 2000 zou and armstrong 2019 the most influential parameter has been suggested to be the way the nonwetting material is introduced as displayed in fig 6 here the size and volume are of the essence as they act as stopping criteria for the advancing si front 3 3 relative permeabilities from morphological vs experimental fluid distributions a previous study by berg et al berg et al 2016 showed that simulated imbibition relative permeability curves on the basis of morphologically and experimentally determined fluid distributions greatly disagree in this section we make the same comparison with the modified morphological approach and the extended imbibition saturation range furthermore in the modified morphological approach there are tuning parameters to a fit the numerical to the experimental results and b determine an uncertainty range since the experimental data refer to a water oil displacement we refer in this section to water and oil instead of the wp and the nwp without losing generality we predominantly applied the deterministic algorithm to investigate the sensitivity of the relative permeabilities with respect to the different wetting states of the system to minimize numerical capillary end effects which can highly influence the relative permeability we mirrored the domain in the flow direction for the flow simulations we cropped the domain back to its original size the procedure proved to have only minor influences on the saturations but improved the connectivity of the phases as a premature disconnection at the end of the domain was avoided as a starting point for the imbibition simulations the experimental fluid phase distribution was used at a connate water saturation of s w c 0 21 the experimental residual oil saturation s o r 0 29 served as a reference end point to choose the right parameters for the algorithm the imbibition simulations were performed considering 75 of the pore space for conversion which resulted in a residual oil saturation ranging from 0 25 to 0 35 for nonwetting material contact angles of 180 and 140 respectively with the initial implementations already shown in the study of berg et al berg et al 2016 a sw 0 41 was attained at the end of the spontaneous imbibition process in the top row of fig 9 we show the experimental relative permeability curves in comparison with the initial morphological modeling approach when applying the new algorithm we reduce the spontaneous imbibition saturation range to between 0 25 and 0 32 depending on the chosen water wet contact angle these are only minor saturation changes with respect to the starting saturation which is a result of the relatively large amount of pore space considered for the implementation of the nonwetting material in the middle row of fig 9 the range of the resulting relative permeability curves is plotted showing that we successfully extended the saturation range while reducing the offset to the experimental data the water wetting contact angle mainly influences the oil relative permeability while the nonwetting contact angle influences both the lower the water wetting contact angle is the lower the oil relative permeability is and this effect is very prominent especially at the early stage of imbibition since the reduced connectivity of the oil comes from spontaneous imbibition the effect is more prominent for strongly wetting contact angles of approximately θ 0 this results from the trends shown in fig 8 where the si part of the curve is larger for low contact angles and the forced part is smaller this is a consequence of nwp clusters which have been disconnected during the si process and will not be reconnected during the forced imbibition process this is especially true since the nwp cannot be reconnected during any further displacement events at first glance this may appear counterintuitive on the other hand in a flow experiment water may invade at a higher rate than the spontaneous rate i e imbibition may be forced the middle row in fig 9 shows the simulation results for different contact angle combinations in the different relative permeability realizations of our system the outliers from the experimental data are from simulations using a contact angle of 120 for the nwp where we have already seen in the pc curves that this contact angle do not act in accordance with the other trends the best matches were achieved as shown at the bottom of fig 9 when modeling the imbibition process by forced imbibition only for both the stochastic and deterministic implementations avoiding extreme contact angles i e contact angles close to 0 90 and 180 proved to work best to ensure that the deterministic and stochastic approaches are comparable the same volume of introduced nonwetting material and a small region size 10 µm for the latter were chosen even though the residual saturations for both approaches differ the trend and results for the k r s w are similar this could be an indication that for the displacement of the nwp the pore throat radii and hence the pore structure itself are more dominant than the wetting conditions implied using the degrees of freedom as discussed above leads to a cloud of relative permeability curves which represents an uncertainty interval with respect to the wetting condition these data can now be compared to the simulation results of the experimental fluid distribution by berg et al the experiments were performed under steady state conditions where the system was imaged at different fractional flow conditions since for each fractional flow step a steady state was reached the flow must correspond to a process forced by injection in addition berg et al observed water film swelling in the initial phase of the experiment without significant displacement events taking place and without significant saturation change assuming that this film swelling represents the spontaneous imbibition process it would only account for a limited saturation range whereas further displacement is connected to a forced displacement this would correlate with the large number of pores where nonwetting material was introduced psc 75 and hence a small si range to match the experiment this aligns well with previous energy based lattice boltzmann simulations performed by alpak et al where the imbibition cycle was also simulated purely by forced imbibition alpak et al 2018 as shown in a series of previous publications geometric state functions can be used to uniquely characterize fluid distributions alpak et al 2018 liu et al 2017 mcclure et al 2018 mcclure et al 2020 ott et al 2020 schlüter et al 2016 the euler characteristics χ of the nwp were used by alpak et al alpak et al 2018 to show that the match of relative permeability is associated with a match of the microscopic fluid distribution following this approach we computed the euler characteristic χ for the best matches with the stochastic and deterministic approaches we report the analyzed values for both phases to avoid arbitrary cutoff volumes of smaller clusters we normalized the euler characteristic by scaling by the cluster volumes as proposed by ott et al 2020 χ n c l χ c l v c l n c l v c l fig 10 shows the k r and χ matches for the nwp left and the wp right the data analyzed for the experimental and numerical fluid distributions show an overall good agreement in more detail the nwp χ values are in great agreement at lower saturations and deviate slightly at higher saturations the wp χ deviates at higher saturations to larger and smaller values for the stochastic and deterministic approaches respectively 4 summary and conclusion we successfully combined morphological algorithms for spontaneous and forced processes to describe full range imbibition capillary pressure and relative permeability curves for this distributions of wetting and nonwetting regions were introduced in this manner premature stopping criteria for the spontaneous process were introduced maintaining the connectivity of both phases at the end of the spontaneous process as both phases were still connected a subsequent forced imbibition process was modeled by using the drainage mm for the implementation of the nonwetting regions two approaches were developed a deterministic approach and a stochastic approach capillary pressure curves were modeled for both approaches by varying the nonwetting region sizes and distributions and the contact angles and their combinations we showed that the p c follows physical trends and scal measurements rücker et al 2020 abdallah et al 2007 anderson 1986 zhou et al 2000 zou and armstrong 2019 furthermore we quantified the wetting changes by calculating two different wettability indices which showed that the volume of nonwetting material introduced was the most influential relative permeability curves were then calculated by solving the stokes equations of the connected pathways for different saturation states varying the wettability related parameters resulted in an uncertainty interval that may be used for stochastic reservoir modeling relative permeability was predominantly calculated using a data set by berg et al which allowed a comparison between the original mm the mm as modified in this work and experimentally determined fluid distributions a good match between morphological and experimental data was achieved by avoiding strong wetting conditions while modeling the imbibition process with forced imbibition only this is potentially due to the actual nature of the imbibition process under injection conditions which may be forced rather than spontaneous in summary with these modifications the mm was used to model imbibition over the full saturation scale we were able to demonstrate realistic physical trends and to deliver realistic results in comparison to pore scale experiments the wettability related parameters can be used for uncertainty modeling and to match morphological results to experimental results however we still could not facilitate the possibility of implementing true neutral wetting conditions as simulations in the vicinity of 90 fail or result in saturation end points opposing the actual physical trends being able to model contact angles in this interval would mitigate or even preclude the sharp transitions between spontaneous and forced imbibition further investigation is needed to explain the best match by assuming a pure forced imbibition this may be a result of an injection rate higher than the spontaneous imbibition rate which may force the imbibition across the full saturation scale this is the definition of a drainage process the remaining questions are how to narrow down the input parameters in cases where no experimental data are available and to a certain extent their physical interpretation of the best matches credit authorship contribution statement pit arnold investigation formal analysis writing original draft mario dragovits investigation sven linden methodology software christian hinz software holger ott supervision conceptualization writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the valuable discussions with steffen berg ryan armstrong rudolf held and boris jammernegg we further acknowledge the continuous financial support of the omv exploration production gmbh that helped us to establish the leoben digital rock laboratory 
61,the morphological approach is a computationally attractive method for calculating relative permeability and capillary pressure saturation functions in the corresponding workflow morphological operations are used to calculate the fluid phase distribution in the pore space of a digital twin once the pore space is occupied the conductivity of the individual fluid phases and thus the relative permeability can be calculated by direct flow simulations it therefore combines computationally favorable geometric operations with direct flow simulations in contrast to pore network modeling all calculations are directly performed on the digital twin without abstraction of the pore space while the morphological operations conceptually correctly describe primary drainage processes and delivers good results the method so far failed to describe imbibition processes and the influence of wettability in this work we implement contact angle distributions in a deterministic and stochastic way in this manner we extend the simulated saturation range from purely spontaneous to forced imbibition resulting in a full range imbibition relative permeability furthermore by introducing stochastic contact angle distributions different fluid phase distributions are obtained which now allow for an uncertainty analysis to verify the simulation results we check a whether the simulation results agree with scal measurements and b compare morphologically and experimentally derived results on the pore scale with the newly introduced concepts the imbibition process behaves as physically expected and shows a good agreement with experimentally derived relative permeability curves and microscopic fluid phase distributions data availability data will be made available on request 1 introduction digital rock physics drp has become increasingly attractive for computing multiphase flow properties compared to classical special core analysis scal experiments drp appear to be less time and labor intensive and hence cost competitive furthermore only small rock samples are needed therefore dr analysis can be applied in situations in which there are no suitable scal samples available drp may be categorized by the way flow and displacement physics are implemented in full and reduced physics models full physics models provide deep insights into displacement physics and are performed on the actual rock structure the digital twin yet are typically computationally expensive and therefore have limited use in upstream developments pan et al 2004 chukwudozie and tyagi 2013 boek et al 2017 methods such as lattice boltzmann are able to model the actual visco capillary effects on the pore scale and therefore can reproduce experimental displacement results outside capillary limits alpak et al 2018 however their limitation lies within the possibility of varying petrophysical parameters such as the wetting state of a system as the simulations are highly time consuming reduced physics models on the other hand are often computationally attractive allowing for a larger number of simulations and hence for uncertainty analysis these models simplify or abstract reality in one way or the other prominent examples are pore network models pnms which handle displacement physics in a rule based fashion on idealized pore networks the phase conductivities are computed by solving specific analytical solutions rather than the underlying differential equations blunt 2001 zhao et al 2019 joekar niasar and majid hassanizadeh 2011 in pnms the idealized pore networks are extracted by calculating network properties pore volumes and pore throat sizes from digital rock structures with different authors using different algorithms dong and blunt 2009 gostick 2017 lindquist and venkatarangan 1999 silin and patzek 2006 however all these algorithms are in principle based on morphological operations the morphological method mm silin and patzek 2006 serra 1983 hilpert and miller 2001 as presented in the following makes use of morphological operations to directly calculate the fluid phase distribution in the digital twin rather than to extract an idealized network in this manner the mm bridges both worlds it makes use of morphological operations to populate the as measured pore space with the fluid phases and directly solves the navier stokes equation of the pore space to simulate effective permeability the morphological operations are applied in a rule based quasi static manner so that no time scale is associated with the displacement process since they are applied to the pore structure the modeled displacement processes refer to a capillary dominated flow viscous processes are not considered however the fact that the displacement processes are purely calculated on the basis of image processing makes the mm very time competitive when simulating drainage processes liquid invasion is controlled by the dilation of the mineral phase of the digital twin pore throats are then identified and connectivity to neighboring pores is tested for each dilation step assigning an interfacial tension to fluid fluid interfaces and a contact angle to mineral fluid fluid three phase contact lines allows the capillary pressure to be calculated for each dilatation step i e for different saturations by the young laplace equation comparison with experimental data shows close agreement for drainage processes while there are significant discrepancies reported for imbibition berg et al 2016 the relative permeability is then simulated by solving the navier stokes equation of the pore space connected by the individual fluid phase this limits the two phase flow to the connected phase volume dynamic effects such as ganglion dynamics which may contribute to the nonwetting phase mobility especially in the case of high wetting phase saturations are therefore not considered rücker et al 2015 armstrong et al 2016 to date the mm has delivered good results for drainage but has shown limitations in terms of imbibition processes and uncertainty modeling in particular imbibition processes were limited since only individual processes either forced drainage or spontaneous imbibition processes could be modeled the forced part of the imbibition was therefore not previously incorporated in this work we implement contact angle distributions in a deterministic and stochastic way in this manner we extend the imbibition process from purely spontaneous to forced imbibition resulting in full range imbibition capillary pressure pc swp and relative permeability kr swp saturation functions furthermore by introducing stochastic contact angle distributions different fluid phase distributions are obtained which allows for uncertainty analyses to verify the simulation results we check a whether the simulation results agree with those from scal measurements and b compare the morphological results with experimentally derived results 2 numerical methods and developments 2 1 morphological method the mm is based on mathematical morphology and applies morphological operations to pore scale rock images it was originally developed by matheron and serra in 1964 for serra s phd thesis and later published in serra et al 1983 serra 1983 the basic dilation and erosion operations applied to the rock s pore structure enable the quantitative analysis of pore geometries with regard to the drainage displacement thresholds the pore throats the morphological identification of thresholds links the pore structure to capillarity and hence to fluid displacement physics the mathematical fundamentals are discussed in detail in hilpert and miller s paper from 2001 hilpert and miller 2001 initially the approach was limited to binary images but it can also be applied to grayscale images heijmans 1995 a derivative the pore mm also known as maximum inscribed spheres silin and patzek 2006 predicts the distributions of a wetting phase wp and a nonwetting phase nwp inside a porous medium in general the mm predicts saturation changes on the basis of geometrical rock properties and therefore intrinsically assumes that capillary forces dominate compared to viscous forces i e it describes displacements at low capillary numbers the method therefore distributes the two fluid phases by using morphological operations rather than solving partial differential equations a criterion for a displacement event is the disconnection to the respective wetting and nonwetting reservoir attached to the system boundaries for imbibition and drainage we refer to the invasion of the wp and the nwp respectively the image operations change the topology of the fluid phases which corresponds to the physical event of a capillary pressure change where the extent of the dilation operation corresponds to the pore throat radius in the young laplace equation fig 1 shows the displacement of the wp blue by the nwp green for a single contact angle gray and two contact angles gray and brown respectively to the mineral phase the number of dilated voxels describes the radius r which corresponds to the pore throat size in a drainage process different contact angles are introduced after schulz by scaling the dilation radius with cos θ with θ being the contact angle schulz et al 2015 this method slightly overestimates the actual contact angle and does not work for contact angles close to 90 2 2 initial drainage and spontaneous imbibition implementations a primary drainage is defined as the displacement of the wp by the nwp the process is described by a sequence of equilibrium steps which mimic the invasion as a consequence of an applied differential pressure and flow restrictions the pore throats a sequence of three operations corresponding to a single displacement event is shown in fig 1 it illustrates a simplified 2d porous structure with circular grains shown in gray and the pore space filled with a wp blue in the steps from images a to b grains are dilated white to identify and close the narrowest pore throats defining the nwp reservoir on the left hand side of the image the invaded nwp is connected to the nwp reservoir and recolored dark green this step identifies the pore space filled with nwp the dilatation radius r corresponds to a critical pore throat radius and the corresponding capillary pressure which is given by the young laplace equation pc 2σ cos θ r where σ denotes the interfacial tension and θ the contact angle in the next step the nwp is dilated light green by the same voxel radius as the grains that were dilated in the prior step since in a drainage process the nw fluid first invades the larger pore throats the invading fluid green phase cannot overcome the first pore throat which is indicated in image c the right hand side of fig 1 d f shows that the approach can be modified by the introduction of a different mineral with a modified contact angle brown when applying multiple contact angles for the same scenario the invading phase can overcome the same pore throat since the dilation is scaled by cos θ light brown which results in different invasion pathways for the same applied pressure furthermore as observable in image f the contact angle of the nwp green is different for both materials in this process the invading nwp must in every step be connected to the inlet phase which is the nwp reservoir and the wp to the outlet the wp reservoir the algorithm of the above described morphological drainage process is schematically illustrated in fig 2 with a simple 2d pore structure the process consists of four steps 1 dilation 1 dilate grains into the wp saturated pore space by a voxel radius r which can be scaled by cos θ 2 connectivity 1 recolor the pore space that is connected to the nwp reservoir and label it nwp 3 dilation 2 dilate the nwp by the initial nonscaled voxel radius from step one 4 connectivity 2 identify all wp disconnected from the wp reservoir as residual it will no longer be considered for further displacement calculations the last step allows for residual saturation and may be ignored when simulating mercury injection capillary pressure experiments ahrenholz et al 2008 performing the drainage algorithm by gradually decreasing the radius r number of voxels results in a quasi stationary invasion of the nwp scaling the dilation radius in step 1 by cos θ alters the invasion pathway with regard to the wetting condition when contacting a nonwetting material the pore space would immediately be populated by the approaching nwp the interfacial tension is accounted for only in postprocessing for calculating pc and therefore results only in an up or down shift of the pc curves but does not influence the resulting fluid distribution a drainage process is either stopped when the wp is entirely disconnected from the outlet or the dilation reaches the voxel size the basic algorithm for drainage can be modified to simulate imbibition processes by interchanging steps 2 and 3 and by exchanging nwp and wp but in dilation step 2 the process is illustrated in fig 2 1 dilation 1 dilate grains into the nwp saturated pore space by a voxel radius r which can be scaled by cos θ 2 dilation 2 dilate the nwp by the initial nonscaled voxel radius from step one 3 connectivity 1 recolor the pore space that is connected to the wp reservoir and label it wp 4 connectivity 2 identify all nwp disconnected from the nwp reservoir as residual it will no longer be considered for further displacement calculations this new sequence of algorithm steps results in a displacement characteristic that is controlled by pore body dimensions rather than by the pore throat size for drainage the algorithm controls the retracting nwp which is predominantly located in larger structures such as pore bodies therefore the process is more controlled by the pore bodies than the pore throats the fluid fluid interfaces are located at positions at which the curvature corresponds to the dilation radius which corresponds to the simulated capillary pressure this defines the stopping criterion for the displacement by the curvature and properly defines an imbibition process an imbibition front stops when either the nwp is disconnected from the nwp reservoir or the dilation radius exceeds the size of the largest pores i e allowing no further fluid phase changes and nonwetting material cannot be bypassed anymore by the wp which means it acts as a barrier 2 3 simulation of effective permeability the pc swp saturation function is a direct result of the mm i e a purely structural property furthermore the mm delivers the fluid distribution in the pore space for each simulated saturation state and hence information on the connectivity of both phases the mm however does not directly deliver permeability and kr swp the absolute permeability k is simulated by solving the stokes equation of the total pore space assuming single phase flow for a small constant pressure drop in the flow direction in the present case δp 0 02 pa and periodic boundary conditions in the tangential direction due to our focus on very slow flows and the corresponding small pressure drops we solve the stokes equation instead of the navier stokes equation as it delivers the same results while being computationally less demanding the effective permeability kr swp k is simulated for each fluid phase separately considering the respective connected pathways only this means that kr swp simulations consider the respective other phase as immobile i e all internal boundaries as rigid and fixed with this we ignore viscous momentum transfer between the fluid phases which means that the movement of one phase is not affecting the respective other fluid phase blunt 2017 hence we ignore effects like ganglion dynamics furthermore kr swp can be calculated only in cases where the respective fluid phase is connected throughout the simulation domain at the given saturation state otherwise it is zero a snap off event can therefore lead to the loss of phase conductivity while the phase is still accessible for a displacement event as it is connected to the outlet fig 3 shows the general workflow on how the relative permeabilities are obtained from the morphological populated phases 2 4 limitations of the initial implementation as described earlier the mm is based on geometric operations on digital rock structures and is therefore entirely governed by the porous structure and if present the residual fluid phases this describes the nature of a primary drainage process quite well as the nwp intrusion is restricted by the pore throat radii which are inversely correlated to the capillary pressures however processes such as imbibition are partly spontaneous and driven by interfacial properties such as the wetting state and contact angle distribution how well does the mm capture these physical processes for a single contact angle the invading fluid always takes the pathway through the porous domain independent of the contact angle this means that a contact angle variation will not alter the invasion sequence and the resulting fluid distribution and therefore will not change the relative permeability curves the implementation of multiple contact angles was addressed by schulz et al schulz et al 2015 hereby the invasion process is altered by scaling the dilation radii with cos θ however limiting the system to contact angles below or above 90 as there the dilation goes to zero contact angles below 60 and above 120 show only minimal numerical errors the introduction of multiple contact angles allows for variating displacement pathways after all the imbibition process as given above is still limited to the spontaneous part of the capillary pressure curve i e to the positive p c range which results in a limited saturation range to date one of the stopping criteria is a disconnection of the nwp from the nwp reservoir we typically describe the flow in a single direction and therefore assign the lateral boundary conditions as periodic while the inlet is connected to a wp reservoir and the outlet is connected to an nwp reservoir hence the invasion process can result in an early snap off early disconnection of the nwp while leaving a larger part of the saturation as residual this results in a drastic reduction of the nwp effective permeabilities and an increase for the wp 2 5 full scale imbibition while the drainage process is defined as the invasion of the nwp i e indicated by an entirely positive capillary pressure imbibition processes can show an early saturation range of positive and a late saturation range of negative capillary pressure a negative capillary pressure indicates a forced process which can actually be understood as a drainage process therefore to simulate the full saturation range with the pore mm we first couple the imbibition process with a subsequent drainage process the stopping criteria of the spontaneous imbibition si process is the disconnection of the nwp from the outlet the nwp is trapped and cannot be displaced either by an imbibition or by a drainage algorithm to switch from a spontaneous to a forced process a nonwetting material must be introduced which prevents access to parts of the pore space by the spontaneous process this may be physically correct because it reflects the meaning of a negative capillary pressure a straightforward implementation is the introduction of nonwetting material before the start of si modeling depending on the topology and volume of the nonwetting material introduced the si stops at different saturation stages in this work the nonwetting material is introduced in two alternative ways 1 the introduction of a nonwetting material on the basis of a stochastic field before the drainage process this ensures that the nonwetting material is in contact with the nwp at the end of the drainage process 2 the introduction of nonwetting material at the end of the drainage process in nwp filled pores only prioritizing the largest pores first in the stochastic approach the volumetric percentage and region size considered for the stochastic field are defined the material is then implemented on the basis of an isotropic gaussian random field fig 4 shows the exemplary implementation of nonwetting materials with two different region sizes in both cases the same random seed was chosen whereas one region size was smaller and the other was larger than the average visible grain size depending on the region size and solid volume percentage svp considered unavoidably the introduced material can be interconnected throughout the structure the volume percentage of material changed equals the surface area percentage between the pore and solid materials with minor deviations the deterministic approach is based on the natural process of a wettability alteration during an aging process where mineral surfaces in contact with the nwp can change their initial wetting state rücker et al 2020 hirasaki et al 1990 abdallah et al 2007 it applies an algorithm at the end of a drainage process analyzing the pore size distribution and introducing nonwetting material in the largest pores first only where the mineral and nwp meet in the algorithm we define the volume of pores considered for the implementation the volume fraction considered does not equal the surface area fraction as only a part of the pore material is changed see fig 7 fig 5 illustrates the algorithm on a simplified structure the different pore sizes are displayed as volume fields scaled by a hue saturation lightness color legend where blue represents the smallest pores and red the largest pores in the second illustration the pore space which is considered by the algorithm is marked in red the pore space considered is currently a user input and can be varied between 1 and 99 the last two images show the resulting material changes where only material in contact with the previous marked pores is considered while prioritizing the material in the larger pores this algorithm has the advantage that different nonwetting contact angles can be introduced at the end of the drainage the forced imbibition fi part is then modeled with the drainage algorithm where the contact angles and the role of the phases are inverted this means that a nonwetting contact angle is considered to be wetting i e 180 α for the fi drainage process while swapping the roles of the wp and nwp this corresponds to a turnover of the menisci between the wp and nwp at the transition from the spontaneous to the forced displacement process 2 6 comparison to experimental data a steady state experimental data set berg et al 2016 was used as a reference for benchmarking the data set consists of a time series of pore scale resolved fluid distributions with which nwp and wp effective permeability can be simulated and directly compared to the respective results from the mm this benchmark was carried out by berg et al and is repeated in the present work with and without the described modifications in the mm while in the earlier study the relative permeability simulated on the numerical and experimental fluid distributions shows a substantial mismatch with the embedded innovations a close match could be achieved as discussed in the results section 2 7 simulation input the uncertainty analysis for the contact angle distributions was performed on berea sandstone with dimensions of 800 800 800 voxels and a voxel size of 1 84 µm 3 voxel the digital rock sample has a resolved porosity of 19 6 and a simulated permeability of 780 md the synchrotron mct based experiment by berg et al was conducted on gildehauser sandstone with an average resolved porosity of 20 and a permeability of 1 5 0 3 d for the comparison to simulations on the experimentally derived fluid distributions the presegmented data set from the digital rocks portal was used berg et al 2018 the digital twin has a resolution of 4 4 µm 3 voxel and consists of a cylindrical domain with dimensions of 830 830 566 voxels the digital twin has a porosity of 20 3 and a simulated permeability of 1 55 d 3 results to test the innovations introduced in this work we use the new degrees of freedom to define and vary the wetting state and simulate different scenarios first we simulate capillary pressure curves on a digital twin for berea sandstone with this we compare the results for the stochastic and deterministic implementation and for different wetting states to assess the trends in the pc swp on a physical basis second we compare the new approaches with experiments by simulating kr swp for experimentally and morphologically determined fluid distributions while varying the simulated wetting states 3 1 full scale imbibition and introduction of a nonwetting material in the previous section we introduced two principally different algorithms for the implementation of a nonwetting material a stochastic algorithm and a deterministic algorithm for the stochastic algorithm the nonwetting material is introduced prior to the drainage process which ensures that the nonwetting pores are filled with the nwp at connate wp saturation with regard to the subsequent imbibition process the higher the svp of the nonwetting region is the earlier the spontaneous imbibition is stopped and the larger the contribution of the forced part to the total imbibition process furthermore the region size chosen is critical as it influences drainage and imbibition in fig 6 left we can observe these changes whereby an increasing svp and decreasing region size resulted in a greater nonwetting state of the system the dark yellow symbols which partly overlap with the newly modeled data sets show the results of the initial drainage and spontaneous imbibition implementation in this case only one wetting contact angle was assigned and therefore only spontaneous imbibition was modeled to make the data comparable the same contact angle set of 40 for the wetting material and 140 for the nonwetting material was used three different nonwetting svp settings 10 20 30 with two different region sizes 10 and 100 μ m were modeled resulting in an additional 6 scenarios while the residual wp saturation was rather unaffected the residual nwp saturation decreased with increasing svp and decreasing region size which is consistent with the proportion of spontaneous to forced imbibition an increasing volumetric proportion svp of nonwetting material resulted in a greater nonwetting trend the region size on the other hand displayed an opposite trend where a decrease in the region size led to an earlier inhibition of spontaneous imbibition this is a result of the spatial distribution of the nonwetting material even though the surface area of the nonwetting material is approximately the same for both region sizes there were more pores that were affected by the nonwetting material consequently the available pore space for invasion during the spontaneous process was reduced the effects of the region size and the contact angle spatial distribution were large they determined whether the overall system was water wet or oil wet which was directly recognized by comparing the positive and negative areas under the imbibition p c curve indicated by the shaded areas for the svp 30 cases in fig 6 which is linked directly to the work the system does to the environment spontaneous and positive and the work the environment does to the system forced and negative the ratio corresponds to the wettability index when taking the logarithm of that ratio similar to the u s bureau of mines usbm wettability index positive values indicate wetting behavior as spontaneous work is larger than forced work and vice versa donaldson et al 1969 another indication is delivered by the amott water wetting index which compares the spontaneously imbibed saturation range to the total imbibed saturation amott 1959 the values range from 0 to 1 where an increasing value indicates more wetting behavior both indices deliver similar trends when plotted against the region size however when directly comparing them the amott wetting index shows less of a wetting trend than the above defined wettability index wi this results from the definition of the indices as we have a reduced threshold for the forced imbibition similar to the primary drainage as regions of nonwetting material are already assigned throughout the system therefore the work necessary for nwp displacement is reduced in fig 7 the wettability indices for different svp values are plotted against the region size assigned for the nonwetting material as well as the volume fraction of the pore throat diameter of the digital rock sample the 30 svp system with a 10 μm region size is characterized as nonwetting and the system with 100 μm as wetting as indicated by the wettability indices of 0 51 and 0 34 respectively which is in accordance with the amott wetting indices of 0 12 and 0 52 respectively furthermore it can be observed that both the svp and region size have a distinct influence on the wettability of the system the region size is correlated to the pore throat size when it is smaller or equal to the average pore throat size the introduced nonwetting material can deny access to a majority of the pores during the spontaneous imbibition process therefore for the same svp a smaller region size leads to lower wettability indices as the small patches are equally distributed throughout the system on the other hand larger region sizes allow bypassing while restricting entire areas for population overall qualitative changes in the indices clearly indicate the wettability changes of the system it is worth mentioning that the drainage curves are also affected for smaller region sizes more work is required to desaturate the system if the region size is smaller the reason for this may be that with larger region sizes some pores are wetting to the nwp and therefore a fraction of the volume can be easily invaded by the nwp in the deterministic approach the nonwetting material is implemented at the end of the drainage process which leaves the drainage process itself unaffected therefore unlike in the stochastic approach all imbibition scenarios start from the same point drainage endpoint despite the substantial differences of both algorithms their trends are similar with regard to forced imbibition and the residual nwp saturation however as discussed above the exact nwp distribution after drainage determines the nonwetting material distribution the right panel of fig 6 shows the results when assigning nonwetting material while considering 5 50 and 95 of the entire pore space the larger the pore space considered psc for turning into nonwetting material the more likely the systems are to behave in a nonwetting manner this is displayed by lower residual nwp saturations and larger areas under the negative p c branch when considering almost the entire pore space the 95 case in fig 6 there was not any spontaneous imbibition as the wp front does not have any available space for advancing spontaneously since it is immediately confronted with nonwetting material for systems with low psc the spontaneous imbibition follows the original trend as only a small portion of the system is unavailable for the invasion sequence generally both algorithms display similar trends with an increasing volume of nonwetting material introduced however the shape and p c quantity differ significantly as the deterministic population does not influence the required work for displacement as much as the stochastic approach the prioritized introduction within the larger pores restricts the wp from entering single pores whereas in the stochastic approach depending on the region size chosen entire areas might be restricted therefore the resulting p c values can differ greatly between the two processes in fig 7 the wi and amott wetting indices are plotted against the psc for the deterministic approach they show the same trends of less wetting behavior with regard to the volume of implemented nonwetting material however it can be observed that the trends for the indices differ as the work required for displacement correlates with the surface area volume of the nonwetting material while the saturation endpoints are rather a result of the psc an evident difference in the imbibition pc curves simulated with the mm and common laboratory pc curves is the abrupt pc drop at the transition from the spontaneous to the forced part of the curves across the pc 0 condition we believe that this discontinuity is physically correct and is a result of a a discrete contact angle distribution and b the finite size of the digital twin at the point at which imbibition changes from spontaneous to forced all the pore space that can be spontaneously invaded is invaded at that point the interfacial curvature locally flips from concave from the perspective of the wp to convex with only a negligible saturation change during the flip the system crosses the pc 0 condition therefore this discontinuity may be mitigated a by a continuous contact angle distribution and b by investigating macroscopic system sizes as for classical pc measurements with regard to a it depends very much on the reason for contact angle variation whether it is due to mineral to mineral variation or due to aging or both in all cases the contact angle distribution may be discontinuous with regard to b the mm and pc measurements are based on fluid invasion processes we assume that one process locally dominates i e spontaneous or forced imbibition however for larger sample domains at a given time and at different positions there are slightly different saturation states this smoothens experimentally derived pc curves for an average saturation state we observe that this point has no influence no discontinuity on the simulated relative permeabilities 3 2 sensitivity to the contact angle to study the sensitivities to the implemented contact angles of imbibition pc and kr the deterministic approach is used where the material is implemented at the end of the drainage process this guarantees better comparability as the drainage process is not affected by the nonwetting contact angle in contrast to the initial implementation two contact angles are assigned resulting in a material distribution with the initially assigned wetting contact angle and with a modified contact angle the modified areas are those prioritized by the primary drainage process to be in contact with the nwp material a certain volume percentage of the prioritized area is then assigned to nonwetting contact angles while drainage is determined by the wetting contact angle only imbibition is sensitive to both unless otherwise stated and for comparability the chosen pore space considered 50 is the same for all simulations the left panel of fig 8 shows the results by variation in the wp contact angle by leaving the nwp contact angle constant both curves drainage and imbibition are affected with increasing wp contact angle less pressure is required for the nwp to enter the pore space the pc curve is lowering regarding imbibition a contact angle increase lowers the saturation range for the si and decreases the residual nwp saturation these are clear indications of a lower wetting behavior of the system which is expected when applying a higher contact angle to the wp furthermore it can be observed that the shape of the forced imbibition curve is not influenced as it is governed entirely by the nonwetting contact angle the earlier the forced imbibition begins the larger the overall saturation range this behavior is expected from scal measurements and is also reflected in the subsequent simulation of the relative permeability curves the right panel of fig 8 shows the influence of the nonwetting contact angle as the wetting contact angle is kept constant only the forced imbibition is influenced it can be observed that not only residual saturations but also the shape of the curve change except for 120 an increasing nonwetting contact angle results in a lower residual nwp saturation however the effects are minor compared to those of the wetting contact angle which affect both parts of the curve as seen in fig 8 not only the crossover at pc 0 but also the saturation endpoints change which results from the nature of the spontaneous and forced imbibition algorithms since the forced imbibition algorithm is modeled like a drainage process the residual saturations are governed by the preexisting fluid phase distributions and the pore throat structure of the medium as the starting point namely the end of the si is the same for all configurations the curves are influenced only by scaling with cos θ during the dilation process this results in slightly altered pathways with similar final states generally we observe that the trends of the capillary pressure curves show physical trends with regard to contact angles and associated wettability index rücker et al 2020 abdallah et al 2007 anderson 1986 zhou et al 2000 zou and armstrong 2019 the most influential parameter has been suggested to be the way the nonwetting material is introduced as displayed in fig 6 here the size and volume are of the essence as they act as stopping criteria for the advancing si front 3 3 relative permeabilities from morphological vs experimental fluid distributions a previous study by berg et al berg et al 2016 showed that simulated imbibition relative permeability curves on the basis of morphologically and experimentally determined fluid distributions greatly disagree in this section we make the same comparison with the modified morphological approach and the extended imbibition saturation range furthermore in the modified morphological approach there are tuning parameters to a fit the numerical to the experimental results and b determine an uncertainty range since the experimental data refer to a water oil displacement we refer in this section to water and oil instead of the wp and the nwp without losing generality we predominantly applied the deterministic algorithm to investigate the sensitivity of the relative permeabilities with respect to the different wetting states of the system to minimize numerical capillary end effects which can highly influence the relative permeability we mirrored the domain in the flow direction for the flow simulations we cropped the domain back to its original size the procedure proved to have only minor influences on the saturations but improved the connectivity of the phases as a premature disconnection at the end of the domain was avoided as a starting point for the imbibition simulations the experimental fluid phase distribution was used at a connate water saturation of s w c 0 21 the experimental residual oil saturation s o r 0 29 served as a reference end point to choose the right parameters for the algorithm the imbibition simulations were performed considering 75 of the pore space for conversion which resulted in a residual oil saturation ranging from 0 25 to 0 35 for nonwetting material contact angles of 180 and 140 respectively with the initial implementations already shown in the study of berg et al berg et al 2016 a sw 0 41 was attained at the end of the spontaneous imbibition process in the top row of fig 9 we show the experimental relative permeability curves in comparison with the initial morphological modeling approach when applying the new algorithm we reduce the spontaneous imbibition saturation range to between 0 25 and 0 32 depending on the chosen water wet contact angle these are only minor saturation changes with respect to the starting saturation which is a result of the relatively large amount of pore space considered for the implementation of the nonwetting material in the middle row of fig 9 the range of the resulting relative permeability curves is plotted showing that we successfully extended the saturation range while reducing the offset to the experimental data the water wetting contact angle mainly influences the oil relative permeability while the nonwetting contact angle influences both the lower the water wetting contact angle is the lower the oil relative permeability is and this effect is very prominent especially at the early stage of imbibition since the reduced connectivity of the oil comes from spontaneous imbibition the effect is more prominent for strongly wetting contact angles of approximately θ 0 this results from the trends shown in fig 8 where the si part of the curve is larger for low contact angles and the forced part is smaller this is a consequence of nwp clusters which have been disconnected during the si process and will not be reconnected during the forced imbibition process this is especially true since the nwp cannot be reconnected during any further displacement events at first glance this may appear counterintuitive on the other hand in a flow experiment water may invade at a higher rate than the spontaneous rate i e imbibition may be forced the middle row in fig 9 shows the simulation results for different contact angle combinations in the different relative permeability realizations of our system the outliers from the experimental data are from simulations using a contact angle of 120 for the nwp where we have already seen in the pc curves that this contact angle do not act in accordance with the other trends the best matches were achieved as shown at the bottom of fig 9 when modeling the imbibition process by forced imbibition only for both the stochastic and deterministic implementations avoiding extreme contact angles i e contact angles close to 0 90 and 180 proved to work best to ensure that the deterministic and stochastic approaches are comparable the same volume of introduced nonwetting material and a small region size 10 µm for the latter were chosen even though the residual saturations for both approaches differ the trend and results for the k r s w are similar this could be an indication that for the displacement of the nwp the pore throat radii and hence the pore structure itself are more dominant than the wetting conditions implied using the degrees of freedom as discussed above leads to a cloud of relative permeability curves which represents an uncertainty interval with respect to the wetting condition these data can now be compared to the simulation results of the experimental fluid distribution by berg et al the experiments were performed under steady state conditions where the system was imaged at different fractional flow conditions since for each fractional flow step a steady state was reached the flow must correspond to a process forced by injection in addition berg et al observed water film swelling in the initial phase of the experiment without significant displacement events taking place and without significant saturation change assuming that this film swelling represents the spontaneous imbibition process it would only account for a limited saturation range whereas further displacement is connected to a forced displacement this would correlate with the large number of pores where nonwetting material was introduced psc 75 and hence a small si range to match the experiment this aligns well with previous energy based lattice boltzmann simulations performed by alpak et al where the imbibition cycle was also simulated purely by forced imbibition alpak et al 2018 as shown in a series of previous publications geometric state functions can be used to uniquely characterize fluid distributions alpak et al 2018 liu et al 2017 mcclure et al 2018 mcclure et al 2020 ott et al 2020 schlüter et al 2016 the euler characteristics χ of the nwp were used by alpak et al alpak et al 2018 to show that the match of relative permeability is associated with a match of the microscopic fluid distribution following this approach we computed the euler characteristic χ for the best matches with the stochastic and deterministic approaches we report the analyzed values for both phases to avoid arbitrary cutoff volumes of smaller clusters we normalized the euler characteristic by scaling by the cluster volumes as proposed by ott et al 2020 χ n c l χ c l v c l n c l v c l fig 10 shows the k r and χ matches for the nwp left and the wp right the data analyzed for the experimental and numerical fluid distributions show an overall good agreement in more detail the nwp χ values are in great agreement at lower saturations and deviate slightly at higher saturations the wp χ deviates at higher saturations to larger and smaller values for the stochastic and deterministic approaches respectively 4 summary and conclusion we successfully combined morphological algorithms for spontaneous and forced processes to describe full range imbibition capillary pressure and relative permeability curves for this distributions of wetting and nonwetting regions were introduced in this manner premature stopping criteria for the spontaneous process were introduced maintaining the connectivity of both phases at the end of the spontaneous process as both phases were still connected a subsequent forced imbibition process was modeled by using the drainage mm for the implementation of the nonwetting regions two approaches were developed a deterministic approach and a stochastic approach capillary pressure curves were modeled for both approaches by varying the nonwetting region sizes and distributions and the contact angles and their combinations we showed that the p c follows physical trends and scal measurements rücker et al 2020 abdallah et al 2007 anderson 1986 zhou et al 2000 zou and armstrong 2019 furthermore we quantified the wetting changes by calculating two different wettability indices which showed that the volume of nonwetting material introduced was the most influential relative permeability curves were then calculated by solving the stokes equations of the connected pathways for different saturation states varying the wettability related parameters resulted in an uncertainty interval that may be used for stochastic reservoir modeling relative permeability was predominantly calculated using a data set by berg et al which allowed a comparison between the original mm the mm as modified in this work and experimentally determined fluid distributions a good match between morphological and experimental data was achieved by avoiding strong wetting conditions while modeling the imbibition process with forced imbibition only this is potentially due to the actual nature of the imbibition process under injection conditions which may be forced rather than spontaneous in summary with these modifications the mm was used to model imbibition over the full saturation scale we were able to demonstrate realistic physical trends and to deliver realistic results in comparison to pore scale experiments the wettability related parameters can be used for uncertainty modeling and to match morphological results to experimental results however we still could not facilitate the possibility of implementing true neutral wetting conditions as simulations in the vicinity of 90 fail or result in saturation end points opposing the actual physical trends being able to model contact angles in this interval would mitigate or even preclude the sharp transitions between spontaneous and forced imbibition further investigation is needed to explain the best match by assuming a pure forced imbibition this may be a result of an injection rate higher than the spontaneous imbibition rate which may force the imbibition across the full saturation scale this is the definition of a drainage process the remaining questions are how to narrow down the input parameters in cases where no experimental data are available and to a certain extent their physical interpretation of the best matches credit authorship contribution statement pit arnold investigation formal analysis writing original draft mario dragovits investigation sven linden methodology software christian hinz software holger ott supervision conceptualization writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the valuable discussions with steffen berg ryan armstrong rudolf held and boris jammernegg we further acknowledge the continuous financial support of the omv exploration production gmbh that helped us to establish the leoben digital rock laboratory 
62,advection dominated transport processes in sub surface formations are characterized by discontinuities in the fields of transported quantities and realistic predictions are challenging for eulerian transport schemes because they suffer from numerical diffusion henceforth we have focused on developing a lagrangian particle tracking scheme for modeling advective solute transport in fractured media to this end we adopt an embedded discrete fracture model edfm for fractured media with a permeable matrix the flexibility to use non conformal fracture matrix discretizations makes edfms a compelling choice in field scale flow problems unaffected by the numerical diffusion lagrangian transport schemes complement the potential of edfms by allowing the use of sufficiently large grid cell sizes for flow field computations in an edfm framework the inter continuum fluid mass exchange cannot be quantified by the particle trajectories pathlines due to the unresolved fracture matrix interfaces and different dimensionalities of the matrix and fracture discretizations these constraints motivate the use of a stochastic particle tracking scheme and thus we formulated a pathline specific probability of inter continuum particle transfer based on mass conservation of an elementary solute fluid mass the particle s transfer probability is calculated for the maximum residence time period in its associated fracture matrix control volume thus making the scheme time adaptive in addition a conditional residence time distribution was derived which dictates the timestamp of the particle transfer first we showcase that the tracking scheme preserves the initially homogeneous solute concentration field suggesting that the probabilistic rules are consistent with the inter continuum fluxes additionally we illustrate the estimation of an evolving solute plume and compare the results with those of an eulerian counterpart the presented stochastic approach enables straightforward formulations of lagrangian models for dynamic and sub grid processes e g solute interactions with the solid phase the mapping of their effects onto large scale transport and additionally be included in random walk models for dispersion keywords particle tracking transfer probability embedded discrete fracture model variance reduction solute transport data availability data will be made available on request 1 introduction 1 1 solute transport with particle tracking methods in the modeling of solute transport lagrangian particle tracking methods are compelling alternatives to finite element volume based eulerian methods a particle tracking method is a numerical technique to simulate the temporal evolution of a system where an intensive quantity is approximated by a linear combination of a large but finite number of dirac measures or simply computational particles tompson and dougherty 1988 a particle s state space generally includes its physical coordinates and other attributes e g a certain mass of the solute in the case of a solute transport problem alternatively a computational or notional particle is an abstraction for a packet of species molecules being transported in the flow field therefore particle based methods can bridge the gap between macroscopically observed state variables e g the solute concentration and the molecular interactions driving the evolution of the macroscopic variables benson and meerschaert 2008 particle tracking methods do not suffer from numerical diffusion and hence are particularly relevant for advection dominated flow scenarios with low mixing rates which are characterized by sharp concentration fronts michalak and kitanidis 2000 complementary to this particle based methods provide more realistic predictions of reaction rates in mixing limited conditions as they do not rely on the assumption of well mixed solute in eulerian grid cells or volumes hence relatively coarse grids can be used for the flow field resolution without compromising the accuracy of transport predictions kapoor and kitanidis 1998 during a particle tracking simulation computation of the solute concentration on an eulerian grid may not be necessary which implies that the statistical errors associated with the corresponding estimates do not propagate to the next time step in purely advective transport processes and in the absence of a source sink divergence free local velocity ensures that the fluid mass as well as the solute mass are conserved pollock 1988 in a tracking scheme global mass conservation can be indicated by the consistency in the number of particles in the computational domain random walk particle methods rwpms are often used to model transport processes involving dispersion diffusion they are based on the similarity between the fokker planck equation and the classical advection dispersion equation kinzelbach 1988 delay et al 2005 local conservation of the solute mass may not be rudimental in many such transport schemes labolle et al 1996 and salamon et al 2006 discuss rwpm techniques to tackle discontinuities in the upscaled properties of heterogeneous media e g the dispersion tensor when dealing with the transport of a conservative solute 1 2 particle tracking methods involving particles with discrete state space valocchi and quinodoz 1989 have used notional particles to simulate solute mass undergoing a sorption desorption reaction and these particles evolve as per a two state continuous time markov chain this is viable because there is a similarity between the evolution equation for the aqueous solute concentration precisely solute mass density in a first order sorption desorption reaction and that for the probability of a notional particle being in a particular discrete state eqs 5 and 12 in valocchi and quinodoz 1989 for coupled surface subsurface set ups de rooij et al 2013 have formulated a pathline specific probability of particle transfer from a 2 d overland domain to a 3 d subsurface domain 1 3 particle tracking methods for fractured porous media in an analogous way but in the context of fractured media mass transfer between fracture and matrix representations can be conceptualized as transitions of particles between discrete states for diffusive mass transfer in dual continua models liu et al 2000 have quantified the cell wise average probability of transfer between the matrix and the fracture continua however with their assumption of complete mixing within grid cells the probability formulation does not account for the particle s location within a grid cell and lagrangian transit time distributions cannot be correctly estimated as reported by de rooij et al 2013 the probability formulation is explicit in nature which puts an upper bound on the allowed time step size and thus constrains the efficiency of the overall transport framework additionally the approach to split the time step into residence times in different states is not consistent with the transfer probability pan et al 2001 proposed that the particles travel in only one continuum during a time step and that the transfers happen at the end of the time step however this approach limits the temporal resolution of the transfers and additionally complete mixing within the grid cells is assumed in this work as well 1 4 models for fractured porous media irrespective of the lagrangian transport scheme the limitations of multi continua models in accurately simulating the flow fields e g their applicability being limited to domains with highly connected fractures and near uniform properties also limits the overall flow and transport framework the notable alternates include a multitude of discrete fracture models dfms which incorporate fractures as discrete representations and account for the effects of individual fractures and their connectivities on the fluid flow jiang and younis 2017 embedded discrete fracture models edfms provide a good balance between accuracy and efficiency in simulating the flow fields for field scale applications in edfm frameworks the matrix is discretized independently of fractures and the individual fracture geometries are resolved but treated as lower dimensional manifolds hajibeygi et al 2011 deb and jenny 2017 jiang and younis 2017 the characteristics of edfm frameworks render a combination with particle based transport schemes attractive as larger grid cells can be used without the risk of having excessively smeared concentration fronts complementary to this the often used structured grids for the matrix supports simple implementations of particle tracking schemes a typical challenge for particle based schemes in fractured domain models is the modeling of interactions between the fractures and the matrix two sub domains often subjected to very different velocities and characteristic time scales in addition fractures often occupy a very small volume compared to the matrix which renders conventional particle based schemes inefficient 1 5 scope of this paper in this paper we propose based on our earlier work monga et al 2020 a stochastic particle tracking scheme suited for embedded discrete fracture models of fractured media with a permeable matrix with the flow field inside grid cells or finite control volumes cvs not being resolved we use a stochastic approach for simulating the mass transfer between the interacting matrix and fracture cells this includes simply a probability of particle transfer from one continuum to another say from the matrix to a fracture the transfer probability takes into consideration the particle s path in the continuum or precisely grid cell of the continuum it is formulated such that in ensemble average sense the particle transfers are consistent with the prescribed flux between the interacting grid cells of the two continua crucial to ensure the local mass conservation at sub grid time step levels is the particle s residence time in the grid cell prior to its transfer to the interacting continuum thereby the formulation for the conditional distribution of particle residence time in the eventuality of the inter continuum transfer is also derived in the next section an overview of a stochastic particle based solution method for transport problems is presented and its details are discussed in a in section 3 we briefly describe the formulations for the steady state flow problem in an edfm framework the time adaptive scheme by pollock 1988 is deployed for particle tracking in the grid cells cvs of the matrix and the fractures exclusive of any inter continuum particle transfer this scheme is introduced in section 4 1 but the details are provided in b in section 4 2 we formulate the inter continuum particle transfer probabilities using conservation of solute mass or in advective transport and incompressible flow fluid volume mass then in section 4 3 the conditional distribution of the particle residence time is derived to improve the scheme s efficiency via variance reduction being especially relevant in the scenarios involving high contrast between matrix and fracture volumes the technique of particle splitting and discarding is used discussed in section 5 section 6 summarizes the analyses based on which the conservative nature of the particle tracking scheme is verified in section 7 we showcase the scheme s utility in the prediction of solute transport with an edfm framework and compare its results with those of an eulerian scheme further we discuss the convergence and computational performance of the tracking algorithm and finally outline the key features of the particle based scheme 2 transport prediction with a particle based method with a particle based approach one can estimate the solution of a transport problem by the spatial distribution of computational or notional particles in such approaches the particles evolve as per a set of prescribed rules in the following text we quantify the concentration of a species by its mass fraction in the fluid phase in a given flow field denoted by u x t l t 1 the species mass fraction c can be estimated with an ensemble of n notional particles given as 1 c x t p 1 n m p c p ζ x x p t x p 0 p 1 n m p ζ x x p t x p 0 where m p m represents the solution or fluid phase mass associated with a notional particle and c p is the particle specific mass fraction of the solute species x p l denotes the particle location x p 0 is its initial location at time t 0 and ζ l 3 is a kernel of finite support centered at x p in stochastic approaches the particle mass m p is generally assumed to be time invariant mechanical dispersion if applicable is accounted for by random jumps in the particle trajectory further a mixing model is needed for the evolution of c p due to molecular diffusion meyer et al 2010 or otherwise c p remains constant in its absence in this work however we are interested in purely advective transport i e neither mechanical dispersion nor molecular diffusion is considered a detailed derivation of eq 1 is provided in a here all the particles have the same mass m and ζ is non zero and uniform in a small region δ x centered around x thus we get the spatially averaged species mass fraction and it is given by 2 c x t p 1 n c p h δ x x p t x p 0 p 1 n h δ x x p t x p 0 where h δ x x p is an indicator function such that 3 h δ x x p 1 if x p δ x 0 otherwise note that a solution of the form of eq 1 can be devised for any set of intensive quantities which are transported by the flow and m p c p associated with the particles is interpreted accordingly we are interested in developing a generic formulation which can be extended to multi species settings or even multiphase flows 3 flow in edfm framework 3 1 modeling of fluid flow in a fluid flow model within an edfm framework matrix and fractures are modeled as distinct continua and the interactions between them are modeled by volumetric source sink terms quantifying the fluid exchange at steady state and under fully saturated conditions for a single phase flow in a porous continuum say the rock matrix the volumetric flux q l t 1 can be modeled by darcy s law given as 4 q k m μ p m here k m is the hydraulic permeability tensor l 2 μ is the dynamic viscosity m l 1 t 1 p m is the pore fluid pressure m l 1 t 2 thus the local fluid volume balance in the rock matrix can be formulated as 5 q s 1 n m ψ m s k m μ p m s 1 n m ψ m s 0 here n m is the number of interacting fractures and ψ m s t 1 denotes the volumetric sink term for fluid transfer to a fracture s positive for outflow from the matrix we assume an isotropic permeability tensor and in the discretized form of eq 5 for a matrix control volume cv or grid cell i it is given by 6 k m i k m i 0 0 0 k m i 0 0 0 k m i the notation i refers to the cell with index i and when used as a superscript a cell specific quantity is being addressed a two point flux approximation is used for the flux from the cv i to j across normal to the interface γ given by 7 k m μ p m γ i j t m i t m j t m i t m j p m i p m j with the half transmissibilities t m i k m i μ d m i and t m j k m j μ d m j deb and jenny 2017 here d m l denotes the distance between the cell centroid and the interface further a grid dependent model is used for ψ m s which uses the concept of well like transport index to connect the matrix and the fracture control volumes jiang and younis 2017 for the matrix cv i with size v m i interacting with a fracture s through its surface area a m s i the volume averaged sink is modeled as 8a ψ m s i η m s i p m i p s j 1 v m i where 8b η m s i t m s i t s m i t m s i t s m i 2 a m s i and t m s i k m i μ d m s i and t s m i k s i μ b s i are the transmissivities of half the matrix cv i and the cv of fracture s which interacts with the matrix cv i described in section 3 2 jiang and younis 2017 d m s i l is the average normal distance of the matrix cv from the fracture which is calculated numerically and b s i l is the fracture aperture within the cv i note that the superscript j in eq 8a refers to the cv of fracture s within the matrix cv i similarly the fluid volume balance in a fracture continuum is given by 9 f b f k f μ f p f ψ f m s 1 n f ψ f s 0 the subscript f denotes the quantities analogous to those in eq 5 but for a fracture continuum and the operator f denotes the spatial derivative along the fracture manifold n f is the number of fractures interacting with the fracture f ψ f m l t 1 and ψ f s l t 1 denote the flux interaction terms for fluid transfer to the matrix and another fracture s respectively positive when outflow from the fracture f by maintaining consistency in the formulated volume flow rates from the matrix to the fractures and vice versa ψ f m can be mapped to ψ m s in eq 5 with s f additionally ψ f s involving cvs i and j of fractures f and s respectively is modeled as 10a ψ f s i η f s i p f i p s j 1 a f i where 10b η f s i t f s i t s f i t f s i t s f i here a f i is similar to a m s i defined earlier eq 8b t f s i k f i μ d f s i b f i l f s i is a function of the permeability aperture of the fracture cv length of the intersection line of the two fracture cvs l f s i and the average normal distance d f s i from the fracture cv i to the intersection line in this work for simplicity we assume d f s i to be half the cv i length 3 2 numerical modeling fig 1 shows the schematic of a 2 d matrix domain discretized using a regular orthogonal grid fractures are modeled as 1 d continua and each one is cut into cells segments by the boundaries of the matrix grid cells with suitably applied boundary conditions the discretized pressure field in the matrix and fractures is evaluated using a finite volume based iterative solver this solver is a part of the edfm framework developed by deb and jenny 2017 for coupled flow mechanics problems fluid transfer between the matrix and the fractures occurs through the pair wise interactions between the control volumes which are defined by the same set of matrix cell boundaries similarly marked cvs in fig 1 a the discretized pressure field provides the fluxes normal to the cv boundaries edges for a matrix grid cell and end nodes for a fracture cell as shown in fig 1 b 4 stochastic particle tracking scheme 4 1 particle tracking in a control volume given a cell face centered discrete flow field the particle tracking scheme by pollock 1988 is an efficient means to re construct a particle s trajectory in a grid cell cv of a continuum i e the matrix or a fracture under the assumption that it is not transferred to a sink interacting cv of another continuum the central idea revolves around the use of linear interpolation to model the components of the local velocity within a cv this approach results in a uniform divergence within the cv zero in the absence of any source sink the chosen interpolation scheme results in simple analytical expressions for the temporal step corresponding to a particle s proposed spatial displacement in the cv and vice versa using this scheme one can estimate the time and spatial coordinates at which the particle exits the cv in this work given a particle s location in a cv k at a certain time the time step after which it potentially exits the cv is denoted by δ t e x k the details concerning the estimation of δ t e x k are presented in b in the following text the notation k used as a superscript or otherwise represents the index of the particle s cv at the concerned time use of regular orthogonal grids allows for an efficient mapping of the particle s location x p t and its continuum to index k in our case set up we focus only on the advective particle motion hence the discontinuity of velocity components across the cell faces which are oriented parallel to them is not deterrent to the local solute mass conservation simply the dispersion coefficients are zero and thus have no discontinuity issues discussed in labolle et al 1996 and salamon et al 2006 4 2 particle transfer probability with the discretization depicted in fig 1 b the flow field in the matrix cells containing one or several fractures does not resolve the matrix fracture interface s within the grid cell nevertheless the fluid mass transfer to from a sink source can be modeled either by i assigning a variable mass m p t to each notional particle in the particle based solution of the transport problem eq 1 or ii transferring notional particles between the interacting continua with a certain probability we adopt the latter approach and in this subsection we formulate the probability of particle transfer to the interacting cv of another continuum this probability depends on the particle s trajectory in the current cv denoted by k a notional particle in the cv k is representative of a certain elementary fluid volume δ v f at a uniform solute mass density ρ s or simply the solute mass m let s be the set of the cvs interacting with the cv k and s s be the set of those interacting cvs which act as a positive sink with respect to the cv k the following analysis could be performed in an analogous way using the fluid mass density ρ f and the corresponding elementary fluid mass note that δ v f is much smaller than the characteristic grid cell volume resulting from the domain discretization we adopt the conception of solute mass transfer described by pan et al 2001 during a time interval 0 τ where τ δ t e x k the mass m is divided into portions which are transferred to s s and the remaining portion which stays in k in the following text subscripts s and s are used to denote the elements of set s and s is a summation variable wherever applicable additionally the notation ψ s k being 0 denotes a volumetric sink term t 1 from the cv k to s s the solute mass balance corresponding to the volume δ v f can be formulated as 11 ρ s 0 δ v f 0 m 0 ρ s τ δ v f τ m τ 0 τ ρ s τ δ v f τ m τ 1 ϕ s s ψ s k d τ where m 0 is the initial elementary mass under consideration at the beginning of the aforementioned time interval ϕ is the porosity of the continuum and τ is an intermediate integration variable such that τ τ δ t e x k in the work of pan et al 2001 the mass balance formulations include the interactions with the adjacent cvs of the same continuum these are not relevant in our work as we do not assume instantaneous complete solute mixing and rather model the particle position representative of the elementary mass m in a cv with the flow field being unresolved within the grid cells it is assumed that the strength of volumetric sink s is uniform throughout a cv and hence does not change over the particle s trajectory in k taking the derivative of eq 11 with respect to τ we get 12 d m τ d τ m τ 1 ϕ s s ψ s k the rate of mass transfer scales with the elementary mass and the cumulative strength of the sinks s s ψ s k integration of eq 12 over the interval 0 τ shows that mass m evolves in the cv k as 13 m τ m 0 exp 1 ϕ s s ψ s k τ for sink strengths along the particle s trajectory that stay constant during the mentioned duration as the elementary mass traverses through a cv which has sinks it continuously interacts with them in this work that interaction is simulated in a probabilistic manner via the elementary mass s representative notional particle this particle either is completely transferred to the sink or entirely stays in the cv with the respective probability next we express the corresponding probability for a complete transfer of a notional particle to one of the sinks within the time interval 0 τ to arrive at a probability that is consistent with the gradual mass transfer described by eq 13 the sum of transfer probabilities to any one of the sinks s s has to be 14a s s p k s τ 1 m τ m 0 1 exp 1 ϕ s s ψ s k τ 14b and p k s τ 0 s s s finally to arrive at the individual probability of transfer to a sink s the total transfer probability from eq 14a needs to be scaled by the ratio of the sink strength ψ s k and the cumulative sink strength s s ψ s k that is 15 p k s τ ψ s k s s ψ s k 1 exp 1 ϕ s s ψ s k τ s s the pre factor in the above equation i e the fraction of the volumetric sink strength is the conditional probability of particle transfer to s s given that the event of transfer to any sink occurs based on the particle s current position in the cell the transport scheme by pollock 1988 section 4 1 is used to determine the maximum residence time of the particle in the cv if it were to stay in the same continuum i e δ t e x k in a transport simulation if a user defined time step δ t is used for data recording and analyses then τ min δ t e x k δ t is used as the time step in the particle tracking mass transfer from sources is defined by incoming particles from s s s into the cv and the transfer probability is given by eq 15 but evaluated for the source cv note that eqs 15 and 14a can be reduced to the transfer probabilities formulated by de rooij et al 2013 using mass balance on a streamtube which has a single inflow however to formulate the transfer probability when multiple inflows exist the authors make an assumption to partition the volumetric sink s into contributions from different inflows equations 35 and 36 in de rooij et al 2013 this assumption states that the fraction of a volumetric sink originating from a particular inflow scales linearly with the average travel time of the pathlines associated with that inflow this assumption however can be limiting in the scenarios involving large outflux from the streamtube due to the sink s 4 3 residence time distribution if the transfer to any sink does not occur in 0 τ the particle traverses the cv k and its new coordinates are evaluated by eq b 5 with δ t min δ t e x k δ t as a next step we formulate the distribution of the residence time in the cv k given that the transfer to a sink s occurs here τ 0 τ is used as the corresponding sample space variable and the joint probability density is given by 16 f k s τ p k s τ τ note that f k s τ is a density with respect to time alone but quantifies a joint probability measure in the space of s τ i e the probability of transfer to s s at τ per unit time normalizing f k s τ by the probability of transfer to s irrespective of the residence or transfer time we get the pdf of the residence time conditional on the event of transfer to s in the interval 0 τ it is formulated as 17 f r e s k τ s τ f k s τ p k s τ the cumulative distribution function cdf corresponding to the conditional pdf is given as monga et al 2020 18 f r e s k τ s τ 0 τ f r e s k τ s τ d τ 1 exp 1 ϕ s s ψ s k τ 1 exp 1 ϕ s s ψ s k τ where τ 0 τ 4 4 stochastic particle tracking algorithm firstly given the particle s current position a decision is made regarding the particle s transfer to an interacting cv s s with τ min δ t e x k δ t the decision of particle transfer to s is made using inverse transform sampling in which a uniformly distributed random number ϵ 1 is compared against the discrete cdf given by 19a p j j 1 j p k s j τ j 1 2 n s with s j s and 19b p n s 1 1 here n s denotes the cardinality i e the number of elements in the set s in case the particle is not transferred to any sink it continues to traverse the cv k till the end of the interval 0 τ when τ δ t e x k the particle exits the cv at x p k e x and enters an adjacent cv of the same continuum in the case of particle transfer its residence time in the cv k denoted by τ is sampled from the conditional distribution given by eq 17 or eq 18 the particle traverses the cv k for the duration of τ before jumping to s and propagating further following the jump the particle is moved to a location in s based on a uniform distribution since the flow into the cvs is not resolved to track the particle in the new cv the steps described above are repeated the particle tracking scheme is adaptive with respect to the time steps and this can be confirmed by a simple analysis the probability of transfer to s given by eq 15 satisfies the following 20 p k s τ δ τ p k s τ 1 s s p k s τ p k s δ τ here the first term in the right hand side denotes the probability of transfer to s during the interval 0 τ and the second term denotes the probability of transfer in τ τ δ τ following that the particle is not transferred to any sink in 0 τ with eq 15 the above analysis is true for any combination of τ δ τ for which the volumetric sink term remains constant during 0 τ δ τ the characteristic time step for tracking in the cv k is the maximum particle residence time i e δ t e x k or in case of inter continuum transfer τ the user given time step δ t for particle data recording is a free choice and is neither constrained by nor constrains the outlined tracking scheme the scheme is summarized in algorithm 1 5 splitting and discarding of particles the formulation of the mass fraction estimate eq 2 is based on the assumption that all the particles are equally weighted i e they represent the same amount of mass while this leads to a scheme which is easy to comprehend formulate and implement it comes with a limitation in the applicability because of the high contrast between the volumes of the matrix and the fracture cvs the number of particles per fracture cv may be very small since the statistical quantities like c x t are estimated using the particles in regions of the size of cvs large statistical errors are inevitable e g in the case studies with small fracture apertures and or a very high matrix porosity a variance reduction technique can significantly reduce the errors with only a marginal increase in the computational cost in this work the methodology of particle splitting and discarding is used melnik melnikov et al 1997 it is similar to importance sampling with a fracture cv being the region of interest and seeks for a larger number of particles in the fracture which are lesser weighted than those in the matrix if a particle is transferred from a matrix cv to a fracture cv eq 19a it is split into multiple daughter particles the number of daughter particles n f resulting from each split is a user defined entity the relative particle weight of the daughter particles is then dependent on n f alternatively we prescribe the particle weights w m 1 and w f r 0 w f 1 in the matrix and in the fracture s respectively hereby n f is a function of w f formulated as 21 n f 1 w f if y 1 w f 1 w f 1 w f otherwise here and denote the ceiling and floor functions respectively and y 0 1 is a uniformly distributed random number all the daughter particles have the same timestamp of the transfer and are uniformly distributed in the fracture cv conversely if a particle is to be transferred from a fracture cv to the matrix cv as per eq 19a the transfer is executed only in a probabilistic manner otherwise the particle is killed i e discarded from further tracking computations and the calculation of statistical estimates for a fracture to matrix transfer the probability of the particle being discarded is 1 w f the weight of the surviving particles is increased to w m as they enter the matrix cv thus a particle s weight can take only the discrete values in the set w f w m this stays true even if a different w f is assigned to each fracture the computation of statistical quantities now includes the relative particle weight w p e g 22 c x t p 1 n w p c p h δ x x p t x p 0 p 1 n w p h δ x x p t x p 0 since the number of particles in the matrix remains unchanged the increment in computational costs due to particle splitting and discarding is only marginal 6 verification of the particle tracking scheme mass conservation as part of the verification of the particle tracking scheme we adopted a simple yet comprehensive 2 d domain set up with a permeable matrix and two intersecting 1 d fractures fig 2 a in the chosen set up a matrix domain of size l l l 2 is discretized into a uniform and orthogonal grid of 24 24 cells two 1 d fractures of different lengths having interacting cv pairs between them are embedded in the matrix fig 2 a the relevant hydraulic and geometric properties of the matrix and fractures are mentioned in table 1 the matrix is assumed to be homogeneous and isotropic in the context of its hydraulic properties similarly the fractures are also assumed to be homogeneous it should be noted that at first the resolution of the grid was chosen to be low so that the resulting few matrix fracture interactions can individually be focused on a solute transport problem with sufficient grid resolution is presented in the next section in the subsequent text wherever applicable denotes a dimensionless quantity the span of the domain l is used to normalize the length units a normalized time coordinate t in terms of pvi is used it is given by the fraction of the domain s pore volume that has been injected into the system due to the steady inflow through a boundary external source the key idea of this section is to check for the mass conservative nature of the proposed scheme to this end we considered a homogeneous solute distribution in the domain at t 0 here the fluid phase mass is equi partitioned into a finite number of particles with m p m the mass in the fractures is represented by equally weighted n f r 0 50 000 notional particles however we chose w f 1 4 to reduce the statistical errors in the fracture associated estimates consequently the mass in the matrix is represented by equally weighted n m 0 30 385 200 particles i e 52 752 particles per matrix grid cell a uniform spatial distribution and equal c p c for all particles then corresponds to the mentioned homogeneous setting both in the matrix and the fractures fig 2 b a normalized mean pressure gradient of p was applied in the matrix along the x 1 direction the local pressure gradient which includes contributions from p and the fluctuations due to high conductivity fractures is periodic across all four boundaries periodic boundary conditions allow the particles exiting at a boundary to be reintroduced back into the domain through the opposite boundary with periodic flow boundaries and in the absence of external sources sinks the matrix fracture system with an initially homogeneous concentration field is time invariant thus in the given setting the conservative nature is confirmed based on the following considerations conservation of mass in the fractures at global level in fig 3 we show the evolution of the particle numbers in each fracture marked solid red and blue curves as well as the total number of the particles in the fractures marked golden curve the dashed lines show the particle numbers for the two fractures if the initial number n f r 0 is distributed in proportion to their respective fluid mass volumes or equivalently solute mass the global conservation of the solute mass in each fracture is thus established local conservation of mass in each continuum since the solute mass represented by each particle i e m c is invariant during its motion in either continuum the local particle number density alone determines the solute mass density an estimate of the solute mass density in a small region δ x centered around x is given by 23 ρ s x t m c w n x t ϕ δ x n x t where n x t is the number of particles in δ x and w is the relative weight of the particles in the continuum here in the homogeneous setting n x t should be uniform in each continuum at all times the particle distribution in the matrix at a later time i e at t 1 00 is presented in fig 3 b though only a subset of particles in the matrix is shown it can safely be said that the particles remain uniformly distributed there is no clustering or dilatation of particle clouds even in the regions with non zero divergence fig 4 a shows the particle number density along the length of each fracture at t 1 0 fig 4 b shows the number density in each of the matrix grid cells within the limits of the statistical error the particle number densities adjusted for fluid volume i e n x t remain uniform and thus time invariant within each continuum hence the tracking scheme honors the conservation of mass at local levels since the initial number of particles in each continuum is proportional to the fluid mass volume in it and the associated particle weight n across different continua can be related to each other at all times by the ratio of the particle weights i e n f n m w m w f the number of particle transfers during a finite time interval should be fully consistent with the flow field fig 5 a shows the number of particles that were transferred from the matrix cells in the duration t 0 9 1 0 fig 5 b is complementary to fig 5 a as it shows the particle transfers from the fractures to the matrix cells in the same time duration figs 5 c and 5 d present the theoretical counterparts of figs 5 a and 5 b respectively here the number of transfers are calculated directly from the flux interactions between different continua in whichever cells it is applicable and the initial particle number in the computational domain figs 5 e and 5 f show the relative error between the empirically estimated and the theoretically calculated transfers the maximum of the relative error in fig 5 e is associated with a cell that has a very low outflux and thus a low number of transfers figs 5 a and 5 c thus the scheme in an average sense correctly simulates the mass transfer between the interacting continua a steady mass flux is simulated by a uniform distribution of the timestamps of particle transfers from say a matrix cell to a fracture cell sink in fig 6 we present the distribution of the timestamps of particle transfers from a matrix cell the one with highest transfers in fig 5 a to the interacting fracture cell sink or alternatively the arrival time distribution in the fracture cell the distribution is based on the timestamps of 399 353 particles transfers that were recorded in the interval t 0 9 1 0 the resulting uniform distribution showcases in an empirical way that the particle specific residence time pdf eq 17 is consistent with the steady state flux a similar analysis can be done for much smaller time intervals provided that a sufficiently large number of particles are used and it infact holds true for any arbitrarily chosen interval 7 solute transport with the particle tracking scheme to illustrate the capabilities of the proposed particle tracking scheme we consider a matrix fracture system which is more complex than the one described in the previous section it is a 2 d square domain model of size l l l 2 in a quarter five spot configuration with impermeable wall boundaries fig 7 in the numerical set up the matrix is discretized into a uniform and orthogonal grid of 100 100 square cells normalized cell size vector δ 0 01 0 01 t twelve 1 d fractures of different lengths are embedded in the matrix fractures have multiple pair wise intersections but there is no percolation of the domain through the fractures the relevant hydraulic properties of the matrix and fractures are the same as mentioned in table 1 there is no solute mass in the system at t 0 but the domain is saturated with the fluid a source of solute and a sink are distributed over square regions at the bottom left and top right corners respectively regions bounded by red dashed lines in fig 7 the influx normalized with the inverse of time required to inject a volume equivalent to the pore volume is given by 24 q 10 0027 if 0 0 x 1 0 1 0 0 x 2 0 1 10 0027 if 0 9 x 1 1 0 0 9 x 2 1 0 0 0 otherwise in the numerical simulation the initial fluid mass in the fractures is represented by n f r 0 100 000 equally weighted notional particles in accordance with w m 1 and w f 1 12 the fluid mass in the matrix is represented by n m 0 31 334 360 particles or 3 133 particles per matrix cell further c p 0 p 1 n f r 0 n m 0 with the progression of time solute particles enter the domain and are uniformly distributed in the regions with q 0 for simplification of the analyses and without loss of generality c p 1 for these solute particles each particle s motion is independent and is dictated by the local pore velocity in its continuum eq b 5 and the probabilities of transfer to other continua eq 15 all the particles exiting through the regions with q 0 are excluded from further tracking the average solute mass fraction can be estimated according to eq 22 in fig 8 we show the spatial distribution of the particles with c p 0 in the matrix at an early time t 0 125 intermediate times t 0 250 0 375 and a later time t 0 500 the high conductivity fractures act as preferential flow paths and the expedited transport by the fractures is very evident figs 9 a 9 b and 9 c show the evolution of the solute mass fraction concentration field in the matrix at different instants it should be emphasized that with sufficient particles the sampling region size could be much smaller than the grid cell size used for flow computations figs 9 d 9 e and 9 f show the corresponding fields resulting from a first order upwind scheme with forward euler integration as with conventional eulerian methods numerical diffusion is clearly observable in this scenario with pre dominantly oblique flow across a majority of matrix cells the particle tracking scheme on the other hand captures sharp fronts a feature of purely advective transport note that these figures present pixel wise mass fraction values without any smoothing in the post processing step figs 9 g 9 h and 9 i highlight the differences in the concentration fields resulting from the two approaches and they primarily differ near the regions of a high gradient the eulerian approach underpredicts the higher concentration value and overpredicts the lower one when the jump occurs over a short length scale the differences are also highlighted in the cross sectional concentration profiles presented in figs 12 a 12 b and 12 c discussed in the next section in figs 10 a 10 b and 10 c the concentrations in the fractures at different times are presented figs 10 d 10 e and 10 f show the counterparts when w f 1 0 i e splitting and discarding of particles is not deployed the number of particles in the matrix is kept the same n m 0 31 334 360 figs 10 g 10 h and 10 i show the absolute differences between the two cases i e with and without considering the splitting and discarding of particles when w f 1 0 a few of the fracture cells may not contain any particle considering that the low average particle numbers may intermittently be overcome by statistical fluctuations for simplifying the analysis the concentration value in such fracture cells is assigned to zero 7 1 model performance and errors the sharpness of the estimated concentration profiles can further be improved with smaller sampling regions irrespective of the discretization grid used for the flow problem however this warrants the use of a higher number of particles to achieve statistical convergence each particle in this linear transport problem is an independent realization thereby particle tracking schemes can remarkably benefit from a parallel implementation transport simulations were performed on a state of the art multi node distributed cluster system and a domain decomposition technique was adopted with 20 processor cores each core handles the particle ensemble in its assigned subdomain of 20 25 matrix cells and the associated fracture cells and the particles spatio temporal coordinates are communicated to the neighboring cores as the particles cross the subdomain boundaries we report the computation run times up to t 0 5 with n p 0 n m 0 n f r 0 31 434 360 the run time for the particle tracking scheme amounted to 10 379 s while that for the eulerian scheme was 2 352 s it should be noted that the same domain decomposition is used for the eulerian transport simulation as well the run time of a particle based simulation in general scales linearly with the number of particles and this is confirmed by our simulations with varying particle numbers precisely n p 0 n p 0 n p 0 5 n p 0 10 n p 0 25 n p 0 100 fig 11 thus when using n p 0 4 5 particles which translates to 700 particles per matrix cell the run times of the particle tracking and eulerian simulations are comparable here all the processes have a nearly similar work load because the particles with c p 0 were tracked as well in case only the particles with c p 1 are tracked dynamic load balancing should be adopted to obtain an optimal scaling with respect to the number of cores optimization of the parallel implementation to achieve a favorable scaling with respect to the number of cores is planned for future works further the optimal parallel set up to achieve the peak speed up is case specific the downside of using lower particle numbers is the increased statistical error in the mass fraction estimates figs 12 a 12 b and 12 c present the estimated profiles at x 1 0 25 0 50 0 90 from the simulations with n p 0 n p 0 10 n p 0 25 n p 0 100 in fig 12 d the mass fraction field at t 0 5 estimated with n p 0 100 is shown it should be noted that for the cases with lower number of particles a few of the fracture cells may contain no particles irrespective of the statistical noise the particle scheme does not suffer from bias errors the noise being purely statistical in nature averages out for time space integrated transport metrics e g overall mass in the system cumulative mass transferred to the sink this is clearly observable in fig 13 where the breakthrough curves from the simulations with n p 0 n p 0 n p 0 10 n p 0 25 n p 0 100 overlap here breakthrough is quantified by the solute mass particles with c p 1 transferred to the sink the region at top right in fig 7 up to time t normalized by the mass transferred up to t 0 5 for the case with n p 0 particles for the considered case of linear solute transport the statistical noise is an acceptable trade off in favor of significant computational gains however in case of non linear transport elimination of noise is critical because the errors in the mass fraction estimates can get propagated in time when using a lower number of particles a denoising or filtering algorithm can be used to curtail the statistical errors however the choice of the filter should be such that it preserves i the total solute mass and ii the sharp edges which are key advantages of the particle tracking approach engquist et al 1989 suggested a series of conservative non linear filtering algorithms which have been applied to numerical solution of non linear hyperbolic transport equations the central principle of these filters is smoothing of local extrema which are quite often manifestations of statistical noise the conservative nature is ensured by selectively modifying the neighbor s of the extremum in consideration we used an adaptation of one of their comprehensive filters algorithm 2 4 in engquist et al 1989 and applied it to the mass fraction estimates with n p 0 100 however such a filtering algorithm introduces artefacts in very narrow regions a few cells wide having a significant jump in the profile along either direction other alternatives include the filtering techniques developed for image processing however many of these techniques are not conservative with respect to the integral of the intensity i e solute mass in the context of this work wavelet based denoising strategies are conservative and sufficiently capable in preserving sharp edges a simple implementation includes decomposition of the signal image into a family of wavelets followed by the attenuation of high frequency noise to a certain threshold misiti et al 1996 the noise may only be present in certain sections of the signal thus the wavelet based approaches are preferred over the conventional fourier decomposition based denoising approaches which assume stationarity of the signal the choice of a suitable wavelet and thresholding strategy is problem specific and hence goes beyond the scope of this work 8 conclusions and remarks in stochastic particle based methods the evolution of computational particles or precisely dirac measures is governed by a set of probabilistic rules such that the particles represent in the ensemble average sense a continuum behavior thus particle methods offer a very natural way to connect microscopic unresolved phenomena with macroscopic quantities in this work we have formalized probabilistic rules for particle transitions that simulate fluxes between matrix and fractures in a fractured porous medium for the fractured media an embedded discrete fracture model edfm was adopted particle tracking in each continuum is deterministic by the virtue of the eulerian flow field however with the flow field being not resolved within grid cells inter continuum mass exchange is not comprehensible in terms of the particle pathlines henceforth a probabilistic scheme was devised for the transfers between the fracture and the matrix continua the transfer probability is specific for each particle and its trajectory in a grid cell forgoing any assumption of complete mixing additionally its formulation does not constrain the time step size and thus holds true for any duration in the particle s flight for which the flux to the other continuum or any other sink stays uniform hence the tracking scheme is time adaptive with the upper limit for the particle specific time step being set by the traverse time in the grid cell finally a conditional distribution for the residence time was formulated in the derived formulations the probability of transfer has a negative exponential scaling with the time spent by the particle in a grid cell often a linear scaling is assumed and henceforth the time step size is capped so that the transfer probability does not exceed unity the linear scaling inherently assumes that the probability of transfer per travel time is uniform however the negative exponential scaling is a result of the transfer probability per displacement in either direction being uniform which is consistent with the spatially uniform strength of the sink s in a grid cell using a simple numerical experiment it was shown that the tracking scheme preserves an initially uniform solute distribution in a system of a permeable matrix and intersecting fractures demonstrating its conservative nature the residence time distribution leads to a temporally stationary particle transfer rate in the ensemble sense consistent with the flux to the sink s the transfer probability and the associated residence time distribution are general in their application to any random walk particle method with sources sinks we envision to include them as a part of a stochastic model for non linear transport including reactions between different phases and or species this transport model will be tailored for an edfm set up with a heterogeneous matrix and fractures further the conventional edfm based approach is shown to be inept in correctly simulating the flow field if fractures have a lower conductivity than the matrix and thus act as flow barriers the projection based edfm pedfm approach has been developed primarily to address this limitation of the edfms ţene et al 2017 the probabilistic particle tracking approach is easily extendible to a pedfm wherein direct particle transfers to the non neighboring connections simulate the corresponding flux the modified corrected fluxes to neighboring connections should be accounted for in the calculation of the corresponding particle transfer probabilities as illustrated by the transport simulations conducted in this work it is possible to simulate sharp fronts particle tracking approach offers an attractive alternative for modeling reactive transport where in the dispersion limited regime mixing at the sub grid level may be incomplete and the macroscopic reaction rates may not hold well then the dynamics towards the local equilibrium can be vastly different from that predicted by eulerian methods using macroscopic reaction rate laws with cell averaged quantities e g composition of species particles on the other hand can model the sub grid level distributions of the species compositions these computational particles can be thought of as elementary fluid phase volumes and in a multi species setting their characterization may include the compositions a particle thus evolves in the compositional space because of the reactions in the fluid phase or between the fluid phase and the solid grains of the porous medium modeling of the particle trajectories in the compositional space can be based on a relevant microscopic physical law in addition particle tracking schemes are well versed to model reactions where the macroscopic reaction laws do hold true for example equilibrium sorption desorption reactions characterized by a linear isotherm can simply be included in the particle tracking scheme then transformed pore velocities and dispersion coefficients involving retardation coefficients are used in the estimation of particle trajectories kinzelbach and uffink 1991 further a particle transition probability similar to the one presented in this work simulates mass transitions between two reaction states e g sorbed aqueous states when the reaction kinetics is described by a first order rate valocchi and quinodoz 1989 sub grid dispersion in each continuum and the effects of molecular diffusion can be captured by adding a wiener process to particle trajectories and including a mixing model for particle specific solute mass fractions respectively however for edfms the primary challenge lies in the modeling of inter continuum diffusive dispersive fluxes further the developed model for inter continuum fluxes should facilitate formulation of a compliant and preferably an exact transfer probability along these lines a prospective first step could be the approach of liu et al 2000 for dual continua models where second order reconstruction is used for the matrix concentration profiles in the vicinity of fractures this enables an interfacial concentration gradient and thus the diffusive flux to be modeled as a linear function of the cell averaged concentration difference between the two continua thereby a straightforward correspondence between the particle transfers and the inter continuum flux is established generally the macroscopic quantities of interest are derived from statistical moments under the assumption of local ergodicity thus keeping statistical errors in check becomes crucial when using particle based methods for non linear problems as is generally the case with particle based approaches we report a linear scaling of the computation time with particle numbers variance reduction techniques and or filtering techniques can be effective and do not significantly add to the computational costs but finding a suitable approach for a wide range of applications needs more attention extension of the particle tracking scheme to 3 d edfms is rather uncomplicated the significance of variance reduction filtering techniques is further enhanced in 3 d applications where the computational costs in view of statistical convergence can be considerably high credit authorship contribution statement ranit monga conceptualization methodology software formal analysis writing original draft rajdeep deb software methodology writing review editing daniel w meyer conceptualization methodology formal analysis writing review editing supervision patrick jenny conceptualization methodology formal analysis writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments ranit monga and patrick jenny acknowledge financial support by the swiss national science foundation snsf through the grant snf 200021 178922 1 rajdeep deb acknowledges financial support provided through the grant geotherm ii switzerland and daniel w meyer acknowledges financial support from eth zürich switzerland the funding sources have no involvement in the study design the preparation of the article and decisions related to its publication the authors thank michael liem and giulia conti eth zürich for proofreading and helpful suggestions appendix a particle based solution of transport problem in a multi species setting with a given flow field denoted by u x t l t 1 mass conservation at the macroscopic level can be formalized with a transport equation for the fluid phase solution density ρ f x t m l 3 as given by a 1 ϕ ρ f t v ϕ ρ f 0 here the porosity ϕ is assumed to be uniform throughout the medium v l t 1 is the average pore velocity i e u ϕ with a particle based approach we seek a solution ρ f of the transport equation eq a 1 salamon et al 2006 given by a 2 ϕ ρ f x t m t δ x x p t where x p l denotes the position of a notional particle δ denotes a dirac delta function and is an averaging operator further the parameter m has the dimension m an integration of the eq a 2 over the physical domain suggests that m represents the total fluid mass in the domain numerically the averaging involves summation over a particle set of finite size n and one obtains an approximate solution ρ f n a particle with index p 1 n has a random initial location x p 0 at time t 0 accordingly the particle s trajectory follows an average streamline in the microscopic pore flow given by a 3 x p t x p 0 t 0 t v x p t x p 0 t d t the choice of the number of particles n is dictated by the balance between the desired accuracy and efficiency since n is finite ρ f n is discrete in the space of the independent variables and is discontinuous a pragmatic approach towards this issue is the regularization of this approximate solution formalized as a 4 ρ f x t ω ρ f n x t ζ x x d x where ζ x x is a kernel or regularization function with finite support such that a 5 ω ζ x d x 1 thus the regularized particle based estimate is given by a 6 ρ f x t 1 ϕ p 1 n m p t ζ x x p t x p 0 where m p is the fluid phase mass associated with each particle i e m p m n if all the particles are equally weighted in a statistical sense in the absence of source sink s as well as in and outflow boundaries m p is time invariant nevertheless addition removal of particles can account for them if present further m p and x p 0 for each particle are determined from the initial conditions and the choice of relative particle weights for example the spatial distribution of particles at t 0 is directly related to the initial mass density field if m p is the same for all particles solute transport at the macroscopic level is generally modeled with an advection dispersion equation ade for the mass density of a solute species ρ s m l 3 given by a 7 ϕ ρ s t v ϕ ρ s d ϕ ρ s here d l 2 t 1 is the mechanical dispersion coefficient tensor and molecular diffusion is assumed to be negligible a particle based approximate solution can be given by a 8 ρ s n x t 1 ϕ p 1 n m p c p t δ x x p t x p 0 where c p represents the particle specific mass fraction of the solute species and denotes the conditional averaging operator i e the expectation for a particle originating at x p 0 corresponding to eq a 8 a particle evolves in physical space as a 9 d x p t v x p t t t d t t d t b x p t t d w such that 1 2 b b t d and w denotes a multivariate wiener process kinzelbach 1988 tompson and dougherty 1992 further c p is time invariant in the absence of mixing due to molecular diffusion in the absence of dispersion i e d 0 a particle s position in the physical space is also given by eq a 3 and the trajectory is purely deterministic the particle based solution requires a regularization step similar to eq a 4 the resulting regularized solution is denoted by ρ s finally the mass fraction of a species can be formalized as the ratio of the species mass density ρ s and the fluid phase density ρ f given by a 10 c x t p 1 n m p c p ζ x x p t x p 0 p 1 n m p ζ x x p t x p 0 appendix b conservative particle tracking in a control volume the conservative tracking scheme by pollock 1988 is used to estimate the particle s maximum residence time in the cv k and also the prospective spatial coordinates of exit the following text describes the relevant assumptions and formulations a global cartesian coordinate system is chosen such that the orthogonal matrix cell boundaries are aligned with the coordinate axes this global coordinate system is used for particle tracking in the matrix for each fracture a local coordinate system is used its axis is oriented along the principal fracture dimension the principal components of velocity in the matrix are the cartesian components which are denoted by v i where i 1 2 for a 2 d cv in a 1 d fracture the velocity is oriented along the length of the fracture and i 1 propagation of a particle in space and time needs the local velocity information eq a 3 the components of the local velocity in a cv are obtained by linear interpolation of the values at the cv boundaries fig 1 b as used in pollock 1988 and meyer and jenny 2004 for a cv with index k the linear interpolation shape function for dimension i is given by b 1 a i k v i x i k 2 v i x i k 1 x i k 2 x i k 1 where the superscript k 1 and k 2 denote the boundaries of the cv k such that x i k 2 x i k 1 the local velocity at a coordinate x i x i k 1 x i k 2 is calculated as b 2 v i x i v i x i k 1 a i k x i x i k 1 here we use the subscript p in the upper case notations for particle related variables along with the subscript i for the dimension wherever applicable pollock 1988 has derived the analytical expression for the particle travel time corresponding to its displacement δ x p i within the cv given by b 3 δ t 1 a i k ln v i x p i δ x p i v i x p i if a i k 0 δ x p i v i x p i otherwise the above expression is devised and valid for the scenarios when the criterion b 4 v i x p i δ x p i v i x p i 0 along with v i x p i δ x p i 0 is met in case of non compliance either the particle cannot traverse across a stagnation point i e x i x p i x p i δ x p i v i x i 0 or it cannot traverse in the proposed displacement direction i e v i x p i δ x p i 0 alternatively the particle s coordinate after a given time step δ t is given by b 5 x p i t δ t x p i t v i x p i a i k exp a i k δ t 1 if a i k 0 x p i t v i x p i δ t otherwise which results from the reformulation of eqs b 2 and b 3 assuming that the particle does not get transferred to a sink and exits the cv through a boundary in the i th dimension the prospective exit coordinate is given by b 6 x p i k e x x i k 2 if v i x p i 0 x i k 1 if v i x p i 0 the proposed particle exit time δ t e x i k can be evaluated from eq b 3 using δ x p i x p i k e x x p i conditional that the particle can exit the cv in the i th direction under the conditions given by expression b 4 in all other scenarios the particle cannot reach the proposed exit coordinate and exits the cv in another direction or through a sink given the particle s current position and assuming no transfer to another continuum the particle s residence time in the cv is given by b 7 δ t e x k min δ t e x i k i 1 2 for i δ t e x i k δ t e x k the exit coordinate x p i k e x can be evaluated with eq b 5 
62,advection dominated transport processes in sub surface formations are characterized by discontinuities in the fields of transported quantities and realistic predictions are challenging for eulerian transport schemes because they suffer from numerical diffusion henceforth we have focused on developing a lagrangian particle tracking scheme for modeling advective solute transport in fractured media to this end we adopt an embedded discrete fracture model edfm for fractured media with a permeable matrix the flexibility to use non conformal fracture matrix discretizations makes edfms a compelling choice in field scale flow problems unaffected by the numerical diffusion lagrangian transport schemes complement the potential of edfms by allowing the use of sufficiently large grid cell sizes for flow field computations in an edfm framework the inter continuum fluid mass exchange cannot be quantified by the particle trajectories pathlines due to the unresolved fracture matrix interfaces and different dimensionalities of the matrix and fracture discretizations these constraints motivate the use of a stochastic particle tracking scheme and thus we formulated a pathline specific probability of inter continuum particle transfer based on mass conservation of an elementary solute fluid mass the particle s transfer probability is calculated for the maximum residence time period in its associated fracture matrix control volume thus making the scheme time adaptive in addition a conditional residence time distribution was derived which dictates the timestamp of the particle transfer first we showcase that the tracking scheme preserves the initially homogeneous solute concentration field suggesting that the probabilistic rules are consistent with the inter continuum fluxes additionally we illustrate the estimation of an evolving solute plume and compare the results with those of an eulerian counterpart the presented stochastic approach enables straightforward formulations of lagrangian models for dynamic and sub grid processes e g solute interactions with the solid phase the mapping of their effects onto large scale transport and additionally be included in random walk models for dispersion keywords particle tracking transfer probability embedded discrete fracture model variance reduction solute transport data availability data will be made available on request 1 introduction 1 1 solute transport with particle tracking methods in the modeling of solute transport lagrangian particle tracking methods are compelling alternatives to finite element volume based eulerian methods a particle tracking method is a numerical technique to simulate the temporal evolution of a system where an intensive quantity is approximated by a linear combination of a large but finite number of dirac measures or simply computational particles tompson and dougherty 1988 a particle s state space generally includes its physical coordinates and other attributes e g a certain mass of the solute in the case of a solute transport problem alternatively a computational or notional particle is an abstraction for a packet of species molecules being transported in the flow field therefore particle based methods can bridge the gap between macroscopically observed state variables e g the solute concentration and the molecular interactions driving the evolution of the macroscopic variables benson and meerschaert 2008 particle tracking methods do not suffer from numerical diffusion and hence are particularly relevant for advection dominated flow scenarios with low mixing rates which are characterized by sharp concentration fronts michalak and kitanidis 2000 complementary to this particle based methods provide more realistic predictions of reaction rates in mixing limited conditions as they do not rely on the assumption of well mixed solute in eulerian grid cells or volumes hence relatively coarse grids can be used for the flow field resolution without compromising the accuracy of transport predictions kapoor and kitanidis 1998 during a particle tracking simulation computation of the solute concentration on an eulerian grid may not be necessary which implies that the statistical errors associated with the corresponding estimates do not propagate to the next time step in purely advective transport processes and in the absence of a source sink divergence free local velocity ensures that the fluid mass as well as the solute mass are conserved pollock 1988 in a tracking scheme global mass conservation can be indicated by the consistency in the number of particles in the computational domain random walk particle methods rwpms are often used to model transport processes involving dispersion diffusion they are based on the similarity between the fokker planck equation and the classical advection dispersion equation kinzelbach 1988 delay et al 2005 local conservation of the solute mass may not be rudimental in many such transport schemes labolle et al 1996 and salamon et al 2006 discuss rwpm techniques to tackle discontinuities in the upscaled properties of heterogeneous media e g the dispersion tensor when dealing with the transport of a conservative solute 1 2 particle tracking methods involving particles with discrete state space valocchi and quinodoz 1989 have used notional particles to simulate solute mass undergoing a sorption desorption reaction and these particles evolve as per a two state continuous time markov chain this is viable because there is a similarity between the evolution equation for the aqueous solute concentration precisely solute mass density in a first order sorption desorption reaction and that for the probability of a notional particle being in a particular discrete state eqs 5 and 12 in valocchi and quinodoz 1989 for coupled surface subsurface set ups de rooij et al 2013 have formulated a pathline specific probability of particle transfer from a 2 d overland domain to a 3 d subsurface domain 1 3 particle tracking methods for fractured porous media in an analogous way but in the context of fractured media mass transfer between fracture and matrix representations can be conceptualized as transitions of particles between discrete states for diffusive mass transfer in dual continua models liu et al 2000 have quantified the cell wise average probability of transfer between the matrix and the fracture continua however with their assumption of complete mixing within grid cells the probability formulation does not account for the particle s location within a grid cell and lagrangian transit time distributions cannot be correctly estimated as reported by de rooij et al 2013 the probability formulation is explicit in nature which puts an upper bound on the allowed time step size and thus constrains the efficiency of the overall transport framework additionally the approach to split the time step into residence times in different states is not consistent with the transfer probability pan et al 2001 proposed that the particles travel in only one continuum during a time step and that the transfers happen at the end of the time step however this approach limits the temporal resolution of the transfers and additionally complete mixing within the grid cells is assumed in this work as well 1 4 models for fractured porous media irrespective of the lagrangian transport scheme the limitations of multi continua models in accurately simulating the flow fields e g their applicability being limited to domains with highly connected fractures and near uniform properties also limits the overall flow and transport framework the notable alternates include a multitude of discrete fracture models dfms which incorporate fractures as discrete representations and account for the effects of individual fractures and their connectivities on the fluid flow jiang and younis 2017 embedded discrete fracture models edfms provide a good balance between accuracy and efficiency in simulating the flow fields for field scale applications in edfm frameworks the matrix is discretized independently of fractures and the individual fracture geometries are resolved but treated as lower dimensional manifolds hajibeygi et al 2011 deb and jenny 2017 jiang and younis 2017 the characteristics of edfm frameworks render a combination with particle based transport schemes attractive as larger grid cells can be used without the risk of having excessively smeared concentration fronts complementary to this the often used structured grids for the matrix supports simple implementations of particle tracking schemes a typical challenge for particle based schemes in fractured domain models is the modeling of interactions between the fractures and the matrix two sub domains often subjected to very different velocities and characteristic time scales in addition fractures often occupy a very small volume compared to the matrix which renders conventional particle based schemes inefficient 1 5 scope of this paper in this paper we propose based on our earlier work monga et al 2020 a stochastic particle tracking scheme suited for embedded discrete fracture models of fractured media with a permeable matrix with the flow field inside grid cells or finite control volumes cvs not being resolved we use a stochastic approach for simulating the mass transfer between the interacting matrix and fracture cells this includes simply a probability of particle transfer from one continuum to another say from the matrix to a fracture the transfer probability takes into consideration the particle s path in the continuum or precisely grid cell of the continuum it is formulated such that in ensemble average sense the particle transfers are consistent with the prescribed flux between the interacting grid cells of the two continua crucial to ensure the local mass conservation at sub grid time step levels is the particle s residence time in the grid cell prior to its transfer to the interacting continuum thereby the formulation for the conditional distribution of particle residence time in the eventuality of the inter continuum transfer is also derived in the next section an overview of a stochastic particle based solution method for transport problems is presented and its details are discussed in a in section 3 we briefly describe the formulations for the steady state flow problem in an edfm framework the time adaptive scheme by pollock 1988 is deployed for particle tracking in the grid cells cvs of the matrix and the fractures exclusive of any inter continuum particle transfer this scheme is introduced in section 4 1 but the details are provided in b in section 4 2 we formulate the inter continuum particle transfer probabilities using conservation of solute mass or in advective transport and incompressible flow fluid volume mass then in section 4 3 the conditional distribution of the particle residence time is derived to improve the scheme s efficiency via variance reduction being especially relevant in the scenarios involving high contrast between matrix and fracture volumes the technique of particle splitting and discarding is used discussed in section 5 section 6 summarizes the analyses based on which the conservative nature of the particle tracking scheme is verified in section 7 we showcase the scheme s utility in the prediction of solute transport with an edfm framework and compare its results with those of an eulerian scheme further we discuss the convergence and computational performance of the tracking algorithm and finally outline the key features of the particle based scheme 2 transport prediction with a particle based method with a particle based approach one can estimate the solution of a transport problem by the spatial distribution of computational or notional particles in such approaches the particles evolve as per a set of prescribed rules in the following text we quantify the concentration of a species by its mass fraction in the fluid phase in a given flow field denoted by u x t l t 1 the species mass fraction c can be estimated with an ensemble of n notional particles given as 1 c x t p 1 n m p c p ζ x x p t x p 0 p 1 n m p ζ x x p t x p 0 where m p m represents the solution or fluid phase mass associated with a notional particle and c p is the particle specific mass fraction of the solute species x p l denotes the particle location x p 0 is its initial location at time t 0 and ζ l 3 is a kernel of finite support centered at x p in stochastic approaches the particle mass m p is generally assumed to be time invariant mechanical dispersion if applicable is accounted for by random jumps in the particle trajectory further a mixing model is needed for the evolution of c p due to molecular diffusion meyer et al 2010 or otherwise c p remains constant in its absence in this work however we are interested in purely advective transport i e neither mechanical dispersion nor molecular diffusion is considered a detailed derivation of eq 1 is provided in a here all the particles have the same mass m and ζ is non zero and uniform in a small region δ x centered around x thus we get the spatially averaged species mass fraction and it is given by 2 c x t p 1 n c p h δ x x p t x p 0 p 1 n h δ x x p t x p 0 where h δ x x p is an indicator function such that 3 h δ x x p 1 if x p δ x 0 otherwise note that a solution of the form of eq 1 can be devised for any set of intensive quantities which are transported by the flow and m p c p associated with the particles is interpreted accordingly we are interested in developing a generic formulation which can be extended to multi species settings or even multiphase flows 3 flow in edfm framework 3 1 modeling of fluid flow in a fluid flow model within an edfm framework matrix and fractures are modeled as distinct continua and the interactions between them are modeled by volumetric source sink terms quantifying the fluid exchange at steady state and under fully saturated conditions for a single phase flow in a porous continuum say the rock matrix the volumetric flux q l t 1 can be modeled by darcy s law given as 4 q k m μ p m here k m is the hydraulic permeability tensor l 2 μ is the dynamic viscosity m l 1 t 1 p m is the pore fluid pressure m l 1 t 2 thus the local fluid volume balance in the rock matrix can be formulated as 5 q s 1 n m ψ m s k m μ p m s 1 n m ψ m s 0 here n m is the number of interacting fractures and ψ m s t 1 denotes the volumetric sink term for fluid transfer to a fracture s positive for outflow from the matrix we assume an isotropic permeability tensor and in the discretized form of eq 5 for a matrix control volume cv or grid cell i it is given by 6 k m i k m i 0 0 0 k m i 0 0 0 k m i the notation i refers to the cell with index i and when used as a superscript a cell specific quantity is being addressed a two point flux approximation is used for the flux from the cv i to j across normal to the interface γ given by 7 k m μ p m γ i j t m i t m j t m i t m j p m i p m j with the half transmissibilities t m i k m i μ d m i and t m j k m j μ d m j deb and jenny 2017 here d m l denotes the distance between the cell centroid and the interface further a grid dependent model is used for ψ m s which uses the concept of well like transport index to connect the matrix and the fracture control volumes jiang and younis 2017 for the matrix cv i with size v m i interacting with a fracture s through its surface area a m s i the volume averaged sink is modeled as 8a ψ m s i η m s i p m i p s j 1 v m i where 8b η m s i t m s i t s m i t m s i t s m i 2 a m s i and t m s i k m i μ d m s i and t s m i k s i μ b s i are the transmissivities of half the matrix cv i and the cv of fracture s which interacts with the matrix cv i described in section 3 2 jiang and younis 2017 d m s i l is the average normal distance of the matrix cv from the fracture which is calculated numerically and b s i l is the fracture aperture within the cv i note that the superscript j in eq 8a refers to the cv of fracture s within the matrix cv i similarly the fluid volume balance in a fracture continuum is given by 9 f b f k f μ f p f ψ f m s 1 n f ψ f s 0 the subscript f denotes the quantities analogous to those in eq 5 but for a fracture continuum and the operator f denotes the spatial derivative along the fracture manifold n f is the number of fractures interacting with the fracture f ψ f m l t 1 and ψ f s l t 1 denote the flux interaction terms for fluid transfer to the matrix and another fracture s respectively positive when outflow from the fracture f by maintaining consistency in the formulated volume flow rates from the matrix to the fractures and vice versa ψ f m can be mapped to ψ m s in eq 5 with s f additionally ψ f s involving cvs i and j of fractures f and s respectively is modeled as 10a ψ f s i η f s i p f i p s j 1 a f i where 10b η f s i t f s i t s f i t f s i t s f i here a f i is similar to a m s i defined earlier eq 8b t f s i k f i μ d f s i b f i l f s i is a function of the permeability aperture of the fracture cv length of the intersection line of the two fracture cvs l f s i and the average normal distance d f s i from the fracture cv i to the intersection line in this work for simplicity we assume d f s i to be half the cv i length 3 2 numerical modeling fig 1 shows the schematic of a 2 d matrix domain discretized using a regular orthogonal grid fractures are modeled as 1 d continua and each one is cut into cells segments by the boundaries of the matrix grid cells with suitably applied boundary conditions the discretized pressure field in the matrix and fractures is evaluated using a finite volume based iterative solver this solver is a part of the edfm framework developed by deb and jenny 2017 for coupled flow mechanics problems fluid transfer between the matrix and the fractures occurs through the pair wise interactions between the control volumes which are defined by the same set of matrix cell boundaries similarly marked cvs in fig 1 a the discretized pressure field provides the fluxes normal to the cv boundaries edges for a matrix grid cell and end nodes for a fracture cell as shown in fig 1 b 4 stochastic particle tracking scheme 4 1 particle tracking in a control volume given a cell face centered discrete flow field the particle tracking scheme by pollock 1988 is an efficient means to re construct a particle s trajectory in a grid cell cv of a continuum i e the matrix or a fracture under the assumption that it is not transferred to a sink interacting cv of another continuum the central idea revolves around the use of linear interpolation to model the components of the local velocity within a cv this approach results in a uniform divergence within the cv zero in the absence of any source sink the chosen interpolation scheme results in simple analytical expressions for the temporal step corresponding to a particle s proposed spatial displacement in the cv and vice versa using this scheme one can estimate the time and spatial coordinates at which the particle exits the cv in this work given a particle s location in a cv k at a certain time the time step after which it potentially exits the cv is denoted by δ t e x k the details concerning the estimation of δ t e x k are presented in b in the following text the notation k used as a superscript or otherwise represents the index of the particle s cv at the concerned time use of regular orthogonal grids allows for an efficient mapping of the particle s location x p t and its continuum to index k in our case set up we focus only on the advective particle motion hence the discontinuity of velocity components across the cell faces which are oriented parallel to them is not deterrent to the local solute mass conservation simply the dispersion coefficients are zero and thus have no discontinuity issues discussed in labolle et al 1996 and salamon et al 2006 4 2 particle transfer probability with the discretization depicted in fig 1 b the flow field in the matrix cells containing one or several fractures does not resolve the matrix fracture interface s within the grid cell nevertheless the fluid mass transfer to from a sink source can be modeled either by i assigning a variable mass m p t to each notional particle in the particle based solution of the transport problem eq 1 or ii transferring notional particles between the interacting continua with a certain probability we adopt the latter approach and in this subsection we formulate the probability of particle transfer to the interacting cv of another continuum this probability depends on the particle s trajectory in the current cv denoted by k a notional particle in the cv k is representative of a certain elementary fluid volume δ v f at a uniform solute mass density ρ s or simply the solute mass m let s be the set of the cvs interacting with the cv k and s s be the set of those interacting cvs which act as a positive sink with respect to the cv k the following analysis could be performed in an analogous way using the fluid mass density ρ f and the corresponding elementary fluid mass note that δ v f is much smaller than the characteristic grid cell volume resulting from the domain discretization we adopt the conception of solute mass transfer described by pan et al 2001 during a time interval 0 τ where τ δ t e x k the mass m is divided into portions which are transferred to s s and the remaining portion which stays in k in the following text subscripts s and s are used to denote the elements of set s and s is a summation variable wherever applicable additionally the notation ψ s k being 0 denotes a volumetric sink term t 1 from the cv k to s s the solute mass balance corresponding to the volume δ v f can be formulated as 11 ρ s 0 δ v f 0 m 0 ρ s τ δ v f τ m τ 0 τ ρ s τ δ v f τ m τ 1 ϕ s s ψ s k d τ where m 0 is the initial elementary mass under consideration at the beginning of the aforementioned time interval ϕ is the porosity of the continuum and τ is an intermediate integration variable such that τ τ δ t e x k in the work of pan et al 2001 the mass balance formulations include the interactions with the adjacent cvs of the same continuum these are not relevant in our work as we do not assume instantaneous complete solute mixing and rather model the particle position representative of the elementary mass m in a cv with the flow field being unresolved within the grid cells it is assumed that the strength of volumetric sink s is uniform throughout a cv and hence does not change over the particle s trajectory in k taking the derivative of eq 11 with respect to τ we get 12 d m τ d τ m τ 1 ϕ s s ψ s k the rate of mass transfer scales with the elementary mass and the cumulative strength of the sinks s s ψ s k integration of eq 12 over the interval 0 τ shows that mass m evolves in the cv k as 13 m τ m 0 exp 1 ϕ s s ψ s k τ for sink strengths along the particle s trajectory that stay constant during the mentioned duration as the elementary mass traverses through a cv which has sinks it continuously interacts with them in this work that interaction is simulated in a probabilistic manner via the elementary mass s representative notional particle this particle either is completely transferred to the sink or entirely stays in the cv with the respective probability next we express the corresponding probability for a complete transfer of a notional particle to one of the sinks within the time interval 0 τ to arrive at a probability that is consistent with the gradual mass transfer described by eq 13 the sum of transfer probabilities to any one of the sinks s s has to be 14a s s p k s τ 1 m τ m 0 1 exp 1 ϕ s s ψ s k τ 14b and p k s τ 0 s s s finally to arrive at the individual probability of transfer to a sink s the total transfer probability from eq 14a needs to be scaled by the ratio of the sink strength ψ s k and the cumulative sink strength s s ψ s k that is 15 p k s τ ψ s k s s ψ s k 1 exp 1 ϕ s s ψ s k τ s s the pre factor in the above equation i e the fraction of the volumetric sink strength is the conditional probability of particle transfer to s s given that the event of transfer to any sink occurs based on the particle s current position in the cell the transport scheme by pollock 1988 section 4 1 is used to determine the maximum residence time of the particle in the cv if it were to stay in the same continuum i e δ t e x k in a transport simulation if a user defined time step δ t is used for data recording and analyses then τ min δ t e x k δ t is used as the time step in the particle tracking mass transfer from sources is defined by incoming particles from s s s into the cv and the transfer probability is given by eq 15 but evaluated for the source cv note that eqs 15 and 14a can be reduced to the transfer probabilities formulated by de rooij et al 2013 using mass balance on a streamtube which has a single inflow however to formulate the transfer probability when multiple inflows exist the authors make an assumption to partition the volumetric sink s into contributions from different inflows equations 35 and 36 in de rooij et al 2013 this assumption states that the fraction of a volumetric sink originating from a particular inflow scales linearly with the average travel time of the pathlines associated with that inflow this assumption however can be limiting in the scenarios involving large outflux from the streamtube due to the sink s 4 3 residence time distribution if the transfer to any sink does not occur in 0 τ the particle traverses the cv k and its new coordinates are evaluated by eq b 5 with δ t min δ t e x k δ t as a next step we formulate the distribution of the residence time in the cv k given that the transfer to a sink s occurs here τ 0 τ is used as the corresponding sample space variable and the joint probability density is given by 16 f k s τ p k s τ τ note that f k s τ is a density with respect to time alone but quantifies a joint probability measure in the space of s τ i e the probability of transfer to s s at τ per unit time normalizing f k s τ by the probability of transfer to s irrespective of the residence or transfer time we get the pdf of the residence time conditional on the event of transfer to s in the interval 0 τ it is formulated as 17 f r e s k τ s τ f k s τ p k s τ the cumulative distribution function cdf corresponding to the conditional pdf is given as monga et al 2020 18 f r e s k τ s τ 0 τ f r e s k τ s τ d τ 1 exp 1 ϕ s s ψ s k τ 1 exp 1 ϕ s s ψ s k τ where τ 0 τ 4 4 stochastic particle tracking algorithm firstly given the particle s current position a decision is made regarding the particle s transfer to an interacting cv s s with τ min δ t e x k δ t the decision of particle transfer to s is made using inverse transform sampling in which a uniformly distributed random number ϵ 1 is compared against the discrete cdf given by 19a p j j 1 j p k s j τ j 1 2 n s with s j s and 19b p n s 1 1 here n s denotes the cardinality i e the number of elements in the set s in case the particle is not transferred to any sink it continues to traverse the cv k till the end of the interval 0 τ when τ δ t e x k the particle exits the cv at x p k e x and enters an adjacent cv of the same continuum in the case of particle transfer its residence time in the cv k denoted by τ is sampled from the conditional distribution given by eq 17 or eq 18 the particle traverses the cv k for the duration of τ before jumping to s and propagating further following the jump the particle is moved to a location in s based on a uniform distribution since the flow into the cvs is not resolved to track the particle in the new cv the steps described above are repeated the particle tracking scheme is adaptive with respect to the time steps and this can be confirmed by a simple analysis the probability of transfer to s given by eq 15 satisfies the following 20 p k s τ δ τ p k s τ 1 s s p k s τ p k s δ τ here the first term in the right hand side denotes the probability of transfer to s during the interval 0 τ and the second term denotes the probability of transfer in τ τ δ τ following that the particle is not transferred to any sink in 0 τ with eq 15 the above analysis is true for any combination of τ δ τ for which the volumetric sink term remains constant during 0 τ δ τ the characteristic time step for tracking in the cv k is the maximum particle residence time i e δ t e x k or in case of inter continuum transfer τ the user given time step δ t for particle data recording is a free choice and is neither constrained by nor constrains the outlined tracking scheme the scheme is summarized in algorithm 1 5 splitting and discarding of particles the formulation of the mass fraction estimate eq 2 is based on the assumption that all the particles are equally weighted i e they represent the same amount of mass while this leads to a scheme which is easy to comprehend formulate and implement it comes with a limitation in the applicability because of the high contrast between the volumes of the matrix and the fracture cvs the number of particles per fracture cv may be very small since the statistical quantities like c x t are estimated using the particles in regions of the size of cvs large statistical errors are inevitable e g in the case studies with small fracture apertures and or a very high matrix porosity a variance reduction technique can significantly reduce the errors with only a marginal increase in the computational cost in this work the methodology of particle splitting and discarding is used melnik melnikov et al 1997 it is similar to importance sampling with a fracture cv being the region of interest and seeks for a larger number of particles in the fracture which are lesser weighted than those in the matrix if a particle is transferred from a matrix cv to a fracture cv eq 19a it is split into multiple daughter particles the number of daughter particles n f resulting from each split is a user defined entity the relative particle weight of the daughter particles is then dependent on n f alternatively we prescribe the particle weights w m 1 and w f r 0 w f 1 in the matrix and in the fracture s respectively hereby n f is a function of w f formulated as 21 n f 1 w f if y 1 w f 1 w f 1 w f otherwise here and denote the ceiling and floor functions respectively and y 0 1 is a uniformly distributed random number all the daughter particles have the same timestamp of the transfer and are uniformly distributed in the fracture cv conversely if a particle is to be transferred from a fracture cv to the matrix cv as per eq 19a the transfer is executed only in a probabilistic manner otherwise the particle is killed i e discarded from further tracking computations and the calculation of statistical estimates for a fracture to matrix transfer the probability of the particle being discarded is 1 w f the weight of the surviving particles is increased to w m as they enter the matrix cv thus a particle s weight can take only the discrete values in the set w f w m this stays true even if a different w f is assigned to each fracture the computation of statistical quantities now includes the relative particle weight w p e g 22 c x t p 1 n w p c p h δ x x p t x p 0 p 1 n w p h δ x x p t x p 0 since the number of particles in the matrix remains unchanged the increment in computational costs due to particle splitting and discarding is only marginal 6 verification of the particle tracking scheme mass conservation as part of the verification of the particle tracking scheme we adopted a simple yet comprehensive 2 d domain set up with a permeable matrix and two intersecting 1 d fractures fig 2 a in the chosen set up a matrix domain of size l l l 2 is discretized into a uniform and orthogonal grid of 24 24 cells two 1 d fractures of different lengths having interacting cv pairs between them are embedded in the matrix fig 2 a the relevant hydraulic and geometric properties of the matrix and fractures are mentioned in table 1 the matrix is assumed to be homogeneous and isotropic in the context of its hydraulic properties similarly the fractures are also assumed to be homogeneous it should be noted that at first the resolution of the grid was chosen to be low so that the resulting few matrix fracture interactions can individually be focused on a solute transport problem with sufficient grid resolution is presented in the next section in the subsequent text wherever applicable denotes a dimensionless quantity the span of the domain l is used to normalize the length units a normalized time coordinate t in terms of pvi is used it is given by the fraction of the domain s pore volume that has been injected into the system due to the steady inflow through a boundary external source the key idea of this section is to check for the mass conservative nature of the proposed scheme to this end we considered a homogeneous solute distribution in the domain at t 0 here the fluid phase mass is equi partitioned into a finite number of particles with m p m the mass in the fractures is represented by equally weighted n f r 0 50 000 notional particles however we chose w f 1 4 to reduce the statistical errors in the fracture associated estimates consequently the mass in the matrix is represented by equally weighted n m 0 30 385 200 particles i e 52 752 particles per matrix grid cell a uniform spatial distribution and equal c p c for all particles then corresponds to the mentioned homogeneous setting both in the matrix and the fractures fig 2 b a normalized mean pressure gradient of p was applied in the matrix along the x 1 direction the local pressure gradient which includes contributions from p and the fluctuations due to high conductivity fractures is periodic across all four boundaries periodic boundary conditions allow the particles exiting at a boundary to be reintroduced back into the domain through the opposite boundary with periodic flow boundaries and in the absence of external sources sinks the matrix fracture system with an initially homogeneous concentration field is time invariant thus in the given setting the conservative nature is confirmed based on the following considerations conservation of mass in the fractures at global level in fig 3 we show the evolution of the particle numbers in each fracture marked solid red and blue curves as well as the total number of the particles in the fractures marked golden curve the dashed lines show the particle numbers for the two fractures if the initial number n f r 0 is distributed in proportion to their respective fluid mass volumes or equivalently solute mass the global conservation of the solute mass in each fracture is thus established local conservation of mass in each continuum since the solute mass represented by each particle i e m c is invariant during its motion in either continuum the local particle number density alone determines the solute mass density an estimate of the solute mass density in a small region δ x centered around x is given by 23 ρ s x t m c w n x t ϕ δ x n x t where n x t is the number of particles in δ x and w is the relative weight of the particles in the continuum here in the homogeneous setting n x t should be uniform in each continuum at all times the particle distribution in the matrix at a later time i e at t 1 00 is presented in fig 3 b though only a subset of particles in the matrix is shown it can safely be said that the particles remain uniformly distributed there is no clustering or dilatation of particle clouds even in the regions with non zero divergence fig 4 a shows the particle number density along the length of each fracture at t 1 0 fig 4 b shows the number density in each of the matrix grid cells within the limits of the statistical error the particle number densities adjusted for fluid volume i e n x t remain uniform and thus time invariant within each continuum hence the tracking scheme honors the conservation of mass at local levels since the initial number of particles in each continuum is proportional to the fluid mass volume in it and the associated particle weight n across different continua can be related to each other at all times by the ratio of the particle weights i e n f n m w m w f the number of particle transfers during a finite time interval should be fully consistent with the flow field fig 5 a shows the number of particles that were transferred from the matrix cells in the duration t 0 9 1 0 fig 5 b is complementary to fig 5 a as it shows the particle transfers from the fractures to the matrix cells in the same time duration figs 5 c and 5 d present the theoretical counterparts of figs 5 a and 5 b respectively here the number of transfers are calculated directly from the flux interactions between different continua in whichever cells it is applicable and the initial particle number in the computational domain figs 5 e and 5 f show the relative error between the empirically estimated and the theoretically calculated transfers the maximum of the relative error in fig 5 e is associated with a cell that has a very low outflux and thus a low number of transfers figs 5 a and 5 c thus the scheme in an average sense correctly simulates the mass transfer between the interacting continua a steady mass flux is simulated by a uniform distribution of the timestamps of particle transfers from say a matrix cell to a fracture cell sink in fig 6 we present the distribution of the timestamps of particle transfers from a matrix cell the one with highest transfers in fig 5 a to the interacting fracture cell sink or alternatively the arrival time distribution in the fracture cell the distribution is based on the timestamps of 399 353 particles transfers that were recorded in the interval t 0 9 1 0 the resulting uniform distribution showcases in an empirical way that the particle specific residence time pdf eq 17 is consistent with the steady state flux a similar analysis can be done for much smaller time intervals provided that a sufficiently large number of particles are used and it infact holds true for any arbitrarily chosen interval 7 solute transport with the particle tracking scheme to illustrate the capabilities of the proposed particle tracking scheme we consider a matrix fracture system which is more complex than the one described in the previous section it is a 2 d square domain model of size l l l 2 in a quarter five spot configuration with impermeable wall boundaries fig 7 in the numerical set up the matrix is discretized into a uniform and orthogonal grid of 100 100 square cells normalized cell size vector δ 0 01 0 01 t twelve 1 d fractures of different lengths are embedded in the matrix fractures have multiple pair wise intersections but there is no percolation of the domain through the fractures the relevant hydraulic properties of the matrix and fractures are the same as mentioned in table 1 there is no solute mass in the system at t 0 but the domain is saturated with the fluid a source of solute and a sink are distributed over square regions at the bottom left and top right corners respectively regions bounded by red dashed lines in fig 7 the influx normalized with the inverse of time required to inject a volume equivalent to the pore volume is given by 24 q 10 0027 if 0 0 x 1 0 1 0 0 x 2 0 1 10 0027 if 0 9 x 1 1 0 0 9 x 2 1 0 0 0 otherwise in the numerical simulation the initial fluid mass in the fractures is represented by n f r 0 100 000 equally weighted notional particles in accordance with w m 1 and w f 1 12 the fluid mass in the matrix is represented by n m 0 31 334 360 particles or 3 133 particles per matrix cell further c p 0 p 1 n f r 0 n m 0 with the progression of time solute particles enter the domain and are uniformly distributed in the regions with q 0 for simplification of the analyses and without loss of generality c p 1 for these solute particles each particle s motion is independent and is dictated by the local pore velocity in its continuum eq b 5 and the probabilities of transfer to other continua eq 15 all the particles exiting through the regions with q 0 are excluded from further tracking the average solute mass fraction can be estimated according to eq 22 in fig 8 we show the spatial distribution of the particles with c p 0 in the matrix at an early time t 0 125 intermediate times t 0 250 0 375 and a later time t 0 500 the high conductivity fractures act as preferential flow paths and the expedited transport by the fractures is very evident figs 9 a 9 b and 9 c show the evolution of the solute mass fraction concentration field in the matrix at different instants it should be emphasized that with sufficient particles the sampling region size could be much smaller than the grid cell size used for flow computations figs 9 d 9 e and 9 f show the corresponding fields resulting from a first order upwind scheme with forward euler integration as with conventional eulerian methods numerical diffusion is clearly observable in this scenario with pre dominantly oblique flow across a majority of matrix cells the particle tracking scheme on the other hand captures sharp fronts a feature of purely advective transport note that these figures present pixel wise mass fraction values without any smoothing in the post processing step figs 9 g 9 h and 9 i highlight the differences in the concentration fields resulting from the two approaches and they primarily differ near the regions of a high gradient the eulerian approach underpredicts the higher concentration value and overpredicts the lower one when the jump occurs over a short length scale the differences are also highlighted in the cross sectional concentration profiles presented in figs 12 a 12 b and 12 c discussed in the next section in figs 10 a 10 b and 10 c the concentrations in the fractures at different times are presented figs 10 d 10 e and 10 f show the counterparts when w f 1 0 i e splitting and discarding of particles is not deployed the number of particles in the matrix is kept the same n m 0 31 334 360 figs 10 g 10 h and 10 i show the absolute differences between the two cases i e with and without considering the splitting and discarding of particles when w f 1 0 a few of the fracture cells may not contain any particle considering that the low average particle numbers may intermittently be overcome by statistical fluctuations for simplifying the analysis the concentration value in such fracture cells is assigned to zero 7 1 model performance and errors the sharpness of the estimated concentration profiles can further be improved with smaller sampling regions irrespective of the discretization grid used for the flow problem however this warrants the use of a higher number of particles to achieve statistical convergence each particle in this linear transport problem is an independent realization thereby particle tracking schemes can remarkably benefit from a parallel implementation transport simulations were performed on a state of the art multi node distributed cluster system and a domain decomposition technique was adopted with 20 processor cores each core handles the particle ensemble in its assigned subdomain of 20 25 matrix cells and the associated fracture cells and the particles spatio temporal coordinates are communicated to the neighboring cores as the particles cross the subdomain boundaries we report the computation run times up to t 0 5 with n p 0 n m 0 n f r 0 31 434 360 the run time for the particle tracking scheme amounted to 10 379 s while that for the eulerian scheme was 2 352 s it should be noted that the same domain decomposition is used for the eulerian transport simulation as well the run time of a particle based simulation in general scales linearly with the number of particles and this is confirmed by our simulations with varying particle numbers precisely n p 0 n p 0 n p 0 5 n p 0 10 n p 0 25 n p 0 100 fig 11 thus when using n p 0 4 5 particles which translates to 700 particles per matrix cell the run times of the particle tracking and eulerian simulations are comparable here all the processes have a nearly similar work load because the particles with c p 0 were tracked as well in case only the particles with c p 1 are tracked dynamic load balancing should be adopted to obtain an optimal scaling with respect to the number of cores optimization of the parallel implementation to achieve a favorable scaling with respect to the number of cores is planned for future works further the optimal parallel set up to achieve the peak speed up is case specific the downside of using lower particle numbers is the increased statistical error in the mass fraction estimates figs 12 a 12 b and 12 c present the estimated profiles at x 1 0 25 0 50 0 90 from the simulations with n p 0 n p 0 10 n p 0 25 n p 0 100 in fig 12 d the mass fraction field at t 0 5 estimated with n p 0 100 is shown it should be noted that for the cases with lower number of particles a few of the fracture cells may contain no particles irrespective of the statistical noise the particle scheme does not suffer from bias errors the noise being purely statistical in nature averages out for time space integrated transport metrics e g overall mass in the system cumulative mass transferred to the sink this is clearly observable in fig 13 where the breakthrough curves from the simulations with n p 0 n p 0 n p 0 10 n p 0 25 n p 0 100 overlap here breakthrough is quantified by the solute mass particles with c p 1 transferred to the sink the region at top right in fig 7 up to time t normalized by the mass transferred up to t 0 5 for the case with n p 0 particles for the considered case of linear solute transport the statistical noise is an acceptable trade off in favor of significant computational gains however in case of non linear transport elimination of noise is critical because the errors in the mass fraction estimates can get propagated in time when using a lower number of particles a denoising or filtering algorithm can be used to curtail the statistical errors however the choice of the filter should be such that it preserves i the total solute mass and ii the sharp edges which are key advantages of the particle tracking approach engquist et al 1989 suggested a series of conservative non linear filtering algorithms which have been applied to numerical solution of non linear hyperbolic transport equations the central principle of these filters is smoothing of local extrema which are quite often manifestations of statistical noise the conservative nature is ensured by selectively modifying the neighbor s of the extremum in consideration we used an adaptation of one of their comprehensive filters algorithm 2 4 in engquist et al 1989 and applied it to the mass fraction estimates with n p 0 100 however such a filtering algorithm introduces artefacts in very narrow regions a few cells wide having a significant jump in the profile along either direction other alternatives include the filtering techniques developed for image processing however many of these techniques are not conservative with respect to the integral of the intensity i e solute mass in the context of this work wavelet based denoising strategies are conservative and sufficiently capable in preserving sharp edges a simple implementation includes decomposition of the signal image into a family of wavelets followed by the attenuation of high frequency noise to a certain threshold misiti et al 1996 the noise may only be present in certain sections of the signal thus the wavelet based approaches are preferred over the conventional fourier decomposition based denoising approaches which assume stationarity of the signal the choice of a suitable wavelet and thresholding strategy is problem specific and hence goes beyond the scope of this work 8 conclusions and remarks in stochastic particle based methods the evolution of computational particles or precisely dirac measures is governed by a set of probabilistic rules such that the particles represent in the ensemble average sense a continuum behavior thus particle methods offer a very natural way to connect microscopic unresolved phenomena with macroscopic quantities in this work we have formalized probabilistic rules for particle transitions that simulate fluxes between matrix and fractures in a fractured porous medium for the fractured media an embedded discrete fracture model edfm was adopted particle tracking in each continuum is deterministic by the virtue of the eulerian flow field however with the flow field being not resolved within grid cells inter continuum mass exchange is not comprehensible in terms of the particle pathlines henceforth a probabilistic scheme was devised for the transfers between the fracture and the matrix continua the transfer probability is specific for each particle and its trajectory in a grid cell forgoing any assumption of complete mixing additionally its formulation does not constrain the time step size and thus holds true for any duration in the particle s flight for which the flux to the other continuum or any other sink stays uniform hence the tracking scheme is time adaptive with the upper limit for the particle specific time step being set by the traverse time in the grid cell finally a conditional distribution for the residence time was formulated in the derived formulations the probability of transfer has a negative exponential scaling with the time spent by the particle in a grid cell often a linear scaling is assumed and henceforth the time step size is capped so that the transfer probability does not exceed unity the linear scaling inherently assumes that the probability of transfer per travel time is uniform however the negative exponential scaling is a result of the transfer probability per displacement in either direction being uniform which is consistent with the spatially uniform strength of the sink s in a grid cell using a simple numerical experiment it was shown that the tracking scheme preserves an initially uniform solute distribution in a system of a permeable matrix and intersecting fractures demonstrating its conservative nature the residence time distribution leads to a temporally stationary particle transfer rate in the ensemble sense consistent with the flux to the sink s the transfer probability and the associated residence time distribution are general in their application to any random walk particle method with sources sinks we envision to include them as a part of a stochastic model for non linear transport including reactions between different phases and or species this transport model will be tailored for an edfm set up with a heterogeneous matrix and fractures further the conventional edfm based approach is shown to be inept in correctly simulating the flow field if fractures have a lower conductivity than the matrix and thus act as flow barriers the projection based edfm pedfm approach has been developed primarily to address this limitation of the edfms ţene et al 2017 the probabilistic particle tracking approach is easily extendible to a pedfm wherein direct particle transfers to the non neighboring connections simulate the corresponding flux the modified corrected fluxes to neighboring connections should be accounted for in the calculation of the corresponding particle transfer probabilities as illustrated by the transport simulations conducted in this work it is possible to simulate sharp fronts particle tracking approach offers an attractive alternative for modeling reactive transport where in the dispersion limited regime mixing at the sub grid level may be incomplete and the macroscopic reaction rates may not hold well then the dynamics towards the local equilibrium can be vastly different from that predicted by eulerian methods using macroscopic reaction rate laws with cell averaged quantities e g composition of species particles on the other hand can model the sub grid level distributions of the species compositions these computational particles can be thought of as elementary fluid phase volumes and in a multi species setting their characterization may include the compositions a particle thus evolves in the compositional space because of the reactions in the fluid phase or between the fluid phase and the solid grains of the porous medium modeling of the particle trajectories in the compositional space can be based on a relevant microscopic physical law in addition particle tracking schemes are well versed to model reactions where the macroscopic reaction laws do hold true for example equilibrium sorption desorption reactions characterized by a linear isotherm can simply be included in the particle tracking scheme then transformed pore velocities and dispersion coefficients involving retardation coefficients are used in the estimation of particle trajectories kinzelbach and uffink 1991 further a particle transition probability similar to the one presented in this work simulates mass transitions between two reaction states e g sorbed aqueous states when the reaction kinetics is described by a first order rate valocchi and quinodoz 1989 sub grid dispersion in each continuum and the effects of molecular diffusion can be captured by adding a wiener process to particle trajectories and including a mixing model for particle specific solute mass fractions respectively however for edfms the primary challenge lies in the modeling of inter continuum diffusive dispersive fluxes further the developed model for inter continuum fluxes should facilitate formulation of a compliant and preferably an exact transfer probability along these lines a prospective first step could be the approach of liu et al 2000 for dual continua models where second order reconstruction is used for the matrix concentration profiles in the vicinity of fractures this enables an interfacial concentration gradient and thus the diffusive flux to be modeled as a linear function of the cell averaged concentration difference between the two continua thereby a straightforward correspondence between the particle transfers and the inter continuum flux is established generally the macroscopic quantities of interest are derived from statistical moments under the assumption of local ergodicity thus keeping statistical errors in check becomes crucial when using particle based methods for non linear problems as is generally the case with particle based approaches we report a linear scaling of the computation time with particle numbers variance reduction techniques and or filtering techniques can be effective and do not significantly add to the computational costs but finding a suitable approach for a wide range of applications needs more attention extension of the particle tracking scheme to 3 d edfms is rather uncomplicated the significance of variance reduction filtering techniques is further enhanced in 3 d applications where the computational costs in view of statistical convergence can be considerably high credit authorship contribution statement ranit monga conceptualization methodology software formal analysis writing original draft rajdeep deb software methodology writing review editing daniel w meyer conceptualization methodology formal analysis writing review editing supervision patrick jenny conceptualization methodology formal analysis writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments ranit monga and patrick jenny acknowledge financial support by the swiss national science foundation snsf through the grant snf 200021 178922 1 rajdeep deb acknowledges financial support provided through the grant geotherm ii switzerland and daniel w meyer acknowledges financial support from eth zürich switzerland the funding sources have no involvement in the study design the preparation of the article and decisions related to its publication the authors thank michael liem and giulia conti eth zürich for proofreading and helpful suggestions appendix a particle based solution of transport problem in a multi species setting with a given flow field denoted by u x t l t 1 mass conservation at the macroscopic level can be formalized with a transport equation for the fluid phase solution density ρ f x t m l 3 as given by a 1 ϕ ρ f t v ϕ ρ f 0 here the porosity ϕ is assumed to be uniform throughout the medium v l t 1 is the average pore velocity i e u ϕ with a particle based approach we seek a solution ρ f of the transport equation eq a 1 salamon et al 2006 given by a 2 ϕ ρ f x t m t δ x x p t where x p l denotes the position of a notional particle δ denotes a dirac delta function and is an averaging operator further the parameter m has the dimension m an integration of the eq a 2 over the physical domain suggests that m represents the total fluid mass in the domain numerically the averaging involves summation over a particle set of finite size n and one obtains an approximate solution ρ f n a particle with index p 1 n has a random initial location x p 0 at time t 0 accordingly the particle s trajectory follows an average streamline in the microscopic pore flow given by a 3 x p t x p 0 t 0 t v x p t x p 0 t d t the choice of the number of particles n is dictated by the balance between the desired accuracy and efficiency since n is finite ρ f n is discrete in the space of the independent variables and is discontinuous a pragmatic approach towards this issue is the regularization of this approximate solution formalized as a 4 ρ f x t ω ρ f n x t ζ x x d x where ζ x x is a kernel or regularization function with finite support such that a 5 ω ζ x d x 1 thus the regularized particle based estimate is given by a 6 ρ f x t 1 ϕ p 1 n m p t ζ x x p t x p 0 where m p is the fluid phase mass associated with each particle i e m p m n if all the particles are equally weighted in a statistical sense in the absence of source sink s as well as in and outflow boundaries m p is time invariant nevertheless addition removal of particles can account for them if present further m p and x p 0 for each particle are determined from the initial conditions and the choice of relative particle weights for example the spatial distribution of particles at t 0 is directly related to the initial mass density field if m p is the same for all particles solute transport at the macroscopic level is generally modeled with an advection dispersion equation ade for the mass density of a solute species ρ s m l 3 given by a 7 ϕ ρ s t v ϕ ρ s d ϕ ρ s here d l 2 t 1 is the mechanical dispersion coefficient tensor and molecular diffusion is assumed to be negligible a particle based approximate solution can be given by a 8 ρ s n x t 1 ϕ p 1 n m p c p t δ x x p t x p 0 where c p represents the particle specific mass fraction of the solute species and denotes the conditional averaging operator i e the expectation for a particle originating at x p 0 corresponding to eq a 8 a particle evolves in physical space as a 9 d x p t v x p t t t d t t d t b x p t t d w such that 1 2 b b t d and w denotes a multivariate wiener process kinzelbach 1988 tompson and dougherty 1992 further c p is time invariant in the absence of mixing due to molecular diffusion in the absence of dispersion i e d 0 a particle s position in the physical space is also given by eq a 3 and the trajectory is purely deterministic the particle based solution requires a regularization step similar to eq a 4 the resulting regularized solution is denoted by ρ s finally the mass fraction of a species can be formalized as the ratio of the species mass density ρ s and the fluid phase density ρ f given by a 10 c x t p 1 n m p c p ζ x x p t x p 0 p 1 n m p ζ x x p t x p 0 appendix b conservative particle tracking in a control volume the conservative tracking scheme by pollock 1988 is used to estimate the particle s maximum residence time in the cv k and also the prospective spatial coordinates of exit the following text describes the relevant assumptions and formulations a global cartesian coordinate system is chosen such that the orthogonal matrix cell boundaries are aligned with the coordinate axes this global coordinate system is used for particle tracking in the matrix for each fracture a local coordinate system is used its axis is oriented along the principal fracture dimension the principal components of velocity in the matrix are the cartesian components which are denoted by v i where i 1 2 for a 2 d cv in a 1 d fracture the velocity is oriented along the length of the fracture and i 1 propagation of a particle in space and time needs the local velocity information eq a 3 the components of the local velocity in a cv are obtained by linear interpolation of the values at the cv boundaries fig 1 b as used in pollock 1988 and meyer and jenny 2004 for a cv with index k the linear interpolation shape function for dimension i is given by b 1 a i k v i x i k 2 v i x i k 1 x i k 2 x i k 1 where the superscript k 1 and k 2 denote the boundaries of the cv k such that x i k 2 x i k 1 the local velocity at a coordinate x i x i k 1 x i k 2 is calculated as b 2 v i x i v i x i k 1 a i k x i x i k 1 here we use the subscript p in the upper case notations for particle related variables along with the subscript i for the dimension wherever applicable pollock 1988 has derived the analytical expression for the particle travel time corresponding to its displacement δ x p i within the cv given by b 3 δ t 1 a i k ln v i x p i δ x p i v i x p i if a i k 0 δ x p i v i x p i otherwise the above expression is devised and valid for the scenarios when the criterion b 4 v i x p i δ x p i v i x p i 0 along with v i x p i δ x p i 0 is met in case of non compliance either the particle cannot traverse across a stagnation point i e x i x p i x p i δ x p i v i x i 0 or it cannot traverse in the proposed displacement direction i e v i x p i δ x p i 0 alternatively the particle s coordinate after a given time step δ t is given by b 5 x p i t δ t x p i t v i x p i a i k exp a i k δ t 1 if a i k 0 x p i t v i x p i δ t otherwise which results from the reformulation of eqs b 2 and b 3 assuming that the particle does not get transferred to a sink and exits the cv through a boundary in the i th dimension the prospective exit coordinate is given by b 6 x p i k e x x i k 2 if v i x p i 0 x i k 1 if v i x p i 0 the proposed particle exit time δ t e x i k can be evaluated from eq b 3 using δ x p i x p i k e x x p i conditional that the particle can exit the cv in the i th direction under the conditions given by expression b 4 in all other scenarios the particle cannot reach the proposed exit coordinate and exits the cv in another direction or through a sink given the particle s current position and assuming no transfer to another continuum the particle s residence time in the cv is given by b 7 δ t e x k min δ t e x i k i 1 2 for i δ t e x i k δ t e x k the exit coordinate x p i k e x can be evaluated with eq b 5 
63,practical simulation of solute transport in river corridors often relies on one dimensional transport models with solute flux between river and hyporheic zone governed by a mass exchange term perhaps most generally expressed using the memory function formalism while expressions for temporal moments of solute breakthrough curves btcs are available for a number of such models those for memory function forms are not to our knowledge here we report closed form btc temporal moment expressions for memory function forms found by exploiting the connection to phase exposure dependent exchange phedex formulations we use these results to investigate the general capability of the memory function form to accommodate specific scaling of river tracer temporal moments reported in the literature and we apply the method to identification of parameters in application to two recent tracer tests the applications involve a simple numerical solution to the memory function river corridor transport model calibrated using measured temporal moments of the tracer test btcs the numerical model is validated only for the classical case of the transient storage model without lateral inflow the analytical solution for which we adapt from the lassey solution for mobile immobile exchange in porous media it should be noted that the temporal moments results obtained here in the context of river corridor transport also apply to one dimensional transport in two domain mobile immobile porous media when governed by a two domain memory function model keywords river transport memory function temporal moments analysis data availability all data used is published by others 1 introduction water quality management relies on practically useful tools for simulation of solute transport in river corridors for which there are often no supporting tracer test data and yet predicting solute transport in streams is among the most challenging problems in surface water quality modeling wörman 2000 o connor et al 2010 river corridors play an important role in fate and transport of nutrients contaminants and weathering products as impacted by the mass exchange between the channel flow and the typically more metabolically active hyporheic zone lawrence et al 2013 harvey and gooseff 2015 brunner et al 2017 researchers have recognized that processes occurring in the hyporheic zone are critical for contaminant degradation nutrient cycling habitat selection and ecosystem metabolism and generally for the management and restoration of the whole river environment haggerty et al 2000 schmid 2003 boano et al 2014 wlostowski et al 2017 mccallum et al 2020 thus in the modeling of solute transport in river corridors it is necessary to consider the mass exchange between the river and the hyporheic zone two examples of the numerous conceptual models of this mass exchange process are advective pumping and turbulent exchange advective pumping describes darcy flow within streambed bars or dunes resulting from hydraulic head gradients between upstream and downstream faces of such morphological features e g elliot and brooks 1997a b salehin et al 2004 marion et al 2002 packman et al 2004 tonina and buffington 2007 bottacin busolin and marion 2010 several of these studies point out that transverse dispersion within the hyporheic zone can transfer solute across streamlines impacting the residence time distribution in the hyporheic zone which is not incorporated into most advective pumping models hester et al 2017 in high permeability sediment beds turbulent streamflow can impart momentum and mass transfer between the stream and the hyporheic zone e g grant et al 2018 roche et al 2018 while streamflow turbulence is often assumed to impact only a thin layer of the hyporheic zone e g tonina and buffington 2007 exchange rates in flat gravel beds have been found to be 2 4 orders of magnitude greater than those predicted by advective pumping o connor and harvey 2008 roche et al 2018 we do not attempt to represent either process explicitly but instead focus on a mathematically general yet effective representation of exchange no chemical reactions are considered here although our focus on residence time accounting in the hyporheic zone may accommodate reactions that depend primarily on this variable e g roche and dentz 2022 the original representation of river hyporheic zone mass exchange is one of reversible first order kinetics with constant coefficients according to the transient storage model tsm bencala and waters 1983 kelleher et al 2019 and many others the evolution of increasingly general models of this mass exchange term is well documented in rivers literature leading to the memory function form haggerty et al 2002 mccallum et al 2020 roche and dentz 2022 the memory function form originated in carrera et al 1998 from leaky aquifer mechanics herrera and rodarte 1973 herrera and yates 1977 in haggerty et al 2000 from carrera et al 1998 and chromatography villermaux 1974 and in hornung and showalter 1990 for transport in fractured media and can represent most theories of exchange in mobile immobile media silva et al 2009 2 background 2 1 basic model forms here we introduce three basic model forms an original river corridor transport model with first order exchange its generalization to memory function form and lastly the representation of the memory function model as a first order exchange model with rate coefficient dependence on residence time spent in the hyporheic zone a table of variables terms with units and definitions is given in appendix a solute concentration in the channel is c c x t and in the hyporheic zone is s s x t both in units of ml 3 the transient storage model tsm e g bencala and walters 1983 is a one dimensional two domain representation of transport in a channel with first order exchange with the hyporheic zone 1a c t q a c x 1 a x d a c x q l a c l c α β c s 1b s t α c s in which q is the stream flow laqu 3 t 1 d is the longitudinal dispersion coefficient l 2 t 1 ql is the lateral influx of subsurface water to the stream channel l 3 t 1 l 1 cl is the solute concentration in that influx mlaqu 3 α is the rate coefficient for first order mass exchange between the channel and the hyporheic zone t 1 β is a as where as is the porous fraction of the hyporheic zone cross sectional area for ease of transition to memory function forms our α is the α of bencala and walters 1983 divided by β it should be noted that in the simple case of constant d the preasymptotic dispersion is ignored so that the model is used only for distances beyond the mixing length for simplicity henceforth we assume lateral influx ql to be negligible eq 1 form the transient storage model tsm to convert the tsm model to memory function form we solve the second tsm equation by integration factor method while assuming zero initial mass in the hyporheic zone and substitute the result into the first equation yielding the memory function model 2a c t l c β t g c 2b s t t g c where l c is the transport operator q a c x 1 a x d a c x g c 0 t g ω c x t ω d ω that is the convolution product and g ω is the memory function which in the tsm case is equal to αe αω the memory function form admits a wide array of different exchange processes well beyond the first order single rate exchange of the tsm eq 2 form the memory function model if we return to the tsm first order kinetics starting point but keep track of the residence time spent in the hyporheic zone that is rewrite the immobile zone concentration s x t as a distribution s x t ω over ω the residence time in the immobile zone we can write any memory function model in terms of such a phase exposure time dependent exchange phedex model ginn 2009 ginn et al 2017 to do this we keep track of time spent in the hyporheic zone by what appears to be an advection operator that moves mass along the ω axis while in the hyporheic zone that is we use advection to age the mass while in the hyporheic zone details of this approach are further summarized in the supplemental information given a memory function g ω and eq 2 the corresponding phedex model is 3a c t l c β k f c β 0 k r ω s ω d ω 3b s t 1 s ω k r ω s where now s s x t ω the new advection aging operator is 1 s ω in eq 3b where the 1 is the aging velocity in units of age per time eq 3b has a new boundary condition 1 s x t ω 0 kfc x t where the 1 is again the aging velocity and thus this is a flux condition that specifies the rate of mass entry to the hyporheic zone at age ω 0 from the channel mass leaves the hyporheic zone by first order kinetic kr ω s but now with the new rate coefficient kr ω that depends on the time spent in the hyporheic zone this mass is collected integrated over all ω and entered into the channel equation via the last term in eq 3a finally the rate coefficients kf and kr ω both t 1 are derived from the memory function as k f lim ω 0 g ω and k r ω 1 g ω d g d ω conversely given a phedex model the corresponding memory function is g ω k f e x p 0 ω k r u d u eq 3 make up the phedex form of the memory model the demonstration that any memory function model of the from of eq 2 can be cast as a phedex model originally done in ginn 2009 is retraversed and streamlined in the supplemental information the primary reason that we introduce the phedex version of a given memory function model here is because we can solve the corresponding temporal moment equations using the phedex version 2 2 temporal moments river tracer tests may be simulated by joining the transport equation with boundary and initial conditions representing the introduction of the tracer to the channel and solving the resulting system to simulate the solute concentration at a downstream location as a function of time the breakthrough curve btc paraphrasing a careful reviewer a btc is by definition a flux averaged concentration whereas most riverine btcs are actually discrete time samples of concentration at one or an average of several measurement point s in the stream unaffiliated with corresponding instantaneous local flux at that location treatment of these data as equivalent to flux averaged concentrations implies complete lateral mixing for conservative tracers each btc represents a non normalized solute concentration distribution over arrival time to the downstream measurement location the btc can be characterized by the temporal moments of this distribution that is if we normalized this distribution by the zeroth moment total mass then the mean of the distribution is mean arrival time and shifting the distribution to this mean the second and third centered moments are arrival time variance and skewness respectively it must be noted that higher moments are generally very sensitive to the extent and shape of late time solute arrival i e tailing as pointed out in context of water age in porous media in varni and carrera 1998 and in solute transport in porous media in haggerty et al 2000 both referring to impacts of matrix diffusion matalas 1967 page 943 highlights this problem in a more general context of hydrologic time series noting that for parameters that are defined in terms of moments their standard errors increase with an increase in the order of the moments the spatial scaling of these temporal moments and their dimensionless combinations can serve as characteristic signatures of transport and so the scaling possibilities of these quantities when governed by a math model are of interest in particular the coefficient of skewness csk the skewness divided by the 3 2 power of the variance is a common dimensionless metric of btc asymmetry and tailing nordin and troutman 1980 schmid 2003 wörman 2000 and wörman et al 2002 developed expressions for temporal moments for several one dimensional river corridor transport models with negligible longitudinal dispersion including the tsm as well as those with general residence time distributions in the hyporheic zone associated with advective pumping schmid 2003 gives closed form expressions for the temporal moments of the tsm model including longitudinal dispersion in the channel and for general boundary conditions specifying the tracer injection gonzález pinzón et al 2013 applied temporal moments analysis to several general model frameworks expressed with parameters not varying with space including simple advection dispersion tsm the decoupled continuous time random walk approach ctrw boano et al 2007 and the multirate mass transfer model mrmt haggerty et al 2002 and showed that all predict a csk that drops with distance traversed an unsurprising result given their practical equivalence per silva et al 2009 their analyses of tracer test data however suggested that the csk is in fact a constant of space and concluded that there is a need to revise the theory of river corridor solute transport so that one dimensional math models can accommodate a constant csk while the foregoing list of models can all be cast in the form of memory function models the scaling of temporal moments of memory function models has not been determined this study reports explicit expressions for the temporal moments of the aqueous solute concentration and of the immobile solute concentration when they are governed by a memory function form of one dimensional two domain transport with advection dispersion in the mobile phase with constant velocity and dispersion coefficient no lateral inflow and with exchange with the immobile domain governed by a memory function the governing equations of these temporal moments are described in luo et al 2008 but the solution to luo s governing equations is non trivial we work around that barrier by exploiting the transformation of the memory function form into its phedex representation e g ginn et al 2017 supplemental information the analyses of which leads directly to a solution of luo et al 2008 governing equations the development of the phedex form of a given memory function river model is described in the supplemental information in the following sections closed form expressions for the first four temporal moments of a river tracer breakthrough curve governed by the memory function form are found using these expressions we test whether the memory function based river model can generate a constant csk we then use the temporal moments expressions to calibrate a 1 d river transport model that is based on the memory function form for the four uvas creek btcs analyzed by schmid 2003 and for a single btc monitored in the sturt river as reported in schaper et al 2018 and in mccallum et al 2020 3 temporal moments of one dimensional river transport models with memory function exchange we wish to find closed form solutions for the temporal moments of btcs governed by the memory function form of eq 2 luo et al 2008 provided the governing equations but not the solution for those temporal moments here we solve for the temporal moments in question by recasting the memory function model into its corresponding phedex model eq 3 form developing the governing equations for the temporal moments of the phedex model form and solving them if we apply the moment operator 0 τ k d τ to the phedex model eq 3 and define the kth temporal moment of c and of s respectively as μ k x 0 τ k c d τ and σ k x 0 τ k s d τ then we obtain the governing equations for the unormalized raw moments μ k x and for σ k x 4 k μ k 1 l μ k β k f μ k β 0 k r ω σ k ω d ω 5 k σ k 1 ω d σ k ω d ω k r ω σ k ω with σ k 0 kf μ k in lieu of mathematical details of the derivation of eqs 4 and 5 we point out that the moment operator commutes with all operators appearing in the phedex eq 3 with the exception of the time derivatives that are handled using integration by parts yielding the first terms in eqs 4 and 5 thus eqs 4 and 5 are similar in form to the original phedex equations we presume the tracer is injected in the river at location x 0 with normalized and centered temporal moments mk 0 k 1 4 to ensure complete recovery of injected solute in the btc we also assume that the mass exchange is fully reversible i e that kr ω 0 which means that all the mass entering the hyporheic zone returns to the main river flow details of the solutions of eqs 4 and 5 for unnormalized raw moments μ k k 0 1 2 3 4 appear in appendix a the normalized absolute moments are defined as e g govindaraju and das 2007 luo et al 2008 μ n μ n μ 0 and the central moments of order 1 2 3 and 4 are m 1 μ 1 m 2 μ 2 μ 1 2 m 3 μ 3 3 μ 1 μ 2 2 μ 1 3 and m 4 μ 4 4 μ 1 μ 3 6 μ 2 μ 1 2 3 μ 1 4 respectively since the normalized central moments for river solute concentration c can give information about longitudinal mixing and exchange processes we focus on the moments for river solute concentration shown in table 1 where with k ω 0 ω k r u d u a 1 β k f 0 e k ω d ω 1 a 2 2 β k f 0 ω e k ω d ω a 3 3 β k f 0 ω 2 e k ω d ω and a 4 4 β k f 0 ω 3 e k ω d ω the coefficients a 1 a 2 a 3 and a 4 can be expressed in terms of the moments of the memory function i e 0 ω k 1 g ω d ω k 1 2 as follows 6 a 1 β 0 g ω d ω 1 7 a 2 2 β 0 ω g ω d ω 8 a 3 3 β 0 ω 2 g ω d ω 9 a 4 4 β 0 ω 3 g ω d ω where g ω kfe k ω the derived expressions for central moments also allow us to find a closed form for the coefficient of skewness csk for the river btc resulting from an instantaneous pulse introduced at x 0 that is 10 c s k m 3 m 2 3 2 a 3 6 a 1 a 2 d v 2 12 a 1 3 d 2 v 4 x v m 3 0 2 a 1 2 d v 2 a 2 x v m 2 0 3 2 note that in the case of negligible dispersion coefficient e g bencala and walters 1983 schmid 2003 and zero initial moments the first three values of a are equivalent to the corresponding btc central moments mi divided by travel time for this specific case the csk reduces to 11 c s k a 3 a 2 3 2 x v 1 2 eqs 10 and 11 show that the csk for memory function river transport models scales generally with space to the negative one half power this result generalizes the identical finding of gonzález pinzón et al 2013 to any model that has a memory function form 3 1 the moments in the tsm by substituting eqs 6 9 into the central moments equations of table 1 we obtain the first four central moments of solute concentration in terms of the memory function g this demonstrates the ability of the expressions obtained to represent temporal moments for any exchange model that can be cast in memory function form for instance we consider the tsm case in which kr as well as kf are constants so k ω 0 ω k r d ω k r ω and then a 1 1 β a 2 2β kr a 3 6 β k r 2 and a 4 24 β k r 3 by substituting these coefficients into table 1 we obtain 12 m 1 1 β x v m 1 0 13 m 2 2 1 β 2 d v 2 2 β k r x v m 2 0 14 m 3 6 β k r 2 12 1 β β d k r v 2 12 1 β 3 d 2 v 4 x v m 3 0 15 m 4 24 β k r 3 12 β k r m 2 0 24 β 2 d k r 2 v 2 48 1 β β d k r 2 v 2 12 1 β 2 d v 2 m 2 0 144 β 1 β 2 d 2 k r v 4 120 1 β 4 d 3 v 6 x v 24 β 1 β 2 d k r v 2 12 β 2 k r 2 12 1 β 4 d 2 v 4 x 2 v 2 m 4 0 that are first four moments of tsm respectively identical to the moments reported by schmid 2003 eqs 21 24 in a specific case when we have m 1 0 m 2 0 m 3 0 m 4 0 0 eqs 12 14 give the same results as eq 11 in gonzález pinzón et al 2013 3 2 the moments in a particular memory function model based on gamma distributed rates if a particular mathematical form for the memory function g ω is chosen so that g ω is expressed in term of parameters then one can write expressions linking measured central moments and those parameters in the case where the memory function is formulated based on a gamma distribution of equivalent multiple rates haggerty et al 2000 ginn et al 2017 absent of the β tot factor present in the haggerty et al 2000 version as in 16 g t γ η γ t 1 η 1 with two parameters η and γ we term this the gm3 model then the coefficients a 1 a 2 a 3 and a 4 can be eliminated by inserting 16 into eqs 6 9 and evaluating the integrals to obtain the corresponding moment expressions 17 m γ 1 x 1 β x v m 1 0 η 0 18 m γ 2 x 2 1 β 2 d v 2 2 β η 1 γ x v m 2 0 η 0 19 m γ 3 x 12 1 β 3 d 2 v 4 12 1 β β η 1 γ d v 2 6 β η 1 η 2 γ 2 x v m 3 0 η 2 20 m γ 4 x 48 β 1 β η 1 η 2 γ 2 d 6 2 β η 1 γ 2 d 12 1 β 2 d m 2 0 v 2 24 β η 1 η 2 η 3 γ 3 12 β η 1 γ m 2 0 144 β 1 β 2 d 2 η 1 γ v 4 120 1 β 4 d 3 v 6 x v 3 2 β η 1 γ 2 24 β 1 β 2 d η 1 γ v 2 12 1 β 4 d 2 v 4 x 2 v 2 m 4 0 η 3 where m γ 2 x m γ 3 x m γ 4 x are undefined for η 1 η 2 and η 3 respectively eqs 17 20 provide the linkage between measured central moments and the combined transport and exchange parameters γ η v β and d the values of which can be obtained using inverse methods for each river data set to solve this inverse problem one requires at least two btcs one at either end of the river reach used for the tracer test given a series of btcs at multiple locations for a given tracer test the parameters γ η v β and d may be estimated on a per reach basis this is the approach used here 4 application one benefit of expressing the temporal moments of modeled btcs in terms of model parameters is that such expressions can be useful in model calibration e g wörman et al 2002 schmid 2003 here we use the temporal moment expressions for a particular form of the memory function model in combination with moments from tracer test btcs to calibrate the model eqs 1 and 2 to narrow the set of memory function models examined we choose the two parameter of gm3 memory function form corresponding to the gamma distributed multirate mass transfer mrmt model of haggerty et al 2000 we first specify expressions for the modeled btc temporal moments in terms of the parameters of this gamma mrmt memory function based river corridor transport model including river velocity v and dimensionless volume ratio β and then we invert these relations in order to calibrate a one dimensional river corridor transport model for two tracer test data sets the uvas creek tracer test data set from a small pool and riffle stream in the sierra nevada mountains in santa clara county california zand et al 1976 bencala and walters 1983 avanzino et al 1984 is well studied jackman et al 1984 wagner and gorelick 1986 wörman 1998 schmid 2003 etc and includes five btcs measured at different distances downstream of the injection the sturt river schaper et al 2018 mccallum et al 2020 tracer test data is from a first order urban stream in adelaide hills australia and includes two btcs these data sets are selected because the respective studies report values for all parameters including river velocity v dispersion coefficient d tsm exchange rate coefficients kf and kr and dimensionless volume ratio β required for simulation of the btcs resulting from the tracer test using the tsm model following schmid 2003 we apply moment expressions to sequential pairs of uvas creek btc data monitored at 38 m 105 m 281 m and 433 m downstream of the injection location to identify parameter values for simplicity we approximate the btc at 38 m with a finite duration pulse of concentration 8 mg l and we ignore the incomplete mass recoveries at downstream locations which are 99 105 m 87 281 m and 82 at 433 m zand et al 1976 for the sturt river data we use the two btcs monitored at 649 m and at 1539 m downstream of the injection location finally we use the parameter values identified by use of the temporal moments in a numerical solution of the gm3 to simulate the original btc data the purpose of the numerical simulation is to demonstrate that the model calibrated to the temporal moments can be solved to simulate the btcs associated with the tracer test however this is not a validation of the transport model itself 4 1 direct inversion given independently measured v d and or β given the btc data and estimated v d and β one may directly calculate the coefficients a i of the moments equations as well as the moments of the memory function we made these calculations for the btcs monitored in the uvas creek bencala and walters 1983 schmid 2003 and the sturt river schaper et al 2018 mccallum et al 2020 tracer tests values of a i were obtained by sequentially inverting the central moments equations of table 1 for the uvas creek data by using the transport parameters v and d and central moments given in schmid 2003 and for the sturt river data with v and d taken from mccallum et al 2020 and central moments calculated directly from the btc data provided by the first author table 2 shows the resulting values for a i for both cases given the values of ai and β we may then also estimate 0 ω i 1 g ω d ω by eqs 6 9 note that this determination of the a i as well as the moments of the memory function given v d and β is achieved without requiring any information about the form of the memory function 4 2 indirect inversion for all transport and exchange parameters given measured central moments the central moments expressions of table 1 provide a closed form link between the ai and measured central moments of a given btc eqs 6 9 in turn provide a link between the ai and the memory function we sought a solution to the inverse problem by application of the gradient based parameter calibration software pest doherty 2001 the objective function minimized was i m i m 0 i e s t m i m 0 i o b s 2 where m i e s t and m 0 i e s t are the estimated central moments at the end and at the beginning of the reach length respectively and m i o b s and m 0 i o b s are the observed central moments at the end and at the beginning of the reach length respectively the moments mi m 0 i est are defined by eqs 17 20 for i 1 3 this corresponds to a simple least squares approach with unit weights on each term of the objective function except for η that was bounded from 3 to 1 0e10 the other parameters γ v β and d were bounded from 1 0e 10 to 1 0e10 no prior information was considered for the parameters values table 3 shows the results for both streams estimated values of η vary significantly between the two streams this is consistent with relatively low sensitivity of the simulated btc data to η for instance in the sturt river case the composite sensitivity sum change in simulated data per 1 change in parameter value at the optimal solution of the inverse problem for η is small compared to those for γ and β it should be noted that the composite sensitivity for d is by far the lowest in all cases consistent with the prior classification of transport in these studies as high péclet transport the comparison of the results of table 3 with those of schmid 2003 shows comparative performance of pest and memory function based moments analysis for estimating parameters schimd 2003 used an unconstrained estimation approach that originally found some negative values for d for the second and third reaches and then fixed the parameter at d 0 and repeated the estimation our estimations give this parameter very close to zero but not negative and our resulting d values are not on a constraining parameter bound our estimations of v and β for sturt river are close to the measured values reported in schaper et al 2018 and in mccallum et al 2020 this indicates the capability of the analysis in estimating the parameters that are time cost consuming to measure we expect that the lack of complete tracer recovery particularly in the uvas creek tracer test data negatively impacts the estimation of higher order moments although such is not certainly manifest in the parameter estimation and we have not pursued this further 4 3 the forward solution we developed a numerical solution to the memory function model eq 2 using explicit finite differences with a forward time centered space stencil this approach is simple and facilitates straightforward treatment of the convolution term however the solution obtained by this method is only conditionally stable to ensure stability the neuman condition dδt δx 2 0 5 and courant condition vδt δx 1 were implemented in the discretization the convolution term was solved by discretizing the integral on the same grid to test our numerical solution we applied it to simulate one dimensional river corridor transport with classical first order exchange that is the tsm model because the tsm is the simplest first order exchange model this serves only as a limited test of our numerical solution however this also demonstrates that the lassey solution may be used to solve the tsm without lateral influx of groundwater to devise a closed form quasi analytical solution to the tsm model with zero lateral influx we adapted the solution that lassey 1988 provided for one dimensional transport in porous media with first order exchange between mobile and immobile domains to translate lassey s solution the mobile domain porosity is treated as the river cross sectional area the immobile domain porosity is treated as the hyporheic zone porous cross sectional area and all other parameters velocity longitudinal dispersion first order exchange rate coefficients are identical in both contexts cf supplemental information note that the lassey solution pertains only to the tsm single rate model case and not to the general memory function case good concordance between the lassey based solution and our numerical solution for the tsm case appears in the plots of concentration profiles for instance as shown in fig 1 at t 10 min dashed lines and at t 20 min solid lines for the parameter values β 0 015 kf kr 0 0236 min v 1 8 m min and d 3 6 m2 min the numerical simulations of gm3 for uvas creek and for sturt river datasets are shown in figs 2 and 3 respectively fig 2 includes the tsm simulation of schmid 2003 we note the reasonably close approximation of the data and the similarities between our simulated btcs and those by schmid 2003 our curves overshoot peaks and to a lesser degree the tails more than the simulation by schmid 2003 possibly due to our overestimation of mass injected relative to that estimated by schmid 2003 who used the actual btc data at 38 m as the injection boundary condition schmid 2003 also noted the deviation in parts of the recession limbs similar errors appear in the falling limb of simulation of the sturt river btc at x 1539 m fig 3 mccallum et al 2020 observed similar behavior of both their tsm and memory function model simulations with truncated powerlaw residence times in the hyporheic zone of these data and suggested that unweighted least squares fitting may be more heavily influenced by peak errors than errors in the btc tail 5 summary there are two primary results of this study first we have explored some basic properties of the general memory function formulation of one dimensional models of solute transport in river corridors comprised of a river channel that exhibits conventional post asymptotitic dispersion advective dispersive transport and an immobile hyporheic zone that exchanges mass in fully reversible fashion with the river channel according to a memory function mass exchange according to a memory function formulation has a corresponding representation as mass exchange according to first order kinetics where the rate coefficient for mass flux from the hyporheic zone to the river channel depends on residence time in the hyporheic zone phedex model ginn et al 2017 we exploited this equivalence to use the phedex form in order to solve the governing equations for temporal moments of btcs simulated with a memory function form the generality of memory function or phedex formulations allows for incorporation of many exchange process models including multi rate mass transfers diffusions and lags this analysis yields closed form expressions for the first four temporal moments of btcs simulated with one dimensional models with memory function exchange involving coefficients that are related to the temporal or age moments of the memory function itself through eqs 6 9 one result of these expressions is the demonstration that memory function based models of one dimensional transport in river corridors give rise to coefficient of skewness csk that scales as x 1 2 where x is distance traversed this generalizes the result of gonzález pinzón et al 2013 who showed the same scaling behavior for a smaller set of models second following schmid 2003 and numerous other authors we here explored the link between river tracer test data and model calibration by calibrating the memory function form under the assumption that the memory function is described with a two parameter template model borrowed from multi rate mass transfer theory haggerty et al 2000 by use of the derived relations between model parameters and measured temporal moments from btcs obtained from river tracer tests our demonstrations illustrate approaches to river transport model calibration using both direct or indirect inverse problem depending on how many parameters are to be determined a side note from these exercises is the fact that the well known tsm model has a closed form quasi analytical solution due originally to lassey 1988 with important correction in lassey 1989 the specific results of this study are as follows 1 closed form expressions for temporal moments of memory function based one dimensional advective dispersive transport models are obtained 2 like essentially all previous models the memory function model cannot give a constant or adjustable csk 3 the moments solutions for memory function phedex model is a useful tool to estimate some river parameters such as β that are time cost consuming to measure generalizing the approach of schmid 2003 and many others in river model calibration 4 the moments analysis gives the capability of obtaining the moments of the memory function without requiring any particular information about its form 5 the tsm without lateral flux of groundwater has an analytical solution obtained by adapting the lassey 1988 solution supplemental information for one dimensional advective dispersive transport in porous media with first order mass exchange between mobile and immobile aqueous phases credit authorship contribution statement mohammad aghababaei formal analysis investigation methodology data curation writing original draft timothy r ginn conceptualization formal analysis investigation methodology data curation writing original draft project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank jim mccallum for sharing data and jim mccallum lynn schreyer and kc carroll for helpful comments on this work that was supported part by the national science foundation under project 2142165 and by the usda under grant 2019 33522 30203 we also thank jesús carrera and two other anonymous reviewers and the editor whose works improved this article very much supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2023 104383 appendix b supplementary materials image application 1 appendix a table a1 shows all the variables terms used in this paper their units and their definitions here we derive the solutions of eqs 4 and 5 for unnormalized raw moments μ k k 0 4 while these results are presented in the context of hyporheic exchange they can be readily applied to any mobile immobile domain mass transfer governed by memory functions for k 0 eqs 4 and 5 become respectively a1 l μ 0 β k f μ 0 β 0 k r ω σ 0 ω d ω a2 d σ 0 ω d ω k r ω σ 0 ω where σ0 0 kf μ0 the solution of a2 is a3 σ 0 ω k f μ 0 e k ω where ω 0 ω k r ω d ω then eq a1 becomes a4 l μ 0 β k f μ 0 β k f μ 0 0 d d ω e k ω d ω with our restriction to fully reversible mass exchange processes i e that lim ω 0 ω k r ω d ω then the integral in a4 has value equal to 1 this is the same as that the 0th moment of g kf is unity ginn 2009 and the solution to a4 is a5 μ 0 c o n s t a n t which is consistent with luo et al 2008 eq 14 for k 1 the moments equations become a6 μ 0 l μ 1 β k f μ 1 β 0 k r ω σ 1 ω d ω a7 d σ 1 ω d ω σ 0 ω k r ω σ 1 ω where σ1 0 kf μ1 and boundary condition μ1 0 we again start by developing the solution to the immobile phase moment eq a7 now by integration factor method here we give the details for demonstration the substitution σ1 ω e k ω ρ ω converts a7 to a8 k r ω e k ω ρ ω e k ω d ρ ω d ω σ 0 ω k r ω σ 1 ω in which by substituting σ1 ω and then canceling the same terms from both sides we eventually have a9 d ρ ω σ 0 ω e k ω d ω or integrating and using the construction that ρ 0 σ1 0 kf μ1 a10 ρ ω 0 e k ω σ 0 ω d ω k f μ 1 with σ1 ω is defined as e k ω ρ ω we have ρ ω σ1 ω e k ω so that a11 σ 1 ω e k ω 0 e k ω σ 0 ω d ω k f μ 1 where after substituting σ0 ω using eq a3 the above equation gives eventually a12 σ 1 ω k f e k ω μ 1 μ 0 ω if we substitute eq a12 into eq a7 and rearrange it and define a 0 0 k r ω e k ω d ω 1 and a 1 β k f 0 k r ω ω e k ω d ω 1 we have a13 l μ 1 β k f a 0 μ 1 a 1 μ 0 we can evaluate a0 and a1 as follows with the assumption of fully reversible exchange i e that kr ω 0 a14 a 0 0 k r ω e k ω d ω 1 0 d d ω e k ω d ω 1 e k ω 0 1 0 now eq a14 can be expressed as a15 d 2 μ 1 d x 2 v d d μ 1 d x a 1 d μ 0 which is consistent with luo et al 2008 eq 15 in which a 1 β tot ω0 1 where β tot is the capacity coefficient and ω0 is the 0th temporal moment of memory function luo et al 2008 the homogeneous form of eq a15 is a16 d 2 μ 1 d x 2 v d d μ 1 d x 0 the characteristic equation of eq a16 is λ 2 v d λ 0 which has two solutions for ƛ as λ 1 v d and λ2 0 since the discriminant is positive the general solution μ 1 c 1 e λ 1 x c 2 e λ 2 x for eq a16 is a17 μ 1 c 1 e v d x c 2 now if we define y 1 e v d x y 2 1 and w x y 1 d y 1 d x y 2 d y 2 d x the general solution for eq a15 is of the form a18 μ 1 u 1 y 1 u 2 y 2 where u 1 y 2 r x w x d x and u 2 y 1 r x w x d x and r x is the right hand side rhs of a15 evaluation of w x yields w x e v d x v d e v d x 1 0 0 v d e v d x v d e v d x and calculating u 1 and u 2 gives u 1 a 1 d μ 0 v 2 e v d x μ 0 v c u 2 a 1 μ 0 v x c finally by substituting y 1 y 2 u 1 and u 2 in eq a18 we have the solution as follows a19 μ 1 x a 1 d μ 0 v 2 a 1 μ 0 v x μ 0 v e v d x c c where c and c are unknown constants using the boundary condition μ1 0 c 0 and consequently μ 1 0 a 1 μ 0 d v 2 c so that from eq a19 we obtain a20 μ 1 x a 1 μ 0 v x μ 1 0 for k 2 the moments equations become a21 2 μ 1 l μ 2 β k f μ 2 β 0 k r ω σ 2 ω d ω a22 d σ 2 ω d ω 2 σ 1 ω k r ω σ 2 ω where σ2 0 kf μ2 again we start with a solution to the immobile phase moment equation a23 σ 2 ω k f e k ω μ 2 2 μ 1 ω μ 0 ω 2 if we substitute eq a23 in eq a21 and rearrange it and define a 2 β k f 0 k r ω ω 2 e k ω d ω given a0 0 from a14 we have a24 d 2 μ 2 d x 2 v d d μ 2 d x 2 a 1 μ 1 d a 2 μ 0 d which is consistent with luo et al 2008 eq 16 in which a 1 is same as before and a 2 2β tot ω1 where ω1 is the 1st temporal moment of memory function luo et al 2008 the solution of eq a24 again follows the similar path as in the k 1 case a25 μ 2 x 2 a 1 2 d μ 0 v 3 a 2 μ 0 2 a 1 μ 1 0 v x a 1 2 μ 0 v 2 x 2 μ 2 0 for k 3 the moments equations become a26 3 μ 2 l μ 3 β k f μ 3 β 0 k r ω σ 3 ω d ω a27 d σ 3 ω d ω 3 σ 2 ω k r ω σ 3 ω where σ3 0 kf μ3 we start with a solution to the immobile phase moment equation as before and get the following solution for eq a27 a28 σ 3 ω k f e k ω μ 3 3 μ 2 ω 3 μ 1 ω 2 μ 0 ω 3 if we substitute eq a28 in eq a26 and rearrange it and define a 3 β k f 0 k r ω ω 3 e k ω d ω given a0 0 we have now a29 d 2 μ 3 d x 2 v d d μ 3 d x 3 a 1 μ 2 d 3 a 2 μ 1 d a 3 μ 0 d the solution for eq a29 is obtained following the same path as in k 1 case a30 μ 3 x 6 a 2 a 1 d μ 0 a 1 2 d μ 1 0 v 3 12 a 1 3 d 2 μ 0 v 5 a 3 μ 0 3 a 1 μ 2 0 3 a 2 μ 1 0 v x 6 a 1 3 d μ 0 v 4 3 a 1 a 2 μ 0 a 1 μ 1 0 v 2 x 2 a 1 3 μ 0 v 3 x 3 μ 3 0 for k 4 the moments equations become a31 4 μ 3 l μ 4 β k f μ 4 β 0 k r ω σ 4 ω d ω a32 d σ 4 ω d ω 4 σ 3 ω k r ω σ 4 ω where σ4 0 kf μ4 we start with a solution to the immobile phase moment eq a32 as before and get the following solution for eq a31 a33 σ 4 ω k f e k ω μ 4 4 μ 3 ω 6 μ 2 ω 2 4 μ 1 ω 3 μ 0 ω 4 if we substitute eq a33 in eq a31 and rearrange it and define a 4 β k f 0 k r ω ω 4 e k ω d ω given a 0 0 we have now a34 d 2 μ 4 d x 2 v d d μ 4 d x 4 a 1 μ 3 d 6 a 2 μ 2 d 4 a 3 μ 1 d a 4 μ 0 d the solution for eq a34 is obtained following the same path as in k 1 case a35 μ 4 x a 4 μ 0 4 a 1 μ 3 0 6 a 2 μ 2 0 4 a 3 μ 1 0 v 8 a 1 a 3 d μ 0 6 a 2 2 d μ 0 24 a 1 a 2 d μ 1 0 12 a 1 2 d μ 2 0 v 3 72 a 1 2 a 2 d 2 μ 0 48 a 1 3 d 2 μ 1 0 v 5 120 a 1 4 d 3 μ 0 v 7 x 3 a 2 2 4 a 1 a 3 μ 0 12 a 1 a 2 μ 1 0 6 a 1 2 μ 2 0 v 2 36 a 1 2 a 2 d μ 0 24 a 1 3 d μ 1 0 v 4 60 a 1 4 d 2 μ 0 v 6 x 2 6 a 1 2 a 2 μ 0 4 a 1 3 μ 1 0 v 3 12 a 1 4 d μ 0 v 5 x 3 a 1 4 μ 0 v 4 x 4 μ 4 0 to summarize we tabulate these results as follows tables a2 and a3 show the moments governing equations for immobile solute concentration and their solutions respectively tables a4 and a5 show the moments governing equations for mobile solute concentration and their solutions respectively tables a6 shows normalized absolute moments of order 1 2 3 and 4 for mobile solute concentration 
63,practical simulation of solute transport in river corridors often relies on one dimensional transport models with solute flux between river and hyporheic zone governed by a mass exchange term perhaps most generally expressed using the memory function formalism while expressions for temporal moments of solute breakthrough curves btcs are available for a number of such models those for memory function forms are not to our knowledge here we report closed form btc temporal moment expressions for memory function forms found by exploiting the connection to phase exposure dependent exchange phedex formulations we use these results to investigate the general capability of the memory function form to accommodate specific scaling of river tracer temporal moments reported in the literature and we apply the method to identification of parameters in application to two recent tracer tests the applications involve a simple numerical solution to the memory function river corridor transport model calibrated using measured temporal moments of the tracer test btcs the numerical model is validated only for the classical case of the transient storage model without lateral inflow the analytical solution for which we adapt from the lassey solution for mobile immobile exchange in porous media it should be noted that the temporal moments results obtained here in the context of river corridor transport also apply to one dimensional transport in two domain mobile immobile porous media when governed by a two domain memory function model keywords river transport memory function temporal moments analysis data availability all data used is published by others 1 introduction water quality management relies on practically useful tools for simulation of solute transport in river corridors for which there are often no supporting tracer test data and yet predicting solute transport in streams is among the most challenging problems in surface water quality modeling wörman 2000 o connor et al 2010 river corridors play an important role in fate and transport of nutrients contaminants and weathering products as impacted by the mass exchange between the channel flow and the typically more metabolically active hyporheic zone lawrence et al 2013 harvey and gooseff 2015 brunner et al 2017 researchers have recognized that processes occurring in the hyporheic zone are critical for contaminant degradation nutrient cycling habitat selection and ecosystem metabolism and generally for the management and restoration of the whole river environment haggerty et al 2000 schmid 2003 boano et al 2014 wlostowski et al 2017 mccallum et al 2020 thus in the modeling of solute transport in river corridors it is necessary to consider the mass exchange between the river and the hyporheic zone two examples of the numerous conceptual models of this mass exchange process are advective pumping and turbulent exchange advective pumping describes darcy flow within streambed bars or dunes resulting from hydraulic head gradients between upstream and downstream faces of such morphological features e g elliot and brooks 1997a b salehin et al 2004 marion et al 2002 packman et al 2004 tonina and buffington 2007 bottacin busolin and marion 2010 several of these studies point out that transverse dispersion within the hyporheic zone can transfer solute across streamlines impacting the residence time distribution in the hyporheic zone which is not incorporated into most advective pumping models hester et al 2017 in high permeability sediment beds turbulent streamflow can impart momentum and mass transfer between the stream and the hyporheic zone e g grant et al 2018 roche et al 2018 while streamflow turbulence is often assumed to impact only a thin layer of the hyporheic zone e g tonina and buffington 2007 exchange rates in flat gravel beds have been found to be 2 4 orders of magnitude greater than those predicted by advective pumping o connor and harvey 2008 roche et al 2018 we do not attempt to represent either process explicitly but instead focus on a mathematically general yet effective representation of exchange no chemical reactions are considered here although our focus on residence time accounting in the hyporheic zone may accommodate reactions that depend primarily on this variable e g roche and dentz 2022 the original representation of river hyporheic zone mass exchange is one of reversible first order kinetics with constant coefficients according to the transient storage model tsm bencala and waters 1983 kelleher et al 2019 and many others the evolution of increasingly general models of this mass exchange term is well documented in rivers literature leading to the memory function form haggerty et al 2002 mccallum et al 2020 roche and dentz 2022 the memory function form originated in carrera et al 1998 from leaky aquifer mechanics herrera and rodarte 1973 herrera and yates 1977 in haggerty et al 2000 from carrera et al 1998 and chromatography villermaux 1974 and in hornung and showalter 1990 for transport in fractured media and can represent most theories of exchange in mobile immobile media silva et al 2009 2 background 2 1 basic model forms here we introduce three basic model forms an original river corridor transport model with first order exchange its generalization to memory function form and lastly the representation of the memory function model as a first order exchange model with rate coefficient dependence on residence time spent in the hyporheic zone a table of variables terms with units and definitions is given in appendix a solute concentration in the channel is c c x t and in the hyporheic zone is s s x t both in units of ml 3 the transient storage model tsm e g bencala and walters 1983 is a one dimensional two domain representation of transport in a channel with first order exchange with the hyporheic zone 1a c t q a c x 1 a x d a c x q l a c l c α β c s 1b s t α c s in which q is the stream flow laqu 3 t 1 d is the longitudinal dispersion coefficient l 2 t 1 ql is the lateral influx of subsurface water to the stream channel l 3 t 1 l 1 cl is the solute concentration in that influx mlaqu 3 α is the rate coefficient for first order mass exchange between the channel and the hyporheic zone t 1 β is a as where as is the porous fraction of the hyporheic zone cross sectional area for ease of transition to memory function forms our α is the α of bencala and walters 1983 divided by β it should be noted that in the simple case of constant d the preasymptotic dispersion is ignored so that the model is used only for distances beyond the mixing length for simplicity henceforth we assume lateral influx ql to be negligible eq 1 form the transient storage model tsm to convert the tsm model to memory function form we solve the second tsm equation by integration factor method while assuming zero initial mass in the hyporheic zone and substitute the result into the first equation yielding the memory function model 2a c t l c β t g c 2b s t t g c where l c is the transport operator q a c x 1 a x d a c x g c 0 t g ω c x t ω d ω that is the convolution product and g ω is the memory function which in the tsm case is equal to αe αω the memory function form admits a wide array of different exchange processes well beyond the first order single rate exchange of the tsm eq 2 form the memory function model if we return to the tsm first order kinetics starting point but keep track of the residence time spent in the hyporheic zone that is rewrite the immobile zone concentration s x t as a distribution s x t ω over ω the residence time in the immobile zone we can write any memory function model in terms of such a phase exposure time dependent exchange phedex model ginn 2009 ginn et al 2017 to do this we keep track of time spent in the hyporheic zone by what appears to be an advection operator that moves mass along the ω axis while in the hyporheic zone that is we use advection to age the mass while in the hyporheic zone details of this approach are further summarized in the supplemental information given a memory function g ω and eq 2 the corresponding phedex model is 3a c t l c β k f c β 0 k r ω s ω d ω 3b s t 1 s ω k r ω s where now s s x t ω the new advection aging operator is 1 s ω in eq 3b where the 1 is the aging velocity in units of age per time eq 3b has a new boundary condition 1 s x t ω 0 kfc x t where the 1 is again the aging velocity and thus this is a flux condition that specifies the rate of mass entry to the hyporheic zone at age ω 0 from the channel mass leaves the hyporheic zone by first order kinetic kr ω s but now with the new rate coefficient kr ω that depends on the time spent in the hyporheic zone this mass is collected integrated over all ω and entered into the channel equation via the last term in eq 3a finally the rate coefficients kf and kr ω both t 1 are derived from the memory function as k f lim ω 0 g ω and k r ω 1 g ω d g d ω conversely given a phedex model the corresponding memory function is g ω k f e x p 0 ω k r u d u eq 3 make up the phedex form of the memory model the demonstration that any memory function model of the from of eq 2 can be cast as a phedex model originally done in ginn 2009 is retraversed and streamlined in the supplemental information the primary reason that we introduce the phedex version of a given memory function model here is because we can solve the corresponding temporal moment equations using the phedex version 2 2 temporal moments river tracer tests may be simulated by joining the transport equation with boundary and initial conditions representing the introduction of the tracer to the channel and solving the resulting system to simulate the solute concentration at a downstream location as a function of time the breakthrough curve btc paraphrasing a careful reviewer a btc is by definition a flux averaged concentration whereas most riverine btcs are actually discrete time samples of concentration at one or an average of several measurement point s in the stream unaffiliated with corresponding instantaneous local flux at that location treatment of these data as equivalent to flux averaged concentrations implies complete lateral mixing for conservative tracers each btc represents a non normalized solute concentration distribution over arrival time to the downstream measurement location the btc can be characterized by the temporal moments of this distribution that is if we normalized this distribution by the zeroth moment total mass then the mean of the distribution is mean arrival time and shifting the distribution to this mean the second and third centered moments are arrival time variance and skewness respectively it must be noted that higher moments are generally very sensitive to the extent and shape of late time solute arrival i e tailing as pointed out in context of water age in porous media in varni and carrera 1998 and in solute transport in porous media in haggerty et al 2000 both referring to impacts of matrix diffusion matalas 1967 page 943 highlights this problem in a more general context of hydrologic time series noting that for parameters that are defined in terms of moments their standard errors increase with an increase in the order of the moments the spatial scaling of these temporal moments and their dimensionless combinations can serve as characteristic signatures of transport and so the scaling possibilities of these quantities when governed by a math model are of interest in particular the coefficient of skewness csk the skewness divided by the 3 2 power of the variance is a common dimensionless metric of btc asymmetry and tailing nordin and troutman 1980 schmid 2003 wörman 2000 and wörman et al 2002 developed expressions for temporal moments for several one dimensional river corridor transport models with negligible longitudinal dispersion including the tsm as well as those with general residence time distributions in the hyporheic zone associated with advective pumping schmid 2003 gives closed form expressions for the temporal moments of the tsm model including longitudinal dispersion in the channel and for general boundary conditions specifying the tracer injection gonzález pinzón et al 2013 applied temporal moments analysis to several general model frameworks expressed with parameters not varying with space including simple advection dispersion tsm the decoupled continuous time random walk approach ctrw boano et al 2007 and the multirate mass transfer model mrmt haggerty et al 2002 and showed that all predict a csk that drops with distance traversed an unsurprising result given their practical equivalence per silva et al 2009 their analyses of tracer test data however suggested that the csk is in fact a constant of space and concluded that there is a need to revise the theory of river corridor solute transport so that one dimensional math models can accommodate a constant csk while the foregoing list of models can all be cast in the form of memory function models the scaling of temporal moments of memory function models has not been determined this study reports explicit expressions for the temporal moments of the aqueous solute concentration and of the immobile solute concentration when they are governed by a memory function form of one dimensional two domain transport with advection dispersion in the mobile phase with constant velocity and dispersion coefficient no lateral inflow and with exchange with the immobile domain governed by a memory function the governing equations of these temporal moments are described in luo et al 2008 but the solution to luo s governing equations is non trivial we work around that barrier by exploiting the transformation of the memory function form into its phedex representation e g ginn et al 2017 supplemental information the analyses of which leads directly to a solution of luo et al 2008 governing equations the development of the phedex form of a given memory function river model is described in the supplemental information in the following sections closed form expressions for the first four temporal moments of a river tracer breakthrough curve governed by the memory function form are found using these expressions we test whether the memory function based river model can generate a constant csk we then use the temporal moments expressions to calibrate a 1 d river transport model that is based on the memory function form for the four uvas creek btcs analyzed by schmid 2003 and for a single btc monitored in the sturt river as reported in schaper et al 2018 and in mccallum et al 2020 3 temporal moments of one dimensional river transport models with memory function exchange we wish to find closed form solutions for the temporal moments of btcs governed by the memory function form of eq 2 luo et al 2008 provided the governing equations but not the solution for those temporal moments here we solve for the temporal moments in question by recasting the memory function model into its corresponding phedex model eq 3 form developing the governing equations for the temporal moments of the phedex model form and solving them if we apply the moment operator 0 τ k d τ to the phedex model eq 3 and define the kth temporal moment of c and of s respectively as μ k x 0 τ k c d τ and σ k x 0 τ k s d τ then we obtain the governing equations for the unormalized raw moments μ k x and for σ k x 4 k μ k 1 l μ k β k f μ k β 0 k r ω σ k ω d ω 5 k σ k 1 ω d σ k ω d ω k r ω σ k ω with σ k 0 kf μ k in lieu of mathematical details of the derivation of eqs 4 and 5 we point out that the moment operator commutes with all operators appearing in the phedex eq 3 with the exception of the time derivatives that are handled using integration by parts yielding the first terms in eqs 4 and 5 thus eqs 4 and 5 are similar in form to the original phedex equations we presume the tracer is injected in the river at location x 0 with normalized and centered temporal moments mk 0 k 1 4 to ensure complete recovery of injected solute in the btc we also assume that the mass exchange is fully reversible i e that kr ω 0 which means that all the mass entering the hyporheic zone returns to the main river flow details of the solutions of eqs 4 and 5 for unnormalized raw moments μ k k 0 1 2 3 4 appear in appendix a the normalized absolute moments are defined as e g govindaraju and das 2007 luo et al 2008 μ n μ n μ 0 and the central moments of order 1 2 3 and 4 are m 1 μ 1 m 2 μ 2 μ 1 2 m 3 μ 3 3 μ 1 μ 2 2 μ 1 3 and m 4 μ 4 4 μ 1 μ 3 6 μ 2 μ 1 2 3 μ 1 4 respectively since the normalized central moments for river solute concentration c can give information about longitudinal mixing and exchange processes we focus on the moments for river solute concentration shown in table 1 where with k ω 0 ω k r u d u a 1 β k f 0 e k ω d ω 1 a 2 2 β k f 0 ω e k ω d ω a 3 3 β k f 0 ω 2 e k ω d ω and a 4 4 β k f 0 ω 3 e k ω d ω the coefficients a 1 a 2 a 3 and a 4 can be expressed in terms of the moments of the memory function i e 0 ω k 1 g ω d ω k 1 2 as follows 6 a 1 β 0 g ω d ω 1 7 a 2 2 β 0 ω g ω d ω 8 a 3 3 β 0 ω 2 g ω d ω 9 a 4 4 β 0 ω 3 g ω d ω where g ω kfe k ω the derived expressions for central moments also allow us to find a closed form for the coefficient of skewness csk for the river btc resulting from an instantaneous pulse introduced at x 0 that is 10 c s k m 3 m 2 3 2 a 3 6 a 1 a 2 d v 2 12 a 1 3 d 2 v 4 x v m 3 0 2 a 1 2 d v 2 a 2 x v m 2 0 3 2 note that in the case of negligible dispersion coefficient e g bencala and walters 1983 schmid 2003 and zero initial moments the first three values of a are equivalent to the corresponding btc central moments mi divided by travel time for this specific case the csk reduces to 11 c s k a 3 a 2 3 2 x v 1 2 eqs 10 and 11 show that the csk for memory function river transport models scales generally with space to the negative one half power this result generalizes the identical finding of gonzález pinzón et al 2013 to any model that has a memory function form 3 1 the moments in the tsm by substituting eqs 6 9 into the central moments equations of table 1 we obtain the first four central moments of solute concentration in terms of the memory function g this demonstrates the ability of the expressions obtained to represent temporal moments for any exchange model that can be cast in memory function form for instance we consider the tsm case in which kr as well as kf are constants so k ω 0 ω k r d ω k r ω and then a 1 1 β a 2 2β kr a 3 6 β k r 2 and a 4 24 β k r 3 by substituting these coefficients into table 1 we obtain 12 m 1 1 β x v m 1 0 13 m 2 2 1 β 2 d v 2 2 β k r x v m 2 0 14 m 3 6 β k r 2 12 1 β β d k r v 2 12 1 β 3 d 2 v 4 x v m 3 0 15 m 4 24 β k r 3 12 β k r m 2 0 24 β 2 d k r 2 v 2 48 1 β β d k r 2 v 2 12 1 β 2 d v 2 m 2 0 144 β 1 β 2 d 2 k r v 4 120 1 β 4 d 3 v 6 x v 24 β 1 β 2 d k r v 2 12 β 2 k r 2 12 1 β 4 d 2 v 4 x 2 v 2 m 4 0 that are first four moments of tsm respectively identical to the moments reported by schmid 2003 eqs 21 24 in a specific case when we have m 1 0 m 2 0 m 3 0 m 4 0 0 eqs 12 14 give the same results as eq 11 in gonzález pinzón et al 2013 3 2 the moments in a particular memory function model based on gamma distributed rates if a particular mathematical form for the memory function g ω is chosen so that g ω is expressed in term of parameters then one can write expressions linking measured central moments and those parameters in the case where the memory function is formulated based on a gamma distribution of equivalent multiple rates haggerty et al 2000 ginn et al 2017 absent of the β tot factor present in the haggerty et al 2000 version as in 16 g t γ η γ t 1 η 1 with two parameters η and γ we term this the gm3 model then the coefficients a 1 a 2 a 3 and a 4 can be eliminated by inserting 16 into eqs 6 9 and evaluating the integrals to obtain the corresponding moment expressions 17 m γ 1 x 1 β x v m 1 0 η 0 18 m γ 2 x 2 1 β 2 d v 2 2 β η 1 γ x v m 2 0 η 0 19 m γ 3 x 12 1 β 3 d 2 v 4 12 1 β β η 1 γ d v 2 6 β η 1 η 2 γ 2 x v m 3 0 η 2 20 m γ 4 x 48 β 1 β η 1 η 2 γ 2 d 6 2 β η 1 γ 2 d 12 1 β 2 d m 2 0 v 2 24 β η 1 η 2 η 3 γ 3 12 β η 1 γ m 2 0 144 β 1 β 2 d 2 η 1 γ v 4 120 1 β 4 d 3 v 6 x v 3 2 β η 1 γ 2 24 β 1 β 2 d η 1 γ v 2 12 1 β 4 d 2 v 4 x 2 v 2 m 4 0 η 3 where m γ 2 x m γ 3 x m γ 4 x are undefined for η 1 η 2 and η 3 respectively eqs 17 20 provide the linkage between measured central moments and the combined transport and exchange parameters γ η v β and d the values of which can be obtained using inverse methods for each river data set to solve this inverse problem one requires at least two btcs one at either end of the river reach used for the tracer test given a series of btcs at multiple locations for a given tracer test the parameters γ η v β and d may be estimated on a per reach basis this is the approach used here 4 application one benefit of expressing the temporal moments of modeled btcs in terms of model parameters is that such expressions can be useful in model calibration e g wörman et al 2002 schmid 2003 here we use the temporal moment expressions for a particular form of the memory function model in combination with moments from tracer test btcs to calibrate the model eqs 1 and 2 to narrow the set of memory function models examined we choose the two parameter of gm3 memory function form corresponding to the gamma distributed multirate mass transfer mrmt model of haggerty et al 2000 we first specify expressions for the modeled btc temporal moments in terms of the parameters of this gamma mrmt memory function based river corridor transport model including river velocity v and dimensionless volume ratio β and then we invert these relations in order to calibrate a one dimensional river corridor transport model for two tracer test data sets the uvas creek tracer test data set from a small pool and riffle stream in the sierra nevada mountains in santa clara county california zand et al 1976 bencala and walters 1983 avanzino et al 1984 is well studied jackman et al 1984 wagner and gorelick 1986 wörman 1998 schmid 2003 etc and includes five btcs measured at different distances downstream of the injection the sturt river schaper et al 2018 mccallum et al 2020 tracer test data is from a first order urban stream in adelaide hills australia and includes two btcs these data sets are selected because the respective studies report values for all parameters including river velocity v dispersion coefficient d tsm exchange rate coefficients kf and kr and dimensionless volume ratio β required for simulation of the btcs resulting from the tracer test using the tsm model following schmid 2003 we apply moment expressions to sequential pairs of uvas creek btc data monitored at 38 m 105 m 281 m and 433 m downstream of the injection location to identify parameter values for simplicity we approximate the btc at 38 m with a finite duration pulse of concentration 8 mg l and we ignore the incomplete mass recoveries at downstream locations which are 99 105 m 87 281 m and 82 at 433 m zand et al 1976 for the sturt river data we use the two btcs monitored at 649 m and at 1539 m downstream of the injection location finally we use the parameter values identified by use of the temporal moments in a numerical solution of the gm3 to simulate the original btc data the purpose of the numerical simulation is to demonstrate that the model calibrated to the temporal moments can be solved to simulate the btcs associated with the tracer test however this is not a validation of the transport model itself 4 1 direct inversion given independently measured v d and or β given the btc data and estimated v d and β one may directly calculate the coefficients a i of the moments equations as well as the moments of the memory function we made these calculations for the btcs monitored in the uvas creek bencala and walters 1983 schmid 2003 and the sturt river schaper et al 2018 mccallum et al 2020 tracer tests values of a i were obtained by sequentially inverting the central moments equations of table 1 for the uvas creek data by using the transport parameters v and d and central moments given in schmid 2003 and for the sturt river data with v and d taken from mccallum et al 2020 and central moments calculated directly from the btc data provided by the first author table 2 shows the resulting values for a i for both cases given the values of ai and β we may then also estimate 0 ω i 1 g ω d ω by eqs 6 9 note that this determination of the a i as well as the moments of the memory function given v d and β is achieved without requiring any information about the form of the memory function 4 2 indirect inversion for all transport and exchange parameters given measured central moments the central moments expressions of table 1 provide a closed form link between the ai and measured central moments of a given btc eqs 6 9 in turn provide a link between the ai and the memory function we sought a solution to the inverse problem by application of the gradient based parameter calibration software pest doherty 2001 the objective function minimized was i m i m 0 i e s t m i m 0 i o b s 2 where m i e s t and m 0 i e s t are the estimated central moments at the end and at the beginning of the reach length respectively and m i o b s and m 0 i o b s are the observed central moments at the end and at the beginning of the reach length respectively the moments mi m 0 i est are defined by eqs 17 20 for i 1 3 this corresponds to a simple least squares approach with unit weights on each term of the objective function except for η that was bounded from 3 to 1 0e10 the other parameters γ v β and d were bounded from 1 0e 10 to 1 0e10 no prior information was considered for the parameters values table 3 shows the results for both streams estimated values of η vary significantly between the two streams this is consistent with relatively low sensitivity of the simulated btc data to η for instance in the sturt river case the composite sensitivity sum change in simulated data per 1 change in parameter value at the optimal solution of the inverse problem for η is small compared to those for γ and β it should be noted that the composite sensitivity for d is by far the lowest in all cases consistent with the prior classification of transport in these studies as high péclet transport the comparison of the results of table 3 with those of schmid 2003 shows comparative performance of pest and memory function based moments analysis for estimating parameters schimd 2003 used an unconstrained estimation approach that originally found some negative values for d for the second and third reaches and then fixed the parameter at d 0 and repeated the estimation our estimations give this parameter very close to zero but not negative and our resulting d values are not on a constraining parameter bound our estimations of v and β for sturt river are close to the measured values reported in schaper et al 2018 and in mccallum et al 2020 this indicates the capability of the analysis in estimating the parameters that are time cost consuming to measure we expect that the lack of complete tracer recovery particularly in the uvas creek tracer test data negatively impacts the estimation of higher order moments although such is not certainly manifest in the parameter estimation and we have not pursued this further 4 3 the forward solution we developed a numerical solution to the memory function model eq 2 using explicit finite differences with a forward time centered space stencil this approach is simple and facilitates straightforward treatment of the convolution term however the solution obtained by this method is only conditionally stable to ensure stability the neuman condition dδt δx 2 0 5 and courant condition vδt δx 1 were implemented in the discretization the convolution term was solved by discretizing the integral on the same grid to test our numerical solution we applied it to simulate one dimensional river corridor transport with classical first order exchange that is the tsm model because the tsm is the simplest first order exchange model this serves only as a limited test of our numerical solution however this also demonstrates that the lassey solution may be used to solve the tsm without lateral influx of groundwater to devise a closed form quasi analytical solution to the tsm model with zero lateral influx we adapted the solution that lassey 1988 provided for one dimensional transport in porous media with first order exchange between mobile and immobile domains to translate lassey s solution the mobile domain porosity is treated as the river cross sectional area the immobile domain porosity is treated as the hyporheic zone porous cross sectional area and all other parameters velocity longitudinal dispersion first order exchange rate coefficients are identical in both contexts cf supplemental information note that the lassey solution pertains only to the tsm single rate model case and not to the general memory function case good concordance between the lassey based solution and our numerical solution for the tsm case appears in the plots of concentration profiles for instance as shown in fig 1 at t 10 min dashed lines and at t 20 min solid lines for the parameter values β 0 015 kf kr 0 0236 min v 1 8 m min and d 3 6 m2 min the numerical simulations of gm3 for uvas creek and for sturt river datasets are shown in figs 2 and 3 respectively fig 2 includes the tsm simulation of schmid 2003 we note the reasonably close approximation of the data and the similarities between our simulated btcs and those by schmid 2003 our curves overshoot peaks and to a lesser degree the tails more than the simulation by schmid 2003 possibly due to our overestimation of mass injected relative to that estimated by schmid 2003 who used the actual btc data at 38 m as the injection boundary condition schmid 2003 also noted the deviation in parts of the recession limbs similar errors appear in the falling limb of simulation of the sturt river btc at x 1539 m fig 3 mccallum et al 2020 observed similar behavior of both their tsm and memory function model simulations with truncated powerlaw residence times in the hyporheic zone of these data and suggested that unweighted least squares fitting may be more heavily influenced by peak errors than errors in the btc tail 5 summary there are two primary results of this study first we have explored some basic properties of the general memory function formulation of one dimensional models of solute transport in river corridors comprised of a river channel that exhibits conventional post asymptotitic dispersion advective dispersive transport and an immobile hyporheic zone that exchanges mass in fully reversible fashion with the river channel according to a memory function mass exchange according to a memory function formulation has a corresponding representation as mass exchange according to first order kinetics where the rate coefficient for mass flux from the hyporheic zone to the river channel depends on residence time in the hyporheic zone phedex model ginn et al 2017 we exploited this equivalence to use the phedex form in order to solve the governing equations for temporal moments of btcs simulated with a memory function form the generality of memory function or phedex formulations allows for incorporation of many exchange process models including multi rate mass transfers diffusions and lags this analysis yields closed form expressions for the first four temporal moments of btcs simulated with one dimensional models with memory function exchange involving coefficients that are related to the temporal or age moments of the memory function itself through eqs 6 9 one result of these expressions is the demonstration that memory function based models of one dimensional transport in river corridors give rise to coefficient of skewness csk that scales as x 1 2 where x is distance traversed this generalizes the result of gonzález pinzón et al 2013 who showed the same scaling behavior for a smaller set of models second following schmid 2003 and numerous other authors we here explored the link between river tracer test data and model calibration by calibrating the memory function form under the assumption that the memory function is described with a two parameter template model borrowed from multi rate mass transfer theory haggerty et al 2000 by use of the derived relations between model parameters and measured temporal moments from btcs obtained from river tracer tests our demonstrations illustrate approaches to river transport model calibration using both direct or indirect inverse problem depending on how many parameters are to be determined a side note from these exercises is the fact that the well known tsm model has a closed form quasi analytical solution due originally to lassey 1988 with important correction in lassey 1989 the specific results of this study are as follows 1 closed form expressions for temporal moments of memory function based one dimensional advective dispersive transport models are obtained 2 like essentially all previous models the memory function model cannot give a constant or adjustable csk 3 the moments solutions for memory function phedex model is a useful tool to estimate some river parameters such as β that are time cost consuming to measure generalizing the approach of schmid 2003 and many others in river model calibration 4 the moments analysis gives the capability of obtaining the moments of the memory function without requiring any particular information about its form 5 the tsm without lateral flux of groundwater has an analytical solution obtained by adapting the lassey 1988 solution supplemental information for one dimensional advective dispersive transport in porous media with first order mass exchange between mobile and immobile aqueous phases credit authorship contribution statement mohammad aghababaei formal analysis investigation methodology data curation writing original draft timothy r ginn conceptualization formal analysis investigation methodology data curation writing original draft project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank jim mccallum for sharing data and jim mccallum lynn schreyer and kc carroll for helpful comments on this work that was supported part by the national science foundation under project 2142165 and by the usda under grant 2019 33522 30203 we also thank jesús carrera and two other anonymous reviewers and the editor whose works improved this article very much supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2023 104383 appendix b supplementary materials image application 1 appendix a table a1 shows all the variables terms used in this paper their units and their definitions here we derive the solutions of eqs 4 and 5 for unnormalized raw moments μ k k 0 4 while these results are presented in the context of hyporheic exchange they can be readily applied to any mobile immobile domain mass transfer governed by memory functions for k 0 eqs 4 and 5 become respectively a1 l μ 0 β k f μ 0 β 0 k r ω σ 0 ω d ω a2 d σ 0 ω d ω k r ω σ 0 ω where σ0 0 kf μ0 the solution of a2 is a3 σ 0 ω k f μ 0 e k ω where ω 0 ω k r ω d ω then eq a1 becomes a4 l μ 0 β k f μ 0 β k f μ 0 0 d d ω e k ω d ω with our restriction to fully reversible mass exchange processes i e that lim ω 0 ω k r ω d ω then the integral in a4 has value equal to 1 this is the same as that the 0th moment of g kf is unity ginn 2009 and the solution to a4 is a5 μ 0 c o n s t a n t which is consistent with luo et al 2008 eq 14 for k 1 the moments equations become a6 μ 0 l μ 1 β k f μ 1 β 0 k r ω σ 1 ω d ω a7 d σ 1 ω d ω σ 0 ω k r ω σ 1 ω where σ1 0 kf μ1 and boundary condition μ1 0 we again start by developing the solution to the immobile phase moment eq a7 now by integration factor method here we give the details for demonstration the substitution σ1 ω e k ω ρ ω converts a7 to a8 k r ω e k ω ρ ω e k ω d ρ ω d ω σ 0 ω k r ω σ 1 ω in which by substituting σ1 ω and then canceling the same terms from both sides we eventually have a9 d ρ ω σ 0 ω e k ω d ω or integrating and using the construction that ρ 0 σ1 0 kf μ1 a10 ρ ω 0 e k ω σ 0 ω d ω k f μ 1 with σ1 ω is defined as e k ω ρ ω we have ρ ω σ1 ω e k ω so that a11 σ 1 ω e k ω 0 e k ω σ 0 ω d ω k f μ 1 where after substituting σ0 ω using eq a3 the above equation gives eventually a12 σ 1 ω k f e k ω μ 1 μ 0 ω if we substitute eq a12 into eq a7 and rearrange it and define a 0 0 k r ω e k ω d ω 1 and a 1 β k f 0 k r ω ω e k ω d ω 1 we have a13 l μ 1 β k f a 0 μ 1 a 1 μ 0 we can evaluate a0 and a1 as follows with the assumption of fully reversible exchange i e that kr ω 0 a14 a 0 0 k r ω e k ω d ω 1 0 d d ω e k ω d ω 1 e k ω 0 1 0 now eq a14 can be expressed as a15 d 2 μ 1 d x 2 v d d μ 1 d x a 1 d μ 0 which is consistent with luo et al 2008 eq 15 in which a 1 β tot ω0 1 where β tot is the capacity coefficient and ω0 is the 0th temporal moment of memory function luo et al 2008 the homogeneous form of eq a15 is a16 d 2 μ 1 d x 2 v d d μ 1 d x 0 the characteristic equation of eq a16 is λ 2 v d λ 0 which has two solutions for ƛ as λ 1 v d and λ2 0 since the discriminant is positive the general solution μ 1 c 1 e λ 1 x c 2 e λ 2 x for eq a16 is a17 μ 1 c 1 e v d x c 2 now if we define y 1 e v d x y 2 1 and w x y 1 d y 1 d x y 2 d y 2 d x the general solution for eq a15 is of the form a18 μ 1 u 1 y 1 u 2 y 2 where u 1 y 2 r x w x d x and u 2 y 1 r x w x d x and r x is the right hand side rhs of a15 evaluation of w x yields w x e v d x v d e v d x 1 0 0 v d e v d x v d e v d x and calculating u 1 and u 2 gives u 1 a 1 d μ 0 v 2 e v d x μ 0 v c u 2 a 1 μ 0 v x c finally by substituting y 1 y 2 u 1 and u 2 in eq a18 we have the solution as follows a19 μ 1 x a 1 d μ 0 v 2 a 1 μ 0 v x μ 0 v e v d x c c where c and c are unknown constants using the boundary condition μ1 0 c 0 and consequently μ 1 0 a 1 μ 0 d v 2 c so that from eq a19 we obtain a20 μ 1 x a 1 μ 0 v x μ 1 0 for k 2 the moments equations become a21 2 μ 1 l μ 2 β k f μ 2 β 0 k r ω σ 2 ω d ω a22 d σ 2 ω d ω 2 σ 1 ω k r ω σ 2 ω where σ2 0 kf μ2 again we start with a solution to the immobile phase moment equation a23 σ 2 ω k f e k ω μ 2 2 μ 1 ω μ 0 ω 2 if we substitute eq a23 in eq a21 and rearrange it and define a 2 β k f 0 k r ω ω 2 e k ω d ω given a0 0 from a14 we have a24 d 2 μ 2 d x 2 v d d μ 2 d x 2 a 1 μ 1 d a 2 μ 0 d which is consistent with luo et al 2008 eq 16 in which a 1 is same as before and a 2 2β tot ω1 where ω1 is the 1st temporal moment of memory function luo et al 2008 the solution of eq a24 again follows the similar path as in the k 1 case a25 μ 2 x 2 a 1 2 d μ 0 v 3 a 2 μ 0 2 a 1 μ 1 0 v x a 1 2 μ 0 v 2 x 2 μ 2 0 for k 3 the moments equations become a26 3 μ 2 l μ 3 β k f μ 3 β 0 k r ω σ 3 ω d ω a27 d σ 3 ω d ω 3 σ 2 ω k r ω σ 3 ω where σ3 0 kf μ3 we start with a solution to the immobile phase moment equation as before and get the following solution for eq a27 a28 σ 3 ω k f e k ω μ 3 3 μ 2 ω 3 μ 1 ω 2 μ 0 ω 3 if we substitute eq a28 in eq a26 and rearrange it and define a 3 β k f 0 k r ω ω 3 e k ω d ω given a0 0 we have now a29 d 2 μ 3 d x 2 v d d μ 3 d x 3 a 1 μ 2 d 3 a 2 μ 1 d a 3 μ 0 d the solution for eq a29 is obtained following the same path as in k 1 case a30 μ 3 x 6 a 2 a 1 d μ 0 a 1 2 d μ 1 0 v 3 12 a 1 3 d 2 μ 0 v 5 a 3 μ 0 3 a 1 μ 2 0 3 a 2 μ 1 0 v x 6 a 1 3 d μ 0 v 4 3 a 1 a 2 μ 0 a 1 μ 1 0 v 2 x 2 a 1 3 μ 0 v 3 x 3 μ 3 0 for k 4 the moments equations become a31 4 μ 3 l μ 4 β k f μ 4 β 0 k r ω σ 4 ω d ω a32 d σ 4 ω d ω 4 σ 3 ω k r ω σ 4 ω where σ4 0 kf μ4 we start with a solution to the immobile phase moment eq a32 as before and get the following solution for eq a31 a33 σ 4 ω k f e k ω μ 4 4 μ 3 ω 6 μ 2 ω 2 4 μ 1 ω 3 μ 0 ω 4 if we substitute eq a33 in eq a31 and rearrange it and define a 4 β k f 0 k r ω ω 4 e k ω d ω given a 0 0 we have now a34 d 2 μ 4 d x 2 v d d μ 4 d x 4 a 1 μ 3 d 6 a 2 μ 2 d 4 a 3 μ 1 d a 4 μ 0 d the solution for eq a34 is obtained following the same path as in k 1 case a35 μ 4 x a 4 μ 0 4 a 1 μ 3 0 6 a 2 μ 2 0 4 a 3 μ 1 0 v 8 a 1 a 3 d μ 0 6 a 2 2 d μ 0 24 a 1 a 2 d μ 1 0 12 a 1 2 d μ 2 0 v 3 72 a 1 2 a 2 d 2 μ 0 48 a 1 3 d 2 μ 1 0 v 5 120 a 1 4 d 3 μ 0 v 7 x 3 a 2 2 4 a 1 a 3 μ 0 12 a 1 a 2 μ 1 0 6 a 1 2 μ 2 0 v 2 36 a 1 2 a 2 d μ 0 24 a 1 3 d μ 1 0 v 4 60 a 1 4 d 2 μ 0 v 6 x 2 6 a 1 2 a 2 μ 0 4 a 1 3 μ 1 0 v 3 12 a 1 4 d μ 0 v 5 x 3 a 1 4 μ 0 v 4 x 4 μ 4 0 to summarize we tabulate these results as follows tables a2 and a3 show the moments governing equations for immobile solute concentration and their solutions respectively tables a4 and a5 show the moments governing equations for mobile solute concentration and their solutions respectively tables a6 shows normalized absolute moments of order 1 2 3 and 4 for mobile solute concentration 
64,computed tomography ct images of sandstone contain rich reservoir information analyzing digital rock images is important for geological research and the flow in the subsurface this paper presents a workflow for assessing digital rock petrophysical properties based on machine learning techniques including 1 automatic segmentation of sandstone rock images using u net networks 2 permeability prediction using machine learning and 3 flow simulation by deep learning first using the u net network the rock images are binary segmented into matrix and pore and multisegmented into the matrix pore and mineral the accuracy and intersection over union iou are used to evaluate the performance of image segmentation the accuracy and iou of binary segmentation results are 99 87 and 0 9986 and the results for multi segmentation are 96 77 and 0 7281 respectively then the key features of ct images influencing sandstone permeability are extracted and the analysis of image features reveals that the hydraulic radius is the most important parameter for permeability prediction after that the sandstone permeability is predicted by long short term memory lstm and random forest rf and then compared with the permeability calculated by the lattice boltzmann lbm method the mean square error mse mean absolute error mae and root mean square error rmse are used to quantitatively evaluate the error of permeability prediction the studies show that the precision of rf in permeability prediction is higher than that of lstm and when all the feature parameters are used as input the accuracy of permeability prediction is a little higher than that when only the hydraulic radius is used as input finally this paper refines a new u net model to predict the flow velocity field from ct images and this new u net model can reduce the computation time by 98 59 compared with the lbm method this study will be significant for applying deep learning in simulate the flow in digital rock keywords digital rock image segmentation permeability flow in porous media deep learning u net data availability the data used in this study has been upload in in the mendeley data with a link 1 introduction digital rock is an important technology to characterize the distribution of pores and minerals and the flow in porous media andrä et al 2013 with the development of unconventional reservoirs the pores of formation rock at the nanoscale and mineral types become more diverse wang et al 2021c the high resolution ct scanning equipment such as nano x ray ct and fib sem brings massive image data processing and analyzing these images reconstructing the multiscale digital rock and modeling the flow behavior in the tight porous media are challenging artificial intelligence such as deep learning has been successfully applied in image processing and recognition which will bring a new way for digital rock reconstruction and modeling the flow in porous media zhao et al 2021 wang and zhao 2022 image segmentation is the basis of digital rock physical analysis however these methods such as the thresholding technique watershed method and edge detection technique are vulnerable to human factors in recent years deep learning has been applied to digital rock image processing because of its accuracy and rapidity without human bias ar rushood et al 2020 segmented sandstone ct images into pore and matrix using u net alqahtani et al 2018 segmented three different types of ct scanning images of sandstones using convolutional neural networks and predicted the porosity coordination number and average pore size based on the segmented images niu et al 2020 constructed lenet5 to segment sandstone ct and sem images the petrophysical parameters such as absolute permeability porosity and pore distribution obtained from segmented images and labels were similar proving the accuracy of lenet5 segmentation wang et al 2021a introduced a hybrid network of u net and resnet to segment μct rock images with an accuracy of over 99 and the hybrid network outperformed u net and resnet variants karimpouli and tahmasebi 2019 segmented berea sandstone ct images using the segnet model for porosity organic matter quartz feldspar and other minerals the results show that the deeper network has a higher accuracy fazekas et al 2017 used fully convolutional networks fcns to identify the artifacts of seafloor sediment cores with low mean iou but with the most accurate predictions varfolomeev et al 2019 utilized three convolutional neural network cnn models 2d u net 3d u net and 2d segnet to segment ct images of various rocks with an accuracy of over 89 kazak et al 2021 segmented fib sem images of tight reservoir rock from berezov formation by cnns the models used for image segmentation above are typical semantic segmentation structures permeability prediction and flow simulation are meaningful for oilfield exploration but the commonly used methods such as the lbm zheng et al 2018 pore network model rabbani et al 2020a capillary bundle model wang and zhao 2019 and continuum model qiao et al 2018 are either overly simplified and cannot reflect the real flow accurately or have high computation time and resources deep learning can learn the connection between the rock image and flow field and while it may cost some time during the training process the well trained deep learning model can make a fast prediction with high accuracy instead of predicting permeability from rock physical parameters such as logging parameters obtained from drilling helle et al 2001 tahmasebi and hezarkhani 2012 ali ahmadi et al 2013 bagheripour 2014 zhong et al 2019 urang et al 2020 this paper predicts rock permeability from rock images one method is to train neural networks on core images directly to predict rock permeability graczyk and matyka 2020 predicted permeability porosity and tortuosity from rock images with cnn chung et al 2020 integrated cnn and finite volume models to predict digital rock permeability with an average error of 13 8 alqahtani et al 2021 applied a resnet 152 to estimate permeability based on sandstone conductivity maps and the conductivity maps rather than binary segmentation images were used as input wu et al 2018 utilized a cnn with physical parameters porosity and specific surface area to rapidly predict permeability based on rock images and showed a great performance with a less than 10 error for most samples and considerably reduced computation time tian et al 2020 studied the influence of cnn architecture and training epochs on rock permeability prediction with the average validating loss of the best model of 1 2 10 3 and comparison between architectures indicated that the increase of cnn complexity could not guarantee performance improvement and a better arrangement of convolutional and pooling layers could improve prediction performance hong and liu 2020 developed 3d cnn models to predict sandstone permeability in three directions and this model demonstrated good generalizability rabbani et al 2020b applied cnn with pore network models to estimate porous material characteristics from ct images and the relative error of absolute permeability was approximately 13 sudakov et al 2019 predicted berea sandstone permeability from ct scanning images with various methods the results showed that the 3d cnn model is superior both in terms of the percent error and error distribution the other method is to predict the permeability indirectly based on the features extracted from the rock images rabbani and babaei 2019 proposed the pnm lbm approach to predict permeability by extracting rock image features there are few studies on flow field prediction based on deep learning wang et al 2020 2021b acquired an accurate estimation of steady state velocity fields and permeability by cnns ribeiro et al 2020 developed the deepcfd model to simulate velocity and pressure fields which were up to 3 orders of magnitude faster than the standard cfd approach with low error rates thompson et al 2017 studied the euler equation for incompressible fluids in two and three dimensional regions by convolutional neural networks and obtained a stable velocity field raissi et al 2020 used a physics informed deep neural network to study the navier stokes equations and visualized the velocity and pressure fields santos et al 2020 simulated the flow of single phase fluid in digital rocks by a three dimensional convolutional neural network the u net network used in this paper combines the feature information and the spatial information using a skip connection and shows better performance in image segmentation varfolomeev et al 2019 meanwhile the u net network has few weight parameters to be adjusted during training which can lead to less training time to the best of the authors knowledge the prediction of the flow field in digital rock using the u net network has not been reported in the literature overall the purpose of introducing artificial intelligence technology is to calculate the physical properties of rocks in another way avoiding human bias and high computational time and resources the highlight of this paper is extending the u net network from semantic segmentation to the regression problem and the performance of current flow field prediction by a deep neural network leaves much to be desired but satisfactory results are obtained through the flexible application of u net networks in this paper 2 u net architecture a u net neural network was first proposed by olaf ronneberger phillip fischer and thomas brox in 2015 ronneberger et al 2015 the u net network as the name suggests is a u shaped architecture that includes a contracting path and an expansive path refer to fig 1 the contracting path and expansive path are also called the encoder and decoder respectively the encoder consists of two repeated convolutions with a kernel size of 3 3 and a stride of 1 and each convolution is followed by a rectified linear unit relu then 2 2 max polling reduces the spatial dimensions replacing fully connected layers with convolution layers reduces many weight parameters of neural networks and improves the running speed the decoder differs from the encoder in adding a 2 2 transpose convolution with a stride of 2 before each block the skip connection concatenates the corresponding feature map from the encoder to combine the feature information and the spatial information which can solve the problem with gradient disappearance and accelerate the training speed finally the 1 1 convolution predicts the probabilities of class and classes per pixel with a softmax function 1 y j e z j t 1 k e z t where zj is the input j denotes the category index k denotes the number of inputs the output yi is the probability that the elements of the index j will occur the output value of the softmax function is between 0 and 1 with a summation of 1 and the classifier outputs the value with a maximum probability in practice each input is subtracted from the maximum to prevent an overflow of values which can be seen as follows 2 y j e z j max z t 1 k e z t max z for multiclass classification softmax is usually used as the output layer of the neural network while in binary classification the output layer always uses a sigmoid activation function the sigmoid function is calculated as follows 3 s i g m o i d x 1 1 exp x in essence training neural networks adjusts the weight parameters which is the basis of neural network learning the most commonly used backpropagation algorithm is the gradient descent method to update the weight parameters briefly the key to the gradient descent algorithm is the derivative of the loss function to weights and the derivative value determines how to modify weight parameters in this paper the cross entropy loss function is used with the formula as follows 4 c 1 n x y ln a 1 y ln 1 a where a σ z z wj xj b c is the value of the loss function x denotes the sample a is the actual output of the neuron y is the expected output n denotes the total number of samples the loss function derived for w and b is as follows 5 c w j 1 n x x j σ z y 6 c b 1 n x σ z y after adjusting the weight parameters according to the derivative values the updated neural network obtains the new loss function values by forward propagation and the updating process is expressed by the equation as follows 7 θ i θ i 1 η f θ i 1 where θ is the independent variable such as weights w and b f θ i 1 denotes the corresponding derivative values such as c w j and c b η is the learning rate and the learning rate controls the size of the adjustment of weight parameters at each step a learning rate that is too high results in a loss function failure to converge while a learning rate that is too low results in a slow training rate the above backpropagation process continuously corrects the weights of the neural network which is the process of neural network training and learning 3 ct image preprocessing in this experiment a carl zeiss 3d stereo x ray ct scanner is used to take a 2 5 mm diameter cylindrical rock sample with a pixel resolution of 2 512 μm a digital rock with a size of 600 600 600 voxels is selected from the scanned image for pore matrix and mineral analysis fig 2 a shows the 3d display of the cut out target digital rock the pore space is segmented manually from the matrix in the ct images with the thresholding method and the 3d display of pore space is shown in fig 2 b fig 2 c shows the 3d pore network model extracted from the 3d pore space the red ball represents the pores and the grey stick indicates the throats the results of the pore structure s quantitative analysis are shown in table 1 the average throat radius is 3 94 μm and the average pore radius is 6 38 μm and the pore radius distribution of the rocks is at the micron level besides the average coordination number is only 2 01 which indicates the connectivity of this sandstone is poor due to the scanning equipment and the rock properties there is random noise in the rock scan images as these image noises might lead to false isolate pores they should be removed before image analysis median filter mehrgardt 1992 unsharp masking filter barry and cooper 1992 and nonlocal means filer buades et al 2005 are compared for the denoising effect as shown in fig 3 the performance of the nonlocal means denoising gives the best results of image denoising in contrast to other filters the nonlocal means denoising method averages similar regions based on the whole image which results in a high resolution and no loss of details therefore the ct images denoised with the nonlocal means filter will be used for the subsequent analysis 4 image segmentation with u net network the computer used in this study is a t7920 tower graphics workstation configured with an intel i9 processor 64 gb of ram nvidia geforce rtx 2080ti and the windows 10 64 bit system we use python to implement the model as python has a large number of open source frameworks and libraries of machine learning the u net model is built based on the keras framework in this paper the pixel size of the input image is adjusted to 256 256 the number of filters in each convolution layer in the encoder is 16 32 64 128 and 256 respectively and the size of the convolutional kernel is 3 3 and the relu function is used as the activation function the size of the convolutional kernel in the maximum pooling layer is 2 2 the number of filters in each convolution layer in the decoder is 128 64 32 and 16 respectively and the size of the convolutional kernel is 2 2 the output layer is the convolution operation with 1 filter the size of the convolutional kernel is 1 1 and the sigmoid function is used as the activation function during the model training the batch size is 20 and the epoch is set to 150 normalization is then used to ensure that all images are distributed similarly making it easier to converge unlike the traditional gradient descent methods which have a constant learning rate for all heavy parameter updates the adam optimizer combines the advantages of the adaptive gradient algorithm adagrad and the root mean square propagation rmsprop the adagrad can improve the performance on sparse problems and the rmsprop performs well on nonsmooth problems such as noise the adam optimizer has advantages such as high computational efficiency small memory requirements a few hyperparameters to be adjusted and applicability to sparse gradient problems the segmentation results can be evaluated by the accuracy the dice slack and the intersection ratio iou and these mathematical formulas are as follows 8 a c c u r a c y t p t n t p t n f p f n 9 d i c e 2 t p 2 t p f p f n 10 i o u t p t p f p f n the iou and dice coefficients are related as follows 11 i o u d i c e 2 d i c e where tp denotes the positive class determined as the positive class fp denotes the negative class determined as the positive class tn denotes the negative class determined as the negative class and fn denotes the positive class determined as the negative class the accuracy represents the proportion of correctly judged pixels to the total pixels and a higher accuracy indicates better segmentation the rock images are manually thresholded into pore fractures and matrices using imagej software with a white color indicating pores or fractures and a black color indicating a matrix the 600 rock images of 600 600 size are divided into training sets and test sets with 500 and 100 images the accuracy of segmentation results of the test set with the u net model is 99 87 with an iou score of 0 9986 as shown in fig 4 next we segment minerals from the rock images in the grayscale map the thresholding grayscale value between the pore and the matrix is 87 for the matrix and the mineral their thresholding grayscale value is 212 600 images with 600 600 pixels are also divided into 500 training sets and 100 test sets the batch size is set to 2 and the epoch is set to 150 an epoch means that all of the data is fed into the neural network for one forward computation and backpropagation process the neural network gradually fits as the number of iterations increases but too many iterations lead to overfitting problems usually instead of feeding all of the data into the neural network at once each training of the neural network is divided into several batches and the size of each batch is called the batch size because the unbalanced samples of each category affect the accuracy of sample prediction the loss function is calculated by multiplying the corresponding sample weights to calculate the final loss value the weight of each class can be calculated by the following formula 12 w i n n n i where n is the total number of pixels n is the number of classes and n i is the number of pixels for each class the weights corresponding to pores matrix and minerals are 5 4 0 4 and 25 8 respectively the accuracy of segmentation results is 96 77 with a mean iou of 0 73 the ious for a pore matrix and mineral prediction are 0 63 0 96 and 0 58 respectively the segmentation results are shown in fig 5 where the blue red and green colors represent pores minerals and matrices respectively 5 permeability prediction with machine learning 5 1 image feature extraction the absolute permeability of rocks is only related to the rock pore structure and not to the fluid properties within the rock the absolute permeability of rocks can be calculated using the open source lbm program in matlab rabbani and babaei 2019 however the lbm algorithm is complex and has a low calculation efficiency with a high computation time while machine learning can solve this problem by extracting the feature data reflecting the pore structure of the rocks a variety of feature parameters of the pores are extracted from the rock image including cross section area wetted perimeter perimeter equivalent diameter solidity hydraulic radius mean distance convex area euler number extent filled area major axis length minor axis length and axes ratio these parameters can be obtained by the regionprops function in matlab table 2 shows the characteristic parameters of the four rock images in fig 6 and the permeability calculated by the lbm analysis of the correlation between the feature parameters extracted from the ct segmented images and the absolute permeability shows that the hydraulic radius has the highest correlation with the permeability as shown in fig 7 a with a correlation coefficient of 0 668 this conclusion can also be verified by the importance ranking of the parameter features as shown in fig 7 b the importance ranking is calculated from linear regression with an l1 regularization which is a linear model with an additional regularization term the calculation is as follows min w 1 2 n s a m p l e s x w y 2 2 α w 1 where α is a constant and w 1 is the norm of the l1 coefficient vector both methods demonstrate that the hydraulic radius parameter is most important in predicting permeability 5 2 results of permeability prediction with machine learning machine learning regression algorithms have been greatly developed over several years and the commonly used machine learning regression algorithms include linear regression groß 2012 support vector machine regression cortes and vapnik 1995 k nearest neighbor regression cover 1968 random forest rf regression ho 1995 and long and short term memory lstm networks hochreiter and schmidhuber 1997 lstm networks are modified recurrent neural networks rnns that introduce cell states to save long term states based on rnns they also add gate structures to control the input and output of information the gate structure is a fully connected layer controlling the amount of information passed through with the sigmoid activation function where the input gate controls how much input information is saved to the cell state the forget gate controls how much information is forgotten from the last cell the output gate controls the amount of information output from the cell state these structures successfully solve the problems with the rnn gradient explosion and gradient disappearance the rf method extracts multiple training samples from the training set randomly and with a return bootstrap sampling thus the training samples that are input to each decision tree are different and there is an intersection between the training samples with a return extraction the prediction results of each decision tree are voted or averaged as the final output the averaging method is applied in this experiment because of the regression problem the rf method is insensitive to outliers noise and overfitting mean square error mse mean absolute error mae and root mean square error rmse are used to evaluate the accuracy of the model prediction suppose the permeability obtained from the ith rock image by the lbm calculation is yi and the permeability predicted by the model is y i 13 m s e 1 m i 1 m y i y i 2 14 m a e 1 m i 1 m y i y i 15 r m s e 1 m i 1 m y i y i 2 mse is the expected value of the square of the difference between the predicted value and the true value a smaller mse indicates that the model s prediction has a higher accuracy rate mae is the average of the absolute errors and rmse is the arithmetic square root of mse similarly the smaller rmse and mae indicate that the model s prediction has a higher accuracy rate the rock image feature parameters are input into the machine learning model the number of samples in the training sets and test sets are 500 and 100 respectively the samples are not mixed to ensure the difference between the samples in the training sets and test sets because of the high similarity of the adjacent samples of the rock ct images in this experiment the lstm network is set to 3 hidden layers and the number of hidden layers is set to 30 20 and 90 the iterations are set to 200 and this proves that after 200 iterations the loss value is flat and unchanged and increasing the number of iterations not only fails to improve the prediction accuracy but also increases the training time the batch size is set to 20 and the adam optimizer is used the prediction results of the lstm network are strong the rmse of the prediction with the input of all feature parameters is 9 82 and the rmse with the input of hydraulic radius is 11 49 as shown in fig 8 the prediction results with all feature parameter inputs are slightly better than those with only the hydraulic radius input the hyperparameters of the rf are set as follows the random state is set to 0 to ensure the same result for each run of the program and to facilitate the adjustment of the parameters the number of decision trees is 100 as too few decision trees are easy to overfit while too many decision trees are easy to underfit and have heavy computation since the input samples and features are not large the maximum number of leaf nodes and depth of the decision trees are not limited and these parameters are used to prevent the model from overfitting the permeability prediction results are shown in fig 9 the rmse mse and mae based on the full feature parameters are 6 07 36 82 and 4 70 respectively while the rmse mse and mae with the input hydraulic radius are 9 65 93 18 and 7 93 respectively the model trained with the full feature parameters predicts slightly better than those with only the hydraulic radius we also input the top three parameters with the most feature importance into the model and the top three feature parameters are hydraulic radius wetted perimeter and mean distance comparing the prediction results of the above two machine learning methods as shown in table 3 the rf model predicts slightly better than the lstm network and the model with all parameters used for training predicts slightly better than the model trained with only the hydraulic radius 6 flow prediction with a deep neural network the semantic segmentation task is a classification problem and each pixel of the images is classified by the u net model however flow velocity field prediction is a regression problem therefore the main idea of modifying the u net network is to remove the softmax activation function in the output layer while retaining the other architecture as shown in fig 10 the modified u net model also consists of an encoder and a decoder both the encoder and decoder are composed of 4 blocks and each block of the encoder contains two convolutional layers with a convolutional kernel size of 3 3 the convolution layer filters numbers for each block which are 16 32 64 128 and 256 to increase the nonlinear capability of the neural network each convolutional layer is followed by the leakyrelu activation function leakyrelu differs from the relu activation function only in the negative inputs leakyrelu has a tiny gradient for input values less than 0 which reduces the silent neurons to prevent overfitting a dropout layer is set between the two convolutional layers which randomly sets the input units to 0 for each update in training and the discard ratios of the dropout layer are set to 0 1 0 1 0 2 and 0 2 a maximum pooling layer with a kernel size of 2 2 follows the convolutional layer the bottleneck consists of two 3 3 convolutional layers each followed by a leakyrelu and the dropout layer with a discard ratio of 0 3 is set between the two convolutional layers the decoder consists of a transpose convolution layer with a kernel size of 2 2 and two 3 3 convolutional layers the leakyrelu activation function and dropout layer setting in the decoder are the same as in the encoder and the discard ratios of the four blocks in the decoder are set to 0 2 0 2 0 1 and 0 1 we concatenate the corresponding feature maps from the encoder at the output layer a 1 1 convolutional layer reduces the number of feature channels and outputs the rock velocity field image with one channel after comparing various optimization algorithms this experiment selects the adam optimizer to update the neural network weight parameters predicting the flow velocity value for each pixel on the image with a deep neural network is essentially a regression problem the mean square error mse is used as the loss function mse is used as the loss function which is sensitive to outliers and it is easy to find the optimal solution by derivation compared with mae the gradient of mse varies with loss with the gradient becoming larger as loss increases the gradient also decreases as loss decreases therefore the prediction results are more accurate using mse as the loss function a total of 600 binary segmented images of size 128 128 and the single phase flow velocity field calculated by the lbm are used as the training sets the data should be preprocessed before inputting it into the modified u net network the grayscale value of the pore is 0 and the matrix is 255 in the input images all of the pixel values of the input image are divided by 255 to convert the values to 0 and 1 and then 0 and 1 are inverted the flow velocity field images are normalized to facilitate the neural network training the neural network learns the data distribution characteristics if each batch of training data has a different distribution then the neural network needs to learn a different distribution every training which leads to loss function oscillation and slow convergence or even non convergence in addition a normalization process will reduce the generalizability of the neural network because the predicted velocity field is the normalized velocity field the prediction results need to be a normalized reduction the l2 norm normalization method is used in this experiment and each element is divided by the l2 norm as follows 16 x x x 2 x i x i 2 from the above equation the l2 norm is the arithmetic square root of the sum of squares of all elements i e the euclidean distance the sum of squares of each element after the l2 norm normalization process is equal to 1 accordingly the normalized recovery multiplies each element by the l2 norm the data is divided into training and test sets with 139 training sets and 13 test sets the number of parameters that can be trained is 1940817 and it is very large therefore it is necessary to use convolution instead of fully connected neural networks for this task the epoch is set to 300 and the batch size is set to 5 the batch size is mainly related to the convergence speed and random gradient noise if the batch size is too small the neural network will not converge in time but too large of a batch size leads to too small of random gradient noise which can avoid falling into local minima and the training loss cannot be reduced the size of the batch is also limited by time and space the gpu cpu memory limitation prevents the batch size from being arbitrarily large while a small batch size will substantially increase the training time the loss and mae of the training process are shown in fig 11 the mae of the prediction results is 0 0015 and the loss value is 3 5 10 6 the prediction results are shown in fig 12 and the model very accurately predicts the velocity field based on the rock binary segmentation image from table 4 replacing lbm with the modified u net reduces almost a hundredfold computation time this work has the potential for future rock flow simulation research 7 conclusions the u net network is applied to digital rock petrophysics research and analysis and satisfactory outcomes are achieved the traditional methods for the segmentation of sandstone ct images face problems including human bias low accuracy and calculation efficiency the lightweight u net network trained by a large number of segmented images performs very accurate segmentation of rock images in experiments binary segmentation of pore matrix and the multi segmentation of pore matrix and mineral for rock images are performed of course it is possible to segment into various classifications such as pore fracture matrix iron rich mineral and noniron bearing mineral using this code depending on the training data although the lbm calculates the permeability of rocks accurately it is complicated to model and requires large computational resources and time indirect prediction of rock permeability uses machine learning by extracting rock image features and the hydraulic radius is the most important parameter for permeability forecasting by analyzing image feature parameters the lstm network and rf methods are used in permeability prediction the results show that rf is slightly better than the lstm network in permeability prediction and the accuracy of permeability prediction with all feature parameters used as input is slightly better than that when only the hydraulic radius is used as input the u net network is creatively modified to predict the flow velocity value of each pixel of the rock images and the model is very accurate in predicting the flow field of rocks with an mae of 0 0015 deep learning has broad application prospects in digital rock because of its small computational resources high computational efficiency and short computation time data availability the digital rock images and data for flow prediction are available in the mendeley data https data mendeley com datasets d7w8p438kw credit authorship contribution statement fuyong wang conceptualization methodology writing review editing yun zai investigation visualization writing original draft declaration of competing interest we declare there is no any actual or potential conflict of interest acknowledgments this work was supported by the national natural science foundation of china no 51874320 
64,computed tomography ct images of sandstone contain rich reservoir information analyzing digital rock images is important for geological research and the flow in the subsurface this paper presents a workflow for assessing digital rock petrophysical properties based on machine learning techniques including 1 automatic segmentation of sandstone rock images using u net networks 2 permeability prediction using machine learning and 3 flow simulation by deep learning first using the u net network the rock images are binary segmented into matrix and pore and multisegmented into the matrix pore and mineral the accuracy and intersection over union iou are used to evaluate the performance of image segmentation the accuracy and iou of binary segmentation results are 99 87 and 0 9986 and the results for multi segmentation are 96 77 and 0 7281 respectively then the key features of ct images influencing sandstone permeability are extracted and the analysis of image features reveals that the hydraulic radius is the most important parameter for permeability prediction after that the sandstone permeability is predicted by long short term memory lstm and random forest rf and then compared with the permeability calculated by the lattice boltzmann lbm method the mean square error mse mean absolute error mae and root mean square error rmse are used to quantitatively evaluate the error of permeability prediction the studies show that the precision of rf in permeability prediction is higher than that of lstm and when all the feature parameters are used as input the accuracy of permeability prediction is a little higher than that when only the hydraulic radius is used as input finally this paper refines a new u net model to predict the flow velocity field from ct images and this new u net model can reduce the computation time by 98 59 compared with the lbm method this study will be significant for applying deep learning in simulate the flow in digital rock keywords digital rock image segmentation permeability flow in porous media deep learning u net data availability the data used in this study has been upload in in the mendeley data with a link 1 introduction digital rock is an important technology to characterize the distribution of pores and minerals and the flow in porous media andrä et al 2013 with the development of unconventional reservoirs the pores of formation rock at the nanoscale and mineral types become more diverse wang et al 2021c the high resolution ct scanning equipment such as nano x ray ct and fib sem brings massive image data processing and analyzing these images reconstructing the multiscale digital rock and modeling the flow behavior in the tight porous media are challenging artificial intelligence such as deep learning has been successfully applied in image processing and recognition which will bring a new way for digital rock reconstruction and modeling the flow in porous media zhao et al 2021 wang and zhao 2022 image segmentation is the basis of digital rock physical analysis however these methods such as the thresholding technique watershed method and edge detection technique are vulnerable to human factors in recent years deep learning has been applied to digital rock image processing because of its accuracy and rapidity without human bias ar rushood et al 2020 segmented sandstone ct images into pore and matrix using u net alqahtani et al 2018 segmented three different types of ct scanning images of sandstones using convolutional neural networks and predicted the porosity coordination number and average pore size based on the segmented images niu et al 2020 constructed lenet5 to segment sandstone ct and sem images the petrophysical parameters such as absolute permeability porosity and pore distribution obtained from segmented images and labels were similar proving the accuracy of lenet5 segmentation wang et al 2021a introduced a hybrid network of u net and resnet to segment μct rock images with an accuracy of over 99 and the hybrid network outperformed u net and resnet variants karimpouli and tahmasebi 2019 segmented berea sandstone ct images using the segnet model for porosity organic matter quartz feldspar and other minerals the results show that the deeper network has a higher accuracy fazekas et al 2017 used fully convolutional networks fcns to identify the artifacts of seafloor sediment cores with low mean iou but with the most accurate predictions varfolomeev et al 2019 utilized three convolutional neural network cnn models 2d u net 3d u net and 2d segnet to segment ct images of various rocks with an accuracy of over 89 kazak et al 2021 segmented fib sem images of tight reservoir rock from berezov formation by cnns the models used for image segmentation above are typical semantic segmentation structures permeability prediction and flow simulation are meaningful for oilfield exploration but the commonly used methods such as the lbm zheng et al 2018 pore network model rabbani et al 2020a capillary bundle model wang and zhao 2019 and continuum model qiao et al 2018 are either overly simplified and cannot reflect the real flow accurately or have high computation time and resources deep learning can learn the connection between the rock image and flow field and while it may cost some time during the training process the well trained deep learning model can make a fast prediction with high accuracy instead of predicting permeability from rock physical parameters such as logging parameters obtained from drilling helle et al 2001 tahmasebi and hezarkhani 2012 ali ahmadi et al 2013 bagheripour 2014 zhong et al 2019 urang et al 2020 this paper predicts rock permeability from rock images one method is to train neural networks on core images directly to predict rock permeability graczyk and matyka 2020 predicted permeability porosity and tortuosity from rock images with cnn chung et al 2020 integrated cnn and finite volume models to predict digital rock permeability with an average error of 13 8 alqahtani et al 2021 applied a resnet 152 to estimate permeability based on sandstone conductivity maps and the conductivity maps rather than binary segmentation images were used as input wu et al 2018 utilized a cnn with physical parameters porosity and specific surface area to rapidly predict permeability based on rock images and showed a great performance with a less than 10 error for most samples and considerably reduced computation time tian et al 2020 studied the influence of cnn architecture and training epochs on rock permeability prediction with the average validating loss of the best model of 1 2 10 3 and comparison between architectures indicated that the increase of cnn complexity could not guarantee performance improvement and a better arrangement of convolutional and pooling layers could improve prediction performance hong and liu 2020 developed 3d cnn models to predict sandstone permeability in three directions and this model demonstrated good generalizability rabbani et al 2020b applied cnn with pore network models to estimate porous material characteristics from ct images and the relative error of absolute permeability was approximately 13 sudakov et al 2019 predicted berea sandstone permeability from ct scanning images with various methods the results showed that the 3d cnn model is superior both in terms of the percent error and error distribution the other method is to predict the permeability indirectly based on the features extracted from the rock images rabbani and babaei 2019 proposed the pnm lbm approach to predict permeability by extracting rock image features there are few studies on flow field prediction based on deep learning wang et al 2020 2021b acquired an accurate estimation of steady state velocity fields and permeability by cnns ribeiro et al 2020 developed the deepcfd model to simulate velocity and pressure fields which were up to 3 orders of magnitude faster than the standard cfd approach with low error rates thompson et al 2017 studied the euler equation for incompressible fluids in two and three dimensional regions by convolutional neural networks and obtained a stable velocity field raissi et al 2020 used a physics informed deep neural network to study the navier stokes equations and visualized the velocity and pressure fields santos et al 2020 simulated the flow of single phase fluid in digital rocks by a three dimensional convolutional neural network the u net network used in this paper combines the feature information and the spatial information using a skip connection and shows better performance in image segmentation varfolomeev et al 2019 meanwhile the u net network has few weight parameters to be adjusted during training which can lead to less training time to the best of the authors knowledge the prediction of the flow field in digital rock using the u net network has not been reported in the literature overall the purpose of introducing artificial intelligence technology is to calculate the physical properties of rocks in another way avoiding human bias and high computational time and resources the highlight of this paper is extending the u net network from semantic segmentation to the regression problem and the performance of current flow field prediction by a deep neural network leaves much to be desired but satisfactory results are obtained through the flexible application of u net networks in this paper 2 u net architecture a u net neural network was first proposed by olaf ronneberger phillip fischer and thomas brox in 2015 ronneberger et al 2015 the u net network as the name suggests is a u shaped architecture that includes a contracting path and an expansive path refer to fig 1 the contracting path and expansive path are also called the encoder and decoder respectively the encoder consists of two repeated convolutions with a kernel size of 3 3 and a stride of 1 and each convolution is followed by a rectified linear unit relu then 2 2 max polling reduces the spatial dimensions replacing fully connected layers with convolution layers reduces many weight parameters of neural networks and improves the running speed the decoder differs from the encoder in adding a 2 2 transpose convolution with a stride of 2 before each block the skip connection concatenates the corresponding feature map from the encoder to combine the feature information and the spatial information which can solve the problem with gradient disappearance and accelerate the training speed finally the 1 1 convolution predicts the probabilities of class and classes per pixel with a softmax function 1 y j e z j t 1 k e z t where zj is the input j denotes the category index k denotes the number of inputs the output yi is the probability that the elements of the index j will occur the output value of the softmax function is between 0 and 1 with a summation of 1 and the classifier outputs the value with a maximum probability in practice each input is subtracted from the maximum to prevent an overflow of values which can be seen as follows 2 y j e z j max z t 1 k e z t max z for multiclass classification softmax is usually used as the output layer of the neural network while in binary classification the output layer always uses a sigmoid activation function the sigmoid function is calculated as follows 3 s i g m o i d x 1 1 exp x in essence training neural networks adjusts the weight parameters which is the basis of neural network learning the most commonly used backpropagation algorithm is the gradient descent method to update the weight parameters briefly the key to the gradient descent algorithm is the derivative of the loss function to weights and the derivative value determines how to modify weight parameters in this paper the cross entropy loss function is used with the formula as follows 4 c 1 n x y ln a 1 y ln 1 a where a σ z z wj xj b c is the value of the loss function x denotes the sample a is the actual output of the neuron y is the expected output n denotes the total number of samples the loss function derived for w and b is as follows 5 c w j 1 n x x j σ z y 6 c b 1 n x σ z y after adjusting the weight parameters according to the derivative values the updated neural network obtains the new loss function values by forward propagation and the updating process is expressed by the equation as follows 7 θ i θ i 1 η f θ i 1 where θ is the independent variable such as weights w and b f θ i 1 denotes the corresponding derivative values such as c w j and c b η is the learning rate and the learning rate controls the size of the adjustment of weight parameters at each step a learning rate that is too high results in a loss function failure to converge while a learning rate that is too low results in a slow training rate the above backpropagation process continuously corrects the weights of the neural network which is the process of neural network training and learning 3 ct image preprocessing in this experiment a carl zeiss 3d stereo x ray ct scanner is used to take a 2 5 mm diameter cylindrical rock sample with a pixel resolution of 2 512 μm a digital rock with a size of 600 600 600 voxels is selected from the scanned image for pore matrix and mineral analysis fig 2 a shows the 3d display of the cut out target digital rock the pore space is segmented manually from the matrix in the ct images with the thresholding method and the 3d display of pore space is shown in fig 2 b fig 2 c shows the 3d pore network model extracted from the 3d pore space the red ball represents the pores and the grey stick indicates the throats the results of the pore structure s quantitative analysis are shown in table 1 the average throat radius is 3 94 μm and the average pore radius is 6 38 μm and the pore radius distribution of the rocks is at the micron level besides the average coordination number is only 2 01 which indicates the connectivity of this sandstone is poor due to the scanning equipment and the rock properties there is random noise in the rock scan images as these image noises might lead to false isolate pores they should be removed before image analysis median filter mehrgardt 1992 unsharp masking filter barry and cooper 1992 and nonlocal means filer buades et al 2005 are compared for the denoising effect as shown in fig 3 the performance of the nonlocal means denoising gives the best results of image denoising in contrast to other filters the nonlocal means denoising method averages similar regions based on the whole image which results in a high resolution and no loss of details therefore the ct images denoised with the nonlocal means filter will be used for the subsequent analysis 4 image segmentation with u net network the computer used in this study is a t7920 tower graphics workstation configured with an intel i9 processor 64 gb of ram nvidia geforce rtx 2080ti and the windows 10 64 bit system we use python to implement the model as python has a large number of open source frameworks and libraries of machine learning the u net model is built based on the keras framework in this paper the pixel size of the input image is adjusted to 256 256 the number of filters in each convolution layer in the encoder is 16 32 64 128 and 256 respectively and the size of the convolutional kernel is 3 3 and the relu function is used as the activation function the size of the convolutional kernel in the maximum pooling layer is 2 2 the number of filters in each convolution layer in the decoder is 128 64 32 and 16 respectively and the size of the convolutional kernel is 2 2 the output layer is the convolution operation with 1 filter the size of the convolutional kernel is 1 1 and the sigmoid function is used as the activation function during the model training the batch size is 20 and the epoch is set to 150 normalization is then used to ensure that all images are distributed similarly making it easier to converge unlike the traditional gradient descent methods which have a constant learning rate for all heavy parameter updates the adam optimizer combines the advantages of the adaptive gradient algorithm adagrad and the root mean square propagation rmsprop the adagrad can improve the performance on sparse problems and the rmsprop performs well on nonsmooth problems such as noise the adam optimizer has advantages such as high computational efficiency small memory requirements a few hyperparameters to be adjusted and applicability to sparse gradient problems the segmentation results can be evaluated by the accuracy the dice slack and the intersection ratio iou and these mathematical formulas are as follows 8 a c c u r a c y t p t n t p t n f p f n 9 d i c e 2 t p 2 t p f p f n 10 i o u t p t p f p f n the iou and dice coefficients are related as follows 11 i o u d i c e 2 d i c e where tp denotes the positive class determined as the positive class fp denotes the negative class determined as the positive class tn denotes the negative class determined as the negative class and fn denotes the positive class determined as the negative class the accuracy represents the proportion of correctly judged pixels to the total pixels and a higher accuracy indicates better segmentation the rock images are manually thresholded into pore fractures and matrices using imagej software with a white color indicating pores or fractures and a black color indicating a matrix the 600 rock images of 600 600 size are divided into training sets and test sets with 500 and 100 images the accuracy of segmentation results of the test set with the u net model is 99 87 with an iou score of 0 9986 as shown in fig 4 next we segment minerals from the rock images in the grayscale map the thresholding grayscale value between the pore and the matrix is 87 for the matrix and the mineral their thresholding grayscale value is 212 600 images with 600 600 pixels are also divided into 500 training sets and 100 test sets the batch size is set to 2 and the epoch is set to 150 an epoch means that all of the data is fed into the neural network for one forward computation and backpropagation process the neural network gradually fits as the number of iterations increases but too many iterations lead to overfitting problems usually instead of feeding all of the data into the neural network at once each training of the neural network is divided into several batches and the size of each batch is called the batch size because the unbalanced samples of each category affect the accuracy of sample prediction the loss function is calculated by multiplying the corresponding sample weights to calculate the final loss value the weight of each class can be calculated by the following formula 12 w i n n n i where n is the total number of pixels n is the number of classes and n i is the number of pixels for each class the weights corresponding to pores matrix and minerals are 5 4 0 4 and 25 8 respectively the accuracy of segmentation results is 96 77 with a mean iou of 0 73 the ious for a pore matrix and mineral prediction are 0 63 0 96 and 0 58 respectively the segmentation results are shown in fig 5 where the blue red and green colors represent pores minerals and matrices respectively 5 permeability prediction with machine learning 5 1 image feature extraction the absolute permeability of rocks is only related to the rock pore structure and not to the fluid properties within the rock the absolute permeability of rocks can be calculated using the open source lbm program in matlab rabbani and babaei 2019 however the lbm algorithm is complex and has a low calculation efficiency with a high computation time while machine learning can solve this problem by extracting the feature data reflecting the pore structure of the rocks a variety of feature parameters of the pores are extracted from the rock image including cross section area wetted perimeter perimeter equivalent diameter solidity hydraulic radius mean distance convex area euler number extent filled area major axis length minor axis length and axes ratio these parameters can be obtained by the regionprops function in matlab table 2 shows the characteristic parameters of the four rock images in fig 6 and the permeability calculated by the lbm analysis of the correlation between the feature parameters extracted from the ct segmented images and the absolute permeability shows that the hydraulic radius has the highest correlation with the permeability as shown in fig 7 a with a correlation coefficient of 0 668 this conclusion can also be verified by the importance ranking of the parameter features as shown in fig 7 b the importance ranking is calculated from linear regression with an l1 regularization which is a linear model with an additional regularization term the calculation is as follows min w 1 2 n s a m p l e s x w y 2 2 α w 1 where α is a constant and w 1 is the norm of the l1 coefficient vector both methods demonstrate that the hydraulic radius parameter is most important in predicting permeability 5 2 results of permeability prediction with machine learning machine learning regression algorithms have been greatly developed over several years and the commonly used machine learning regression algorithms include linear regression groß 2012 support vector machine regression cortes and vapnik 1995 k nearest neighbor regression cover 1968 random forest rf regression ho 1995 and long and short term memory lstm networks hochreiter and schmidhuber 1997 lstm networks are modified recurrent neural networks rnns that introduce cell states to save long term states based on rnns they also add gate structures to control the input and output of information the gate structure is a fully connected layer controlling the amount of information passed through with the sigmoid activation function where the input gate controls how much input information is saved to the cell state the forget gate controls how much information is forgotten from the last cell the output gate controls the amount of information output from the cell state these structures successfully solve the problems with the rnn gradient explosion and gradient disappearance the rf method extracts multiple training samples from the training set randomly and with a return bootstrap sampling thus the training samples that are input to each decision tree are different and there is an intersection between the training samples with a return extraction the prediction results of each decision tree are voted or averaged as the final output the averaging method is applied in this experiment because of the regression problem the rf method is insensitive to outliers noise and overfitting mean square error mse mean absolute error mae and root mean square error rmse are used to evaluate the accuracy of the model prediction suppose the permeability obtained from the ith rock image by the lbm calculation is yi and the permeability predicted by the model is y i 13 m s e 1 m i 1 m y i y i 2 14 m a e 1 m i 1 m y i y i 15 r m s e 1 m i 1 m y i y i 2 mse is the expected value of the square of the difference between the predicted value and the true value a smaller mse indicates that the model s prediction has a higher accuracy rate mae is the average of the absolute errors and rmse is the arithmetic square root of mse similarly the smaller rmse and mae indicate that the model s prediction has a higher accuracy rate the rock image feature parameters are input into the machine learning model the number of samples in the training sets and test sets are 500 and 100 respectively the samples are not mixed to ensure the difference between the samples in the training sets and test sets because of the high similarity of the adjacent samples of the rock ct images in this experiment the lstm network is set to 3 hidden layers and the number of hidden layers is set to 30 20 and 90 the iterations are set to 200 and this proves that after 200 iterations the loss value is flat and unchanged and increasing the number of iterations not only fails to improve the prediction accuracy but also increases the training time the batch size is set to 20 and the adam optimizer is used the prediction results of the lstm network are strong the rmse of the prediction with the input of all feature parameters is 9 82 and the rmse with the input of hydraulic radius is 11 49 as shown in fig 8 the prediction results with all feature parameter inputs are slightly better than those with only the hydraulic radius input the hyperparameters of the rf are set as follows the random state is set to 0 to ensure the same result for each run of the program and to facilitate the adjustment of the parameters the number of decision trees is 100 as too few decision trees are easy to overfit while too many decision trees are easy to underfit and have heavy computation since the input samples and features are not large the maximum number of leaf nodes and depth of the decision trees are not limited and these parameters are used to prevent the model from overfitting the permeability prediction results are shown in fig 9 the rmse mse and mae based on the full feature parameters are 6 07 36 82 and 4 70 respectively while the rmse mse and mae with the input hydraulic radius are 9 65 93 18 and 7 93 respectively the model trained with the full feature parameters predicts slightly better than those with only the hydraulic radius we also input the top three parameters with the most feature importance into the model and the top three feature parameters are hydraulic radius wetted perimeter and mean distance comparing the prediction results of the above two machine learning methods as shown in table 3 the rf model predicts slightly better than the lstm network and the model with all parameters used for training predicts slightly better than the model trained with only the hydraulic radius 6 flow prediction with a deep neural network the semantic segmentation task is a classification problem and each pixel of the images is classified by the u net model however flow velocity field prediction is a regression problem therefore the main idea of modifying the u net network is to remove the softmax activation function in the output layer while retaining the other architecture as shown in fig 10 the modified u net model also consists of an encoder and a decoder both the encoder and decoder are composed of 4 blocks and each block of the encoder contains two convolutional layers with a convolutional kernel size of 3 3 the convolution layer filters numbers for each block which are 16 32 64 128 and 256 to increase the nonlinear capability of the neural network each convolutional layer is followed by the leakyrelu activation function leakyrelu differs from the relu activation function only in the negative inputs leakyrelu has a tiny gradient for input values less than 0 which reduces the silent neurons to prevent overfitting a dropout layer is set between the two convolutional layers which randomly sets the input units to 0 for each update in training and the discard ratios of the dropout layer are set to 0 1 0 1 0 2 and 0 2 a maximum pooling layer with a kernel size of 2 2 follows the convolutional layer the bottleneck consists of two 3 3 convolutional layers each followed by a leakyrelu and the dropout layer with a discard ratio of 0 3 is set between the two convolutional layers the decoder consists of a transpose convolution layer with a kernel size of 2 2 and two 3 3 convolutional layers the leakyrelu activation function and dropout layer setting in the decoder are the same as in the encoder and the discard ratios of the four blocks in the decoder are set to 0 2 0 2 0 1 and 0 1 we concatenate the corresponding feature maps from the encoder at the output layer a 1 1 convolutional layer reduces the number of feature channels and outputs the rock velocity field image with one channel after comparing various optimization algorithms this experiment selects the adam optimizer to update the neural network weight parameters predicting the flow velocity value for each pixel on the image with a deep neural network is essentially a regression problem the mean square error mse is used as the loss function mse is used as the loss function which is sensitive to outliers and it is easy to find the optimal solution by derivation compared with mae the gradient of mse varies with loss with the gradient becoming larger as loss increases the gradient also decreases as loss decreases therefore the prediction results are more accurate using mse as the loss function a total of 600 binary segmented images of size 128 128 and the single phase flow velocity field calculated by the lbm are used as the training sets the data should be preprocessed before inputting it into the modified u net network the grayscale value of the pore is 0 and the matrix is 255 in the input images all of the pixel values of the input image are divided by 255 to convert the values to 0 and 1 and then 0 and 1 are inverted the flow velocity field images are normalized to facilitate the neural network training the neural network learns the data distribution characteristics if each batch of training data has a different distribution then the neural network needs to learn a different distribution every training which leads to loss function oscillation and slow convergence or even non convergence in addition a normalization process will reduce the generalizability of the neural network because the predicted velocity field is the normalized velocity field the prediction results need to be a normalized reduction the l2 norm normalization method is used in this experiment and each element is divided by the l2 norm as follows 16 x x x 2 x i x i 2 from the above equation the l2 norm is the arithmetic square root of the sum of squares of all elements i e the euclidean distance the sum of squares of each element after the l2 norm normalization process is equal to 1 accordingly the normalized recovery multiplies each element by the l2 norm the data is divided into training and test sets with 139 training sets and 13 test sets the number of parameters that can be trained is 1940817 and it is very large therefore it is necessary to use convolution instead of fully connected neural networks for this task the epoch is set to 300 and the batch size is set to 5 the batch size is mainly related to the convergence speed and random gradient noise if the batch size is too small the neural network will not converge in time but too large of a batch size leads to too small of random gradient noise which can avoid falling into local minima and the training loss cannot be reduced the size of the batch is also limited by time and space the gpu cpu memory limitation prevents the batch size from being arbitrarily large while a small batch size will substantially increase the training time the loss and mae of the training process are shown in fig 11 the mae of the prediction results is 0 0015 and the loss value is 3 5 10 6 the prediction results are shown in fig 12 and the model very accurately predicts the velocity field based on the rock binary segmentation image from table 4 replacing lbm with the modified u net reduces almost a hundredfold computation time this work has the potential for future rock flow simulation research 7 conclusions the u net network is applied to digital rock petrophysics research and analysis and satisfactory outcomes are achieved the traditional methods for the segmentation of sandstone ct images face problems including human bias low accuracy and calculation efficiency the lightweight u net network trained by a large number of segmented images performs very accurate segmentation of rock images in experiments binary segmentation of pore matrix and the multi segmentation of pore matrix and mineral for rock images are performed of course it is possible to segment into various classifications such as pore fracture matrix iron rich mineral and noniron bearing mineral using this code depending on the training data although the lbm calculates the permeability of rocks accurately it is complicated to model and requires large computational resources and time indirect prediction of rock permeability uses machine learning by extracting rock image features and the hydraulic radius is the most important parameter for permeability forecasting by analyzing image feature parameters the lstm network and rf methods are used in permeability prediction the results show that rf is slightly better than the lstm network in permeability prediction and the accuracy of permeability prediction with all feature parameters used as input is slightly better than that when only the hydraulic radius is used as input the u net network is creatively modified to predict the flow velocity value of each pixel of the rock images and the model is very accurate in predicting the flow field of rocks with an mae of 0 0015 deep learning has broad application prospects in digital rock because of its small computational resources high computational efficiency and short computation time data availability the digital rock images and data for flow prediction are available in the mendeley data https data mendeley com datasets d7w8p438kw credit authorship contribution statement fuyong wang conceptualization methodology writing review editing yun zai investigation visualization writing original draft declaration of competing interest we declare there is no any actual or potential conflict of interest acknowledgments this work was supported by the national natural science foundation of china no 51874320 
