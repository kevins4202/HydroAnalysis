index,text
4505,the nonlinear relationship between runoff and time is a major challenge in hydrological forecasting it is important to improve the prediction accuracy of models for disaster mitigation thus allowing decision makers to make decisions in advance this paper proposes a method called joint error correction first we cluster the initial prediction errors then the moving average method is used to smooth the classified error series finally we establish a 4d copula function model for errors in different forecasting periods after a sampling test we compared the errors before and after the correction we found the system corrected the initial error of the least squares support vector machines ls svm the overestimation of flood in ls svm model is reduced taking the runoff data from the fu yu hydrological station from 2004 to 2018 as an example the following conclusions were drawn 1 the correction effect of errors after pretreatment is better than that without pretreatment compared with the initial error the nse values of the revised models in four different forecasting periods increased by 8 5 5 and 16 and the decreases in the rmse values were 39 37 12 25 10 38 and 32 6 2 after the initial error was corrected the errors in ωt were correlated with each other and the variables in ω h were independent of each other after preprocessing the initial values the joint error improvement value groups ωt and ω h displayed independent characteristics 3 the revised forecast was unbiased therefore the overestimated actual runoff predicted was corrected to some extent keywords joint correction of errors 4d copula martingale model ls svm runoff prediction 1 introduction flood prediction plays a key role in human activities flood control and disaster reduction the accuracy timeliness and reliability of flood forecasting are prerequisites for the establishment of an effective forecasting system bogner and pappenberger 2011 the deviation between the predicted value and actual value obtained by a hydrological prediction model is the main factor that affects the accuracy of the final result uncertainty is an inherent and important feature of hydrological forecasting zhao et al 2013 however rainfall as an input condition of runoff forecasting models is uncertain due to the influences of temperature monsoons cyclones and other factors in addition the system uncertainty of the prediction model can lead to a decrease in the prediction accuracy the system uncertainty of the prediction model includes the uncertainty of the model state model structure and model parameters in this case model uncertainty is reflected by the difference between the predicted and actual values in other words due to the uncertainty of inputs and the model state structure and parameters prediction error is difficult to eliminate zhang et al 2018 the existence of these uncertainties can seriously affect the prediction accuracy therefore quantitative analyses of hydrological forecasting uncertainty have become the focus of many studies it is of great practical significance to establish and optimize error correction models the simplest deviation correction method involves modifying the calculated results directly according to the flow error franchini et al 2011 for example the autoregressive model ar model uses an n order autoregressive model to simulate the error series si et al 2016 in fact the flow can change abruptly near the peak of a flood the population error sequence is irrelevant simply using the ar model to correct the error is not good in the estimation of prediction uncertainty bogner and pappenberger 2011 compared ar arx and autoregressive models based on wavelet transform their experiments found that the accuracy of the prediction model improved after wavelet analysis quantile mapping is another commonly used bias correction method the method assumes that the error series function is stationary and time invariant however switanek et al 2017 found that the error correction function is not smooth therefore they proposed an sdm method scaled distribution mapping this method preserves the variability of meteorological variables temperature and precipitation predicted by the original climate model in addition researchers often use the kalman filter and subsequent improved models to correct errors pagano et al 2011 although the design concept and structure of kalman filters are scientifically sound the kalman filter method is similar to the ar model due to the limitations of real time information franchini et al 2011 dechant and moradkhani 2012 noted that kalman filter technology provides quantitative descriptions of the uncertainty of hydrological predictions with inappropriate confidence levels for the first time zhao et al 2013 introduced the martingale model in the field of economics into hydrological science and extended this approach a statistical analysis of the bias normality temporal independence and stationarity of the improved value sequence of forecasting errors was performed zhao et al 2011 most researchers have focused on improving prediction model systems to correct prediction errors there have been few error analyses of prediction results error correction is a data assimilation technique used in flood forecasting pagano et al 2011 and it has the same value as the optimization prediction model the intrinsic properties of error sequences composed in different ways can also considerably vary the key points in error correction are to fully utilize relevant information comprehensively assess error data and perform correlation analyses of the data through the appropriate mathematical and statistical methods to identify the corresponding trends in addition the hydrological forecasting period is of great significance for decision makers and policy makers and it is an important component considered when establishing flood control measures in advance unfortunately the uncertainty of flood prediction generally increases with the forecasting period wu et al 2012 one of the issues that needs to be addressed is the narrowing of the bias due to the extension of the forecasting period based on the above problems we propose a new method to correct runoff forecasting errors the core objective of this method is to combine a least square support vector machine with a 4d joint copula distribution to improve the accuracy of runoff prediction first we used the ls svm algorithm to obtain runoff prediction values in four different forecasting periods next we performed systematic clustering and smooth denoising for the initial prediction error sequence then we used the 4d copula function to establish the joint distribution of errors in different forecasting periods finally combined with a randomly sampled feedback forecast we obtained the corrected forecasting error the research results have important theoretical value for improving runoff predictions 2 methods 2 1 runoff prediction based on the ls svm algorithm suykens and vandewalle 1999 first proposed the ls svm model the model is an upgrade of the svm algorithm the ls svm algorithm uses the sum of squared errors as the loss function and transforms the convex quadratic programming problem of the svm algorithm into a problem involving a set of linear equations therefore the ls svm algorithm can be applied to solve nonlinear problems with small sample sets accelerate the model solution speed and improve the run speed of the traditional algorithm a training sample set of measured runoff is defined as xi yi where i 1 n and n is the total number of training samples in this case xi rd and yi r where xi is the input value and yi is the output value the optimal decision function is as follows 1 y f x ω φ x b in eq 1 ω is the weight vector b is the partial vector and φ x is the nonlinear mapping function from the low dimensional space to the high dimensional space the optimization problem of ls svm can be converted to the form shown in eq 2 min j ω e 1 2 ω 2 1 2 γ i 1 n e i 2 2 s t y i ω t φ x i b 1 e i i 1 n in eq 2 ei is the error e is the error vector and e rn 1 γ is the penalty coefficient which represents the penalty weight of the test samples beyond the error e and controls the penalty degree of the error and j ω e is the loss function to obtain ω and e the lagrangian multiplier λ rn 1 is introduced the function is defined as 3 min l ω b e λ j ω e i 1 n λ i y i ω t φ x i b 1 e i the derivatives of ω b e and λ can be obtained as follows 4 l ω 0 ω i 1 n λ i y i φ x i l b 0 i 1 n λ i y i 0 l e i 0 λ i γ e i i 1 2 n l λ i 0 y i ω t φ x i b 1 e i 0 i 1 2 n after the calculation the linear equation is as follows 5 0 y t y ω i γ 1 b λ 0 y in eq 5 λ λ 1 λ 2 λ n t is an n 1 dimensional column vector and y y 1 y 2 y n t ω is a nuclear matrix and ω y i y l k x k x l i is the identity matrix and i 1 1 1 t k is the kernel the following relation exists between the mapping function φ x and the kernel function k x k x l 6 k x k x l φ x k t φ x l in eq 6 xk xi and xj xi the kernel function adopted in this paper is the radial basis function rbf kernel function the fitting function of the ls svm algorithm namely the runoff prediction function is 7 f x i 1 n λ i k x k x l b through autocorrelation analysis the best prediction results are obtained when the 4th order is used for the input sample of the threshold value the runoff prediction values of the four groups in different forecasting periods are shown in fig 1 the initial prediction error is expressed as 8 e f q in eq 8 q is the measured value and f is the predicted value obtained by the ls svm algorithm 2 2 joint error correction based on the copula function 2 2 1 pretreatment of the initial error 2 2 1 1 system clustering analysis due to the dynamic nonlinear relationship between rainfall and runoff river discharge varies greatly in different periods according to the potential characteristics of the data the preprocessing of the initial error data plays a notable role in improving the correction and prediction accuracy in this paper the preprocessing of the initial error consists of two steps system clustering analysis and smooth denoising according to xie 2010 among the eight conventional system clustering methods the intermediate distance method and the center of gravity method are not monotonic the shortest distance and the center of gravity methods are spatially concentrated and they are not sensitive enough for many applications the maximum distance method and the squared dispersion method expand the space and the result is easily distorted only the averaging method is not monotonous and not too concentrated or expansive additionally all the available error information is appropriately considered therefore we adopt the class average method for system clustering a class is defined as g we assume that there are m errors in g the m errors are represented by the column vector xi i 1 2 m dij is the distance between xi and xj dsp represents the distance between class gs and gp the square distance two between classes is defined as the average square distance between error pairs the square distance between gs and gp is 9 d sp 2 1 n s n p x i g s x j g p d ij in this paper we first collate the error sequence the error sequences refer to the four sets of error sets with different prediction periods obtained by the ls svm prediction model then the systematic clustering of these errors is performed by the class averaging method the cophenetic correlation coefficient is used to evaluate the clustering effect the closer the value is to 1 the better the clustering effect is 10 c k 1 n n 1 2 y k y d k d k 1 n n 1 2 y k y 2 k 1 n n 1 2 d k d 2 11 y 2 n n 1 k 1 n n 1 2 y k 12 d 2 n n 1 k 1 n n 1 2 d k where i j is an error pair composed of the ith error and jth error terms the elements in y are the ordered distances between the error pairs 2 1 3 1 n 1 3 2 n n 1 the elements in d are the union distances for the errors of 2 1 3 1 n 1 3 2 n n 1 at the first union the cophenetic correlation coefficient refers to the linear correlation coefficient between y and d the inconsistency coefficient is used to determine the final number of classifications in the process of merging the greater the increase in the inconsistency coefficient the better the effect of the former union for the links obtained by the kth union class the formula for the inconsistency coefficient is as follows 13 y k 4 z k 3 y k 1 y k 2 in the formula z is the system cluster tree matrix y is a matrix of n 1 4 n is the number of observations and the meanings of each column of y are shown in table 1 2 2 1 2 data smoothing to eliminate the influence of random fluctuations in the error curve we use the moving average method to smooth the runoff prediction error sequence after clustering the initial errors the specific calculation formula is as follows where ee 1 ee 2 ee n is the value of the initial error after preprocessing 14 ee 1 e 1 ee 2 e 1 e 2 e 3 3 ee 3 e 1 e 2 e 3 e 4 e 5 5 ee 4 e 2 e 3 e 4 e 5 e 6 5 ee n 2 e n 4 e n 3 e n 2 e n 1 e n 5 ee n 1 e n 2 e n 1 e n 3 ee n e n 2 2 2 error correction theory based on a copula function a copula function has strong applicability and can connect two or more related or unrelated variables in 1959 sklar 1959 proposed the copula theory de michele and salvadoria 2003 were the first to apply the copula function to hydrology in recent years copula functions have been increasingly applied in hydrology nelsen 2006 established the archimedean copula function iacus and torre 2002 not only introduced the characteristics and properties of the t copula function but also pointed out the advantages of the t copula function in practical application in this paper a 4d elliptical joint copula distribution function is established according to the runoff prediction error sequences in four different forecasting periods in the common elliptical copula function the normal copula function cannot describe the tail correlation of the considered variable however the t copula can effectively solve this problem to effectively describe the distribution of errors we establish the 4d normal copula and 4d t copula functions the sklar theorem of the 4d copula distribution is as follows suppose that f e1 e2 e3 e4 is a quaternion joint distribution function with edge distributions f1 e1 f2 e2 f3 e3 and f4 e4 a copula function c u1 u2 u3 u4 exists that satisfies the following equation 15 f e 1 e 2 e 3 e 4 c f 1 e 1 f 2 e 2 f 3 e 3 f 4 e 4 if f1 e1 f2 e2 f3 e3 and f4 e4 are continuous functions c u1 u2 u3 u4 is uniquely determined conversely if f1 e1 f2 e2 f3 e3 and f4 e4 are unary distribution functions and c u1 u2 u3 u4 is a copula function f e1 e2 e3 e4 is a quaternary joint distribution function with edge distributions f1 e1 f2 e2 f3 e3 and f4 e4 2 2 2 1 edge distribution function there are two ways to estimate the probability density distribution of a population from samples the two approaches involve parametric and nonparametric methods parametric methods assume that the population obeys a known distribution and estimate the parameters from the sample set this method requires a prior assumption of the population distribution in general making this assumption is difficult nonparametric methods do not have this problem therefore this paper uses a nonparametric method to estimate the parameters of the edge distribution function kernel density estimation process is a nonparametric method this method is used to estimate the probability density of the edge distributions we assume that e1 e2 e3 and e4 are deviation samples taken from unitary continuous populations the kernel density of the total density function f h x at any point x is estimated to be 16 f h x 1 nh i 1 n k x e i h in eq 16 k is the kernel function and h is the window width to ensure that fh x is reasonable as a density function estimation the kernel function k needs to satisfy the following conditions 17 k x 0 18 k x d x 1 kernel functions can be expressed in many different ways common kernel functions include the uniform triangular epanechnikov quadratic tri weight gaussian and cosine functions the use of different kernel functions often has little effect on kernel density estimates 2 2 2 2 the selection of the copula function in this paper the 4d normal copula function and 4d t copula function are selected for calculations then we select the better joint copula distribution function based on the fit between these two functions the expressions of the 4d normal copula distribution function and probability density function are as follows 19 c e 1 e 2 e 3 e 4 ρ δ p δ 1 e 1 δ 1 e 2 δ 1 e 3 δ 1 e 4 20 c e 1 e 2 e 3 e 4 ρ 4 c e 1 e 2 e 3 e 4 ρ e 1 e 2 e 3 e 4 ρ 1 2 e x p 1 2 ξ ρ 1 i ξ in the formulas ξ δ 1 e 1 δ 1 e 2 δ 1 e 3 δ 1 e 4 ρ is a symmetric positive definite matrix of order 4 with diagonal elements equal to 1 δρ is the distribution function of the quaternion standard normal distribution with coefficient matrix ρ and i is the identity matrix the expressions of the 4d t copula distribution function and probability density function are as follows 21 c e 1 e 2 e 3 e 4 ρ k t ρ k t k 1 e 1 t k 1 e 2 t k 1 e 3 t k 1 e 4 22 c e 1 e 2 e 3 e 4 ρ k ρ 1 2 γ k 4 2 γ k 2 3 γ k 1 2 4 1 1 k ξ ρ 1 ξ k 4 2 i 1 4 1 ξ i 2 k k 1 2 in the formulas ξ t k 1 e 1 t k 1 e 2 t k 1 e 3 t k 1 e 4 ρ is a symmetric positive definite matrix of order 4 with diagonal elements equal to 1 and tρ k represents the distribution function of the standard quaternion t distribution with the correlation matrix ρ and degree of freedom k 2 2 2 3 fitting evaluation of the copula function yue et al 1999 yue 2001 first used a fitting curve based on theoretical and measured values to visually test the fitting effect of a multidimensional distribution beersma and buishand 2004 applied this method in a fitting test of the copula function based on this approach zhang and singh 2006 quantitatively evaluated the magnitude of the fitting error by calculating rmse values for theoretical and measured values genest and rivest proposed a method of copula selection this method calculates theoretical and empirical estimates then the estimates are plotted if the points on the graph fall near the diagonal at 45 the copula function provides a good fit sun et al 2011 the formula for the 4d empirical copula is as follows 23 c n u v 1 n i 1 n i f n e 1 e i u i f n e 2 e i v i f n e 3 e i w i f n e 4 e i z in eq 23 i is an indicative function when f n e 1 e i u i f n e 1 e i u 1 otherwise i f n e 1 e i u 0 we calculated the square euclidean distance between the 4d t copula and empirical copula and between the 4d normal copula and empirical copula the smaller the distance is the better the fitting effect the specific calculation formula is as follows 24 d t 2 i 1 n c n u i v i w i z i c t u i v i w i z i 2 25 d norm 2 i 1 n c n u i v i w i z i c norm u i v i w i z i 2 2 2 2 4 joint correction of errors the properties of the original variables are reflected in the relation function between the intermediate variables and the edge distribution in this case we can perform random sampling with intermediate variables ma and cui 2018 and obtain a combination of multiple groups u1 u2 u3 u4 from a randomly sampled simulation of the established 4d copula function by substituting u1 u2 u3 u4 into the inverse function of the edge distribution function the error simulation values e1 e2 e3 e4 can be obtained then each error simulation value is input as the initial prediction value and the corresponding revised prediction value is obtained 26 f f e in eq 26 f is the initial predicted value obtained by the ls svm algorithm e is the modified value after sampling and f is the revised predicted value 2 3 error statistical analysis based on the martingale model 2 3 1 the establishment of the martingale model after scholes and black 1973 made a breakthrough in stock option pricing analysis a large number of financial economists jarrow et al 1992 merton 1973 cox et al 1980 vasicek 1977 dothan 1978 established a variety of term structure models for interest rates by using the wiener process and martingale model in continuous time analyses martingale model theory can be used to describe the evolution characteristics of prediction uncertainty over time and it is suitable for describing the variation characteristics of prediction error over time in hydrology to analyze the correction effect of errors and compare the prediction accuracy before and after correction we use the martingale model to perform a statistical analysis the hydrological prediction process considering different forecasting periods is shown in fig 2 in this case ft h is the flow value predicted at time h in period t and qh is the measured flow value at time h the formula for the forecasting error is 27 e t h f t h q h where et is the prediction deviation vector the elements of which are the predicted values at different moments in period t and e h is the prediction deviation vector the elements of which are the predicted values of h in other periods 28 e t f t t q t f t t 1 q t 1 f t t s q t s e t t e t t 1 e t t s 29 e h f h s h q h f h s 1 h q h f h h q h e h s h e h s 1 h e h h the error improvement value ωs t of the two adjacent periods can be expressed as es t 30 ω t h e t h e t 1 h f t h q h f t 1 h q h f t h f t 1 h the evolution process of prediction error over time can be described as shown in fig 3 2 3 2 hypothesis testing for improved error values to further determine the statistical properties of the joint distribution of errors in different forecasting periods two hypothesis tests are considered in this paper the first is a hypothesis test of temporal independence the null hypothesis is that the variables in ωt and ω h are independent of each other the spearman correlation coefficient can describe the correlation between two variables if the null hypothesis is not true the value of the correlation coefficient is significantly greater than or less than 0 the p value of the correlation coefficients is compared with a certain probability threshold value if the p value is less than the threshold value the null hypothesis is rejected otherwise the null hypothesis is accepted the second test is an unbiased hypothesis test the null hypothesis is that the statistically expected value of the variable in ωt is zero we calculate the statistical mean of the error improvement sequence group ωt and estimate the 95 confidence interval of this mean if the confidence interval contains 0 the null hypothesis should be accepted otherwise the null hypothesis should be rejected the test method of the martingale model and corresponding data for the statistical hypotheses are shown in table 2 2 4 research concept based on the above research methods the overall research concept of this paper is shown in fig 4 first we enter the 2004 2017 daily runoff data of fu yu hydrological station as the input of the ls svm model and then we get the predicated daily runoff data of 2018 after collecting and rearranging the predicted errors there are two cases found preprocessed data and unprocessed data based on this we build a four dimensional copula joint distribution function taking samples correct the initial forecast value and at last we carry out the statistical analysis of the corrected errors with martingale models 3 case study 3 1 data the data were taken from the fu yu hydrological station a hydrological station in jilin province china we sorted and summarized the daily runoff data collected at 8 o clock over 15 years from 2004 to 2018 the daily runoff data from 2004 to 2017 were used to form the parameter calibration group in the ls svm prediction model based on the determined parameters we obtained daily rolling predictions of runoff in 2018 through autocorrelation analysis we found that the best prediction results were obtained when the input sample pair was established with order 4 as the threshold the runoff results for the fu yu hydrological station from january 8 to december 26 2018 obtained by the ls svm prediction model are shown in fig 5 a 3 2 prediction results of ls svm as shown in fig 5 a before mid april out of flood season the runoff flow remained near the value of 200 m3 s the runoff variation remained limited from the middle of april to the end of the year the fluctuation in runoff considerably varied and the uncertainty of the forecast was significant four sets of initial error sequences can be obtained by calculating the difference between the predicted and measured values the four initial error sequences are denoted as e1 e2 e3 and e4 after these calculations the nse value and rmse value of the prediction results in four different forecasting periods are shown in table 3 fig 5 c shows the changes in the mean value and rmse value in different forecasting periods fig 5 b and table 3 show that the prediction accuracy decreases with the extension of the prediction period and the prediction value becomes increasingly discrete 3 3 joint correction of errors 3 3 1 pretreatment of the initial error 3 3 1 1 system clustering analysis the clustering tree diagram of initial error sequences in different predicted periods is shown in fig 6 all the inverted u shaped lines in the figure connect cluster objects the height of the line is the union distance there are 353 elements in each prediction period the prediction result of ls svm is a rolling prediction value of 353 days from january 8 to december 26 to avoid confusion among tree graphs caused by the consideration of large quantities of data the 353 classified elements were merged into the leaves of 15 tree graphs in this paper and each leaf node contained one or more error elements after systematic clustering the cophenetic correlation coefficients were 0 8660 0 8187 0 8183 and 0 8196 the value decreases with the extension of the forecasting period but they are above 0 8 thus the clustering effect is relatively good in addition the error sequence can be classified by calculating the increase or decrease in the inconsistency coefficient the specific classification results are shown in table 4 3 3 1 2 data smoothing the second step in preprocessing is to smooth the error sequence after clustering with the moving average method fig 7 shows the new error distribution after the error is pretreated and the mean value of the new error and the rmse value are presented the new errors after pretreatment are expressed by e1 e2 e3 and e4 obviously with 0 as the center e3 has the largest dispersion degree e2 and e4 have the same diffusion degree and e1 is the closest to the 0 axis the absolute value of the error after pretreatment was extracted table 5 shows the specific calculation results for the mean and rmse values 3 3 2 establishment and evaluation of the 4d copula function 3 3 2 1 the establishment of the copula function the first step in establishing the copula function is to determine the edge distribution function fe ei of each variable it is not easy to determine the overall distribution of the error sequence in different forecasting periods therefore the empirical method and the kernel smoothing method were used to evaluate the overall distribution of edge variables the edge distribution function is shown in fig 8 the edge distribution function of the error variable yields values between 0 and 1 the coincidence degree of the empirical distribution function and kernel density estimation function is very high in this paper the kernel smoothing method is used to calculate the value of the edge distribution function the 4d t copula function includes two parameters these two parameters are the linearly dependent parameter ρt and the number of degrees of freedom k the 4d normal copula function has only one parameter this parameter is the linearly dependent parameter ρnorm the specific calculation results of the parameters are shown in tables 6 and 7 by substituting these parameters into eqs 19 20 21 and 22 the probability density function and distribution function of the 4d normal copula and the 4d t copula can be calculated 3 3 2 2 goodness of fit test table 8 shows the rmse and squared euclidean distance values of the calculated 4d t copula function and 4d normal copula function in general the rmse and euclidean distance values of the 4d normal copula joint distribution function are both greater than the values for the 4d t copula joint distribution function the theoretical empirical relationship obtained by the genest and rivest methods is shown in fig 9 the theoretical and empirical discrete points obtained from the initial error are relatively concentrated near the 45 trend line 3 3 3 results of joint error correction the statistical results of the newly forecasted values after joint correction are shown in table 9 compared with the prediction results obtained by the ls svm algorithm after the direct joint correction of the initial error the nse value decreases and the rmse value increases after the initial error is pretreated the subsequent error is jointly modified as a result the nse value increases and the rmse value decreases data are randomly extracted from the established 4d t copula function then the extracted data are substituted into the inverse function of the kernel density distribution function of edge variables thus we can obtain the joint correction in four different forecasting periods the newly predicted values obtained from the combined correction of the pretreated errors are shown in fig 10 3 4 error analysis based on the martingale model 3 4 1 test of unbiasedness table 10 shows the sample mean and 95 confidence interval of the initial error improvement value ω t table 10 shows that the 95 confidence interval of ω t does not contain zero this result indicates that the null hypothesis that the initial error improvement is unbiased should be rejected in general the sample mean of the initial error improvement value group ω t is less than zero which means that the rolling forecast of the ls svm algorithm overestimates the actual runoff the longer the forecasting period is the more obvious the degree of overestimation table 11 shows the sample mean and 95 confidence interval of group ω t for the modified error improvement values table 11 shows the 95 confidence interval of ω t when the initial joint error correction does not contain zero thus without preprocessing the prediction results are still biased after the correction of the copula function directly established by the initial error the mean value of ω t is less than zero which indicates that the revised value is still greater than the actual runoff the degree of overestimation decreases slightly compared with the initial error however the sample mean of the pretreated group ω t is obviously improved additionally the sample mean is close to zero which suggests that the revised estimate is close to the actual runoff value in addition the 95 confidence interval of the pretreated group ω t contains zero in general zero is in the middle of the interval thus the correction result of the initial error is unbiased 3 4 2 test of temporal independence a scatter diagram was created for each pair of initial error improvement values ω h 3 h ω h 2 h ω h 1 h ω h h and the corresponding spearman coefficients were calculated as shown in fig 11 the null hypothesis should be accepted next scatter plots of the initial error improvement values ω t t ω t t 1 ω t t 2 ω t t 3 were drawn and the corresponding spearman correlation coefficients were calculated as shown in fig 12 ω t t ω t t 1 ω t t 2 ω t t 3 displays an obvious correlation the correlation between the improved value groups in two adjacent prediction periods is particularly obvious with the extension of the forecasting interval the relative value decreases therefore the null hypothesis of temporal independence should be rejected the scatter diagram of the improved value group of the initial joint error is shown in fig 13 the scatter diagram of the combined error improvement value group after pretreatment is shown in fig 14 there is an obvious correlation between the error groups of ω t t ω t t 1 ω t t 2 ω t t 3 compared with the original error improvement value the correlation of group ω t with the directly corrected error improvement value is improved after preprocessing the improved value group ω t of the corrected error displays an independent relation with each other the error groups of ω h 3 h ω h 2 h ω h 1 h ω h h still display an obvious independent relation with each other 4 discussion as mentioned above the new error correction method proposed in this paper is effective especially after the initial error pretreatment the key step in the modeling process is to select the copula function that best fits the data favre et al 2004 in the example we find that the fitting effect of the t copula function is the best according to the characteristics of the normal copula and t copula functions the t copula function can describe the tail information of the error more effectively than can the normal copula function shi and lin 2011 the error groups have tail dependent characteristics in different prediction periods the evaluation data in section 3 2 support these views the nse and rmse values before and after modifying the runoff forecasting values are shown in fig 15 the purpose of pretreatment is to eliminate the magnitude effect system clustering classifies the initial values according to the class averaging method this process smooths the input conditions of the initial values and improves the subsequent moving average filtering process this method reduces the magnitude effect to some extent therefore in the subsequent random sampling process the distribution of the magnitude is more uniform than that of the initial values and the correction effect is better notably the magnitude of floods has a considerable impact on the correction results and this relation is worth studying in the future compared with the range of the initial prediction values the range of the nse values after error preprocessing increased by 8 5 5 and 16 and the corresponding rmse value decreases were 39 37 12 25 10 38 and 32 6 after the direct joint correction of the initial error the nse value did not increase but decreased and the rmse value increased specifically the magnitude difference between flood season and nonflood season runoff is not considered when the joint distribution function is established based on the initial values in the process of random sampling the error magnitude ratio may become unbalanced which would lead to a poor correction effect in future research we could consider fixing a certain parameter and conditionally sampling other parameters based on the average surface rainfall si et al 2018 revised the forecasted values of real time floods their results showed that the revised nse value increased from 0 748 to 0 905 and the nse value increased by 15 7 although the correction range of this method is very high it only modifies the forecasted values in one forecasting period and does not consider the correlations among the forecasting errors in different forecasting periods after the joint correction method proposed in this paper corrects the forecasted values in forecasting period 1 the nse value increases to 0 96 this nse value is 5 5 higher than that obtained by the average surface rainfall method the joint correction method proposed in this paper considers the correlation among different forecasting periods this is the biggest difference between the proposed approach and the typical error correction method joint correction refers to the comprehensive correction of errors in different forecasting periods the data show that the forecasted values in each forecasting period have been revised which impact decision making section 3 4 shows that the correction result of the initial error after preprocessing is unbiased therefore to some extent the revised results improve the overestimation of the ls svm prediction results for the actual runoff through tests and comparisons of time series independence the errors for ω t have a strong correlation with each other and the variables associated with ω h are independent of each other this result is consistent with the conclusion drawn by zhao et al 2013 the time period of the data we adopted is longer than that used by zhao et al and the applicability of the data is broader due to the use of the 4d copula function after the initial error is pretreated both ω t and ω h show independent characteristics this result is somewhat different from the conclusion drawn by zhao et al 2013 likely because the pretreatment process reduces the correlation among the initial error groups therefore the relations involving the groups of joint error improvement values is affected in a temporally rolling hydrological forecast improvements to the forecast depend on updating hydrological information such as basin water storage and meteorological forecasts sankarasubramanian et al 2008 koster et al 2010 saavedra valeriano et al 2010 the independence of the variables in ω h suggests that the updated hydrological information is independent in different time periods the variables in ω t reflect the forecasting improvement achieved in the same period which is derived from the hydrological information being updated in the same period therefore there will be a strong correlation 5 conclusions this paper performs joint correction for errors in different forecasting periods in the preprocessing phase we use the class averaging method to cluster the initial errors this process uses the input data in low pass filtering in the second step of preprocessing the moving average method is used to smooth the data pretreatment can reduce the influence of the runoff magnitude on the predicted results to some extent therefore the copula function of preprocessed values is more balanced than that for the initial error values the results support the following conclusions 1 the error correction effect after pretreatment is improved compared with the initial error the increases in the nse values in the four different forecasting periods were 8 5 5 and 16 and the decreases in the rmse values were 39 37 12 25 10 38 and 32 6 2 after correction the correlations among variables in the initial joint error improvement group ω t increased the variables in ω h are independent of each other after the initial error was pretreated the components of the joint error improvement groups ω t and ω h displayed independent characteristics 3 the revised forecast is unbiased to some extent the overestimated runoff predictions of the ls svm algorithm are improved credit authorship contribution statement yan liu conceptualization methodology investigation writing original draft formal analysis yi ji conceptualization methodology investigation writing review editing dong liu software methodology qiang fu conceptualization project administration resources funding acquisition tianxiao li software methodology writing review editing resources renjie hou methodology qinglin li methodology resources song cui writing review editing mo li writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by national key r d program of china 2018yfc0407303 the national science fund for distinguished young scholars 51825901 the national natural science foundation of china 51909033 the youth talents foundation project of neau 18qc28 china postdoctoral science foundation grant 2019m651247 and the heilongjiang provincial science fund for distinguished young scholars yq2020e002 the original series data of annual precipitation used in this paper which is not available to the public under a secrecy agreement was obtained from the hydrological yearbook of jilin province from 2004 to 2018 
4505,the nonlinear relationship between runoff and time is a major challenge in hydrological forecasting it is important to improve the prediction accuracy of models for disaster mitigation thus allowing decision makers to make decisions in advance this paper proposes a method called joint error correction first we cluster the initial prediction errors then the moving average method is used to smooth the classified error series finally we establish a 4d copula function model for errors in different forecasting periods after a sampling test we compared the errors before and after the correction we found the system corrected the initial error of the least squares support vector machines ls svm the overestimation of flood in ls svm model is reduced taking the runoff data from the fu yu hydrological station from 2004 to 2018 as an example the following conclusions were drawn 1 the correction effect of errors after pretreatment is better than that without pretreatment compared with the initial error the nse values of the revised models in four different forecasting periods increased by 8 5 5 and 16 and the decreases in the rmse values were 39 37 12 25 10 38 and 32 6 2 after the initial error was corrected the errors in ωt were correlated with each other and the variables in ω h were independent of each other after preprocessing the initial values the joint error improvement value groups ωt and ω h displayed independent characteristics 3 the revised forecast was unbiased therefore the overestimated actual runoff predicted was corrected to some extent keywords joint correction of errors 4d copula martingale model ls svm runoff prediction 1 introduction flood prediction plays a key role in human activities flood control and disaster reduction the accuracy timeliness and reliability of flood forecasting are prerequisites for the establishment of an effective forecasting system bogner and pappenberger 2011 the deviation between the predicted value and actual value obtained by a hydrological prediction model is the main factor that affects the accuracy of the final result uncertainty is an inherent and important feature of hydrological forecasting zhao et al 2013 however rainfall as an input condition of runoff forecasting models is uncertain due to the influences of temperature monsoons cyclones and other factors in addition the system uncertainty of the prediction model can lead to a decrease in the prediction accuracy the system uncertainty of the prediction model includes the uncertainty of the model state model structure and model parameters in this case model uncertainty is reflected by the difference between the predicted and actual values in other words due to the uncertainty of inputs and the model state structure and parameters prediction error is difficult to eliminate zhang et al 2018 the existence of these uncertainties can seriously affect the prediction accuracy therefore quantitative analyses of hydrological forecasting uncertainty have become the focus of many studies it is of great practical significance to establish and optimize error correction models the simplest deviation correction method involves modifying the calculated results directly according to the flow error franchini et al 2011 for example the autoregressive model ar model uses an n order autoregressive model to simulate the error series si et al 2016 in fact the flow can change abruptly near the peak of a flood the population error sequence is irrelevant simply using the ar model to correct the error is not good in the estimation of prediction uncertainty bogner and pappenberger 2011 compared ar arx and autoregressive models based on wavelet transform their experiments found that the accuracy of the prediction model improved after wavelet analysis quantile mapping is another commonly used bias correction method the method assumes that the error series function is stationary and time invariant however switanek et al 2017 found that the error correction function is not smooth therefore they proposed an sdm method scaled distribution mapping this method preserves the variability of meteorological variables temperature and precipitation predicted by the original climate model in addition researchers often use the kalman filter and subsequent improved models to correct errors pagano et al 2011 although the design concept and structure of kalman filters are scientifically sound the kalman filter method is similar to the ar model due to the limitations of real time information franchini et al 2011 dechant and moradkhani 2012 noted that kalman filter technology provides quantitative descriptions of the uncertainty of hydrological predictions with inappropriate confidence levels for the first time zhao et al 2013 introduced the martingale model in the field of economics into hydrological science and extended this approach a statistical analysis of the bias normality temporal independence and stationarity of the improved value sequence of forecasting errors was performed zhao et al 2011 most researchers have focused on improving prediction model systems to correct prediction errors there have been few error analyses of prediction results error correction is a data assimilation technique used in flood forecasting pagano et al 2011 and it has the same value as the optimization prediction model the intrinsic properties of error sequences composed in different ways can also considerably vary the key points in error correction are to fully utilize relevant information comprehensively assess error data and perform correlation analyses of the data through the appropriate mathematical and statistical methods to identify the corresponding trends in addition the hydrological forecasting period is of great significance for decision makers and policy makers and it is an important component considered when establishing flood control measures in advance unfortunately the uncertainty of flood prediction generally increases with the forecasting period wu et al 2012 one of the issues that needs to be addressed is the narrowing of the bias due to the extension of the forecasting period based on the above problems we propose a new method to correct runoff forecasting errors the core objective of this method is to combine a least square support vector machine with a 4d joint copula distribution to improve the accuracy of runoff prediction first we used the ls svm algorithm to obtain runoff prediction values in four different forecasting periods next we performed systematic clustering and smooth denoising for the initial prediction error sequence then we used the 4d copula function to establish the joint distribution of errors in different forecasting periods finally combined with a randomly sampled feedback forecast we obtained the corrected forecasting error the research results have important theoretical value for improving runoff predictions 2 methods 2 1 runoff prediction based on the ls svm algorithm suykens and vandewalle 1999 first proposed the ls svm model the model is an upgrade of the svm algorithm the ls svm algorithm uses the sum of squared errors as the loss function and transforms the convex quadratic programming problem of the svm algorithm into a problem involving a set of linear equations therefore the ls svm algorithm can be applied to solve nonlinear problems with small sample sets accelerate the model solution speed and improve the run speed of the traditional algorithm a training sample set of measured runoff is defined as xi yi where i 1 n and n is the total number of training samples in this case xi rd and yi r where xi is the input value and yi is the output value the optimal decision function is as follows 1 y f x ω φ x b in eq 1 ω is the weight vector b is the partial vector and φ x is the nonlinear mapping function from the low dimensional space to the high dimensional space the optimization problem of ls svm can be converted to the form shown in eq 2 min j ω e 1 2 ω 2 1 2 γ i 1 n e i 2 2 s t y i ω t φ x i b 1 e i i 1 n in eq 2 ei is the error e is the error vector and e rn 1 γ is the penalty coefficient which represents the penalty weight of the test samples beyond the error e and controls the penalty degree of the error and j ω e is the loss function to obtain ω and e the lagrangian multiplier λ rn 1 is introduced the function is defined as 3 min l ω b e λ j ω e i 1 n λ i y i ω t φ x i b 1 e i the derivatives of ω b e and λ can be obtained as follows 4 l ω 0 ω i 1 n λ i y i φ x i l b 0 i 1 n λ i y i 0 l e i 0 λ i γ e i i 1 2 n l λ i 0 y i ω t φ x i b 1 e i 0 i 1 2 n after the calculation the linear equation is as follows 5 0 y t y ω i γ 1 b λ 0 y in eq 5 λ λ 1 λ 2 λ n t is an n 1 dimensional column vector and y y 1 y 2 y n t ω is a nuclear matrix and ω y i y l k x k x l i is the identity matrix and i 1 1 1 t k is the kernel the following relation exists between the mapping function φ x and the kernel function k x k x l 6 k x k x l φ x k t φ x l in eq 6 xk xi and xj xi the kernel function adopted in this paper is the radial basis function rbf kernel function the fitting function of the ls svm algorithm namely the runoff prediction function is 7 f x i 1 n λ i k x k x l b through autocorrelation analysis the best prediction results are obtained when the 4th order is used for the input sample of the threshold value the runoff prediction values of the four groups in different forecasting periods are shown in fig 1 the initial prediction error is expressed as 8 e f q in eq 8 q is the measured value and f is the predicted value obtained by the ls svm algorithm 2 2 joint error correction based on the copula function 2 2 1 pretreatment of the initial error 2 2 1 1 system clustering analysis due to the dynamic nonlinear relationship between rainfall and runoff river discharge varies greatly in different periods according to the potential characteristics of the data the preprocessing of the initial error data plays a notable role in improving the correction and prediction accuracy in this paper the preprocessing of the initial error consists of two steps system clustering analysis and smooth denoising according to xie 2010 among the eight conventional system clustering methods the intermediate distance method and the center of gravity method are not monotonic the shortest distance and the center of gravity methods are spatially concentrated and they are not sensitive enough for many applications the maximum distance method and the squared dispersion method expand the space and the result is easily distorted only the averaging method is not monotonous and not too concentrated or expansive additionally all the available error information is appropriately considered therefore we adopt the class average method for system clustering a class is defined as g we assume that there are m errors in g the m errors are represented by the column vector xi i 1 2 m dij is the distance between xi and xj dsp represents the distance between class gs and gp the square distance two between classes is defined as the average square distance between error pairs the square distance between gs and gp is 9 d sp 2 1 n s n p x i g s x j g p d ij in this paper we first collate the error sequence the error sequences refer to the four sets of error sets with different prediction periods obtained by the ls svm prediction model then the systematic clustering of these errors is performed by the class averaging method the cophenetic correlation coefficient is used to evaluate the clustering effect the closer the value is to 1 the better the clustering effect is 10 c k 1 n n 1 2 y k y d k d k 1 n n 1 2 y k y 2 k 1 n n 1 2 d k d 2 11 y 2 n n 1 k 1 n n 1 2 y k 12 d 2 n n 1 k 1 n n 1 2 d k where i j is an error pair composed of the ith error and jth error terms the elements in y are the ordered distances between the error pairs 2 1 3 1 n 1 3 2 n n 1 the elements in d are the union distances for the errors of 2 1 3 1 n 1 3 2 n n 1 at the first union the cophenetic correlation coefficient refers to the linear correlation coefficient between y and d the inconsistency coefficient is used to determine the final number of classifications in the process of merging the greater the increase in the inconsistency coefficient the better the effect of the former union for the links obtained by the kth union class the formula for the inconsistency coefficient is as follows 13 y k 4 z k 3 y k 1 y k 2 in the formula z is the system cluster tree matrix y is a matrix of n 1 4 n is the number of observations and the meanings of each column of y are shown in table 1 2 2 1 2 data smoothing to eliminate the influence of random fluctuations in the error curve we use the moving average method to smooth the runoff prediction error sequence after clustering the initial errors the specific calculation formula is as follows where ee 1 ee 2 ee n is the value of the initial error after preprocessing 14 ee 1 e 1 ee 2 e 1 e 2 e 3 3 ee 3 e 1 e 2 e 3 e 4 e 5 5 ee 4 e 2 e 3 e 4 e 5 e 6 5 ee n 2 e n 4 e n 3 e n 2 e n 1 e n 5 ee n 1 e n 2 e n 1 e n 3 ee n e n 2 2 2 error correction theory based on a copula function a copula function has strong applicability and can connect two or more related or unrelated variables in 1959 sklar 1959 proposed the copula theory de michele and salvadoria 2003 were the first to apply the copula function to hydrology in recent years copula functions have been increasingly applied in hydrology nelsen 2006 established the archimedean copula function iacus and torre 2002 not only introduced the characteristics and properties of the t copula function but also pointed out the advantages of the t copula function in practical application in this paper a 4d elliptical joint copula distribution function is established according to the runoff prediction error sequences in four different forecasting periods in the common elliptical copula function the normal copula function cannot describe the tail correlation of the considered variable however the t copula can effectively solve this problem to effectively describe the distribution of errors we establish the 4d normal copula and 4d t copula functions the sklar theorem of the 4d copula distribution is as follows suppose that f e1 e2 e3 e4 is a quaternion joint distribution function with edge distributions f1 e1 f2 e2 f3 e3 and f4 e4 a copula function c u1 u2 u3 u4 exists that satisfies the following equation 15 f e 1 e 2 e 3 e 4 c f 1 e 1 f 2 e 2 f 3 e 3 f 4 e 4 if f1 e1 f2 e2 f3 e3 and f4 e4 are continuous functions c u1 u2 u3 u4 is uniquely determined conversely if f1 e1 f2 e2 f3 e3 and f4 e4 are unary distribution functions and c u1 u2 u3 u4 is a copula function f e1 e2 e3 e4 is a quaternary joint distribution function with edge distributions f1 e1 f2 e2 f3 e3 and f4 e4 2 2 2 1 edge distribution function there are two ways to estimate the probability density distribution of a population from samples the two approaches involve parametric and nonparametric methods parametric methods assume that the population obeys a known distribution and estimate the parameters from the sample set this method requires a prior assumption of the population distribution in general making this assumption is difficult nonparametric methods do not have this problem therefore this paper uses a nonparametric method to estimate the parameters of the edge distribution function kernel density estimation process is a nonparametric method this method is used to estimate the probability density of the edge distributions we assume that e1 e2 e3 and e4 are deviation samples taken from unitary continuous populations the kernel density of the total density function f h x at any point x is estimated to be 16 f h x 1 nh i 1 n k x e i h in eq 16 k is the kernel function and h is the window width to ensure that fh x is reasonable as a density function estimation the kernel function k needs to satisfy the following conditions 17 k x 0 18 k x d x 1 kernel functions can be expressed in many different ways common kernel functions include the uniform triangular epanechnikov quadratic tri weight gaussian and cosine functions the use of different kernel functions often has little effect on kernel density estimates 2 2 2 2 the selection of the copula function in this paper the 4d normal copula function and 4d t copula function are selected for calculations then we select the better joint copula distribution function based on the fit between these two functions the expressions of the 4d normal copula distribution function and probability density function are as follows 19 c e 1 e 2 e 3 e 4 ρ δ p δ 1 e 1 δ 1 e 2 δ 1 e 3 δ 1 e 4 20 c e 1 e 2 e 3 e 4 ρ 4 c e 1 e 2 e 3 e 4 ρ e 1 e 2 e 3 e 4 ρ 1 2 e x p 1 2 ξ ρ 1 i ξ in the formulas ξ δ 1 e 1 δ 1 e 2 δ 1 e 3 δ 1 e 4 ρ is a symmetric positive definite matrix of order 4 with diagonal elements equal to 1 δρ is the distribution function of the quaternion standard normal distribution with coefficient matrix ρ and i is the identity matrix the expressions of the 4d t copula distribution function and probability density function are as follows 21 c e 1 e 2 e 3 e 4 ρ k t ρ k t k 1 e 1 t k 1 e 2 t k 1 e 3 t k 1 e 4 22 c e 1 e 2 e 3 e 4 ρ k ρ 1 2 γ k 4 2 γ k 2 3 γ k 1 2 4 1 1 k ξ ρ 1 ξ k 4 2 i 1 4 1 ξ i 2 k k 1 2 in the formulas ξ t k 1 e 1 t k 1 e 2 t k 1 e 3 t k 1 e 4 ρ is a symmetric positive definite matrix of order 4 with diagonal elements equal to 1 and tρ k represents the distribution function of the standard quaternion t distribution with the correlation matrix ρ and degree of freedom k 2 2 2 3 fitting evaluation of the copula function yue et al 1999 yue 2001 first used a fitting curve based on theoretical and measured values to visually test the fitting effect of a multidimensional distribution beersma and buishand 2004 applied this method in a fitting test of the copula function based on this approach zhang and singh 2006 quantitatively evaluated the magnitude of the fitting error by calculating rmse values for theoretical and measured values genest and rivest proposed a method of copula selection this method calculates theoretical and empirical estimates then the estimates are plotted if the points on the graph fall near the diagonal at 45 the copula function provides a good fit sun et al 2011 the formula for the 4d empirical copula is as follows 23 c n u v 1 n i 1 n i f n e 1 e i u i f n e 2 e i v i f n e 3 e i w i f n e 4 e i z in eq 23 i is an indicative function when f n e 1 e i u i f n e 1 e i u 1 otherwise i f n e 1 e i u 0 we calculated the square euclidean distance between the 4d t copula and empirical copula and between the 4d normal copula and empirical copula the smaller the distance is the better the fitting effect the specific calculation formula is as follows 24 d t 2 i 1 n c n u i v i w i z i c t u i v i w i z i 2 25 d norm 2 i 1 n c n u i v i w i z i c norm u i v i w i z i 2 2 2 2 4 joint correction of errors the properties of the original variables are reflected in the relation function between the intermediate variables and the edge distribution in this case we can perform random sampling with intermediate variables ma and cui 2018 and obtain a combination of multiple groups u1 u2 u3 u4 from a randomly sampled simulation of the established 4d copula function by substituting u1 u2 u3 u4 into the inverse function of the edge distribution function the error simulation values e1 e2 e3 e4 can be obtained then each error simulation value is input as the initial prediction value and the corresponding revised prediction value is obtained 26 f f e in eq 26 f is the initial predicted value obtained by the ls svm algorithm e is the modified value after sampling and f is the revised predicted value 2 3 error statistical analysis based on the martingale model 2 3 1 the establishment of the martingale model after scholes and black 1973 made a breakthrough in stock option pricing analysis a large number of financial economists jarrow et al 1992 merton 1973 cox et al 1980 vasicek 1977 dothan 1978 established a variety of term structure models for interest rates by using the wiener process and martingale model in continuous time analyses martingale model theory can be used to describe the evolution characteristics of prediction uncertainty over time and it is suitable for describing the variation characteristics of prediction error over time in hydrology to analyze the correction effect of errors and compare the prediction accuracy before and after correction we use the martingale model to perform a statistical analysis the hydrological prediction process considering different forecasting periods is shown in fig 2 in this case ft h is the flow value predicted at time h in period t and qh is the measured flow value at time h the formula for the forecasting error is 27 e t h f t h q h where et is the prediction deviation vector the elements of which are the predicted values at different moments in period t and e h is the prediction deviation vector the elements of which are the predicted values of h in other periods 28 e t f t t q t f t t 1 q t 1 f t t s q t s e t t e t t 1 e t t s 29 e h f h s h q h f h s 1 h q h f h h q h e h s h e h s 1 h e h h the error improvement value ωs t of the two adjacent periods can be expressed as es t 30 ω t h e t h e t 1 h f t h q h f t 1 h q h f t h f t 1 h the evolution process of prediction error over time can be described as shown in fig 3 2 3 2 hypothesis testing for improved error values to further determine the statistical properties of the joint distribution of errors in different forecasting periods two hypothesis tests are considered in this paper the first is a hypothesis test of temporal independence the null hypothesis is that the variables in ωt and ω h are independent of each other the spearman correlation coefficient can describe the correlation between two variables if the null hypothesis is not true the value of the correlation coefficient is significantly greater than or less than 0 the p value of the correlation coefficients is compared with a certain probability threshold value if the p value is less than the threshold value the null hypothesis is rejected otherwise the null hypothesis is accepted the second test is an unbiased hypothesis test the null hypothesis is that the statistically expected value of the variable in ωt is zero we calculate the statistical mean of the error improvement sequence group ωt and estimate the 95 confidence interval of this mean if the confidence interval contains 0 the null hypothesis should be accepted otherwise the null hypothesis should be rejected the test method of the martingale model and corresponding data for the statistical hypotheses are shown in table 2 2 4 research concept based on the above research methods the overall research concept of this paper is shown in fig 4 first we enter the 2004 2017 daily runoff data of fu yu hydrological station as the input of the ls svm model and then we get the predicated daily runoff data of 2018 after collecting and rearranging the predicted errors there are two cases found preprocessed data and unprocessed data based on this we build a four dimensional copula joint distribution function taking samples correct the initial forecast value and at last we carry out the statistical analysis of the corrected errors with martingale models 3 case study 3 1 data the data were taken from the fu yu hydrological station a hydrological station in jilin province china we sorted and summarized the daily runoff data collected at 8 o clock over 15 years from 2004 to 2018 the daily runoff data from 2004 to 2017 were used to form the parameter calibration group in the ls svm prediction model based on the determined parameters we obtained daily rolling predictions of runoff in 2018 through autocorrelation analysis we found that the best prediction results were obtained when the input sample pair was established with order 4 as the threshold the runoff results for the fu yu hydrological station from january 8 to december 26 2018 obtained by the ls svm prediction model are shown in fig 5 a 3 2 prediction results of ls svm as shown in fig 5 a before mid april out of flood season the runoff flow remained near the value of 200 m3 s the runoff variation remained limited from the middle of april to the end of the year the fluctuation in runoff considerably varied and the uncertainty of the forecast was significant four sets of initial error sequences can be obtained by calculating the difference between the predicted and measured values the four initial error sequences are denoted as e1 e2 e3 and e4 after these calculations the nse value and rmse value of the prediction results in four different forecasting periods are shown in table 3 fig 5 c shows the changes in the mean value and rmse value in different forecasting periods fig 5 b and table 3 show that the prediction accuracy decreases with the extension of the prediction period and the prediction value becomes increasingly discrete 3 3 joint correction of errors 3 3 1 pretreatment of the initial error 3 3 1 1 system clustering analysis the clustering tree diagram of initial error sequences in different predicted periods is shown in fig 6 all the inverted u shaped lines in the figure connect cluster objects the height of the line is the union distance there are 353 elements in each prediction period the prediction result of ls svm is a rolling prediction value of 353 days from january 8 to december 26 to avoid confusion among tree graphs caused by the consideration of large quantities of data the 353 classified elements were merged into the leaves of 15 tree graphs in this paper and each leaf node contained one or more error elements after systematic clustering the cophenetic correlation coefficients were 0 8660 0 8187 0 8183 and 0 8196 the value decreases with the extension of the forecasting period but they are above 0 8 thus the clustering effect is relatively good in addition the error sequence can be classified by calculating the increase or decrease in the inconsistency coefficient the specific classification results are shown in table 4 3 3 1 2 data smoothing the second step in preprocessing is to smooth the error sequence after clustering with the moving average method fig 7 shows the new error distribution after the error is pretreated and the mean value of the new error and the rmse value are presented the new errors after pretreatment are expressed by e1 e2 e3 and e4 obviously with 0 as the center e3 has the largest dispersion degree e2 and e4 have the same diffusion degree and e1 is the closest to the 0 axis the absolute value of the error after pretreatment was extracted table 5 shows the specific calculation results for the mean and rmse values 3 3 2 establishment and evaluation of the 4d copula function 3 3 2 1 the establishment of the copula function the first step in establishing the copula function is to determine the edge distribution function fe ei of each variable it is not easy to determine the overall distribution of the error sequence in different forecasting periods therefore the empirical method and the kernel smoothing method were used to evaluate the overall distribution of edge variables the edge distribution function is shown in fig 8 the edge distribution function of the error variable yields values between 0 and 1 the coincidence degree of the empirical distribution function and kernel density estimation function is very high in this paper the kernel smoothing method is used to calculate the value of the edge distribution function the 4d t copula function includes two parameters these two parameters are the linearly dependent parameter ρt and the number of degrees of freedom k the 4d normal copula function has only one parameter this parameter is the linearly dependent parameter ρnorm the specific calculation results of the parameters are shown in tables 6 and 7 by substituting these parameters into eqs 19 20 21 and 22 the probability density function and distribution function of the 4d normal copula and the 4d t copula can be calculated 3 3 2 2 goodness of fit test table 8 shows the rmse and squared euclidean distance values of the calculated 4d t copula function and 4d normal copula function in general the rmse and euclidean distance values of the 4d normal copula joint distribution function are both greater than the values for the 4d t copula joint distribution function the theoretical empirical relationship obtained by the genest and rivest methods is shown in fig 9 the theoretical and empirical discrete points obtained from the initial error are relatively concentrated near the 45 trend line 3 3 3 results of joint error correction the statistical results of the newly forecasted values after joint correction are shown in table 9 compared with the prediction results obtained by the ls svm algorithm after the direct joint correction of the initial error the nse value decreases and the rmse value increases after the initial error is pretreated the subsequent error is jointly modified as a result the nse value increases and the rmse value decreases data are randomly extracted from the established 4d t copula function then the extracted data are substituted into the inverse function of the kernel density distribution function of edge variables thus we can obtain the joint correction in four different forecasting periods the newly predicted values obtained from the combined correction of the pretreated errors are shown in fig 10 3 4 error analysis based on the martingale model 3 4 1 test of unbiasedness table 10 shows the sample mean and 95 confidence interval of the initial error improvement value ω t table 10 shows that the 95 confidence interval of ω t does not contain zero this result indicates that the null hypothesis that the initial error improvement is unbiased should be rejected in general the sample mean of the initial error improvement value group ω t is less than zero which means that the rolling forecast of the ls svm algorithm overestimates the actual runoff the longer the forecasting period is the more obvious the degree of overestimation table 11 shows the sample mean and 95 confidence interval of group ω t for the modified error improvement values table 11 shows the 95 confidence interval of ω t when the initial joint error correction does not contain zero thus without preprocessing the prediction results are still biased after the correction of the copula function directly established by the initial error the mean value of ω t is less than zero which indicates that the revised value is still greater than the actual runoff the degree of overestimation decreases slightly compared with the initial error however the sample mean of the pretreated group ω t is obviously improved additionally the sample mean is close to zero which suggests that the revised estimate is close to the actual runoff value in addition the 95 confidence interval of the pretreated group ω t contains zero in general zero is in the middle of the interval thus the correction result of the initial error is unbiased 3 4 2 test of temporal independence a scatter diagram was created for each pair of initial error improvement values ω h 3 h ω h 2 h ω h 1 h ω h h and the corresponding spearman coefficients were calculated as shown in fig 11 the null hypothesis should be accepted next scatter plots of the initial error improvement values ω t t ω t t 1 ω t t 2 ω t t 3 were drawn and the corresponding spearman correlation coefficients were calculated as shown in fig 12 ω t t ω t t 1 ω t t 2 ω t t 3 displays an obvious correlation the correlation between the improved value groups in two adjacent prediction periods is particularly obvious with the extension of the forecasting interval the relative value decreases therefore the null hypothesis of temporal independence should be rejected the scatter diagram of the improved value group of the initial joint error is shown in fig 13 the scatter diagram of the combined error improvement value group after pretreatment is shown in fig 14 there is an obvious correlation between the error groups of ω t t ω t t 1 ω t t 2 ω t t 3 compared with the original error improvement value the correlation of group ω t with the directly corrected error improvement value is improved after preprocessing the improved value group ω t of the corrected error displays an independent relation with each other the error groups of ω h 3 h ω h 2 h ω h 1 h ω h h still display an obvious independent relation with each other 4 discussion as mentioned above the new error correction method proposed in this paper is effective especially after the initial error pretreatment the key step in the modeling process is to select the copula function that best fits the data favre et al 2004 in the example we find that the fitting effect of the t copula function is the best according to the characteristics of the normal copula and t copula functions the t copula function can describe the tail information of the error more effectively than can the normal copula function shi and lin 2011 the error groups have tail dependent characteristics in different prediction periods the evaluation data in section 3 2 support these views the nse and rmse values before and after modifying the runoff forecasting values are shown in fig 15 the purpose of pretreatment is to eliminate the magnitude effect system clustering classifies the initial values according to the class averaging method this process smooths the input conditions of the initial values and improves the subsequent moving average filtering process this method reduces the magnitude effect to some extent therefore in the subsequent random sampling process the distribution of the magnitude is more uniform than that of the initial values and the correction effect is better notably the magnitude of floods has a considerable impact on the correction results and this relation is worth studying in the future compared with the range of the initial prediction values the range of the nse values after error preprocessing increased by 8 5 5 and 16 and the corresponding rmse value decreases were 39 37 12 25 10 38 and 32 6 after the direct joint correction of the initial error the nse value did not increase but decreased and the rmse value increased specifically the magnitude difference between flood season and nonflood season runoff is not considered when the joint distribution function is established based on the initial values in the process of random sampling the error magnitude ratio may become unbalanced which would lead to a poor correction effect in future research we could consider fixing a certain parameter and conditionally sampling other parameters based on the average surface rainfall si et al 2018 revised the forecasted values of real time floods their results showed that the revised nse value increased from 0 748 to 0 905 and the nse value increased by 15 7 although the correction range of this method is very high it only modifies the forecasted values in one forecasting period and does not consider the correlations among the forecasting errors in different forecasting periods after the joint correction method proposed in this paper corrects the forecasted values in forecasting period 1 the nse value increases to 0 96 this nse value is 5 5 higher than that obtained by the average surface rainfall method the joint correction method proposed in this paper considers the correlation among different forecasting periods this is the biggest difference between the proposed approach and the typical error correction method joint correction refers to the comprehensive correction of errors in different forecasting periods the data show that the forecasted values in each forecasting period have been revised which impact decision making section 3 4 shows that the correction result of the initial error after preprocessing is unbiased therefore to some extent the revised results improve the overestimation of the ls svm prediction results for the actual runoff through tests and comparisons of time series independence the errors for ω t have a strong correlation with each other and the variables associated with ω h are independent of each other this result is consistent with the conclusion drawn by zhao et al 2013 the time period of the data we adopted is longer than that used by zhao et al and the applicability of the data is broader due to the use of the 4d copula function after the initial error is pretreated both ω t and ω h show independent characteristics this result is somewhat different from the conclusion drawn by zhao et al 2013 likely because the pretreatment process reduces the correlation among the initial error groups therefore the relations involving the groups of joint error improvement values is affected in a temporally rolling hydrological forecast improvements to the forecast depend on updating hydrological information such as basin water storage and meteorological forecasts sankarasubramanian et al 2008 koster et al 2010 saavedra valeriano et al 2010 the independence of the variables in ω h suggests that the updated hydrological information is independent in different time periods the variables in ω t reflect the forecasting improvement achieved in the same period which is derived from the hydrological information being updated in the same period therefore there will be a strong correlation 5 conclusions this paper performs joint correction for errors in different forecasting periods in the preprocessing phase we use the class averaging method to cluster the initial errors this process uses the input data in low pass filtering in the second step of preprocessing the moving average method is used to smooth the data pretreatment can reduce the influence of the runoff magnitude on the predicted results to some extent therefore the copula function of preprocessed values is more balanced than that for the initial error values the results support the following conclusions 1 the error correction effect after pretreatment is improved compared with the initial error the increases in the nse values in the four different forecasting periods were 8 5 5 and 16 and the decreases in the rmse values were 39 37 12 25 10 38 and 32 6 2 after correction the correlations among variables in the initial joint error improvement group ω t increased the variables in ω h are independent of each other after the initial error was pretreated the components of the joint error improvement groups ω t and ω h displayed independent characteristics 3 the revised forecast is unbiased to some extent the overestimated runoff predictions of the ls svm algorithm are improved credit authorship contribution statement yan liu conceptualization methodology investigation writing original draft formal analysis yi ji conceptualization methodology investigation writing review editing dong liu software methodology qiang fu conceptualization project administration resources funding acquisition tianxiao li software methodology writing review editing resources renjie hou methodology qinglin li methodology resources song cui writing review editing mo li writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by national key r d program of china 2018yfc0407303 the national science fund for distinguished young scholars 51825901 the national natural science foundation of china 51909033 the youth talents foundation project of neau 18qc28 china postdoctoral science foundation grant 2019m651247 and the heilongjiang provincial science fund for distinguished young scholars yq2020e002 the original series data of annual precipitation used in this paper which is not available to the public under a secrecy agreement was obtained from the hydrological yearbook of jilin province from 2004 to 2018 
4506,groundwater drought is a drought phenomenon caused by the decrease in groundwater level or groundwater storage under natural and anthropogenic disturbances e g climate variability change and groundwater abstraction due to the complexity of groundwater flow systems and the difficulty in obtaining direct observational data related to groundwater resources it remains challenging to characterize groundwater drought quantitatively to this end standardized groundwater level index sgi which was modified from the standardized precipitation index spi was used to quantify groundwater drought with the long term groundwater level data 1981 2010 obtained from the climate response network wells across the conterminous united states the best fitting function of groundwater level distributions was lognormal which was selected from various distribution functions based on the anderson darling ad test among 100 wells four monitoring wells located in georgia massachusetts oklahoma and washington were selected as the main research objects the trend of change in groundwater level was divided into two categories the wells in georgia and oklahoma showed an initial decrease followed by an increase while the wells in massachusetts and washington showed a continuous decline groundwater drought varied significantly in different areas due to the complexity of geographical location agricultural irrigation population and other natural environment and human activities start and end time of drought conditions and the severity of drought and flooding at different time scales in the same area also varied therefore it is necessary to describe different groundwater droughts at a reasonable time scale in this paper the difference between sgi and spi at different time scales was so obvious that the cross correlation analysis was used to find the law of lag time the cross correlation coefficients increased with the increasing time scales and the average correlation values between spi and sgi of wells in georgia massachusetts oklahoma and washington were 0 568 0 634 0 667 and 0 496 respectively with the time scale increased the lag time in georgia and oklahoma also increased but the lag time in massachusetts and washington region was almost unchanged and there was almost no lag time in massachusetts region through the study of the hydrogeological conditions such as vadose zone lithology soil and the influence of human activities the hysteresis effect can be analysed which can provide a new alternative to the conventional method and important information for future groundwater resource management keywords sgi spi groundwater drought lag effect 1 introduction as one of the costliest natural hazards drought has a wide spectrum of adverse impacts on natural environments and socio economic activities ranging from the reduction in water supply and crop yield to the loss of riparian vegetation and habitat cook et al 2007 garssen et al 2014 mishra and singh 2010 touma et al 2015 the occurrence of droughts is usually triggered by prolonged periods e g from weeks to years with below normal precipitation which is normally accompanied by above normal temperature and evapotranspiration dai 2011 vicente serrano et al 2015 from a disciplinary perspective droughts can be divided into four categories meteorological hydrological agricultural and socio economic droughts wilhite and glantz 1985 recently groundwater has been one of the most valuable natural resources providing approximately 50 of drinking water and 20 of irrigation water globally zektser and everett 2004 although groundwater withdrawal in the united states only accounted for 21 4 of total water withdrawal in 2010 groundwater provided more than 43 of irrigation water and 98 of water for self supplied domestic uses maupin et al 2014 due to the ever increasing demands for groundwater resources the issue of groundwater depletion has been intensified on a global scale giordano 2009 wada et al 2010 in addition to anthropogenic impacts e g excessive pumping climate variability change also affects groundwater resources allen et al 2004 green et al 2011 taylor et al 2013 particularly through climate induced groundwater drought mishra and singh 2010 in a recent review mishra and singh 2010 argued that groundwater drought should be treated separately as a distinct type according to the drought classification system as groundwater drought can have pronounced impacts on many industrial and domestic sectors as well as on groundwater dependent ecosystems lange et al 2017 in addition unlike other hydrological components groundwater aquifers can act as low pass filters which can significantly modify hydrological signals by removing high frequency noises and retaining low frequency signals eltahir and yeh 1999 istanbulluoglu et al 2012 loon and anne 2015 peters et al 2003 wang et al 2009 therefore groundwater drought may exhibit different temporal characteristics e g higher temporal persistence than other types of droughts eltahir and yeh 1999 peters et al 2005 2003 because groundwater drought is a continuous slow and complex process when people are aware of the occurrence of groundwater drought it has lasted for a long time and caused losses therefore it is necessary to detect identify and forecast groundwater drought it is an effective method to quantify groundwater drought events using groundwater drought index gwi mendicino et al 2008 proposed the use of the groundwater resource index gri to better monitor groundwater resources based on the comprehensive consideration of meteorological hydrological and agricultural information li and rodell 2015 evaluated groundwater drought of pressure wells and semi pressure wells in the central and eastern regions of the northern united states through the gwi thomas et al 2017 used the normalized grace derived groundwater storage deviations which was defined as the grace groundwater drought index ggdi to quantify groundwater storage deficits and applied it to the central plains of california successfully standardized precipitation index spi was recommended over other drought indices by the world meteorological organization for monitoring meteorological droughts hayes et al 2011 although certain limitations existed for the computation of spi lloyd hughes and saunders 2002 mckee et al 1993 mishra and singh 2010 spi based methods have been also successfully applied to investigate other types of droughts such as soil moisture sheffield et al 2009 vidal et al 2010 surface runoff niu et al 2015 shukla and wood 2008 streamflow lópez moreno et al 2009 zhang et al 2015 and spring discharge fiorillo and guadagno 2012 2010 in recent years this method has been also applied to the study of groundwater drought bloomfield and marchant 2013 constructed the standardized groundwater index sgi according to the groundwater level data using the construction method of spi which adopted a non parametric normal score transform method yeh and chang 2019 used the sgi and spi to analyse the region s drought characteristics of the kaoping river basin taiwan which revealed that continuous droughts occurred in the river basin from 2003 to 2005 ai et al 2019 selected different distribution functions to determine the sgi based on groundwater level data and used them to analyse the temporal and spatial evolution of groundwater in the middle and lower reaches of the heihe river the proposed sgi combined with other methods for identifying drought signals has become a substantial step toward an effective regional groundwater resource planning in recent years chu 2018 used data clustering and decomposition analysis eof to identify the underlying signals of sgi following the standardized drought analysis sda at local and regional scales which showed the regional sgi integrated with eof was a useful and direct way for detecting and quantifying groundwater drought seo and lee 2019 calculated the sgi by normalizing an artificial neural network ann that employed grace trmm as well as gldas models to predict groundwater storage changes from 2003 to 2015 across south korea generally speaking as a new drought type groundwater drought index is still in the exploration stage as one of a few attempts to use the sgi technique for delineating groundwater drought we used the 1981 2010 monthly groundwater level data obtained from the climate response network crn located in the conterminous united states and monthly precipitation data for the same yeas retrieved from the national climatic data center the primary goals of this paper were to 1 assess the use of different probability density functions for calculating the sgi over the conterminous us 2 evaluate the change in groundwater storage through 4 specific monitoring wells based on the change in the sgi and 3 determine the pattern of lag time between the sgi and spi the results of this paper can provide additional insights into using the spi based method for characterizing groundwater drought and provide more information for future groundwater resource management in the united states 2 materials and methods 2 1 groundwater level and precipitation data the use of spi based methods for monitoring droughts is constrained by the lack of long term continuous measurements of the hydrometeorological variable under consideration particularly observed groundwater level data li and rodell 2015 lloyd hughes and saunders 2002 mckee et al 1993 mishra and singh 2010 for instance mckee et al 1993 suggested that at least 30 years of monthly precipitation data were needed to calculate spi following the recommendation of mckee et al 1993 long term monthly groundwater level data from 1981 to 2010 were taken from the crn wells operated by the usgs fig 1 data can be accessed at http groundwaterwatch usgs gov net ogwnetwork asp ncd crn crn wells are located in unconfined or near surface confined aquifers and not subject to anthropogenic influences e g pumping and artificial recharge as such fluctuations in the groundwater levels in the crn wells mainly reflect the effect of climate variability on underlying groundwater systems making them ideal for calculating groundwater drought to maximize the number of wells analysed in this study those with less than 5 missing data i e no groundwater level measurements during the period from 1981 to 2010 were selected resulting in a total of 100 wells fig 1 shows that a large portion of the selected wells were located in the northeastern united states e g massachusetts new hampshire and vermont to fill the missing monthly data linear interpolation was employed li and rodell 2015 to calculate the spi monthly precipitation data at each well location were retrieved from the closest meteorological stations generally within a 20 km radius from the national climatic data center http www ncdc noaa gov 2 2 calculation procedures for the spi and sgi mckee et al 1993 first proposed the spi method for characterizing meteorological drought by transforming time series of monthly precipitation data into a standardized normal distribution with a mean of zero and variance of one for the spi compared to other drought indices e g the palmer drought severity index pdsi palmer 1965 the use of spi like indices provides several advantages for delineating droughts guttman 1998 lloyd hughes and saunders 2002 mckee et al 1993 mishra and singh 2010 for example unlike other commonly used drought indices such as the pdsi the spi requires the input of only one variable e g precipitation or depth to groundwater table and is relatively easy to compute the flexibility of the calculation procedures for spi like indices over different time scales also allows for monitoring of both short term and long term droughts for various purposes heim jr 2002 mishra and singh 2010 moreover the use of the threshold level approach peters et al 2003 or the pdsi to identify droughts is dependent on conditions at a specific site guttman 1998 hisdal et al 2000 in contrast the adoption of the standardized normalization procedures for calculating spi like indices makes them suitable not only for comparing droughts in different regions but also for comparing different types of droughts within a consistent framework guttman 1998 lópez moreno et al 2009 mishra and singh 2010 following the procedures of mckee et al 1993 and guttman 1999 the computation of the spi and sgi involves four steps first the time series of the variable of interest e g precipitation and depth to groundwater table in this study is averaged over the time scale of interest e g running series for 1 3 6 12 and 24 months secondly an appropriate probability density function is fitted to the time series of the data for the same time period e g each calendar month during a calendar year after the parameters of the probability density function are determined from the historic records the corresponding cumulative distribution function is then used to calculate the cumulative probability of any observed value of the variable finally the inverse normal cumulative distribution function with a mean of zero and variance of one is applied to convert the cumulative probability of the observed value of the variable to the spi or sgi the spi like the sgi of zero value corresponds to the median precipitation and the spi of a negative value indicates below median precipitation and vice versa the severity of a drought is determined by the departure of a negative spi value from zero for instance mckee et al 1993 categorized spi 2 as extreme drought 2 spi 1 5 as severe drought 1 5 spi 1 0 as moderate drought 1 0 spi 0 as minor drought and spi greater than 0 as no drought in this study according to the calculation of spi sgi values were assigned as follows sgi less than 0 for groundwater drought and sgi 0 for no groundwater drought 2 3 probability density functions selecting an appropriate probability density function to fit the observed data is important for applying the spi or spi like indices method to identify droughts as the value of spi is affected by the use of different probability distributions mishra and singh 2010 summarized some of the commonly used probability distributions for fitting precipitation data in the literature including gamma lognormal and extreme value distributions bloomfield and marchant 2013 tested gamma normal lognormal and extreme value distributions for fitting groundwater level data according to previous studies five probability density functions i e gamma normal lognormal extreme value and weibull distributions were selected in this study to further test the performances of different distributions for fitting the groundwater level data obtained from the crn wells more detailed descriptions of those probability density functions can be found elsewhere in the literature e g guenang and kamga 2014 lloyd hughes and saunders 2002 the maximum likelihood approach embedded in the matlab software package mathworks 2017 was used to obtain the fitted parameters for each distribution to evaluate the performances of different probability distributions for fitting the groundwater level data the anderson darling test was used in this study anderson and darling 1952 the anderson darling test measures how well a probability distribution fits the observed data for a given sample dataset xi x 1 x 2 xn the anderson darling statistic a 2 is defined as 1 a 2 n i 1 n 2 i 1 n ln f x i l n 1 f x n 1 i where n is the number of observations in the sample dataset and f x is the cumulative distribution function a smaller value of a 2 indicates a better fit of the distribution to the data the significance level of the test statistic a 2 can be determined according to the tabulated values derived from theoretical distributions if a 2 is greater than the tabulated values from a specified distribution the null hypothesis that the sample data come from the distribution is rejected at the given significance level 3 results 3 1 fitting functions for the sgi groundwater level is a continuous variable with strong seasonality which is different from precipitation as a cumulative variable jasechko et al 2014 thus the gamma function which is normally used to calculate the spi cannot be directly applied to fit the sgi based on the spi method that is the fitting function of the sgi should be optimized therefore selecting an appropriate fitting function is essential for calculating the sgi which can have a noticeable impact on the computed values of sgis ai et al 2019 given the geographical locations of wells from different climate regimes four wells located in georgia massachusetts oklahoma and washington were used as examples here for demonstrating the selection of fitting functions in addition the cumulative distribution functions cdfs of depth to groundwater table at the 1 month and 6 month time scales were calculated by five different fitting functions as shown in figs 2 and 3 respectively some errors existed in the selected fitting functions for fitting the observed data at different time scales as seen in fig 2 and 3 specifically the shorter the time scale the smaller error of each fitting function to find the best fitting function the anderson darling ad test was used to evaluate the performances of different cdfs the passing rates of the ad criterion for the five selected fitting functions are shown in fig 4 based on the monthly groundwater level data of 100 observation wells in the united states from 1981 to 2010 the best fitting distribution function varied in different regions ai et al 2019 pointed out that the beta distribution function was the best fitting function within the heihe river basin china the four distributions normal lognormal gamma and extreme value were explored to fit the distribution of groundwater levels best at different sites in the uk as discussed by bloomfield and marchant 2013 the results found that the best fitting distribution varied among different sites and calendar months however in our study it can be seen from fig 4 that the lognormal function was the best fitting function with approximately 40 of the annual passing rate at all time scales among 100 wells moreover the passing rate of the lognormal function increased as the time scale increased from 29 at a 1 month time scale to 49 at a 24 month time scale thus the lognormal function was selected to calculate the sgi based on the monthly groundwater level data for example fig 5 shows the histograms of observed groundwater levels and the corresponding sgi with the lognormal distribution at different time scales for the well in washington the sign and magnitude of their skewness and kurtosis were roughly consistent in the form of their distributions except for slight differences among their frequencies 3 2 different time scale evolutions of the sgi the change in the sgi can be used to depict variations in groundwater storage fig 6 shows the curve of the change in the sgi at five different time scales for each of the four study wells different time scales reflect different types of droughts the sgi 1 reflects the monthly variation in drought characteristics which involves very rapid and sensitive changes but the error is notable when analysing a long term trend the sgi 3 reflects the characteristics of seasonal drought and flood which is usually closely related to agricultural groundwater drought the sgi 6 sgi 12 and sgi 24 reflect the characteristics of drought change at a long time scale which can reflect the characteristics of groundwater drought change from the perspective of time scales the fluctuation in the sgi was very violent at the 1 month time scale sgi 1 and there was almost no obvious trend in the change in georgia massachusetts oklahoma and washington as shown in fig 6 however with the increase of time scale especially in the sgi 24 a distinct trend was emerging fluctuation rise with a linear slope of 0 0545 in the sgi 24 in georgia showed that groundwater has become slightly moist in recent years fluctuation drop with a linear slope of 0 0606 and 0 0636 in the sgi 24 in massachusetts and washington showed that groundwater would become increasing drought while an initial drop followed by an increase with an average linear slope of 0 0412 in oklahoma indicated that the groundwater presented a trend of initial drought and followed by wet conditions on the whole the trend of change in the sgi seemed to be more obvious as the time scale length increased the starting and ending time of drought and the severity of drought and flood at different time scales in the same region were also distinct according to the analysis shown in fig 6 for example regarding groundwater drought in oklahoma in 2007 as shown in fig 6 c the sgi 1 occurred over 6 months from june to november with an average drought intensity of 1 80 and a maximum drought intensity of 3 22 in july of 2007 while the sgi 3 occurred over 6 months from july to december with an average drought intensity of 1 80 and a maximum drought intensity of 2 95 in september of 2007 the sgi 6 occurred for 8 months from july to february of the next year with an average drought intensity of 1 26 and a maximum drought intensity in november of 2007 reaching 2 11 the sgi 12 occurred for 10 months from september to june of the next year with an average drought intensity of 0 66 and a maximum drought intensity in january of 2008 reaching 0 90 the sgi 24 did not indicate drought among the sgi 1 sgi 3 sgi 6 and sgi 12 with the increase of time scale the duration of drought gradually increased but the average and maximum drought intensity decreased however the drought periods were essentially the same and appeared in september october and november in 2007 3 3 seasonal evolutions of the sgi fig 7 shows the curve of the seasonal change in the sgi for each of the four study wells the 5th 8th 11th and 2nd month with sgi 3 are used to represent spring summer autumn and winter respectively the 10th and 4th month with sgi 6 are used to represent rainy and dry season while the 12th month with sgi 12 is used to represent the annual situation it can be seen that the seasonal change of groundwater in different areas is various according to the change in the sgi at the seasonal scale of georgia shown in fig 7 a the slope of the linear regression equations in spring summer autumn winter rainy dry and inter annual seasons were 0 0275 0 0266 0 0182 0 0175 0 0245 0 0251 and 0 0253 respectively the slope of the linear regression equations of the change in the sgi of massachusetts in spring summer autumn winter rainy dry and inter annual seasons were 0 0158 0 0244 0 0312 0 0281 0 0377 0 0215 and 0 0407 shown in fig 7 b the slope of the linear regression equations of the change in the sgi of oklahoma in corresponding different seasons were 0 0150 0 0115 0 0096 0 0161 0 0116 0 0230 and 0 01047 shown in fig 7 c while the slope of the linear regression equations of the change in the sgi of washington in spring summer autumn winter rainy dry and inter annual seasons were 0 0422 0 0602 0 0702 0 0591 0 0542 0 0555 and 0 0576 shown in fig 7 d overall the curves of sgi seasonal change in fig 7 a and fig 7 c showed a similar trend first dropped and then went up and the sgi in different seasons showed a similar increasing trend indicating that the groundwater was in a humid trend on the contrary sgi in fig 7 b and fig 7 d continued to decline and the sgi in different seasons showed a similar decreasing trend indicating that groundwater experienced a drought trend however the variation of groundwater in different seasons in the same area is not completely the same taking the change curves in the sgi at the seasonal scale in georgia shown in fig 7 a as an example the sgi values in spring fluctuated and increased there were 13 dry years within the past 30 years from 1985 to 1999 groundwater was in a state of water shortage and the drought situation was severe from 2000 to 2010 the drought situation was alleviated during the summer there were several abrupt changes in the sgi value and there were 14 dry years within the 30 year period although the dynamic range was smaller and the peak change was not higher than that in spring the duration was longer in autumn the rising trend in the sgi value was not obvious there were 12 dry years within the past 30 years with two peaks in 1984 and 1994 the dry situation strengthened and the wet situation weakened compared with summer values in winter the rising trend in the sgi value was not obvious and there were 13 dry years within the past 30 years in the rainy season the change in groundwater showed a rising trend with little fluctuation compared with that in the rainy season the situation of groundwater drought in the dry season was slightly serious and the dynamic range was large especially for groundwater drought in 1995 which was severe with a minimum sgi value of 2 539 it has been shown that the groundwater drought in 1995 may have been caused by excessive exploitation of groundwater for agricultural irrigation li et al 2016 what s more severe drought in the dry season in 1995 may be due to infrequent precipitation which together resulted in an inability to supplement groundwater the monitoring wells in other three different locations also showed similar phenomenon although the sgi had a similar temporal pattern in different seasons from 1981 to 2010 in the same region the drought time and extend varied over different seasons 3 4 lag effect between the spi and sgi as shown in fig 8 a high proportion of the variability in groundwater levels was due to climate variability lorenzo lacruz et al 2017 however the changes in the sgi and spi were not very synchronous in the short term 3 month time scale and long term 12 month time scale mostly due to the time lag effect in this section the lag time of different time scales in four different regions between the sgi and spi were calculated using the principle of cross correlation analysis with spss 24 0 software fig 9 shows the results of these calculations it can be concluded from fig 9 that the absolute values of the cross correlation between the spi and sgi of the well in georgia were 0 298 0 492 0 606 0 698 and 0 747 at 1 3 6 12 and 24 month time scales respectively the absolute values of cross correlation of the well in massachusetts were 0 586 0 628 0 651 0 656 and 0 651 at 1 3 6 12 and 24 month time scales respectively the absolute values of cross correlation of the well in oklahoma were 0 360 0 630 0 743 0 787 and 0 814 respectively and the absolute values of the cross correlation of the well in washington were 0 249 0 419 0 530 0 601 and 0 681 respectively as the time scale increased the value of the cross correlation between the spi and sgi in different regions also increased it can also be concluded from the delay value that the spi and sgi of the well in georgia had 2 3 4 5 and 7 month time lags at five different time scales there were 0 1 1 1 and 0 month time lags for the well in massachusetts 1 2 3 3 and 4 month time lags for the well in oklahoma and the spi and sgi of the well in washington had time lag of 22 24 24 24 and 24 month as the time scale increased the lag time in georgia and oklahoma also increased but the lag time in massachusetts and washington region was almost unchanged and there was almost no lag time in massachusetts region 4 discussion 4 1 reasons for the differences of sgi change in different regions groundwater level is essential for local water assessment and management cherry et al 2009 groundwater level fluctuations and variation trends can be used to estimate changes in aquifer storage resulting from the effects of groundwater withdrawal and recharge from precipitation according to the study of groundwater condition in georgia in 2003 leeth 2005 the groundwater level varied in a downward trend around 2000 we can see the same situation in fig 6 a from 1981 to 2010 the sgi value of the well located in georgia increased slightly per year and groundwater drought occurred frequently before 2000 after 2000 the groundwater level tended to decline from 1981 to 2010 the sgi value of the well located in massachusetts fluctuated and decreased and the fluctuation range was the largest around 2000 georgia is in the southeast of the united states and massachusetts is located in the northeast li and shu 2016 have stated with the popularization of water saving irrigation technology and the improvement of cooling system in thermal power plants the total water consumption in the united states decreased by 13 2 from 2005 to 2010 but the reduced part was mainly surface water which led to a highest proportion of groundwater consumption with the value of 22 3 in history as shown in fig 10 there are more cities in the east with large population and more groundwater was used as domestic water instead of polluted surface water from 1981 to 2010 the sgi in oklahoma first decreased significantly and then fluctuated again but since 2000 the groundwater level has been on the decline on the whole rao and yang 2010 referred to the changes in the groundwater levels within texas county in the oklahoma panhandle region they explained that the region overlay the central portion of the high plains aquifer had a significant decline in groundwater levels largely due to the development of irrigated agriculture the sgi of the well in washington from 1997 to 2010 showed a slight decreasing trend based on analysis of the annual scale which was consistent with fasser and julich 2010 this trend may have been related to the natural environment of the united states previous studies edwards 1997 lin 1983 have referred that although water resources in the united states are rich there are fewer water resources in the western regions than in eastern regions from 1950 to 2010 the annual consumption of groundwater in the united states increased from 469 7 108 m3 to 1095 5 108 m3 an increase of 130 maupin et al 2014 the difference between supply and demand of water resources in the western region is particularly obvious and the rates of development and utilization of groundwater are relatively high as a result the groundwater levels tend to be lower in washington according to the previous data the change of groundwater also depends on the aquifer some monitoring wells were located in the upper floridan aquifer some were in the caliborne aquifer some were in the clayton aquifer and some were in cretaceous aquifers and so on cherry et al 2009 however the monitoring wells in this paper are lack of hydrogeological conditions so we have no discussion of the aquifer 4 2 correlation coefficient analysis of spi and sgi fig 9 showed that at five different time scales in turn correlation coefficient of the well in georgia massachusetts and oklahoma were all negative while only correlation coefficients of the well in washington were positive generally speaking sgi and spi should be positively correlated to a certain extent but there were three typical wells at different time scales showed a negative correlation trend as mentioned above the wells located in georgia and massachusetts were affected by human activities mainly population and the well in oklahoma was affected by agricultural irrigation in many studies there has been a negative correlation between sgi and spi thomas et al 2017 lorenzo lacruz et al 2017 even emphasized that different response patterns were observed in terms of the effects of accumulated precipitation deficits on aquifer storage which was characterized by very weak correlations at short time scales while reaching the strongest correlation at medium time scales at this point all the correlation curves maintained a pattern of decrease until the 48 month time scale given the relationship between groundwater storage changes and surface water allocations thomas et al 2017 indicated that groundwater storage was largely driven by soil moisture deficits which were fulfilled by a complex mix of surface water allocations and groundwater use to sustain agriculture lorenzo lacruz et al 2017 referred that in flat and open topography the influence of precipitation on the sgi was greater in terms of spatial extent marchant and bloomfield 2018 found that some sites may be influenced by features of the regional hydrogeology that act to modify recharge and hence affect the form of the sgi hydrographs besides bloomfield and marchant 2013 referred that the hydrogeological context of groundwater monitoring sites is needed to be taken into account when designing and interpreting data from groundwater drought monitoring networks therefore it is not comprehensive to only consider the relationship between spi and sgi the influence of natural environment e g hydrogeology and human activities should also be considered 4 3 time lag analysis of spi and sgi in the analysis of section 3 4 the lag time of different time scales in four different regions between the sgi and spi were calculated using the principle of cross correlation analysis the results showed that with the time scale increased the values of the cross correlation between the spi and sgi in different regions increased and the lag time in georgia and oklahoma also increased but the lag time in massachusetts and washington region were almost unchanged and there was almost no lag time in massachusetts region while in the analysis of section 3 2 the groundwater in georgia and oklahoma was in a moist state or tended to be wet and the groundwater in massachusetts and washington was in a state of long term drought or presented a trend of drought therefore it can be inferred that the groundwater in georgia and oklahoma was in a wet state and can supply water to the vadose zone so that the vadose zone had a redistribution effect on precipitation there was a lag effect the same method was used by song 2018 to determine accumulation period ap which represents the month with the highest correlation coefficient between sgi and spi indicating that the ap values ranged in 1 3 months for most of 68 wells but it was 7 10 months in some wells these results can be interpreted such that the total amount of groundwater will not decrease significantly in long term drought situations and the wells with low ap value tended to respond to short term drought but it had little effect on groundwater system when the long drought occurs maybe we can make the similar conclusion under short term drought the lag phenomenon was also obvious while in long term drought the lag phenomenon was not obvious lorenzo lacruz et al 2017 also referred that differences in the response of aquifer levels to precipitation variability were found based on the time scale at which the best correlations between the sgi and spi occurred in many mediterranean coastal areas they found the presence of clay in the aquifer recharge area affected the relationship between precipitation and aquifer storage and made those aquifers less sensitive to climatic variability overall it can be also explained that groundwater aquifer will have a certain impact on the lag time of spi and sgi 5 conclusions in this paper the sgi was determined based on groundwater level data of the crn wells in the united states from 1981 to 2010 according to the spi method the fitting function types of groundwater level distribution were optimized from a variety of distribution functions using ad criteria and the pattern of lag time between the sgi and spi in different time scales was compared to calculate the sgi and evaluate the groundwater drought situation combined with the spi according to the comparative analysis results the lognormal function can be selected for the optimal probability density function at different time scales start and end time of drought conditions and the severity of drought and flooding at different time scales in the same area varied and groundwater drought varied significantly in different areas due to the complexity of geographical location agricultural irrigation and other natural environment and human activities with the increasing time scales the cross correlation coefficients increased the average correlation values between spi and sgi of wells in georgia massachusetts oklahoma and washington were 0 568 0 634 0 667 and 0 496 also due to hydrogeological conditions such as vadose zone lithology soil and the influence of human activities the lag time in georgia and oklahoma increased but the lag time in massachusetts and washington region were almost unchanged and there was almost no lag time in massachusetts region under short term drought in a wet state in general the lag phenomenon was also obvious while it was not obvious in long term drought in a dry state credit authorship contribution statement mengshen guo investigation formal analysis visualization writing original draft weifeng yue investigation conceptualization methodology formal analysis writing review editing tiejun wang supervision methodology investigation writing review editing nengzhan zheng formal analysis visualization lijun wu formal analysis visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the national natural science foundation of china grant no 51879011 the national key research and development program of china grant no 2019yfc0409201 the key science and technology projects of inner mongolia autonomous region 2019zd001 beijing advanced innovation program for land surface science and the 111 project b18006 
4506,groundwater drought is a drought phenomenon caused by the decrease in groundwater level or groundwater storage under natural and anthropogenic disturbances e g climate variability change and groundwater abstraction due to the complexity of groundwater flow systems and the difficulty in obtaining direct observational data related to groundwater resources it remains challenging to characterize groundwater drought quantitatively to this end standardized groundwater level index sgi which was modified from the standardized precipitation index spi was used to quantify groundwater drought with the long term groundwater level data 1981 2010 obtained from the climate response network wells across the conterminous united states the best fitting function of groundwater level distributions was lognormal which was selected from various distribution functions based on the anderson darling ad test among 100 wells four monitoring wells located in georgia massachusetts oklahoma and washington were selected as the main research objects the trend of change in groundwater level was divided into two categories the wells in georgia and oklahoma showed an initial decrease followed by an increase while the wells in massachusetts and washington showed a continuous decline groundwater drought varied significantly in different areas due to the complexity of geographical location agricultural irrigation population and other natural environment and human activities start and end time of drought conditions and the severity of drought and flooding at different time scales in the same area also varied therefore it is necessary to describe different groundwater droughts at a reasonable time scale in this paper the difference between sgi and spi at different time scales was so obvious that the cross correlation analysis was used to find the law of lag time the cross correlation coefficients increased with the increasing time scales and the average correlation values between spi and sgi of wells in georgia massachusetts oklahoma and washington were 0 568 0 634 0 667 and 0 496 respectively with the time scale increased the lag time in georgia and oklahoma also increased but the lag time in massachusetts and washington region was almost unchanged and there was almost no lag time in massachusetts region through the study of the hydrogeological conditions such as vadose zone lithology soil and the influence of human activities the hysteresis effect can be analysed which can provide a new alternative to the conventional method and important information for future groundwater resource management keywords sgi spi groundwater drought lag effect 1 introduction as one of the costliest natural hazards drought has a wide spectrum of adverse impacts on natural environments and socio economic activities ranging from the reduction in water supply and crop yield to the loss of riparian vegetation and habitat cook et al 2007 garssen et al 2014 mishra and singh 2010 touma et al 2015 the occurrence of droughts is usually triggered by prolonged periods e g from weeks to years with below normal precipitation which is normally accompanied by above normal temperature and evapotranspiration dai 2011 vicente serrano et al 2015 from a disciplinary perspective droughts can be divided into four categories meteorological hydrological agricultural and socio economic droughts wilhite and glantz 1985 recently groundwater has been one of the most valuable natural resources providing approximately 50 of drinking water and 20 of irrigation water globally zektser and everett 2004 although groundwater withdrawal in the united states only accounted for 21 4 of total water withdrawal in 2010 groundwater provided more than 43 of irrigation water and 98 of water for self supplied domestic uses maupin et al 2014 due to the ever increasing demands for groundwater resources the issue of groundwater depletion has been intensified on a global scale giordano 2009 wada et al 2010 in addition to anthropogenic impacts e g excessive pumping climate variability change also affects groundwater resources allen et al 2004 green et al 2011 taylor et al 2013 particularly through climate induced groundwater drought mishra and singh 2010 in a recent review mishra and singh 2010 argued that groundwater drought should be treated separately as a distinct type according to the drought classification system as groundwater drought can have pronounced impacts on many industrial and domestic sectors as well as on groundwater dependent ecosystems lange et al 2017 in addition unlike other hydrological components groundwater aquifers can act as low pass filters which can significantly modify hydrological signals by removing high frequency noises and retaining low frequency signals eltahir and yeh 1999 istanbulluoglu et al 2012 loon and anne 2015 peters et al 2003 wang et al 2009 therefore groundwater drought may exhibit different temporal characteristics e g higher temporal persistence than other types of droughts eltahir and yeh 1999 peters et al 2005 2003 because groundwater drought is a continuous slow and complex process when people are aware of the occurrence of groundwater drought it has lasted for a long time and caused losses therefore it is necessary to detect identify and forecast groundwater drought it is an effective method to quantify groundwater drought events using groundwater drought index gwi mendicino et al 2008 proposed the use of the groundwater resource index gri to better monitor groundwater resources based on the comprehensive consideration of meteorological hydrological and agricultural information li and rodell 2015 evaluated groundwater drought of pressure wells and semi pressure wells in the central and eastern regions of the northern united states through the gwi thomas et al 2017 used the normalized grace derived groundwater storage deviations which was defined as the grace groundwater drought index ggdi to quantify groundwater storage deficits and applied it to the central plains of california successfully standardized precipitation index spi was recommended over other drought indices by the world meteorological organization for monitoring meteorological droughts hayes et al 2011 although certain limitations existed for the computation of spi lloyd hughes and saunders 2002 mckee et al 1993 mishra and singh 2010 spi based methods have been also successfully applied to investigate other types of droughts such as soil moisture sheffield et al 2009 vidal et al 2010 surface runoff niu et al 2015 shukla and wood 2008 streamflow lópez moreno et al 2009 zhang et al 2015 and spring discharge fiorillo and guadagno 2012 2010 in recent years this method has been also applied to the study of groundwater drought bloomfield and marchant 2013 constructed the standardized groundwater index sgi according to the groundwater level data using the construction method of spi which adopted a non parametric normal score transform method yeh and chang 2019 used the sgi and spi to analyse the region s drought characteristics of the kaoping river basin taiwan which revealed that continuous droughts occurred in the river basin from 2003 to 2005 ai et al 2019 selected different distribution functions to determine the sgi based on groundwater level data and used them to analyse the temporal and spatial evolution of groundwater in the middle and lower reaches of the heihe river the proposed sgi combined with other methods for identifying drought signals has become a substantial step toward an effective regional groundwater resource planning in recent years chu 2018 used data clustering and decomposition analysis eof to identify the underlying signals of sgi following the standardized drought analysis sda at local and regional scales which showed the regional sgi integrated with eof was a useful and direct way for detecting and quantifying groundwater drought seo and lee 2019 calculated the sgi by normalizing an artificial neural network ann that employed grace trmm as well as gldas models to predict groundwater storage changes from 2003 to 2015 across south korea generally speaking as a new drought type groundwater drought index is still in the exploration stage as one of a few attempts to use the sgi technique for delineating groundwater drought we used the 1981 2010 monthly groundwater level data obtained from the climate response network crn located in the conterminous united states and monthly precipitation data for the same yeas retrieved from the national climatic data center the primary goals of this paper were to 1 assess the use of different probability density functions for calculating the sgi over the conterminous us 2 evaluate the change in groundwater storage through 4 specific monitoring wells based on the change in the sgi and 3 determine the pattern of lag time between the sgi and spi the results of this paper can provide additional insights into using the spi based method for characterizing groundwater drought and provide more information for future groundwater resource management in the united states 2 materials and methods 2 1 groundwater level and precipitation data the use of spi based methods for monitoring droughts is constrained by the lack of long term continuous measurements of the hydrometeorological variable under consideration particularly observed groundwater level data li and rodell 2015 lloyd hughes and saunders 2002 mckee et al 1993 mishra and singh 2010 for instance mckee et al 1993 suggested that at least 30 years of monthly precipitation data were needed to calculate spi following the recommendation of mckee et al 1993 long term monthly groundwater level data from 1981 to 2010 were taken from the crn wells operated by the usgs fig 1 data can be accessed at http groundwaterwatch usgs gov net ogwnetwork asp ncd crn crn wells are located in unconfined or near surface confined aquifers and not subject to anthropogenic influences e g pumping and artificial recharge as such fluctuations in the groundwater levels in the crn wells mainly reflect the effect of climate variability on underlying groundwater systems making them ideal for calculating groundwater drought to maximize the number of wells analysed in this study those with less than 5 missing data i e no groundwater level measurements during the period from 1981 to 2010 were selected resulting in a total of 100 wells fig 1 shows that a large portion of the selected wells were located in the northeastern united states e g massachusetts new hampshire and vermont to fill the missing monthly data linear interpolation was employed li and rodell 2015 to calculate the spi monthly precipitation data at each well location were retrieved from the closest meteorological stations generally within a 20 km radius from the national climatic data center http www ncdc noaa gov 2 2 calculation procedures for the spi and sgi mckee et al 1993 first proposed the spi method for characterizing meteorological drought by transforming time series of monthly precipitation data into a standardized normal distribution with a mean of zero and variance of one for the spi compared to other drought indices e g the palmer drought severity index pdsi palmer 1965 the use of spi like indices provides several advantages for delineating droughts guttman 1998 lloyd hughes and saunders 2002 mckee et al 1993 mishra and singh 2010 for example unlike other commonly used drought indices such as the pdsi the spi requires the input of only one variable e g precipitation or depth to groundwater table and is relatively easy to compute the flexibility of the calculation procedures for spi like indices over different time scales also allows for monitoring of both short term and long term droughts for various purposes heim jr 2002 mishra and singh 2010 moreover the use of the threshold level approach peters et al 2003 or the pdsi to identify droughts is dependent on conditions at a specific site guttman 1998 hisdal et al 2000 in contrast the adoption of the standardized normalization procedures for calculating spi like indices makes them suitable not only for comparing droughts in different regions but also for comparing different types of droughts within a consistent framework guttman 1998 lópez moreno et al 2009 mishra and singh 2010 following the procedures of mckee et al 1993 and guttman 1999 the computation of the spi and sgi involves four steps first the time series of the variable of interest e g precipitation and depth to groundwater table in this study is averaged over the time scale of interest e g running series for 1 3 6 12 and 24 months secondly an appropriate probability density function is fitted to the time series of the data for the same time period e g each calendar month during a calendar year after the parameters of the probability density function are determined from the historic records the corresponding cumulative distribution function is then used to calculate the cumulative probability of any observed value of the variable finally the inverse normal cumulative distribution function with a mean of zero and variance of one is applied to convert the cumulative probability of the observed value of the variable to the spi or sgi the spi like the sgi of zero value corresponds to the median precipitation and the spi of a negative value indicates below median precipitation and vice versa the severity of a drought is determined by the departure of a negative spi value from zero for instance mckee et al 1993 categorized spi 2 as extreme drought 2 spi 1 5 as severe drought 1 5 spi 1 0 as moderate drought 1 0 spi 0 as minor drought and spi greater than 0 as no drought in this study according to the calculation of spi sgi values were assigned as follows sgi less than 0 for groundwater drought and sgi 0 for no groundwater drought 2 3 probability density functions selecting an appropriate probability density function to fit the observed data is important for applying the spi or spi like indices method to identify droughts as the value of spi is affected by the use of different probability distributions mishra and singh 2010 summarized some of the commonly used probability distributions for fitting precipitation data in the literature including gamma lognormal and extreme value distributions bloomfield and marchant 2013 tested gamma normal lognormal and extreme value distributions for fitting groundwater level data according to previous studies five probability density functions i e gamma normal lognormal extreme value and weibull distributions were selected in this study to further test the performances of different distributions for fitting the groundwater level data obtained from the crn wells more detailed descriptions of those probability density functions can be found elsewhere in the literature e g guenang and kamga 2014 lloyd hughes and saunders 2002 the maximum likelihood approach embedded in the matlab software package mathworks 2017 was used to obtain the fitted parameters for each distribution to evaluate the performances of different probability distributions for fitting the groundwater level data the anderson darling test was used in this study anderson and darling 1952 the anderson darling test measures how well a probability distribution fits the observed data for a given sample dataset xi x 1 x 2 xn the anderson darling statistic a 2 is defined as 1 a 2 n i 1 n 2 i 1 n ln f x i l n 1 f x n 1 i where n is the number of observations in the sample dataset and f x is the cumulative distribution function a smaller value of a 2 indicates a better fit of the distribution to the data the significance level of the test statistic a 2 can be determined according to the tabulated values derived from theoretical distributions if a 2 is greater than the tabulated values from a specified distribution the null hypothesis that the sample data come from the distribution is rejected at the given significance level 3 results 3 1 fitting functions for the sgi groundwater level is a continuous variable with strong seasonality which is different from precipitation as a cumulative variable jasechko et al 2014 thus the gamma function which is normally used to calculate the spi cannot be directly applied to fit the sgi based on the spi method that is the fitting function of the sgi should be optimized therefore selecting an appropriate fitting function is essential for calculating the sgi which can have a noticeable impact on the computed values of sgis ai et al 2019 given the geographical locations of wells from different climate regimes four wells located in georgia massachusetts oklahoma and washington were used as examples here for demonstrating the selection of fitting functions in addition the cumulative distribution functions cdfs of depth to groundwater table at the 1 month and 6 month time scales were calculated by five different fitting functions as shown in figs 2 and 3 respectively some errors existed in the selected fitting functions for fitting the observed data at different time scales as seen in fig 2 and 3 specifically the shorter the time scale the smaller error of each fitting function to find the best fitting function the anderson darling ad test was used to evaluate the performances of different cdfs the passing rates of the ad criterion for the five selected fitting functions are shown in fig 4 based on the monthly groundwater level data of 100 observation wells in the united states from 1981 to 2010 the best fitting distribution function varied in different regions ai et al 2019 pointed out that the beta distribution function was the best fitting function within the heihe river basin china the four distributions normal lognormal gamma and extreme value were explored to fit the distribution of groundwater levels best at different sites in the uk as discussed by bloomfield and marchant 2013 the results found that the best fitting distribution varied among different sites and calendar months however in our study it can be seen from fig 4 that the lognormal function was the best fitting function with approximately 40 of the annual passing rate at all time scales among 100 wells moreover the passing rate of the lognormal function increased as the time scale increased from 29 at a 1 month time scale to 49 at a 24 month time scale thus the lognormal function was selected to calculate the sgi based on the monthly groundwater level data for example fig 5 shows the histograms of observed groundwater levels and the corresponding sgi with the lognormal distribution at different time scales for the well in washington the sign and magnitude of their skewness and kurtosis were roughly consistent in the form of their distributions except for slight differences among their frequencies 3 2 different time scale evolutions of the sgi the change in the sgi can be used to depict variations in groundwater storage fig 6 shows the curve of the change in the sgi at five different time scales for each of the four study wells different time scales reflect different types of droughts the sgi 1 reflects the monthly variation in drought characteristics which involves very rapid and sensitive changes but the error is notable when analysing a long term trend the sgi 3 reflects the characteristics of seasonal drought and flood which is usually closely related to agricultural groundwater drought the sgi 6 sgi 12 and sgi 24 reflect the characteristics of drought change at a long time scale which can reflect the characteristics of groundwater drought change from the perspective of time scales the fluctuation in the sgi was very violent at the 1 month time scale sgi 1 and there was almost no obvious trend in the change in georgia massachusetts oklahoma and washington as shown in fig 6 however with the increase of time scale especially in the sgi 24 a distinct trend was emerging fluctuation rise with a linear slope of 0 0545 in the sgi 24 in georgia showed that groundwater has become slightly moist in recent years fluctuation drop with a linear slope of 0 0606 and 0 0636 in the sgi 24 in massachusetts and washington showed that groundwater would become increasing drought while an initial drop followed by an increase with an average linear slope of 0 0412 in oklahoma indicated that the groundwater presented a trend of initial drought and followed by wet conditions on the whole the trend of change in the sgi seemed to be more obvious as the time scale length increased the starting and ending time of drought and the severity of drought and flood at different time scales in the same region were also distinct according to the analysis shown in fig 6 for example regarding groundwater drought in oklahoma in 2007 as shown in fig 6 c the sgi 1 occurred over 6 months from june to november with an average drought intensity of 1 80 and a maximum drought intensity of 3 22 in july of 2007 while the sgi 3 occurred over 6 months from july to december with an average drought intensity of 1 80 and a maximum drought intensity of 2 95 in september of 2007 the sgi 6 occurred for 8 months from july to february of the next year with an average drought intensity of 1 26 and a maximum drought intensity in november of 2007 reaching 2 11 the sgi 12 occurred for 10 months from september to june of the next year with an average drought intensity of 0 66 and a maximum drought intensity in january of 2008 reaching 0 90 the sgi 24 did not indicate drought among the sgi 1 sgi 3 sgi 6 and sgi 12 with the increase of time scale the duration of drought gradually increased but the average and maximum drought intensity decreased however the drought periods were essentially the same and appeared in september october and november in 2007 3 3 seasonal evolutions of the sgi fig 7 shows the curve of the seasonal change in the sgi for each of the four study wells the 5th 8th 11th and 2nd month with sgi 3 are used to represent spring summer autumn and winter respectively the 10th and 4th month with sgi 6 are used to represent rainy and dry season while the 12th month with sgi 12 is used to represent the annual situation it can be seen that the seasonal change of groundwater in different areas is various according to the change in the sgi at the seasonal scale of georgia shown in fig 7 a the slope of the linear regression equations in spring summer autumn winter rainy dry and inter annual seasons were 0 0275 0 0266 0 0182 0 0175 0 0245 0 0251 and 0 0253 respectively the slope of the linear regression equations of the change in the sgi of massachusetts in spring summer autumn winter rainy dry and inter annual seasons were 0 0158 0 0244 0 0312 0 0281 0 0377 0 0215 and 0 0407 shown in fig 7 b the slope of the linear regression equations of the change in the sgi of oklahoma in corresponding different seasons were 0 0150 0 0115 0 0096 0 0161 0 0116 0 0230 and 0 01047 shown in fig 7 c while the slope of the linear regression equations of the change in the sgi of washington in spring summer autumn winter rainy dry and inter annual seasons were 0 0422 0 0602 0 0702 0 0591 0 0542 0 0555 and 0 0576 shown in fig 7 d overall the curves of sgi seasonal change in fig 7 a and fig 7 c showed a similar trend first dropped and then went up and the sgi in different seasons showed a similar increasing trend indicating that the groundwater was in a humid trend on the contrary sgi in fig 7 b and fig 7 d continued to decline and the sgi in different seasons showed a similar decreasing trend indicating that groundwater experienced a drought trend however the variation of groundwater in different seasons in the same area is not completely the same taking the change curves in the sgi at the seasonal scale in georgia shown in fig 7 a as an example the sgi values in spring fluctuated and increased there were 13 dry years within the past 30 years from 1985 to 1999 groundwater was in a state of water shortage and the drought situation was severe from 2000 to 2010 the drought situation was alleviated during the summer there were several abrupt changes in the sgi value and there were 14 dry years within the 30 year period although the dynamic range was smaller and the peak change was not higher than that in spring the duration was longer in autumn the rising trend in the sgi value was not obvious there were 12 dry years within the past 30 years with two peaks in 1984 and 1994 the dry situation strengthened and the wet situation weakened compared with summer values in winter the rising trend in the sgi value was not obvious and there were 13 dry years within the past 30 years in the rainy season the change in groundwater showed a rising trend with little fluctuation compared with that in the rainy season the situation of groundwater drought in the dry season was slightly serious and the dynamic range was large especially for groundwater drought in 1995 which was severe with a minimum sgi value of 2 539 it has been shown that the groundwater drought in 1995 may have been caused by excessive exploitation of groundwater for agricultural irrigation li et al 2016 what s more severe drought in the dry season in 1995 may be due to infrequent precipitation which together resulted in an inability to supplement groundwater the monitoring wells in other three different locations also showed similar phenomenon although the sgi had a similar temporal pattern in different seasons from 1981 to 2010 in the same region the drought time and extend varied over different seasons 3 4 lag effect between the spi and sgi as shown in fig 8 a high proportion of the variability in groundwater levels was due to climate variability lorenzo lacruz et al 2017 however the changes in the sgi and spi were not very synchronous in the short term 3 month time scale and long term 12 month time scale mostly due to the time lag effect in this section the lag time of different time scales in four different regions between the sgi and spi were calculated using the principle of cross correlation analysis with spss 24 0 software fig 9 shows the results of these calculations it can be concluded from fig 9 that the absolute values of the cross correlation between the spi and sgi of the well in georgia were 0 298 0 492 0 606 0 698 and 0 747 at 1 3 6 12 and 24 month time scales respectively the absolute values of cross correlation of the well in massachusetts were 0 586 0 628 0 651 0 656 and 0 651 at 1 3 6 12 and 24 month time scales respectively the absolute values of cross correlation of the well in oklahoma were 0 360 0 630 0 743 0 787 and 0 814 respectively and the absolute values of the cross correlation of the well in washington were 0 249 0 419 0 530 0 601 and 0 681 respectively as the time scale increased the value of the cross correlation between the spi and sgi in different regions also increased it can also be concluded from the delay value that the spi and sgi of the well in georgia had 2 3 4 5 and 7 month time lags at five different time scales there were 0 1 1 1 and 0 month time lags for the well in massachusetts 1 2 3 3 and 4 month time lags for the well in oklahoma and the spi and sgi of the well in washington had time lag of 22 24 24 24 and 24 month as the time scale increased the lag time in georgia and oklahoma also increased but the lag time in massachusetts and washington region was almost unchanged and there was almost no lag time in massachusetts region 4 discussion 4 1 reasons for the differences of sgi change in different regions groundwater level is essential for local water assessment and management cherry et al 2009 groundwater level fluctuations and variation trends can be used to estimate changes in aquifer storage resulting from the effects of groundwater withdrawal and recharge from precipitation according to the study of groundwater condition in georgia in 2003 leeth 2005 the groundwater level varied in a downward trend around 2000 we can see the same situation in fig 6 a from 1981 to 2010 the sgi value of the well located in georgia increased slightly per year and groundwater drought occurred frequently before 2000 after 2000 the groundwater level tended to decline from 1981 to 2010 the sgi value of the well located in massachusetts fluctuated and decreased and the fluctuation range was the largest around 2000 georgia is in the southeast of the united states and massachusetts is located in the northeast li and shu 2016 have stated with the popularization of water saving irrigation technology and the improvement of cooling system in thermal power plants the total water consumption in the united states decreased by 13 2 from 2005 to 2010 but the reduced part was mainly surface water which led to a highest proportion of groundwater consumption with the value of 22 3 in history as shown in fig 10 there are more cities in the east with large population and more groundwater was used as domestic water instead of polluted surface water from 1981 to 2010 the sgi in oklahoma first decreased significantly and then fluctuated again but since 2000 the groundwater level has been on the decline on the whole rao and yang 2010 referred to the changes in the groundwater levels within texas county in the oklahoma panhandle region they explained that the region overlay the central portion of the high plains aquifer had a significant decline in groundwater levels largely due to the development of irrigated agriculture the sgi of the well in washington from 1997 to 2010 showed a slight decreasing trend based on analysis of the annual scale which was consistent with fasser and julich 2010 this trend may have been related to the natural environment of the united states previous studies edwards 1997 lin 1983 have referred that although water resources in the united states are rich there are fewer water resources in the western regions than in eastern regions from 1950 to 2010 the annual consumption of groundwater in the united states increased from 469 7 108 m3 to 1095 5 108 m3 an increase of 130 maupin et al 2014 the difference between supply and demand of water resources in the western region is particularly obvious and the rates of development and utilization of groundwater are relatively high as a result the groundwater levels tend to be lower in washington according to the previous data the change of groundwater also depends on the aquifer some monitoring wells were located in the upper floridan aquifer some were in the caliborne aquifer some were in the clayton aquifer and some were in cretaceous aquifers and so on cherry et al 2009 however the monitoring wells in this paper are lack of hydrogeological conditions so we have no discussion of the aquifer 4 2 correlation coefficient analysis of spi and sgi fig 9 showed that at five different time scales in turn correlation coefficient of the well in georgia massachusetts and oklahoma were all negative while only correlation coefficients of the well in washington were positive generally speaking sgi and spi should be positively correlated to a certain extent but there were three typical wells at different time scales showed a negative correlation trend as mentioned above the wells located in georgia and massachusetts were affected by human activities mainly population and the well in oklahoma was affected by agricultural irrigation in many studies there has been a negative correlation between sgi and spi thomas et al 2017 lorenzo lacruz et al 2017 even emphasized that different response patterns were observed in terms of the effects of accumulated precipitation deficits on aquifer storage which was characterized by very weak correlations at short time scales while reaching the strongest correlation at medium time scales at this point all the correlation curves maintained a pattern of decrease until the 48 month time scale given the relationship between groundwater storage changes and surface water allocations thomas et al 2017 indicated that groundwater storage was largely driven by soil moisture deficits which were fulfilled by a complex mix of surface water allocations and groundwater use to sustain agriculture lorenzo lacruz et al 2017 referred that in flat and open topography the influence of precipitation on the sgi was greater in terms of spatial extent marchant and bloomfield 2018 found that some sites may be influenced by features of the regional hydrogeology that act to modify recharge and hence affect the form of the sgi hydrographs besides bloomfield and marchant 2013 referred that the hydrogeological context of groundwater monitoring sites is needed to be taken into account when designing and interpreting data from groundwater drought monitoring networks therefore it is not comprehensive to only consider the relationship between spi and sgi the influence of natural environment e g hydrogeology and human activities should also be considered 4 3 time lag analysis of spi and sgi in the analysis of section 3 4 the lag time of different time scales in four different regions between the sgi and spi were calculated using the principle of cross correlation analysis the results showed that with the time scale increased the values of the cross correlation between the spi and sgi in different regions increased and the lag time in georgia and oklahoma also increased but the lag time in massachusetts and washington region were almost unchanged and there was almost no lag time in massachusetts region while in the analysis of section 3 2 the groundwater in georgia and oklahoma was in a moist state or tended to be wet and the groundwater in massachusetts and washington was in a state of long term drought or presented a trend of drought therefore it can be inferred that the groundwater in georgia and oklahoma was in a wet state and can supply water to the vadose zone so that the vadose zone had a redistribution effect on precipitation there was a lag effect the same method was used by song 2018 to determine accumulation period ap which represents the month with the highest correlation coefficient between sgi and spi indicating that the ap values ranged in 1 3 months for most of 68 wells but it was 7 10 months in some wells these results can be interpreted such that the total amount of groundwater will not decrease significantly in long term drought situations and the wells with low ap value tended to respond to short term drought but it had little effect on groundwater system when the long drought occurs maybe we can make the similar conclusion under short term drought the lag phenomenon was also obvious while in long term drought the lag phenomenon was not obvious lorenzo lacruz et al 2017 also referred that differences in the response of aquifer levels to precipitation variability were found based on the time scale at which the best correlations between the sgi and spi occurred in many mediterranean coastal areas they found the presence of clay in the aquifer recharge area affected the relationship between precipitation and aquifer storage and made those aquifers less sensitive to climatic variability overall it can be also explained that groundwater aquifer will have a certain impact on the lag time of spi and sgi 5 conclusions in this paper the sgi was determined based on groundwater level data of the crn wells in the united states from 1981 to 2010 according to the spi method the fitting function types of groundwater level distribution were optimized from a variety of distribution functions using ad criteria and the pattern of lag time between the sgi and spi in different time scales was compared to calculate the sgi and evaluate the groundwater drought situation combined with the spi according to the comparative analysis results the lognormal function can be selected for the optimal probability density function at different time scales start and end time of drought conditions and the severity of drought and flooding at different time scales in the same area varied and groundwater drought varied significantly in different areas due to the complexity of geographical location agricultural irrigation and other natural environment and human activities with the increasing time scales the cross correlation coefficients increased the average correlation values between spi and sgi of wells in georgia massachusetts oklahoma and washington were 0 568 0 634 0 667 and 0 496 also due to hydrogeological conditions such as vadose zone lithology soil and the influence of human activities the lag time in georgia and oklahoma increased but the lag time in massachusetts and washington region were almost unchanged and there was almost no lag time in massachusetts region under short term drought in a wet state in general the lag phenomenon was also obvious while it was not obvious in long term drought in a dry state credit authorship contribution statement mengshen guo investigation formal analysis visualization writing original draft weifeng yue investigation conceptualization methodology formal analysis writing review editing tiejun wang supervision methodology investigation writing review editing nengzhan zheng formal analysis visualization lijun wu formal analysis visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the national natural science foundation of china grant no 51879011 the national key research and development program of china grant no 2019yfc0409201 the key science and technology projects of inner mongolia autonomous region 2019zd001 beijing advanced innovation program for land surface science and the 111 project b18006 
4507,sustainable groundwater management is becoming increasingly important due to intensifying water deficits around the world which highlights the necessities and challenges to explore the dynamics of groundwater at the catchment scale in this paper a tracer aided approach has been developed and applied to quantify the relationships between groundwater storage and discharge upon which the dynamics of groundwater storage and its residence time are assessed robust nonlinear storage discharge relationships are found for the eight studied catchments located in a headwater region of the murray darling basin australia the dynamics of groundwater storage for all the studied catchments largely show synchronization with regional climate the estimated highest and active groundwater storages in a year are more responsive to precipitation than the lowest storages for all the studied catchments during dry seasons without recharge the depletion rate of groundwater is found to decrease with the decline in groundwater storage which can be ascribed to the vertical heterogeneity of their unconfined aquifers the mean residence time of groundwater represented by mrt75 i e time taken for groundwater storage to diminish from its mean level to the 75th percentile varies between 57 and 111 days across the studied catchments suggesting considerable hydrogeological differences among the studied catchments the groundwater dynamics observed in this research could contribute to improving hydrogeological model performance in simulating the connection between groundwater and surface water at the catchment scale moreover the findings could serve to develop guidelines for groundwater extraction when considering the constraints of environmental flow requirements keywords groundwater storage residence time chemical tracer murray darling basin 1 introduction groundwater is a fundamental component of the hydrological cycle and plays a critical role in sustaining water supplies to both socio economic systems and terrestrial ecosystems because of its widespread availability generally high quality and intrinsic ability to buffer the impacts of episodic drought and climate variability fan et al 2013 gleeson et al 2016 jakeman et al 2016 cuthbert et al 2019 as a result of increasing water demand and changing climate groundwater has been found to be declining in many regions around the world scanlon et al 2012 russo and lall 2017 bijl et al 2018 unesco 2018 which has led to reduced groundwater discharge into streams and subsequently weakened the hydrological connections between surface water and groundwater systems mair and fares 2010 andermann et al 2012 mukherjee et al 2018 for sustainable groundwater management such as that proposed in the australian national groundwater strategic framework 2016 2026 commonwealth of australia 2017 one of the essential but challenging hydrogeological missions is to track the dynamics and residence time of groundwater storage spence 2010 thomas et al 2016 the most straightforward approach to assess the amount of water stored underground arguably is based on in situ borehole observations although in situ groundwater observation provides the tangible water level of an aquifer it is limited to the plot scale and comes with high cost hector et al 2015 barthel and banzhaf 2016 on the other hand the remote sensing approach based on grace gravity recovery and climate experiment satellite data can be valuable in monitoring groundwater storage dynamics at regional to global scales but its spatial temporal resolution is rather coarse richey et al 2015 rodell et al 2018 thomas and famiglietti 2019 most often the remote sensing approach is more capable of quantifying the variation or anomalies of groundwater storage rather than the magnitude of storage volume furthermore as the temporal gravity data from grace itself does not provide direct observation of groundwater storage the remote sensing approach requires one to explore the relationship between temporal gravity changes and groundwater storage variations watkins et al 2015 scanlon et al 2018 which could lead to uncertainties in the estimated groundwater anomalies at a catchment scale groundwater storage usually is estimated as a component of catchment water balance analysis by using conceptual or process based hydrological models siebert 2010 birkel et al 2011 bhanja et al 2018 li et al 2019 the water balance approach has shown strength in providing a sensible estimation of groundwater storage for catchment totals but with uncertainties from model assumptions and model calibration alternatively for a gauged catchment groundwater storage can be estimated from the observed daily stream hydrograph based on hydraulic groundwater theory sánchez murillo et al 2015 thomas et al 2015a 2015b buttle 2018 the hydrograph based approach has been widely recognized as an effective and efficient method for catchment scale groundwater storage estimation because streamflow records are extensively available stewart 2015 fan et al 2019 meriö et al 2019 ploum et al 2019 for instance under the linear reservoir assumption for the groundwater system the temporal changes in watershed storage estimated from streamflow records have been investigated for catchments in the u s brutsaert 2008 and australia zhang et al 2014 thus thomas et al 2016 found for catchments in the southeastern u s that storage trend estimated using in situ groundwater level observations are consistent with those from the hydrograph based approach the core of the hydrograph based approach in estimating groundwater storage is to determine the relationship between groundwater storage and groundwater discharge or baseflow which commonly assumes that groundwater can be represented as a linear or nonlinear reservoir brutsaert and hiyama 2012 troch 2013 bart and tague 2017 jachens et al 2020 for example kirchner 2009 found a power law functional relationship existing between groundwater storage and discharge inferred directly from the streamflow observations the recession parameters e g recession constants of the linear or nonlinear reservoir can be derived from hydrograph recession sections but can be substantially misrepresented resulting in uncertainties in groundwater storage estimation if the recession flow is not just from the underground aquifer but also includes drainage from bank storage and other surface water stores the estimation could be improved if the hydrograph of baseflow rather than that of total streamflow is used to determine the parameters in the functional relationship e g stewart 2015 in this study we aim to estimate catchment scale groundwater storage as well as its residence time with the aid of chemical hydrographs the chemical observations specific electrical conductance are used to estimate groundwater discharge i e baseflow in the stream the estimated groundwater discharge is then used to determine the parameters in the functional relationship between groundwater storage and discharge upon which storage and residence time of groundwater are calculated the approach is tested on eight headwater catchments within the domain of the murray darling basin in australia to demonstrate its capabilities and limitations for catchment scale groundwater storage estimation this study is expected to contribute to improving hydrogeological model conceptualization and more accurate quantification of the connections between groundwater and surface water in the studied catchments 2 study area and data eight unregulated catchments in a headwater region of the murray darling basin mdb are selected for this study fig 1 the area of the eight selected catchments ranges from 130 km2 to 1519 km2 table 1 boundaries of the groundwater and surface water catchments are largely the same gmw 2014 groundwater plays an important role in sustaining the river system and is highly connected with surface water for all studied catchments the hydrogeology in all studied catchments is dominated by small shallow confined fractured rock aquifers in a range of different geologies including palaeozoic or mesozoic granites volcanic and consolidated sediments groundwater levels in the fractured rock aquifers of the region show a broad correlation with long term climate groundwater levels and flow in the bedrock aquifer are likely to mirror topography and flow systems are generally short in length recharge to the fractured rock systems flows through the fractures and follows the gradient of the river valley eventually flowing locally towards the adjacent rivers and valley floors in line with the topography csiro 2008 where discharge occurs it is typically in valley bottoms where the water table is close to the land surface at breaks of slope or where faults and fissures in the rock appear at the surface the selected catchments are considered unregulated as there is no significant human control or diversion of streamflow in the catchments as defined and identified by the state government water agency in australia csiro 2008 zhang et al 2014 for the study daily streamflow and specific electrical conductance data were collected from the state water agencies key statistics of the hydroclimatic variables are summarized in table 1 for water years 2000 2019 the mean annual precipitation of the selected catchments varies between 856 mm and 1189 mm while mean annual potential evapotranspiration is around 1170 mm precipitation of the selected catchments is winter dominated and mainly in the form of rainfall as the minimum daily mean temperatures are all above 0 c 3 methodology 3 1 tracer aided groundwater discharge estimation the underlying principle of tracer aided groundwater discharge estimation is the mass conservation law which assumes that the composition or chemical signature of water coming from various sources is constant and unique different from each other and that conservation of mass applies to the water quantities and water quality including conservative mixing of different water components e g kronholm and capel 2016 smith and capel 2018 hence the tracer aided approach for groundwater discharge estimation is also known as the chemical mass balance approach stewart et al 2007 li et al 2014 miller et al 2015 lott and stewart 2016 where the specific electrical conductance is a measure of theconservative chemical constituent i e total ionic concentration in the streamflow and one of the most widely used stable chemical tracers due to its cost effective merit mccarthy and johnson 2009 ali et al 2010 sanford et al 2012 cano paoli et al 2019 according to the chemical mass balance principle the tracer aided groundwater discharge estimation can be expressed as pinder and jones 1969 1 qg q sc sc s sc g sc s where qg is the groundwater discharge from the aquifer to stream q is total streamflow sc is the measured daily mean specific electrical conductance of streamflow sc s is the specific electrical conductance of the surface runoff end member and sc g is the specific electrical conductance of the groundwater discharge end member q and sc are both measured variables while sc s and sc g can be derived from sc accordingly in general the surface runoff conductivity sc s is considered equal to the lowest streamflow conductivity and is kept constant for the studied catchment in contrast sc g shows a significant intra annual variation because of the seasonal replenishment of groundwater to alleviate the impacts of outliers in measured sc as proposed by sanford et al 2012 the daily sc with nonexceedance probability of 99 for a specific calendar month is assumed to be the sc g of the first day in that month the daily sc g is then estimated by linear interpolation between the twelve values for the first day of each month the inter annual variation of sc g is assumed to be negligible as compared against the intra annual variation under these definitions of sc g there is 1 of days that could have qg greater than measured q for which qg is set equal to total streamflow e g miller et al 2014 it should be noted that application of the chemical mass balance cmb approach assumes that a streamflow from other sources e g snowmelt or irrigation is negligible b sc s does not change during the period of record and c sc s and sc g are significantly different from one other e g sklash and farvolden 1979 stewart et al 2007 3 2 determining relationships between groundwater storage and discharge the outflow from an unconfined aquifer that is sitting on a horizontal impermeable layer into a fully penetrating stream channel can be described by the well known boussinesq equation boussinesq 1877 making use of the dupuit assumptions and neglecting the effect of capillarity above the water table dupuit 1863 based on different assumptions and simplications several theoretical solutions to the boussinesq equation are available e g boussinesq 1903 1904 polubarinova kochina 1962 the solutions have provided a physical basis for the power law relationship between groundwater storage and discharge that is widely used in modelling hydrological systems the relation is expressed as horton 1941 brutsaert and nieber 1977 tallaksen 1995 wittenberg 1999 2 g μ qg v where g is the groundwater storage in the upstream aquifer spreading over the catchment area parameters μ and ν depend on the area porosity hydraulic conductivity and morphometric properties of the catchment brutsaert and nieber 1977 for example when ν 1 it is assumed that the groundwater system can be considered as a linear reservoir according to 3 μ φ a 2 p π k d l 2 where k is the hydraulic conductivity lt 1 φ is the drainable porosity p is the average fraction of the vertical aquifer thickness d l occupied by flowing water 0 p 1 l is the length of the drainage network l and a is catchment area l2 according to eq 2 the challenge in assessing groundwater storage given known discharge is to determine the parameters μ and ν the two parameters are not practically measurable but could be derived according to the recession characteristics of groundwater discharge wittenberg 1999 under low flow or drought flow conditions when there is little impact of precipitation and no recharge to the aquifer the water balance of the groundwater system can be expressed as 4 dg dt q g where t is time substituting eq 2 into eq 4 one obtains a power law relationship reflecting the flow recession process 5 dqg dt 1 μ ν qg 2 v α qg β where parameter α 1 μ ν is a function of the hydraulic properties of the system the parameter β 2 v determines the shape of the storage discharge function and allows for both linear β 1 hence v 1 and nonlinear β 1 hence v 1 storage discharge relationships both parameters α and β determine the recession rate of the flow the higher the values of both parameters α and β the quicker is the recession rate it is clear that if parameters α and β in eq 5 can be estimated given groundwater discharge time series during recession periods the relationship between groundwater storage and discharge eq 2 can then be determined to calculate parameters α and β we can rewrite eq 5 in its difference form as 6 qg t qg t 1 δ t α qg t qg t 1 2 β let δ t 1 d a y δ qg t qg t qg t 1 and qg t qg t qg t 1 2 hence parameters α and β can be estimated by linear regression between the time series of log δ qg t and log qg t expressed as 7 log δ qg t log α β l o g qg t to determine parameters α and β on the basis of the estimated groundwater discharge time series using the tracer aided approach then for a catchment with an area of a km2 we adopt the following criteria to retrieve the paired data points δ qg t qg t from the recession period a the recession begins at τ 0 827 a 0 2 days following a precipitation recharge event linsley et al 1975 and b data points with positive or zero δ qg t values are considered as anomalies and eliminated in principle all paired data points from the recession periods can be used in the regression analysis for a robust estimation as suggested by brutsaert and nieber 1977 data points at the lower envelope of all the paired points are used to estimate the parameters α and β where the position of the lower envelope is defined by δ qg t with exceedance probability of 90 of the data point cloud within a specified interval of qg t in the δ qg t qg t scatterplots troch et al 1993 malvicini et al 2005 rupp and selker 2006 stoelzle et al 2013 3 3 estimating mean residence time of groundwater mean residence time mrt of groundwater measures the duration of water retained underground or how rapidly groundwater storage depletes without further replenishment it is an important indicator reflecting the hydrogeological properties of the aquifer that shapes the connection between the groundwater system and surface water wolock et al 1989 zhu et al 2010 lapworth et al 2013 stoelzle et al 2013 the shorter the mrt the quicker is the depletion of groundwater with the estimated parameters μ and ν the mrt of groundwater can be determined by combining eq 2 and eq 4 i e 8 mrt μ ln g 0 ln g mrt f o r v 1 μ 1 v g 0 1 1 v g mrt 1 1 v 1 1 v f o r v 1 where g 0 and g mrt are groundwater storage at the initial time t 0 and mrt days after respectively according to eq 8 it can be seen that for a catchment meeting the linear reservoir v 1 assumption mrt μ holds when g 0 g mrt e which suggests that μ equals the e folding time for a nonlinear reservoir v 1 and if the depletion of groundwater is above the threshold value μ i e both g 0 and g mrt are higher than μ it can be derived that the estimated mrt would be shorter than that from the linear reservoir assumption and vice versa herein we set g 0 to be the median of the yearly mean groundwater storage g ave series while g mrt is set to be the medians of the yearly g 75 and g 99 i e 75th and 99th percentiles of groundwater storage at the lower end in a year series respectively hence mrt75 and mrt99 represent the mean duration of groundwater storage decrease from g ave to g 75 and to g 99 correspondingly inversely rewriting eq 8 we can estimate the volume of groundwater storage n days after the specified initial storage which is given as 9 g t g 0 e t μ f o r v 1 g 0 1 1 v 1 1 v μ 1 v t v v 1 f o r v 1 eq 9 can be used to calculate the residual ratio g t g 0 of groundwater in a specified duration where g 0 is the median of the yearly mean groundwater storage g ave series the residual ratio is a substitute for residence time generally for a groundwater system with a smaller depletion rate it has longer residence time and higher residual ratio after a specified time frame herein we estimate the residual ratios of groundwater at t 90 days and t 180 days respectively 4 results and discussion 4 1 tracer aided estimates of groundwater discharge fig 2 shows the specific electrical conductance of surface flow and groundwater discharge for each month which is used in eq 1 to estimate groundwater discharge it is found that the specific electrical conductance of groundwater discharge sc g fluctuates seasonally in a year which indicates the intra annual variation of groundwater storage within a year the maximum specific electrical conductance occurs in february or march which is the dry season in the region and when the streamflow is mainly from groundwater discharge meanwhile the minimum specific electrical conductance occurs in august or september which corresponds to the wet season indicating that groundwater is replenished due to rainfall events the ratio of the variation i e max min in sc g is around 1 40 2 25 among the studied catchments catchments 401012 and 401013 have the highest variation ratios indicating that they have stronger recharge effects from the rainfall events and where groundwater storage could be renewed much more quickly by recharge from rainfall as shown in fig 2 the specific electrical conductance of surface flow sc s is around 4 15 36 20 among the studied catchments the substantial spatial difference of sc s could be caused by catchment properties like catchment area geological texture soil types land use and land cover conditions that may affect the rainfall runoff processes and chemical load in the surface flow the estimated groundwater discharge based on eq 1 for the studied catchments is shown in fig 3 the ratio of groundwater discharge to total streamflow baseflow index bfi ranges from 0 58 to 0 65 among the catchments catchment 401013 has the highest bfi which suggests groundwater plays a more important role than in our other catchments in sustaining the river system and that there is a stronger connection between groundwater and surface water the inter annual variation of annual total groundwater discharge over the period 2000 2019 as represented by the coefficient of variation cv sd mean ranges from 0 52 to 0 77 among the studied catchments which is relatively smaller than that of the total streamflow with cv ranging from 0 52 to 1 0 the smaller inter annual variation of groundwater discharge implies the buffering effects of the groundwater store it is reckoned that the lower the variation of groundwater discharge the stronger the groundwater store is in buffering the variation of its climate drivers it is worth noticing that the specific electrical conductance of both surface flow and groundwater flow are the two critical parameters to separate groundwater discharge from the observed daily streamflow however measurements of the two parameters are not directly available which is the most critical limitation of the approach the two parameters though can be determined based on empirical assumptions developed and suggested by a few researchers e g sanford et al 2012 miller et al 2014 it is valuable to undertake a rationality check by comparing the results to that derived from other approaches in the study herein the estimated ratio of groundwater discharge to total runoff has been checked and found largely consistent with previous research zhu et al 2020b where groundwater discharge was estimated by digital filter approaches 4 2 relationship between groundwater storage and discharge the recession characteristics of groundwater discharge estimated based on the tracer aided approach are the foundation to determine the storage discharge relationship of each studied catchment fig 4 demonstrates the relationship between δ q g and qg for each studied catchment using data points from the recession part of the flow regime lower envelopes are fitted to the data points positioned at the 90th percentiles of δ q g in a specified qg interval the fitted lower envelopes of the data points reveal that the nonlinear relationships between δ q g and qg approximately follow the power law among the studied catchments the exponents β of the power functions are in the range of 1 04 1 54 whereas the intercepts α vary from 0 01 to 0 03 for the studied catchments the estimated β of the studied catchments are all in the physically reasonable range 1 β 3 as reported in the literature e g brutsaert and nieber 1977 palmroth et al 2010 shaw and riha 2012 stoelzle et al 2013 the catchments with an exponent β close to one e g 401013 suggest the relationships between δ q g and qg are approximately linear the catchments with higher values of either α and β e g 401008 and 401017 suggest a quicker declining rate of groundwater discharge during periods without recharge events fig 5 it should be noted however that the recession rate of groundwater discharge is concurrently determined by both α and β and so an isolated comparison of α or β values among different catchments could be ill advised with the estimated parameters α and β the relationship between groundwater storage and discharge is determined according to eq 2 where the parameters μ 1 α v and v 2 β the estimated μ and v of the studied catchments are listed in table 2 and the nonlinear relationships between groundwater storage and discharge are shown in fig 5 the nonlinear relationships suggest that aquifer porosity and permeability of the studied catchments all decrease disproportionately with depth and hence the drainage network could shrink and decelerate groundwater discharge preserving storage and prolonging the recession as the groundwater table falls fan et al 2019 the nonlinear storage discharge relationships of the studied catchments are all seen to be concave which means the retention capability of the aquifer is smaller when storage is high but increases continuously with the depletion of storage wittenberg 1994 the parameter μ indicates the amount of groundwater storage when groundwater discharge is of one unit i e qg 1 hence a catchment with a smaller μ e g 401008 means that the specific yield of its aquifer is smaller than catchments with a higher value of the parameter μ e g 410057 and 410024 for instance if the groundwater discharge is 1 mm in both catchments 401008 and 410057 the corresponding storages of them are 35 5 mm and 93 1 mm respectively however the specific yield of an aquifer does not increase linearly with increase in storage but is shaped by the parameter v which could reflect the vertical heterogeneity of the saturated hydraulic conductivity kirchner 2009 the catchments with parameter v closer to 1 0 e g 401013 imply stronger vertical homogeneity in saturated hydraulic conductivity and hence approximately conform to the behavior of a linear reservoir than the other catchments for a catchment with a smaller parameter v e g 410024 the corresponding increase in mean specific yield of the aquifer accompanied with a proportional increase of groundwater storage would be larger than catchments with higher v values as illustrated in fig 5 if qg is doubled for catchments 410024 and 401013 for example the corresponding proportional increase in their storages should be around 137 and 198 respectively 4 3 estimated groundwater storage based on the storage discharge relationships and the estimated groundwater discharge from the tracer aided approach the dynamics of groundwater storage at the catchment scale for the studied catchments are derived according to eq 2 as shown in fig 6 intra annually groundwater storages of all studied catchments generally reach their highest level in winter or early spring from around august to september rapidly recede during summer and then continue to be low level in autumn this is mainly because precipitation of the studied catchments is winter dominated where the higher precipitation in the winter together with lower temperature hence lower evaporation loss contribute to most water recharging into the aquifers in a year gmw 2014 zhu et al 2020a 2020b in the summer however higher potential evapotranspiration together with lower precipitation lead to a large evapotranspiration loss and little recharge into the aquifers hence lower groundwater level and storage volume fig 7 left panel summarizes the statistics of groundwater in each catchment over the period 2000 2019 where the probability distributions of the lowest g low average g ave the highest g high and the active g act storage i e the difference between the highest and the lowest storage in a year are represented in the boxplots it is found that groundwater storage varies substantially among the studied catchments for instance the lowest groundwater storage g low in a year ranges from 0 4 mm catchment 401008 to 21 6 mm catchment 401012 while the highest groundwater storage g high in a year ranges from 66 mm to 219 mm the spatial difference in groundwater storage could be attributed to the heterogeneities in climatic and hydrogeological conditions generally as shown in fig 7 right panel except for g low all the other three groundwater storage metrics i e g high g ave and g act display good positive correlation at a significance level of 0 05 with annual precipitation but weakly correlate with annual potential evapotranspiration the stronger correlations found between g high and precipitation than those between g low and precipitation imply that g high is more responsive to precipitation this is because groundwater storage reaches its highest level in a year mainly due to the accumulated recharge from precipitation the lowest groundwater storage however reflects not only the effects of groundwater recharge in the wet season but also the effects of groundwater loss in the dry season the active storage g act which represents the fluctuation range of groundwater in a year shows a similar correlation with precipitation to g high since g act largely depends on g high moreover the catchments with higher mean annual precipitation are generally found to have lower inter annual variation in their groundwater storage metrics which could be attributed to the relatively smaller inter annual variation of precipitation and hence of groundwater recharge in the wetter catchments it should be noted that groundwater storage is estimated herein according to the storage discharge relationship for which discharge from groundwater should be observable for catchments when there is no groundwater discharge to the river zero flow period it need not be the case that mean groundwater storage is nil since groundwater storage or level could be too low and thus the linkage between groundwater and surface water is suspended hence strictly speaking the estimated storage is the volume of the underground water store above the level i e the zero flow level triggering zero groundwater discharge to the river nevertheless there is no recorded zero flow in the studied catchments which means that the storage discharge relationships derived are valid for estimating their groundwater storage 4 4 estimated residence time of groundwater fig 8 summarizes the residence time of all studied catchments and the residual ratio of groundwater storage after 90 days and 180 days for all catchments groundwater residence time mrt75 varies between 57 and 111 days when it decreases from g ave to g 75 while mrt99 ranges from 107 to 216 days it is observed that the depletion rate of groundwater declines following the decrease of storage due to the concave nonlinear reservoir relationships see fig 5 it can be seen from fig 8 left that the catchment with the longest mrt75 is not necessarily the one having the longest mrt99 for example the mrt75 of catchment 401013 is the longest 111 days but its mrt99 ranks second among the studied catchments this is not only because of the difference in aquifer properties represented by the parameters in the nonlinear reservoir relationships it is also because the initial g ave and cessation g 75 and g 99 storages used to estimate the mrt are different among the catchments and the absolute changes in groundwater storage during the mrts are not identical it should be noted that mrt herein is estimated based on the storage discharge relationship for an unconfined aquifer in addition the discharge from other sources such as bank storage wetlands and deeper confined aquifers may also contribute to baseflow in the stream which could have distorted the relationships hall 1968 sujono et al 2004 as shown in fig 8 the residual ratio of groundwater storage over 90 days varies among the catchments from 26 to 68 whereas the residual ratio over 180 days ranges from 7 to 52 it is worth noting that catchment 410024 keeps a much higher proportion of groundwater storage than other catchments because of its relatively slower groundwater depletion and if groundwater declines in that catchment from its annual mean 180 days later the groundwater store is still above 52 of its initial amount suggesting a stronger potential for groundwater as a supplementary water source to tackle the challenges of seasonal drought or water deficit 5 conclusions storage and residence time are important features of a groundwater system in shaping its capability to sustain the needs of human society and natural ecosystems these features reflect the compounding effects of regional hydrogeological properties and climate conditions it is challenging however to observe the features directly at the catchment scale based on observed streamflow and chemical hydrographs a framework has been introduced and applied to investigate groundwater storage and residence time for catchments located in a headwater source of the murray darling basin australia the approach is found to be effective and efficient in determining the storage discharge relationship and in investigating the dynamics of groundwater storage the approach shows extensive potential in assessing regional groundwater because the required observational data are more generally available than in situ borehole observations however it is noted that the storage discharge relationship derived is limited to representing the conditions when groundwater storage is above a threshold level i e level with zero discharge to stream hence the storage and residence time estimated is for the unconfined aquifer with water table above the threshold level only but not for the total unconfined and confined storage in a catchment nevertheless the approach can be used to investigate groundwater dynamics in a catchment where there are persistent connections between groundwater and surface water such as occurs in perennial rivers investigating how groundwater flows from aquifer storage into the stream provides important insight into both vulnerabilities to droughts and sustainability of low flows e g uchida et al 2006 spence 2007 kirchner 2009 for eight studied catchments the nonlinear storage discharge relationships found by the tracer aided approach have suggested the vertical heterogeneity of the unconfined aquifers and hence temporally non constant depletion rates of groundwater the disproportional decrease in the depletion rate of groundwater in association with the declines in groundwater storage can be indicated by the parameters in the storage discharge relationships and by metrics like mean residence time and residual ratio for catchments with higher groundwater depletion rate shorter mean residence time or smaller residual ratio after a specified time frame the hydraulic conductivity of the unconfined aquifer could be higher to maintain the physical connectivity between groundwater and surface water the storage discharge relationships obtained in this research can not only be used to estimate groundwater store given known discharge but also to improve hydrogeological model performance in simulating groundwater discharge at the catchment scale as suggested by skaugen and mengistu 2016 furthermore the relationships could be used as a guideline for groundwater extraction constrained by instream flow or environmental flow requirements groundwater can buffer the impacts of climate change on water resource systems as it is less responsive to the changing climate than surface water the linkage between groundwater and climate however is challenging to quantify in this research it is found that the dynamics of groundwater storage are largely in synchronization with the regional climate for all the studied catchments the highest and the active groundwater storages of a year are more closely correlated positively with annual precipitation than is the lowest storage the groundwater storage of the wetter catchments is more responsive to climate than the relatively drier catchments the linkages between groundwater storage and climate found here can be developed further in the future to quantify the impacts of climate change and climate variability on groundwater in the studied catchments and to project groundwater changes under future climate scenarios it warrants stressing that uncertainties exist in the groundwater storage estimation using the approach introduced here the uncertainties could be due to the difference in contributing area of the groundwater system and the surface drainage area the precision of the streamflow and chemical hydrographs and the regression models used to fit the low envelopes more importantly the approach used in this research is more applicable for unregulated catchments for a heavily regulated river the natural flow regime could have been altered and hence have distorted the storage discharge relationships for such cases it is imperative to reproduce the natural streamflow before the method can be used for catchments without an observed chemical hydrograph it is possible to estimate groundwater discharge based on observed streamflow using approaches like digital filters e g lyne and hollick 1979 boughton 1993 eckhardt 2005 zhu et al 2020b with a linear reservoir assumption they are however inapplicable to investigate the groundwater storage discharge relationship for catchments where it is highly nonlinear and cannot be approximated by linear ones credit authorship contribution statement ruirui zhu conceptualization methodology writing original draft hongxing zheng conceptualization writing review editing anthony j jakeman intepreting and editing lu zhang intepreting and editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the research of the first author is supported by the australian government research training program agrtp appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126230 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4507,sustainable groundwater management is becoming increasingly important due to intensifying water deficits around the world which highlights the necessities and challenges to explore the dynamics of groundwater at the catchment scale in this paper a tracer aided approach has been developed and applied to quantify the relationships between groundwater storage and discharge upon which the dynamics of groundwater storage and its residence time are assessed robust nonlinear storage discharge relationships are found for the eight studied catchments located in a headwater region of the murray darling basin australia the dynamics of groundwater storage for all the studied catchments largely show synchronization with regional climate the estimated highest and active groundwater storages in a year are more responsive to precipitation than the lowest storages for all the studied catchments during dry seasons without recharge the depletion rate of groundwater is found to decrease with the decline in groundwater storage which can be ascribed to the vertical heterogeneity of their unconfined aquifers the mean residence time of groundwater represented by mrt75 i e time taken for groundwater storage to diminish from its mean level to the 75th percentile varies between 57 and 111 days across the studied catchments suggesting considerable hydrogeological differences among the studied catchments the groundwater dynamics observed in this research could contribute to improving hydrogeological model performance in simulating the connection between groundwater and surface water at the catchment scale moreover the findings could serve to develop guidelines for groundwater extraction when considering the constraints of environmental flow requirements keywords groundwater storage residence time chemical tracer murray darling basin 1 introduction groundwater is a fundamental component of the hydrological cycle and plays a critical role in sustaining water supplies to both socio economic systems and terrestrial ecosystems because of its widespread availability generally high quality and intrinsic ability to buffer the impacts of episodic drought and climate variability fan et al 2013 gleeson et al 2016 jakeman et al 2016 cuthbert et al 2019 as a result of increasing water demand and changing climate groundwater has been found to be declining in many regions around the world scanlon et al 2012 russo and lall 2017 bijl et al 2018 unesco 2018 which has led to reduced groundwater discharge into streams and subsequently weakened the hydrological connections between surface water and groundwater systems mair and fares 2010 andermann et al 2012 mukherjee et al 2018 for sustainable groundwater management such as that proposed in the australian national groundwater strategic framework 2016 2026 commonwealth of australia 2017 one of the essential but challenging hydrogeological missions is to track the dynamics and residence time of groundwater storage spence 2010 thomas et al 2016 the most straightforward approach to assess the amount of water stored underground arguably is based on in situ borehole observations although in situ groundwater observation provides the tangible water level of an aquifer it is limited to the plot scale and comes with high cost hector et al 2015 barthel and banzhaf 2016 on the other hand the remote sensing approach based on grace gravity recovery and climate experiment satellite data can be valuable in monitoring groundwater storage dynamics at regional to global scales but its spatial temporal resolution is rather coarse richey et al 2015 rodell et al 2018 thomas and famiglietti 2019 most often the remote sensing approach is more capable of quantifying the variation or anomalies of groundwater storage rather than the magnitude of storage volume furthermore as the temporal gravity data from grace itself does not provide direct observation of groundwater storage the remote sensing approach requires one to explore the relationship between temporal gravity changes and groundwater storage variations watkins et al 2015 scanlon et al 2018 which could lead to uncertainties in the estimated groundwater anomalies at a catchment scale groundwater storage usually is estimated as a component of catchment water balance analysis by using conceptual or process based hydrological models siebert 2010 birkel et al 2011 bhanja et al 2018 li et al 2019 the water balance approach has shown strength in providing a sensible estimation of groundwater storage for catchment totals but with uncertainties from model assumptions and model calibration alternatively for a gauged catchment groundwater storage can be estimated from the observed daily stream hydrograph based on hydraulic groundwater theory sánchez murillo et al 2015 thomas et al 2015a 2015b buttle 2018 the hydrograph based approach has been widely recognized as an effective and efficient method for catchment scale groundwater storage estimation because streamflow records are extensively available stewart 2015 fan et al 2019 meriö et al 2019 ploum et al 2019 for instance under the linear reservoir assumption for the groundwater system the temporal changes in watershed storage estimated from streamflow records have been investigated for catchments in the u s brutsaert 2008 and australia zhang et al 2014 thus thomas et al 2016 found for catchments in the southeastern u s that storage trend estimated using in situ groundwater level observations are consistent with those from the hydrograph based approach the core of the hydrograph based approach in estimating groundwater storage is to determine the relationship between groundwater storage and groundwater discharge or baseflow which commonly assumes that groundwater can be represented as a linear or nonlinear reservoir brutsaert and hiyama 2012 troch 2013 bart and tague 2017 jachens et al 2020 for example kirchner 2009 found a power law functional relationship existing between groundwater storage and discharge inferred directly from the streamflow observations the recession parameters e g recession constants of the linear or nonlinear reservoir can be derived from hydrograph recession sections but can be substantially misrepresented resulting in uncertainties in groundwater storage estimation if the recession flow is not just from the underground aquifer but also includes drainage from bank storage and other surface water stores the estimation could be improved if the hydrograph of baseflow rather than that of total streamflow is used to determine the parameters in the functional relationship e g stewart 2015 in this study we aim to estimate catchment scale groundwater storage as well as its residence time with the aid of chemical hydrographs the chemical observations specific electrical conductance are used to estimate groundwater discharge i e baseflow in the stream the estimated groundwater discharge is then used to determine the parameters in the functional relationship between groundwater storage and discharge upon which storage and residence time of groundwater are calculated the approach is tested on eight headwater catchments within the domain of the murray darling basin in australia to demonstrate its capabilities and limitations for catchment scale groundwater storage estimation this study is expected to contribute to improving hydrogeological model conceptualization and more accurate quantification of the connections between groundwater and surface water in the studied catchments 2 study area and data eight unregulated catchments in a headwater region of the murray darling basin mdb are selected for this study fig 1 the area of the eight selected catchments ranges from 130 km2 to 1519 km2 table 1 boundaries of the groundwater and surface water catchments are largely the same gmw 2014 groundwater plays an important role in sustaining the river system and is highly connected with surface water for all studied catchments the hydrogeology in all studied catchments is dominated by small shallow confined fractured rock aquifers in a range of different geologies including palaeozoic or mesozoic granites volcanic and consolidated sediments groundwater levels in the fractured rock aquifers of the region show a broad correlation with long term climate groundwater levels and flow in the bedrock aquifer are likely to mirror topography and flow systems are generally short in length recharge to the fractured rock systems flows through the fractures and follows the gradient of the river valley eventually flowing locally towards the adjacent rivers and valley floors in line with the topography csiro 2008 where discharge occurs it is typically in valley bottoms where the water table is close to the land surface at breaks of slope or where faults and fissures in the rock appear at the surface the selected catchments are considered unregulated as there is no significant human control or diversion of streamflow in the catchments as defined and identified by the state government water agency in australia csiro 2008 zhang et al 2014 for the study daily streamflow and specific electrical conductance data were collected from the state water agencies key statistics of the hydroclimatic variables are summarized in table 1 for water years 2000 2019 the mean annual precipitation of the selected catchments varies between 856 mm and 1189 mm while mean annual potential evapotranspiration is around 1170 mm precipitation of the selected catchments is winter dominated and mainly in the form of rainfall as the minimum daily mean temperatures are all above 0 c 3 methodology 3 1 tracer aided groundwater discharge estimation the underlying principle of tracer aided groundwater discharge estimation is the mass conservation law which assumes that the composition or chemical signature of water coming from various sources is constant and unique different from each other and that conservation of mass applies to the water quantities and water quality including conservative mixing of different water components e g kronholm and capel 2016 smith and capel 2018 hence the tracer aided approach for groundwater discharge estimation is also known as the chemical mass balance approach stewart et al 2007 li et al 2014 miller et al 2015 lott and stewart 2016 where the specific electrical conductance is a measure of theconservative chemical constituent i e total ionic concentration in the streamflow and one of the most widely used stable chemical tracers due to its cost effective merit mccarthy and johnson 2009 ali et al 2010 sanford et al 2012 cano paoli et al 2019 according to the chemical mass balance principle the tracer aided groundwater discharge estimation can be expressed as pinder and jones 1969 1 qg q sc sc s sc g sc s where qg is the groundwater discharge from the aquifer to stream q is total streamflow sc is the measured daily mean specific electrical conductance of streamflow sc s is the specific electrical conductance of the surface runoff end member and sc g is the specific electrical conductance of the groundwater discharge end member q and sc are both measured variables while sc s and sc g can be derived from sc accordingly in general the surface runoff conductivity sc s is considered equal to the lowest streamflow conductivity and is kept constant for the studied catchment in contrast sc g shows a significant intra annual variation because of the seasonal replenishment of groundwater to alleviate the impacts of outliers in measured sc as proposed by sanford et al 2012 the daily sc with nonexceedance probability of 99 for a specific calendar month is assumed to be the sc g of the first day in that month the daily sc g is then estimated by linear interpolation between the twelve values for the first day of each month the inter annual variation of sc g is assumed to be negligible as compared against the intra annual variation under these definitions of sc g there is 1 of days that could have qg greater than measured q for which qg is set equal to total streamflow e g miller et al 2014 it should be noted that application of the chemical mass balance cmb approach assumes that a streamflow from other sources e g snowmelt or irrigation is negligible b sc s does not change during the period of record and c sc s and sc g are significantly different from one other e g sklash and farvolden 1979 stewart et al 2007 3 2 determining relationships between groundwater storage and discharge the outflow from an unconfined aquifer that is sitting on a horizontal impermeable layer into a fully penetrating stream channel can be described by the well known boussinesq equation boussinesq 1877 making use of the dupuit assumptions and neglecting the effect of capillarity above the water table dupuit 1863 based on different assumptions and simplications several theoretical solutions to the boussinesq equation are available e g boussinesq 1903 1904 polubarinova kochina 1962 the solutions have provided a physical basis for the power law relationship between groundwater storage and discharge that is widely used in modelling hydrological systems the relation is expressed as horton 1941 brutsaert and nieber 1977 tallaksen 1995 wittenberg 1999 2 g μ qg v where g is the groundwater storage in the upstream aquifer spreading over the catchment area parameters μ and ν depend on the area porosity hydraulic conductivity and morphometric properties of the catchment brutsaert and nieber 1977 for example when ν 1 it is assumed that the groundwater system can be considered as a linear reservoir according to 3 μ φ a 2 p π k d l 2 where k is the hydraulic conductivity lt 1 φ is the drainable porosity p is the average fraction of the vertical aquifer thickness d l occupied by flowing water 0 p 1 l is the length of the drainage network l and a is catchment area l2 according to eq 2 the challenge in assessing groundwater storage given known discharge is to determine the parameters μ and ν the two parameters are not practically measurable but could be derived according to the recession characteristics of groundwater discharge wittenberg 1999 under low flow or drought flow conditions when there is little impact of precipitation and no recharge to the aquifer the water balance of the groundwater system can be expressed as 4 dg dt q g where t is time substituting eq 2 into eq 4 one obtains a power law relationship reflecting the flow recession process 5 dqg dt 1 μ ν qg 2 v α qg β where parameter α 1 μ ν is a function of the hydraulic properties of the system the parameter β 2 v determines the shape of the storage discharge function and allows for both linear β 1 hence v 1 and nonlinear β 1 hence v 1 storage discharge relationships both parameters α and β determine the recession rate of the flow the higher the values of both parameters α and β the quicker is the recession rate it is clear that if parameters α and β in eq 5 can be estimated given groundwater discharge time series during recession periods the relationship between groundwater storage and discharge eq 2 can then be determined to calculate parameters α and β we can rewrite eq 5 in its difference form as 6 qg t qg t 1 δ t α qg t qg t 1 2 β let δ t 1 d a y δ qg t qg t qg t 1 and qg t qg t qg t 1 2 hence parameters α and β can be estimated by linear regression between the time series of log δ qg t and log qg t expressed as 7 log δ qg t log α β l o g qg t to determine parameters α and β on the basis of the estimated groundwater discharge time series using the tracer aided approach then for a catchment with an area of a km2 we adopt the following criteria to retrieve the paired data points δ qg t qg t from the recession period a the recession begins at τ 0 827 a 0 2 days following a precipitation recharge event linsley et al 1975 and b data points with positive or zero δ qg t values are considered as anomalies and eliminated in principle all paired data points from the recession periods can be used in the regression analysis for a robust estimation as suggested by brutsaert and nieber 1977 data points at the lower envelope of all the paired points are used to estimate the parameters α and β where the position of the lower envelope is defined by δ qg t with exceedance probability of 90 of the data point cloud within a specified interval of qg t in the δ qg t qg t scatterplots troch et al 1993 malvicini et al 2005 rupp and selker 2006 stoelzle et al 2013 3 3 estimating mean residence time of groundwater mean residence time mrt of groundwater measures the duration of water retained underground or how rapidly groundwater storage depletes without further replenishment it is an important indicator reflecting the hydrogeological properties of the aquifer that shapes the connection between the groundwater system and surface water wolock et al 1989 zhu et al 2010 lapworth et al 2013 stoelzle et al 2013 the shorter the mrt the quicker is the depletion of groundwater with the estimated parameters μ and ν the mrt of groundwater can be determined by combining eq 2 and eq 4 i e 8 mrt μ ln g 0 ln g mrt f o r v 1 μ 1 v g 0 1 1 v g mrt 1 1 v 1 1 v f o r v 1 where g 0 and g mrt are groundwater storage at the initial time t 0 and mrt days after respectively according to eq 8 it can be seen that for a catchment meeting the linear reservoir v 1 assumption mrt μ holds when g 0 g mrt e which suggests that μ equals the e folding time for a nonlinear reservoir v 1 and if the depletion of groundwater is above the threshold value μ i e both g 0 and g mrt are higher than μ it can be derived that the estimated mrt would be shorter than that from the linear reservoir assumption and vice versa herein we set g 0 to be the median of the yearly mean groundwater storage g ave series while g mrt is set to be the medians of the yearly g 75 and g 99 i e 75th and 99th percentiles of groundwater storage at the lower end in a year series respectively hence mrt75 and mrt99 represent the mean duration of groundwater storage decrease from g ave to g 75 and to g 99 correspondingly inversely rewriting eq 8 we can estimate the volume of groundwater storage n days after the specified initial storage which is given as 9 g t g 0 e t μ f o r v 1 g 0 1 1 v 1 1 v μ 1 v t v v 1 f o r v 1 eq 9 can be used to calculate the residual ratio g t g 0 of groundwater in a specified duration where g 0 is the median of the yearly mean groundwater storage g ave series the residual ratio is a substitute for residence time generally for a groundwater system with a smaller depletion rate it has longer residence time and higher residual ratio after a specified time frame herein we estimate the residual ratios of groundwater at t 90 days and t 180 days respectively 4 results and discussion 4 1 tracer aided estimates of groundwater discharge fig 2 shows the specific electrical conductance of surface flow and groundwater discharge for each month which is used in eq 1 to estimate groundwater discharge it is found that the specific electrical conductance of groundwater discharge sc g fluctuates seasonally in a year which indicates the intra annual variation of groundwater storage within a year the maximum specific electrical conductance occurs in february or march which is the dry season in the region and when the streamflow is mainly from groundwater discharge meanwhile the minimum specific electrical conductance occurs in august or september which corresponds to the wet season indicating that groundwater is replenished due to rainfall events the ratio of the variation i e max min in sc g is around 1 40 2 25 among the studied catchments catchments 401012 and 401013 have the highest variation ratios indicating that they have stronger recharge effects from the rainfall events and where groundwater storage could be renewed much more quickly by recharge from rainfall as shown in fig 2 the specific electrical conductance of surface flow sc s is around 4 15 36 20 among the studied catchments the substantial spatial difference of sc s could be caused by catchment properties like catchment area geological texture soil types land use and land cover conditions that may affect the rainfall runoff processes and chemical load in the surface flow the estimated groundwater discharge based on eq 1 for the studied catchments is shown in fig 3 the ratio of groundwater discharge to total streamflow baseflow index bfi ranges from 0 58 to 0 65 among the catchments catchment 401013 has the highest bfi which suggests groundwater plays a more important role than in our other catchments in sustaining the river system and that there is a stronger connection between groundwater and surface water the inter annual variation of annual total groundwater discharge over the period 2000 2019 as represented by the coefficient of variation cv sd mean ranges from 0 52 to 0 77 among the studied catchments which is relatively smaller than that of the total streamflow with cv ranging from 0 52 to 1 0 the smaller inter annual variation of groundwater discharge implies the buffering effects of the groundwater store it is reckoned that the lower the variation of groundwater discharge the stronger the groundwater store is in buffering the variation of its climate drivers it is worth noticing that the specific electrical conductance of both surface flow and groundwater flow are the two critical parameters to separate groundwater discharge from the observed daily streamflow however measurements of the two parameters are not directly available which is the most critical limitation of the approach the two parameters though can be determined based on empirical assumptions developed and suggested by a few researchers e g sanford et al 2012 miller et al 2014 it is valuable to undertake a rationality check by comparing the results to that derived from other approaches in the study herein the estimated ratio of groundwater discharge to total runoff has been checked and found largely consistent with previous research zhu et al 2020b where groundwater discharge was estimated by digital filter approaches 4 2 relationship between groundwater storage and discharge the recession characteristics of groundwater discharge estimated based on the tracer aided approach are the foundation to determine the storage discharge relationship of each studied catchment fig 4 demonstrates the relationship between δ q g and qg for each studied catchment using data points from the recession part of the flow regime lower envelopes are fitted to the data points positioned at the 90th percentiles of δ q g in a specified qg interval the fitted lower envelopes of the data points reveal that the nonlinear relationships between δ q g and qg approximately follow the power law among the studied catchments the exponents β of the power functions are in the range of 1 04 1 54 whereas the intercepts α vary from 0 01 to 0 03 for the studied catchments the estimated β of the studied catchments are all in the physically reasonable range 1 β 3 as reported in the literature e g brutsaert and nieber 1977 palmroth et al 2010 shaw and riha 2012 stoelzle et al 2013 the catchments with an exponent β close to one e g 401013 suggest the relationships between δ q g and qg are approximately linear the catchments with higher values of either α and β e g 401008 and 401017 suggest a quicker declining rate of groundwater discharge during periods without recharge events fig 5 it should be noted however that the recession rate of groundwater discharge is concurrently determined by both α and β and so an isolated comparison of α or β values among different catchments could be ill advised with the estimated parameters α and β the relationship between groundwater storage and discharge is determined according to eq 2 where the parameters μ 1 α v and v 2 β the estimated μ and v of the studied catchments are listed in table 2 and the nonlinear relationships between groundwater storage and discharge are shown in fig 5 the nonlinear relationships suggest that aquifer porosity and permeability of the studied catchments all decrease disproportionately with depth and hence the drainage network could shrink and decelerate groundwater discharge preserving storage and prolonging the recession as the groundwater table falls fan et al 2019 the nonlinear storage discharge relationships of the studied catchments are all seen to be concave which means the retention capability of the aquifer is smaller when storage is high but increases continuously with the depletion of storage wittenberg 1994 the parameter μ indicates the amount of groundwater storage when groundwater discharge is of one unit i e qg 1 hence a catchment with a smaller μ e g 401008 means that the specific yield of its aquifer is smaller than catchments with a higher value of the parameter μ e g 410057 and 410024 for instance if the groundwater discharge is 1 mm in both catchments 401008 and 410057 the corresponding storages of them are 35 5 mm and 93 1 mm respectively however the specific yield of an aquifer does not increase linearly with increase in storage but is shaped by the parameter v which could reflect the vertical heterogeneity of the saturated hydraulic conductivity kirchner 2009 the catchments with parameter v closer to 1 0 e g 401013 imply stronger vertical homogeneity in saturated hydraulic conductivity and hence approximately conform to the behavior of a linear reservoir than the other catchments for a catchment with a smaller parameter v e g 410024 the corresponding increase in mean specific yield of the aquifer accompanied with a proportional increase of groundwater storage would be larger than catchments with higher v values as illustrated in fig 5 if qg is doubled for catchments 410024 and 401013 for example the corresponding proportional increase in their storages should be around 137 and 198 respectively 4 3 estimated groundwater storage based on the storage discharge relationships and the estimated groundwater discharge from the tracer aided approach the dynamics of groundwater storage at the catchment scale for the studied catchments are derived according to eq 2 as shown in fig 6 intra annually groundwater storages of all studied catchments generally reach their highest level in winter or early spring from around august to september rapidly recede during summer and then continue to be low level in autumn this is mainly because precipitation of the studied catchments is winter dominated where the higher precipitation in the winter together with lower temperature hence lower evaporation loss contribute to most water recharging into the aquifers in a year gmw 2014 zhu et al 2020a 2020b in the summer however higher potential evapotranspiration together with lower precipitation lead to a large evapotranspiration loss and little recharge into the aquifers hence lower groundwater level and storage volume fig 7 left panel summarizes the statistics of groundwater in each catchment over the period 2000 2019 where the probability distributions of the lowest g low average g ave the highest g high and the active g act storage i e the difference between the highest and the lowest storage in a year are represented in the boxplots it is found that groundwater storage varies substantially among the studied catchments for instance the lowest groundwater storage g low in a year ranges from 0 4 mm catchment 401008 to 21 6 mm catchment 401012 while the highest groundwater storage g high in a year ranges from 66 mm to 219 mm the spatial difference in groundwater storage could be attributed to the heterogeneities in climatic and hydrogeological conditions generally as shown in fig 7 right panel except for g low all the other three groundwater storage metrics i e g high g ave and g act display good positive correlation at a significance level of 0 05 with annual precipitation but weakly correlate with annual potential evapotranspiration the stronger correlations found between g high and precipitation than those between g low and precipitation imply that g high is more responsive to precipitation this is because groundwater storage reaches its highest level in a year mainly due to the accumulated recharge from precipitation the lowest groundwater storage however reflects not only the effects of groundwater recharge in the wet season but also the effects of groundwater loss in the dry season the active storage g act which represents the fluctuation range of groundwater in a year shows a similar correlation with precipitation to g high since g act largely depends on g high moreover the catchments with higher mean annual precipitation are generally found to have lower inter annual variation in their groundwater storage metrics which could be attributed to the relatively smaller inter annual variation of precipitation and hence of groundwater recharge in the wetter catchments it should be noted that groundwater storage is estimated herein according to the storage discharge relationship for which discharge from groundwater should be observable for catchments when there is no groundwater discharge to the river zero flow period it need not be the case that mean groundwater storage is nil since groundwater storage or level could be too low and thus the linkage between groundwater and surface water is suspended hence strictly speaking the estimated storage is the volume of the underground water store above the level i e the zero flow level triggering zero groundwater discharge to the river nevertheless there is no recorded zero flow in the studied catchments which means that the storage discharge relationships derived are valid for estimating their groundwater storage 4 4 estimated residence time of groundwater fig 8 summarizes the residence time of all studied catchments and the residual ratio of groundwater storage after 90 days and 180 days for all catchments groundwater residence time mrt75 varies between 57 and 111 days when it decreases from g ave to g 75 while mrt99 ranges from 107 to 216 days it is observed that the depletion rate of groundwater declines following the decrease of storage due to the concave nonlinear reservoir relationships see fig 5 it can be seen from fig 8 left that the catchment with the longest mrt75 is not necessarily the one having the longest mrt99 for example the mrt75 of catchment 401013 is the longest 111 days but its mrt99 ranks second among the studied catchments this is not only because of the difference in aquifer properties represented by the parameters in the nonlinear reservoir relationships it is also because the initial g ave and cessation g 75 and g 99 storages used to estimate the mrt are different among the catchments and the absolute changes in groundwater storage during the mrts are not identical it should be noted that mrt herein is estimated based on the storage discharge relationship for an unconfined aquifer in addition the discharge from other sources such as bank storage wetlands and deeper confined aquifers may also contribute to baseflow in the stream which could have distorted the relationships hall 1968 sujono et al 2004 as shown in fig 8 the residual ratio of groundwater storage over 90 days varies among the catchments from 26 to 68 whereas the residual ratio over 180 days ranges from 7 to 52 it is worth noting that catchment 410024 keeps a much higher proportion of groundwater storage than other catchments because of its relatively slower groundwater depletion and if groundwater declines in that catchment from its annual mean 180 days later the groundwater store is still above 52 of its initial amount suggesting a stronger potential for groundwater as a supplementary water source to tackle the challenges of seasonal drought or water deficit 5 conclusions storage and residence time are important features of a groundwater system in shaping its capability to sustain the needs of human society and natural ecosystems these features reflect the compounding effects of regional hydrogeological properties and climate conditions it is challenging however to observe the features directly at the catchment scale based on observed streamflow and chemical hydrographs a framework has been introduced and applied to investigate groundwater storage and residence time for catchments located in a headwater source of the murray darling basin australia the approach is found to be effective and efficient in determining the storage discharge relationship and in investigating the dynamics of groundwater storage the approach shows extensive potential in assessing regional groundwater because the required observational data are more generally available than in situ borehole observations however it is noted that the storage discharge relationship derived is limited to representing the conditions when groundwater storage is above a threshold level i e level with zero discharge to stream hence the storage and residence time estimated is for the unconfined aquifer with water table above the threshold level only but not for the total unconfined and confined storage in a catchment nevertheless the approach can be used to investigate groundwater dynamics in a catchment where there are persistent connections between groundwater and surface water such as occurs in perennial rivers investigating how groundwater flows from aquifer storage into the stream provides important insight into both vulnerabilities to droughts and sustainability of low flows e g uchida et al 2006 spence 2007 kirchner 2009 for eight studied catchments the nonlinear storage discharge relationships found by the tracer aided approach have suggested the vertical heterogeneity of the unconfined aquifers and hence temporally non constant depletion rates of groundwater the disproportional decrease in the depletion rate of groundwater in association with the declines in groundwater storage can be indicated by the parameters in the storage discharge relationships and by metrics like mean residence time and residual ratio for catchments with higher groundwater depletion rate shorter mean residence time or smaller residual ratio after a specified time frame the hydraulic conductivity of the unconfined aquifer could be higher to maintain the physical connectivity between groundwater and surface water the storage discharge relationships obtained in this research can not only be used to estimate groundwater store given known discharge but also to improve hydrogeological model performance in simulating groundwater discharge at the catchment scale as suggested by skaugen and mengistu 2016 furthermore the relationships could be used as a guideline for groundwater extraction constrained by instream flow or environmental flow requirements groundwater can buffer the impacts of climate change on water resource systems as it is less responsive to the changing climate than surface water the linkage between groundwater and climate however is challenging to quantify in this research it is found that the dynamics of groundwater storage are largely in synchronization with the regional climate for all the studied catchments the highest and the active groundwater storages of a year are more closely correlated positively with annual precipitation than is the lowest storage the groundwater storage of the wetter catchments is more responsive to climate than the relatively drier catchments the linkages between groundwater storage and climate found here can be developed further in the future to quantify the impacts of climate change and climate variability on groundwater in the studied catchments and to project groundwater changes under future climate scenarios it warrants stressing that uncertainties exist in the groundwater storage estimation using the approach introduced here the uncertainties could be due to the difference in contributing area of the groundwater system and the surface drainage area the precision of the streamflow and chemical hydrographs and the regression models used to fit the low envelopes more importantly the approach used in this research is more applicable for unregulated catchments for a heavily regulated river the natural flow regime could have been altered and hence have distorted the storage discharge relationships for such cases it is imperative to reproduce the natural streamflow before the method can be used for catchments without an observed chemical hydrograph it is possible to estimate groundwater discharge based on observed streamflow using approaches like digital filters e g lyne and hollick 1979 boughton 1993 eckhardt 2005 zhu et al 2020b with a linear reservoir assumption they are however inapplicable to investigate the groundwater storage discharge relationship for catchments where it is highly nonlinear and cannot be approximated by linear ones credit authorship contribution statement ruirui zhu conceptualization methodology writing original draft hongxing zheng conceptualization writing review editing anthony j jakeman intepreting and editing lu zhang intepreting and editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the research of the first author is supported by the australian government research training program agrtp appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126230 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4508,laboratory experiments examined how the hydrodynamic interaction between neighboring patches of model vegetation impacted deposition and the potential for patch expansion the evolution of the vegetated region was modeled experimentally by introducing new artificial vegetation into regions of enhanced deposition the study began with a pair of side by side circular patches each of diameter d 10 5 cm constructed from circular cylinders d 3 2 mm that extended through the flow depth the interaction between the patches generated a zone of enhanced deposition on the centerline between the patches and this zone had a much greater longitudinal extent than the region of enhanced deposition formed behind an individual patch this suggested that the interaction between patches could enhance streamwise growth in addition deposition on the centerline eventually led to the merger of the two adjacent patches a mechanism for lateral patch growth finally regions of diminished velocity on the outside edge of the patch pair were observed to enhance deposition over a lateral distance of 0 5d these observations of lateral growth stand in contrast to previous descriptions of vegetation flow interaction that emphasize negative feedbacks for lateral growth and positive feedbacks only for streamwise growth although lateral growth was observed the tendency for enhanced deposition growth extended much farther in the streamwise direction 40d than in the lateral direction 0 5d such that vegetation expansion was dominated by streamwise growth keywords aquatic vegetation flow vegetation feedback landscape evolution 1 introduction vegetation is common in aquatic systems and provides several benefits it improves water quality through nutrient uptake and oxygen production wilcock et al 1999 schulz et al 2003 it also stabilizes banks binds soil and protects against erosion and slumping lawler 2008 wang et al 2009 pollen bankhead and simon 2010 the stabilization provided by vegetation plays a role in the formation of single thread tal and paola 2007 and meandering braudrick et al 2009 channels vegetation also promotes habitat diversity by providing a source of organic matter producing shade and shelter buffering temperature and creating habitat for fish crowder and diplas 2000 2002 kemp et al 2000 recent studies have shown that the interaction between biological and physical processes called biogeomorphic feedback plays a role in the evolution of vegetated aquatic landscape sand jensen 1998 corenblit et al 2007 murray et al 2008 larsen and harvey 2011 physically the presence of vegetation modifies the velocity field creating new patterns that can induce either positive feedbacks such as stress reduction and accumulation of nutrients or negative feedbacks such as stress enhancement and depletion of nutrients schoelynck et al 2012 for example flow approaching a patch of emergent vegetation is partially diverted to the side accelerating around the patch and partially passes through the patch chen et al 2012 previous studies suggest that the accelerated flow at the patch edge can both reduce sediment deposition and erode the channel inhibiting the expansion of the patch in the lateral direction bouma et al 2009 bennett et al 2008 follett and nepf 2012 which is considered a negative feedback in contrast the reduced velocity in the wake of the patch provides a positive feedback by allowing sediment deposition and providing shelter for the establishment of new seedlings encouraging new vegetation growth in the streamwise direction tsujimoto 1999 chen et al 2012 consequently vegetation can create local patterns of deposition and erosion producing a bed morphology that is distinct from that observed in open channels without vegetation for example sand jensen 1998 noted that within dense patches of callitriche cophocarpa and elodea canadensis the channel bed was both elevated and enriched with fine organic particles in addition a shift from migrating sand dunes to stationary bed forms scour holes around individual plants was observed after juncus effusus and scirpus atrovirens were planted on a point bar in a meandering channel see figure 8 in nepf 2012 similarly near a patch of model emergent vegetation the normal sand bed pattern of ripples and dunes was replaced by a scour and deposition pattern created by the patch see fig 6 in follett and nepf 2012 vandenbruwaene et al 2011 noted that in the initial phases of growth vegetation often develops from individual patches the authors presented a sequence of aerial photographs of an intertidal landscape in which distinct patches of vegetation grew and merged over a timespan of seven years see fig 1 in the authors work similarly through aerial photographs recorded over several years callaway and josselyn 1992 and schwarz et al 2016 both observed the merger of initially distinct patches of marsh vegetation in two river reaches in the uk cotton et al 2006 studied the seasonal growth of ranunculus and its impact on flow and sediment deposition in one of the reaches the vegetation coverage maintained discrete patches through the growing season while in the other reach ranunculus coverage was so complete that individual stands could not be discerned these studies suggest that the development of vegetated regions include phases within which initially separated patches grow and interact and in some cases merge the goal of this study was to illustrate a mechanism for patch merger a mechanism promoting patch merger is needed because previous studies of individual patches have highlighted how flow acceleration at the edges of a patch inhibits sediment deposition and lateral growth which would inhibit a merger event wesenbeeck et al 2008 bouma et al 2007 vandenbruwaene et al 2011 looked for mechanisms governing patch merger by studying the interaction between two adjacent patches constructed from spartina anglica they mimicked growth by increasing the patch diameter and decreasing the gap width between them as the gap width decreased the flow acceleration between the patches increased however when the ratio of patch diameter to gap width reached values between 6 7 and 10 the acceleration between the patches was suppressed and the patches started to act as a single hydrodynamic obstacle this transition could be a precursor to merger because the reduction of velocity in the gap between patches could promote deposition growth and eventual merger meire et al 2014 used measurements of velocity turbulence and deposition around a pair of adjacent artificial patches to identify another potential mechanism for the patch merger the authors identified two zones of diminished velocity and enhanced deposition a primary deposition zone was located directly behind each patch and the length of this zone ld 1 was not impacted by the presence of a neighboring patch that is ld 1 was the same as that observed for isolated model patches of comparable stem density chen et al 2012 the end of the primary deposition zone coincided with a peak in turbulence behind each patch farther downstream a secondary zone of reduced velocity and enhanced deposition was observed on the centerline between the adjacent patches at a distance lm from the patches near this region dye traces revealed that the lateral extent of von kármán vortex streets spanned the merged wakes of the patches which allowed mixing across the gap reducing velocity in the gap between the patches knowing that vegetation growth is encouraged in regions of deposition scott et al 1996 sand jensen 1998 gurnell et al 2001 schoelynck et al 2012 meire et al 2014 hypothesized that if this secondary zone of enhanced deposition were colonized by vegetation the additional drag and flow blockage could further diminish the velocity between the patches possibly leading to a merger of the two patches our laboratory study was designed to test the premise that side by side patches can merge by promoting deposition and new growth along the centerline in their combined wake the experiments started with the configuration studied by meire et al 2014 a pair of adjacent circular patches constructed from rigid circular cylinders representing two vegetation patches fig 1 a after the velocity and deposition were measured new cylinders were added into the regions of the wake where elevated deposition was observed this process was repeated through two cycles of artificial growth after which merging of the two patches was indicated these observations validated meire s premise demonstrating that the hydrodynamic interaction between adjacent patches could promote a cycle of deposition and growth that leads to the merger of the two patches 2 material and methods the experiments were conducted in a 16 m long by 1 2 m wide recirculating flume with a horizontal bed mimicking conditions of water depth and flow velocity found in shallow aquatic systems such as lowland streams sand jensen and pedersen 2008 and intertidal landscapes bouma et al 2009 the water depth h 14 0 2 cm was controlled by a weir at the downstream end of the flume and the volumetric discharge q 970 20 l min was measured by an electromagnetic flow meter siemens sitrans 166f m magflo mag 5000 the depth averaged velocity upstream of the patches was u 0 9 9 0 5 cm s which corresponded to turbulent re 11238 2000 and subcritical fr 0 08 1 flow conditions the initial circular patches of model vegetation had diameter d 10 5 cm much smaller than the flume width so that the walls had no impact on the flow adjacent to the patches follett and nepf 2012 shi et al 2016 the patch reynolds number red ud ν 10 000 indicated fully turbulent wakes the patches were placed 3 3 m downstream from the channel entrance the patches were constructed from circular cylinders of diameter d 3 2 mm representing vegetation stems of emergent reeds and marsh grass leonard and luther 1995 lightbody and nepf 2006 the cylinders were placed in a staggered arrangement the cylinders were emergent extending through the water surface the solid volume fraction occupied by the cylinders was ϕ 10 the frontal area per patch volume was a nd 0 4 cm 1 with n being the number of cylinders per bed area within the patch the flow blockage of each patch was ad 4 2 which is considered a dense patch chen et al 2012 the initial configuration consisted of a pair of side by side patches with 11 5 cm between patch centers such that the gap between the patches was δ 1 cm or δ d 0 1 the initial patches are shown in fig 1a and the spatial layout of the experiment is illustrated by the top view of the channel shown in fig 2 note that patches that occur in the field exhibit a range of orientations which may include the side by side configuration considered here i e see the mosaic of patches in fig 1 of vandenbruwaene et al 2011 but this geometry is not representative of all conditions observed in the field the value of δ d was chosen to fall in the range of strong wake interaction as reported in meire et al 2014 for the initial configuration the pair of patches blocked 18 of the channel the coordinate system was x in the streamwise direction with x 0 at the upstream edge of the patches y in the transverse direction with y 0 at the center of the gap between the patches fig 2 the vertical direction z was positive upward with z 0 at the bed the velocity was measured with a nortek vectrino the position of each velocity measurement is noted with a dot in fig 2a the spacing between velocity measurements was smaller in regions of high velocity gradient and larger in regions of low velocity gradient at each measurement point the longitudinal u transverse v and vertical w components of velocity were recorded at mid depth 7 cm above bed for 360 s at a sampling frequency of 25 hz previous studies in the same flume have shown that the velocity at mid depth provided a reasonable estimate of the depth averaged velocity to within 5 white and nepf 2007 the points that had low values of signal to noise ratio snr 12 correlation corr 70 or amplitude amp 90 were removed in matlab mclelland and nicholas 2000 each instantaneous velocity was decomposed into time average u v w and fluctuating components u v w the turbulent kinetic energy per unit mass was t k e 0 5 u 2 v 2 w 2 with the over bar denoting the time average finally velocity spectra were obtained using welch s method as described in the matlab toolbox the spectra were used to infer the scale of wake turbulence vortex formation behind an obstruction of width l occurs at frequency f described by the strouhal number st fl u 0 for turbulent wakes re u 0 l ν 200 st 0 2 roshko 1961 schewe 1983 here re 104 such that vortices formed by individual patches l d produced a spectral peak at f 0 19 hz vortices formed by the combined patch structure l 2d δ were associated with f 0 09 hz indicating a merged wake in this way the frequency measured in the wake of the patches revealed the length scale of turbulence which in turn revealed whether the hydrodynamic impact of the patches resembled that of two individual patches or a single combined patch structure the following procedure was used to characterize the deposition of fine particles before an experiment the flume was cleaned to remove model sediment accumulated in the previous experiment each experiment was initiated by pouring 600 g of 10 µm spherical particles into the tailbox the glass spheres had a density of 2 5 g cm3 and a settling velocity of ws 0 01 cm s potters industry valley forge pa the particle settling velocity was selected to mimic fine particle and organic matter transport in the field the particle size was not geometrically scaled following the discussion in ortiz et al 2013 the ratio of settling velocity to channel friction velocity u was matched to ratios reported in the field specifically in the lab w s u 0 014 which fell in the range of conditions for fine particles and organic matter in the field w s u 0 002 to 0 3 see ortiz et al 2013 in addition this ratio is similar to previous studies zong and nepf 2010 meire et al 2014 in which clear differences in deposition were observed between the open channel and the regions influenced by model vegetation before being poured into the flume the particles were vigorously mixed with water in small containers the particles were mixed over the flow depth within seconds after entering the flume and they were recirculated with the water through the closed flume system for 4 h the 4 hr duration was selected to be long enough to develop a measurable deposition on the slides but short enough to facilitate multiple runs the net deposition was measured using two types of microscope slides 75 mm 25 mm and 25 mm 25 mm each 1 mm thick dry slides were weighed labeled and placed on the bed of the flume starting 2 1 m upstream of the patches and extending to x 8 0 m each slide position is shown with a dot in fig 2c unfortunately it was not possible to easily place and remove the deposition slides inside the tight arrays of cylinders for this reason there were no measurements of deposition within the patches after 4 h the flow was slowly stopped and the flume was drained some additional deposition occurred during the draining of the flume in an experiment using the same flow depth h 14 cm liu and nepf 2016 measured the additional deposition that occurred during draining and showed that it represented 5 to 12 of the total deposition further the additional deposition during the flume draining was spatially uniform and so did not influence the spatial patterns of deposition after the flume was drained the slides were left to dry for 2 days in the flume the slides were then dried in a 90 c oven for 4 h to remove all moisture and then reweighed the net deposition on each slide wi was calculated by the difference in weight before and after the experiment divided by the slide area replicates of each experiment were made cycle 1 3 replicates cycle 2a 2 replicates cycle 2b 4 replicates the average of the replicate values at each slide position was defined as depi the spatial averaged deposition dep was the average of all depi values a control experiment with no patches was performed with the same flow condition for which the deposition was uniformly distributed in the streamwise direction indicating that the deposition was not supply limited i e loss of sediment to the upstream section did not impact deposition in the downstream section the standard deviation among the 24 control slides sdc represented the degree of heterogeneity within a nominally uniform flow this was used as the baseline against which spatial heterogeneity in the patch cases was compared that is in the patch cases deposition at a point depi needed to differ from the spatial mean deposition dep by more than the standard deviation observed in the control to be considered different from the mean a slide was considered to show enhanced depi dep or diminished depi dep deposition if the average net deposition at a given position depi differed from the spatial averaged net deposition dep by more than the sum of the standard error of the point measurement sei and the standard deviation of the control sdc 1 de p i d e p s e i s d c definition of enhanced deposition new cylinders were added to the wake where 1 indicated enhanced deposition fig 1b showing deposition along the centerline between a pair of patches as in fig 1a illustrates the application of equation 1 the symbols represent the deviation from the spatial average depi dep the grey band represents the range of values in a channel without patches based on the open channel control the symbols that fall outside the grey band indicated either enhanced or diminished deposition relative to the uniform control previous research supports the idea that regions of enhanced deposition lead to regions of vegetation growth edwards et al 1999 cotton et al 2006 gurnell et al 2006 2008 to represent this process in the lab additional cylinders were added within the regions of the wake where enhanced deposition was observed equation 1 representing a cycle of growth after new cylinders were added a new velocity field was measured and new deposition experiments were run this was repeated through two cycles of growth 3 results the results are organized into four sub sections the first describes the flow and deposition associated with the initial configuration of side by side patches called cycle 1 based on the deposition in cycle 1 cylinders were added to create a new distribution of artificial vegetation sub sections 2 and 3 describe the flow and deposition associated with the new vegetation distributions the final sub section considers the correlation between deposition velocity and tke 3 1 cycle 1 side by side patches the time mean streamwise velocity u and net deposition associated with the initial side by side configuration are depicted in fig 2 the velocity decelerated from the free stream value u 0 starting at a distance l 0 d 2 5 0 5 upstream of the patches the deceleration was observed both on the centerline between the patches and in line with each patch fig 2a the length scale of the upstream deceleration was in rough agreement with meire et al 2014 who observed l 0 d 1 8 0 2 for a pair of patches and with rominger and nepf 2011 who observed l 0 d 2 0 0 4 for isolated patches previous measurements suggest that l 0 is not a function of flow blockage ad but only of patch width d similar to bluff bodies rominger and nepf 2011 the similarity in l 0 d between a single patch and a patch pair suggested that the approaching flow sees each patch as a distinct obstruction i e there is no upstream interaction meire et al 2014 a few points of enhanced deposition were observed upstream of the patches within the distance l 0 fig 2 gurnell et al 2001 zong and nepf 2010 and meire et al 2014 also observed enhanced deposition upstream of a patch and attributed it to flow deceleration approaching the patch which diminishes the local bed stress consistent with vandenbruwaene et al 2011 the velocity was enhanced both along the outside edges of the patch pair y d 1 and 1 and in between the patches y 0 fig 2a the enhanced velocity was associated with diminished deposition blue dots in fig 2c which was consistent with the negative feedback described in the introduction directly behind each patch the velocity was diminished resulting in a region of enhanced deposition red dots that extended farther behind the right hand patch fig 2 this asymmetry was attributed to a deflection of the flow exiting the gap toward the left hand patch specifically downstream of the right hand patch the flow deceleration was greater than behind the left hand patch including a region of reverse flow at x d 4 and the flow remained close to zero until x d 5 fig 2a behind the left hand patch fig 2b the re acceleration and increase of tke that occurred at x d 3 was associated with the deflected gap flow the end of the primary deposition zone ld 1 coincided with the point at which the velocity and tke began to increase in the wake of each patch which was consistent with observations of flow and deposition made behind isolated patches chen et al 2012 specifically for the right hand patch ld 1 d 4 5 0 5 for the left hand patch the deflected flow shortened the primary deposition zone to ld 1 d 3 0 0 5 note that a deflection of the flow has also been observed for side by side solid cylinders with a small gap width δ d 0 2 sumner 2010 specifically the flow behind closely spaced cylinders may be laterally deflected resulting in an asymmetric wake structure or may be undeflected resulting in a symmetric wake structure wang et al 2002 sumner 2010 the same two scenarios have been observed here i e on average the flow was deflected as discussed above but in one replicate see section 3 3 and also in meire et al 2014 the flow was not deflected resulting in symmetric wakes behind the two side by side patches according to sumner 2010 this bi stable characteristic is not caused by misalignment of the obstructions but is an instability influenced by turbulent perturbations in the incoming flow on the centerline between the patches y d 0 fig 2a the flow accelerated reaching a maximum of u u 0 1 2 directly behind the patches x d 1 5 this region of enhanced velocity was associated with a region of reduced deposition blue dots that extended from x d 0 to x d 4 fig 2c beyond this point the deposition was enhanced red dots beginning at the distance lm d 4 5 0 5 downstream from the patch which meire et al 2014 defined as the secondary deposition zone importantly the primary deposition zone behind the right hand patch extended far enough ld 1 d 4 5 0 5 downstream to connect with the beginning of the secondary deposition zone lm d 4 5 0 5 the linking of these two deposition zones created the possibility for lateral growth between the patches finally the secondary deposition zone persisted over the full length of the test section x d 22 fig 2c the length scale of turbulence in the wake was inferred from the frequency peaks in the velocity spectra fig 3 to examine the strongest signal the spectra were estimated at the point of maximum tke in the wake x d 10 5 at this position the same frequency peak f 0 09 hz was observed in line with each patch center and also at the centerline between the patches based on the strouhal number st fl u 0 0 2 this frequency corresponded to the length scale of the combined patch structure l 22 cm 2d δ indicating that a single von karman vortex street had formed at the scale of the combined patch wake the formation of a single vortex street as opposed to a vortex street formed separately behind each patch was an indication that the patch wakes had merged consistent with this the lateral velocity profile resembles that of a single patch of width 2d δ figure 9 meire et al 2014 in contrast patches with a larger gap spacing δ d 0 5 generate two distinct vortex streets one behind each patch meire et al 2014 3 2 asymmetric patches cycle 2a new cylinders were added to the region of enhanced deposition observed downstream of the initial side by side patches fig 2 because the study focused on downstream growth no cylinders were added upstream of the patch the resulting distribution of model vegetation is shown in black in fig 4 note that patch merger had not yet occurred and two distinct but asymmetric patches were formed the spatial distribution of velocity turbulence intensity and deposition observed for this phase of artificial growth are shown in fig 4 regions of enhanced deposition were consistent with regions of diminished velocity fig 4 in contrast to the first side by side patch configuration cycle 1 fig 2 there was no acceleration within the gap between the new patches specifically the velocity in the gap was less than u 0 fig 4a this confirmed the conjecture made in meire et al 2014 that growth within the secondary deposition zone would diminish flow between the patches however the velocity through the gap was still sufficient to diminish deposition in the gap the new patch shape black outline directed flow through the gap toward the left so the flow along the left side of the patch was higher up to u u 0 0 7 than that along the right side u u 0 0 3 this velocity difference was sufficient to be reflected in the deposition fig 4c with a wider region of enhanced deposition observed on the right side of the patch downstream of the original right hand patch x d 3 to 8 y d 0 4 to 1 a recirculation zone formed with negative velocity u u 0 0 1 at x d 6 y d 0 8 labeled eddy region in fig 4 this recirculation was associated with the highest deposition specifically at x d 4 5 and y d 1 the deposition reached 2 3 mg cm2 compared to an average deposition of 1 5 mg cm2 a region of low velocity without recirculation formed downstream of the original left hand patch and this region was also a site of enhanced deposition fig 4c x d 3 to 6 and y d 1 importantly the enhanced deposition in this region spanned the gap between the patches indicating that the two patches would merge into a single structure in the next cycle of artificial growth diminished velocity in the wake downstream of the larger patch x d 20 fig 4a was associated with enhanced deposition that extended to x d 40 fig 4c a peak in turbulence was observed directly behind the end of the patch x d 21 which locally offset the influence of diminished velocity to produce several points without enhanced deposition directly behind the patch x d 20 to 22 y d 0 3 3 comparison between symmetric cycle 2a and asymmetric cycle 2b patch growth in one of the three replicate experiments for the initial side by side patch configuration cycle 1 the enhanced deposition was distributed symmetrically around the centerline figure s1 in supporting information taking this as a possible outcome in the field the symmetric configuration was used as a template for a second cycle of artificial growth resulting in the black outline in fig 5 along with the resulting velocity and deposition fields produced by this vegetation distribution not surprisingly the symmetric patch produced symmetric distributions of both velocity fig 5a and tke fig 5b taking advantage of the symmetry deposition was measured on only one side right hand patch the key features in the velocity and deposition will be discussed through comparisons between the symmetric fig 5 and asymmetric fig 4 patches both patches exhibited enhanced deposition in the recirculating eddy downstream from the initial patch positions labeled eddy region in figs 4 and 5 new growth in the recirculating eddy would lengthen the widest part of the patch note that in this region x d 2 to 5 points of enhanced deposition extended laterally from the edge of the patch i e y d δ 2 associated with regions of diminished velocity measured against the patch edge fig 4a c and 5a c for example just past the leading edge x d 1 diminished velocity was observed next to the patch and extending 0 5d from the patch edge u u 0 1 blue dots in fig 4a and 5a this created the possibility for lateral patch expansion vandenbruwaene et al 2011 also observed diminished velocity adjacent to the patch edge and over a similar length scale i e extending 0 5d from the patch edge figures 4 and 7 of their paper these observations are highlighted to emphasize that lateral growth may be possible even at the patch outer edge where previous studies have concluded that high velocity and scour at the patch edge inhibit lateral patch growth e g wesenbeeck et al 2008 here we see in greater detail that the flow deflection that begins upstream of the patch can re direct the high velocity region to a distance 0 5d away from the patch edge x d 1 orange dots fig 4a and 5a providing opportunity for lateral patch growth in addition as flow entering the patch adjusts to the vegetation drag it decelerates which necessitates that some flow exit the patch at the edge for example at position x d 0 5 y d 1 1 of the symmetric case fig 5a the lateral velocity leaving the patch was 3 0 cm s this lateral bleed flow pushed high velocity streamlines further from the patch edge extending the region of lower velocity where deposition can occur the deposition in the wake downstream of the patch differed between the symmetric and asymmetric cases with enhanced deposition extending much farther downstream behind the asymmetric patch over 20d fig 4c than behind the symmetric patch over 1 5d fig 5c for the symmetric patch the end of the wake deposition zone corresponded with the peak turbulence in the wake fig 5b the difference in wake deposition between the asymmetric and symmetric patches was difficult to explain because the velocity and tke had similar magnitudes and evolved in similar ways with distance from the trailing edge y 0 x d 20 further the velocity spectra revealed that both the symmetric and asymmetric patches produced turbulent structures at the scale of the total patch width 2d δ see discussion of velocity spectra in section 3 1 the most important result was that both the asymmetric and symmetric growth led to a deposition pattern with enhanced deposition in the region between the patches indicating that the two patches would merge in the next cycle of artificial growth which confirmed meire s premise we caution that these results are preliminary because only a single initial configuration was considered making generalizations difficult for example considering a wider range of initial patch distributions and a larger number of initial patches numerical simulations have suggested other growth patterns lima et al 2015 yamasaki et al 2019 further note that this experiment considered a single sediment size and deposition will be a function of sediment size 3 4 correlations between deposition velocity and tke the pattern of net deposition observed in the wakes of the patches reflected the dual influences of time mean velocity and turbulence intensity on the one hand the diminished velocity in the wake should promote deposition relative to the free stream on the other hand the enhanced turbulence levels observed in the wake may inhibit deposition it would be useful to understand if the local values of velocity and tke i e measured at a point were sufficient to predict the deposition at that point to this end the net deposition at each point was plotted on a grid defined by the velocity and tke fig 6 the individual points are colored to indicate whether the local net deposition was enhanced red or diminished blue relative to the spatial average deposition as defined by equation 1 the enhanced deposition mapped more closely with velocity that tke that is regardless of the local tke enhanced deposition was observed for all points for which u 0 4u 0 and reduced deposition was observed for all points for which u u 0 across the velocity range of 0 4u 0 to u 0 both enhanced and reduced deposition were observed with little correlation to tke the lack of clear trends within the intermediate velocity range suggested that additional information would be needed to predict the potential for deposition at a given location this may be attributed to particle history which was not captured in this analysis for example particles that recently experienced strong turbulence may be mixed higher in the water column and thus are less available for deposition even after entering a region of lower tke or u consistent with this points of low deposition in regions of low velocity were generally found close to regions of high velocity gradient for example in cycle 2b low deposition blue dots fig 5c was observed along the edge of the eddy y d 1 5 x d 5 to 8 which was a region of low velocity adjacent to a region of high velocity we caution that the velocity limits implied in fig 6 are specific to the particle size considered in this experiment the tendency to deposit will also be a function of sediment size for example shi et al 2016 showed that enhanced deposition within a patch wake relative to adjacent bare channel will only occur when the ratio of channel shear velocity to critical shear falls within a specific range and the critical shear velocity is a function of particle size 4 discussion previous descriptions of vegetation flow interaction identified positive feedbacks only for streamwise patch growth and negative feedbacks for lateral growth e g bouma et al 2007 in contrast this study demonstrated two mechanisms of lateral growth first lateral growth occurred through patches merging meire et al 2014 observed that adjacent patches produce a secondary zone of enhanced deposition on the centerline between the patches they hypothesized that if this secondary zone of enhanced deposition were colonized by vegetation the additional drag and flow blockage on the centerline would diminish velocity between the patches eventually leading to the patches merging our study provided an example of this progression demonstrating this mechanism of lateral growth after two cycles of artificial growth the vegetated regions merged into a single patch second this study measured regions of diminished velocity extending 0 5d from the patch lateral edge similar to observations in vandenbruwaene et al 2011 and these regions were associated with enhanced deposition suggesting the possibility of lateral growth the present experiments considered conditions with patch width small compared to channel width so that the confinement of the walls did not impact the flow around the patches however in natural channels the width of the vegetated region may be large compared to the channel width e g green 2005 and the flow confinement due to the walls will impact the flow around the patches changing the patch evolution from what has been described in this study for this reason it is useful to consider how the patch evolution might be different in wide unconstrained flow versus narrow channel flow conditions in an unbounded domain the patch may progressively but slowly grow wider as diminished velocity will enhance deposition and encourage new growth over the length scale of 0 5d adjacent to the patch confining walls impact this mechanism of lateral growth as the patch width d grows and approaches the channel width b the walls limit the degree of lateral flow deflection around the patch studies of solid obstructions suggest that confining walls impact the flow structure when b 5d e g sahin and owen 2004 the wall confinement would force streamlines closer to the patch diminishing or eliminating the regions of reduced velocity and enhanced deposition at the lateral edge of a patch and thus eliminating the potential for further lateral growth as noted previously e g sand jensen and madsen 1992 and also observed in the present study patches have a strong tendency to grow in the streamwise direction the present study suggested that the interaction between patches enhances this tendency specifically behind a pair of side by side high flow blockage ad 4 patches the secondary deposition zone extended over the distance x d 22 fig 2 this was a much greater length of deposition than observed behind an isolated high flow blockage patch which extended over x d 2 5d e g case 17 figure 12 in chen et al 2012 this can be attributed in part to the wake merger which gives the wake the appearance of being formed behind a structure of size dsp 2d δ in which subscript sp denotes the equivalent single patch see section 3 1 a larger apparent patch size would be expected to produce a longer wake here dsp 22 cm and deposition extended to x dsp 10 5 one must also consider the change in flow blockage using a weighted average of a over the bare and vegetated regions within the equivalent patch asp 2a d dsp 2 0 18 cm 1 the equivalent flow blockage was aspdsp 4 which was similar to the original individual patch value ad 4 2 this indicated that despite having similar flow blockage ad aspdsp the deposition extended farther downstream in units of diameter behind the pair of patches than behind a single isolated patch a possible explanation for this is that the gap between the original patches allowed a stronger bleed flow to enter the wake compared to a patch of uniformly distributed vegetation as the bleed flow into the wake increases the von karman vortex formation occurs farther from the patch zong and nepf 2012 and this lengthens the region of combined low velocity and low turbulence that is favorable to deposition chen et al 2012 the key feature here is that the interaction between adjacent patches produced enhanced deposition over a longer distance than a single patch of comparable total width and flow blockage combining the strong tendency for streamwise growth with the impact of confining walls on lateral growth we cautiously suggest that the patch growth modeled in this study is evolving toward a final state in which a continuous band of vegetation exists along the center of the channel with bare bed regions to either side this landscape would be maintained by the following feedback deflection of flow away from the vegetation band maintains high velocity in the bare region inhibiting growth and maintaining the bare region at the same time the low velocity within the vegetation provides a positive feedback for deposition and continued vegetation growth this is similar to the landscape pattern observed in some wetlands called parallel preferential flow channels which is characterized by open channels separated by long bands of vegetation running parallel to the flow direction larsen and harvey 2011 a similar pattern of extended vegetated regions cut through by long channels has also been observed in tidal landscapes and its formation is similarly attributed to the channel s ability to attract flow away from vegetated regions stabilizing both the channel and the vegetation temmerman et al 2007 kondziolka and nepf 2014 in contrast to the streamwise growth pattern observed here and in some previous studies larsen and harvey 2011 kondziolka and nepf 2014 other studies have noted vegetation distributed into many patches of limited streamwise extent sand jensen and madsen 1992 larsen and harvey 2011 schoelynck et al 2012 cameron et al 2013 in particular sand jensen and madsen 1992 observed a predominance of patches with length l 2 5 d which is shorter than the patch length observed in our study fig 4c and 5c but comparable to the patch length suggested by the deposition pattern observed for an individual patch of l d 2 5 figure 12 ad 9 in chen et al 2012 drawing on similar observations by schnauder and moggridge 2009 chen et al 2012 proposed that the geometry l d 2 5 may be sufficiently streamlined that a patch of this geometry would not produce a wake of sufficient velocity depression to promote downstream deposition such that the patch would have no tendency to lengthen further i e l d 2 5 is a stable patch geometry the difference between the two development scenarios that results either in long patches extending in the streamwise direction large l d or many short patches l d 2 5 may be linked to whether or not the secondary deposition mechanism described in this study occurs which in turn depends on the sediment size and initial patch spacing specifically kondziolka and nepf 2014 used a numerical simulation to show that long patches large l d emerged when the initial patches were close enough for wake merger to occur and the reduction in wake velocity was sufficient to generate deposition within the merged wake the necessary velocity for deposition depends on the sediment size alternatively short patches l d 2 5 emerged if either the initial patch spacing was too great to facilitate wake merger or the merged wake velocity was not sufficiently reduced to facilitate deposition which would depend on particle size kondziolka and nepf 2014 for example in meire et al 2014 a pair of sparse patches ad 2 9 separated by δ d 0 5 produced a merged wake but no secondary zone of deposition because the minimum velocity in the merged wake was not low enough to encourage enhanced net deposition for the particle size used in that study we caution that the secondary region of deposition is only one possible mechanism of patch merging through physical processes and that the present experiments considered a single set of sediment size patch density and flow field the current study did not consider biological processes through which merging could also occur 5 conclusions this paper described an artificial growth experiment which demonstrated the premise that the interaction between wakes of adjacent patches has a positive feedback on both streamwise and lateral growth of the vegetated region first the merging of wakes behind adjacent patches produces a zone of diminished velocity on the centerline between the patches if the velocity is sufficiently reduced as to enhance deposition in this region as observed in this study and encourage new growth as modeled in this study the additional vegetation drag on the centerline diminishes the velocity between the patches eventually leading to patch merger and associated lateral growth our observations suggested that wake interaction also enhances streamwise patch growth compared to a patch in isolation finally regions of diminished velocity were observed to extend laterally 0 5d from the patch edge similar to observations in vandenbruwaene et al 2011 and this region was associated with enhanced deposition suggesting the potential for lateral growth importantly these regions were associated with lateral flow leaving the patch which pushed the higher velocity streamlines farther from the patch as compared to a solid obstruction however as the patch grows and approaches the scale of the channel b d 3 the confinement of flow by the channel walls can force streamlines closer to the patch limiting the potential for lateral growth credit authorship contribution statement taís n yamasaki writing review editing formal analysis beihan jiang formal analysis investigation visualization methodology johannes g janzen formal analysis investigation visualization conceptualization methodology heidi m nepf conceptualization methodology resources funding acquisition supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements taís n yamasaki received funding from cnpq the brazilian national council for scientific and technological development process n 145692 2018 3 and capes coordination for the improvement of higher education personnel process n 88882 458516 2019 01 beihan jiang received funding from china scholarship council johannes janzen received funding from cnpq and capes scholarship and capes print programme appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126232 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4508,laboratory experiments examined how the hydrodynamic interaction between neighboring patches of model vegetation impacted deposition and the potential for patch expansion the evolution of the vegetated region was modeled experimentally by introducing new artificial vegetation into regions of enhanced deposition the study began with a pair of side by side circular patches each of diameter d 10 5 cm constructed from circular cylinders d 3 2 mm that extended through the flow depth the interaction between the patches generated a zone of enhanced deposition on the centerline between the patches and this zone had a much greater longitudinal extent than the region of enhanced deposition formed behind an individual patch this suggested that the interaction between patches could enhance streamwise growth in addition deposition on the centerline eventually led to the merger of the two adjacent patches a mechanism for lateral patch growth finally regions of diminished velocity on the outside edge of the patch pair were observed to enhance deposition over a lateral distance of 0 5d these observations of lateral growth stand in contrast to previous descriptions of vegetation flow interaction that emphasize negative feedbacks for lateral growth and positive feedbacks only for streamwise growth although lateral growth was observed the tendency for enhanced deposition growth extended much farther in the streamwise direction 40d than in the lateral direction 0 5d such that vegetation expansion was dominated by streamwise growth keywords aquatic vegetation flow vegetation feedback landscape evolution 1 introduction vegetation is common in aquatic systems and provides several benefits it improves water quality through nutrient uptake and oxygen production wilcock et al 1999 schulz et al 2003 it also stabilizes banks binds soil and protects against erosion and slumping lawler 2008 wang et al 2009 pollen bankhead and simon 2010 the stabilization provided by vegetation plays a role in the formation of single thread tal and paola 2007 and meandering braudrick et al 2009 channels vegetation also promotes habitat diversity by providing a source of organic matter producing shade and shelter buffering temperature and creating habitat for fish crowder and diplas 2000 2002 kemp et al 2000 recent studies have shown that the interaction between biological and physical processes called biogeomorphic feedback plays a role in the evolution of vegetated aquatic landscape sand jensen 1998 corenblit et al 2007 murray et al 2008 larsen and harvey 2011 physically the presence of vegetation modifies the velocity field creating new patterns that can induce either positive feedbacks such as stress reduction and accumulation of nutrients or negative feedbacks such as stress enhancement and depletion of nutrients schoelynck et al 2012 for example flow approaching a patch of emergent vegetation is partially diverted to the side accelerating around the patch and partially passes through the patch chen et al 2012 previous studies suggest that the accelerated flow at the patch edge can both reduce sediment deposition and erode the channel inhibiting the expansion of the patch in the lateral direction bouma et al 2009 bennett et al 2008 follett and nepf 2012 which is considered a negative feedback in contrast the reduced velocity in the wake of the patch provides a positive feedback by allowing sediment deposition and providing shelter for the establishment of new seedlings encouraging new vegetation growth in the streamwise direction tsujimoto 1999 chen et al 2012 consequently vegetation can create local patterns of deposition and erosion producing a bed morphology that is distinct from that observed in open channels without vegetation for example sand jensen 1998 noted that within dense patches of callitriche cophocarpa and elodea canadensis the channel bed was both elevated and enriched with fine organic particles in addition a shift from migrating sand dunes to stationary bed forms scour holes around individual plants was observed after juncus effusus and scirpus atrovirens were planted on a point bar in a meandering channel see figure 8 in nepf 2012 similarly near a patch of model emergent vegetation the normal sand bed pattern of ripples and dunes was replaced by a scour and deposition pattern created by the patch see fig 6 in follett and nepf 2012 vandenbruwaene et al 2011 noted that in the initial phases of growth vegetation often develops from individual patches the authors presented a sequence of aerial photographs of an intertidal landscape in which distinct patches of vegetation grew and merged over a timespan of seven years see fig 1 in the authors work similarly through aerial photographs recorded over several years callaway and josselyn 1992 and schwarz et al 2016 both observed the merger of initially distinct patches of marsh vegetation in two river reaches in the uk cotton et al 2006 studied the seasonal growth of ranunculus and its impact on flow and sediment deposition in one of the reaches the vegetation coverage maintained discrete patches through the growing season while in the other reach ranunculus coverage was so complete that individual stands could not be discerned these studies suggest that the development of vegetated regions include phases within which initially separated patches grow and interact and in some cases merge the goal of this study was to illustrate a mechanism for patch merger a mechanism promoting patch merger is needed because previous studies of individual patches have highlighted how flow acceleration at the edges of a patch inhibits sediment deposition and lateral growth which would inhibit a merger event wesenbeeck et al 2008 bouma et al 2007 vandenbruwaene et al 2011 looked for mechanisms governing patch merger by studying the interaction between two adjacent patches constructed from spartina anglica they mimicked growth by increasing the patch diameter and decreasing the gap width between them as the gap width decreased the flow acceleration between the patches increased however when the ratio of patch diameter to gap width reached values between 6 7 and 10 the acceleration between the patches was suppressed and the patches started to act as a single hydrodynamic obstacle this transition could be a precursor to merger because the reduction of velocity in the gap between patches could promote deposition growth and eventual merger meire et al 2014 used measurements of velocity turbulence and deposition around a pair of adjacent artificial patches to identify another potential mechanism for the patch merger the authors identified two zones of diminished velocity and enhanced deposition a primary deposition zone was located directly behind each patch and the length of this zone ld 1 was not impacted by the presence of a neighboring patch that is ld 1 was the same as that observed for isolated model patches of comparable stem density chen et al 2012 the end of the primary deposition zone coincided with a peak in turbulence behind each patch farther downstream a secondary zone of reduced velocity and enhanced deposition was observed on the centerline between the adjacent patches at a distance lm from the patches near this region dye traces revealed that the lateral extent of von kármán vortex streets spanned the merged wakes of the patches which allowed mixing across the gap reducing velocity in the gap between the patches knowing that vegetation growth is encouraged in regions of deposition scott et al 1996 sand jensen 1998 gurnell et al 2001 schoelynck et al 2012 meire et al 2014 hypothesized that if this secondary zone of enhanced deposition were colonized by vegetation the additional drag and flow blockage could further diminish the velocity between the patches possibly leading to a merger of the two patches our laboratory study was designed to test the premise that side by side patches can merge by promoting deposition and new growth along the centerline in their combined wake the experiments started with the configuration studied by meire et al 2014 a pair of adjacent circular patches constructed from rigid circular cylinders representing two vegetation patches fig 1 a after the velocity and deposition were measured new cylinders were added into the regions of the wake where elevated deposition was observed this process was repeated through two cycles of artificial growth after which merging of the two patches was indicated these observations validated meire s premise demonstrating that the hydrodynamic interaction between adjacent patches could promote a cycle of deposition and growth that leads to the merger of the two patches 2 material and methods the experiments were conducted in a 16 m long by 1 2 m wide recirculating flume with a horizontal bed mimicking conditions of water depth and flow velocity found in shallow aquatic systems such as lowland streams sand jensen and pedersen 2008 and intertidal landscapes bouma et al 2009 the water depth h 14 0 2 cm was controlled by a weir at the downstream end of the flume and the volumetric discharge q 970 20 l min was measured by an electromagnetic flow meter siemens sitrans 166f m magflo mag 5000 the depth averaged velocity upstream of the patches was u 0 9 9 0 5 cm s which corresponded to turbulent re 11238 2000 and subcritical fr 0 08 1 flow conditions the initial circular patches of model vegetation had diameter d 10 5 cm much smaller than the flume width so that the walls had no impact on the flow adjacent to the patches follett and nepf 2012 shi et al 2016 the patch reynolds number red ud ν 10 000 indicated fully turbulent wakes the patches were placed 3 3 m downstream from the channel entrance the patches were constructed from circular cylinders of diameter d 3 2 mm representing vegetation stems of emergent reeds and marsh grass leonard and luther 1995 lightbody and nepf 2006 the cylinders were placed in a staggered arrangement the cylinders were emergent extending through the water surface the solid volume fraction occupied by the cylinders was ϕ 10 the frontal area per patch volume was a nd 0 4 cm 1 with n being the number of cylinders per bed area within the patch the flow blockage of each patch was ad 4 2 which is considered a dense patch chen et al 2012 the initial configuration consisted of a pair of side by side patches with 11 5 cm between patch centers such that the gap between the patches was δ 1 cm or δ d 0 1 the initial patches are shown in fig 1a and the spatial layout of the experiment is illustrated by the top view of the channel shown in fig 2 note that patches that occur in the field exhibit a range of orientations which may include the side by side configuration considered here i e see the mosaic of patches in fig 1 of vandenbruwaene et al 2011 but this geometry is not representative of all conditions observed in the field the value of δ d was chosen to fall in the range of strong wake interaction as reported in meire et al 2014 for the initial configuration the pair of patches blocked 18 of the channel the coordinate system was x in the streamwise direction with x 0 at the upstream edge of the patches y in the transverse direction with y 0 at the center of the gap between the patches fig 2 the vertical direction z was positive upward with z 0 at the bed the velocity was measured with a nortek vectrino the position of each velocity measurement is noted with a dot in fig 2a the spacing between velocity measurements was smaller in regions of high velocity gradient and larger in regions of low velocity gradient at each measurement point the longitudinal u transverse v and vertical w components of velocity were recorded at mid depth 7 cm above bed for 360 s at a sampling frequency of 25 hz previous studies in the same flume have shown that the velocity at mid depth provided a reasonable estimate of the depth averaged velocity to within 5 white and nepf 2007 the points that had low values of signal to noise ratio snr 12 correlation corr 70 or amplitude amp 90 were removed in matlab mclelland and nicholas 2000 each instantaneous velocity was decomposed into time average u v w and fluctuating components u v w the turbulent kinetic energy per unit mass was t k e 0 5 u 2 v 2 w 2 with the over bar denoting the time average finally velocity spectra were obtained using welch s method as described in the matlab toolbox the spectra were used to infer the scale of wake turbulence vortex formation behind an obstruction of width l occurs at frequency f described by the strouhal number st fl u 0 for turbulent wakes re u 0 l ν 200 st 0 2 roshko 1961 schewe 1983 here re 104 such that vortices formed by individual patches l d produced a spectral peak at f 0 19 hz vortices formed by the combined patch structure l 2d δ were associated with f 0 09 hz indicating a merged wake in this way the frequency measured in the wake of the patches revealed the length scale of turbulence which in turn revealed whether the hydrodynamic impact of the patches resembled that of two individual patches or a single combined patch structure the following procedure was used to characterize the deposition of fine particles before an experiment the flume was cleaned to remove model sediment accumulated in the previous experiment each experiment was initiated by pouring 600 g of 10 µm spherical particles into the tailbox the glass spheres had a density of 2 5 g cm3 and a settling velocity of ws 0 01 cm s potters industry valley forge pa the particle settling velocity was selected to mimic fine particle and organic matter transport in the field the particle size was not geometrically scaled following the discussion in ortiz et al 2013 the ratio of settling velocity to channel friction velocity u was matched to ratios reported in the field specifically in the lab w s u 0 014 which fell in the range of conditions for fine particles and organic matter in the field w s u 0 002 to 0 3 see ortiz et al 2013 in addition this ratio is similar to previous studies zong and nepf 2010 meire et al 2014 in which clear differences in deposition were observed between the open channel and the regions influenced by model vegetation before being poured into the flume the particles were vigorously mixed with water in small containers the particles were mixed over the flow depth within seconds after entering the flume and they were recirculated with the water through the closed flume system for 4 h the 4 hr duration was selected to be long enough to develop a measurable deposition on the slides but short enough to facilitate multiple runs the net deposition was measured using two types of microscope slides 75 mm 25 mm and 25 mm 25 mm each 1 mm thick dry slides were weighed labeled and placed on the bed of the flume starting 2 1 m upstream of the patches and extending to x 8 0 m each slide position is shown with a dot in fig 2c unfortunately it was not possible to easily place and remove the deposition slides inside the tight arrays of cylinders for this reason there were no measurements of deposition within the patches after 4 h the flow was slowly stopped and the flume was drained some additional deposition occurred during the draining of the flume in an experiment using the same flow depth h 14 cm liu and nepf 2016 measured the additional deposition that occurred during draining and showed that it represented 5 to 12 of the total deposition further the additional deposition during the flume draining was spatially uniform and so did not influence the spatial patterns of deposition after the flume was drained the slides were left to dry for 2 days in the flume the slides were then dried in a 90 c oven for 4 h to remove all moisture and then reweighed the net deposition on each slide wi was calculated by the difference in weight before and after the experiment divided by the slide area replicates of each experiment were made cycle 1 3 replicates cycle 2a 2 replicates cycle 2b 4 replicates the average of the replicate values at each slide position was defined as depi the spatial averaged deposition dep was the average of all depi values a control experiment with no patches was performed with the same flow condition for which the deposition was uniformly distributed in the streamwise direction indicating that the deposition was not supply limited i e loss of sediment to the upstream section did not impact deposition in the downstream section the standard deviation among the 24 control slides sdc represented the degree of heterogeneity within a nominally uniform flow this was used as the baseline against which spatial heterogeneity in the patch cases was compared that is in the patch cases deposition at a point depi needed to differ from the spatial mean deposition dep by more than the standard deviation observed in the control to be considered different from the mean a slide was considered to show enhanced depi dep or diminished depi dep deposition if the average net deposition at a given position depi differed from the spatial averaged net deposition dep by more than the sum of the standard error of the point measurement sei and the standard deviation of the control sdc 1 de p i d e p s e i s d c definition of enhanced deposition new cylinders were added to the wake where 1 indicated enhanced deposition fig 1b showing deposition along the centerline between a pair of patches as in fig 1a illustrates the application of equation 1 the symbols represent the deviation from the spatial average depi dep the grey band represents the range of values in a channel without patches based on the open channel control the symbols that fall outside the grey band indicated either enhanced or diminished deposition relative to the uniform control previous research supports the idea that regions of enhanced deposition lead to regions of vegetation growth edwards et al 1999 cotton et al 2006 gurnell et al 2006 2008 to represent this process in the lab additional cylinders were added within the regions of the wake where enhanced deposition was observed equation 1 representing a cycle of growth after new cylinders were added a new velocity field was measured and new deposition experiments were run this was repeated through two cycles of growth 3 results the results are organized into four sub sections the first describes the flow and deposition associated with the initial configuration of side by side patches called cycle 1 based on the deposition in cycle 1 cylinders were added to create a new distribution of artificial vegetation sub sections 2 and 3 describe the flow and deposition associated with the new vegetation distributions the final sub section considers the correlation between deposition velocity and tke 3 1 cycle 1 side by side patches the time mean streamwise velocity u and net deposition associated with the initial side by side configuration are depicted in fig 2 the velocity decelerated from the free stream value u 0 starting at a distance l 0 d 2 5 0 5 upstream of the patches the deceleration was observed both on the centerline between the patches and in line with each patch fig 2a the length scale of the upstream deceleration was in rough agreement with meire et al 2014 who observed l 0 d 1 8 0 2 for a pair of patches and with rominger and nepf 2011 who observed l 0 d 2 0 0 4 for isolated patches previous measurements suggest that l 0 is not a function of flow blockage ad but only of patch width d similar to bluff bodies rominger and nepf 2011 the similarity in l 0 d between a single patch and a patch pair suggested that the approaching flow sees each patch as a distinct obstruction i e there is no upstream interaction meire et al 2014 a few points of enhanced deposition were observed upstream of the patches within the distance l 0 fig 2 gurnell et al 2001 zong and nepf 2010 and meire et al 2014 also observed enhanced deposition upstream of a patch and attributed it to flow deceleration approaching the patch which diminishes the local bed stress consistent with vandenbruwaene et al 2011 the velocity was enhanced both along the outside edges of the patch pair y d 1 and 1 and in between the patches y 0 fig 2a the enhanced velocity was associated with diminished deposition blue dots in fig 2c which was consistent with the negative feedback described in the introduction directly behind each patch the velocity was diminished resulting in a region of enhanced deposition red dots that extended farther behind the right hand patch fig 2 this asymmetry was attributed to a deflection of the flow exiting the gap toward the left hand patch specifically downstream of the right hand patch the flow deceleration was greater than behind the left hand patch including a region of reverse flow at x d 4 and the flow remained close to zero until x d 5 fig 2a behind the left hand patch fig 2b the re acceleration and increase of tke that occurred at x d 3 was associated with the deflected gap flow the end of the primary deposition zone ld 1 coincided with the point at which the velocity and tke began to increase in the wake of each patch which was consistent with observations of flow and deposition made behind isolated patches chen et al 2012 specifically for the right hand patch ld 1 d 4 5 0 5 for the left hand patch the deflected flow shortened the primary deposition zone to ld 1 d 3 0 0 5 note that a deflection of the flow has also been observed for side by side solid cylinders with a small gap width δ d 0 2 sumner 2010 specifically the flow behind closely spaced cylinders may be laterally deflected resulting in an asymmetric wake structure or may be undeflected resulting in a symmetric wake structure wang et al 2002 sumner 2010 the same two scenarios have been observed here i e on average the flow was deflected as discussed above but in one replicate see section 3 3 and also in meire et al 2014 the flow was not deflected resulting in symmetric wakes behind the two side by side patches according to sumner 2010 this bi stable characteristic is not caused by misalignment of the obstructions but is an instability influenced by turbulent perturbations in the incoming flow on the centerline between the patches y d 0 fig 2a the flow accelerated reaching a maximum of u u 0 1 2 directly behind the patches x d 1 5 this region of enhanced velocity was associated with a region of reduced deposition blue dots that extended from x d 0 to x d 4 fig 2c beyond this point the deposition was enhanced red dots beginning at the distance lm d 4 5 0 5 downstream from the patch which meire et al 2014 defined as the secondary deposition zone importantly the primary deposition zone behind the right hand patch extended far enough ld 1 d 4 5 0 5 downstream to connect with the beginning of the secondary deposition zone lm d 4 5 0 5 the linking of these two deposition zones created the possibility for lateral growth between the patches finally the secondary deposition zone persisted over the full length of the test section x d 22 fig 2c the length scale of turbulence in the wake was inferred from the frequency peaks in the velocity spectra fig 3 to examine the strongest signal the spectra were estimated at the point of maximum tke in the wake x d 10 5 at this position the same frequency peak f 0 09 hz was observed in line with each patch center and also at the centerline between the patches based on the strouhal number st fl u 0 0 2 this frequency corresponded to the length scale of the combined patch structure l 22 cm 2d δ indicating that a single von karman vortex street had formed at the scale of the combined patch wake the formation of a single vortex street as opposed to a vortex street formed separately behind each patch was an indication that the patch wakes had merged consistent with this the lateral velocity profile resembles that of a single patch of width 2d δ figure 9 meire et al 2014 in contrast patches with a larger gap spacing δ d 0 5 generate two distinct vortex streets one behind each patch meire et al 2014 3 2 asymmetric patches cycle 2a new cylinders were added to the region of enhanced deposition observed downstream of the initial side by side patches fig 2 because the study focused on downstream growth no cylinders were added upstream of the patch the resulting distribution of model vegetation is shown in black in fig 4 note that patch merger had not yet occurred and two distinct but asymmetric patches were formed the spatial distribution of velocity turbulence intensity and deposition observed for this phase of artificial growth are shown in fig 4 regions of enhanced deposition were consistent with regions of diminished velocity fig 4 in contrast to the first side by side patch configuration cycle 1 fig 2 there was no acceleration within the gap between the new patches specifically the velocity in the gap was less than u 0 fig 4a this confirmed the conjecture made in meire et al 2014 that growth within the secondary deposition zone would diminish flow between the patches however the velocity through the gap was still sufficient to diminish deposition in the gap the new patch shape black outline directed flow through the gap toward the left so the flow along the left side of the patch was higher up to u u 0 0 7 than that along the right side u u 0 0 3 this velocity difference was sufficient to be reflected in the deposition fig 4c with a wider region of enhanced deposition observed on the right side of the patch downstream of the original right hand patch x d 3 to 8 y d 0 4 to 1 a recirculation zone formed with negative velocity u u 0 0 1 at x d 6 y d 0 8 labeled eddy region in fig 4 this recirculation was associated with the highest deposition specifically at x d 4 5 and y d 1 the deposition reached 2 3 mg cm2 compared to an average deposition of 1 5 mg cm2 a region of low velocity without recirculation formed downstream of the original left hand patch and this region was also a site of enhanced deposition fig 4c x d 3 to 6 and y d 1 importantly the enhanced deposition in this region spanned the gap between the patches indicating that the two patches would merge into a single structure in the next cycle of artificial growth diminished velocity in the wake downstream of the larger patch x d 20 fig 4a was associated with enhanced deposition that extended to x d 40 fig 4c a peak in turbulence was observed directly behind the end of the patch x d 21 which locally offset the influence of diminished velocity to produce several points without enhanced deposition directly behind the patch x d 20 to 22 y d 0 3 3 comparison between symmetric cycle 2a and asymmetric cycle 2b patch growth in one of the three replicate experiments for the initial side by side patch configuration cycle 1 the enhanced deposition was distributed symmetrically around the centerline figure s1 in supporting information taking this as a possible outcome in the field the symmetric configuration was used as a template for a second cycle of artificial growth resulting in the black outline in fig 5 along with the resulting velocity and deposition fields produced by this vegetation distribution not surprisingly the symmetric patch produced symmetric distributions of both velocity fig 5a and tke fig 5b taking advantage of the symmetry deposition was measured on only one side right hand patch the key features in the velocity and deposition will be discussed through comparisons between the symmetric fig 5 and asymmetric fig 4 patches both patches exhibited enhanced deposition in the recirculating eddy downstream from the initial patch positions labeled eddy region in figs 4 and 5 new growth in the recirculating eddy would lengthen the widest part of the patch note that in this region x d 2 to 5 points of enhanced deposition extended laterally from the edge of the patch i e y d δ 2 associated with regions of diminished velocity measured against the patch edge fig 4a c and 5a c for example just past the leading edge x d 1 diminished velocity was observed next to the patch and extending 0 5d from the patch edge u u 0 1 blue dots in fig 4a and 5a this created the possibility for lateral patch expansion vandenbruwaene et al 2011 also observed diminished velocity adjacent to the patch edge and over a similar length scale i e extending 0 5d from the patch edge figures 4 and 7 of their paper these observations are highlighted to emphasize that lateral growth may be possible even at the patch outer edge where previous studies have concluded that high velocity and scour at the patch edge inhibit lateral patch growth e g wesenbeeck et al 2008 here we see in greater detail that the flow deflection that begins upstream of the patch can re direct the high velocity region to a distance 0 5d away from the patch edge x d 1 orange dots fig 4a and 5a providing opportunity for lateral patch growth in addition as flow entering the patch adjusts to the vegetation drag it decelerates which necessitates that some flow exit the patch at the edge for example at position x d 0 5 y d 1 1 of the symmetric case fig 5a the lateral velocity leaving the patch was 3 0 cm s this lateral bleed flow pushed high velocity streamlines further from the patch edge extending the region of lower velocity where deposition can occur the deposition in the wake downstream of the patch differed between the symmetric and asymmetric cases with enhanced deposition extending much farther downstream behind the asymmetric patch over 20d fig 4c than behind the symmetric patch over 1 5d fig 5c for the symmetric patch the end of the wake deposition zone corresponded with the peak turbulence in the wake fig 5b the difference in wake deposition between the asymmetric and symmetric patches was difficult to explain because the velocity and tke had similar magnitudes and evolved in similar ways with distance from the trailing edge y 0 x d 20 further the velocity spectra revealed that both the symmetric and asymmetric patches produced turbulent structures at the scale of the total patch width 2d δ see discussion of velocity spectra in section 3 1 the most important result was that both the asymmetric and symmetric growth led to a deposition pattern with enhanced deposition in the region between the patches indicating that the two patches would merge in the next cycle of artificial growth which confirmed meire s premise we caution that these results are preliminary because only a single initial configuration was considered making generalizations difficult for example considering a wider range of initial patch distributions and a larger number of initial patches numerical simulations have suggested other growth patterns lima et al 2015 yamasaki et al 2019 further note that this experiment considered a single sediment size and deposition will be a function of sediment size 3 4 correlations between deposition velocity and tke the pattern of net deposition observed in the wakes of the patches reflected the dual influences of time mean velocity and turbulence intensity on the one hand the diminished velocity in the wake should promote deposition relative to the free stream on the other hand the enhanced turbulence levels observed in the wake may inhibit deposition it would be useful to understand if the local values of velocity and tke i e measured at a point were sufficient to predict the deposition at that point to this end the net deposition at each point was plotted on a grid defined by the velocity and tke fig 6 the individual points are colored to indicate whether the local net deposition was enhanced red or diminished blue relative to the spatial average deposition as defined by equation 1 the enhanced deposition mapped more closely with velocity that tke that is regardless of the local tke enhanced deposition was observed for all points for which u 0 4u 0 and reduced deposition was observed for all points for which u u 0 across the velocity range of 0 4u 0 to u 0 both enhanced and reduced deposition were observed with little correlation to tke the lack of clear trends within the intermediate velocity range suggested that additional information would be needed to predict the potential for deposition at a given location this may be attributed to particle history which was not captured in this analysis for example particles that recently experienced strong turbulence may be mixed higher in the water column and thus are less available for deposition even after entering a region of lower tke or u consistent with this points of low deposition in regions of low velocity were generally found close to regions of high velocity gradient for example in cycle 2b low deposition blue dots fig 5c was observed along the edge of the eddy y d 1 5 x d 5 to 8 which was a region of low velocity adjacent to a region of high velocity we caution that the velocity limits implied in fig 6 are specific to the particle size considered in this experiment the tendency to deposit will also be a function of sediment size for example shi et al 2016 showed that enhanced deposition within a patch wake relative to adjacent bare channel will only occur when the ratio of channel shear velocity to critical shear falls within a specific range and the critical shear velocity is a function of particle size 4 discussion previous descriptions of vegetation flow interaction identified positive feedbacks only for streamwise patch growth and negative feedbacks for lateral growth e g bouma et al 2007 in contrast this study demonstrated two mechanisms of lateral growth first lateral growth occurred through patches merging meire et al 2014 observed that adjacent patches produce a secondary zone of enhanced deposition on the centerline between the patches they hypothesized that if this secondary zone of enhanced deposition were colonized by vegetation the additional drag and flow blockage on the centerline would diminish velocity between the patches eventually leading to the patches merging our study provided an example of this progression demonstrating this mechanism of lateral growth after two cycles of artificial growth the vegetated regions merged into a single patch second this study measured regions of diminished velocity extending 0 5d from the patch lateral edge similar to observations in vandenbruwaene et al 2011 and these regions were associated with enhanced deposition suggesting the possibility of lateral growth the present experiments considered conditions with patch width small compared to channel width so that the confinement of the walls did not impact the flow around the patches however in natural channels the width of the vegetated region may be large compared to the channel width e g green 2005 and the flow confinement due to the walls will impact the flow around the patches changing the patch evolution from what has been described in this study for this reason it is useful to consider how the patch evolution might be different in wide unconstrained flow versus narrow channel flow conditions in an unbounded domain the patch may progressively but slowly grow wider as diminished velocity will enhance deposition and encourage new growth over the length scale of 0 5d adjacent to the patch confining walls impact this mechanism of lateral growth as the patch width d grows and approaches the channel width b the walls limit the degree of lateral flow deflection around the patch studies of solid obstructions suggest that confining walls impact the flow structure when b 5d e g sahin and owen 2004 the wall confinement would force streamlines closer to the patch diminishing or eliminating the regions of reduced velocity and enhanced deposition at the lateral edge of a patch and thus eliminating the potential for further lateral growth as noted previously e g sand jensen and madsen 1992 and also observed in the present study patches have a strong tendency to grow in the streamwise direction the present study suggested that the interaction between patches enhances this tendency specifically behind a pair of side by side high flow blockage ad 4 patches the secondary deposition zone extended over the distance x d 22 fig 2 this was a much greater length of deposition than observed behind an isolated high flow blockage patch which extended over x d 2 5d e g case 17 figure 12 in chen et al 2012 this can be attributed in part to the wake merger which gives the wake the appearance of being formed behind a structure of size dsp 2d δ in which subscript sp denotes the equivalent single patch see section 3 1 a larger apparent patch size would be expected to produce a longer wake here dsp 22 cm and deposition extended to x dsp 10 5 one must also consider the change in flow blockage using a weighted average of a over the bare and vegetated regions within the equivalent patch asp 2a d dsp 2 0 18 cm 1 the equivalent flow blockage was aspdsp 4 which was similar to the original individual patch value ad 4 2 this indicated that despite having similar flow blockage ad aspdsp the deposition extended farther downstream in units of diameter behind the pair of patches than behind a single isolated patch a possible explanation for this is that the gap between the original patches allowed a stronger bleed flow to enter the wake compared to a patch of uniformly distributed vegetation as the bleed flow into the wake increases the von karman vortex formation occurs farther from the patch zong and nepf 2012 and this lengthens the region of combined low velocity and low turbulence that is favorable to deposition chen et al 2012 the key feature here is that the interaction between adjacent patches produced enhanced deposition over a longer distance than a single patch of comparable total width and flow blockage combining the strong tendency for streamwise growth with the impact of confining walls on lateral growth we cautiously suggest that the patch growth modeled in this study is evolving toward a final state in which a continuous band of vegetation exists along the center of the channel with bare bed regions to either side this landscape would be maintained by the following feedback deflection of flow away from the vegetation band maintains high velocity in the bare region inhibiting growth and maintaining the bare region at the same time the low velocity within the vegetation provides a positive feedback for deposition and continued vegetation growth this is similar to the landscape pattern observed in some wetlands called parallel preferential flow channels which is characterized by open channels separated by long bands of vegetation running parallel to the flow direction larsen and harvey 2011 a similar pattern of extended vegetated regions cut through by long channels has also been observed in tidal landscapes and its formation is similarly attributed to the channel s ability to attract flow away from vegetated regions stabilizing both the channel and the vegetation temmerman et al 2007 kondziolka and nepf 2014 in contrast to the streamwise growth pattern observed here and in some previous studies larsen and harvey 2011 kondziolka and nepf 2014 other studies have noted vegetation distributed into many patches of limited streamwise extent sand jensen and madsen 1992 larsen and harvey 2011 schoelynck et al 2012 cameron et al 2013 in particular sand jensen and madsen 1992 observed a predominance of patches with length l 2 5 d which is shorter than the patch length observed in our study fig 4c and 5c but comparable to the patch length suggested by the deposition pattern observed for an individual patch of l d 2 5 figure 12 ad 9 in chen et al 2012 drawing on similar observations by schnauder and moggridge 2009 chen et al 2012 proposed that the geometry l d 2 5 may be sufficiently streamlined that a patch of this geometry would not produce a wake of sufficient velocity depression to promote downstream deposition such that the patch would have no tendency to lengthen further i e l d 2 5 is a stable patch geometry the difference between the two development scenarios that results either in long patches extending in the streamwise direction large l d or many short patches l d 2 5 may be linked to whether or not the secondary deposition mechanism described in this study occurs which in turn depends on the sediment size and initial patch spacing specifically kondziolka and nepf 2014 used a numerical simulation to show that long patches large l d emerged when the initial patches were close enough for wake merger to occur and the reduction in wake velocity was sufficient to generate deposition within the merged wake the necessary velocity for deposition depends on the sediment size alternatively short patches l d 2 5 emerged if either the initial patch spacing was too great to facilitate wake merger or the merged wake velocity was not sufficiently reduced to facilitate deposition which would depend on particle size kondziolka and nepf 2014 for example in meire et al 2014 a pair of sparse patches ad 2 9 separated by δ d 0 5 produced a merged wake but no secondary zone of deposition because the minimum velocity in the merged wake was not low enough to encourage enhanced net deposition for the particle size used in that study we caution that the secondary region of deposition is only one possible mechanism of patch merging through physical processes and that the present experiments considered a single set of sediment size patch density and flow field the current study did not consider biological processes through which merging could also occur 5 conclusions this paper described an artificial growth experiment which demonstrated the premise that the interaction between wakes of adjacent patches has a positive feedback on both streamwise and lateral growth of the vegetated region first the merging of wakes behind adjacent patches produces a zone of diminished velocity on the centerline between the patches if the velocity is sufficiently reduced as to enhance deposition in this region as observed in this study and encourage new growth as modeled in this study the additional vegetation drag on the centerline diminishes the velocity between the patches eventually leading to patch merger and associated lateral growth our observations suggested that wake interaction also enhances streamwise patch growth compared to a patch in isolation finally regions of diminished velocity were observed to extend laterally 0 5d from the patch edge similar to observations in vandenbruwaene et al 2011 and this region was associated with enhanced deposition suggesting the potential for lateral growth importantly these regions were associated with lateral flow leaving the patch which pushed the higher velocity streamlines farther from the patch as compared to a solid obstruction however as the patch grows and approaches the scale of the channel b d 3 the confinement of flow by the channel walls can force streamlines closer to the patch limiting the potential for lateral growth credit authorship contribution statement taís n yamasaki writing review editing formal analysis beihan jiang formal analysis investigation visualization methodology johannes g janzen formal analysis investigation visualization conceptualization methodology heidi m nepf conceptualization methodology resources funding acquisition supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements taís n yamasaki received funding from cnpq the brazilian national council for scientific and technological development process n 145692 2018 3 and capes coordination for the improvement of higher education personnel process n 88882 458516 2019 01 beihan jiang received funding from china scholarship council johannes janzen received funding from cnpq and capes scholarship and capes print programme appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126232 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4509,we proposed four new models wclasscb wclassvl wclassvp wclassvr for water classification using categorical boosting catboost and support vector machines svm with three kernels linear polynomial and radial basis function the new models were compared with the recently proposed wclasshlr 7 hybrid log ratio model based on linear discriminant analysis and canonical analysis techniques a training database 50 000 samples and another independent validation database 8 000 samples of ionic charge balanced concentrations of 4 cations ca m g n a and k and 4 anions so 4 cl hco 3 and co 3 were generated through monte carlo simulations the initial 16 classes were assigned from the highest cation and anion molar concentrations gmc criteria i e greater molar concentration model seven hybrid log ratio transformations were used as features for training and external validation of the multidimensional classification models these models generate probability values for each of the output classes allowing us to determine hybrid water types improving the possible water types to 256 wclasscb model showed the best accuracy values in the training set however wclassvl model is the recommended procedure because it generalizes better than other models in the external validation set the new models outperform the recently proposed wclasshlr with up to a 7 difference the usefulness of all models wclasshlr wclasscb wclassvl wclassvp wclassvr is illustrated by four applications to groundwater samples from india and nigeria all models have difficulties in classifying real samples when there is more than one major cation or anion but they can recover the classification suggesting hybrid water types the new computer program waterclasys ml has been developed for applying these new models keywords machine learning gradient boosting support vector machines hill piper diagram molar concentrations monte carlo simulation groundwater samples 1 introduction water type based on hydrochemical facies evaluation is extremely useful in providing a preliminary idea about the complex hydrochemical processes at the subsurface sajil kumar 2013 thus there have been many attempts to identify their nomenclature and develop easy to use techniques durov 1948 handa 1965 romani 1981 chadha 1999 ahmad et al 2003 giménez forcada 2010 elhag 2017 shelton et al 2018 güler et al 2002 evaluated graphical and multivariate statistical methods for water classification such as schoeller semi logarithmic diagrams schoeller 1955 and principal component analysis pca even though multiple ideas have been explored the most used tools to identify hydrochemical facies are derived from the popular hill piper diagram piper 1944 this technique is based on two ternary diagrams constructed from the normalized milliequivalent per liter meq l concentrations of the cations ca 2 mg 2 na k and anions so 4 2 cl hco 3 co 3 2 and then projected in a diamond field to identify hydrochemical facies many other techniques such as durov diagram durov 1948 and chadha diagram chadha 1999 are also popular approaches to determine water classification which use trilinear diagrams or percent values of the chemical composition however there are severe problems like distortion and amplification reduction of analytical errors in these diagrams caused by closure and constant sum problems chayes 1960 1971 aitchison 1986 because crude compositional variables represent a closed unit sum constrained system and ternary diagrams impose a further unit sum constraint on any experimental data these diagrams become statistically unsuitable to handle experimental data verma 2012 the ternary diagram problems were stressed by aitchison 1986 and verma 2012 2015 aitchison 1986 proposed solutions to overcome the constant sum difficulties through a multivariate approach by calculation of ratios and log ratio transformations instead of using crude compositions this approach eliminates the compositional units and renders the compositions as simple numbers opening the space error propagation through monte carlo simulations was reported for the first time by verma 2012 to illustrate the inconvenience of using ternary diagrams for compositional data and instead a natural logarithm transformed bivariate diagram was suggested afterward verma 2015 compared ternary diagrams against bivariate diagrams using linear discriminant and canonical analysis ldca and also compared the performance of three types of log ratio transformations additive and centered proposed by aitchison 1986 and isometric proposed by egozcue et al 2003 concluding that the bivariate diagrams were a better option to visualize and interpret compositional data because they do not show the analytical distortion error problems moreover the three log ratios showed similar results later verma et al 2016 and verma and armstrong altrin 2013 used a hybrid log ratio hlr transformation which differs from the other transformations isometric additive and centered defined in the section of methods hybrid log ratio transformation however the performance of the hlr is little known in the literature also verma et al 2020 compared the isometric and hlr transformation concluding that when both transformations were applied to the same database of major element compositions of igneous rocks in conjunction with the ldca the same results were obtained similar conclusions were achieved earlier by verma 2015 for the isometric additive and centered transformations this consistency has shown that it does not matter which transformation is used for a multidimensional classification using major element concentrations furthermore according to piper 1944 most natural water contains relatively few dissolved constituents with cations metals or bases and anions acid radicales in chemical equilibrium with each other the most abundant cation constituents are two alkaline earth ca 2 and mg 2 and one alkali na k also occurs but ordinarily is much less abundant than na similarly the most common anion constituents are one weak acid hco 3 and two strong acids so 4 2 and cl other cations and anions occur in considerable quantities in highly concentrated waters however piper 1944 suggested that all these less abundant constituents can be added with the major three constituents to which they are respectively related in chemical properties e g ca 2 with barium ba 2 or strontium sr 2 na with k cesium cs rubidium rb lithium li or ammonium nh 4 hco 3 with co 3 or tetraborate b 4 o 7 2 cl with fluoride f nitrate no 3 or nitrite no 2 thus a water sample is treated on hill piper ternary diagram substantially as though it contains only three cation constituents and three anion constituents this explains why the cations na and k are ordinarily combined as the anions hco 3 and co 3 and this approach reduces the number of possible hydrochemical facies that can be determined by ternary diagrams therefore since our scheme for water multidimensional classification is not based on ternary diagrams we decided that it would be worthwhile to explore a new classification scheme without combining any of these 8 ionic species the 7 hlr model recently presented by verma et al 2021 denoted as wclasshlr was developed using ldca and the hybrid log ratio hlr transformations of the millimoles mm l concentrations of 8 major ions without combining any of them for wclasshlr model a representative database from monte carlo simulations law and kelton 2000 verma and quiroz ruiz 2006 was generated defined in section methods database simulation procedure this initial classification of each simulated sample was achieved from the greater molar concentration concept of each cation and anion called the greater molar concentration gmc criteria the 16 classes were all set to similar sizes minimum size 3021 samples maximum size 3247 samples see table 1 before undertaking the ldca classes were free censored from multivariate discordant outliers each class was processed through domudaf discordant outlier from multivariate data through f test of w verma et al 2016 program for the detection and separation of multivariate discordant outliers because ldca require that the individual classes be multi normally distributed in terms of the features 7 hlr variables domudaf program detects multivariate discordant outliers through a transformation of the wilks statistic w wilks 1963 to the well known f test a total of 46 292 multivariate discordant outlier free samples were obtained from domudaf for training the ldca the statistical characteristics of outlier free multivariate data are summarized in table s1 finally the wclasshlr model was obtained using the 16 classes initially assigned and from the probability concept it was possible to identify hybrid water types along with the basic types of water thus wclasshlr model under the hybrid option defined in section methods hybrid log ratio transformation can classify as many as 256 different water classes machine learning ml techniques have been used in many aspects of hydrological science e g acharya et al 2019 but mainly to classify or estimate water quality muhammad et al 2015 wang et al 2017 gakii and jepkoech 2019 abba et al 2020 gaya et al 2020 melesse et al 2020 lu and ma 2020 liang et al 2020 banadkooki et al 2020 tung and yaseen 2020 zhou 2020 bayram and gultekin 2010 proposed an artificial neuron network ann model to classify water samples from simav geothermal area in western turkey this model classify the samples into 4 different classes eynal çitgöl geothermal water and cold water the model indeed have good results however this classification is not a general nomenclature that could be used as hydrochemical facies also ml techniques such as support vector machines svm and random forest rf have been used for flood susceptibility mapping nachappa et al 2020 ni et al 2020 compared the following three ml models extreme gradient boosting model with gaussian mixture model xgb standalone xgboost and svm to provide streamflow forecasting wu et al 2019 conducted a comparison of eight ml models i e ann rf gradient boosting decision tree gbdt xgboost multivariate adaptive regression spline mars svm and kernel based nonlinear extension of arps decline knea model for the estimation of monthly mean daily reference evapotranspiration which is important in hydrology research irrigation scheduling design and water resources management and svm and xgboost comparison for streamflow forecasting yu et al 2020 in general all the ml techniques show good results over other techniques employed particularly the svm and xgb models in this work our main aims are summarized as follows i to generate a training database n 50 000 samples and another independent validation database n 8 000 samples through monte carlo simulations methods databases simulation procedure available in the public server https github com usju water databases ii to develop four new nonparametric models wclasscb wclassvl wclassvp wclassvr for water nomenclature through the molar concentrations of 8 ions ca 2 mg 2 na k so 4 2 cl hco 3 and co 3 2 from two machine learning techniques based on gradient boosting and support vector machines methods classification methods and hlr transformation methods hybrid log ratio transformation iii to develop the new models on python following standard machine learning practices methods training and validation of models such as hyperparameter optimization and training and evaluation metrics which performance up to 99 was achieved this python program is available in the public server https github com usju water training test models iv to develop a post processing program to identify hybrid water types in the four machine learning models from probabilities generated for each of the output basic classes v to compare through machine learning metrics section of methods models evaluation metrics the performance of these four nonparametric models with wclasshlr model verma et al 2021 to find which technique performs better to determine hydrochemical facies in water samples vi to illustrate the usefulness of all the models by four applications on real groundwater samples from india and nigeria and vii to develop a program on python for the effective use of the new four machine learning models which is available in the public server https github com usju water classification ml 2 methods 2 1 training database the training and the independent validation databases consist of 50 000 samples and 8 000 samples on molar concentrations mm l with 4 cations ca 2 mg 2 na k and 4 anions so 4 2 cl hco 3 co 3 2 respectively the generated databases are described in the following section 2 2 databases simulation procedure the monte carlo procedure suggested by verma and quiroz ruiz 2006 shows how to assess the randomness of uniformly distributed numbers i e iid u 0 1 and to generate normally distributed samples i e iid n 0 1 using different seeds to guaranteed the randomness of such values via numerical simulation following these suggestions our monte carlo sampling simulation can be summarizing as follows generate n individual uniformly distributed numbers iid u 0 1 for each element ca 2 mg 2 na k so 4 2 cl hco 3 and co 3 2 using the mersenne twister pseudo random number generator algorithm matsumoto and nishimura 1998 where n took values of 50 000 samples for the training dataset and 8 000 samples for the independent validation dataset compute a scalar value of 100 to cover the representability of the ternary diagrams fig s2a the representativeness of the initial database is illustrated by plotting the simulated in a cation ternary diagram ca 2 mg 2 na fig 1 a and an anion ternary diagram so 4 2 cl hco 3 fig 1b use the icb equation ionic charge balance equation nicholson 1933 as icb c a t i o n s a n i o n s c a t i o n s a n i o n s where c a t i o n s o r a n i o n s are given on milliequivalent per liter meq l units also a value of 0 00005 was established as the maximum unbalance however as the samples were randomly generated we proceed to apply the following unbalance factor as factor c a t i o n s a n i o n s to assess the charge balance in our simulated database this unbalance factor is applied to a pseudo random increment from 0 to 10 for each element the ionic charge balance validation procedure is shown in fig s1 which enabled the selection of samples with icb 0 00005 for a better dataset setting a histogram of the database after the icb procedure is presented in fig s2b determine the cross combination of majoritarian cation and anions of the simulated dataset table 1 the 16 classes achieved consist of cross combinations of 4 cations and 4 anions primary classes which were assigned from the highest anion and cation molar concentrations table 1 listed under the column water class the statistical characteristics of the multivariate database number of samples n median x maximum and minimum values are summarized in table 1 this database has 16 balanced or equal sized classes minimum size 3021 samples maximum size 3247 samples see table 1 2 3 hybrid log ratio transformation we decided to use hlr transformation based on the previous comparisons reported by verma 2015 2020 where it concluded that is not relevant which transformation is chosen for multidimensional classification using major element concentrations the hlr transformation of the molar concentrations mm l of 8 elements ca 2 mg 2 na k so 4 2 cl hco 3 and co 3 2 were calculated using the following general equation hlr i 1 l n g x i x n 1 n x i 1 i 1 2 n 1 where g denotes the geometric mean x i represent the concentration of each element in the same order c a m g n a k so 4 c l hco 3 co 3 1 8 x i 1 denotes one ion at a time from second mg 2 to last co 3 2 and n subscript is the total number of major elements n 8 for more information about hlr transformation see a1 additional details on hybrid log ratio transformation section in appendix a thus the seven hlr variables hlr 2 to hlr 8 eqs s1 to s7 were used as features for training the multidimensional classification models a histogram of the hlr transformations is presented in fig s2c according to aitchison 1986 and aitchison and egozcue 2005 in any discipline when a problem is compositional we are recognizing that the sizes of our specimens are irrelevant for example a geologist talking about the composition of an object such as the major oxide composition of a rock is declaring as a dimensionless problem there is no concern about whether the rock specimen weighs one gm or one lb compositions are concerned with relative values and ratios of components the geometric mean was used in the clr and ilr transformations proposed by aitchison 1986 and egozcue et al 2003 respectively for the treatment of compositional data using the geometric mean on the components of a sample has the advantage of treating the parts symmetrically and is a reasonable way to measure the dependence between the composition parts in this work as the water components are charge balanced concentrations of 4 cations ca m g n a and k and 4 anions so 4 cl hco 3 and co 3 the geometric mean was applied considering that these components are chemically related the geometric mean use relies on the fact that it considers the cumulative and compound effects spizman and weinstein 2008 moreover the geometric mean is closely related to the log transformation in statistics which is widely used for skewed data feng et al 2013 furthermore the geometric mean has been used in a very broad range of natural and social science disciplines like environmental monitoring scientometrics nuclear medicine infometrics economics finance ecology surface and groundwater hydrology geoscience and geomechanics vogel 2020 2 4 classification methods 2 4 1 wclasshlr model generated by ldca the 7 hlr model proposed by verma et al 2021 denoted as wclasshlr consists of an assembly of classifiers created by ldca which is a supervised classification technique that consists of finding a one dimensional linear function that discriminates between the classes by the measure of maximum separation and serves as a basis for classifying samples of unknown classes this methodology maximizes the distance between the classes and minimizes the distance between the samples for each class the main idea was to achieve a classification model for cations and another for anions however for 4 groups the ldca would provide 3 discriminant functions requiring a three dimensional diagram to visualize them therefore 3 groups were evaluated at the same time which required making 4 2d models for cations ca m g n a and k and 4 2d models for anions so 4 c l hco 3 and co 3 the 16 water types could thus be classified by cross combinations each of these models has the advantage of being visualized in 2d diagrams using two discriminant functions which can be represented in a general form in eq s8 see a2 additional details on linear discriminant and canonical analysis ldca section in appendix a the wclasshlr model consists of 8 sub models 4 for cations and 4 for anions containing 16 dfs 128 coefficients table s2 and 48 centroids table s3 for example the d f 1 h c a m g n a and d f 2 h c a m g n a required for the classification of ca m g n a can be calculated from eqs s9 and s10 for the other cation sub models of three at a time ca m g k c a n a k and m g n a k the discriminant functions can be similarly calculated see coefficients in table s2 the classification of anions so 4 c l hco 3 and co 3 was similarly achieved from 4 sub models of the three at a time type the final water nomenclature is achieved from probability calculations for the competing fields in all three at a time sub models and their comparison 2 4 2 gradient boosting catboost technique catboost i e categorial boosting works by sequentially adding weak predictors to make a strong classifier each predictor of the assemble is trained with the residual errors of its predecessor géron 2019 catboost is a process of constructing an ensemble model strong classifier by performing gradient descent in a functional space prokhorenkova et al 2018 categorical boosting is an open source library that implements a modification of the standard algorithm it uses binary decision trees as weak predictors that make up the assemble which divide the feature space into disjoint regions according to the values of some splitting attributes prokhorenkova et al 2018 catboost is available as a python library and uses scikit learn pedregosa et al 2011 framework 2 4 3 support vector machines svm technique svm are supervised machine learning algorithms that are used for classification and regression purposes when it comes to classification samples of the form x i y i i 1 n can be classified by a hyperplane which optimizes the distances between itself and the closest vectors of each class these vectors are called support vectors and are examples from the training set the distance between the vectors and the classes is called margin géron 2019 fig 2 diagram illustrates these concepts visually in svm our main objective is to select a hyperplane with the maximum possible margin between support vectors in the given dataset the hyperplane can be expressed as f x ω ϕ x b where x is the input data ϕ x represents a kernel function that projects x into the high dimensional feature space ω and b are the coefficients estimated by the svm procedure huang et al 2019 svms use the so called kernel trick that allows using a kernel function denoted as k x z which makes it possible to map the dot product of vectors x z in high dimensional space géron 2019 when samples are projected in a higher dimensional space by the kernel function the additional dimensions afford a greater opportunity to find a hyperplane that separates classes wadkar et al 2019 svms are recommended when it is needed to perform classification on complex small or medium datasets as in our dataset of 50 000 samples géron 2019 in this work we use and evaluate svms with three different kernel functions linear l polynomial p and radial basis function rbf svms are used through scikit learn s svc module pedregosa et al 2011 2 4 4 new water classification models wclasscb wclassvl wclassvp wclassvr to carry out the water classification models through catboost and smv techniques a general computational methodology was developed fig 3 a total of 50 000 simulated analyses of ionic charge balanced concentrations of 8 major elements ca m g n a k so 4 c l hco 3 co 3 mmol l were used for training models the hlr transformations of the millimoles mm l concentrations of the 8 ions were calculated after two ml techniques based on gradient boosting and support vector machines were applied 2 4 4 1 gradient boosting catboost implementation catboost is a machine learning algorithm that uses gradient boosting on decision trees we applied this algorithm from the catboost catboostclassifier python module the multiclass support is handled according to a one vs rest scheme thus to classify 4 classes of cations ca m g n a and k 4 binary classifiers are constructed as follow i ca vs m g n a k ii m g vs c a n a k iii n a vs c a m g k and iv k vs c a m g n a the classification of anions so 4 c l hco 3 and co 3 was similarly completed from 4 sub models of the one to rest type fig 3 the decision trees were used for these classifiers each of the trees corresponds to a partition of the feature input variables hlr 2 to hlr 8 space and the output value a decision rule is used for each level of the tree acting as the splitting criterion each decision rule can be conceptualized as a pair r k v that contains a feature index r 1 m and a threshold value v r thus a set of feature vectors x can be split into two disjoint subsets of x l and x r kang et al 2019 then for each x x 1 x n x we have that x x l i f x k v or x x r i f x k v then applying the decision rule to s disjoint sets x 1 x s r m the total number of disjoint sets is 2 s x 1 l x 1 r x s l x s r kang et al 2019 once the models were trained we used the predict and predict proba functions of the sklearn svm svc library to perform classification on unknown water samples the predict function applies the model to the given dataset and the predict proba function generates the probability that the object belongs to the given classes the catboost based model named wclasscb can be used in the executable program available at the public server https github com usju water classification ml 2 4 4 2 support vector machines svm implementation for svm the sklearn svm svc library pedregosa et al 2011 was used the multiclass support is handled according to a one vs one scheme thus to classify 4 classes of cations ca m g n a and k 6 binary classifiers n classes n classes 1 2 as follow i ca vs mg ii c a vs na iii ca vs k iv m g v s n a v mg vs k and vi na vs k the classification of anions so 4 cl hco 3 and co 3 was similarly achieved the final water nomenclature is achieved from probabilities for the competing fields in all sub models we applied linear wclassvl model polynomial wclassvp model and radial basis function wclassvr model kernel functions for details on the precise mathematical formulation of the kernels see the corresponding documentation provided by pedregosa et al 2011 in the linear kernel the hyperplane or decision function for discriminates of c 1 and c 2 classes can be constructed as hp c 1 c 2 w 1 h l r 2 w 2 hlr 3 w 3 hlr 4 w 4 hlr 5 w 5 hlr 6 w 6 hlr 7 w 7 hlr 8 b where hp c 1 c 2 is the hyperplane equation for discriminates of c 1 and c 2 classes hlr 2 hlr 8 are input variables w 1 to w 7 and b are the coefficients or adjustable parameters of the decision function for an unknown sample the hyperplane equation generates a positive or negative value for a sample classified as c 1 or c 2 class respectively once the svm models have been trained their coefficients and intercept values can be extracted through the functions coef and intercept respectively from sklearn svm svc library these coefficients are listed in table s3 and are used to construct the hyperplane functions df the wclassvl model consists of 12 one to one sub models 6 for cations and 6 for anions and 96 coefficients table s3 the wclassvl model final water nomenclature is achieved from probability calculations for the competing fields in all sub models when the kernel is not linear the sklearn svm svc library provides the coefficients dual coef and support vectors support vectors that are required to construct the hyperplane or decision function to keep this work short we only present the svl l model coefficients however we used the predict function from sklearn svm svc library to perform classification on unknown samples this function predicts the results using the trained model the proposed svm based models wclassvl linear kernel wclassvp polynomial kernel and wclassvr radial basis function kernel can be used through the waterclasys ml executable program available at the public server https github com usju water classification ml 2 5 training and validation of models 2 5 1 hyperparameter tuning since ml algorithms have many hyper parameters to tune this process has been automated hyperparameter tuning was done through gridsearchcv module from scikit learn pedregosa et al 2011 which for given values exhaustively considers all parameter combinations gridsearchcv uses a 5 fold cross validation procedure of which 80 four subsets is used to train and the remaining 20 one fold is used to validate the model the process makes combinations of the folds where all subsets are used as a validation set at least once the cross validation was executed per combination of given hyperparameters the best hyperparameters were selected by looking at the average accuracy of each cross validation heung et al 2016 once a set of hyperparameters is selected it is used to train the model with the complete training dataset the general procedure for the training and evaluation of the ml models wclasscb wclassvl wclassvp wclassvr and the cross validation procedure are shown schematically in fig 4 2 5 2 evaluation metrics to compare the performance of the models we use the following four metrics i classification accuracy eq s11 ii classification precision eq s12 iii recall eq s13 and the number of false positives eq s14 these metrics are calculated for all possible classification thresholds géron 2019 an ideal model with high precision and high recall will return many results with all results classified correctly and would have an auc close to 1 that tells us that the classifier is not making random decisions géron 2019 to achieve the prediction of multiple classes by the classifiers we compute the macro average precision eq s15 macro average recall eq s16 and macro average auc eq s17 using the one vs rest approach see a3 additional details evaluation metrics section in appendix a 2 6 application of the models 2 6 1 preprocessing of real samples before applying the models we used l2 normalization defined as x new x x 1 2 x 2 2 x 3 2 x n 2 where x is a sample vector and x new is the scaled vector to scale field water samples before the application of the classification models l2 norm is a standard method to compute the length of a vector in euclidean space l2 norm of a vector is defined as the square root of the sum of the squares of the values in each dimension the features or input variables hlr 2 to hlr 8 of field water samples non simulated water samples could have different scales and contain some extreme values which could degrade the predictive performance of the machine learning algorithms pedregosaet al 2011 2 6 2 waterclasys ml program it should be clear that it is difficult to use and evaluate these new classification schemes without a suitable computer program therefore a computer program waterclasys ml was written in python which is available on the public server https github com usju water classification ml and requires an input file and provides an output file for the proper use of this program the user must provide the input samples in mg l concentrations of 4 cations ca m g n a and k and 4 anions so 4 cl hco 3 and co 3 2 6 3 hybrid water types since these multidimensional models are based on the probability concept it is possible to find a final combined basic and hybrid types theoretically up to a total of 256 different water classes let us suppose that p i is the probability for a cation or anion where the subscript i varies from 1 to 4 for 4 cations or anions of these 4 probabilities let p m be the highest probability and p n be the second highest probability the conditions that define if the nomenclature is basic just a water type are as follows if p m 0 5 and p m p n 0 25 and p n 0 25 otherwise a hybrid two water types the highest probability class name followed by the next highest name nomenclature is assigned this condition allows us to determine up to 256 hybrid water types 16 16 given that for the 4 cations and anions separately 4 basic and 12 hybrid classes can be achieved verma et al 2021 3 results and discussion in this work we used the mmol l units as was suggested by verma et al 2021 because the initial assignment for 16 classes was achieved from the greater molar concentration concept of each cation and anion also the number of atoms of the chemical elements proved to be a feasible way to determine water types 3 1 training of the new multidimensional models the 7 variables hlr 2 to hlr 8 calculated from the molar concentrations mm l of 4 cations ca 2 mg 2 na k and 4 anions so 4 2 cl hco 3 co 3 2 of the training set were used to train the wclasscb wclassvl wclassvp and wclassvr models the training database has 12297 12584 12484 12 635 samples respectively for each cation class and 12451 12424 12553 12 572 samples for each anion class both parts of the classification were determined by the greater cation and anion on the other hand the outlier free database used for training the wclasshlr model has 11368 11585 11559 11 780 samples for each cation class and 11523 11516 11667 11 586 samples for the anion classes this criterion is called gmc which stands for greater molar concentration model to designate initial water types verma et al 2021 from scikit learn gridsearchcv python module pedregosa et al 2011 we selected a set of hyperparameter for each model by searching the equilibrium point between good regularization and accuracy the selected hyperparameters along with their accuracy values are listed in table 2 the depth equal to 4 table 2 and table s2 for the wclasscb model was selected because very large depths could prone to overfit huang et al 2019 the c regularization parameter equal to 10 for the wclassvl wclassvp and wclassvr models was selected since small values achieved a better generalization géron 2019 the tested parameter settings are listed in tables s2 and s3 the training of the models was executed in an intel core i7 9750h cpu we present the results of the training process which shows the accuracy of each class in the selected classification methods the wclasshlr model provided a success value of 90 83 for ca 10 325 samples correctly classified 91 06 for mg 10 549 samples correctly classified 93 60 for na 10 819 samples correctly classified and 93 84 for k 11 054 samples correctly classified the overall success of the wclasshlr model is 92 34 that corresponds to 42 747 samples correctly classified of a total of 46 292 samples of the outlier free database verma et al 2021 whereas a total of 3 545 samples incorrect classified which corresponds to 7 66 of the total database for the classification of anion classes so 4 c l hco 3 co 3 the individual class success goes from 92 75 to 93 75 providing an overall classification accuracy of 93 04 the overall classification accuracy of the remaining models for predicting the cation and anion classes are 99 71 and 99 96 for wclasscb 99 67 and 99 77 for wclassvl 98 34 and 99 38 for wclassvp and 98 96 and 99 26 for wclassvr percent and number of samples incorrectly classified are also listed in table 3 3 2 external validation of all classification models the external validation database contains a total of 8 000 samples on molar concentrations mm l each consisting of 8 ions ca 2 mg 2 na k so 4 2 cl hco 3 co 3 2 this database is independent of the set used to train the wclasscb wclassvl wclassvp and wclassvr models model wclasshlr was also applied to this external dataset in table 4 we show the values of classification accuracy macro average precision and macro average recall for training and external validation sets for each model for the training set wclasscb presented the best overall results for both cations 99 71 and anions 99 96 models in all metrics wclassvl is the second best model to classify both cations 99 67 and anions 99 77 in this set further wclassvr wclassvp and wclasshlr models are in third fourth and fifth place respectively on the other hand for the external validation set wclassvl presented the best overall results for both cations 99 51 and anions 99 84 models in all metrics while wclassvp wclassvr wclasscb and wclasshlr models are in the second third fourth and fifth place the macro average auc scores for each model are presented in table s6 all models have an auc score equal to 1 in both training and external validation sets 3 3 application for field samples in this section we present four application cases for illustrating figs 5 and 6 the use of these classification schemes wclasshlr wclasscb wclassvl wclassvp and wclassvr models as well as the gmc model these application cases are constituted by groundwater samples from india and nigeria of each application case only the samples with complete and non zero concentrations in the 8 major ions were selected we used l2 normalization to scale field water samples before applying the models based on catboost and svm this normalization was not used for the wclasshlr model as it was not part of the original proposal by verma et al 2021 for these application cases we also show the results obtained from ccwater program pérez espinosa et al 2019 for the application of hill piper diagrams 3 3 1 groundwater from nirmal province south india chemical compositions of 34 groundwater samples of nirmal province in south india were presented by adimalla et al 2019 only 28 samples fig 5a with complete and non zero concentrations in the 8 major ions were selected the chemical composition mmol l and results of water classification obtained for all the models are presented in table 5 the water types determined by the major ions criteria gmc column in table 5 are distributed only in two water types na c l 21 samples and na h c o 3 7 samples the hill piper diagram through ccwater program pérez espinosa et al 2019 fig 6b and table 5 indicates that the samples are spread over in three zones as follow 17 samples of zone 7 noncarbonate alkali 50 alkalies and strong acids dominate 10 samples of zone 9 no cation anion pair 50 and 1 sample of zone 5 carbonate hardness 50 alkaline earths and weak acids dominate the water nomenclature column provides the water nomenclature a total of 16 basic classes and the hybrid water nomenclature column can provide up to 256 hybrid water classes all models performed well in classifying the water types particularly the wclasshlr wclasscb and wclassvp models which correctly predicted all water samples the remaining models wclassvl and wclassvr incorrectly predicted only one sample nt 18 the wclasshlr model unlike the other models obtained hybrid types of water for most of the samples 26 out of a total of 28 the wclassvp model identified 4 samples as hybrid types and the remaining models identified only 1 sample as a hybrid type a graphical representation of the mmol l concentrations of these 28 groundwater samples is presented in fig 5a 3 3 2 carbonate aquifers samples from ngbo ebonyi state nigeria ifediegwu et al 2019 reported compositional data of 10 samples collected from pit lakes pl hang dug wells hdw boreholes bh and rivers rs from ngbo and environs in ebonyi state southeastern nigeria to ascertain the major ion chemistry and quality of waters for domestic and drinking uses a graphical representation of the mmol l concentrations of these 10 samples is presented in fig 5b where each sample is identified by the initials of the place where they were sampled these samples were processed through all the classification models and the results of each model including the basic and hybrid water nomenclature are summarized in table 6 these authors used the hill piper diagram piper 1944 to determine the water types units in meq l they did not used the segmented diamond but part of the diagram to determine the major cation and anion in all the samples they determined that the main water types were ca c o 3 and mg h c o 3 the hill piper diagram ccwater program pérez espinosa et al 2019 fig 6b and table 6 indicates that all samples are of zone 5 alkaline earths and weak acids dominate the initial gmc criteria based nomenclature indicated that the carbonate aquifers from ngbo samples were distributed as follows ca c o 3 3 samples ca c l 1 sample ca h c o 3 4 samples mg c o 3 1 sample and mg h c o 3 1 sample considering the gmc criterion as a reference the wclassvl model obtained the highest number of coincidences or correctly classified samples with 9 out of 10 samples followed by wclasshlr model with 8 out of 10 samples wclassvp 5 samples wclassvr 2 samples and wclasscb 2 samples in this dataset wclassvl was the best model only 1 misclassification in the hybrid water nomenclature table 6 wclasshlr model obtained hybrid types of water for all samples wclassvl and wclassvp predicted 3 samples as hybrid water types wclasscb model predicted only 1 and s wclassvr did not identify any 3 3 3 fluoride rich groundwater from sattenapalle region guntur district andhra pradesh india chemical compositions of 30 fluoride rich groundwater samples from sattenapalle region guntur district andhra pradesh india were reported by subba rao et al 2019 of which only 19 samples were processed through the classification models fig 5c and samples with missing concentrations were discarded the chemical composition of each sample is presented in table 7 along with the classification of each model the hill piper diagram through ccwater program pérez espinosa et al 2019 indicated that the water samples are spread over in three zones as follow fig 6c and table 7 3 samples of zone 7 alkalies and strong acids dominate 9 sample of zone 5 alkaline earths and weak acids dominate and 7 samples of zone 9 no cation anion pair 50 the initial gmc criteria based nomenclature indicated that these samples were distributed as follows ca c l 1 sample ca h c o 3 3 samples mg c l 1 sample mg h c o 3 2 samples na c l 5 samples and na h c o 3 7 samples considering the gmc nomenclature as a reference the wclassvl model obtained all correctly classified samples followed by wclasshlr wclassvp and wclassvr models which only had a single misclassified sample and the wclasscb model had only two mistakes out of a total of 19 samples in the hybrid water nomenclature table 7 wclasshlr model obtained hybrid types for all samples and wclassvp wclasscb wclassvl and wclassvr models obtained hybrid types for 5 3 2 and 2 samples respectively 3 3 4 groundwater from point calimere wetland in lower cauvery region india the chemical composition of 9 water samples was reported by sajil kumar et al 2020 from point calimere wetland which is in the vedaranyam block of nagapattinam district in india these samples were collected to assess the impact and sources of saline intrusion on groundwater these authors used the hill piper diagram piper 1944 and reported that 83 of the samples are na c l type and the remaining samples are of ca n a h c o 3 type only 8 samples fig 5d with complete data were processed by the classification models fig 2d the chemical composition mmol l and water nomenclature determined by the models are shown in table 8 according to the major ions criteria gmc all 8 samples are na cl type all models classified all 8 samples correctly and only wclasshlr model identified hybrid water types 7 samples the hill piper diagram through ccwater program pérez espinosa et al 2019 fig 6d and table 8 indicates that 7 samples belong to zone 7 alkalies and strong acids dominate and 1 sample to zone 9 no cation anion pair 50 4 discussion the training and external validation datasets consist of synthetic samples that were generated from monte carlo simulations all synthetic samples presented an ionic charge imbalance almost perfectly at better than 0 00004 the initial 16 classes were assigned from the highest anion and cation molar concentrations seven variables hlr 2 to hlr 8 previously calculated with the mmol l concentrations of the 4 major cations ca 2 mg 2 na k and the 4 major anions so 4 2 cl hco 3 co 3 2 were used as features for the training of classification models the four new multidimensional water classification models wclasscb wclassvl wclassvp and wclassvr were successfully developed and were compared with the wclasshlr model proposed by verma et al 2021 all models were enabled to provide the type of hybrid water wclasscb and wclassvl models had the highest performances on the training set wclassvl model had the highest performance on the external validation set the assemble model wclasshlr had the lowest performance both in the training and external validation set all anion classification models have better performance than the cation classification ones finally this work involves standardized practices for the development of machine learning models using simulated data the recently proposed wclasshlr 7 hlr model verma et al 2021 has the advantage of generating a graphical output using the discriminant functions the new models wclasscb wclassvl wclassvp wclassvr can easily process up to 50 000 water samples on a single run also the output probabilities from these models allow us to determine hybrid water types which increase the number of hydrochemical facies that can be determined this is impossible with traditional methods such as hill piper diagram and its derivatives this is a significant improvement considering that classical approaches have fewer possible hydrochemical facies resulting in ambiguous water types 5 conclusions this work highlights the importance and applicability of machine learning models for water multidimensional classification using rich volumes of data generated through monte carlo simulations the developed water classification models on this work would afford better benefits than the traditional methods e g hill piper diagram since our ml models accurately offer a diversity of basic and hybrid water types over performing those traditional models which only provide 5 to 6 types e g hill piper diagram and two of them zone 9 are ambiguous and overlap several water compositions we suggest that implementing these multidimensional models should replace the use of classical methods such as hill piper diagrams because the usage of ternary diagrams had been shown severe problems like distortion and amplification reduction of analytical errors as was mentioned by many researchers before the usefulness of the new models wclasscb wclassvl wclassvp and wclassvr and wclasshlr model is illustrated by applications to groundwater samples from india and nigeria considering the performance of the models in real cases we can see that all have difficulties in real samples when there is not a single major cation or anion for example nt 18 see cl and hco 3 sample from nirmal province india adimalla et al 2019 and bh1 see hco 3 and co 3 sample from ngbo ebonyi state nigeria ifediegwu et al 2019 when these cases occur it is highly useful for the model to provide hybrid water types in this context one of the main advantages of the wclasshlr model is that identifies more hybrid types than other models however wclassvl is the best model overall because shows higher classification accuracy in the external validation dataset and identifies basic and hybrid water types when there are similar molar concentrations then we highly recommended the use of wclassvl model with hybrid water nomenclature in any future applications for water multidimensional classification credit authorship contribution statement lorena díaz gonzález supervision conceptualization methodology writing review editing oscar alejandro uscanga junco methodology resources software validation visualization mauricio rosales rivera conceptualization methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126234 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4509,we proposed four new models wclasscb wclassvl wclassvp wclassvr for water classification using categorical boosting catboost and support vector machines svm with three kernels linear polynomial and radial basis function the new models were compared with the recently proposed wclasshlr 7 hybrid log ratio model based on linear discriminant analysis and canonical analysis techniques a training database 50 000 samples and another independent validation database 8 000 samples of ionic charge balanced concentrations of 4 cations ca m g n a and k and 4 anions so 4 cl hco 3 and co 3 were generated through monte carlo simulations the initial 16 classes were assigned from the highest cation and anion molar concentrations gmc criteria i e greater molar concentration model seven hybrid log ratio transformations were used as features for training and external validation of the multidimensional classification models these models generate probability values for each of the output classes allowing us to determine hybrid water types improving the possible water types to 256 wclasscb model showed the best accuracy values in the training set however wclassvl model is the recommended procedure because it generalizes better than other models in the external validation set the new models outperform the recently proposed wclasshlr with up to a 7 difference the usefulness of all models wclasshlr wclasscb wclassvl wclassvp wclassvr is illustrated by four applications to groundwater samples from india and nigeria all models have difficulties in classifying real samples when there is more than one major cation or anion but they can recover the classification suggesting hybrid water types the new computer program waterclasys ml has been developed for applying these new models keywords machine learning gradient boosting support vector machines hill piper diagram molar concentrations monte carlo simulation groundwater samples 1 introduction water type based on hydrochemical facies evaluation is extremely useful in providing a preliminary idea about the complex hydrochemical processes at the subsurface sajil kumar 2013 thus there have been many attempts to identify their nomenclature and develop easy to use techniques durov 1948 handa 1965 romani 1981 chadha 1999 ahmad et al 2003 giménez forcada 2010 elhag 2017 shelton et al 2018 güler et al 2002 evaluated graphical and multivariate statistical methods for water classification such as schoeller semi logarithmic diagrams schoeller 1955 and principal component analysis pca even though multiple ideas have been explored the most used tools to identify hydrochemical facies are derived from the popular hill piper diagram piper 1944 this technique is based on two ternary diagrams constructed from the normalized milliequivalent per liter meq l concentrations of the cations ca 2 mg 2 na k and anions so 4 2 cl hco 3 co 3 2 and then projected in a diamond field to identify hydrochemical facies many other techniques such as durov diagram durov 1948 and chadha diagram chadha 1999 are also popular approaches to determine water classification which use trilinear diagrams or percent values of the chemical composition however there are severe problems like distortion and amplification reduction of analytical errors in these diagrams caused by closure and constant sum problems chayes 1960 1971 aitchison 1986 because crude compositional variables represent a closed unit sum constrained system and ternary diagrams impose a further unit sum constraint on any experimental data these diagrams become statistically unsuitable to handle experimental data verma 2012 the ternary diagram problems were stressed by aitchison 1986 and verma 2012 2015 aitchison 1986 proposed solutions to overcome the constant sum difficulties through a multivariate approach by calculation of ratios and log ratio transformations instead of using crude compositions this approach eliminates the compositional units and renders the compositions as simple numbers opening the space error propagation through monte carlo simulations was reported for the first time by verma 2012 to illustrate the inconvenience of using ternary diagrams for compositional data and instead a natural logarithm transformed bivariate diagram was suggested afterward verma 2015 compared ternary diagrams against bivariate diagrams using linear discriminant and canonical analysis ldca and also compared the performance of three types of log ratio transformations additive and centered proposed by aitchison 1986 and isometric proposed by egozcue et al 2003 concluding that the bivariate diagrams were a better option to visualize and interpret compositional data because they do not show the analytical distortion error problems moreover the three log ratios showed similar results later verma et al 2016 and verma and armstrong altrin 2013 used a hybrid log ratio hlr transformation which differs from the other transformations isometric additive and centered defined in the section of methods hybrid log ratio transformation however the performance of the hlr is little known in the literature also verma et al 2020 compared the isometric and hlr transformation concluding that when both transformations were applied to the same database of major element compositions of igneous rocks in conjunction with the ldca the same results were obtained similar conclusions were achieved earlier by verma 2015 for the isometric additive and centered transformations this consistency has shown that it does not matter which transformation is used for a multidimensional classification using major element concentrations furthermore according to piper 1944 most natural water contains relatively few dissolved constituents with cations metals or bases and anions acid radicales in chemical equilibrium with each other the most abundant cation constituents are two alkaline earth ca 2 and mg 2 and one alkali na k also occurs but ordinarily is much less abundant than na similarly the most common anion constituents are one weak acid hco 3 and two strong acids so 4 2 and cl other cations and anions occur in considerable quantities in highly concentrated waters however piper 1944 suggested that all these less abundant constituents can be added with the major three constituents to which they are respectively related in chemical properties e g ca 2 with barium ba 2 or strontium sr 2 na with k cesium cs rubidium rb lithium li or ammonium nh 4 hco 3 with co 3 or tetraborate b 4 o 7 2 cl with fluoride f nitrate no 3 or nitrite no 2 thus a water sample is treated on hill piper ternary diagram substantially as though it contains only three cation constituents and three anion constituents this explains why the cations na and k are ordinarily combined as the anions hco 3 and co 3 and this approach reduces the number of possible hydrochemical facies that can be determined by ternary diagrams therefore since our scheme for water multidimensional classification is not based on ternary diagrams we decided that it would be worthwhile to explore a new classification scheme without combining any of these 8 ionic species the 7 hlr model recently presented by verma et al 2021 denoted as wclasshlr was developed using ldca and the hybrid log ratio hlr transformations of the millimoles mm l concentrations of 8 major ions without combining any of them for wclasshlr model a representative database from monte carlo simulations law and kelton 2000 verma and quiroz ruiz 2006 was generated defined in section methods database simulation procedure this initial classification of each simulated sample was achieved from the greater molar concentration concept of each cation and anion called the greater molar concentration gmc criteria the 16 classes were all set to similar sizes minimum size 3021 samples maximum size 3247 samples see table 1 before undertaking the ldca classes were free censored from multivariate discordant outliers each class was processed through domudaf discordant outlier from multivariate data through f test of w verma et al 2016 program for the detection and separation of multivariate discordant outliers because ldca require that the individual classes be multi normally distributed in terms of the features 7 hlr variables domudaf program detects multivariate discordant outliers through a transformation of the wilks statistic w wilks 1963 to the well known f test a total of 46 292 multivariate discordant outlier free samples were obtained from domudaf for training the ldca the statistical characteristics of outlier free multivariate data are summarized in table s1 finally the wclasshlr model was obtained using the 16 classes initially assigned and from the probability concept it was possible to identify hybrid water types along with the basic types of water thus wclasshlr model under the hybrid option defined in section methods hybrid log ratio transformation can classify as many as 256 different water classes machine learning ml techniques have been used in many aspects of hydrological science e g acharya et al 2019 but mainly to classify or estimate water quality muhammad et al 2015 wang et al 2017 gakii and jepkoech 2019 abba et al 2020 gaya et al 2020 melesse et al 2020 lu and ma 2020 liang et al 2020 banadkooki et al 2020 tung and yaseen 2020 zhou 2020 bayram and gultekin 2010 proposed an artificial neuron network ann model to classify water samples from simav geothermal area in western turkey this model classify the samples into 4 different classes eynal çitgöl geothermal water and cold water the model indeed have good results however this classification is not a general nomenclature that could be used as hydrochemical facies also ml techniques such as support vector machines svm and random forest rf have been used for flood susceptibility mapping nachappa et al 2020 ni et al 2020 compared the following three ml models extreme gradient boosting model with gaussian mixture model xgb standalone xgboost and svm to provide streamflow forecasting wu et al 2019 conducted a comparison of eight ml models i e ann rf gradient boosting decision tree gbdt xgboost multivariate adaptive regression spline mars svm and kernel based nonlinear extension of arps decline knea model for the estimation of monthly mean daily reference evapotranspiration which is important in hydrology research irrigation scheduling design and water resources management and svm and xgboost comparison for streamflow forecasting yu et al 2020 in general all the ml techniques show good results over other techniques employed particularly the svm and xgb models in this work our main aims are summarized as follows i to generate a training database n 50 000 samples and another independent validation database n 8 000 samples through monte carlo simulations methods databases simulation procedure available in the public server https github com usju water databases ii to develop four new nonparametric models wclasscb wclassvl wclassvp wclassvr for water nomenclature through the molar concentrations of 8 ions ca 2 mg 2 na k so 4 2 cl hco 3 and co 3 2 from two machine learning techniques based on gradient boosting and support vector machines methods classification methods and hlr transformation methods hybrid log ratio transformation iii to develop the new models on python following standard machine learning practices methods training and validation of models such as hyperparameter optimization and training and evaluation metrics which performance up to 99 was achieved this python program is available in the public server https github com usju water training test models iv to develop a post processing program to identify hybrid water types in the four machine learning models from probabilities generated for each of the output basic classes v to compare through machine learning metrics section of methods models evaluation metrics the performance of these four nonparametric models with wclasshlr model verma et al 2021 to find which technique performs better to determine hydrochemical facies in water samples vi to illustrate the usefulness of all the models by four applications on real groundwater samples from india and nigeria and vii to develop a program on python for the effective use of the new four machine learning models which is available in the public server https github com usju water classification ml 2 methods 2 1 training database the training and the independent validation databases consist of 50 000 samples and 8 000 samples on molar concentrations mm l with 4 cations ca 2 mg 2 na k and 4 anions so 4 2 cl hco 3 co 3 2 respectively the generated databases are described in the following section 2 2 databases simulation procedure the monte carlo procedure suggested by verma and quiroz ruiz 2006 shows how to assess the randomness of uniformly distributed numbers i e iid u 0 1 and to generate normally distributed samples i e iid n 0 1 using different seeds to guaranteed the randomness of such values via numerical simulation following these suggestions our monte carlo sampling simulation can be summarizing as follows generate n individual uniformly distributed numbers iid u 0 1 for each element ca 2 mg 2 na k so 4 2 cl hco 3 and co 3 2 using the mersenne twister pseudo random number generator algorithm matsumoto and nishimura 1998 where n took values of 50 000 samples for the training dataset and 8 000 samples for the independent validation dataset compute a scalar value of 100 to cover the representability of the ternary diagrams fig s2a the representativeness of the initial database is illustrated by plotting the simulated in a cation ternary diagram ca 2 mg 2 na fig 1 a and an anion ternary diagram so 4 2 cl hco 3 fig 1b use the icb equation ionic charge balance equation nicholson 1933 as icb c a t i o n s a n i o n s c a t i o n s a n i o n s where c a t i o n s o r a n i o n s are given on milliequivalent per liter meq l units also a value of 0 00005 was established as the maximum unbalance however as the samples were randomly generated we proceed to apply the following unbalance factor as factor c a t i o n s a n i o n s to assess the charge balance in our simulated database this unbalance factor is applied to a pseudo random increment from 0 to 10 for each element the ionic charge balance validation procedure is shown in fig s1 which enabled the selection of samples with icb 0 00005 for a better dataset setting a histogram of the database after the icb procedure is presented in fig s2b determine the cross combination of majoritarian cation and anions of the simulated dataset table 1 the 16 classes achieved consist of cross combinations of 4 cations and 4 anions primary classes which were assigned from the highest anion and cation molar concentrations table 1 listed under the column water class the statistical characteristics of the multivariate database number of samples n median x maximum and minimum values are summarized in table 1 this database has 16 balanced or equal sized classes minimum size 3021 samples maximum size 3247 samples see table 1 2 3 hybrid log ratio transformation we decided to use hlr transformation based on the previous comparisons reported by verma 2015 2020 where it concluded that is not relevant which transformation is chosen for multidimensional classification using major element concentrations the hlr transformation of the molar concentrations mm l of 8 elements ca 2 mg 2 na k so 4 2 cl hco 3 and co 3 2 were calculated using the following general equation hlr i 1 l n g x i x n 1 n x i 1 i 1 2 n 1 where g denotes the geometric mean x i represent the concentration of each element in the same order c a m g n a k so 4 c l hco 3 co 3 1 8 x i 1 denotes one ion at a time from second mg 2 to last co 3 2 and n subscript is the total number of major elements n 8 for more information about hlr transformation see a1 additional details on hybrid log ratio transformation section in appendix a thus the seven hlr variables hlr 2 to hlr 8 eqs s1 to s7 were used as features for training the multidimensional classification models a histogram of the hlr transformations is presented in fig s2c according to aitchison 1986 and aitchison and egozcue 2005 in any discipline when a problem is compositional we are recognizing that the sizes of our specimens are irrelevant for example a geologist talking about the composition of an object such as the major oxide composition of a rock is declaring as a dimensionless problem there is no concern about whether the rock specimen weighs one gm or one lb compositions are concerned with relative values and ratios of components the geometric mean was used in the clr and ilr transformations proposed by aitchison 1986 and egozcue et al 2003 respectively for the treatment of compositional data using the geometric mean on the components of a sample has the advantage of treating the parts symmetrically and is a reasonable way to measure the dependence between the composition parts in this work as the water components are charge balanced concentrations of 4 cations ca m g n a and k and 4 anions so 4 cl hco 3 and co 3 the geometric mean was applied considering that these components are chemically related the geometric mean use relies on the fact that it considers the cumulative and compound effects spizman and weinstein 2008 moreover the geometric mean is closely related to the log transformation in statistics which is widely used for skewed data feng et al 2013 furthermore the geometric mean has been used in a very broad range of natural and social science disciplines like environmental monitoring scientometrics nuclear medicine infometrics economics finance ecology surface and groundwater hydrology geoscience and geomechanics vogel 2020 2 4 classification methods 2 4 1 wclasshlr model generated by ldca the 7 hlr model proposed by verma et al 2021 denoted as wclasshlr consists of an assembly of classifiers created by ldca which is a supervised classification technique that consists of finding a one dimensional linear function that discriminates between the classes by the measure of maximum separation and serves as a basis for classifying samples of unknown classes this methodology maximizes the distance between the classes and minimizes the distance between the samples for each class the main idea was to achieve a classification model for cations and another for anions however for 4 groups the ldca would provide 3 discriminant functions requiring a three dimensional diagram to visualize them therefore 3 groups were evaluated at the same time which required making 4 2d models for cations ca m g n a and k and 4 2d models for anions so 4 c l hco 3 and co 3 the 16 water types could thus be classified by cross combinations each of these models has the advantage of being visualized in 2d diagrams using two discriminant functions which can be represented in a general form in eq s8 see a2 additional details on linear discriminant and canonical analysis ldca section in appendix a the wclasshlr model consists of 8 sub models 4 for cations and 4 for anions containing 16 dfs 128 coefficients table s2 and 48 centroids table s3 for example the d f 1 h c a m g n a and d f 2 h c a m g n a required for the classification of ca m g n a can be calculated from eqs s9 and s10 for the other cation sub models of three at a time ca m g k c a n a k and m g n a k the discriminant functions can be similarly calculated see coefficients in table s2 the classification of anions so 4 c l hco 3 and co 3 was similarly achieved from 4 sub models of the three at a time type the final water nomenclature is achieved from probability calculations for the competing fields in all three at a time sub models and their comparison 2 4 2 gradient boosting catboost technique catboost i e categorial boosting works by sequentially adding weak predictors to make a strong classifier each predictor of the assemble is trained with the residual errors of its predecessor géron 2019 catboost is a process of constructing an ensemble model strong classifier by performing gradient descent in a functional space prokhorenkova et al 2018 categorical boosting is an open source library that implements a modification of the standard algorithm it uses binary decision trees as weak predictors that make up the assemble which divide the feature space into disjoint regions according to the values of some splitting attributes prokhorenkova et al 2018 catboost is available as a python library and uses scikit learn pedregosa et al 2011 framework 2 4 3 support vector machines svm technique svm are supervised machine learning algorithms that are used for classification and regression purposes when it comes to classification samples of the form x i y i i 1 n can be classified by a hyperplane which optimizes the distances between itself and the closest vectors of each class these vectors are called support vectors and are examples from the training set the distance between the vectors and the classes is called margin géron 2019 fig 2 diagram illustrates these concepts visually in svm our main objective is to select a hyperplane with the maximum possible margin between support vectors in the given dataset the hyperplane can be expressed as f x ω ϕ x b where x is the input data ϕ x represents a kernel function that projects x into the high dimensional feature space ω and b are the coefficients estimated by the svm procedure huang et al 2019 svms use the so called kernel trick that allows using a kernel function denoted as k x z which makes it possible to map the dot product of vectors x z in high dimensional space géron 2019 when samples are projected in a higher dimensional space by the kernel function the additional dimensions afford a greater opportunity to find a hyperplane that separates classes wadkar et al 2019 svms are recommended when it is needed to perform classification on complex small or medium datasets as in our dataset of 50 000 samples géron 2019 in this work we use and evaluate svms with three different kernel functions linear l polynomial p and radial basis function rbf svms are used through scikit learn s svc module pedregosa et al 2011 2 4 4 new water classification models wclasscb wclassvl wclassvp wclassvr to carry out the water classification models through catboost and smv techniques a general computational methodology was developed fig 3 a total of 50 000 simulated analyses of ionic charge balanced concentrations of 8 major elements ca m g n a k so 4 c l hco 3 co 3 mmol l were used for training models the hlr transformations of the millimoles mm l concentrations of the 8 ions were calculated after two ml techniques based on gradient boosting and support vector machines were applied 2 4 4 1 gradient boosting catboost implementation catboost is a machine learning algorithm that uses gradient boosting on decision trees we applied this algorithm from the catboost catboostclassifier python module the multiclass support is handled according to a one vs rest scheme thus to classify 4 classes of cations ca m g n a and k 4 binary classifiers are constructed as follow i ca vs m g n a k ii m g vs c a n a k iii n a vs c a m g k and iv k vs c a m g n a the classification of anions so 4 c l hco 3 and co 3 was similarly completed from 4 sub models of the one to rest type fig 3 the decision trees were used for these classifiers each of the trees corresponds to a partition of the feature input variables hlr 2 to hlr 8 space and the output value a decision rule is used for each level of the tree acting as the splitting criterion each decision rule can be conceptualized as a pair r k v that contains a feature index r 1 m and a threshold value v r thus a set of feature vectors x can be split into two disjoint subsets of x l and x r kang et al 2019 then for each x x 1 x n x we have that x x l i f x k v or x x r i f x k v then applying the decision rule to s disjoint sets x 1 x s r m the total number of disjoint sets is 2 s x 1 l x 1 r x s l x s r kang et al 2019 once the models were trained we used the predict and predict proba functions of the sklearn svm svc library to perform classification on unknown water samples the predict function applies the model to the given dataset and the predict proba function generates the probability that the object belongs to the given classes the catboost based model named wclasscb can be used in the executable program available at the public server https github com usju water classification ml 2 4 4 2 support vector machines svm implementation for svm the sklearn svm svc library pedregosa et al 2011 was used the multiclass support is handled according to a one vs one scheme thus to classify 4 classes of cations ca m g n a and k 6 binary classifiers n classes n classes 1 2 as follow i ca vs mg ii c a vs na iii ca vs k iv m g v s n a v mg vs k and vi na vs k the classification of anions so 4 cl hco 3 and co 3 was similarly achieved the final water nomenclature is achieved from probabilities for the competing fields in all sub models we applied linear wclassvl model polynomial wclassvp model and radial basis function wclassvr model kernel functions for details on the precise mathematical formulation of the kernels see the corresponding documentation provided by pedregosa et al 2011 in the linear kernel the hyperplane or decision function for discriminates of c 1 and c 2 classes can be constructed as hp c 1 c 2 w 1 h l r 2 w 2 hlr 3 w 3 hlr 4 w 4 hlr 5 w 5 hlr 6 w 6 hlr 7 w 7 hlr 8 b where hp c 1 c 2 is the hyperplane equation for discriminates of c 1 and c 2 classes hlr 2 hlr 8 are input variables w 1 to w 7 and b are the coefficients or adjustable parameters of the decision function for an unknown sample the hyperplane equation generates a positive or negative value for a sample classified as c 1 or c 2 class respectively once the svm models have been trained their coefficients and intercept values can be extracted through the functions coef and intercept respectively from sklearn svm svc library these coefficients are listed in table s3 and are used to construct the hyperplane functions df the wclassvl model consists of 12 one to one sub models 6 for cations and 6 for anions and 96 coefficients table s3 the wclassvl model final water nomenclature is achieved from probability calculations for the competing fields in all sub models when the kernel is not linear the sklearn svm svc library provides the coefficients dual coef and support vectors support vectors that are required to construct the hyperplane or decision function to keep this work short we only present the svl l model coefficients however we used the predict function from sklearn svm svc library to perform classification on unknown samples this function predicts the results using the trained model the proposed svm based models wclassvl linear kernel wclassvp polynomial kernel and wclassvr radial basis function kernel can be used through the waterclasys ml executable program available at the public server https github com usju water classification ml 2 5 training and validation of models 2 5 1 hyperparameter tuning since ml algorithms have many hyper parameters to tune this process has been automated hyperparameter tuning was done through gridsearchcv module from scikit learn pedregosa et al 2011 which for given values exhaustively considers all parameter combinations gridsearchcv uses a 5 fold cross validation procedure of which 80 four subsets is used to train and the remaining 20 one fold is used to validate the model the process makes combinations of the folds where all subsets are used as a validation set at least once the cross validation was executed per combination of given hyperparameters the best hyperparameters were selected by looking at the average accuracy of each cross validation heung et al 2016 once a set of hyperparameters is selected it is used to train the model with the complete training dataset the general procedure for the training and evaluation of the ml models wclasscb wclassvl wclassvp wclassvr and the cross validation procedure are shown schematically in fig 4 2 5 2 evaluation metrics to compare the performance of the models we use the following four metrics i classification accuracy eq s11 ii classification precision eq s12 iii recall eq s13 and the number of false positives eq s14 these metrics are calculated for all possible classification thresholds géron 2019 an ideal model with high precision and high recall will return many results with all results classified correctly and would have an auc close to 1 that tells us that the classifier is not making random decisions géron 2019 to achieve the prediction of multiple classes by the classifiers we compute the macro average precision eq s15 macro average recall eq s16 and macro average auc eq s17 using the one vs rest approach see a3 additional details evaluation metrics section in appendix a 2 6 application of the models 2 6 1 preprocessing of real samples before applying the models we used l2 normalization defined as x new x x 1 2 x 2 2 x 3 2 x n 2 where x is a sample vector and x new is the scaled vector to scale field water samples before the application of the classification models l2 norm is a standard method to compute the length of a vector in euclidean space l2 norm of a vector is defined as the square root of the sum of the squares of the values in each dimension the features or input variables hlr 2 to hlr 8 of field water samples non simulated water samples could have different scales and contain some extreme values which could degrade the predictive performance of the machine learning algorithms pedregosaet al 2011 2 6 2 waterclasys ml program it should be clear that it is difficult to use and evaluate these new classification schemes without a suitable computer program therefore a computer program waterclasys ml was written in python which is available on the public server https github com usju water classification ml and requires an input file and provides an output file for the proper use of this program the user must provide the input samples in mg l concentrations of 4 cations ca m g n a and k and 4 anions so 4 cl hco 3 and co 3 2 6 3 hybrid water types since these multidimensional models are based on the probability concept it is possible to find a final combined basic and hybrid types theoretically up to a total of 256 different water classes let us suppose that p i is the probability for a cation or anion where the subscript i varies from 1 to 4 for 4 cations or anions of these 4 probabilities let p m be the highest probability and p n be the second highest probability the conditions that define if the nomenclature is basic just a water type are as follows if p m 0 5 and p m p n 0 25 and p n 0 25 otherwise a hybrid two water types the highest probability class name followed by the next highest name nomenclature is assigned this condition allows us to determine up to 256 hybrid water types 16 16 given that for the 4 cations and anions separately 4 basic and 12 hybrid classes can be achieved verma et al 2021 3 results and discussion in this work we used the mmol l units as was suggested by verma et al 2021 because the initial assignment for 16 classes was achieved from the greater molar concentration concept of each cation and anion also the number of atoms of the chemical elements proved to be a feasible way to determine water types 3 1 training of the new multidimensional models the 7 variables hlr 2 to hlr 8 calculated from the molar concentrations mm l of 4 cations ca 2 mg 2 na k and 4 anions so 4 2 cl hco 3 co 3 2 of the training set were used to train the wclasscb wclassvl wclassvp and wclassvr models the training database has 12297 12584 12484 12 635 samples respectively for each cation class and 12451 12424 12553 12 572 samples for each anion class both parts of the classification were determined by the greater cation and anion on the other hand the outlier free database used for training the wclasshlr model has 11368 11585 11559 11 780 samples for each cation class and 11523 11516 11667 11 586 samples for the anion classes this criterion is called gmc which stands for greater molar concentration model to designate initial water types verma et al 2021 from scikit learn gridsearchcv python module pedregosa et al 2011 we selected a set of hyperparameter for each model by searching the equilibrium point between good regularization and accuracy the selected hyperparameters along with their accuracy values are listed in table 2 the depth equal to 4 table 2 and table s2 for the wclasscb model was selected because very large depths could prone to overfit huang et al 2019 the c regularization parameter equal to 10 for the wclassvl wclassvp and wclassvr models was selected since small values achieved a better generalization géron 2019 the tested parameter settings are listed in tables s2 and s3 the training of the models was executed in an intel core i7 9750h cpu we present the results of the training process which shows the accuracy of each class in the selected classification methods the wclasshlr model provided a success value of 90 83 for ca 10 325 samples correctly classified 91 06 for mg 10 549 samples correctly classified 93 60 for na 10 819 samples correctly classified and 93 84 for k 11 054 samples correctly classified the overall success of the wclasshlr model is 92 34 that corresponds to 42 747 samples correctly classified of a total of 46 292 samples of the outlier free database verma et al 2021 whereas a total of 3 545 samples incorrect classified which corresponds to 7 66 of the total database for the classification of anion classes so 4 c l hco 3 co 3 the individual class success goes from 92 75 to 93 75 providing an overall classification accuracy of 93 04 the overall classification accuracy of the remaining models for predicting the cation and anion classes are 99 71 and 99 96 for wclasscb 99 67 and 99 77 for wclassvl 98 34 and 99 38 for wclassvp and 98 96 and 99 26 for wclassvr percent and number of samples incorrectly classified are also listed in table 3 3 2 external validation of all classification models the external validation database contains a total of 8 000 samples on molar concentrations mm l each consisting of 8 ions ca 2 mg 2 na k so 4 2 cl hco 3 co 3 2 this database is independent of the set used to train the wclasscb wclassvl wclassvp and wclassvr models model wclasshlr was also applied to this external dataset in table 4 we show the values of classification accuracy macro average precision and macro average recall for training and external validation sets for each model for the training set wclasscb presented the best overall results for both cations 99 71 and anions 99 96 models in all metrics wclassvl is the second best model to classify both cations 99 67 and anions 99 77 in this set further wclassvr wclassvp and wclasshlr models are in third fourth and fifth place respectively on the other hand for the external validation set wclassvl presented the best overall results for both cations 99 51 and anions 99 84 models in all metrics while wclassvp wclassvr wclasscb and wclasshlr models are in the second third fourth and fifth place the macro average auc scores for each model are presented in table s6 all models have an auc score equal to 1 in both training and external validation sets 3 3 application for field samples in this section we present four application cases for illustrating figs 5 and 6 the use of these classification schemes wclasshlr wclasscb wclassvl wclassvp and wclassvr models as well as the gmc model these application cases are constituted by groundwater samples from india and nigeria of each application case only the samples with complete and non zero concentrations in the 8 major ions were selected we used l2 normalization to scale field water samples before applying the models based on catboost and svm this normalization was not used for the wclasshlr model as it was not part of the original proposal by verma et al 2021 for these application cases we also show the results obtained from ccwater program pérez espinosa et al 2019 for the application of hill piper diagrams 3 3 1 groundwater from nirmal province south india chemical compositions of 34 groundwater samples of nirmal province in south india were presented by adimalla et al 2019 only 28 samples fig 5a with complete and non zero concentrations in the 8 major ions were selected the chemical composition mmol l and results of water classification obtained for all the models are presented in table 5 the water types determined by the major ions criteria gmc column in table 5 are distributed only in two water types na c l 21 samples and na h c o 3 7 samples the hill piper diagram through ccwater program pérez espinosa et al 2019 fig 6b and table 5 indicates that the samples are spread over in three zones as follow 17 samples of zone 7 noncarbonate alkali 50 alkalies and strong acids dominate 10 samples of zone 9 no cation anion pair 50 and 1 sample of zone 5 carbonate hardness 50 alkaline earths and weak acids dominate the water nomenclature column provides the water nomenclature a total of 16 basic classes and the hybrid water nomenclature column can provide up to 256 hybrid water classes all models performed well in classifying the water types particularly the wclasshlr wclasscb and wclassvp models which correctly predicted all water samples the remaining models wclassvl and wclassvr incorrectly predicted only one sample nt 18 the wclasshlr model unlike the other models obtained hybrid types of water for most of the samples 26 out of a total of 28 the wclassvp model identified 4 samples as hybrid types and the remaining models identified only 1 sample as a hybrid type a graphical representation of the mmol l concentrations of these 28 groundwater samples is presented in fig 5a 3 3 2 carbonate aquifers samples from ngbo ebonyi state nigeria ifediegwu et al 2019 reported compositional data of 10 samples collected from pit lakes pl hang dug wells hdw boreholes bh and rivers rs from ngbo and environs in ebonyi state southeastern nigeria to ascertain the major ion chemistry and quality of waters for domestic and drinking uses a graphical representation of the mmol l concentrations of these 10 samples is presented in fig 5b where each sample is identified by the initials of the place where they were sampled these samples were processed through all the classification models and the results of each model including the basic and hybrid water nomenclature are summarized in table 6 these authors used the hill piper diagram piper 1944 to determine the water types units in meq l they did not used the segmented diamond but part of the diagram to determine the major cation and anion in all the samples they determined that the main water types were ca c o 3 and mg h c o 3 the hill piper diagram ccwater program pérez espinosa et al 2019 fig 6b and table 6 indicates that all samples are of zone 5 alkaline earths and weak acids dominate the initial gmc criteria based nomenclature indicated that the carbonate aquifers from ngbo samples were distributed as follows ca c o 3 3 samples ca c l 1 sample ca h c o 3 4 samples mg c o 3 1 sample and mg h c o 3 1 sample considering the gmc criterion as a reference the wclassvl model obtained the highest number of coincidences or correctly classified samples with 9 out of 10 samples followed by wclasshlr model with 8 out of 10 samples wclassvp 5 samples wclassvr 2 samples and wclasscb 2 samples in this dataset wclassvl was the best model only 1 misclassification in the hybrid water nomenclature table 6 wclasshlr model obtained hybrid types of water for all samples wclassvl and wclassvp predicted 3 samples as hybrid water types wclasscb model predicted only 1 and s wclassvr did not identify any 3 3 3 fluoride rich groundwater from sattenapalle region guntur district andhra pradesh india chemical compositions of 30 fluoride rich groundwater samples from sattenapalle region guntur district andhra pradesh india were reported by subba rao et al 2019 of which only 19 samples were processed through the classification models fig 5c and samples with missing concentrations were discarded the chemical composition of each sample is presented in table 7 along with the classification of each model the hill piper diagram through ccwater program pérez espinosa et al 2019 indicated that the water samples are spread over in three zones as follow fig 6c and table 7 3 samples of zone 7 alkalies and strong acids dominate 9 sample of zone 5 alkaline earths and weak acids dominate and 7 samples of zone 9 no cation anion pair 50 the initial gmc criteria based nomenclature indicated that these samples were distributed as follows ca c l 1 sample ca h c o 3 3 samples mg c l 1 sample mg h c o 3 2 samples na c l 5 samples and na h c o 3 7 samples considering the gmc nomenclature as a reference the wclassvl model obtained all correctly classified samples followed by wclasshlr wclassvp and wclassvr models which only had a single misclassified sample and the wclasscb model had only two mistakes out of a total of 19 samples in the hybrid water nomenclature table 7 wclasshlr model obtained hybrid types for all samples and wclassvp wclasscb wclassvl and wclassvr models obtained hybrid types for 5 3 2 and 2 samples respectively 3 3 4 groundwater from point calimere wetland in lower cauvery region india the chemical composition of 9 water samples was reported by sajil kumar et al 2020 from point calimere wetland which is in the vedaranyam block of nagapattinam district in india these samples were collected to assess the impact and sources of saline intrusion on groundwater these authors used the hill piper diagram piper 1944 and reported that 83 of the samples are na c l type and the remaining samples are of ca n a h c o 3 type only 8 samples fig 5d with complete data were processed by the classification models fig 2d the chemical composition mmol l and water nomenclature determined by the models are shown in table 8 according to the major ions criteria gmc all 8 samples are na cl type all models classified all 8 samples correctly and only wclasshlr model identified hybrid water types 7 samples the hill piper diagram through ccwater program pérez espinosa et al 2019 fig 6d and table 8 indicates that 7 samples belong to zone 7 alkalies and strong acids dominate and 1 sample to zone 9 no cation anion pair 50 4 discussion the training and external validation datasets consist of synthetic samples that were generated from monte carlo simulations all synthetic samples presented an ionic charge imbalance almost perfectly at better than 0 00004 the initial 16 classes were assigned from the highest anion and cation molar concentrations seven variables hlr 2 to hlr 8 previously calculated with the mmol l concentrations of the 4 major cations ca 2 mg 2 na k and the 4 major anions so 4 2 cl hco 3 co 3 2 were used as features for the training of classification models the four new multidimensional water classification models wclasscb wclassvl wclassvp and wclassvr were successfully developed and were compared with the wclasshlr model proposed by verma et al 2021 all models were enabled to provide the type of hybrid water wclasscb and wclassvl models had the highest performances on the training set wclassvl model had the highest performance on the external validation set the assemble model wclasshlr had the lowest performance both in the training and external validation set all anion classification models have better performance than the cation classification ones finally this work involves standardized practices for the development of machine learning models using simulated data the recently proposed wclasshlr 7 hlr model verma et al 2021 has the advantage of generating a graphical output using the discriminant functions the new models wclasscb wclassvl wclassvp wclassvr can easily process up to 50 000 water samples on a single run also the output probabilities from these models allow us to determine hybrid water types which increase the number of hydrochemical facies that can be determined this is impossible with traditional methods such as hill piper diagram and its derivatives this is a significant improvement considering that classical approaches have fewer possible hydrochemical facies resulting in ambiguous water types 5 conclusions this work highlights the importance and applicability of machine learning models for water multidimensional classification using rich volumes of data generated through monte carlo simulations the developed water classification models on this work would afford better benefits than the traditional methods e g hill piper diagram since our ml models accurately offer a diversity of basic and hybrid water types over performing those traditional models which only provide 5 to 6 types e g hill piper diagram and two of them zone 9 are ambiguous and overlap several water compositions we suggest that implementing these multidimensional models should replace the use of classical methods such as hill piper diagrams because the usage of ternary diagrams had been shown severe problems like distortion and amplification reduction of analytical errors as was mentioned by many researchers before the usefulness of the new models wclasscb wclassvl wclassvp and wclassvr and wclasshlr model is illustrated by applications to groundwater samples from india and nigeria considering the performance of the models in real cases we can see that all have difficulties in real samples when there is not a single major cation or anion for example nt 18 see cl and hco 3 sample from nirmal province india adimalla et al 2019 and bh1 see hco 3 and co 3 sample from ngbo ebonyi state nigeria ifediegwu et al 2019 when these cases occur it is highly useful for the model to provide hybrid water types in this context one of the main advantages of the wclasshlr model is that identifies more hybrid types than other models however wclassvl is the best model overall because shows higher classification accuracy in the external validation dataset and identifies basic and hybrid water types when there are similar molar concentrations then we highly recommended the use of wclassvl model with hybrid water nomenclature in any future applications for water multidimensional classification credit authorship contribution statement lorena díaz gonzález supervision conceptualization methodology writing review editing oscar alejandro uscanga junco methodology resources software validation visualization mauricio rosales rivera conceptualization methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126234 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
