index,text
3410,over the past few decades eco friendly channel construction has gained wide attention around the world including china as it considers both navigational and ecological functions the groin system is a hydraulic structure that can effectively increase the area of fish habitats groin shape has an influence on the local flow field and the scour and deposition pattern near the structure thereby affecting the adaptability of fishes to the groin fields in this study a new groin structure with a notch in its middle part was proposed a lab experiment was conducted on a physical model to investigate the characteristics of the flow field including patterns of water level distribution flow velocity distribution and scour and deposition on different submergence levels and incoming flows this experiment used four notch depths 0 unnotched 1 3 of groin height 2 3 of groin height and full groin height then the distribution of habitat suitability index hsi was calculated based on the assessment index system of the indicator fish species cyprinidae the results showed that the notches created in the middle of localized overflow groins had a significant effect on the surrounding flow pattern due to localized overflow both the flow velocity and the velocity gradient behind each groin increased the flow velocity behind each groin was positively correlated with notch depth while the flow velocity in the main channel was negatively correlated with notch depth under the complex flow conditions depositional features did not occur along the edges of the groin fields ensuring connectivity between groin fields and the main channel an analysis of water depth and flow velocity suitability indexes of cyprinidae suggests when notch depth is 2 3 of groin height the notched groins have good ecological effects especially in the groin fields keywords new groin structure localized overflow groin flow velocity distribution scour and deposition ecological effects 1 introduction hard revetments such as those made of stone blocks and mortar are usually used in traditional channel construction projects however hard revetments prevent substance exchange between river banks and water bodies causing the loss of many ecosystem functions ouillon and dartus 1997 this harms the habitat and reproduction of fishes and other aquatic organisms over the past decades eco friendly channel construction has gained wide attention around the world including china as it considers both navigational and ecological functions azinfar and kells 2011b yossef and vriend 2010a as a typical river training structure the groin system is popular in eco friendly channel construction bigham 2020 it can not only clear bed sediments by constraining flow and serve for river training but also provide a habitat for fishes by changing the surrounding hydrodynamic conditions studies by arlinghaus et al 2002 armstrong et al 2003 yossef and vriend 2010b and other researchers have shown that groin fields with shallow water and low flow velocities allow sediment deposition and vegetation growth and provide favorable habitats for fishes to spawn and forage chang et al 2019 investigated the flow behavior around a groin system along the yizheng section of the yangtze river and found that this groin system provided abundant food and a stable migration route for fishes by using netstars and tabs 2 modeling shih et al 2008 analyzed the effects of water depth and flow velocity on fish habitat with and without spur dikes they found that the spur dikes can offer additional fish habitat and the weighted usable area wua and proportion of usable area pua of fish habitat are associated with groin layout these studies confirm that groin systems have made an important contribution to river ecosystems and the flow behavior around them is one of the main factors in determining the quality of fish habitat followed by these excited find outs hydrodynamics around the structures of groin systems has become a hot topic for research kimura and hosoda 1997 kuhnle et al 2002 some scholars have conducted numerical research on this topic for example xu et al 2014 li et al 2016 and ma et al 2020 have created two dimensional and three dimensional mathematical models using the finite volume method and then analyzed the length and width of a recirculation zone downstream of a groin and the variation in shear flow along the river xing et al 2018 analyzed the hydrodynamics around groins by three dimensional numerical computation besides some researchers have systematically observed localized flow field scour and deposition and geometry of scour holes near groins ouillon and dartus 1997 xu et al 2014 yossef and vriend 2010a besides there is also experimental research on this topic for instance yossef and vriend 2010b investigated the flow near the dutch river waal by experimenting on a physical model on a 1 40 scale and found that the nature of the turbulence differs between submerged and emerged groins cai et al 2018 experimentally investigated the distribution patterns of flow velocity and water depth around groins and explored the effects of groin length and submergence level on flow force coefficient by conducting a physical model on a 1 40 scale uijttewaal 2005 investigated the properties of turbulence around four different types of groins i e standard reference groins extended impermeable groins fully permeable groins and semi permeable groins the results demonstrated that the intensity of recirculation and the nature of turbulence around groins are associated with the shape and permeability of groins the above studies indicate that the groin system is a hydraulic structure that can effectively increase the area of fish habitats and the adaptability of fishes to groin fields is related to groin shape submergence level groin layout and other conditions the characteristics of water flow around groins significantly affect the adaptability of fishes to groin fields however it remains unclear how groin shape affects flow fields and further affects the scour and deposition of sediment around the groin and the adaptability of fishes khosronejad et al 2013 former studies focused on the assessment of the suitability of aquatic habitat after the construction of large hydraulic structures while there is little research on the design of groin shapes the present study aims to explore the relationship between groin shape and the characteristics of scour and deposition and adaptability of fishes around a groin system to help coordinate the channel navigation and protection of the river ecosystem for this purpose a new notched groin structure was designed based on the new structure a system of eco friendly notched groins was built the system can build up the slow flow and shallow water environment in the groin fields and is supposed to achieve a more suitable flow condition for target species later a physical model in the 1 30 scale was used to analyze the characteristics of the flow field and scour and deposition in the groin fields as well as the advantages and disadvantages of different localized overflow groins moreover the habitat suitability functions for a typical fish species in the study area were analyzed to study the distribution of habitat suitability index hsi for local fishes finally a suggestion about notch depth for notched groins is made based on the research results 2 materials and methodology 2 1 stimulated natural river section in this study the hukou yumenkou section of the yellow river was selected as the simulation object and the spur dike system was arranged in the stimulated river fig 1 with a tortuosity of about 1 15 this section is characterized by its narrow valley which is largely u shaped in cross section as the water flow along the narrow valley is heavily constrained by the rock masses on the banks the river surface downstream of hukou ranges in width roughly from 90 m to 150 m during drought and from 200 m to 500 m during floods and the flow velocity is between 0 6 m s and 1 0 m s the riverbed from top to bottom is composed of fine sand sandy gravel and bedrock and the aquatic vegetation covers the riverbed in total it measures up to 80 m thick there are several point bars at different levels along the valley which are up to several meters above the design water level mid channel bars are found locally 2 2 design of modeling experiment for the results of experiments on a scale model can be applicable to the natural river it is necessary to scale the water flow water level and flow velocity for modeling according to the theory of similitude modeling of the whole river section allowed us to simulate the flow pattern around groins more comprehensively and accurately and obtain more accurate information about localized flow patterns and riverbed deformation however given the difficulty in setting the scale for the model it was quite challenging to create a physical model for the whole section and use it to investigate the ecological effects of the new groin structure proposed the physical model is set up in a 2 m width experimental flume therefore rather to establish a physical model of the entire river course we treated the interaction between water flow and groins as a two dimensional problem and the groin river width ratio μ which describes the degree to which the groin system narrows the water surface was introduced to set up the physical model 1 μ l b r l b m where l represents the groin length b represents the width of the river or the width of the flume in the experiment the subscript r represents the real case while the subscript m presents the physical model case in the hukou yumenkou section of the yellow river the river width roughly ranges from 200 m to 500 m during floods the groin length ranges from 60 m to 200 m accordingly the groin river width ratio μ then be obtained within the range between 0 3 0 4 in our experimental set up μ 0 35 and the length of the model groin was 70 cm based on the test site and equipment as well as the size of the studied river section and the dimensions of groins a normal model with a length scale of 1 30 was constructed the scales for each variable are obtained as follow 2 λ l λ h 30 3 λ v λ h 1 2 5 48 4 λ t λ l λ v 5 48 5 λ q λ h λ v 164 3 6 λ n λ h 1 2 λ h λ l 1 2 λ v 1 76 where λl represents the horizontal scale λh represents the vertical scale besides λv and λt represents the velocity scale and the time scale respectively λq represents the flow rate scale and λn represents the roughness scale besides the diameter of the plastic sand which is used to simulate the bed load is properly selected to make the sediment competent velocity scale approximately equal to the velocity scale in our experiment the diameter of the plastic sand is 0 3 mm its volume weight is 1 25 103 kg m3 the sediment competent velocity scale is 7 λ w 5 52 where λω represents the sediment competent velocity scale table 1 summarized all different scale factors used in this study the experimental conditions are shown in table 2 in this flume experiment the incoming flow was controlled by mag6000 with the precision of 0 2 a magnetic flow meter produced by siemens camarena 2008 guo et al 2019 further three water level gauges with the precision of 0 1 mm denoted as l1 l2 and l3 respectively were installed along the flume l1 was installed 0 5 m downstream the horizontal grate to measure the water level at the inlet l2 and l3 were installed at the locations where x 0 and x 6 4 to measure the water surface slope along the test section the 0 2 m thick plastic sand was paved throughout the flume within the 6 4 m long test section the sand bed was adjusted and shaped to the river bed topography then the target flow was introduced into the flume after the flow went steady water level gauges l1 l2 and l3 were then used to measure the water level all across the test field besides vectrino produced by nortek was employed to measure the flow field using three points method i e the flow field was identified by three velocities at 0 2 0 6 and 0 8 times flow depth from top to bottom the measurement range of vectrino is from 0 01 m s to 4 m s the experimental setup is shown in fig 2 after the test the riverbed elevation was measured using the total station trimble rts 771 2 3 structure and layout of notched groins the localized overflow structure was simplified based on the experimental conditions the groin structure was designed into a top small and down wide shape for it can stand steady in rivers its schematic diagram and dimensions are shown in fig 3 the groin model was composed of wire mesh cages filled with rock pieces whose diameters are greater than the mesh size thus forming a permeable structure the mesh cages were joined by lap joints and a notch was left in the middle of the groin the notch depth could be controlled by adjusting the height of the middle part of the groin based on the generalized flow conditions three different combinations of flow and water depth were used in the experiment ① q 0 0272 m3 s h 8 3 cm ② q 0 0493 m3 s h 12 5 cm and ③ q 0 0994 m3 s h 18 4 cm the notch depth was set at four values 0 cm unnotched groin 3 33 cm 1 3 of groin height 6 67 cm 2 3 of groin height 10 cm full groin height 16 measurement cross sections each with 6 measurement points were selected for measuring the water depth flow velocity and scour and deposition pattern around the groins fig 4 presents the layout of these measurement cross sections and points 2 4 indicator species and its habitat suitability index hsi in this paper the habitat suitability index hsi was used to relate flow parameters for the quantification of the adaptability of indicator species to the habitat hsi is an index designed to quantitatively score the specific flow parameter according to the study on the habitat preferences of the species by using the hsi the habitat suitability can be better compared among different river section designs situations the data shows that schizothorax a species of family cyprinidae is the typical fish in the study area yu et al 2010 since the hsi of schizothorax in this area is missing cyprinidae was selected for analysis of the habitat requirements of schizothorax living in the river section studied the hsi of cyprinidae measures the effect of different factors on this fish on a scale of 0 to 1 with 1 indicating the most suitable habitat for this fish and 0 indicating the least suitable habitat with the increase of the factor index the habitat suitability is considered to transition linearly from worst to best or best to worst rated on a scale between 0 and 1 by experiment and analysis as well as referring to the findings of fish s habitat suitability from the literature we obtained critical data about the criteria for cyprinidae habitat in the yellow river in different growth stages including quantitative criteria for water depth flow velocity and riverbed in adult fish habitat young fish habitat and spawning ground lei et al 2020 wu et al 2013 zhang et al 2010 these are presented in tables 3 and 4 according to this knowledge suitable flow depth and velocities for the general cyprinidae habitat can be obtained in this paper the habitat suitability functions for cyprinidae for different water depths and flow velocities are defined in fig 5 the water depth is calculated based on the measurements of water level and river bed elevation then the water depth suitability index can be evaluated at each sampling point according to fig 5 a based on the obtained water depth results accordingly the flow velocity suitability index at each sampling point can be calculated according to fig 5 b based on the velocity observation results 3 results see fig 4 both water level velocity and riverbed elevation are collected at each point especially we logged the information around the groin system in detail thus the distributions of water level and flow velocity can be obtained directly from our observation which makes the flow field around the groins looks vivid to us an example of water level distribution in the case of h 8 3 cm with unnotched groins is given in fig 6 by comparing the results from unnotched and notched groins important observations and findings are reported 3 1 distribution of water level fig 7 compares the water surface profiles along the ① and ⑤ longitudinal sections for different notch depths under the emerged h 8 3 cm and shallow submerged h 12 5 cm conditions the dotted lines in the figure indicate the locations of groins fig 7a and b revealed that in the zone near the left bank ① longitudinal section the backwater level did not change significantly with increasing notch depth due to the obstruction by groins however as the notch depth increases the water overflowing groins increase and thus the water level behind the groins rises this trend is more marked under the submerged condition on the other hand the water level behind the groins was relatively uniform under the emerged condition while under the submerged condition there was still backwater in front of the no 2 groin this shows the notched area can link the area before and behind the groin which makes the water level around the no 2 groin go nearly uniform see fig 7a as the notched area gets deeper and deeper the water level difference before and behind the no 2 groin gets smaller and smaller but in the submerged condition the groin itself already has flow capacity the additional flow capacity of the notched area is relatively small and cannot offset the backwater phenomena in front of the no 2 groin according to fig 7c and d in the zone near the channel ⑤ longitudinal section the water level behind the no 1 groin under the emerged condition rose with increasing notch depth this was because the flow velocity in the groin field increased in the case of notched groins and the water level in the main channel rose due to increased water coming from the groin field under the submerged condition the groins had little influence on the flow change along the main channel and the water level gradually declined from upstream to downstream the water level difference between the upstream and downstream of a groin tended to decrease with increasing notch depth moreover the water surface profile along the ① longitudinal section was consistent at different water depths 3 2 distribution of flow velocity fig 8 compares the average flow velocity across 5 cross section for three different water depths and four different notch depths fig 8a showed that under the emerged condition the flow velocity across the groin field was relatively uniform and closed to zero in the unnotched case in the notched case the flow velocity tended to differ recirculation occurred in the zone near the left bank from left to right the flow velocity gradually increased and reached its first peak at the point 50 cm from the left bank and the peak value tended to increase with increasing notch depth fig 8c showed that when the groin was submerged the notch depth had a significant effect on the flow field distribution along this cross section as the notch depth increased the flow velocity behind the groin generally increased while the flow velocity in the main channel declined slightly keeping the balance of the total amount of water passing through the entire section hence the main difference between the traditional unnotched groin and notched groin is their different velocity distributions across the groin field their differences in the mainstream are subtle besides fig 8c showed that when the groin was deeply submerged the flow velocity at the point 75 cm from the left bank approached a similar flow velocity to that in the main channel which was much higher than that in other conditions i e h 8 3 cm emerged case and h 12 5 cm shallowly submerged case this demonstrates that when the groin system is deeply submerged its ability to affect the mainstream is significantly restrained 3 3 patterns of the flow field fig 9 shows the distribution of the flow field around localized overflow groins the notched groins had a confining effect on water flow regardless of notch depth giving rise to shear stress between the water bodies in the main channel and the groin fields the shear stress caused a separation of boundary layers at the interface between the water bodies as a result a vortex occurred in each groin field forming a recirculation zone the area of the recirculation zone decreased from upstream to downstream as the notch depth increased the flow velocity and recirculation intensity in the recirculation zone behind a groin increased the separation point between recirculation and the main flow moved downstream after the compressed water flow bypassed a groin the boundary layers of water bodies were separated and a vortex occurred forming a recirculation zone behind the groin this phenomenon was most noticeable around the no 1 groin furthermore a comparison of the flow field indicated that as the notch depth increased the flow velocity in the recirculation zone behind a groin increased and the recirculation zone gradually moved toward downstream when h 12 5 cm the groins were shallowly submerged and thus had a weaker confining effect on water flow and a small recirculation zone occurred behind each groin as the notch depth increased the flow across a notch accelerated and localized recirculation takes place on both sides left and right of the notch this facilitated the development of a scour and deposition process characterized by alternate scour troughs and sand ridges the flow behind a groin tended to move downstream resulting in a scouring effect on the riverbed sediment after the water depth increased to 18 4 cm the groins were deeply submerged under this condition the flow velocity behind the groins tended to be uniform except for the small scale eddy close to the groins and the effect of notch depth on the flow pattern around the groins becomes weaker 3 4 pattern of scouring and deposition fig 10 shows the variation in riverbed elevation at the 4 and 9 cross sections under the emerged condition h 8 3 cm which reflects the characteristics of scouring and deposition for different notch depths as indicated in the figure an obvious scour pit occurs at the head of the no 1 groin and the scour depth tended to decrease with increasing notch depth a depositional feature occurred behind the groin in the unnotched case while in the notched case a scour trough formed behind the groin the trough tended to expand with increasing notch depth along the 9 cross section behind the no 2 groin deposition occurred in the unnotched case as well in the notched case the deposition height increased with increasing notch depth 3 5 distribution of fish hsi fig 11 shows the spatial distribution of the water depth suitability index in the emerged case for different notch depths as shown in the figure suitable water depths were distributed primarily in the shoals behind the groins the zones where the depth suitability index exceeded 0 9 tended to expand with increasing notch depth fig 12 illustrates the flow velocity suitability index in the emerged case it was clear that the zones or conditions with a high flow velocity suitability index did not necessarily have a high depth suitability index which implied no positive correlation between the two indexes simply by overlapping the two distribution patterns we could find that the zones that had both suitable water depth and flow velocity were located largely in the recirculation zones behind the groins according to our statistics these zones had the greatest total area when the notch depth was 2 3 of the groin height 4 discussion compared to conventional groins a notched groin has an opening in its middle part which increases localized overflow and changes the flow properties around a groin system more precisely the flow velocity behind the notch increases the water level difference between the two sides of the groin decreases and the recirculation in the groin fields intensify finally a range of scouring and depositional features will occur in different parts of the groins in a conventional groin project backwater occurs in front of groins while depositional shoals occur behind groins as a result of recirculation azinfar and kells 2008 azinfar and kells 2011a a groin system can change the originally smooth flow field in the channel to a complex pattern characterized by diverse velocity during floods overflow whirlpool and other complex flow conditions occur around groins and the water body experiences violent vertical motion jamieson et al 2013 jia et al 2005 and in the near bank region the flow is significantly buffered blanckaert 2010 all these conditions not only allow the growth of near bank aquatic plants but also create favorable spawning foraging and wintering grounds as well as a migration route for fishes shih et al 2008 in a notched groin system local water depth and flow velocity in groin fields can be regulated efficiently by controlling the notch width and depth unlike in a conventional groin system water depth and flow velocity are the key hydraulic variables affecting fish habitat adaptability bhuiyan et al 2009 the results of the study suggest that we can improve the adaptability of the typical fish in the study area to groin fields by optimizing notch depth according to the fish s habits to enhance the ecological effect of groins in addition it is found that the water level in the main channel rises after the groins are notched this is primarily because in the notched case the flow velocity in the groin fields increases and thus more water moves from the groin fields into the main channel the flow velocity and scour and deposition pattern in the main channel differ little in the notched and unnotched cases indicating that creating a small opening in a groin does not affect the groin system s ability to clear bed sediments by constraining flow an inference is that compared to other groin modification methods such as increasing or reducing overall groin height or using permeable groins making a notch in a groin has a smaller influence on the main channel uijttewaal 2005 this plus the finding that notched groins can enhance fish s habitat adaptability suggests that notched groins enable rivers to better offer both navigational and ecosystem functions compared to conventional groins and thus are worth applying in the construction of eco friendly channels 5 conclusions the paper systematically investigates the water surface profile flow velocity and scour and deposition pattern around newly designed eco friendly notched groins and offers insights into how the notched groins create diverse flow patterns and channel morphology for different water levels and incoming flows as well as its advance in enhancing aquatic habitat suitability the conclusions are as follows 1 as notch depth increased the backwater level in front of a groin decreased while the water level behind it increased the presence of a notch in the middle of a groin reduced the water level difference between the two sides of the groin and between the left and right banks the water level difference became smaller with increasing notch depth 2 the notches in the groins had a significant effect on the surrounding flow pattern due to localized overflow the flow behind each groin accelerated and the velocity gradient also increased the flow velocity behind each groin was positively correlated with the notch depth 3 the scour and deposition behind the groin were affected by the groin notches a scour trough occurred behind the no 1 groin and the scour depth tended to increase with increasing notch depth the sediment scoured moved backward and was then deposited in the middle of the groin behind and along the back of the no 2 groin forming a shoal in the main channel the scour depth slightly decreased with increasing notch depth which did not affect navigation 4 the zones with suitable water depth and flow velocity were distributed primarily in the recirculation zones behind the groins these zones had the greatest total area when the notch depth was 2 3 of the groin height 5 compared to conventional groins notched groins enable rivers to better offer both navigational and ecosystem functions and thus are worth applying in the construction of eco friendly channels funding this work was supported by the joint research on the ecological intelligent monitoring and impact assessment of inland waterway engineering grant numbers 2019yfe0121000 the research and application of monitoring and simulation technology for inland waterway ecological treatment engineering grant numbers tks20200310 credit authorship contribution statement dianguang ma conceptualization methodology conceptualization methodology junwei zhou investigation validation writing original draft zhenhong wang software data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
3410,over the past few decades eco friendly channel construction has gained wide attention around the world including china as it considers both navigational and ecological functions the groin system is a hydraulic structure that can effectively increase the area of fish habitats groin shape has an influence on the local flow field and the scour and deposition pattern near the structure thereby affecting the adaptability of fishes to the groin fields in this study a new groin structure with a notch in its middle part was proposed a lab experiment was conducted on a physical model to investigate the characteristics of the flow field including patterns of water level distribution flow velocity distribution and scour and deposition on different submergence levels and incoming flows this experiment used four notch depths 0 unnotched 1 3 of groin height 2 3 of groin height and full groin height then the distribution of habitat suitability index hsi was calculated based on the assessment index system of the indicator fish species cyprinidae the results showed that the notches created in the middle of localized overflow groins had a significant effect on the surrounding flow pattern due to localized overflow both the flow velocity and the velocity gradient behind each groin increased the flow velocity behind each groin was positively correlated with notch depth while the flow velocity in the main channel was negatively correlated with notch depth under the complex flow conditions depositional features did not occur along the edges of the groin fields ensuring connectivity between groin fields and the main channel an analysis of water depth and flow velocity suitability indexes of cyprinidae suggests when notch depth is 2 3 of groin height the notched groins have good ecological effects especially in the groin fields keywords new groin structure localized overflow groin flow velocity distribution scour and deposition ecological effects 1 introduction hard revetments such as those made of stone blocks and mortar are usually used in traditional channel construction projects however hard revetments prevent substance exchange between river banks and water bodies causing the loss of many ecosystem functions ouillon and dartus 1997 this harms the habitat and reproduction of fishes and other aquatic organisms over the past decades eco friendly channel construction has gained wide attention around the world including china as it considers both navigational and ecological functions azinfar and kells 2011b yossef and vriend 2010a as a typical river training structure the groin system is popular in eco friendly channel construction bigham 2020 it can not only clear bed sediments by constraining flow and serve for river training but also provide a habitat for fishes by changing the surrounding hydrodynamic conditions studies by arlinghaus et al 2002 armstrong et al 2003 yossef and vriend 2010b and other researchers have shown that groin fields with shallow water and low flow velocities allow sediment deposition and vegetation growth and provide favorable habitats for fishes to spawn and forage chang et al 2019 investigated the flow behavior around a groin system along the yizheng section of the yangtze river and found that this groin system provided abundant food and a stable migration route for fishes by using netstars and tabs 2 modeling shih et al 2008 analyzed the effects of water depth and flow velocity on fish habitat with and without spur dikes they found that the spur dikes can offer additional fish habitat and the weighted usable area wua and proportion of usable area pua of fish habitat are associated with groin layout these studies confirm that groin systems have made an important contribution to river ecosystems and the flow behavior around them is one of the main factors in determining the quality of fish habitat followed by these excited find outs hydrodynamics around the structures of groin systems has become a hot topic for research kimura and hosoda 1997 kuhnle et al 2002 some scholars have conducted numerical research on this topic for example xu et al 2014 li et al 2016 and ma et al 2020 have created two dimensional and three dimensional mathematical models using the finite volume method and then analyzed the length and width of a recirculation zone downstream of a groin and the variation in shear flow along the river xing et al 2018 analyzed the hydrodynamics around groins by three dimensional numerical computation besides some researchers have systematically observed localized flow field scour and deposition and geometry of scour holes near groins ouillon and dartus 1997 xu et al 2014 yossef and vriend 2010a besides there is also experimental research on this topic for instance yossef and vriend 2010b investigated the flow near the dutch river waal by experimenting on a physical model on a 1 40 scale and found that the nature of the turbulence differs between submerged and emerged groins cai et al 2018 experimentally investigated the distribution patterns of flow velocity and water depth around groins and explored the effects of groin length and submergence level on flow force coefficient by conducting a physical model on a 1 40 scale uijttewaal 2005 investigated the properties of turbulence around four different types of groins i e standard reference groins extended impermeable groins fully permeable groins and semi permeable groins the results demonstrated that the intensity of recirculation and the nature of turbulence around groins are associated with the shape and permeability of groins the above studies indicate that the groin system is a hydraulic structure that can effectively increase the area of fish habitats and the adaptability of fishes to groin fields is related to groin shape submergence level groin layout and other conditions the characteristics of water flow around groins significantly affect the adaptability of fishes to groin fields however it remains unclear how groin shape affects flow fields and further affects the scour and deposition of sediment around the groin and the adaptability of fishes khosronejad et al 2013 former studies focused on the assessment of the suitability of aquatic habitat after the construction of large hydraulic structures while there is little research on the design of groin shapes the present study aims to explore the relationship between groin shape and the characteristics of scour and deposition and adaptability of fishes around a groin system to help coordinate the channel navigation and protection of the river ecosystem for this purpose a new notched groin structure was designed based on the new structure a system of eco friendly notched groins was built the system can build up the slow flow and shallow water environment in the groin fields and is supposed to achieve a more suitable flow condition for target species later a physical model in the 1 30 scale was used to analyze the characteristics of the flow field and scour and deposition in the groin fields as well as the advantages and disadvantages of different localized overflow groins moreover the habitat suitability functions for a typical fish species in the study area were analyzed to study the distribution of habitat suitability index hsi for local fishes finally a suggestion about notch depth for notched groins is made based on the research results 2 materials and methodology 2 1 stimulated natural river section in this study the hukou yumenkou section of the yellow river was selected as the simulation object and the spur dike system was arranged in the stimulated river fig 1 with a tortuosity of about 1 15 this section is characterized by its narrow valley which is largely u shaped in cross section as the water flow along the narrow valley is heavily constrained by the rock masses on the banks the river surface downstream of hukou ranges in width roughly from 90 m to 150 m during drought and from 200 m to 500 m during floods and the flow velocity is between 0 6 m s and 1 0 m s the riverbed from top to bottom is composed of fine sand sandy gravel and bedrock and the aquatic vegetation covers the riverbed in total it measures up to 80 m thick there are several point bars at different levels along the valley which are up to several meters above the design water level mid channel bars are found locally 2 2 design of modeling experiment for the results of experiments on a scale model can be applicable to the natural river it is necessary to scale the water flow water level and flow velocity for modeling according to the theory of similitude modeling of the whole river section allowed us to simulate the flow pattern around groins more comprehensively and accurately and obtain more accurate information about localized flow patterns and riverbed deformation however given the difficulty in setting the scale for the model it was quite challenging to create a physical model for the whole section and use it to investigate the ecological effects of the new groin structure proposed the physical model is set up in a 2 m width experimental flume therefore rather to establish a physical model of the entire river course we treated the interaction between water flow and groins as a two dimensional problem and the groin river width ratio μ which describes the degree to which the groin system narrows the water surface was introduced to set up the physical model 1 μ l b r l b m where l represents the groin length b represents the width of the river or the width of the flume in the experiment the subscript r represents the real case while the subscript m presents the physical model case in the hukou yumenkou section of the yellow river the river width roughly ranges from 200 m to 500 m during floods the groin length ranges from 60 m to 200 m accordingly the groin river width ratio μ then be obtained within the range between 0 3 0 4 in our experimental set up μ 0 35 and the length of the model groin was 70 cm based on the test site and equipment as well as the size of the studied river section and the dimensions of groins a normal model with a length scale of 1 30 was constructed the scales for each variable are obtained as follow 2 λ l λ h 30 3 λ v λ h 1 2 5 48 4 λ t λ l λ v 5 48 5 λ q λ h λ v 164 3 6 λ n λ h 1 2 λ h λ l 1 2 λ v 1 76 where λl represents the horizontal scale λh represents the vertical scale besides λv and λt represents the velocity scale and the time scale respectively λq represents the flow rate scale and λn represents the roughness scale besides the diameter of the plastic sand which is used to simulate the bed load is properly selected to make the sediment competent velocity scale approximately equal to the velocity scale in our experiment the diameter of the plastic sand is 0 3 mm its volume weight is 1 25 103 kg m3 the sediment competent velocity scale is 7 λ w 5 52 where λω represents the sediment competent velocity scale table 1 summarized all different scale factors used in this study the experimental conditions are shown in table 2 in this flume experiment the incoming flow was controlled by mag6000 with the precision of 0 2 a magnetic flow meter produced by siemens camarena 2008 guo et al 2019 further three water level gauges with the precision of 0 1 mm denoted as l1 l2 and l3 respectively were installed along the flume l1 was installed 0 5 m downstream the horizontal grate to measure the water level at the inlet l2 and l3 were installed at the locations where x 0 and x 6 4 to measure the water surface slope along the test section the 0 2 m thick plastic sand was paved throughout the flume within the 6 4 m long test section the sand bed was adjusted and shaped to the river bed topography then the target flow was introduced into the flume after the flow went steady water level gauges l1 l2 and l3 were then used to measure the water level all across the test field besides vectrino produced by nortek was employed to measure the flow field using three points method i e the flow field was identified by three velocities at 0 2 0 6 and 0 8 times flow depth from top to bottom the measurement range of vectrino is from 0 01 m s to 4 m s the experimental setup is shown in fig 2 after the test the riverbed elevation was measured using the total station trimble rts 771 2 3 structure and layout of notched groins the localized overflow structure was simplified based on the experimental conditions the groin structure was designed into a top small and down wide shape for it can stand steady in rivers its schematic diagram and dimensions are shown in fig 3 the groin model was composed of wire mesh cages filled with rock pieces whose diameters are greater than the mesh size thus forming a permeable structure the mesh cages were joined by lap joints and a notch was left in the middle of the groin the notch depth could be controlled by adjusting the height of the middle part of the groin based on the generalized flow conditions three different combinations of flow and water depth were used in the experiment ① q 0 0272 m3 s h 8 3 cm ② q 0 0493 m3 s h 12 5 cm and ③ q 0 0994 m3 s h 18 4 cm the notch depth was set at four values 0 cm unnotched groin 3 33 cm 1 3 of groin height 6 67 cm 2 3 of groin height 10 cm full groin height 16 measurement cross sections each with 6 measurement points were selected for measuring the water depth flow velocity and scour and deposition pattern around the groins fig 4 presents the layout of these measurement cross sections and points 2 4 indicator species and its habitat suitability index hsi in this paper the habitat suitability index hsi was used to relate flow parameters for the quantification of the adaptability of indicator species to the habitat hsi is an index designed to quantitatively score the specific flow parameter according to the study on the habitat preferences of the species by using the hsi the habitat suitability can be better compared among different river section designs situations the data shows that schizothorax a species of family cyprinidae is the typical fish in the study area yu et al 2010 since the hsi of schizothorax in this area is missing cyprinidae was selected for analysis of the habitat requirements of schizothorax living in the river section studied the hsi of cyprinidae measures the effect of different factors on this fish on a scale of 0 to 1 with 1 indicating the most suitable habitat for this fish and 0 indicating the least suitable habitat with the increase of the factor index the habitat suitability is considered to transition linearly from worst to best or best to worst rated on a scale between 0 and 1 by experiment and analysis as well as referring to the findings of fish s habitat suitability from the literature we obtained critical data about the criteria for cyprinidae habitat in the yellow river in different growth stages including quantitative criteria for water depth flow velocity and riverbed in adult fish habitat young fish habitat and spawning ground lei et al 2020 wu et al 2013 zhang et al 2010 these are presented in tables 3 and 4 according to this knowledge suitable flow depth and velocities for the general cyprinidae habitat can be obtained in this paper the habitat suitability functions for cyprinidae for different water depths and flow velocities are defined in fig 5 the water depth is calculated based on the measurements of water level and river bed elevation then the water depth suitability index can be evaluated at each sampling point according to fig 5 a based on the obtained water depth results accordingly the flow velocity suitability index at each sampling point can be calculated according to fig 5 b based on the velocity observation results 3 results see fig 4 both water level velocity and riverbed elevation are collected at each point especially we logged the information around the groin system in detail thus the distributions of water level and flow velocity can be obtained directly from our observation which makes the flow field around the groins looks vivid to us an example of water level distribution in the case of h 8 3 cm with unnotched groins is given in fig 6 by comparing the results from unnotched and notched groins important observations and findings are reported 3 1 distribution of water level fig 7 compares the water surface profiles along the ① and ⑤ longitudinal sections for different notch depths under the emerged h 8 3 cm and shallow submerged h 12 5 cm conditions the dotted lines in the figure indicate the locations of groins fig 7a and b revealed that in the zone near the left bank ① longitudinal section the backwater level did not change significantly with increasing notch depth due to the obstruction by groins however as the notch depth increases the water overflowing groins increase and thus the water level behind the groins rises this trend is more marked under the submerged condition on the other hand the water level behind the groins was relatively uniform under the emerged condition while under the submerged condition there was still backwater in front of the no 2 groin this shows the notched area can link the area before and behind the groin which makes the water level around the no 2 groin go nearly uniform see fig 7a as the notched area gets deeper and deeper the water level difference before and behind the no 2 groin gets smaller and smaller but in the submerged condition the groin itself already has flow capacity the additional flow capacity of the notched area is relatively small and cannot offset the backwater phenomena in front of the no 2 groin according to fig 7c and d in the zone near the channel ⑤ longitudinal section the water level behind the no 1 groin under the emerged condition rose with increasing notch depth this was because the flow velocity in the groin field increased in the case of notched groins and the water level in the main channel rose due to increased water coming from the groin field under the submerged condition the groins had little influence on the flow change along the main channel and the water level gradually declined from upstream to downstream the water level difference between the upstream and downstream of a groin tended to decrease with increasing notch depth moreover the water surface profile along the ① longitudinal section was consistent at different water depths 3 2 distribution of flow velocity fig 8 compares the average flow velocity across 5 cross section for three different water depths and four different notch depths fig 8a showed that under the emerged condition the flow velocity across the groin field was relatively uniform and closed to zero in the unnotched case in the notched case the flow velocity tended to differ recirculation occurred in the zone near the left bank from left to right the flow velocity gradually increased and reached its first peak at the point 50 cm from the left bank and the peak value tended to increase with increasing notch depth fig 8c showed that when the groin was submerged the notch depth had a significant effect on the flow field distribution along this cross section as the notch depth increased the flow velocity behind the groin generally increased while the flow velocity in the main channel declined slightly keeping the balance of the total amount of water passing through the entire section hence the main difference between the traditional unnotched groin and notched groin is their different velocity distributions across the groin field their differences in the mainstream are subtle besides fig 8c showed that when the groin was deeply submerged the flow velocity at the point 75 cm from the left bank approached a similar flow velocity to that in the main channel which was much higher than that in other conditions i e h 8 3 cm emerged case and h 12 5 cm shallowly submerged case this demonstrates that when the groin system is deeply submerged its ability to affect the mainstream is significantly restrained 3 3 patterns of the flow field fig 9 shows the distribution of the flow field around localized overflow groins the notched groins had a confining effect on water flow regardless of notch depth giving rise to shear stress between the water bodies in the main channel and the groin fields the shear stress caused a separation of boundary layers at the interface between the water bodies as a result a vortex occurred in each groin field forming a recirculation zone the area of the recirculation zone decreased from upstream to downstream as the notch depth increased the flow velocity and recirculation intensity in the recirculation zone behind a groin increased the separation point between recirculation and the main flow moved downstream after the compressed water flow bypassed a groin the boundary layers of water bodies were separated and a vortex occurred forming a recirculation zone behind the groin this phenomenon was most noticeable around the no 1 groin furthermore a comparison of the flow field indicated that as the notch depth increased the flow velocity in the recirculation zone behind a groin increased and the recirculation zone gradually moved toward downstream when h 12 5 cm the groins were shallowly submerged and thus had a weaker confining effect on water flow and a small recirculation zone occurred behind each groin as the notch depth increased the flow across a notch accelerated and localized recirculation takes place on both sides left and right of the notch this facilitated the development of a scour and deposition process characterized by alternate scour troughs and sand ridges the flow behind a groin tended to move downstream resulting in a scouring effect on the riverbed sediment after the water depth increased to 18 4 cm the groins were deeply submerged under this condition the flow velocity behind the groins tended to be uniform except for the small scale eddy close to the groins and the effect of notch depth on the flow pattern around the groins becomes weaker 3 4 pattern of scouring and deposition fig 10 shows the variation in riverbed elevation at the 4 and 9 cross sections under the emerged condition h 8 3 cm which reflects the characteristics of scouring and deposition for different notch depths as indicated in the figure an obvious scour pit occurs at the head of the no 1 groin and the scour depth tended to decrease with increasing notch depth a depositional feature occurred behind the groin in the unnotched case while in the notched case a scour trough formed behind the groin the trough tended to expand with increasing notch depth along the 9 cross section behind the no 2 groin deposition occurred in the unnotched case as well in the notched case the deposition height increased with increasing notch depth 3 5 distribution of fish hsi fig 11 shows the spatial distribution of the water depth suitability index in the emerged case for different notch depths as shown in the figure suitable water depths were distributed primarily in the shoals behind the groins the zones where the depth suitability index exceeded 0 9 tended to expand with increasing notch depth fig 12 illustrates the flow velocity suitability index in the emerged case it was clear that the zones or conditions with a high flow velocity suitability index did not necessarily have a high depth suitability index which implied no positive correlation between the two indexes simply by overlapping the two distribution patterns we could find that the zones that had both suitable water depth and flow velocity were located largely in the recirculation zones behind the groins according to our statistics these zones had the greatest total area when the notch depth was 2 3 of the groin height 4 discussion compared to conventional groins a notched groin has an opening in its middle part which increases localized overflow and changes the flow properties around a groin system more precisely the flow velocity behind the notch increases the water level difference between the two sides of the groin decreases and the recirculation in the groin fields intensify finally a range of scouring and depositional features will occur in different parts of the groins in a conventional groin project backwater occurs in front of groins while depositional shoals occur behind groins as a result of recirculation azinfar and kells 2008 azinfar and kells 2011a a groin system can change the originally smooth flow field in the channel to a complex pattern characterized by diverse velocity during floods overflow whirlpool and other complex flow conditions occur around groins and the water body experiences violent vertical motion jamieson et al 2013 jia et al 2005 and in the near bank region the flow is significantly buffered blanckaert 2010 all these conditions not only allow the growth of near bank aquatic plants but also create favorable spawning foraging and wintering grounds as well as a migration route for fishes shih et al 2008 in a notched groin system local water depth and flow velocity in groin fields can be regulated efficiently by controlling the notch width and depth unlike in a conventional groin system water depth and flow velocity are the key hydraulic variables affecting fish habitat adaptability bhuiyan et al 2009 the results of the study suggest that we can improve the adaptability of the typical fish in the study area to groin fields by optimizing notch depth according to the fish s habits to enhance the ecological effect of groins in addition it is found that the water level in the main channel rises after the groins are notched this is primarily because in the notched case the flow velocity in the groin fields increases and thus more water moves from the groin fields into the main channel the flow velocity and scour and deposition pattern in the main channel differ little in the notched and unnotched cases indicating that creating a small opening in a groin does not affect the groin system s ability to clear bed sediments by constraining flow an inference is that compared to other groin modification methods such as increasing or reducing overall groin height or using permeable groins making a notch in a groin has a smaller influence on the main channel uijttewaal 2005 this plus the finding that notched groins can enhance fish s habitat adaptability suggests that notched groins enable rivers to better offer both navigational and ecosystem functions compared to conventional groins and thus are worth applying in the construction of eco friendly channels 5 conclusions the paper systematically investigates the water surface profile flow velocity and scour and deposition pattern around newly designed eco friendly notched groins and offers insights into how the notched groins create diverse flow patterns and channel morphology for different water levels and incoming flows as well as its advance in enhancing aquatic habitat suitability the conclusions are as follows 1 as notch depth increased the backwater level in front of a groin decreased while the water level behind it increased the presence of a notch in the middle of a groin reduced the water level difference between the two sides of the groin and between the left and right banks the water level difference became smaller with increasing notch depth 2 the notches in the groins had a significant effect on the surrounding flow pattern due to localized overflow the flow behind each groin accelerated and the velocity gradient also increased the flow velocity behind each groin was positively correlated with the notch depth 3 the scour and deposition behind the groin were affected by the groin notches a scour trough occurred behind the no 1 groin and the scour depth tended to increase with increasing notch depth the sediment scoured moved backward and was then deposited in the middle of the groin behind and along the back of the no 2 groin forming a shoal in the main channel the scour depth slightly decreased with increasing notch depth which did not affect navigation 4 the zones with suitable water depth and flow velocity were distributed primarily in the recirculation zones behind the groins these zones had the greatest total area when the notch depth was 2 3 of the groin height 5 compared to conventional groins notched groins enable rivers to better offer both navigational and ecosystem functions and thus are worth applying in the construction of eco friendly channels funding this work was supported by the joint research on the ecological intelligent monitoring and impact assessment of inland waterway engineering grant numbers 2019yfe0121000 the research and application of monitoring and simulation technology for inland waterway ecological treatment engineering grant numbers tks20200310 credit authorship contribution statement dianguang ma conceptualization methodology conceptualization methodology junwei zhou investigation validation writing original draft zhenhong wang software data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
3411,the transport property of natural fissured reservoir is highly related to the fracture permeability the composite topography of natural fractures is always rough with self affine surfaces and non uniform aperture field all these would affect the transport properties significantly therefore it is of fundamental importance to clarify the control mechanism on fluid flow through rough fractures with self affine and mismatched surfaces in this work four controlling factors namely local rough geometry hydraulic tortuosity surface tortuosity and non uniform aperture distribution were identified for the mismatched and rough fracture flows afterwards the implications of these factors on fluid flow were specified by analytical derivation combined with the cubic law and the triple effect model a quadruple effect permeability model was established to characterize the comprehensive effects from the composite topography of rough fractures moreover the semi empirical coefficient and index in surface roughness factor were determined by lattice boltzmann simulations and provide fundamental support to define the effective hydraulic aperture which is a key parameter in the quadruple effect model theoretical analysis denoted that the quadruple effect model could generalize other models in the literature and its performance was approved by numerical validation keywords self affine fracture triple effect model hydraulic tortuosity surface tortuosity non uniform aperture field nomenclature α fitted coefficient in the surface roughness factor β fitted index in the surface roughness factor δ aperture δ e effective aperture derived from the triple effect model δ h hydraulic aperture δ m mechanical aperture δ m aperture of the m th segment of a fracture x lattice spacing γ scaling factor determining the sampling density of frequency δ mean aperture ω fractal topography ω i collision operator p pressure gradient ν fluid viscosity ω i weight coefficient in the corresponding direction δ e effective aperture by considering the effects from composite topography of a fracture ϕ 1 n random phase used to generate the upper surface ϕ m random phase used to generate the lower surface ϕ n random phase in the range of 0 2 π ρ x t local mass density at each lattice position x and time t σ variance of the surface heights σ b variance of b τ lbm dimensionless relaxation time τ hydraulic tortuosity τ s surface tortuosity υ s lattice sound speed ς scaling factor in the x and y directions υ i velocity in the direction i ξ exponent of the power law model of permeability proposed by zhang et al 1996 ζ i effective error σ δ variance of the aperture latin symbols b mean of the natural log of the aperture u x t velocity at each lattice position x and time t b natural log of the aperture c coefficient of the power law model of permeability proposed by zhang et al 1996 d fractal dimension f scaling coverage f r surface roughness factor f i particle mass distribution function after collision f i eq x t quasi equilibrium distribution function g l scaling object with characteristic size of l h hurst exponent h minimum height of the rock sample containing a fracture h xy general hurst exponent k as m analytical permeability obtained by the quadruple effect model k as o analytical permeability obtained by the triple effect model k as analytical permeability k cl permeability obtained by cl k lbm dimensionless numerical permeability by lbm k lcl permeability obtained by lcl k ns numerical permeability k zb permeability obtained by zbm k i permeability obtained by different models l sample length l characteristic size l m length of the m th segment of a fracture n wavenumber n g l number of the scaling object g l n h maximum wavenumber n l minimum wavenumber p scaling lacunarity p x scaling lacunarity in the x direction p y scaling lacunarity in the y direction r time step re reynolds number t time u mean velocity of lattice z x height of fracture surface in horizontal position x 1 introduction as the main migration pathway fractures may widely and strongly affect the transport properties of porous media an accurate characterization of the behavior of fluid flow through a single fracture is crucial for many environmental and hydrogeological problems such as enhanced oil gas recovery wang et al 2017 geothermal energy development kumari and ranjith 2019 gong et al 2020 remediation of contaminated groundwater mackay and cherry 1989 council 1996 ross et al 2001 and nuclear waste disposal hadgu et al 2017 therefore the research on the influence of fracture transport performance has been carried out for a long time according to the classical cubic law lomize 1951 the average flow rate along a single fracture consisting of two parallel smooth plates varies with the cube of the aperture however by a great deal of experimental research brown 1987 auradou et al 2001 and numerical simulations eker and akin 2006 zheng et al 2020 the cubic law was deemed to be invalid for accurately describing the hydrodynamic problems in natural fractures the reasons mainly boil down to the roughness of internal surfaces and the self affine property of surface geometries schmittbuhl et al 1993 cambonie et al 2015 in view of the extremely irregular nature of surface heights a thought of dividing the rough surface into segments was yielded so as to sustain the applicability of the cubic law namely the well known local cubic law lcl zimmerman et al 1991 mourzenko et al 1995 however despite its widely application the adequacy of the lcl for the permeability estimation of rough fractures remains an open question oron and berkowitz 1998 for example the assumption that the fracture midsurface is a flat plane is contrary to the fact that a tortuous plane is exhibited in natural fractures ge 1997 furthermore the total flow rate predicted by lcl is 1 5 to 2 times higher than that obtained by experiments yeo et al 1998 konzuk and kueper 2004 although the lcl has been successively modified and improved by many researchers watanabe et al 2008 wang et al 2015 wang and cardenas 2016 ju et al 2019 it may still produce some errors in the definition of apertures and the determination of the dividing steps more importantly the issue that the application of lcl may greatly affect the quantitative analysis and interpretation of the experimental and field test results of fracture flow has not been effectively solved by current research based on the above understanding more attention of another approach recorrecting the cubic law by analytical derivation should be paid in this approach the surface roughness factor srf that characterize the surface roughness effect was initially introduced into the cubic law to improve the estimation accuracy witherspoon et al 1980 unfortunately the srf is a semi empirical parameter whose value is obtained by fitting the estimated permeabilities to the measured values in terms of the relative roughness of residual surface geometries and srf is heavily dependent on the complexity of surface geometries which will result in two different values of srf for fractures with the same statistics amounts of relative roughness with the help of micro geometrical structure characteristics of fracture surfaces considerable effort has been placed on the analysis of the influence characteristics of physical parameters roughness aperture tortuosity etc on fracture flow and the quantification of the relationship between these parameters and penetrating quality renshaw 1995 jin et al 2017 in this direction zhang et al 1996 earlier found that a power law relationship of k δ ξ is satisfied between effective permeability k and mean aperture δ with ξ an h independent function of ξ h ranged in 2 6 madadi and sahimi 2003 subsequently murata and saito 2003 carried out a study of the estimation of the tortuosity which indicated that it would significantly affect the transport capacity of rough fracture by an experimental investigation babadagli et al 2015 pointed out that the roughness of fracture surfaces has a significant effect on the permeability of a rough fracture all these studies indicate that the rough geometries of the surfaces have multiple effects on the transport performance of micro fractures the modification of the cubic law by the introduction of the srf is not sufficient to characterize the effects of rough geometries on flow capacity in addition due to the absence of a detailed understanding of the physical implications from surface geometries there were no definitive expressions of ξ h recently by careful analysis of the effects of rough geometries on fluid flow jin et al 2017 divided them into hydraulic tortuosity surface tortuosity and local stationary roughness effects and then the relationship between the above triple effects and permeability was established which was called triple effect model the presentation of triple effect model provides a theoretical support for the mechanism study of gas fluid flow ju et al 2019 zeng et al 2018 zhu and cheng 2018 jin et al 2019 and advection diffusion process zheng et al 2021 due to the rough and random distribution of the surface heights the geometries of two internal surfaces which were scale invariant with size spanned several orders of magnitude yu and li 2001 might appear mismatched behavior at some scale brown et al 1986 which leads to the non uniform distribution of apertures brown 1987 alquaimi and rossen 2017 and significantly affects the transport properties of fractures cardenas et al 2007 talon et al 2010 rodrigues et al 2013 for this zheng et al 2020 developed a weight algorithm to construct the mismatched fractures and established the validity of the triple effect model for fluid flow in mismatched self affine fractures in spite of this there was no specific parameter in the triple effect model to represent the effect from non uniform aperture field which is not conducive to the fundamental understanding of the control mechanism of composite topography on fluid flow through rough fractures in natural reservoir in this work we aimed to investigate the influence of non uniform aperture distribution on flow capacity and accordingly reexamine the permeability aperture relationship for fluid flow through mismatched rough fractures first based on the triple effect model the comprehensive effects of composite topological characteristics were coupled and a novel model that include specific parameters representing the effects from fracture surfaces and non uniform aperture field was established then the mismatched rough fractures were constructed so as to implement the pore scale simulations of fluid flow by lattice boltzmann method lbm finally to assess the performance of our proposed model the permeability values calculated by our proposed model were compared to those from lbm simulations local cubic law lcl and previous models for synthetic fractures with varying aperture roughness 2 permeability aperture relationship for rough fractures 2 1 triple effect model considering the roughness effects from mated fracture surfaces experimental data indicates that the two internal surfaces of a natural fracture are often rough which affect the flow capacity significantly ju et al 2019 zimmerman and bodvarsson 1996 and cause cubic law to fail to accurately predict the fracture permeability brown 1987 auradou et al 2001 drazer and koplik 2000 therefore to take into account the effect of surface roughness on permeability the permeability estimation model that obtained from the classical cubic law was initially corrected by 1 k δ 3 12 hf r where δ is the mean aperture of a matched fracture h is the minimum height of the rock sample containing a fracture f r 1 α σ δ β is the srf wherein σ quantifies the root mean square of the roughness heights of a residual surface and α and β are the fitted parameters dependent on the surface geometry however it is not adequate to characterize the multiple effects of surface rough components on fracture flow only by semi empirical parameters therefore jin et al 2017 catalogued the effects of surface geometries into three parts hydraulic tortuosity effect surface tortuosity effect and local stationary roughness effect thus based on eq 1 a triple effect permeability model for matched fractures could be written as 2 k δ 3 12 hf r τ 2 τ s 2 where τ and τ s are hydraulic tortuosity and surface tortuosity respectively as eq 2 is rewritten into the homogeneous form of eq 3 the three parameters i e f r τ and τ s are introduced to reduce the aperture of δ to the effective aperture of δ e δ f r 1 3 τ 2 3 τ s 2 3 thus it is convenient to use the classical cubic law to predict the permeability of rough fractures 3 k 1 12 h δ f r 1 3 τ 2 3 τ s 2 3 3 1 12 h δ e 3 2 2 a novel model considering the comprehensive effects from surfaces and aperture field as mentioned before the two rough surfaces play a decisive role in the assessment of flow capacity specifically the composite topography of a rough fracture possessing the rough and mismatched features has a comprehensive effect on hydrodynamic behavior thus combined with the triple effects those exist in a matched rough fracture jin et al 2017 the comprehensive effects from composite topography in mismatched rough fractures could be cataloged into four parts the triple effects that from the two internal surfaces and the effect from the rough distribution of apertures as demonstrated in fig 1 therefore to maintain the validity of classical cubic law for predicting the permeability of mismatched fractures the new effective aperture of δ e could be obtained by taking into account the effect of rough distribution of the apertures to replace δ e then eq 3 could be rewritten as 4 k 1 12 h δ e 3 if the fracture aperture of δ x follows lognormal distribution the natural log of the aperture of b x ln δ x follows normal distribution assuming the mean b and the variance σ b 2 are given the arithmetic mean aperture i e mechanical aperture of δ m and the aperture variance of σ δ 2 are respectively expressed as renshaw 1995 vanmarcke 1983 5 δ m e b e σ b 2 2 6 σ δ 2 e 2 b e σ b 2 e σ b 2 1 where hydraulic aperture δ h is defined as δ h e b renshaw 1995 following the work of renshaw 1995 the effective permeability of a mismatched fracture only depends on b i e the surface roughness effect is neglected and the effect from the non uniform aperture field is mainly considered accordingly δ m could be recorrected by δ e for a mismatched rough fractures thus the hydraulic aperture of δ h is equivalent to the effective aperture of δ e then eq 5 and eq 6 could be respectively rewritten as 7 δ e δ e e σ b 2 2 8 σ δ δ e e σ b 2 e σ b 2 1 e σ b 2 2 together with eqs 7 and 8 we can obtain eq 9 as 9 δ e 2 δ e 4 δ e 2 σ δ 2 of particular note is that the correlation between eqs 7 and 8 is not very sensitive to the statistics of the aperture distribution zimmerman et al 1991 therefore if the distribution of the apertures is not precisely lognormal for example if it follows a normal distribution the relationship described by eq 9 is also approximately valid renshaw 1995 substituting the eq 9 into eq 4 the fracture permeability equation that coupling the effects of surface roughness and aperture roughness is obtained as 10 k 1 12 h δ e 2 δ e 2 σ δ 2 3 δ e 3 12 h 1 1 σ δ δ e 2 1 5 it is evident that four effects of surface geometries on fracture flow are identified and quantified by eq 10 in details they are hydraulic tortuosity τ surface tortuosity τ s local stationary roughness f r and aperture roughness effects σ δ respectively therefore eq 10 is called as quadruple effect permeability estimation model hereafter called quadruple effect model for short for more details of the calculation and determination of f r τ and τ s please consult the ref jin et al 2017 3 computational experiments 3 1 characterization of mismatched self affine fractures recently jin et al 2017 and jin et al 2019 proposed a new concept of fractal topography and defined the fractal dimension of a fractal by ω p f subsequently the fractal topography theory was successfully applied to the characterization of complexity assembly in fractal porous media jin et al 2020 and that of pore structure in a coal matrix zhao et al 2020 as the dimensionless parameters the scaling lacunarity p and the scaling coverage f respectively represent the size and number ratio of two successive scaling objects and together determine the fractal behavior of a fractal namely behavioral complexity their expressions are p l i l i 1 and f n g l i 1 n g l i where g l represents a scaling object with characteristic size of l n g l represents the number of the scaling object g l generally a self affine fractal is defined as g ς x ς h y in a two dimensional xy space where ς is the scaling factor and h is the hurst exponent thus as per fractal topography jin et al 2019 the scaling lacunarities in the x and y directions are p x 1 ς and p y 1 ς h respectively consequently the general hurst exponent of h xy is scale invariantly defined by 11 h xy log p y log p x in view of the superiority of weierstrass mandelbrot function in modelling the such characteristics as randomness self affinity and continuity of natural profiles it was widely used to model the fracture surfaces zheng et al 2020 ju et al 2019 jin et al 2017 jin et al 2019 zheng et al 2021 and defined as 12 z x n n l n h γ n d 2 cos ϕ n cos 2 π γ n x l ϕ n where z x is the height of fracture surface in horizontal position x γ is the scaling factor determining the sampling density of frequency which usually takes the value of 1 5 ϕ n is a random phase in the range of 0 2 π n l and n h are the minimum and maximum wavenumber respectively l γ n l is the maximum scale of the scaling object in z x in the x direction namely the sample length following the fractal topography mentioned above the scaling lacunarities of p x and p y in eq 12 are equal to γ and γ 2 d respectively this is however obviously different from p y γ h that indicated by eq 11 because the relationship of h 2 d is not satisfied jin et al 2019 consequently eq 12 should be redefined as eq 13 to model self affine surfaces in rough fractures 13 z x n n l n h p y n cos ϕ n cos 2 π p x n n l x ϕ n following the eq 13 the equations for modeling the upper and lower surfaces are respectively defined as 14 z x n n l n h p y n cos ϕ 1 n cos 2 π p x n n l x ϕ 1 n 15 z x n n l n h p y n cos ϕ m cos 2 π p x n n l x ϕ m where ϕ 1 n and ϕ m respectively represent the random phase used to generate the upper and lower surfaces to effectively describe the mismatched behavior between internal surfaces the weight algorithm that developed in our previous work zheng et al 2020 is employed to model the non uniform distribution characteristics of the apertures and then construct the composite topography space of fractures with mismatched features specifically the aperture distribution characteristics are controlled by the mismatched wavenumber range for the details of the modeling process of mismatched fractures interested readers can consult ref zheng et al 2020 3 2 numerical simulations of fluid flow at pore scale by lbm among the computational approaches the newly developed lbm has a strong capability in dealing with complex fluid flows and is widely used to describe the real fluid flow zhang et al 2012 jin et al 2017 jin et al 2017 jin et al 2019 zheng et al 2021 qian et al 1992 dou et al 2013 as a simulation method at mesoscopic scale lbm simulation is carried out by dealing with the continuous distribution functions of the current lattice and the adjacent lattice based on the principle of effective conversion between physical and lattice systems the real fracture space is discretized in terms of a regular lattice with spacing x time t in terms of a time step r and velocity space in terms of a small set of velocities υ i to ensure that υ i r is a vector connecting two adjacent lattice sites succi 2002 for simplicity and without loss of generality a two dimensional d2q9 lattice model qian et al 1992 is employed in this work to discrete lattice velocity space the local mass density ρ x t and velocity u x t at each lattice position x and time t are expressed as 16 ρ x t i 0 8 f i x t u x t i 0 8 f i x t υ i ρ x t the corresponding lattice boltzmann equation lbe is given by 17 f i x υ i r t r f i x t ω i f x t where f i is the particle mass distribution function after collision and ω i is the collision operator according to the mass and momentum conservation requirements ω i ω i υ i according to the bgk model chen and doolen 1998 qian et al 1992 the collision operator takes the single relaxation time approximation 18 ω i f x t r τ lbm f i eq x t f i x t where τ lbm is a dimensionless relaxation time and f i eq x t is a quasi equilibrium distribution function its discrete velocities υ i are then defined as 19 υ i υ 0 0 i 0 cos θ sin θ i 1 4 θ i 1 2 π 2 cos θ sin θ i 5 8 θ 2 i 9 4 π to recover the navier stokes ns equations for the fluid flow f i eq is constructed by eq 20 and the kinetic viscosity of the fluid ν is given by eq 21 20 f i eq x t ω i ρ x t 1 υ i u υ s 2 υ i u 2 2 υ s 4 u 2 2 υ s 2 21 ν υ s 2 τ lbm 1 2 x 2 r where υ s 1 3 is the lattice sound speed ω i is the weight coefficient in the corresponding direction and υ i is the discrete velocity since there is almost no net fluid motion at solid boundaries succi 2002 a no slip boundary condition is approximately set at the solid fluid interfaces jin et al 2013 wang et al 2014 for simplicity and without loss of generality the complete bounce back scheme is used in our flow simulations and the reynolds number re 1 is held to guarantee that the flow fits darcy s law according to the method introduced above the upper and lower surfaces were generated by setting n l 0 and n h 50 and then mismatched rough fractures with different hs and mismatched ranges were constructed by making vertical relative displacement of the two surfaces in the lbm simulations the physical scale of 1 μ m was discretized into 2048 lu lattice unit to guarantee numerical precision the pressure gradient p between the input and output boundaries of the fracture was set to 10 5 pa m and the dimensionless relaxation time τ lbm was set to 1 0 to ensure the stability of lbm simulations based on the above settings and darcy s law the calculation model of the dimensionless numerical permeability k lbm could be obtained by p ν u k lbm where u is the mean velocity of lattice whereafter the numerical permeability of a fracture with physical unit is obtained by k ns k lbm 1 2048 2 sukop et al 2013 4 results and discussion 4 1 validity of the characterization approach for mismatched self affine fractures generally probability density function pdf and power spectral density psd are always used to demonstrate the statistical characteristics of random processes in the surface heights of fractures brown et al 1986 brown 1995 glover et al 1998 matsuki et al 2006 brown et al 1986 pointed out the psd of the composite topography of a fracture is different from that of internal surfaces in details the psd of internal surfaces follows a power law whatever the frequency is while that of the composite topography follows a power law which holds only for the frequency larger than a certain value i e mismatched length scale defined by brown 1995 otherwise it would be a constant to validate the equivalence of the fracture models synthesized by the method in section 3 1 an example of the statistical characteristics of a fracture synthesized based on eq 13 with two different random phases was shown in fig 2 obviously the psds of the apertures and the surface follow two different variation characteristics and the apertures approximately satisfy a gaussian distribution both of which coincide with the results obtained in previous work brown et al 1986 glover et al 1998 matsuki et al 2006 as a consequence it could be concluded that the mismatched fractures modeled by the method in section 3 1 are equivalent to those in natural reservoirs 4 2 influence of non uniform aperture field on the permeability to explore the influence of aperture variation on the permeability estimation by triple effect model eq 2 fifty six fractures with different mismatched ranges i e different aperture roughnesses and hs were constructed where h ranged from 0 70 to 0 90 with the increment of 0 05 and the mismatched ranges realized by the adjustment of the wavenumber with the interval of 2 the aperture roughness σ δ along the macroscopic direction of fracture flow was then calculated by the standard deviation of apertures by lbm simulations some results of the variation characteristics of the ratio of the analytical permeability k as o calculated by eq 2 to the numerical permeability k ns with relative aperture roughness σ δ δ were plotted in fig 3 a apparently a significant positive correlation between σ δ δ and k as o k ns was observed no matter what value of h takes when σ δ δ is small the value of k as o k ns is close to 1 and thus the triple effect model is valid and accurate for the permeability estimation of mismatched fractures zheng et al 2020 as σ δ δ increases the deviation between k as o k ns and 1 increases this indicates that owing to the enhancement of the mismatched behavior between internal surfaces the permeability will be overestimated while the triple effect model is still applied and the prediction accuracy is inversely proportional to the aperture roughness as a consequence the assumption made in section 2 2 i e non uniform aperture field affects the fluid flow behavior is confirmed again due to the surface and aperture roughness effects from fracture composite topography the relationships between δ and k ns for different hs are scattered with their power fitted exponents different from each other as demonstrated by the dotted curves in fig 3 b after replacing δ by δ e however an excellent power fitted law between δ e and k ns is represented with the exponent equals to 3 see fig 3 c therefore relative to δ the introduction of δ e is necessary and perfectly characterizes the surface and aperture roughness effects on fracture permeability 4 3 performance of the quadruple effect model as mentioned previously the classical cubic law lomize 1951 derived in the case of smooth and parallel plate model is invalid for the mismatched rough fractures based on this understanding eq 10 is derived in this work under the overall consideration of the features of surface mismatch and roughness for fractures composed by two completely mated rough surfaces the apertures follow uniform and smooth distribution aperture standard deviation σ δ 0 and eq 10 can be simplified into eq 2 if the fracture surfaces are smooth i e f r 1 τ 1 τ s 1 eq 10 would be further simplified into a cubic law model more importantly compared with eq 2 eq 10 realized the representation of the effect from non uniform aperture distribution to further improve the prediction performance of permeability especially for fractures with larger degree of surface mismatch on the other hand zimmerman and bodvarsson 1996 reviewed various analytical and numerical results with respect to the issue of relating the effective hydraulic aperture to the statistics of the aperture distribution based on the lognormal aperture distributions zimmerman and bodvarsson 1996 proposed a permeability model by defining an expression of the effective hydraulic aperture 22 k δ 3 12 h 1 1 5 σ δ 2 δ 2 in this model δ and σ δ were introduced to revise the effective hydraulic aperture for fluid flow in mismatched rough fractures however according to the recent study of jin et al 2017 just introducing δ is insufficient to completely describe the surface roughness effect fortunately eq 10 contained some other parameters i e f r τ τ s to improve the understanding of the surface roughness effect more importantly for self affine rough fractures τ and τ s are the functions of δ because of the scale effects jin et al 2017 and regardless of the surface topography and aperture distribution the relationship between fracture permeability and mean aperture follows a power law model k δ ξ as noted by zhang et al 1996 based on this knowledge eq 10 can be generally expressed by k c δ ξ demonstrated by the power fitted curve below in fig 6 a wherein c is a function that contains parameters of f r and σ δ above discussion confirms that the quadruple effect model could generalize the other existing models from the literature to further exhibit the validity and accuracy advantage of the quadruple effect model at the numerical level the performance of the quadruple effect model relative to other models is stated below generally to calculate the analytical permeability k as m by eq 10 the values of f r should be determined in advance although different investigations of f r including theoretical derivation experimental and numerical simulation analysis were successively carried out lomize 1951 witherspoon et al 1980 jin et al 2017 louis 1969 the effects of hydraulic tortuosity and surface tortuosity on fracture flow were not eliminated in existing empirical models because the effects of surface roughness on permeability not only include local stationary roughness effect but also the hydraulic and surface tortuosity effects and they are independent of each other jin et al 2017 as a consequence we cannot be sure about the applicability of those models for the refined analytical calculation of permeability for this we employed the semi empirical method in the literature jin et al 2017 to first obtain the values of α and β and then calculate f r by the semi empirical model of f r 1 α σ δ β as for the calculation of τ and τ s we also used the method that proposed by jin et al 2017 for convenience therefore the values of k as m were calculated by eq 10 and compared with lbm numerical permeability k ns as plotted in fig 4 the good agreement between k as m and k ns approves the validity of the quadruple effect model considering the wide application of lcl in studying the migration law of rough fracture flow a set of mismatched fractures with h 0 9 were selected and their permeability values would be calculated by lcl to improve the calculation accuracy as much as possible the fractures with a sample length of 2048 grids were divided into 2048 equal segments and the actual length of each segment was 0 02 μ m in terms of the principle of equal flow of each section the calculation expression of equivalent hydraulic aperture δ h was derived as 23 δ h l m 1 n l m δ m 3 3 where l m and δ m are the length and aperture of the mth segment respectively then δ h was substituted into classical cubic law to obtain the permeability k lcl of rough fractures with mismatched characteristics to further evaluate the prediction performance of the quadruple effect model for mismatched rough fractures the classical cubic law and zimmerman bodvarsson model zbm zimmerman and bodvarsson 1996 were used to calculate the corresponding analytical permeability k cl and k zb respectively subsequently k lcl k cl k zbm k as o eq 2 and k as m eq 10 were compared with k ns as demonstrated by scatter plots in fig 6 a comparative results indicate that compared with k as o and k as m the analytical permeability k lcl k cl or k zbm has a larger deviation from k ns the reason that results in a larger k lcl is mainly because the segmentation of fractures in the lcl does not eliminate the roughness effect of local surface geometry on permeability on the contrary the triple effect model emphatically considered the effect of surface roughness but ignored the weakening effect of the aperture variation on the overall permeability of the fracture leading to a larger k as o than k as m among these models the permeability estimated by the quadruple effect model is closest to the numerical permeability and by best power fitted the relationship between k as m and δ is consistent with the results of zhang et al 1996 and madadi and sahimi 2003 i e k δ ξ with ξ 4 18 in addition the overall performance of the quadruple effect model could also be evaluated via quantifying the effective errors as ζ i k i k ns k ns where k i is the permeability calculated through different models where i refers to the type of models i e cl lcl eqs 2 10 and zbm therefore for a statistical description of the performance the effective errors ζ in permeability predicted using the above models compared to that calculated through lbm simulations were calculated and plotted as box charts in fig 6 b results indicate that the cl overestimates the permeability with ζ 1 ranging from 3 1 to 11 3 with arithmetic mean ζ 1 5 8 depending on the local surface roughness tortuosity aperture roughness etc after emphatically accounting for the aperture roughness effect ζ 2 of zbm decreases with ζ 2 4 79 while ζ 3 of lcl decreases substantially with ζ 3 2 39 due to the consideration of tortuosity and aperture roughness effects similarly accounting for the tortuosity and local surface roughness effects ζ 4 of the triple effect model decreases with ζ 4 0 75 in particular the comprehensive consideration of the local surface roughness tortuosity and aperture roughness effects further improves the performance of the quadruple effect model with ζ 5 decreasing to 0 09 overall the quadruple effect model performs better than the other models because k as m is in good agreement with k ns and ζ 5 is the minimum at the same time we also conclude that the advantage and advancement of the quadruple effect model is the combination of all factors those have been taken into account and studied separately witherspoon et al 1980 renshaw 1995 jin et al 2017 murata and saito 2003 babadagli et al 2015 including local surface roughness tortuosity and aperture roughness 4 4 numerical determination of the semi empirical parameters in srf due to the two semi empirical parameters α and β contained in the calculation model of f r it is apparent that the process of the above determination of f r is slightly complicated which is not conducive to the fast analytical calculation of permeability to minimize the calculation and guarantee the prediction accuracy as much as possible a series of mismatched fractures with fixed mismatched range but different hs and δ s were synthesised and the values of permeability k ns were then calculated by lbm simulations thus the values of f r could be obtained based on eq 10 wherein k k ns fig 5 a demonstrates the relationship between f r 1 and σ δ in fig 5 a a best fitted power law model was obtained as 24 f r 1 4 9 σ δ 0 75 eq 24 well represents the local roughness effect in the mismatched fractures at the empirical level nevertheless whether the novel empirical model is applicable to the calculation of f r in fractures with different mismatched ranges should be further validated to this end based on the previously synthesised mismatched fracture models and the corresponding lbm simulation results f r s were calculated by eq 24 and substituted them into eq 10 to obtain the analytical permeability k as of the fracture models with different mismatched ranges the relationship between k as and the numerical permeability k ns was plotted in fig 5 b it is found that the k as is nearly close to k ns no matter what values of h take where the small errors should be ascribed to the numerical precision consequently the validity of eq 24 for the estimation of f r is approved by now the parameters in the quadruple effect model are all well defined and easily estimated 4 5 discussion compared with previous investigations the present work indicates that the permeability varies depending on the aperture roughness in addition to local stationary roughness hydraulic and surface tortuosity although this knowledge is achieved on the basis of small scale rough fractures and it is difficult to model explicit fractures with varying apertures on a large field scale some general results can also be derived from our newly developed model that may capture the fluid flow variability in upscaled fractures for large field scale modelling the permeability is frequently modeled with a constant aperture i e aperture roughness is equal to 0 to investigate the impact of using varying apertures for calculating equivalent permeability bisdom et al 2016 calculated the average aperture as a constant aperture for entire fracture network and found that equivalent permeability was higher for models with a constant aperture than for the varying apertures apparently this is consistent with the result derived from our newly developed model i e the larger the aperture roughness is the smaller the permeability is furthermore the study of hooker et al 2009 showed that a varying aperture is more applicable for outcrop data than a constant aperture all above studies confirm the significance of the effect of non uniform aperture field on fracture flow for large field scale modelling to sum up our newly developed model for permeability estimation has a fundamental but significant role in capturing the natural variability of fracture flow in large field scale modelling 5 conclusions the present work reveals that the effects from fracture composite topography include hydraulic tortuosity surface tortuosity local stationary roughness and aperture roughness accordingly a quadruple effect model was established for permeability estimation of mismatched fractures to evaluate the model performance the fluid flow process in fracture space was simulated by lbm at pore scale numerical results indicated that the estimation accuracy of the triple effect model was inversely proportional to the aperture relative roughness due to the absence of the representation of the effect from non uniform aperture distribution nevertheless the permeability values estimated by the quadruple effect model were in good agreement with lbm ones whatever the aperture roughness is which approved the validity and robustness of the quadruple effect model moreover the semi empirical parameters in the determination of srf were numerically quantified with α 4 9 and β 0 75 which provide a fundamental support for the definition of the effective hydraulic aperture by theoretical analysis it was denoted that the quadruple effect model could generalize the other models from the literature for a statistical description of the performance the effective errors of the analytical models for the permeability estimation were calculated and the minimum arithmetic mean error of the quadruple effect model i e ζ 5 0 09 validated its better performance relative to other models overall the quadruple effect model proposed here provides a fundamental understanding of the control mechanism of composite topography on fluid flow through mismatched and rough fractures moreover it might shed light on the accurate analysis of the advection diffusion process that in a single fracture or a complex cleat network credit authorship contribution statement junling zheng conceptualization investigation methodology writing original draft yi jin supervision writing review editing funding acquisition jiabin dong data curation methodology formal analysis shunxi liu validation formal analysis qing zhang formal analysis writing review editing huibo song visualization pinghua huang visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was supported by the national natural science foundation of china grant no 41972175 the science and technology major project of shanxi province china grant no 20181101013 1 the program for innovative research team in science and technology in universities of henan province china grant no 21irtsthn007 the program for innovative research team in science and technology of henan polytechnic university grant no t2020 4 and the program for key scientific research of universities in henan province china grant no 22a170008 
3411,the transport property of natural fissured reservoir is highly related to the fracture permeability the composite topography of natural fractures is always rough with self affine surfaces and non uniform aperture field all these would affect the transport properties significantly therefore it is of fundamental importance to clarify the control mechanism on fluid flow through rough fractures with self affine and mismatched surfaces in this work four controlling factors namely local rough geometry hydraulic tortuosity surface tortuosity and non uniform aperture distribution were identified for the mismatched and rough fracture flows afterwards the implications of these factors on fluid flow were specified by analytical derivation combined with the cubic law and the triple effect model a quadruple effect permeability model was established to characterize the comprehensive effects from the composite topography of rough fractures moreover the semi empirical coefficient and index in surface roughness factor were determined by lattice boltzmann simulations and provide fundamental support to define the effective hydraulic aperture which is a key parameter in the quadruple effect model theoretical analysis denoted that the quadruple effect model could generalize other models in the literature and its performance was approved by numerical validation keywords self affine fracture triple effect model hydraulic tortuosity surface tortuosity non uniform aperture field nomenclature α fitted coefficient in the surface roughness factor β fitted index in the surface roughness factor δ aperture δ e effective aperture derived from the triple effect model δ h hydraulic aperture δ m mechanical aperture δ m aperture of the m th segment of a fracture x lattice spacing γ scaling factor determining the sampling density of frequency δ mean aperture ω fractal topography ω i collision operator p pressure gradient ν fluid viscosity ω i weight coefficient in the corresponding direction δ e effective aperture by considering the effects from composite topography of a fracture ϕ 1 n random phase used to generate the upper surface ϕ m random phase used to generate the lower surface ϕ n random phase in the range of 0 2 π ρ x t local mass density at each lattice position x and time t σ variance of the surface heights σ b variance of b τ lbm dimensionless relaxation time τ hydraulic tortuosity τ s surface tortuosity υ s lattice sound speed ς scaling factor in the x and y directions υ i velocity in the direction i ξ exponent of the power law model of permeability proposed by zhang et al 1996 ζ i effective error σ δ variance of the aperture latin symbols b mean of the natural log of the aperture u x t velocity at each lattice position x and time t b natural log of the aperture c coefficient of the power law model of permeability proposed by zhang et al 1996 d fractal dimension f scaling coverage f r surface roughness factor f i particle mass distribution function after collision f i eq x t quasi equilibrium distribution function g l scaling object with characteristic size of l h hurst exponent h minimum height of the rock sample containing a fracture h xy general hurst exponent k as m analytical permeability obtained by the quadruple effect model k as o analytical permeability obtained by the triple effect model k as analytical permeability k cl permeability obtained by cl k lbm dimensionless numerical permeability by lbm k lcl permeability obtained by lcl k ns numerical permeability k zb permeability obtained by zbm k i permeability obtained by different models l sample length l characteristic size l m length of the m th segment of a fracture n wavenumber n g l number of the scaling object g l n h maximum wavenumber n l minimum wavenumber p scaling lacunarity p x scaling lacunarity in the x direction p y scaling lacunarity in the y direction r time step re reynolds number t time u mean velocity of lattice z x height of fracture surface in horizontal position x 1 introduction as the main migration pathway fractures may widely and strongly affect the transport properties of porous media an accurate characterization of the behavior of fluid flow through a single fracture is crucial for many environmental and hydrogeological problems such as enhanced oil gas recovery wang et al 2017 geothermal energy development kumari and ranjith 2019 gong et al 2020 remediation of contaminated groundwater mackay and cherry 1989 council 1996 ross et al 2001 and nuclear waste disposal hadgu et al 2017 therefore the research on the influence of fracture transport performance has been carried out for a long time according to the classical cubic law lomize 1951 the average flow rate along a single fracture consisting of two parallel smooth plates varies with the cube of the aperture however by a great deal of experimental research brown 1987 auradou et al 2001 and numerical simulations eker and akin 2006 zheng et al 2020 the cubic law was deemed to be invalid for accurately describing the hydrodynamic problems in natural fractures the reasons mainly boil down to the roughness of internal surfaces and the self affine property of surface geometries schmittbuhl et al 1993 cambonie et al 2015 in view of the extremely irregular nature of surface heights a thought of dividing the rough surface into segments was yielded so as to sustain the applicability of the cubic law namely the well known local cubic law lcl zimmerman et al 1991 mourzenko et al 1995 however despite its widely application the adequacy of the lcl for the permeability estimation of rough fractures remains an open question oron and berkowitz 1998 for example the assumption that the fracture midsurface is a flat plane is contrary to the fact that a tortuous plane is exhibited in natural fractures ge 1997 furthermore the total flow rate predicted by lcl is 1 5 to 2 times higher than that obtained by experiments yeo et al 1998 konzuk and kueper 2004 although the lcl has been successively modified and improved by many researchers watanabe et al 2008 wang et al 2015 wang and cardenas 2016 ju et al 2019 it may still produce some errors in the definition of apertures and the determination of the dividing steps more importantly the issue that the application of lcl may greatly affect the quantitative analysis and interpretation of the experimental and field test results of fracture flow has not been effectively solved by current research based on the above understanding more attention of another approach recorrecting the cubic law by analytical derivation should be paid in this approach the surface roughness factor srf that characterize the surface roughness effect was initially introduced into the cubic law to improve the estimation accuracy witherspoon et al 1980 unfortunately the srf is a semi empirical parameter whose value is obtained by fitting the estimated permeabilities to the measured values in terms of the relative roughness of residual surface geometries and srf is heavily dependent on the complexity of surface geometries which will result in two different values of srf for fractures with the same statistics amounts of relative roughness with the help of micro geometrical structure characteristics of fracture surfaces considerable effort has been placed on the analysis of the influence characteristics of physical parameters roughness aperture tortuosity etc on fracture flow and the quantification of the relationship between these parameters and penetrating quality renshaw 1995 jin et al 2017 in this direction zhang et al 1996 earlier found that a power law relationship of k δ ξ is satisfied between effective permeability k and mean aperture δ with ξ an h independent function of ξ h ranged in 2 6 madadi and sahimi 2003 subsequently murata and saito 2003 carried out a study of the estimation of the tortuosity which indicated that it would significantly affect the transport capacity of rough fracture by an experimental investigation babadagli et al 2015 pointed out that the roughness of fracture surfaces has a significant effect on the permeability of a rough fracture all these studies indicate that the rough geometries of the surfaces have multiple effects on the transport performance of micro fractures the modification of the cubic law by the introduction of the srf is not sufficient to characterize the effects of rough geometries on flow capacity in addition due to the absence of a detailed understanding of the physical implications from surface geometries there were no definitive expressions of ξ h recently by careful analysis of the effects of rough geometries on fluid flow jin et al 2017 divided them into hydraulic tortuosity surface tortuosity and local stationary roughness effects and then the relationship between the above triple effects and permeability was established which was called triple effect model the presentation of triple effect model provides a theoretical support for the mechanism study of gas fluid flow ju et al 2019 zeng et al 2018 zhu and cheng 2018 jin et al 2019 and advection diffusion process zheng et al 2021 due to the rough and random distribution of the surface heights the geometries of two internal surfaces which were scale invariant with size spanned several orders of magnitude yu and li 2001 might appear mismatched behavior at some scale brown et al 1986 which leads to the non uniform distribution of apertures brown 1987 alquaimi and rossen 2017 and significantly affects the transport properties of fractures cardenas et al 2007 talon et al 2010 rodrigues et al 2013 for this zheng et al 2020 developed a weight algorithm to construct the mismatched fractures and established the validity of the triple effect model for fluid flow in mismatched self affine fractures in spite of this there was no specific parameter in the triple effect model to represent the effect from non uniform aperture field which is not conducive to the fundamental understanding of the control mechanism of composite topography on fluid flow through rough fractures in natural reservoir in this work we aimed to investigate the influence of non uniform aperture distribution on flow capacity and accordingly reexamine the permeability aperture relationship for fluid flow through mismatched rough fractures first based on the triple effect model the comprehensive effects of composite topological characteristics were coupled and a novel model that include specific parameters representing the effects from fracture surfaces and non uniform aperture field was established then the mismatched rough fractures were constructed so as to implement the pore scale simulations of fluid flow by lattice boltzmann method lbm finally to assess the performance of our proposed model the permeability values calculated by our proposed model were compared to those from lbm simulations local cubic law lcl and previous models for synthetic fractures with varying aperture roughness 2 permeability aperture relationship for rough fractures 2 1 triple effect model considering the roughness effects from mated fracture surfaces experimental data indicates that the two internal surfaces of a natural fracture are often rough which affect the flow capacity significantly ju et al 2019 zimmerman and bodvarsson 1996 and cause cubic law to fail to accurately predict the fracture permeability brown 1987 auradou et al 2001 drazer and koplik 2000 therefore to take into account the effect of surface roughness on permeability the permeability estimation model that obtained from the classical cubic law was initially corrected by 1 k δ 3 12 hf r where δ is the mean aperture of a matched fracture h is the minimum height of the rock sample containing a fracture f r 1 α σ δ β is the srf wherein σ quantifies the root mean square of the roughness heights of a residual surface and α and β are the fitted parameters dependent on the surface geometry however it is not adequate to characterize the multiple effects of surface rough components on fracture flow only by semi empirical parameters therefore jin et al 2017 catalogued the effects of surface geometries into three parts hydraulic tortuosity effect surface tortuosity effect and local stationary roughness effect thus based on eq 1 a triple effect permeability model for matched fractures could be written as 2 k δ 3 12 hf r τ 2 τ s 2 where τ and τ s are hydraulic tortuosity and surface tortuosity respectively as eq 2 is rewritten into the homogeneous form of eq 3 the three parameters i e f r τ and τ s are introduced to reduce the aperture of δ to the effective aperture of δ e δ f r 1 3 τ 2 3 τ s 2 3 thus it is convenient to use the classical cubic law to predict the permeability of rough fractures 3 k 1 12 h δ f r 1 3 τ 2 3 τ s 2 3 3 1 12 h δ e 3 2 2 a novel model considering the comprehensive effects from surfaces and aperture field as mentioned before the two rough surfaces play a decisive role in the assessment of flow capacity specifically the composite topography of a rough fracture possessing the rough and mismatched features has a comprehensive effect on hydrodynamic behavior thus combined with the triple effects those exist in a matched rough fracture jin et al 2017 the comprehensive effects from composite topography in mismatched rough fractures could be cataloged into four parts the triple effects that from the two internal surfaces and the effect from the rough distribution of apertures as demonstrated in fig 1 therefore to maintain the validity of classical cubic law for predicting the permeability of mismatched fractures the new effective aperture of δ e could be obtained by taking into account the effect of rough distribution of the apertures to replace δ e then eq 3 could be rewritten as 4 k 1 12 h δ e 3 if the fracture aperture of δ x follows lognormal distribution the natural log of the aperture of b x ln δ x follows normal distribution assuming the mean b and the variance σ b 2 are given the arithmetic mean aperture i e mechanical aperture of δ m and the aperture variance of σ δ 2 are respectively expressed as renshaw 1995 vanmarcke 1983 5 δ m e b e σ b 2 2 6 σ δ 2 e 2 b e σ b 2 e σ b 2 1 where hydraulic aperture δ h is defined as δ h e b renshaw 1995 following the work of renshaw 1995 the effective permeability of a mismatched fracture only depends on b i e the surface roughness effect is neglected and the effect from the non uniform aperture field is mainly considered accordingly δ m could be recorrected by δ e for a mismatched rough fractures thus the hydraulic aperture of δ h is equivalent to the effective aperture of δ e then eq 5 and eq 6 could be respectively rewritten as 7 δ e δ e e σ b 2 2 8 σ δ δ e e σ b 2 e σ b 2 1 e σ b 2 2 together with eqs 7 and 8 we can obtain eq 9 as 9 δ e 2 δ e 4 δ e 2 σ δ 2 of particular note is that the correlation between eqs 7 and 8 is not very sensitive to the statistics of the aperture distribution zimmerman et al 1991 therefore if the distribution of the apertures is not precisely lognormal for example if it follows a normal distribution the relationship described by eq 9 is also approximately valid renshaw 1995 substituting the eq 9 into eq 4 the fracture permeability equation that coupling the effects of surface roughness and aperture roughness is obtained as 10 k 1 12 h δ e 2 δ e 2 σ δ 2 3 δ e 3 12 h 1 1 σ δ δ e 2 1 5 it is evident that four effects of surface geometries on fracture flow are identified and quantified by eq 10 in details they are hydraulic tortuosity τ surface tortuosity τ s local stationary roughness f r and aperture roughness effects σ δ respectively therefore eq 10 is called as quadruple effect permeability estimation model hereafter called quadruple effect model for short for more details of the calculation and determination of f r τ and τ s please consult the ref jin et al 2017 3 computational experiments 3 1 characterization of mismatched self affine fractures recently jin et al 2017 and jin et al 2019 proposed a new concept of fractal topography and defined the fractal dimension of a fractal by ω p f subsequently the fractal topography theory was successfully applied to the characterization of complexity assembly in fractal porous media jin et al 2020 and that of pore structure in a coal matrix zhao et al 2020 as the dimensionless parameters the scaling lacunarity p and the scaling coverage f respectively represent the size and number ratio of two successive scaling objects and together determine the fractal behavior of a fractal namely behavioral complexity their expressions are p l i l i 1 and f n g l i 1 n g l i where g l represents a scaling object with characteristic size of l n g l represents the number of the scaling object g l generally a self affine fractal is defined as g ς x ς h y in a two dimensional xy space where ς is the scaling factor and h is the hurst exponent thus as per fractal topography jin et al 2019 the scaling lacunarities in the x and y directions are p x 1 ς and p y 1 ς h respectively consequently the general hurst exponent of h xy is scale invariantly defined by 11 h xy log p y log p x in view of the superiority of weierstrass mandelbrot function in modelling the such characteristics as randomness self affinity and continuity of natural profiles it was widely used to model the fracture surfaces zheng et al 2020 ju et al 2019 jin et al 2017 jin et al 2019 zheng et al 2021 and defined as 12 z x n n l n h γ n d 2 cos ϕ n cos 2 π γ n x l ϕ n where z x is the height of fracture surface in horizontal position x γ is the scaling factor determining the sampling density of frequency which usually takes the value of 1 5 ϕ n is a random phase in the range of 0 2 π n l and n h are the minimum and maximum wavenumber respectively l γ n l is the maximum scale of the scaling object in z x in the x direction namely the sample length following the fractal topography mentioned above the scaling lacunarities of p x and p y in eq 12 are equal to γ and γ 2 d respectively this is however obviously different from p y γ h that indicated by eq 11 because the relationship of h 2 d is not satisfied jin et al 2019 consequently eq 12 should be redefined as eq 13 to model self affine surfaces in rough fractures 13 z x n n l n h p y n cos ϕ n cos 2 π p x n n l x ϕ n following the eq 13 the equations for modeling the upper and lower surfaces are respectively defined as 14 z x n n l n h p y n cos ϕ 1 n cos 2 π p x n n l x ϕ 1 n 15 z x n n l n h p y n cos ϕ m cos 2 π p x n n l x ϕ m where ϕ 1 n and ϕ m respectively represent the random phase used to generate the upper and lower surfaces to effectively describe the mismatched behavior between internal surfaces the weight algorithm that developed in our previous work zheng et al 2020 is employed to model the non uniform distribution characteristics of the apertures and then construct the composite topography space of fractures with mismatched features specifically the aperture distribution characteristics are controlled by the mismatched wavenumber range for the details of the modeling process of mismatched fractures interested readers can consult ref zheng et al 2020 3 2 numerical simulations of fluid flow at pore scale by lbm among the computational approaches the newly developed lbm has a strong capability in dealing with complex fluid flows and is widely used to describe the real fluid flow zhang et al 2012 jin et al 2017 jin et al 2017 jin et al 2019 zheng et al 2021 qian et al 1992 dou et al 2013 as a simulation method at mesoscopic scale lbm simulation is carried out by dealing with the continuous distribution functions of the current lattice and the adjacent lattice based on the principle of effective conversion between physical and lattice systems the real fracture space is discretized in terms of a regular lattice with spacing x time t in terms of a time step r and velocity space in terms of a small set of velocities υ i to ensure that υ i r is a vector connecting two adjacent lattice sites succi 2002 for simplicity and without loss of generality a two dimensional d2q9 lattice model qian et al 1992 is employed in this work to discrete lattice velocity space the local mass density ρ x t and velocity u x t at each lattice position x and time t are expressed as 16 ρ x t i 0 8 f i x t u x t i 0 8 f i x t υ i ρ x t the corresponding lattice boltzmann equation lbe is given by 17 f i x υ i r t r f i x t ω i f x t where f i is the particle mass distribution function after collision and ω i is the collision operator according to the mass and momentum conservation requirements ω i ω i υ i according to the bgk model chen and doolen 1998 qian et al 1992 the collision operator takes the single relaxation time approximation 18 ω i f x t r τ lbm f i eq x t f i x t where τ lbm is a dimensionless relaxation time and f i eq x t is a quasi equilibrium distribution function its discrete velocities υ i are then defined as 19 υ i υ 0 0 i 0 cos θ sin θ i 1 4 θ i 1 2 π 2 cos θ sin θ i 5 8 θ 2 i 9 4 π to recover the navier stokes ns equations for the fluid flow f i eq is constructed by eq 20 and the kinetic viscosity of the fluid ν is given by eq 21 20 f i eq x t ω i ρ x t 1 υ i u υ s 2 υ i u 2 2 υ s 4 u 2 2 υ s 2 21 ν υ s 2 τ lbm 1 2 x 2 r where υ s 1 3 is the lattice sound speed ω i is the weight coefficient in the corresponding direction and υ i is the discrete velocity since there is almost no net fluid motion at solid boundaries succi 2002 a no slip boundary condition is approximately set at the solid fluid interfaces jin et al 2013 wang et al 2014 for simplicity and without loss of generality the complete bounce back scheme is used in our flow simulations and the reynolds number re 1 is held to guarantee that the flow fits darcy s law according to the method introduced above the upper and lower surfaces were generated by setting n l 0 and n h 50 and then mismatched rough fractures with different hs and mismatched ranges were constructed by making vertical relative displacement of the two surfaces in the lbm simulations the physical scale of 1 μ m was discretized into 2048 lu lattice unit to guarantee numerical precision the pressure gradient p between the input and output boundaries of the fracture was set to 10 5 pa m and the dimensionless relaxation time τ lbm was set to 1 0 to ensure the stability of lbm simulations based on the above settings and darcy s law the calculation model of the dimensionless numerical permeability k lbm could be obtained by p ν u k lbm where u is the mean velocity of lattice whereafter the numerical permeability of a fracture with physical unit is obtained by k ns k lbm 1 2048 2 sukop et al 2013 4 results and discussion 4 1 validity of the characterization approach for mismatched self affine fractures generally probability density function pdf and power spectral density psd are always used to demonstrate the statistical characteristics of random processes in the surface heights of fractures brown et al 1986 brown 1995 glover et al 1998 matsuki et al 2006 brown et al 1986 pointed out the psd of the composite topography of a fracture is different from that of internal surfaces in details the psd of internal surfaces follows a power law whatever the frequency is while that of the composite topography follows a power law which holds only for the frequency larger than a certain value i e mismatched length scale defined by brown 1995 otherwise it would be a constant to validate the equivalence of the fracture models synthesized by the method in section 3 1 an example of the statistical characteristics of a fracture synthesized based on eq 13 with two different random phases was shown in fig 2 obviously the psds of the apertures and the surface follow two different variation characteristics and the apertures approximately satisfy a gaussian distribution both of which coincide with the results obtained in previous work brown et al 1986 glover et al 1998 matsuki et al 2006 as a consequence it could be concluded that the mismatched fractures modeled by the method in section 3 1 are equivalent to those in natural reservoirs 4 2 influence of non uniform aperture field on the permeability to explore the influence of aperture variation on the permeability estimation by triple effect model eq 2 fifty six fractures with different mismatched ranges i e different aperture roughnesses and hs were constructed where h ranged from 0 70 to 0 90 with the increment of 0 05 and the mismatched ranges realized by the adjustment of the wavenumber with the interval of 2 the aperture roughness σ δ along the macroscopic direction of fracture flow was then calculated by the standard deviation of apertures by lbm simulations some results of the variation characteristics of the ratio of the analytical permeability k as o calculated by eq 2 to the numerical permeability k ns with relative aperture roughness σ δ δ were plotted in fig 3 a apparently a significant positive correlation between σ δ δ and k as o k ns was observed no matter what value of h takes when σ δ δ is small the value of k as o k ns is close to 1 and thus the triple effect model is valid and accurate for the permeability estimation of mismatched fractures zheng et al 2020 as σ δ δ increases the deviation between k as o k ns and 1 increases this indicates that owing to the enhancement of the mismatched behavior between internal surfaces the permeability will be overestimated while the triple effect model is still applied and the prediction accuracy is inversely proportional to the aperture roughness as a consequence the assumption made in section 2 2 i e non uniform aperture field affects the fluid flow behavior is confirmed again due to the surface and aperture roughness effects from fracture composite topography the relationships between δ and k ns for different hs are scattered with their power fitted exponents different from each other as demonstrated by the dotted curves in fig 3 b after replacing δ by δ e however an excellent power fitted law between δ e and k ns is represented with the exponent equals to 3 see fig 3 c therefore relative to δ the introduction of δ e is necessary and perfectly characterizes the surface and aperture roughness effects on fracture permeability 4 3 performance of the quadruple effect model as mentioned previously the classical cubic law lomize 1951 derived in the case of smooth and parallel plate model is invalid for the mismatched rough fractures based on this understanding eq 10 is derived in this work under the overall consideration of the features of surface mismatch and roughness for fractures composed by two completely mated rough surfaces the apertures follow uniform and smooth distribution aperture standard deviation σ δ 0 and eq 10 can be simplified into eq 2 if the fracture surfaces are smooth i e f r 1 τ 1 τ s 1 eq 10 would be further simplified into a cubic law model more importantly compared with eq 2 eq 10 realized the representation of the effect from non uniform aperture distribution to further improve the prediction performance of permeability especially for fractures with larger degree of surface mismatch on the other hand zimmerman and bodvarsson 1996 reviewed various analytical and numerical results with respect to the issue of relating the effective hydraulic aperture to the statistics of the aperture distribution based on the lognormal aperture distributions zimmerman and bodvarsson 1996 proposed a permeability model by defining an expression of the effective hydraulic aperture 22 k δ 3 12 h 1 1 5 σ δ 2 δ 2 in this model δ and σ δ were introduced to revise the effective hydraulic aperture for fluid flow in mismatched rough fractures however according to the recent study of jin et al 2017 just introducing δ is insufficient to completely describe the surface roughness effect fortunately eq 10 contained some other parameters i e f r τ τ s to improve the understanding of the surface roughness effect more importantly for self affine rough fractures τ and τ s are the functions of δ because of the scale effects jin et al 2017 and regardless of the surface topography and aperture distribution the relationship between fracture permeability and mean aperture follows a power law model k δ ξ as noted by zhang et al 1996 based on this knowledge eq 10 can be generally expressed by k c δ ξ demonstrated by the power fitted curve below in fig 6 a wherein c is a function that contains parameters of f r and σ δ above discussion confirms that the quadruple effect model could generalize the other existing models from the literature to further exhibit the validity and accuracy advantage of the quadruple effect model at the numerical level the performance of the quadruple effect model relative to other models is stated below generally to calculate the analytical permeability k as m by eq 10 the values of f r should be determined in advance although different investigations of f r including theoretical derivation experimental and numerical simulation analysis were successively carried out lomize 1951 witherspoon et al 1980 jin et al 2017 louis 1969 the effects of hydraulic tortuosity and surface tortuosity on fracture flow were not eliminated in existing empirical models because the effects of surface roughness on permeability not only include local stationary roughness effect but also the hydraulic and surface tortuosity effects and they are independent of each other jin et al 2017 as a consequence we cannot be sure about the applicability of those models for the refined analytical calculation of permeability for this we employed the semi empirical method in the literature jin et al 2017 to first obtain the values of α and β and then calculate f r by the semi empirical model of f r 1 α σ δ β as for the calculation of τ and τ s we also used the method that proposed by jin et al 2017 for convenience therefore the values of k as m were calculated by eq 10 and compared with lbm numerical permeability k ns as plotted in fig 4 the good agreement between k as m and k ns approves the validity of the quadruple effect model considering the wide application of lcl in studying the migration law of rough fracture flow a set of mismatched fractures with h 0 9 were selected and their permeability values would be calculated by lcl to improve the calculation accuracy as much as possible the fractures with a sample length of 2048 grids were divided into 2048 equal segments and the actual length of each segment was 0 02 μ m in terms of the principle of equal flow of each section the calculation expression of equivalent hydraulic aperture δ h was derived as 23 δ h l m 1 n l m δ m 3 3 where l m and δ m are the length and aperture of the mth segment respectively then δ h was substituted into classical cubic law to obtain the permeability k lcl of rough fractures with mismatched characteristics to further evaluate the prediction performance of the quadruple effect model for mismatched rough fractures the classical cubic law and zimmerman bodvarsson model zbm zimmerman and bodvarsson 1996 were used to calculate the corresponding analytical permeability k cl and k zb respectively subsequently k lcl k cl k zbm k as o eq 2 and k as m eq 10 were compared with k ns as demonstrated by scatter plots in fig 6 a comparative results indicate that compared with k as o and k as m the analytical permeability k lcl k cl or k zbm has a larger deviation from k ns the reason that results in a larger k lcl is mainly because the segmentation of fractures in the lcl does not eliminate the roughness effect of local surface geometry on permeability on the contrary the triple effect model emphatically considered the effect of surface roughness but ignored the weakening effect of the aperture variation on the overall permeability of the fracture leading to a larger k as o than k as m among these models the permeability estimated by the quadruple effect model is closest to the numerical permeability and by best power fitted the relationship between k as m and δ is consistent with the results of zhang et al 1996 and madadi and sahimi 2003 i e k δ ξ with ξ 4 18 in addition the overall performance of the quadruple effect model could also be evaluated via quantifying the effective errors as ζ i k i k ns k ns where k i is the permeability calculated through different models where i refers to the type of models i e cl lcl eqs 2 10 and zbm therefore for a statistical description of the performance the effective errors ζ in permeability predicted using the above models compared to that calculated through lbm simulations were calculated and plotted as box charts in fig 6 b results indicate that the cl overestimates the permeability with ζ 1 ranging from 3 1 to 11 3 with arithmetic mean ζ 1 5 8 depending on the local surface roughness tortuosity aperture roughness etc after emphatically accounting for the aperture roughness effect ζ 2 of zbm decreases with ζ 2 4 79 while ζ 3 of lcl decreases substantially with ζ 3 2 39 due to the consideration of tortuosity and aperture roughness effects similarly accounting for the tortuosity and local surface roughness effects ζ 4 of the triple effect model decreases with ζ 4 0 75 in particular the comprehensive consideration of the local surface roughness tortuosity and aperture roughness effects further improves the performance of the quadruple effect model with ζ 5 decreasing to 0 09 overall the quadruple effect model performs better than the other models because k as m is in good agreement with k ns and ζ 5 is the minimum at the same time we also conclude that the advantage and advancement of the quadruple effect model is the combination of all factors those have been taken into account and studied separately witherspoon et al 1980 renshaw 1995 jin et al 2017 murata and saito 2003 babadagli et al 2015 including local surface roughness tortuosity and aperture roughness 4 4 numerical determination of the semi empirical parameters in srf due to the two semi empirical parameters α and β contained in the calculation model of f r it is apparent that the process of the above determination of f r is slightly complicated which is not conducive to the fast analytical calculation of permeability to minimize the calculation and guarantee the prediction accuracy as much as possible a series of mismatched fractures with fixed mismatched range but different hs and δ s were synthesised and the values of permeability k ns were then calculated by lbm simulations thus the values of f r could be obtained based on eq 10 wherein k k ns fig 5 a demonstrates the relationship between f r 1 and σ δ in fig 5 a a best fitted power law model was obtained as 24 f r 1 4 9 σ δ 0 75 eq 24 well represents the local roughness effect in the mismatched fractures at the empirical level nevertheless whether the novel empirical model is applicable to the calculation of f r in fractures with different mismatched ranges should be further validated to this end based on the previously synthesised mismatched fracture models and the corresponding lbm simulation results f r s were calculated by eq 24 and substituted them into eq 10 to obtain the analytical permeability k as of the fracture models with different mismatched ranges the relationship between k as and the numerical permeability k ns was plotted in fig 5 b it is found that the k as is nearly close to k ns no matter what values of h take where the small errors should be ascribed to the numerical precision consequently the validity of eq 24 for the estimation of f r is approved by now the parameters in the quadruple effect model are all well defined and easily estimated 4 5 discussion compared with previous investigations the present work indicates that the permeability varies depending on the aperture roughness in addition to local stationary roughness hydraulic and surface tortuosity although this knowledge is achieved on the basis of small scale rough fractures and it is difficult to model explicit fractures with varying apertures on a large field scale some general results can also be derived from our newly developed model that may capture the fluid flow variability in upscaled fractures for large field scale modelling the permeability is frequently modeled with a constant aperture i e aperture roughness is equal to 0 to investigate the impact of using varying apertures for calculating equivalent permeability bisdom et al 2016 calculated the average aperture as a constant aperture for entire fracture network and found that equivalent permeability was higher for models with a constant aperture than for the varying apertures apparently this is consistent with the result derived from our newly developed model i e the larger the aperture roughness is the smaller the permeability is furthermore the study of hooker et al 2009 showed that a varying aperture is more applicable for outcrop data than a constant aperture all above studies confirm the significance of the effect of non uniform aperture field on fracture flow for large field scale modelling to sum up our newly developed model for permeability estimation has a fundamental but significant role in capturing the natural variability of fracture flow in large field scale modelling 5 conclusions the present work reveals that the effects from fracture composite topography include hydraulic tortuosity surface tortuosity local stationary roughness and aperture roughness accordingly a quadruple effect model was established for permeability estimation of mismatched fractures to evaluate the model performance the fluid flow process in fracture space was simulated by lbm at pore scale numerical results indicated that the estimation accuracy of the triple effect model was inversely proportional to the aperture relative roughness due to the absence of the representation of the effect from non uniform aperture distribution nevertheless the permeability values estimated by the quadruple effect model were in good agreement with lbm ones whatever the aperture roughness is which approved the validity and robustness of the quadruple effect model moreover the semi empirical parameters in the determination of srf were numerically quantified with α 4 9 and β 0 75 which provide a fundamental support for the definition of the effective hydraulic aperture by theoretical analysis it was denoted that the quadruple effect model could generalize the other models from the literature for a statistical description of the performance the effective errors of the analytical models for the permeability estimation were calculated and the minimum arithmetic mean error of the quadruple effect model i e ζ 5 0 09 validated its better performance relative to other models overall the quadruple effect model proposed here provides a fundamental understanding of the control mechanism of composite topography on fluid flow through mismatched and rough fractures moreover it might shed light on the accurate analysis of the advection diffusion process that in a single fracture or a complex cleat network credit authorship contribution statement junling zheng conceptualization investigation methodology writing original draft yi jin supervision writing review editing funding acquisition jiabin dong data curation methodology formal analysis shunxi liu validation formal analysis qing zhang formal analysis writing review editing huibo song visualization pinghua huang visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was supported by the national natural science foundation of china grant no 41972175 the science and technology major project of shanxi province china grant no 20181101013 1 the program for innovative research team in science and technology in universities of henan province china grant no 21irtsthn007 the program for innovative research team in science and technology of henan polytechnic university grant no t2020 4 and the program for key scientific research of universities in henan province china grant no 22a170008 
3412,the present study was done in order to simulate the flash flood susceptibility across the suha river basin in romania using a number of 3 hybrid models and fuzzy ahp multicriteria decision making analysis it should be noted that flash flood events are triggered by heavy rainfall in small river catchments to achieve the proposed results a total of 8 flash flood predictors slope angle plan curvature hydrological soil groups land use convergence index profile curvature topographic position index aspect along with a sample of 111 torrential phenomena points were used as input datasets in the next four algorithms fuzzy analytical hierarchy process fahp deep learning neural network analytical hierarchy process dlnn ahp multilayer perceptron analytical hierarchy process mlp ahp and naïve bayes analytical hierarchy process nb ahp the analytical hierarchy process was used to calculate the coefficients for each class category of flash flood predictors the torrential points sample was split into training 70 and validating samples 30 the modelling was done in excel spss and r software h2o package while the result mapping was performed in arcgis 10 5 software the analysis revealed that the high and very high susceptibility degrees are spread over a maximum of 35 01 of the study area the best performances demonstrated by an auc roc of 0 984 are associated with the deep learning neural network analytical hierarchy process model followed by naïve bayes analytical hierarchy process model auc 0 976 multilayer perceptron analytical hierarchy process model auc 0 882 and fuzzy analytical hierarchy process auc 0 807 these results indicates that deep learning neural network is a promising machine learning model which can provide outcomes with very high precision also according to the present research results the deep learning neural network having many hidden layers is able outperform the multilayer perceptron that contains a single hidden layer the main novelty of the present research is the application of the three ensemble models dlnn ahp mlp ahp and nb ahp and also the use of h2o package for the first time in literature to evaluate the flash flood susceptibility in small river catchments keywords flash flood susceptibility machine learning h2o package suha river basin romania 1 introduction a flash flood occurs when heavy rainfall from convective weather has a short duration and highly intensity and it is often generated in small river basins less than 200 square kilometers with a high complex orography destro et al 2018 wang et al 2021 as a result of precipitation filling the drainage capacity of the basin slope flash floods occur when the drainage network is incarcerated and the basin outlets discharge at extraordinarily high rates youssef et al 2016 each year global economic losses are estimated to be around 60 billion usd due to floods and flash floods janizadeh et al 2019 storms that produce flash floods can cause severe damage to infrastructures such as roads railway tracks and urban areas as a result of ongoing urbanization and climate change many areas are facing many environmental challenges and greater risks of natural disasters kjeldsen 2010 there are many different types of riverine flooding but the most common are flash floods which occur when a massive amount of water is released in a short amount of time three to six hours due to excessive rainfall the melting of natural ice or a dam failure janizadeh et al 2019 the rapid onset of river levels and the high velocity of flash floods make them among the most dangerous types of floods they cause serious injuries economic losses and environmental damage destro et al 2018 due to the complexity of flash floods it remains challenging to predict them accurately bui et al 2019 however it is well known that weather conditions soil types geomorphological structures and vegetation have a major contribution to flash flood genesis asadi et al 2019 youssef et al 2016 to mitigate the negative effects of flash floods it is mandatory to accurately identify the potential zones that can be damaged by these natural hazards in order to predict the flash flood likelihood a variety of studies were conducted by the researchers thus a part of these studies belongs to the rainfall runoff modelling approaches kratzert et al 2018 zhang et al 2019 liu et al 2020 another type of approach comprises the hydraulic modelling that can be done using some models like mike hec ras telemac 2d or jflow alho and aaltonen 2008 bures et al 2019 tamiru and dinka 2021 based on this hydraulic modelling software the flooded areas corresponding to different discharge return probabilities can be estimated however both the rainfall runoff modelling and hydraulic modelling approaches require a huge amount of measured data and also are time consuming another category of approach is represented by the flash flood susceptibility models that are based on the application of various methods having as input data a various number of flash flood predictors and flash flood locations arabameri et al 2020 in this regard we can mention many categories of models like multicriteria decision making analysis bivariate statistical models and machine learning models popa et al 2019 from the first class of models represented by multicriteria decision making analysis the follwing algorithms can be noted analytical hierarchy process handini et al 2021 vlse kriterijuska optamizacija i komoromisno resenje vikor singh and pandey 2021 technique for order preference by similarity to ideal solution topsis rafiei sardooi et al 2021 analytical network process chukwuma et al 2021 and fuzzy analytical hierarchy process costache et al 2021a the bivariate statistical models comprise many algorithms like frequency ratio waqas et al 2021 weights of evidence pham et al 2021a index of entropy wang et al 2021 statistical index liu et al 2021a certainty factor costache et al 2020b and evidential belief function chowdhuri et al 2020 the third category represented by the machine learning models contains a large number of algorithms like decision trees khosravi et al 2018 neural networks panahi et al 2021 pandey et al 2021 support vector machine xiong et al 2019 naive bayes elmahdy et al 2020 k nearest neighbor shahabi et al 2020a k star costache et al 2020c or deep learning neural network chakrabortty et al 2021 from the category of deep learning algorithms that were used in the literature we also mention the convolutional neural network wang et al 2020 recurrent neural network fang et al 2021 and autoencoder neural network ahmadlou et al 2021 with the intention of improving the results provided by the various models the researchers resorted to the application of existing optimization models such as biogeography based optimization bbo ahmadlou et al 2019 particle swarm optimization pso arora et al 2021 ngo et al 2021 or harris hawk optimization hho malik et al 2021 moreover another procedure intended to improve the accuracy of results is the hybridization between two or many models arabameri et al 2020 islam et al 2021 however there is a gap of know knowledge in the literature in terms of using the advance machine learning models in small river catchments to derive the flash flood susceptibility taking into account the above considerations the present research work aims to accurately detect the areas prone to flash flooding using the following algorithms hybrid combinations between deep learning based on h2o r package and analytical hierarchy process dlnn ahp hybrid combination between multilayer perceptron and analytical hierarchy process mlp ahp hybrid combinations between naive bayes and analytical hierarchy process nb ahp and fuzzy analytical hierarchy process fuzzy ahp these models were selected to be used for the estimation of flash flood susceptibility because they belong of the category of state of the art machine learning and multicriteria decision making algorithms and also their very high precision was demonstrated in the previous research works related to the natural hazard susceptibility evaluation abedini et al 2019 bui et al 2020a choubin et al 2019 wang et al 2021 it should be noted that in the present research the model s accuracy and results validation will be carried out using the roc curve method and several statistical metrics moreover in the case of dlnn their application was highly facilitated by the development of h2o r package in fact the use for the first time in the literature of nb ahp mlp ahp and dlnn ahp hybrid models along with the h2o r package for the application of dlnn model represents the main elements of novelty that characterize the present research study the area on which the present study is focused is the suha river catchment from romania a region that was highly affected in the past by flash floods phenomena and where these hazards caused many damages another reason for selecting this area as case study was the specific relief that is very favorable to the flash flood genesis for the present analysis geospatial data regarding the flash flood predictors and the presence of torrential areas were used in order to apply the proposed models 2 study area suha river basin is located in the northern part of romania fig 1 the elevation ranges between 500 m and 1600 m within the 363 km2 of land in spite of the large extent of afforestation approximately 72 of the basin is covered by forest the steep slope angles and numerous areas characterized by impassable soils render the suha catchment susceptible to flash floods tîrnovan et al 2014 a forest s protective role from a hydrological standpoint is reduced or wiped out if the precipitation caused by heavy rain exceeds the tree canopy s maximum interception capacity throughout the main valleys of the suha river catchment are built up areas that have active surface runoff other important land use categories are represented by pastures 12 89 and agriculture areas 5 25 the land use category with the lowest surface across suha river basin is represented by the rivers 0 72 in terms of hydrological soil groups it should be noted that across the study region all the 4 groups a b c and d are present costache and bui 2020 within the study area the most significant flash floods occurred in 1970 2005 2010 and 2018 this information was provided by the romanian national inspectorate for emergency situations there are a number of socio economic aspects that were profoundly affected by these phenomena in 2005 including 32 4 km of road infrastructure 148 buildings and more than 267 ha of agricultural land it was estimated that the economic damage totaled about 260 0000 euros costache and bui 2020 3 data 3 1 torrential locations inventory a thorough inventory of areas that have previously been impacted by natural hazards is the key to predicting future surfaces likely to experience these phenomena chen et al 2018 it was determined that the best method of analysis was to identify areas that had been affected by torrential phenomena costache 2019 generally torrential relief sites behave in a way that favors rapid surface runoff events which in turn lead to flash floods that propagate downslope we examined aerial imagery from google earth to identify areas already affected by torrentiality these surfaces consist exclusively of the unified presence of torrential microforms like ravines and gullies that are formed by surface runoff costache 2019 approximately 7 5 km2 of torrential areas were identified across the suha river basin a total of 111 points were extracted from the information regarding the presence of torrential phenomena as a part of the methodological workflow a second dataset representing an equal number of points 111 with non torrential phenomena was created by performing this step a low slope angle is ideal for non torrential pixels where rapid runoff is virtually impossible costache 2019 the dataset was divided into a training sample 70 and validation sample 30 fig 1 this division of the data set was made in order to create the possibility to validate the results offered by the model by using a percentage of 30 of the entire collected data sample also it is very important to note that the split procedure into 70 for training and 30 for validation sample is suggested by the vast majority of the previous similar research works ahmadlou et al 2019 costache et al 2020c islam et al 2021 shahabi et al 2020a 3 2 flash flood predictors on the basis of digital elevation model dem data extracted from shuttle radar topography mission srtm 30 m database six flash flood predictors have been derived in addition the hydrological soil groups and land use factors were extracted from digital soil map of romania 1 200000 and corine land cover 2018 database respectively it should be noted that even if the rainfall is an important factor in the flash flood genesis given the small surface of the study area it was considered that the values of this factor have a low spatial variability across suha river basin therefore the rainfall was not considered in the present study in the next rows a brief description of each flash flood predictor will be highlighted in general researchers consider the slope angle fig 2 a determined from the digital elevation model dem as the factor with the greatest influence on surface runoff ngo et al 2021 chao et al 2021 wang et al 2022 according to the morphological analysis slope angle has a significant impact on flash flood occurrences and manifestations since it controls surface runoff velocity which in turn affects flash flood characteristics costache and bui 2020 sahana et al 2020 the runoff and flash flooding associated with steep slopes are well known whereas their occurrence on flat surfaces is less likely elmahdy et al 2020 the slope angles of the study area ranging from 0 and 40 1 were partitioned into a number of 5 classes through the natural breaks classification method plan curvature fig 2b represents a second morphometric index achieved by the processing of digital elevation model specifically its values distinguish convergent runoff areas from divergent runoff areas minár et al 2020 the majority of torrential pixels occupy the zones with a plan curvature between 0 1 and 2 5 hydrological soil groups surface fig 2c runoff is directly controlled by hydrological soil groups which in turn influence the infiltration process stewart et al 2011 lan et al 2021 zhao et al 2021 the soil class c cover approximately 70 of suha river basin and comprises around 56 of torrential pixels land use fig 2d predictor has a widely usage in the research works that are related to the flash flood susceptibility estimation chakrabortty et al 2021 xiong et al 2019 as the first layer of a topographical surface with which raindrops are in contact the land use plays a vital role in flash floods prăvălie and costache 2013 costache and bui 2020 across the study zone a number of 6 different land use categories were identified the forest has the biggest percentage 72 while 41 of surfaces with torrential pixels are localized within the pastures convergence index fig 2e is the third predictor derived from dem its main feature is represented by its capacity to highlight the hydrographic convergence degree over a specific zone using the natural breaks algorithm the convergence index values were classified into 5 different classes the areas with values from 0 9 to 4 3 have around 40 of the total torrential pixels the profile curvature fig 2f shows the zones having an accelerated surface runoff and due to its significance in morphometry it should be considered in this study in the present research the profile curvature was classified into 3 intervals of values and the highest area belongs to the values from 0 to 0 9 topographic position index tpi fig 2g derived from dem indicates the altitude difference between a specific pixel and the pixels from its vicinity natural breaks was also used to divide its values into 5 classes the middle class with values between 0 4 and 0 4 has the largest surface and contains 30 of torrential pixels the aspect fig 2h is the last morphometric predictor taken into account for the flash flood susceptibility modelling in this research work the shaded slopes allow the presence of a saturated soil and therefore these surfaces could contribute in a more active manner to surface runoff genesis and then to flash flood occurrence north eastern slopes account 15 47 of the study region and 18 of torrential pixels are located on south eastern slopes fig 3 4 methods 4 1 feature selection using relieff method the use of relieff algorithm will allow an initial assessment of the predictive capacity of flash flood predictors this method have multiple benefits like costache et al 2021b i manage to minimize the training process time ii help to make the algorithms easier to be analyzed and less complex ii increase the models accuracy by selecting the highest predictive variables iv minimize the models overfitting this method can be applied with both discrete and continuous data in relieff algorithm the closest instance of either a different or the same class is considered when evaluating the attribute value urbanowicz et al 2018 weka 3 9 software was used to apply relieff method 4 2 deep learning neural network dlnn deep learning neural network is a type of machine learning model which can efficiently deal with huge amount and unstructured data deng et al 2013 he et al 2020 zhan et al 2022 this model represents a neural network with more than one hidden layer which is widely used in the literature that comprises studies approaching the natural disasters susceptibility bui et al 2020b costache et al 2020a shahabi et al 2020b these multiple hidden layers will help the transfer of information from the input layer containing the flash flood predictors to the output layer that will have 2 neurons represented by torrential and non torrential pixels panahi et al 2021 due to the fact that in essence the flash flood susceptibility estimation is a binary classification procedure the torrential pixels will be encoded with 1 while the non torrential pixels will be encoded with 0 at the same time the next sigmoid function will be applied e y i x the approximation of sigmoid function will be provided by the information that is assigned to a single output neuron associated to the class i in this research a softmax function having the next form will be also applied 1 softmax a i e x p a i k e x p a i where ai represents the layer of softmax function the next relations will be used to express a deep neural network containing multiple hidden layers h for h 1 h hidden layers 2 a h x b h w h p h 1 x 3 p h x a h x where is the activation function the dlnn algorithm will use as input the ahp coefficients calculated for each class category of flash flood predictors the dlnn model was implemented using h2o package from r programming language 4 3 fuzzy analytical hierarchy process fahp fuzzy analytical hierarchy process fahp represent an extension of analytical hierarchy process ahp multicriteria decision making model roodposhti et al 2014 this extension is mainly intended to solve several fuzzy problems from the hierarchical point of view sun 2010 by employing fuzzy set theory as well as the analytical hierarchy process can be improved the analysis quality by minimizing the subjectivity when estimating weights criteria the next steps are required to apply fahp model for the present research the flash flood predictors mentioned at 3 2 are involved in the construction of pairwise comparison matrices further to calculate the highest important criteria the linguistic terms will be associated with the pairwise comparisons using the next relation 4 a 1 a 12 a 1 n a 21 1 a 1 n a n 1 a n 2 1 1 a 12 a 1 n 1 a 21 1 a 1 n 1 a n 1 1 a n 2 1 where a ij are pairs of criteria i and j in the next phase the fuzzy weights and geometric mean of each criterion are calculated with the buckley method hategekimana et al 2018 5 r i a i 1 h a i 2 h h a in 1 n 6 w i r i h r 1 h h r n 1 where a in represents the comparison fuzzy value of the pair criterion i and criterion n r 1 represents the value of geometric mean of the fuzzy values comparison of criterion i compared to each of the other criteria and w i represents the fuzzy weighting of the i th criterion which could be expressed as a tfn w i lw i mw i uw i where lw i mw i and uw i represent the lower middle and upper values respectively of the fuzzy weighting of the ith criterion costache et al 2021a the next step was represented by the application of the extent analysis through which the weights of flash flood predictors will be achieved the fuzzy triangular comparison matrix was constructed in the first step and has the next form hategekimana et al 2018 7 a a ij nxn 1 1 1 l 12 m 12 u 12 l 1 n m 1 n u 1 n l 21 m 21 u 21 1 1 1 l 2 n m 2 n u 2 n l n 1 m n 1 u n 1 l n 2 m n 2 u n 2 1 1 1 where a ij l ij m ij u ij a n d a ij 1 1 l ij 1 m ij 1 u ij for i j 1 n and i j thus will be done the computation of triangular matrix priority vector further the fuzzy arithmetic function will be applied in order to sum up each row of matrix a 8 rs i j 1 n a ij j 1 n l ij j 1 n m ij j 1 n u ij i 1 n using the normalized version of equation 8 the fuzzy synthetic extent values for each ith object will be achieved roodposhti et al 2014 9 s i j n a ij h k 1 n j 1 n a kj 1 j 1 n l ij k 1 n j 1 n u kj j 1 n m ij k 1 n j 1 n m kj j 1 n u ij k 1 n j 1 n l kj i 1 n next through equation 10 the degree of possibility of s i s j is computed 10 v s i s j 1 i f m i m j u i l j u i m i m j l j l j u i i j 1 n j i 0 o t h e r s where s i l i m i u i and s j l j m j u j l e t w a i min v s i s k k 1 2 n k i then the weight vector value is determined as following 12 w a i w a 1 w a 2 w a n t where ai i 1 2 n are n elements the equation 13 is used after the normalization process when the weight vectors are computed 13 w a i w a 1 w a 2 w a n t where w is a non fuzzy number 4 4 multilayer perceptron mlp mlp is a very popular artificial neural network being characterized by one way error propagation of the feed forward network model li et al 2019 time series prediction pattern recognition and so forth can be solved using mlp the mlp structure contains an input layer a hidden layer and an output layer ke et al 2021 each layer s connections to the input and hidden layers and its connections to the output layers will be processed according to the weight values li et al 2019 the back propagation method is involved in the update process of the weight values liu et al 2021b zare et al 2013 two stages can be distinguished when this procedure is performed i input and output values are propagated through hidden layers and the output values are compared with pre values to determine the difference between them ii the connection weights are adjusted in order to achieve the most performant results with the minimum difference repeated iteratively the procedure is continued until a root mean square error of the network is within acceptable limits in the present study the input neurons in the input layer are represented by flash flood predictors while the output neurons in the output layer are represented by the torrential and non torrential surfaces the optimal number of hidden neurons will be established according to the minimum rmse value eq 14 14 rmse 1 n i 1 n c i c i 2 where n represents the date number ci are the measured data and ĉi the calculated values 4 5 naïve bayes nb based on bayes theorem naïve bayes presumes that the dependencies among the predictor attributes do not exists jiang et al 2016 the wide use of nb is due to the fact that it does not require a large volume of training data or a complex workflow for building classification models tien bui et al 2012 by using the ahp values assigned to each category of flash flood predictors from the training sample the nb was involved in the estimation of flash flood within the research zone if we consider 2 vectors the first assigned to each predictor having ahp coefficients computed g g1 g2 g10 and the second which corresponds to the presence and absence of torrential zones f f1 f2 the classification using nb algorithm is based on the next mathematical relation 15 t nb argmax p t i t i torrential no torrential i 1 n p f i t i where p ti is equal to the ti prior probability which can be computed using the proportion of the observed cases and the output class ti within the training sample moreover the conditional probability value is calculated using the next equation tien bui et al 2012 16 p f i t i 1 2 π δ e f i μ 2 2 δ 2 where μ represents the mean and δ is equal to the xi standard deviation weka v 3 9 software was involved for the application of nb model 4 6 results validation 4 6 1 statistical metrics the following indices were involved in the results validation process sensitivity specificity kappa index f1 score accuracy and precision statistical indices are significant if they show a correlation from the spatial point of view between the torrential and non torrential locations that were observed and the estimated flash flood susceptible zone costache 2019 the next relations will be applied for statistical metrics derivation canbek et al 2017 17 s e n s i t i v i t y t p t p f n 18 s p e c i f i c i t y t n f p t n 19 p r e c i s i o n t p t p f p 20 a c c u r a c y t p t n t p f p t n f n 21 k p o p e 1 p e where p represents the equivalent number of locations with torrential phenomenon n represents the equivalent number of non torrential pixels fp false positive and fn false negative represents the equivalent number of locations erroneously classified k is kappa coefficient po is the observed torrential locations and pe is equal to the estimated flash flood susceptibility value 4 6 2 roc curve in statistics receiver operating characteristic roc curves are used to determine the predictive value of different statistical or machine learning techniques costache et al 2019 zhang et al 2020 a roc curve is constructed by displaying sensitivity on the y axis and false positive rate 1 specificity on the x axis area under curve auc is the essential measure for the model s performance estimated through roc curve the closer auc to 1 the better the models performance hosseini et al 2020 the following mathematical relationship can be involved for auc computation 22 a u c t p t n p n the entire workflow is schematically represented in fig 4 5 results 5 1 feature selection and correlation analysis following the application of the relieff method for feature selection the following results were achieved slope angle 0 74 land use 0 56 convergence index 0 43 hydrological soil groups 0 35 tpi 0 32 plan curvature 0 29 profile curvature 0 24 aspect 0 09 fig 5 by analyzing the achieved results it can be concluded that all the factors are able to influence the flash flood phenomena and therefore all of them will be included in the future workflow to avoid the redundant information among the 8 flash flood predictors the correlation matrix in r software was constructed it reveals that the highest degree of correlation take place between profile curvature and convergence index with a value of correlation coefficient equal to 0 327 fig 6 the fig 6 shows that in four cases the correlation coefficient is equal to 0 thus it can be seen that no serious correlation is detected between the input variables and so as all of them will be involved in the computational workflow 5 2 ahp coefficients table 1 shows the pair wise comparison between all the classes or categories of flash flood predictors according to the outcomes of ahp method the profile curvature class was between 2 2 and 0 achieved the highest ahp coefficient 0 633 being followed by plan curvature class between 0 1 and 0 1 ahp 0 512 slope angle class between 23 8 and 40 1 ahp 0 507 convergence index class between 96 and 3 ahp 0 485 the lowest values of ahp were achieved by flat surface derived from aspect predictor ahp 0 034 slope angle between 0 and 7 4 ahp 0 035 and forest surfaces ahp 0 04 the judgment consistency for each matrix was assessed through consistency ratio cr table 2 given the fact that all values of cr are below to 0 1 all the comparison within the matrices are consistent 5 3 flash flood susceptibility computation 5 3 1 fuzzy ahp using the fuzzy ahp method the first step to determine the flash flood susceptibility was to create in microsoft excel a fuzzy pair wise comparison matrix table 3 thus in this matrix all 8 flash flood predictors were included and compared according to their importance in the flash flood genesis based on the results in the comparison matrix the following equation was used to determine the synthesis values 24 k 1 n j 1 n a kj 1 164 74 217 617 275 783 1 0 0036 0 0046 0 006 these results were then used to calculate fuzzy numbers that could be assigned to each flash flood predictor in the next step the degree of possibility process was applied based on the fuzzy number table 4 next the weight of each flash flood predictor was calculated with the following equations 25 w a i 0 54 0 43 0 49 0 09 0 1 0 0 061 t 26 w a i 0 19 0 155 0 175 0 033 0 0 354 0 0 061 t in addition the defuzzification process allows tfns to be converted into crisp weights that are applied to each flash flood conditioning factor and subsequently multiplied by ahp values to create the ffsifahp fig 10a the value of ffsifahp range from 0 07 to 0 48 the natural breaks method was utilized to classify the flash flood susceptibility values having the very low class between 0 07 and 0 19 characterized by a percentage of 18 32 fig 9a the low class is situated between 0 2 and 0 25 having a percentage of 31 59 while the moderate class between 0 26 and 0 3 occupies a percentage of 32 41 the high and very high susceptibility values above 0 31 is spread on 17 68 5 3 2 dlnn ahp the dlnn ahp model was trained in r environment with the help of tools available in h2o package the optimum architecture was reached by estimating the loss and accuracy values by after the application of total number of epochs equal to 100 according to the results the maximum accuracy of 0 95 was obtained after 89 epochs while the minimum value of loss 0 042 was reached after 95 epochs the uniform kernel was used as initializer function while relu was involved as activation function the batch size was set to 100 validation rate to 0 2 while the dropout rate to 0 1 thus the optimal architecture of ahp dlnn is formed by 8 input neurons 3 hidden layers with a maximum of 64 neurons and 2 output neurons represented by the presence or absence of torrential pixels fig 7 finally the functionalities of h2o r package in terms of deep learning neural networks algorithm allow to derive the following importance values for each variable slope angle 0 206 plan curvature 0 114 hydrological soil group 0 114 land use 0 088 convergence index 0 122 profile curvature 0 179 topographic position index 0 111 and aspect 0 066 these values were used to derive in map algebra the ffsiahp dlnn within the study zone fig 9b using the natural breaks classification method the ffsiahp dlnn values were divided into 5 classes the very low class has a percentage of 13 16 and values from 0 09 and 0 19 the low class with a percentage of 29 12 is situated in the range from 0 2 to 0 23 the moderate susceptibility is spread on 22 7 while the high and very high values account 35 01 of the study zone 5 3 3 mlp ahp the architecture of mlp ahp model used in the present research was established according the lowest value achieved by rmse thus the lowest rmse equal to 0 013 was achieved with a hidden layer containing 14 hidden neurons fig 8 a moreover the pseudoprobability plot exposed in fig 8b confirm that the torrential and non torrential pixels were correct classified because the majority of values represented on the left side in blue and right side in green are situated over the 0 5 of y axis the gain chart fig 8c and lift chart fig 8d prove also the high degree of performance obtained through mlp ahp model the spss software permitted the possibility to derive the values of each flash flood predictor importance in the mlp ahp ensemble as following slope angle 0 538 topographic position index 0 109 convergence index 0 096 plan curvature 0 093 hydrological soil group 0 055 aspect 0 052 profile curvature 0 035 and land use 0 022 the factor importance was used to compute the ffsimlp ahp fig 9c again natural breaks algorithm was used to split the susceptibility values into 5 classes the very low values between 0 06 and 0 16 span on 31 32 of the study zone while the low class is spread on 39 09 and is characterized by values from 0 17 to 0 22 moderate flash flood susceptibility is characteristic for a percentage of 20 35 of the total territory while another 9 25 has a high and very high susceptibility 5 3 4 nb ahp using training data and a 10 fold cross validation algorithm in the weka 3 9 environment the nb ahp model was built the cross validation procedure is designed to minimize over fitting and reduce data variability as much as possible based on the training process the maximum accuracy reached was 0 926 while the k index was 0 74 the most important factor was the slope angle 0 427 followed by plan curvature 0 112 topographic position index 0 098 hydrological soil group 0 092 convergence index 0 078 profile curvature 0 066 aspect 0 065 and land use 0 062 table 5 like in the previous cases natural breaks method helped to split the susceptibility values into 5 classes the very low values between 0 07 and 0 16 are spread on 17 44 of the research area while the low class spans on 35 5 and has values between 0 17 and 0 2 moderate flash flood susceptibility is characteristic for a percentage of 23 21 of the total territory while another 23 85 has a high and very high susceptibility fig 9d 5 4 validation and comparison of the models the results validation part was accomplished using the roc curve and a number of 4 statistical metrics 5 4 1 analysis of statistical metrics basically the use of training dataset highlights the following values for the accuracy metric the highest value was assigned to dlnn ahp 0 968 followed by nb ahp 0 942 mlp ahp 0 885 and fahp 0 84 table 6 the use of validating sample showed that the best accuracy was associated to dlnn ahp 0 97 followed by nb ahp 0 955 mlp ahp 0 848 and fahp 0 803 5 4 2 analysis of the roc curve in terms of roc curves the success rate was constructed with the help of training sample while the prediction rate was designed by taking into consideration the validating dataset the highest auc of success rate shows was registered by the dlnn ahp model 0 971 on the second place being nb ahp 0 945 followed by mlp ahp 0 888 and fahp 0 836 fig 10a the prediction rate shows the same hierarchy as follows dlnn ahp model 0 984 nb ahp 0 976 mlp ahp 0 882 and fahp 0 807 fig 10b since the auc values were above 0 8 we can state that all applied algorithms have a good performance 6 discussions one of the areas highly affected by flash floods hazards on the european continent is the romanian mountain region romanescu et al 2017 within which is situated also the present research area in light of the predicted increase in heavy rain frequency alfieri et al 2018 it is crucial to detect promptly areas exposed to flash flood hazards within the suha river catchment in order to achieve very high precise results the mechanisms of flash floods must be understood and state of the art techniques must be used to evaluate the flash flood susceptibility to determine which surfaces are prone to rapid surface runoff we developed four models based on machine learning techniques fuzzy multicriteria decision making and their ensemble to model the ffsi values from the spatial point of view in the last 10 years many papers brewster 2010 kruzdlo and ceru 2010 tincu et al 2018 zaharia et al 2015 zaharia et al 2012 aimed to evaluate flash flood susceptibility using the method proposed by smith 2003 however the aforementioned studies did not include any methodological considerations regarding surface runoff in the past and or a statistical approach to determining flash flood susceptibility within their methodological workflow past studies were also subject to a large degree of subjectivity due to the simple overlapping of flash flood predictors in gis software nonetheless the training process for the 4 models applied in this paper made use of many flash flood predictors that have been studied in previous papers based on the results of all the models slope angle was the most significant factor it has been established in many of the past research works that slope angle has a major influence on runoff genesis and manifestation borga et al 2011 chakrabortty et al 2021 elmahdy et al 2020 this is explained by the fact that the slope angle affects the surface runoff velocity which determines how flash floods behave fontanine and costache 2013 this affirmation is in total agreement with the outputs of the feature selection process that was applied in the present research and which showed that the slope angle has the highest correlation among all the flash flood predictors with the previous torrential phenomena land use and convergence index are another 2 flash flood predictors that resulted to be highly correlated with the historical torrential processes on the reliability of the models it becomes evident that the dlnn ahp ensemble provided the best results while fahp was the least reliable in line with tehrany et al 2015 findings multicriteria decision making analysis algorithms like fahp have some disadvantages because this category of methods relies on expert knowledge without considering the location of the previous areas affected by that hazard furthermore the results of the present study show that the deep learning neural network due to its complex structure with many hidden layers which are able for an input data deep processing outperforms the multilayer perceptron with only one hidden layer and also the other three ensemble models used in this research thus the statistical metrics involved in the results validation procedure highlights an accuracy of 0 97 for dlnn ahp comparing to the lowest accuracy of 0 803 that belongs to the fahp model the same difference is also highlighted by the prediction rate of roc curve where the auc of dlnn ahp was 0 984 meanwhile the auc of fahp was 0 807 the very high precision of dlnn model in terms of flash flood susceptibility prediction was also certified in the study carried out by bui et al 2020a b in the lao cai province of vietnam where this algorithm reached an accuracy of 0 94 also in the same study the auc roc curve of dlnn equal to 0 96 exceeded the auc roc curve of mlp that was equal to 0 926 also in another study done on the same topic by pham et al 2021b in quang nam province of vietnam deep learning neural network algorithm reached an accuracy maximum value of 0 961 and exceeded the performance of the other models like logistic regression accuracy 0 954 artificial neural network radial basis function accuracy 0 954 logistic model tree accuracy 0 954 and alternating decision tree accuracy 0 958 therefore we can state that the dlnn is a very high performant model that is capable to provide highly accurate results in terms of flood and flash flood susceptibility prediction 7 conclusions the current study aimed to propose new 3 hybrid algorithms and fuzzy ahp method to estimate the flash flood susceptibility within the suha river basin in each of the hybrid models pixels associated with torrential areas were used alongside eight flash flood predictors as input data as a result of the application of the relieff method all eight flash flood conditioning factors are reliable and should be incorporated into the analysis by evaluating the results with roc curve all the models achieved good to very good performance as indicated by area under the curve auc values above 0 807 furthermore the accuracy values of over 0 803 indicate the models robustness over 9 25 of the research zone is covered by surfaces with high and high flash flood susceptibility which are uniformly distributed within the suha basin in this study there is a significant novelty in that the 3 ensemble models dlnn ahp mlp ahp and nb ahp and h2o r package are used for the first time to predict whether a region is vulnerable to flash flood phenomena the results obtained in this study which have very good accuracy can be used with a high degree of confidence by the authorities responsible for the mitigation of flash flood negative effects as in any study in which geospatial data is used a limitation of this study may be the errors that may occur in the spatial representation of the data therefore it should be noted that the focus of the future study will be to obtain data with higher resolution and accuracy and to use them in studies on estimating susceptibility to flash floods funding this work was supported by a grant of the romanian ministry of education and research cncs uefiscdi project number pn iii p1 1 1 pd 2019 0424 p within pncdi iii credit authorship contribution statement romulus costache conceptualization methodology software validation formal analysis investigation resources data curation writing original draft writing review editing visualization supervision funding acquisition tran trung tin conceptualization visualization funding acquisition alireza arabameri methodology formal analysis investigation writing review editing supervision anca crăciun r s ajin methodology formal analysis investigation writing review editing supervision iulia costache methodology software validation formal analysis investigation resources data curation writing original draft writing review editing supervision abu reza md towfiqul islam data curation writing original draft s i abba methodology data curation mehebub sahana conceptualization methodology mohammadtaghi avand software validation resources data curation writing original draft binh thai pham conceptualization software validation resources data curation writing original draft visualization funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
3412,the present study was done in order to simulate the flash flood susceptibility across the suha river basin in romania using a number of 3 hybrid models and fuzzy ahp multicriteria decision making analysis it should be noted that flash flood events are triggered by heavy rainfall in small river catchments to achieve the proposed results a total of 8 flash flood predictors slope angle plan curvature hydrological soil groups land use convergence index profile curvature topographic position index aspect along with a sample of 111 torrential phenomena points were used as input datasets in the next four algorithms fuzzy analytical hierarchy process fahp deep learning neural network analytical hierarchy process dlnn ahp multilayer perceptron analytical hierarchy process mlp ahp and naïve bayes analytical hierarchy process nb ahp the analytical hierarchy process was used to calculate the coefficients for each class category of flash flood predictors the torrential points sample was split into training 70 and validating samples 30 the modelling was done in excel spss and r software h2o package while the result mapping was performed in arcgis 10 5 software the analysis revealed that the high and very high susceptibility degrees are spread over a maximum of 35 01 of the study area the best performances demonstrated by an auc roc of 0 984 are associated with the deep learning neural network analytical hierarchy process model followed by naïve bayes analytical hierarchy process model auc 0 976 multilayer perceptron analytical hierarchy process model auc 0 882 and fuzzy analytical hierarchy process auc 0 807 these results indicates that deep learning neural network is a promising machine learning model which can provide outcomes with very high precision also according to the present research results the deep learning neural network having many hidden layers is able outperform the multilayer perceptron that contains a single hidden layer the main novelty of the present research is the application of the three ensemble models dlnn ahp mlp ahp and nb ahp and also the use of h2o package for the first time in literature to evaluate the flash flood susceptibility in small river catchments keywords flash flood susceptibility machine learning h2o package suha river basin romania 1 introduction a flash flood occurs when heavy rainfall from convective weather has a short duration and highly intensity and it is often generated in small river basins less than 200 square kilometers with a high complex orography destro et al 2018 wang et al 2021 as a result of precipitation filling the drainage capacity of the basin slope flash floods occur when the drainage network is incarcerated and the basin outlets discharge at extraordinarily high rates youssef et al 2016 each year global economic losses are estimated to be around 60 billion usd due to floods and flash floods janizadeh et al 2019 storms that produce flash floods can cause severe damage to infrastructures such as roads railway tracks and urban areas as a result of ongoing urbanization and climate change many areas are facing many environmental challenges and greater risks of natural disasters kjeldsen 2010 there are many different types of riverine flooding but the most common are flash floods which occur when a massive amount of water is released in a short amount of time three to six hours due to excessive rainfall the melting of natural ice or a dam failure janizadeh et al 2019 the rapid onset of river levels and the high velocity of flash floods make them among the most dangerous types of floods they cause serious injuries economic losses and environmental damage destro et al 2018 due to the complexity of flash floods it remains challenging to predict them accurately bui et al 2019 however it is well known that weather conditions soil types geomorphological structures and vegetation have a major contribution to flash flood genesis asadi et al 2019 youssef et al 2016 to mitigate the negative effects of flash floods it is mandatory to accurately identify the potential zones that can be damaged by these natural hazards in order to predict the flash flood likelihood a variety of studies were conducted by the researchers thus a part of these studies belongs to the rainfall runoff modelling approaches kratzert et al 2018 zhang et al 2019 liu et al 2020 another type of approach comprises the hydraulic modelling that can be done using some models like mike hec ras telemac 2d or jflow alho and aaltonen 2008 bures et al 2019 tamiru and dinka 2021 based on this hydraulic modelling software the flooded areas corresponding to different discharge return probabilities can be estimated however both the rainfall runoff modelling and hydraulic modelling approaches require a huge amount of measured data and also are time consuming another category of approach is represented by the flash flood susceptibility models that are based on the application of various methods having as input data a various number of flash flood predictors and flash flood locations arabameri et al 2020 in this regard we can mention many categories of models like multicriteria decision making analysis bivariate statistical models and machine learning models popa et al 2019 from the first class of models represented by multicriteria decision making analysis the follwing algorithms can be noted analytical hierarchy process handini et al 2021 vlse kriterijuska optamizacija i komoromisno resenje vikor singh and pandey 2021 technique for order preference by similarity to ideal solution topsis rafiei sardooi et al 2021 analytical network process chukwuma et al 2021 and fuzzy analytical hierarchy process costache et al 2021a the bivariate statistical models comprise many algorithms like frequency ratio waqas et al 2021 weights of evidence pham et al 2021a index of entropy wang et al 2021 statistical index liu et al 2021a certainty factor costache et al 2020b and evidential belief function chowdhuri et al 2020 the third category represented by the machine learning models contains a large number of algorithms like decision trees khosravi et al 2018 neural networks panahi et al 2021 pandey et al 2021 support vector machine xiong et al 2019 naive bayes elmahdy et al 2020 k nearest neighbor shahabi et al 2020a k star costache et al 2020c or deep learning neural network chakrabortty et al 2021 from the category of deep learning algorithms that were used in the literature we also mention the convolutional neural network wang et al 2020 recurrent neural network fang et al 2021 and autoencoder neural network ahmadlou et al 2021 with the intention of improving the results provided by the various models the researchers resorted to the application of existing optimization models such as biogeography based optimization bbo ahmadlou et al 2019 particle swarm optimization pso arora et al 2021 ngo et al 2021 or harris hawk optimization hho malik et al 2021 moreover another procedure intended to improve the accuracy of results is the hybridization between two or many models arabameri et al 2020 islam et al 2021 however there is a gap of know knowledge in the literature in terms of using the advance machine learning models in small river catchments to derive the flash flood susceptibility taking into account the above considerations the present research work aims to accurately detect the areas prone to flash flooding using the following algorithms hybrid combinations between deep learning based on h2o r package and analytical hierarchy process dlnn ahp hybrid combination between multilayer perceptron and analytical hierarchy process mlp ahp hybrid combinations between naive bayes and analytical hierarchy process nb ahp and fuzzy analytical hierarchy process fuzzy ahp these models were selected to be used for the estimation of flash flood susceptibility because they belong of the category of state of the art machine learning and multicriteria decision making algorithms and also their very high precision was demonstrated in the previous research works related to the natural hazard susceptibility evaluation abedini et al 2019 bui et al 2020a choubin et al 2019 wang et al 2021 it should be noted that in the present research the model s accuracy and results validation will be carried out using the roc curve method and several statistical metrics moreover in the case of dlnn their application was highly facilitated by the development of h2o r package in fact the use for the first time in the literature of nb ahp mlp ahp and dlnn ahp hybrid models along with the h2o r package for the application of dlnn model represents the main elements of novelty that characterize the present research study the area on which the present study is focused is the suha river catchment from romania a region that was highly affected in the past by flash floods phenomena and where these hazards caused many damages another reason for selecting this area as case study was the specific relief that is very favorable to the flash flood genesis for the present analysis geospatial data regarding the flash flood predictors and the presence of torrential areas were used in order to apply the proposed models 2 study area suha river basin is located in the northern part of romania fig 1 the elevation ranges between 500 m and 1600 m within the 363 km2 of land in spite of the large extent of afforestation approximately 72 of the basin is covered by forest the steep slope angles and numerous areas characterized by impassable soils render the suha catchment susceptible to flash floods tîrnovan et al 2014 a forest s protective role from a hydrological standpoint is reduced or wiped out if the precipitation caused by heavy rain exceeds the tree canopy s maximum interception capacity throughout the main valleys of the suha river catchment are built up areas that have active surface runoff other important land use categories are represented by pastures 12 89 and agriculture areas 5 25 the land use category with the lowest surface across suha river basin is represented by the rivers 0 72 in terms of hydrological soil groups it should be noted that across the study region all the 4 groups a b c and d are present costache and bui 2020 within the study area the most significant flash floods occurred in 1970 2005 2010 and 2018 this information was provided by the romanian national inspectorate for emergency situations there are a number of socio economic aspects that were profoundly affected by these phenomena in 2005 including 32 4 km of road infrastructure 148 buildings and more than 267 ha of agricultural land it was estimated that the economic damage totaled about 260 0000 euros costache and bui 2020 3 data 3 1 torrential locations inventory a thorough inventory of areas that have previously been impacted by natural hazards is the key to predicting future surfaces likely to experience these phenomena chen et al 2018 it was determined that the best method of analysis was to identify areas that had been affected by torrential phenomena costache 2019 generally torrential relief sites behave in a way that favors rapid surface runoff events which in turn lead to flash floods that propagate downslope we examined aerial imagery from google earth to identify areas already affected by torrentiality these surfaces consist exclusively of the unified presence of torrential microforms like ravines and gullies that are formed by surface runoff costache 2019 approximately 7 5 km2 of torrential areas were identified across the suha river basin a total of 111 points were extracted from the information regarding the presence of torrential phenomena as a part of the methodological workflow a second dataset representing an equal number of points 111 with non torrential phenomena was created by performing this step a low slope angle is ideal for non torrential pixels where rapid runoff is virtually impossible costache 2019 the dataset was divided into a training sample 70 and validation sample 30 fig 1 this division of the data set was made in order to create the possibility to validate the results offered by the model by using a percentage of 30 of the entire collected data sample also it is very important to note that the split procedure into 70 for training and 30 for validation sample is suggested by the vast majority of the previous similar research works ahmadlou et al 2019 costache et al 2020c islam et al 2021 shahabi et al 2020a 3 2 flash flood predictors on the basis of digital elevation model dem data extracted from shuttle radar topography mission srtm 30 m database six flash flood predictors have been derived in addition the hydrological soil groups and land use factors were extracted from digital soil map of romania 1 200000 and corine land cover 2018 database respectively it should be noted that even if the rainfall is an important factor in the flash flood genesis given the small surface of the study area it was considered that the values of this factor have a low spatial variability across suha river basin therefore the rainfall was not considered in the present study in the next rows a brief description of each flash flood predictor will be highlighted in general researchers consider the slope angle fig 2 a determined from the digital elevation model dem as the factor with the greatest influence on surface runoff ngo et al 2021 chao et al 2021 wang et al 2022 according to the morphological analysis slope angle has a significant impact on flash flood occurrences and manifestations since it controls surface runoff velocity which in turn affects flash flood characteristics costache and bui 2020 sahana et al 2020 the runoff and flash flooding associated with steep slopes are well known whereas their occurrence on flat surfaces is less likely elmahdy et al 2020 the slope angles of the study area ranging from 0 and 40 1 were partitioned into a number of 5 classes through the natural breaks classification method plan curvature fig 2b represents a second morphometric index achieved by the processing of digital elevation model specifically its values distinguish convergent runoff areas from divergent runoff areas minár et al 2020 the majority of torrential pixels occupy the zones with a plan curvature between 0 1 and 2 5 hydrological soil groups surface fig 2c runoff is directly controlled by hydrological soil groups which in turn influence the infiltration process stewart et al 2011 lan et al 2021 zhao et al 2021 the soil class c cover approximately 70 of suha river basin and comprises around 56 of torrential pixels land use fig 2d predictor has a widely usage in the research works that are related to the flash flood susceptibility estimation chakrabortty et al 2021 xiong et al 2019 as the first layer of a topographical surface with which raindrops are in contact the land use plays a vital role in flash floods prăvălie and costache 2013 costache and bui 2020 across the study zone a number of 6 different land use categories were identified the forest has the biggest percentage 72 while 41 of surfaces with torrential pixels are localized within the pastures convergence index fig 2e is the third predictor derived from dem its main feature is represented by its capacity to highlight the hydrographic convergence degree over a specific zone using the natural breaks algorithm the convergence index values were classified into 5 different classes the areas with values from 0 9 to 4 3 have around 40 of the total torrential pixels the profile curvature fig 2f shows the zones having an accelerated surface runoff and due to its significance in morphometry it should be considered in this study in the present research the profile curvature was classified into 3 intervals of values and the highest area belongs to the values from 0 to 0 9 topographic position index tpi fig 2g derived from dem indicates the altitude difference between a specific pixel and the pixels from its vicinity natural breaks was also used to divide its values into 5 classes the middle class with values between 0 4 and 0 4 has the largest surface and contains 30 of torrential pixels the aspect fig 2h is the last morphometric predictor taken into account for the flash flood susceptibility modelling in this research work the shaded slopes allow the presence of a saturated soil and therefore these surfaces could contribute in a more active manner to surface runoff genesis and then to flash flood occurrence north eastern slopes account 15 47 of the study region and 18 of torrential pixels are located on south eastern slopes fig 3 4 methods 4 1 feature selection using relieff method the use of relieff algorithm will allow an initial assessment of the predictive capacity of flash flood predictors this method have multiple benefits like costache et al 2021b i manage to minimize the training process time ii help to make the algorithms easier to be analyzed and less complex ii increase the models accuracy by selecting the highest predictive variables iv minimize the models overfitting this method can be applied with both discrete and continuous data in relieff algorithm the closest instance of either a different or the same class is considered when evaluating the attribute value urbanowicz et al 2018 weka 3 9 software was used to apply relieff method 4 2 deep learning neural network dlnn deep learning neural network is a type of machine learning model which can efficiently deal with huge amount and unstructured data deng et al 2013 he et al 2020 zhan et al 2022 this model represents a neural network with more than one hidden layer which is widely used in the literature that comprises studies approaching the natural disasters susceptibility bui et al 2020b costache et al 2020a shahabi et al 2020b these multiple hidden layers will help the transfer of information from the input layer containing the flash flood predictors to the output layer that will have 2 neurons represented by torrential and non torrential pixels panahi et al 2021 due to the fact that in essence the flash flood susceptibility estimation is a binary classification procedure the torrential pixels will be encoded with 1 while the non torrential pixels will be encoded with 0 at the same time the next sigmoid function will be applied e y i x the approximation of sigmoid function will be provided by the information that is assigned to a single output neuron associated to the class i in this research a softmax function having the next form will be also applied 1 softmax a i e x p a i k e x p a i where ai represents the layer of softmax function the next relations will be used to express a deep neural network containing multiple hidden layers h for h 1 h hidden layers 2 a h x b h w h p h 1 x 3 p h x a h x where is the activation function the dlnn algorithm will use as input the ahp coefficients calculated for each class category of flash flood predictors the dlnn model was implemented using h2o package from r programming language 4 3 fuzzy analytical hierarchy process fahp fuzzy analytical hierarchy process fahp represent an extension of analytical hierarchy process ahp multicriteria decision making model roodposhti et al 2014 this extension is mainly intended to solve several fuzzy problems from the hierarchical point of view sun 2010 by employing fuzzy set theory as well as the analytical hierarchy process can be improved the analysis quality by minimizing the subjectivity when estimating weights criteria the next steps are required to apply fahp model for the present research the flash flood predictors mentioned at 3 2 are involved in the construction of pairwise comparison matrices further to calculate the highest important criteria the linguistic terms will be associated with the pairwise comparisons using the next relation 4 a 1 a 12 a 1 n a 21 1 a 1 n a n 1 a n 2 1 1 a 12 a 1 n 1 a 21 1 a 1 n 1 a n 1 1 a n 2 1 where a ij are pairs of criteria i and j in the next phase the fuzzy weights and geometric mean of each criterion are calculated with the buckley method hategekimana et al 2018 5 r i a i 1 h a i 2 h h a in 1 n 6 w i r i h r 1 h h r n 1 where a in represents the comparison fuzzy value of the pair criterion i and criterion n r 1 represents the value of geometric mean of the fuzzy values comparison of criterion i compared to each of the other criteria and w i represents the fuzzy weighting of the i th criterion which could be expressed as a tfn w i lw i mw i uw i where lw i mw i and uw i represent the lower middle and upper values respectively of the fuzzy weighting of the ith criterion costache et al 2021a the next step was represented by the application of the extent analysis through which the weights of flash flood predictors will be achieved the fuzzy triangular comparison matrix was constructed in the first step and has the next form hategekimana et al 2018 7 a a ij nxn 1 1 1 l 12 m 12 u 12 l 1 n m 1 n u 1 n l 21 m 21 u 21 1 1 1 l 2 n m 2 n u 2 n l n 1 m n 1 u n 1 l n 2 m n 2 u n 2 1 1 1 where a ij l ij m ij u ij a n d a ij 1 1 l ij 1 m ij 1 u ij for i j 1 n and i j thus will be done the computation of triangular matrix priority vector further the fuzzy arithmetic function will be applied in order to sum up each row of matrix a 8 rs i j 1 n a ij j 1 n l ij j 1 n m ij j 1 n u ij i 1 n using the normalized version of equation 8 the fuzzy synthetic extent values for each ith object will be achieved roodposhti et al 2014 9 s i j n a ij h k 1 n j 1 n a kj 1 j 1 n l ij k 1 n j 1 n u kj j 1 n m ij k 1 n j 1 n m kj j 1 n u ij k 1 n j 1 n l kj i 1 n next through equation 10 the degree of possibility of s i s j is computed 10 v s i s j 1 i f m i m j u i l j u i m i m j l j l j u i i j 1 n j i 0 o t h e r s where s i l i m i u i and s j l j m j u j l e t w a i min v s i s k k 1 2 n k i then the weight vector value is determined as following 12 w a i w a 1 w a 2 w a n t where ai i 1 2 n are n elements the equation 13 is used after the normalization process when the weight vectors are computed 13 w a i w a 1 w a 2 w a n t where w is a non fuzzy number 4 4 multilayer perceptron mlp mlp is a very popular artificial neural network being characterized by one way error propagation of the feed forward network model li et al 2019 time series prediction pattern recognition and so forth can be solved using mlp the mlp structure contains an input layer a hidden layer and an output layer ke et al 2021 each layer s connections to the input and hidden layers and its connections to the output layers will be processed according to the weight values li et al 2019 the back propagation method is involved in the update process of the weight values liu et al 2021b zare et al 2013 two stages can be distinguished when this procedure is performed i input and output values are propagated through hidden layers and the output values are compared with pre values to determine the difference between them ii the connection weights are adjusted in order to achieve the most performant results with the minimum difference repeated iteratively the procedure is continued until a root mean square error of the network is within acceptable limits in the present study the input neurons in the input layer are represented by flash flood predictors while the output neurons in the output layer are represented by the torrential and non torrential surfaces the optimal number of hidden neurons will be established according to the minimum rmse value eq 14 14 rmse 1 n i 1 n c i c i 2 where n represents the date number ci are the measured data and ĉi the calculated values 4 5 naïve bayes nb based on bayes theorem naïve bayes presumes that the dependencies among the predictor attributes do not exists jiang et al 2016 the wide use of nb is due to the fact that it does not require a large volume of training data or a complex workflow for building classification models tien bui et al 2012 by using the ahp values assigned to each category of flash flood predictors from the training sample the nb was involved in the estimation of flash flood within the research zone if we consider 2 vectors the first assigned to each predictor having ahp coefficients computed g g1 g2 g10 and the second which corresponds to the presence and absence of torrential zones f f1 f2 the classification using nb algorithm is based on the next mathematical relation 15 t nb argmax p t i t i torrential no torrential i 1 n p f i t i where p ti is equal to the ti prior probability which can be computed using the proportion of the observed cases and the output class ti within the training sample moreover the conditional probability value is calculated using the next equation tien bui et al 2012 16 p f i t i 1 2 π δ e f i μ 2 2 δ 2 where μ represents the mean and δ is equal to the xi standard deviation weka v 3 9 software was involved for the application of nb model 4 6 results validation 4 6 1 statistical metrics the following indices were involved in the results validation process sensitivity specificity kappa index f1 score accuracy and precision statistical indices are significant if they show a correlation from the spatial point of view between the torrential and non torrential locations that were observed and the estimated flash flood susceptible zone costache 2019 the next relations will be applied for statistical metrics derivation canbek et al 2017 17 s e n s i t i v i t y t p t p f n 18 s p e c i f i c i t y t n f p t n 19 p r e c i s i o n t p t p f p 20 a c c u r a c y t p t n t p f p t n f n 21 k p o p e 1 p e where p represents the equivalent number of locations with torrential phenomenon n represents the equivalent number of non torrential pixels fp false positive and fn false negative represents the equivalent number of locations erroneously classified k is kappa coefficient po is the observed torrential locations and pe is equal to the estimated flash flood susceptibility value 4 6 2 roc curve in statistics receiver operating characteristic roc curves are used to determine the predictive value of different statistical or machine learning techniques costache et al 2019 zhang et al 2020 a roc curve is constructed by displaying sensitivity on the y axis and false positive rate 1 specificity on the x axis area under curve auc is the essential measure for the model s performance estimated through roc curve the closer auc to 1 the better the models performance hosseini et al 2020 the following mathematical relationship can be involved for auc computation 22 a u c t p t n p n the entire workflow is schematically represented in fig 4 5 results 5 1 feature selection and correlation analysis following the application of the relieff method for feature selection the following results were achieved slope angle 0 74 land use 0 56 convergence index 0 43 hydrological soil groups 0 35 tpi 0 32 plan curvature 0 29 profile curvature 0 24 aspect 0 09 fig 5 by analyzing the achieved results it can be concluded that all the factors are able to influence the flash flood phenomena and therefore all of them will be included in the future workflow to avoid the redundant information among the 8 flash flood predictors the correlation matrix in r software was constructed it reveals that the highest degree of correlation take place between profile curvature and convergence index with a value of correlation coefficient equal to 0 327 fig 6 the fig 6 shows that in four cases the correlation coefficient is equal to 0 thus it can be seen that no serious correlation is detected between the input variables and so as all of them will be involved in the computational workflow 5 2 ahp coefficients table 1 shows the pair wise comparison between all the classes or categories of flash flood predictors according to the outcomes of ahp method the profile curvature class was between 2 2 and 0 achieved the highest ahp coefficient 0 633 being followed by plan curvature class between 0 1 and 0 1 ahp 0 512 slope angle class between 23 8 and 40 1 ahp 0 507 convergence index class between 96 and 3 ahp 0 485 the lowest values of ahp were achieved by flat surface derived from aspect predictor ahp 0 034 slope angle between 0 and 7 4 ahp 0 035 and forest surfaces ahp 0 04 the judgment consistency for each matrix was assessed through consistency ratio cr table 2 given the fact that all values of cr are below to 0 1 all the comparison within the matrices are consistent 5 3 flash flood susceptibility computation 5 3 1 fuzzy ahp using the fuzzy ahp method the first step to determine the flash flood susceptibility was to create in microsoft excel a fuzzy pair wise comparison matrix table 3 thus in this matrix all 8 flash flood predictors were included and compared according to their importance in the flash flood genesis based on the results in the comparison matrix the following equation was used to determine the synthesis values 24 k 1 n j 1 n a kj 1 164 74 217 617 275 783 1 0 0036 0 0046 0 006 these results were then used to calculate fuzzy numbers that could be assigned to each flash flood predictor in the next step the degree of possibility process was applied based on the fuzzy number table 4 next the weight of each flash flood predictor was calculated with the following equations 25 w a i 0 54 0 43 0 49 0 09 0 1 0 0 061 t 26 w a i 0 19 0 155 0 175 0 033 0 0 354 0 0 061 t in addition the defuzzification process allows tfns to be converted into crisp weights that are applied to each flash flood conditioning factor and subsequently multiplied by ahp values to create the ffsifahp fig 10a the value of ffsifahp range from 0 07 to 0 48 the natural breaks method was utilized to classify the flash flood susceptibility values having the very low class between 0 07 and 0 19 characterized by a percentage of 18 32 fig 9a the low class is situated between 0 2 and 0 25 having a percentage of 31 59 while the moderate class between 0 26 and 0 3 occupies a percentage of 32 41 the high and very high susceptibility values above 0 31 is spread on 17 68 5 3 2 dlnn ahp the dlnn ahp model was trained in r environment with the help of tools available in h2o package the optimum architecture was reached by estimating the loss and accuracy values by after the application of total number of epochs equal to 100 according to the results the maximum accuracy of 0 95 was obtained after 89 epochs while the minimum value of loss 0 042 was reached after 95 epochs the uniform kernel was used as initializer function while relu was involved as activation function the batch size was set to 100 validation rate to 0 2 while the dropout rate to 0 1 thus the optimal architecture of ahp dlnn is formed by 8 input neurons 3 hidden layers with a maximum of 64 neurons and 2 output neurons represented by the presence or absence of torrential pixels fig 7 finally the functionalities of h2o r package in terms of deep learning neural networks algorithm allow to derive the following importance values for each variable slope angle 0 206 plan curvature 0 114 hydrological soil group 0 114 land use 0 088 convergence index 0 122 profile curvature 0 179 topographic position index 0 111 and aspect 0 066 these values were used to derive in map algebra the ffsiahp dlnn within the study zone fig 9b using the natural breaks classification method the ffsiahp dlnn values were divided into 5 classes the very low class has a percentage of 13 16 and values from 0 09 and 0 19 the low class with a percentage of 29 12 is situated in the range from 0 2 to 0 23 the moderate susceptibility is spread on 22 7 while the high and very high values account 35 01 of the study zone 5 3 3 mlp ahp the architecture of mlp ahp model used in the present research was established according the lowest value achieved by rmse thus the lowest rmse equal to 0 013 was achieved with a hidden layer containing 14 hidden neurons fig 8 a moreover the pseudoprobability plot exposed in fig 8b confirm that the torrential and non torrential pixels were correct classified because the majority of values represented on the left side in blue and right side in green are situated over the 0 5 of y axis the gain chart fig 8c and lift chart fig 8d prove also the high degree of performance obtained through mlp ahp model the spss software permitted the possibility to derive the values of each flash flood predictor importance in the mlp ahp ensemble as following slope angle 0 538 topographic position index 0 109 convergence index 0 096 plan curvature 0 093 hydrological soil group 0 055 aspect 0 052 profile curvature 0 035 and land use 0 022 the factor importance was used to compute the ffsimlp ahp fig 9c again natural breaks algorithm was used to split the susceptibility values into 5 classes the very low values between 0 06 and 0 16 span on 31 32 of the study zone while the low class is spread on 39 09 and is characterized by values from 0 17 to 0 22 moderate flash flood susceptibility is characteristic for a percentage of 20 35 of the total territory while another 9 25 has a high and very high susceptibility 5 3 4 nb ahp using training data and a 10 fold cross validation algorithm in the weka 3 9 environment the nb ahp model was built the cross validation procedure is designed to minimize over fitting and reduce data variability as much as possible based on the training process the maximum accuracy reached was 0 926 while the k index was 0 74 the most important factor was the slope angle 0 427 followed by plan curvature 0 112 topographic position index 0 098 hydrological soil group 0 092 convergence index 0 078 profile curvature 0 066 aspect 0 065 and land use 0 062 table 5 like in the previous cases natural breaks method helped to split the susceptibility values into 5 classes the very low values between 0 07 and 0 16 are spread on 17 44 of the research area while the low class spans on 35 5 and has values between 0 17 and 0 2 moderate flash flood susceptibility is characteristic for a percentage of 23 21 of the total territory while another 23 85 has a high and very high susceptibility fig 9d 5 4 validation and comparison of the models the results validation part was accomplished using the roc curve and a number of 4 statistical metrics 5 4 1 analysis of statistical metrics basically the use of training dataset highlights the following values for the accuracy metric the highest value was assigned to dlnn ahp 0 968 followed by nb ahp 0 942 mlp ahp 0 885 and fahp 0 84 table 6 the use of validating sample showed that the best accuracy was associated to dlnn ahp 0 97 followed by nb ahp 0 955 mlp ahp 0 848 and fahp 0 803 5 4 2 analysis of the roc curve in terms of roc curves the success rate was constructed with the help of training sample while the prediction rate was designed by taking into consideration the validating dataset the highest auc of success rate shows was registered by the dlnn ahp model 0 971 on the second place being nb ahp 0 945 followed by mlp ahp 0 888 and fahp 0 836 fig 10a the prediction rate shows the same hierarchy as follows dlnn ahp model 0 984 nb ahp 0 976 mlp ahp 0 882 and fahp 0 807 fig 10b since the auc values were above 0 8 we can state that all applied algorithms have a good performance 6 discussions one of the areas highly affected by flash floods hazards on the european continent is the romanian mountain region romanescu et al 2017 within which is situated also the present research area in light of the predicted increase in heavy rain frequency alfieri et al 2018 it is crucial to detect promptly areas exposed to flash flood hazards within the suha river catchment in order to achieve very high precise results the mechanisms of flash floods must be understood and state of the art techniques must be used to evaluate the flash flood susceptibility to determine which surfaces are prone to rapid surface runoff we developed four models based on machine learning techniques fuzzy multicriteria decision making and their ensemble to model the ffsi values from the spatial point of view in the last 10 years many papers brewster 2010 kruzdlo and ceru 2010 tincu et al 2018 zaharia et al 2015 zaharia et al 2012 aimed to evaluate flash flood susceptibility using the method proposed by smith 2003 however the aforementioned studies did not include any methodological considerations regarding surface runoff in the past and or a statistical approach to determining flash flood susceptibility within their methodological workflow past studies were also subject to a large degree of subjectivity due to the simple overlapping of flash flood predictors in gis software nonetheless the training process for the 4 models applied in this paper made use of many flash flood predictors that have been studied in previous papers based on the results of all the models slope angle was the most significant factor it has been established in many of the past research works that slope angle has a major influence on runoff genesis and manifestation borga et al 2011 chakrabortty et al 2021 elmahdy et al 2020 this is explained by the fact that the slope angle affects the surface runoff velocity which determines how flash floods behave fontanine and costache 2013 this affirmation is in total agreement with the outputs of the feature selection process that was applied in the present research and which showed that the slope angle has the highest correlation among all the flash flood predictors with the previous torrential phenomena land use and convergence index are another 2 flash flood predictors that resulted to be highly correlated with the historical torrential processes on the reliability of the models it becomes evident that the dlnn ahp ensemble provided the best results while fahp was the least reliable in line with tehrany et al 2015 findings multicriteria decision making analysis algorithms like fahp have some disadvantages because this category of methods relies on expert knowledge without considering the location of the previous areas affected by that hazard furthermore the results of the present study show that the deep learning neural network due to its complex structure with many hidden layers which are able for an input data deep processing outperforms the multilayer perceptron with only one hidden layer and also the other three ensemble models used in this research thus the statistical metrics involved in the results validation procedure highlights an accuracy of 0 97 for dlnn ahp comparing to the lowest accuracy of 0 803 that belongs to the fahp model the same difference is also highlighted by the prediction rate of roc curve where the auc of dlnn ahp was 0 984 meanwhile the auc of fahp was 0 807 the very high precision of dlnn model in terms of flash flood susceptibility prediction was also certified in the study carried out by bui et al 2020a b in the lao cai province of vietnam where this algorithm reached an accuracy of 0 94 also in the same study the auc roc curve of dlnn equal to 0 96 exceeded the auc roc curve of mlp that was equal to 0 926 also in another study done on the same topic by pham et al 2021b in quang nam province of vietnam deep learning neural network algorithm reached an accuracy maximum value of 0 961 and exceeded the performance of the other models like logistic regression accuracy 0 954 artificial neural network radial basis function accuracy 0 954 logistic model tree accuracy 0 954 and alternating decision tree accuracy 0 958 therefore we can state that the dlnn is a very high performant model that is capable to provide highly accurate results in terms of flood and flash flood susceptibility prediction 7 conclusions the current study aimed to propose new 3 hybrid algorithms and fuzzy ahp method to estimate the flash flood susceptibility within the suha river basin in each of the hybrid models pixels associated with torrential areas were used alongside eight flash flood predictors as input data as a result of the application of the relieff method all eight flash flood conditioning factors are reliable and should be incorporated into the analysis by evaluating the results with roc curve all the models achieved good to very good performance as indicated by area under the curve auc values above 0 807 furthermore the accuracy values of over 0 803 indicate the models robustness over 9 25 of the research zone is covered by surfaces with high and high flash flood susceptibility which are uniformly distributed within the suha basin in this study there is a significant novelty in that the 3 ensemble models dlnn ahp mlp ahp and nb ahp and h2o r package are used for the first time to predict whether a region is vulnerable to flash flood phenomena the results obtained in this study which have very good accuracy can be used with a high degree of confidence by the authorities responsible for the mitigation of flash flood negative effects as in any study in which geospatial data is used a limitation of this study may be the errors that may occur in the spatial representation of the data therefore it should be noted that the focus of the future study will be to obtain data with higher resolution and accuracy and to use them in studies on estimating susceptibility to flash floods funding this work was supported by a grant of the romanian ministry of education and research cncs uefiscdi project number pn iii p1 1 1 pd 2019 0424 p within pncdi iii credit authorship contribution statement romulus costache conceptualization methodology software validation formal analysis investigation resources data curation writing original draft writing review editing visualization supervision funding acquisition tran trung tin conceptualization visualization funding acquisition alireza arabameri methodology formal analysis investigation writing review editing supervision anca crăciun r s ajin methodology formal analysis investigation writing review editing supervision iulia costache methodology software validation formal analysis investigation resources data curation writing original draft writing review editing supervision abu reza md towfiqul islam data curation writing original draft s i abba methodology data curation mehebub sahana conceptualization methodology mohammadtaghi avand software validation resources data curation writing original draft binh thai pham conceptualization software validation resources data curation writing original draft visualization funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
3413,storage of water within soil pores of the root zone introduce memory effects in the dynamics of soil moisture that are considerably longer than the integral timescale of many atmospheric processes thus hydro climatic states can be sustained through land surface heat and water vapor fluxes primarily because they can feed off on this long term soil moisture memory root zone soil moisture memory is only but one feature characterizing the spectrum of soil moisture dynamics which is analyzed here using a combination of long term measurements and models in particular the spectrum of root zone soil moisture content in a mediterranean ecosystem is examined using 14 years of half hourly measurements a distinguishing hydro climatic feature in such ecosystems is that sources mainly rainfall and sinks mainly evapotranspiration of soil moisture are roughly out of phase with each other for over 4 decades of time scales and 7 decades of energy the canonical shape of the measured soil moisture spectrum is shown to be approximately lorentzian determined by the soil moisture variance and its memory but with two exceptions the occurrences of a peak at diurnal to daily time scales and a weaker peak at near annual time scales model calculations and spectral analysis demonstrate that diurnal and seasonal variations in hydroclimate forcing responsible for variability in evapotranspiration had minor impact on the normalized shape of the soil moisture spectrum however their impact was captured by adjustments in the temporal variance these findings indicate that precipitation and not evapotranspiration variability dominates the multi scaling properties of soil moisture variability consistent with prior climate model simulations furthermore the soil moisture memory inferred by the annual peak of soil moisture 340 d is consistent with climate model simulations while the memory evaluated from the loss function of a linearized mass balance approach leads to a smaller value 50 d highlighting the effect of weak non stationarity on soil moisture variability keywords ecohydrology lorentzian spectrum mediterranean ecosystems root zone soil moisture 1 introduction while root zone soil water is less than 0 001 of water on earth shiklamonov 1993 it affects a plethora of mass and energy exchange processes relevant to climate science ecohydrology crop production and numerous ecosystem services seneviratne et al 2010 schwingshackl et al 2017 zhou et al 2019 on short time scales i e hourly to sub daily root zone soil moisture content hereafter labeled as θ influences the partitioning of net radiation into latent le and sensible h heat fluxes that in turn affect the dynamics of the atmospheric boundary layer depth shukla and mintz 1982 koster et al 2000 siqueira et al 2009 koster et al 2004 seneviratne et al 2010 van den hurk et al 2012 schwingshackl et al 2017 haghighi et al 2018 ardilouze et al 2020 on longer time scales days to months storage of water in the root zone introduces memory that modifies hydro climatic conditions impacting cloud formation and rainfall p wet soil moisture states when they persist for an extended period of time can alter air relative humidity to higher values and vapor pressure deficit to lower values in the overlying atmosphere thereby altering the lifting condensation level cloud formation and rainfall thus wet soil moisture states that persist in time for an extended period compared to hydro climatic variability allows atmospheric processes to feed off this wet root zone soil moisture state eliciting a positive feedback on the atmosphere meaning pushing boundary layer processes towards preferential states that then favor rainfall thereby increasing the root zone soil moisture for these reasons the investigation of θ variability at multiple time scales and its connection with atmospheric processes at different time scales is necessary for quantifying and modelling climatic hydrological and ecological processes wang et al 2006 seneviratne et al 2010 several studies assessed the key role of the root zone soil moisture variability on hydrological ecological and climate models and demonstrated how the model results are sensitive to the variability in the root zone soil moisture content at different time scales detto et al 2006 wang et al 2006 lozano parra et al 2018 van oorschot et al 2021 konings et al 2021 the interactive effect between θ and p has been found to be stronger in areas where soil moisture temporal variability is enhanced such as in arid and semi arid regions delworth and manabe 1988 srivastava et al 2021 and in transitional regions between dry and wet climate koster and suarez 1995 seneviratne et al 2010 mccoll et al 2017 for this reason variability in θ at multiple time scales continues to draw attention in climate science and hydrology delworth and manabe 1988 oglesby et al 2002 pan et al 2001 huang et al 1996 yeh et al 1984 mintz and serafini 1992 dong et al 2007 albertson and montaldo 2003 dirmeyer 2011 koster et al 2004 seneviratne et al 2010 mccoll et al 2017 and frames the scope of the work here in practice multi scale variability in measured or modeled θ time series is quantified using the spectrum of soil moisture e θ f that satisfies the normalizing property 1 σ θ 2 0 e θ f df where f is the frequency or inverse time scale and σ θ 2 is the temporal soil moisture variance at the global scale e θ f was already derived from general circulation models gcm and often compared to a red noise process i e e θ f f 2 delworth and manabe 1988 nakai et al 2014 at much longer time scales e θ f is primarily forced by p and snow melt and dampened by evapotranspirational et and drainage losses from the root zone under certain conditions such as white noise spectrum for p and with et losses scaling linearly with θ e θ f attains a lorentzian shape given by delworth and manabe 1988 katul et al 2007 nakai et al 2014 ghannam et al 2016 2 e θ f 2 σ θ 2 β π 1 β 2 f 2 where β is related to the 1 e 0 37 folding time as well as soil moisture memory γ which is the time needed for a soil column to forget its wet conditions when induced by a rainfall event delworth and manabe 1988 koster and suarez 1995 ghannam et al 2016 the lorentzian spectrum converges to red noise when f β 1 and to white noise i e e θ f f 0 when f β 1 halley 1996 at f β fe θ f σ θ 2 1 π as well as d fe f df 0 implying that fe f is a maximum for this reason the so called pre multiplied spectrum fe θ f can be used to operationally infer soil moisture memory from β viewed from this perspective the memory timescale becomes a rough measure of the time needed by the root zone soil column to forget an imposed anomaly such as a rainfall event or lack thereof as discussed elsewhere ghannam et al 2016 typical gcm derived e θ f have been shown to follow a lorentzian shape see fig 1 but with decrease in β as latitude increases moving beyond large scale latitudinal variations a number of studies have demonstrated that e θ f is controlled by p and its seasonal dynamics soil hydraulic properties and vegetation cover koster and suarez 2001 wei et al 2006 dong et al 2007 katul et al 2007 nakai et al 2014 ghannam et al 2016 in general e θ f or its fourier pair the autocovariance function encodes the soil moisture memory γ entin et al 2000 nakai et al 2014 ghannam et al 2016 for a lorentzian spectrum that is derived from a finite time series of θ γ may be determined empirically from the frequency at which fe θ f attains its maximum in this case f β as earlier noted when drainage losses from the root zone are small compared to the maximum et et max an estimate of β et max η d r can also be derived katul et al 2007 nakai et al 2014 ghannam et al 2016 where η is the soil porosity within the rooting zone and d r is the root zone depth for an et max 5 mm d 1 d r 0 5 m and η 0 5 the modeled γ β 1 50 d and is much longer than the time scales representing hydroclimatic variability hours to few days this long time scales 50 days enables atmospheric processes to feed off from persistent root zone soil moisture states thereby experiencing an alteration in their own states through feedback mechanisms that are beginning to be uncovered delworth and manabe 1988 vinnikov et al 1996 koster and suarez 2001 seneviratne and koster 2012 nicolai shaw et al 2016 ghannam et al 2016 the memory of soil moisture due to its connection with soil hydraulic properties martínez fernández et al 2021 katul et al 2007 is spatially dependent and it is found to be higher in dry than wet areas katul et al 2007 ghannam et al 2016 martínez fernández et al 2021 a number of other studies have also shown links between e θ f and persistence which represents the probability that the soil moisture remains in a dry condition over a certain time period ghannam et al 2016 for these reasons the ability of climate and hydrological models to reproduce e θ f across a wide range of f and across spatial scales is becoming a necessity pan et al 1995 delworth and manabe 1988 huang et al 1996 yeh et al 1984 mintz 1982 dong et al 2007 koster et al 2004 seneviratne et al 2010 western et al 2002 mccoll et al 2017 zhu et al 2020 some studies evaluated soil moisture variations produced by gcms or regional land surface models using a network of extended in situ soil moisture observations guo and dirmeyer 2006 xia et al 2015 yuan and quiring 2017 knist et al 2017 by and large these studies conclude that soil moisture variability is reasonably represented by climate models when seasonal soil moisture patterns are adequately captured however large deviations between measured and modeled soil moisture was reported in transitional climatic areas yuan and quiring 2017 knist et al 2017 a case in point is the mediterranean region where climatic and vegetation cover variations impact and are impacted by soil moisture knist et al 2017 quintana seguí et al 2020 the mediterranean region experiences high soil moisture variability and has been identified as a climatic area with strong coupling between the atmosphere and the land surface seneviratne et al 2010 knist et al 2017 hertig et al 2019 mimeau et al 2021 such strong coupling between soil moisture variability vegetation cover changes tree grass bare soil and hydroclimatic conditions where p and air temperature t a are seasonally out of phase with each other offers a dynamically interesting test case for assessing the controls on e θ f and motivate the present work the spectral properties of measured e θ f sampled in a typical mediterranean ecosystem and shown in fig 1 is considered the main science question to be addressed is this what hydroclimatic and hydrologic factors dictate the shape of e θ f a particular focus is dedicated to the scaling laws of e θ f with f the dominant modes of variability and γ more specifically we seek to uncover signatures in e θ f of key hydroclimatic factors and land surface cover transformation between tree grass and tree bare soil configurations the data used to generate the spectrum in fig 1 were collected in orroli sardinia where half hourly measured soil moisture content p et and all the key terms in the energy balance have been collected for 14 years starting in 2003 as described elsewhere montaldo et al 2008 montaldo et al 2013 montaldo et al 2020 a land surface model lsm that accounts for dynamic vegetation through a biomass budget and all the hydrometeorological and energy balance considerations impacting the water budget is also employed to interpret mechanistically the measured e θ f and the expected controls on it 2 materials and methods 2 1 experimental site the orroli field site is a mediterranean natural ecosystem located in east central sardinia 39 41 12 57 n 9 16 30 34 e 500 m a s l detto et al 2006 detto et al 2008 montaldo et al 2008 montaldo et al 2013 the climate is maritime mediterranean with mean annual p 1922 2017 of 643 mm but characterized by dry summers 11 mm in july the mean annual air temperature t a is 14 6 c mean t a of 23 7 c in july the landscape is a mixture of woody vegetation and grass on a shallow 15 40 cm thick silt loam soil 19 sand 76 silt 5 clay bulk density of 1 38 g cm 3 and η 53 the soil depth above a fractured rocky layer ranges between 10 50 cm averaging 17 cm 6 cm standard deviation sd the rooting depth d r for all practical purposes is not constrained vertically by an optimizing between carbon investment below ground versus root water and nutrient uptake to the contrary the entire soil above the fractured rock layer is populated by roots grass trees or both for this reason the mean soil depth is assumed to represent the mean d r however the presence of cracks soil pockets with some water content were qualitatively estimated from observed electrical resistivity maps and shown to partially contribute to et corona and montaldo 2020 montaldo et al 2020 more recently the root zone depth for grass and trees has been evaluated separately based on root observation trenches each trench was 7 m long and 0 2 m wide extending to the underlying rock montaldo et al 2021 the depth of the root zone for the grass species was found to range from 1 cm to 20 cm but this depth is limited by the presence of fractured rock the roots and their distribution is mainly horizontal in this zone the root zone for trees is about 20 cm on average and again mostly limited by the fractured rock layer interestingly some tree roots penetrating vertically into the fractured rock were also confirmed by these observation trenches montaldo et al 2021 the dominant wild olive trees are distributed in patches forming a canopy covering 3 3 of the footprint area associated with the eddy covariance flux measurements 1 5 km2 the surrounding inter clump areas are covered by herbaceous and grass species during high moisture periods becoming dry bare soil during the drier periods of summer as described elsewhere detto et al 2006 detto et al 2008 montaldo et al 2008 montaldo et al 2013 corona and montaldo 2020 2 2 soil moisture and micrometeorological measurements seven frequency domain reflectometer probes fdr model cs 616 campbell scientific instruments logan utah were inserted in the soil close to the tower 3 3 5 5 m away to measure soil moisture in the shallow root zone layer the cs 616 probes are 30 cm in length and can measure soil moisture when positioned at any probe orientation the installation and calibration of the fdr sensors are detailed elsewhere montaldo et al 2020 montaldo et al 2021 and are not repeated here the presence of fractured rocks and reduced soil depth required the installation of most of the soil moisture sensors tilted from the sought vertical alignment soil moisture time series were then vertically averaged after conducting a fourier transformation on the soil moisture time series the phase angle was computed and shown to be in phase with precipitation time series on short time scales or high frequency but opposite at very long time scales or low frequency as discussed elsewhere katul et al 2007 we have also conducted a separate spectral analysis on the time series of soil moisture content for probes inserted in grass dominated areas and probes under trees the analysis revealed no appreciable differences in spectral shapes supplementary material fig s1 for this reason we averaged all probes together and treated them as an ensemble averaged time series in the ensuing analysis meteorological measurements were made with conventional instruments installed on a 10 m tower since may 2003 a licor 7500 co2 h2o infrared gas analyzer licor lincoln nebraska was used for measuring high frequency 10 hz co 2 and h 2 o concentration whereas a campbell scientific csat 3 sonic anemometer was used for measuring the 3 components of the velocity these high frequency measurements were used to estimate half hourly et h and net ecosystem carbon dioxide exchange nee using the eddy covariance method brutsaert 2013 garratt 1992 baldocchi 2003 measurements of incoming and outgoing short wave and long wave radiation were used to derive net radiation r n and surface temperature t s the t a air relative humidity soil heat flux and precipitation p were also measured at half hourly time step the complete list of variables instruments and their heights and data post processing are described elsewhere montaldo et al 2020 the fraction of vegetation cover and its distribution over the site was estimated from a multispectral high spatial resolution 2 8 m satellite image digitalglobe inc based on a supervised classification scheme montaldo et al 2008 data analyzed here cover the period between 10 may 2003 and 3 august 2017 2 3 spectral analysis in fourier analysis the determination of e θ f from time series of soil moisture used the welch averaged modified periodogram method here the time series of spatially averaged soil moisture is first divided into 7 overlapping sections in time then a hamming or cosine window is applied with zero padding to enable the implementation of fast fourier transforms because of the presence of gaps and their potential impact on the scaling laws an alternative spectral representation was also employed based on orthonormal wavelet transformation owt for the wavelet spectra the owt coefficients were computed using a fast wavelet transform algorithm utilizing a dyadic arrangement across scales the haar basis function was used to determine these wavelet coefficients in the wavelet half plane as discussed elsewhere foufoula georgiou and kumar 1994 kumar and foufoula georgiou 1993 lee and yamamoto 1994 katul et al 2001 stoy et al 2005 the haar wavelet was chosen because it is among the most localized basis functions in time and thus optimal for detecting gaps in time series but not in frequency contrary to the fourier basis thus the fourier and haar owt represent the two extremes of locality and continuity in the time frequency domain the owt spectrum was computed at each dyadic scale by averaging the squared wavelet coefficients across time katul and parlange 1994 due to the locality of the haar wavelet in the time domain the owt spectrum was determined for a gap filled and gap infected time series with coefficients associated with gaps excluded when averaging the squared wavelet coefficients across scales for ease of comparisons of spectra across different variables all variables are first normalized to zero mean and unit variance when assessing the effect of gaps in the time series 2 4 the land surface model lsm a land surface model lsm that has been calibrated and tested for the site montaldo et al 2008 was used to estimate the dynamics of water and energy fluxes on a half hour time step model evaluation and performance are discussed elsewhere montaldo and oren 2022 and the results of the statistical test of model performance are given in table 3 in the aforementioned study the model represents soil moisture from the root zone as a reservoir that supplies the bare soil and vegetation the root zone soil moisture also regulates the infiltration and runoff mechanisms the root zone depth represents the lower boundary for the lsm where the soil hydraulic properties dictate drainage losses the surface temperature and the energy balance equations for sensible heat flux ground heat flux and the net radiation were all solved using an approach similar to the force restore method noilhan and planton 1989 the hydraulic properties including the soil water characteristic curve and hydraulic conductivity function are specified for a silty soil using standard power law relations with volumetric soil moisture clapp and hornberger 1978 the lsm is used for two purposes i as a tool to define the factors that exert control on e θ f above and beyond throughfall i and ii to gap fill et and θ in the computations of e θ f in the fourier and wavelet domains the model was also used in the owt wavelet spectral comparisons between gap infected and gap filled θ series the lsm was run with five different configurations for which the seasonal and yearly variability of t a incoming shortwave radiation r swin wind velocity wsp leaf area index lai for both vegetation species and vapor pressure deficit vpd were individually arrested these variables all impact et the primary loss term in the soil water hydrological balance each model configuration assumes a constant value for each of the aforementioned four variables the value changes every year and set to the averaged mean value of the variable the list of the five model configurations hereafter indicated as c1 c2 c3 c4 and c5 are summarized below c1 constant mean air temperature c2 constant incident shortwave radiation c3 constant mean wind speed c4 constant mean vapor pressure deficit c5 constant leaf area index set to long term mean value 2 5 a linearized model for e θ f the five scenarios in the previous section are contrasted with a simplified hydrologic only model predicting the shape of e θ f in this simplified model the soil water balance for the root zone is considered and is given by 3 d θ t d t 1 d r i t e bs e g e wv q d where i t is the throughfall rate infiltrating into the soil surface e bs is bare soil evaporation e g and e wv are transpiration rates of grass and woody vegetation respectively and q d is the drainage flux set at d r since q d is small relative to the other hydrological fluxes it is ignored when analyzing the controls on e θ f defining the overall loss as l a 1 e wv a 2 e g a 3 e bs with a 1 a 2 a 3 1 a 1 a 2 and a 3 are the fraction of trees grass and bare soil cover and upon naively assuming l scales linearly with θ the simplified hydrological balance for the root zone soil moisture can be expressed as 4 η d r d s t d t i t s t l max where s t θ η d r 1 is the degree of saturation s t 0 1 a model for e s f can now be analytically derived for this budget when multiplying eq 4 by e ift with i 2 1 integrating with respect to t to determine the fourier coefficients of soil moisture in relation to the fourier coefficients of throughfall and then computing e s f from the squared fourier amplitudes to yield 5 e s f e ni f β l 2 f 2 where e ni f is the spectrum of normalized throughfall i t η d r 1 that is related but not identical to rainfall due to variations in lai and need not be white noise β l l max η d r 1 is the inverse of memory and f 0 the throughfall rates infiltrating into the soil covered by vegetation is modeled through a balance equation of the intercepted water by the canopy reservoir its capacity is a function of the lai which produces throughfall when the reservoir is saturated as described elsewhere noilhan and planton 1989 this spectrum is considered as a reference given that the variability in hydrometeorological drivers and vegetation dynamics considered in c1 c5 are non existent in this formulation the only external driver affecting the soil moisture spectrum in eq 5 is temporal variability in i thus this spectrum is contrasted with the spectrum derived from the calibrated lsm approach as well as those computed from cases c1 c5 applied to the lsm that capture all the complex time dependent interactions between hydroclimatic variables dynamic vegetation and non linear relation between losses from the root zone and soil moisture 2 6 data gap filling the soil moisture long term dataset invariably includes gaps resulting from electrical power loss or instrument failure gaps were more frequent during winter 18 of total because reduced incoming solar radiation limited the recharge of batteries that power the entire system missing data of p were replaced with observations from a nearby rain gauge station in nurri located 4 km from the orroli site missing t a and other hydroclimatic variables were replaced with measurements from a nearby weather station in mandas 10 km from the orroli site montaldo et al 2021 gaps in θ and et were replaced with a corresponding land surface model lsm predictions calibrated for the site and later described spectral analysis was conducted in fourier local in frequency but not in time and haar wavelet domains as noted earlier the former is much better suited for detecting precise frequencies where e θ f may be large whereas the latter is better suited for a gap infected time series characterized by pulses katul et al 2001 stoy et al 2005 a preliminary analysis demonstrated that the owt spectra of hydrometeorological variables including gaps and gap filled series did not show significant differences at all time scales considered 3 results fig 1c repeats prior gcm derived e θ f delworth and manabe 1988 for four different latitudinal bands equatorial subtropical mid latitude and high latitude there is a clear increase in redness in the gcm derived e θ f with the increase in latitude the frequency where e θ f transitions from white to a finite exponent also shifts when moving towards the highest latitudes time scales of 200 d for equatorial and subtropical and 780 d for mid latitude and high latitude bands for the mediterranean region studied here the e θ f is computed at higher temporal resolution and exhibit clear peaks at daily sub daily and annual time scale 341 d as shown in fig 1a at frequencies exceeding 100 days not resolved in the gcm derived e θ f e θ f exhibits an approximate power law i e e θ f f α with an exponent close to α 2 near the sampling frequency range or time scales 0 1 d the measured spectrum resembles white noise likely due to random errors in fdr soil moisture measurements including electronics detection of reflected energy content etc the fdr can measure soil moisture at higher sampling frequencies when compared to time domain reflectometry but the signal to noise ratio is lower the spectrum of measured soil moisture is also compared with the lorentzian shape predicted from eq 2 with β determined empirically from the frequency at which fe θ f fig 1b reaches its maximum 1 f 1 β 341 d the main features of the measured soil moisture spectrum are reasonably described by such lorentzian shape but not the peaks at diurnal to daily and near annual for the low frequencies e θ f some deviations from constant white noise are expected due to the seasonality of i t common to mediterranean climates however the record here is not sufficiently long to ascertain the precise spectral shape at decadal time scales though the gcm runs suggest near white spectra at time scales exceeding 104 d for all regions nonetheless the measured spectral peak here appear to be in line with gcm runs it is longer than equatorial and sub tropical regions but shorter than mid and high latitude regions reported in fig 1c returning to the hydro climate forcing the monthly incident shortwave radiation and mean air temperature show the same pattern i e they are in phase the highest monthly values occur during the summer months fig 2 a and b precipitation and soil moisture time series are roughly in phase with each other but out of phase with incident shortwave radiation and air temperature the lowest p and θ occur during the driest months of the year june july and august fig 2c and d the decrease in θ begins in the month of may due to the increase in air temperature along with et fig 2f and reduced p soil moisture increases again in september with the increasing frequency of precipitation events the vpd is in phase with p and θ fig 2e and it is for this reason that its variability is highest during the summer when both precipitation and soil moisture are low interestingly monthly variations of et which is the main loss from the rooting zone in the hydrological balance is not precisely in phase or out of phase with any of the hydro climatic drivers or soil moisture in fig 2f this finding confirms the role of land cover switches on et variability but as shown later less so on the normalized spectrum of θ the normalized spectra of vpd et θ and the meteorological variables r swin t a p in fig 3 have been estimated for the gap infected top and gap removed middle time series using the orthonormal wavelet transform fig 3a and fig 3b respectively and applying the fourier analyses for the gap removed time series fig 3c the normalized haar wavelet power spectra of θ the meteorological variables r swin t a p and et show the same pattern except for p and θ for both the gap infected fig 3c and the gap removed time series fig 3b no significance difference were found comparing the spectra in fig 3a and fig 3b while the energy distribution among time scales is most distributed for p when compared to other hydro climatic variables p is clearly not a white noise process the meteorological variables and et all exhibit common features for the time occurrence of spectral peaks which are localized at daily and annual time scales there is a difference in the power magnitude at daily time scales where rswin and et are three order of magnitude higher than the θ spectrum and almost one order of magnitude higher than t a p and vpd spectrum fig 3b considering that the owt spectra of hydrometeorological variables for gap removed series did not significantly differ from gap infected spectra fig 3a and fig 3b respectively the gap removed series are used with the fourier approach fig 3c given its superior localization in the frequency domain even if the fourier approach detects the spectral variability of all hydrometeorological variables better than the owt the differences with the owt spectra in fig 3b are not as relevant to the spectral exponents the spectra of θ for both fourier and owt methodologies for gap removed time series violet line and thick black line respectively fig 3d show some reduced variance compared with the spectra for gap infected time series thick red line fig 3d but the overall shape is not modified the soil moisture time series estimated with the five runs of the lsm allowed evaluating the effect of censoring the seasonal and yearly variability of t a r swin w sp vpd and lai c1 c2 c3 c4 c5 configurations respectively on the modeled normalized soil moisture spectra e θ m f fig 4 a and fig 4b for each model configuration the owt normalized spectra of e θ f does not show any significant difference with that of the calibrated lsm that includes all the hydrometeorological variability fig 4a the estimated e θ m f with fourier analysis shows the same behaviour for all the model configurations with peaks localized at the seasonal daily and sub daily time scales as was in owt analysis nevertheless the modeled soil moisture time series are different from each other supplementary material fig s2a however this difference to a leading order is not in the shape of the spectrum but in the area under the actual spectrum i e the soil moisture variance the normalized relative differences between the variances of the e θ m f estimated with the calibrated model and obtained for c1 and c5 configurations is about 11 and 7 respectively supplementary material fig s2b at high frequencies the behaviour of normalized e θ f is the same for all model configurations suggesting the absence of any appreciable hydrometeorological and vegetation dynamic effect on the soil moisture spectrum fig 4a and fig 4b beyond i this finding is in line with e θ being controlled by variability in p and soil moisture memory instead of the hydrometeorological controls on et the normalized spectra of p and modeled i from p and lai unsurprisingly have the same behaviour fig 4c and show a spectral decay reasonably described by a power law i e e p f f α the exponent α 0 3 at 1 to 10 day time scales but increases to α 0 75 at sub daily or storm time scale for convective storms α 1 whereas for frontal systems α 0 5 molini et al 2009 hence an α 0 75 at sub daily time scales here resides in between these two storm types the normalized spectrum of soil moisture content e s f given by the linear model of eq 5 is compared with the measured spectrum of θ estimate with the owt and fourier approaches in fig 5 a and in fig 5b respectively the linear model predicts a spectral decay of θ that is characterized by two scaling regimes e s f f α as expected the exponent α is equal to 2 3 at 1 to 10 day time scales while it is α 2 75 for the lowest frequencies however measured e θ f appears to be described by a single power law with α 2 for all the frequencies between 1 and 10 days and differently than the linear model it shows peaks at daily sub daily and seasonal time scales the owt transform limits the presence of noise at the high frequency and its shape is also well represented by a single power law i e e p f f α with α 2 fig 5a than what is obtained with the fourier methodology fig 5b the owt cannot resolve energy at precise frequencies e g diurnal and daily time scales because of the dyadic arrangement in scale decomposition and its non locality in the frequency domain these are some the reasons why the owt spectrum reveals a single α 2 for the soil moisture spectrum without bumps on diurnal and daily time scales to be clear differences in the normalized spectral estimates between fourier and haar based owt methods including scaling exponents are to be expected the two approaches decompose the time series using different basis functions and processing algorithms e g boundary conditions at edges tapering and windowing dyadic arrangements etc for finite and multi scaled time series such as the ones analyzed here we wish to emphasize that there is no correct or true spectrum and the only necessary condition for the scale wise decomposition fourier or haar based owt is conservation of spectral energy when summed across all frequencies both transformations fourier and haar based owt satisfy this condition i e parseval s identity 4 discussion and conclusions the connection between the soil moisture state and atmospheric processes at different scales has made the investigation of θ variability a necessity for quantifying and modelling climatic hydrological and ecological processes in this study a 14 year soil moisture time series record collected at a mediterranean site provided an opportunity to investigate variability in soil moisture at multiple time scales ranging from hours to more than a decade a unique feature of this data set is that measured precipitation main source of soil moisture and eddy covariance measured et main sink of soil moisture are roughly but not precisely out of phase with each other the spectrum of measured θ evaluated with fourier analysis showed spectral peaks at diurnal to daily and close to annual time scales 341 d beyond those peaks e θ f attains a near lorentzian shape analogous to what was computed by gcms fig 2c delworth and manabe 1988 katul et al 2007 nakai et al 2014 ghannam et al 2016 but with some differences unlike the gcm spectra the measured spectrum of θ here does not attain a well defined constant value independent of frequency at low frequencies 1 year though longer records are needed to reliably resolve this issue that the measured soil moisture spectrum appears reasonably approximated by a near lorentzian shape perturbed by two well defined peaks may lead to the conclusion that a linearized mass balance analysis driven by rainfall only suffices to explain the key drivers of e θ f partial support for this conclusion stems from the fact that variability in the key hydrometeorological variables fig 2 had minor impact on the shape of the normalized θ variability and rainfall variability remains the most influential factor explaining the shape of the normalized soil moisture spectrum koster and suarez 2001 wei et al 2006 dong et al 2007 katul et al 2007 nakai et al 2014 indeed the use of a linear model for e θ f i e eq 5 where the variability of external drivers are not included but only the spectrum of modeled throughfall is used recovers both the overall features of the measured spectrum of soil moisture as well as those obtained from a detailed land surface formulation that accommodates variability in hydrometeorological drivers and land cover type however this conclusion is premature and naive on 2 accounts the memory inferred from the measured peak of the pre multiplied lorentzian spectrum 340 d appears commensurate with expected interpolated values from gcms for such a mediterranean climate the memory inferred from the loss function of the linearized mass balance approach leading to a lorentzian spectrum where eddy covariance measured et and root zone depth are used lead to a much smaller value 50 d this finding points to the fact that weak non stationarity or low frequency modes introduce appreciable shifts in soil memory by a factor of 7 here moreover the scaling laws at high frequency do not strictly abide by predictions from the linearized mass balance analysis at sub daily time scale the spectrum of rainfall exhibits a scaling law commensurate with f 0 75 hence the linearized mass balance analysis predicts that the spectrum of soil moisture scales as f 2 75 the exponent estimate here from the measured soil moisture spectrum remains consistent with an f 2 moving to time scales commensurate with 10 days the precipitation spectrum scales as f 0 3 and thus the predicted soil moisture spectral scaling exponent from linearized mass balance analysis is f 2 3 once again the measured soil moisture spectrum maintains its approximate f 2 range for those time scales these deviations between measured and modeled soil moisture fourier spectra suggest that during summer months trees may be withdrawing water from much deeper layers and this withdrawal generates an effective root zone depth that can exceed the assumed root zone depth here constrained by soil depth above the fractured rock layer an increase in the effective root zone depth increases the memory predicted from the linearized mass balance γ η d r et max there is already partial evidence that trees are withdrawing water from well below the assumed rooting zone during summer months as noted earlier here and in prior studies corona and montaldo 2020 montaldo et al 2021 this analysis ignores the more significant effect that such a withdrawal can also be non stationary i e d r fluctuates at low frequency whether the non stationarity in d r alone is sufficient to shift the soil moisture memory by a factor of 7 alone remains unclear and requires targeted experiments hence differences in the two soil moisture memory estimates here peak in the spectrum and γ η d r et max point to an under appreciated role of a vertically dynamic root water extraction in addition we speculate that the relation between measured rainfall and measured increases in spatially averaged stored water during rainfall is noisy supplementary fig s3a and b pointing to some randomization effect in both time and space if so this randomization implies that short term correlations in rainfall described by the rainfall spectral exponent are partially destroyed by throughfall and subsequent infiltration process as detected by increases in stored water in individual fdr probes during rainfall this conjectured randomization may explain why the measured soil moisture spectral exponent remains close to f 2 red noise and not f 2 3 to f 2 8 black noise as predicted from the fourier transformed linear hydrological balance at short to intermediate time scales at least for the probe locations analyzed here again the role of throughfall appears to play a role in shaping the normalized soil moisture spectral exponent from sub daily to monthly time scales not withstanding these issues it is clear that deviations between measured and modeled spectra offer a new perspective about two eco hydrological processes specifically intermittent extraction of water by deep roots i e memory deviations on long time scales and the role of randomness in infiltration destroying rainfall memory within the root zone at short to intermediate time scales warrant directed explorations in the future declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments rc and nm acknowledge support by the ministry of education university and research miur through the altos european project of prima med cup n f24d19000020006 the swatch european project of the prima med program cup n f24d19000010006 and the fluxmed european project of the water jpi program cup n f24d19000030001 gk acknowledges support from the u s national science foundation nsf ags 2028633 nsf ios 1754893 and the department of energy de sc0022072 we also acknowledge riccardo piras for his support in data analysis finally we thank the meteoclimatic department of arpa sardegna for providing the meteorological data and the sardinian water authority enas for supporting the eddy covariance tower installation and maintenance appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2022 127757 supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 
3413,storage of water within soil pores of the root zone introduce memory effects in the dynamics of soil moisture that are considerably longer than the integral timescale of many atmospheric processes thus hydro climatic states can be sustained through land surface heat and water vapor fluxes primarily because they can feed off on this long term soil moisture memory root zone soil moisture memory is only but one feature characterizing the spectrum of soil moisture dynamics which is analyzed here using a combination of long term measurements and models in particular the spectrum of root zone soil moisture content in a mediterranean ecosystem is examined using 14 years of half hourly measurements a distinguishing hydro climatic feature in such ecosystems is that sources mainly rainfall and sinks mainly evapotranspiration of soil moisture are roughly out of phase with each other for over 4 decades of time scales and 7 decades of energy the canonical shape of the measured soil moisture spectrum is shown to be approximately lorentzian determined by the soil moisture variance and its memory but with two exceptions the occurrences of a peak at diurnal to daily time scales and a weaker peak at near annual time scales model calculations and spectral analysis demonstrate that diurnal and seasonal variations in hydroclimate forcing responsible for variability in evapotranspiration had minor impact on the normalized shape of the soil moisture spectrum however their impact was captured by adjustments in the temporal variance these findings indicate that precipitation and not evapotranspiration variability dominates the multi scaling properties of soil moisture variability consistent with prior climate model simulations furthermore the soil moisture memory inferred by the annual peak of soil moisture 340 d is consistent with climate model simulations while the memory evaluated from the loss function of a linearized mass balance approach leads to a smaller value 50 d highlighting the effect of weak non stationarity on soil moisture variability keywords ecohydrology lorentzian spectrum mediterranean ecosystems root zone soil moisture 1 introduction while root zone soil water is less than 0 001 of water on earth shiklamonov 1993 it affects a plethora of mass and energy exchange processes relevant to climate science ecohydrology crop production and numerous ecosystem services seneviratne et al 2010 schwingshackl et al 2017 zhou et al 2019 on short time scales i e hourly to sub daily root zone soil moisture content hereafter labeled as θ influences the partitioning of net radiation into latent le and sensible h heat fluxes that in turn affect the dynamics of the atmospheric boundary layer depth shukla and mintz 1982 koster et al 2000 siqueira et al 2009 koster et al 2004 seneviratne et al 2010 van den hurk et al 2012 schwingshackl et al 2017 haghighi et al 2018 ardilouze et al 2020 on longer time scales days to months storage of water in the root zone introduces memory that modifies hydro climatic conditions impacting cloud formation and rainfall p wet soil moisture states when they persist for an extended period of time can alter air relative humidity to higher values and vapor pressure deficit to lower values in the overlying atmosphere thereby altering the lifting condensation level cloud formation and rainfall thus wet soil moisture states that persist in time for an extended period compared to hydro climatic variability allows atmospheric processes to feed off this wet root zone soil moisture state eliciting a positive feedback on the atmosphere meaning pushing boundary layer processes towards preferential states that then favor rainfall thereby increasing the root zone soil moisture for these reasons the investigation of θ variability at multiple time scales and its connection with atmospheric processes at different time scales is necessary for quantifying and modelling climatic hydrological and ecological processes wang et al 2006 seneviratne et al 2010 several studies assessed the key role of the root zone soil moisture variability on hydrological ecological and climate models and demonstrated how the model results are sensitive to the variability in the root zone soil moisture content at different time scales detto et al 2006 wang et al 2006 lozano parra et al 2018 van oorschot et al 2021 konings et al 2021 the interactive effect between θ and p has been found to be stronger in areas where soil moisture temporal variability is enhanced such as in arid and semi arid regions delworth and manabe 1988 srivastava et al 2021 and in transitional regions between dry and wet climate koster and suarez 1995 seneviratne et al 2010 mccoll et al 2017 for this reason variability in θ at multiple time scales continues to draw attention in climate science and hydrology delworth and manabe 1988 oglesby et al 2002 pan et al 2001 huang et al 1996 yeh et al 1984 mintz and serafini 1992 dong et al 2007 albertson and montaldo 2003 dirmeyer 2011 koster et al 2004 seneviratne et al 2010 mccoll et al 2017 and frames the scope of the work here in practice multi scale variability in measured or modeled θ time series is quantified using the spectrum of soil moisture e θ f that satisfies the normalizing property 1 σ θ 2 0 e θ f df where f is the frequency or inverse time scale and σ θ 2 is the temporal soil moisture variance at the global scale e θ f was already derived from general circulation models gcm and often compared to a red noise process i e e θ f f 2 delworth and manabe 1988 nakai et al 2014 at much longer time scales e θ f is primarily forced by p and snow melt and dampened by evapotranspirational et and drainage losses from the root zone under certain conditions such as white noise spectrum for p and with et losses scaling linearly with θ e θ f attains a lorentzian shape given by delworth and manabe 1988 katul et al 2007 nakai et al 2014 ghannam et al 2016 2 e θ f 2 σ θ 2 β π 1 β 2 f 2 where β is related to the 1 e 0 37 folding time as well as soil moisture memory γ which is the time needed for a soil column to forget its wet conditions when induced by a rainfall event delworth and manabe 1988 koster and suarez 1995 ghannam et al 2016 the lorentzian spectrum converges to red noise when f β 1 and to white noise i e e θ f f 0 when f β 1 halley 1996 at f β fe θ f σ θ 2 1 π as well as d fe f df 0 implying that fe f is a maximum for this reason the so called pre multiplied spectrum fe θ f can be used to operationally infer soil moisture memory from β viewed from this perspective the memory timescale becomes a rough measure of the time needed by the root zone soil column to forget an imposed anomaly such as a rainfall event or lack thereof as discussed elsewhere ghannam et al 2016 typical gcm derived e θ f have been shown to follow a lorentzian shape see fig 1 but with decrease in β as latitude increases moving beyond large scale latitudinal variations a number of studies have demonstrated that e θ f is controlled by p and its seasonal dynamics soil hydraulic properties and vegetation cover koster and suarez 2001 wei et al 2006 dong et al 2007 katul et al 2007 nakai et al 2014 ghannam et al 2016 in general e θ f or its fourier pair the autocovariance function encodes the soil moisture memory γ entin et al 2000 nakai et al 2014 ghannam et al 2016 for a lorentzian spectrum that is derived from a finite time series of θ γ may be determined empirically from the frequency at which fe θ f attains its maximum in this case f β as earlier noted when drainage losses from the root zone are small compared to the maximum et et max an estimate of β et max η d r can also be derived katul et al 2007 nakai et al 2014 ghannam et al 2016 where η is the soil porosity within the rooting zone and d r is the root zone depth for an et max 5 mm d 1 d r 0 5 m and η 0 5 the modeled γ β 1 50 d and is much longer than the time scales representing hydroclimatic variability hours to few days this long time scales 50 days enables atmospheric processes to feed off from persistent root zone soil moisture states thereby experiencing an alteration in their own states through feedback mechanisms that are beginning to be uncovered delworth and manabe 1988 vinnikov et al 1996 koster and suarez 2001 seneviratne and koster 2012 nicolai shaw et al 2016 ghannam et al 2016 the memory of soil moisture due to its connection with soil hydraulic properties martínez fernández et al 2021 katul et al 2007 is spatially dependent and it is found to be higher in dry than wet areas katul et al 2007 ghannam et al 2016 martínez fernández et al 2021 a number of other studies have also shown links between e θ f and persistence which represents the probability that the soil moisture remains in a dry condition over a certain time period ghannam et al 2016 for these reasons the ability of climate and hydrological models to reproduce e θ f across a wide range of f and across spatial scales is becoming a necessity pan et al 1995 delworth and manabe 1988 huang et al 1996 yeh et al 1984 mintz 1982 dong et al 2007 koster et al 2004 seneviratne et al 2010 western et al 2002 mccoll et al 2017 zhu et al 2020 some studies evaluated soil moisture variations produced by gcms or regional land surface models using a network of extended in situ soil moisture observations guo and dirmeyer 2006 xia et al 2015 yuan and quiring 2017 knist et al 2017 by and large these studies conclude that soil moisture variability is reasonably represented by climate models when seasonal soil moisture patterns are adequately captured however large deviations between measured and modeled soil moisture was reported in transitional climatic areas yuan and quiring 2017 knist et al 2017 a case in point is the mediterranean region where climatic and vegetation cover variations impact and are impacted by soil moisture knist et al 2017 quintana seguí et al 2020 the mediterranean region experiences high soil moisture variability and has been identified as a climatic area with strong coupling between the atmosphere and the land surface seneviratne et al 2010 knist et al 2017 hertig et al 2019 mimeau et al 2021 such strong coupling between soil moisture variability vegetation cover changes tree grass bare soil and hydroclimatic conditions where p and air temperature t a are seasonally out of phase with each other offers a dynamically interesting test case for assessing the controls on e θ f and motivate the present work the spectral properties of measured e θ f sampled in a typical mediterranean ecosystem and shown in fig 1 is considered the main science question to be addressed is this what hydroclimatic and hydrologic factors dictate the shape of e θ f a particular focus is dedicated to the scaling laws of e θ f with f the dominant modes of variability and γ more specifically we seek to uncover signatures in e θ f of key hydroclimatic factors and land surface cover transformation between tree grass and tree bare soil configurations the data used to generate the spectrum in fig 1 were collected in orroli sardinia where half hourly measured soil moisture content p et and all the key terms in the energy balance have been collected for 14 years starting in 2003 as described elsewhere montaldo et al 2008 montaldo et al 2013 montaldo et al 2020 a land surface model lsm that accounts for dynamic vegetation through a biomass budget and all the hydrometeorological and energy balance considerations impacting the water budget is also employed to interpret mechanistically the measured e θ f and the expected controls on it 2 materials and methods 2 1 experimental site the orroli field site is a mediterranean natural ecosystem located in east central sardinia 39 41 12 57 n 9 16 30 34 e 500 m a s l detto et al 2006 detto et al 2008 montaldo et al 2008 montaldo et al 2013 the climate is maritime mediterranean with mean annual p 1922 2017 of 643 mm but characterized by dry summers 11 mm in july the mean annual air temperature t a is 14 6 c mean t a of 23 7 c in july the landscape is a mixture of woody vegetation and grass on a shallow 15 40 cm thick silt loam soil 19 sand 76 silt 5 clay bulk density of 1 38 g cm 3 and η 53 the soil depth above a fractured rocky layer ranges between 10 50 cm averaging 17 cm 6 cm standard deviation sd the rooting depth d r for all practical purposes is not constrained vertically by an optimizing between carbon investment below ground versus root water and nutrient uptake to the contrary the entire soil above the fractured rock layer is populated by roots grass trees or both for this reason the mean soil depth is assumed to represent the mean d r however the presence of cracks soil pockets with some water content were qualitatively estimated from observed electrical resistivity maps and shown to partially contribute to et corona and montaldo 2020 montaldo et al 2020 more recently the root zone depth for grass and trees has been evaluated separately based on root observation trenches each trench was 7 m long and 0 2 m wide extending to the underlying rock montaldo et al 2021 the depth of the root zone for the grass species was found to range from 1 cm to 20 cm but this depth is limited by the presence of fractured rock the roots and their distribution is mainly horizontal in this zone the root zone for trees is about 20 cm on average and again mostly limited by the fractured rock layer interestingly some tree roots penetrating vertically into the fractured rock were also confirmed by these observation trenches montaldo et al 2021 the dominant wild olive trees are distributed in patches forming a canopy covering 3 3 of the footprint area associated with the eddy covariance flux measurements 1 5 km2 the surrounding inter clump areas are covered by herbaceous and grass species during high moisture periods becoming dry bare soil during the drier periods of summer as described elsewhere detto et al 2006 detto et al 2008 montaldo et al 2008 montaldo et al 2013 corona and montaldo 2020 2 2 soil moisture and micrometeorological measurements seven frequency domain reflectometer probes fdr model cs 616 campbell scientific instruments logan utah were inserted in the soil close to the tower 3 3 5 5 m away to measure soil moisture in the shallow root zone layer the cs 616 probes are 30 cm in length and can measure soil moisture when positioned at any probe orientation the installation and calibration of the fdr sensors are detailed elsewhere montaldo et al 2020 montaldo et al 2021 and are not repeated here the presence of fractured rocks and reduced soil depth required the installation of most of the soil moisture sensors tilted from the sought vertical alignment soil moisture time series were then vertically averaged after conducting a fourier transformation on the soil moisture time series the phase angle was computed and shown to be in phase with precipitation time series on short time scales or high frequency but opposite at very long time scales or low frequency as discussed elsewhere katul et al 2007 we have also conducted a separate spectral analysis on the time series of soil moisture content for probes inserted in grass dominated areas and probes under trees the analysis revealed no appreciable differences in spectral shapes supplementary material fig s1 for this reason we averaged all probes together and treated them as an ensemble averaged time series in the ensuing analysis meteorological measurements were made with conventional instruments installed on a 10 m tower since may 2003 a licor 7500 co2 h2o infrared gas analyzer licor lincoln nebraska was used for measuring high frequency 10 hz co 2 and h 2 o concentration whereas a campbell scientific csat 3 sonic anemometer was used for measuring the 3 components of the velocity these high frequency measurements were used to estimate half hourly et h and net ecosystem carbon dioxide exchange nee using the eddy covariance method brutsaert 2013 garratt 1992 baldocchi 2003 measurements of incoming and outgoing short wave and long wave radiation were used to derive net radiation r n and surface temperature t s the t a air relative humidity soil heat flux and precipitation p were also measured at half hourly time step the complete list of variables instruments and their heights and data post processing are described elsewhere montaldo et al 2020 the fraction of vegetation cover and its distribution over the site was estimated from a multispectral high spatial resolution 2 8 m satellite image digitalglobe inc based on a supervised classification scheme montaldo et al 2008 data analyzed here cover the period between 10 may 2003 and 3 august 2017 2 3 spectral analysis in fourier analysis the determination of e θ f from time series of soil moisture used the welch averaged modified periodogram method here the time series of spatially averaged soil moisture is first divided into 7 overlapping sections in time then a hamming or cosine window is applied with zero padding to enable the implementation of fast fourier transforms because of the presence of gaps and their potential impact on the scaling laws an alternative spectral representation was also employed based on orthonormal wavelet transformation owt for the wavelet spectra the owt coefficients were computed using a fast wavelet transform algorithm utilizing a dyadic arrangement across scales the haar basis function was used to determine these wavelet coefficients in the wavelet half plane as discussed elsewhere foufoula georgiou and kumar 1994 kumar and foufoula georgiou 1993 lee and yamamoto 1994 katul et al 2001 stoy et al 2005 the haar wavelet was chosen because it is among the most localized basis functions in time and thus optimal for detecting gaps in time series but not in frequency contrary to the fourier basis thus the fourier and haar owt represent the two extremes of locality and continuity in the time frequency domain the owt spectrum was computed at each dyadic scale by averaging the squared wavelet coefficients across time katul and parlange 1994 due to the locality of the haar wavelet in the time domain the owt spectrum was determined for a gap filled and gap infected time series with coefficients associated with gaps excluded when averaging the squared wavelet coefficients across scales for ease of comparisons of spectra across different variables all variables are first normalized to zero mean and unit variance when assessing the effect of gaps in the time series 2 4 the land surface model lsm a land surface model lsm that has been calibrated and tested for the site montaldo et al 2008 was used to estimate the dynamics of water and energy fluxes on a half hour time step model evaluation and performance are discussed elsewhere montaldo and oren 2022 and the results of the statistical test of model performance are given in table 3 in the aforementioned study the model represents soil moisture from the root zone as a reservoir that supplies the bare soil and vegetation the root zone soil moisture also regulates the infiltration and runoff mechanisms the root zone depth represents the lower boundary for the lsm where the soil hydraulic properties dictate drainage losses the surface temperature and the energy balance equations for sensible heat flux ground heat flux and the net radiation were all solved using an approach similar to the force restore method noilhan and planton 1989 the hydraulic properties including the soil water characteristic curve and hydraulic conductivity function are specified for a silty soil using standard power law relations with volumetric soil moisture clapp and hornberger 1978 the lsm is used for two purposes i as a tool to define the factors that exert control on e θ f above and beyond throughfall i and ii to gap fill et and θ in the computations of e θ f in the fourier and wavelet domains the model was also used in the owt wavelet spectral comparisons between gap infected and gap filled θ series the lsm was run with five different configurations for which the seasonal and yearly variability of t a incoming shortwave radiation r swin wind velocity wsp leaf area index lai for both vegetation species and vapor pressure deficit vpd were individually arrested these variables all impact et the primary loss term in the soil water hydrological balance each model configuration assumes a constant value for each of the aforementioned four variables the value changes every year and set to the averaged mean value of the variable the list of the five model configurations hereafter indicated as c1 c2 c3 c4 and c5 are summarized below c1 constant mean air temperature c2 constant incident shortwave radiation c3 constant mean wind speed c4 constant mean vapor pressure deficit c5 constant leaf area index set to long term mean value 2 5 a linearized model for e θ f the five scenarios in the previous section are contrasted with a simplified hydrologic only model predicting the shape of e θ f in this simplified model the soil water balance for the root zone is considered and is given by 3 d θ t d t 1 d r i t e bs e g e wv q d where i t is the throughfall rate infiltrating into the soil surface e bs is bare soil evaporation e g and e wv are transpiration rates of grass and woody vegetation respectively and q d is the drainage flux set at d r since q d is small relative to the other hydrological fluxes it is ignored when analyzing the controls on e θ f defining the overall loss as l a 1 e wv a 2 e g a 3 e bs with a 1 a 2 a 3 1 a 1 a 2 and a 3 are the fraction of trees grass and bare soil cover and upon naively assuming l scales linearly with θ the simplified hydrological balance for the root zone soil moisture can be expressed as 4 η d r d s t d t i t s t l max where s t θ η d r 1 is the degree of saturation s t 0 1 a model for e s f can now be analytically derived for this budget when multiplying eq 4 by e ift with i 2 1 integrating with respect to t to determine the fourier coefficients of soil moisture in relation to the fourier coefficients of throughfall and then computing e s f from the squared fourier amplitudes to yield 5 e s f e ni f β l 2 f 2 where e ni f is the spectrum of normalized throughfall i t η d r 1 that is related but not identical to rainfall due to variations in lai and need not be white noise β l l max η d r 1 is the inverse of memory and f 0 the throughfall rates infiltrating into the soil covered by vegetation is modeled through a balance equation of the intercepted water by the canopy reservoir its capacity is a function of the lai which produces throughfall when the reservoir is saturated as described elsewhere noilhan and planton 1989 this spectrum is considered as a reference given that the variability in hydrometeorological drivers and vegetation dynamics considered in c1 c5 are non existent in this formulation the only external driver affecting the soil moisture spectrum in eq 5 is temporal variability in i thus this spectrum is contrasted with the spectrum derived from the calibrated lsm approach as well as those computed from cases c1 c5 applied to the lsm that capture all the complex time dependent interactions between hydroclimatic variables dynamic vegetation and non linear relation between losses from the root zone and soil moisture 2 6 data gap filling the soil moisture long term dataset invariably includes gaps resulting from electrical power loss or instrument failure gaps were more frequent during winter 18 of total because reduced incoming solar radiation limited the recharge of batteries that power the entire system missing data of p were replaced with observations from a nearby rain gauge station in nurri located 4 km from the orroli site missing t a and other hydroclimatic variables were replaced with measurements from a nearby weather station in mandas 10 km from the orroli site montaldo et al 2021 gaps in θ and et were replaced with a corresponding land surface model lsm predictions calibrated for the site and later described spectral analysis was conducted in fourier local in frequency but not in time and haar wavelet domains as noted earlier the former is much better suited for detecting precise frequencies where e θ f may be large whereas the latter is better suited for a gap infected time series characterized by pulses katul et al 2001 stoy et al 2005 a preliminary analysis demonstrated that the owt spectra of hydrometeorological variables including gaps and gap filled series did not show significant differences at all time scales considered 3 results fig 1c repeats prior gcm derived e θ f delworth and manabe 1988 for four different latitudinal bands equatorial subtropical mid latitude and high latitude there is a clear increase in redness in the gcm derived e θ f with the increase in latitude the frequency where e θ f transitions from white to a finite exponent also shifts when moving towards the highest latitudes time scales of 200 d for equatorial and subtropical and 780 d for mid latitude and high latitude bands for the mediterranean region studied here the e θ f is computed at higher temporal resolution and exhibit clear peaks at daily sub daily and annual time scale 341 d as shown in fig 1a at frequencies exceeding 100 days not resolved in the gcm derived e θ f e θ f exhibits an approximate power law i e e θ f f α with an exponent close to α 2 near the sampling frequency range or time scales 0 1 d the measured spectrum resembles white noise likely due to random errors in fdr soil moisture measurements including electronics detection of reflected energy content etc the fdr can measure soil moisture at higher sampling frequencies when compared to time domain reflectometry but the signal to noise ratio is lower the spectrum of measured soil moisture is also compared with the lorentzian shape predicted from eq 2 with β determined empirically from the frequency at which fe θ f fig 1b reaches its maximum 1 f 1 β 341 d the main features of the measured soil moisture spectrum are reasonably described by such lorentzian shape but not the peaks at diurnal to daily and near annual for the low frequencies e θ f some deviations from constant white noise are expected due to the seasonality of i t common to mediterranean climates however the record here is not sufficiently long to ascertain the precise spectral shape at decadal time scales though the gcm runs suggest near white spectra at time scales exceeding 104 d for all regions nonetheless the measured spectral peak here appear to be in line with gcm runs it is longer than equatorial and sub tropical regions but shorter than mid and high latitude regions reported in fig 1c returning to the hydro climate forcing the monthly incident shortwave radiation and mean air temperature show the same pattern i e they are in phase the highest monthly values occur during the summer months fig 2 a and b precipitation and soil moisture time series are roughly in phase with each other but out of phase with incident shortwave radiation and air temperature the lowest p and θ occur during the driest months of the year june july and august fig 2c and d the decrease in θ begins in the month of may due to the increase in air temperature along with et fig 2f and reduced p soil moisture increases again in september with the increasing frequency of precipitation events the vpd is in phase with p and θ fig 2e and it is for this reason that its variability is highest during the summer when both precipitation and soil moisture are low interestingly monthly variations of et which is the main loss from the rooting zone in the hydrological balance is not precisely in phase or out of phase with any of the hydro climatic drivers or soil moisture in fig 2f this finding confirms the role of land cover switches on et variability but as shown later less so on the normalized spectrum of θ the normalized spectra of vpd et θ and the meteorological variables r swin t a p in fig 3 have been estimated for the gap infected top and gap removed middle time series using the orthonormal wavelet transform fig 3a and fig 3b respectively and applying the fourier analyses for the gap removed time series fig 3c the normalized haar wavelet power spectra of θ the meteorological variables r swin t a p and et show the same pattern except for p and θ for both the gap infected fig 3c and the gap removed time series fig 3b no significance difference were found comparing the spectra in fig 3a and fig 3b while the energy distribution among time scales is most distributed for p when compared to other hydro climatic variables p is clearly not a white noise process the meteorological variables and et all exhibit common features for the time occurrence of spectral peaks which are localized at daily and annual time scales there is a difference in the power magnitude at daily time scales where rswin and et are three order of magnitude higher than the θ spectrum and almost one order of magnitude higher than t a p and vpd spectrum fig 3b considering that the owt spectra of hydrometeorological variables for gap removed series did not significantly differ from gap infected spectra fig 3a and fig 3b respectively the gap removed series are used with the fourier approach fig 3c given its superior localization in the frequency domain even if the fourier approach detects the spectral variability of all hydrometeorological variables better than the owt the differences with the owt spectra in fig 3b are not as relevant to the spectral exponents the spectra of θ for both fourier and owt methodologies for gap removed time series violet line and thick black line respectively fig 3d show some reduced variance compared with the spectra for gap infected time series thick red line fig 3d but the overall shape is not modified the soil moisture time series estimated with the five runs of the lsm allowed evaluating the effect of censoring the seasonal and yearly variability of t a r swin w sp vpd and lai c1 c2 c3 c4 c5 configurations respectively on the modeled normalized soil moisture spectra e θ m f fig 4 a and fig 4b for each model configuration the owt normalized spectra of e θ f does not show any significant difference with that of the calibrated lsm that includes all the hydrometeorological variability fig 4a the estimated e θ m f with fourier analysis shows the same behaviour for all the model configurations with peaks localized at the seasonal daily and sub daily time scales as was in owt analysis nevertheless the modeled soil moisture time series are different from each other supplementary material fig s2a however this difference to a leading order is not in the shape of the spectrum but in the area under the actual spectrum i e the soil moisture variance the normalized relative differences between the variances of the e θ m f estimated with the calibrated model and obtained for c1 and c5 configurations is about 11 and 7 respectively supplementary material fig s2b at high frequencies the behaviour of normalized e θ f is the same for all model configurations suggesting the absence of any appreciable hydrometeorological and vegetation dynamic effect on the soil moisture spectrum fig 4a and fig 4b beyond i this finding is in line with e θ being controlled by variability in p and soil moisture memory instead of the hydrometeorological controls on et the normalized spectra of p and modeled i from p and lai unsurprisingly have the same behaviour fig 4c and show a spectral decay reasonably described by a power law i e e p f f α the exponent α 0 3 at 1 to 10 day time scales but increases to α 0 75 at sub daily or storm time scale for convective storms α 1 whereas for frontal systems α 0 5 molini et al 2009 hence an α 0 75 at sub daily time scales here resides in between these two storm types the normalized spectrum of soil moisture content e s f given by the linear model of eq 5 is compared with the measured spectrum of θ estimate with the owt and fourier approaches in fig 5 a and in fig 5b respectively the linear model predicts a spectral decay of θ that is characterized by two scaling regimes e s f f α as expected the exponent α is equal to 2 3 at 1 to 10 day time scales while it is α 2 75 for the lowest frequencies however measured e θ f appears to be described by a single power law with α 2 for all the frequencies between 1 and 10 days and differently than the linear model it shows peaks at daily sub daily and seasonal time scales the owt transform limits the presence of noise at the high frequency and its shape is also well represented by a single power law i e e p f f α with α 2 fig 5a than what is obtained with the fourier methodology fig 5b the owt cannot resolve energy at precise frequencies e g diurnal and daily time scales because of the dyadic arrangement in scale decomposition and its non locality in the frequency domain these are some the reasons why the owt spectrum reveals a single α 2 for the soil moisture spectrum without bumps on diurnal and daily time scales to be clear differences in the normalized spectral estimates between fourier and haar based owt methods including scaling exponents are to be expected the two approaches decompose the time series using different basis functions and processing algorithms e g boundary conditions at edges tapering and windowing dyadic arrangements etc for finite and multi scaled time series such as the ones analyzed here we wish to emphasize that there is no correct or true spectrum and the only necessary condition for the scale wise decomposition fourier or haar based owt is conservation of spectral energy when summed across all frequencies both transformations fourier and haar based owt satisfy this condition i e parseval s identity 4 discussion and conclusions the connection between the soil moisture state and atmospheric processes at different scales has made the investigation of θ variability a necessity for quantifying and modelling climatic hydrological and ecological processes in this study a 14 year soil moisture time series record collected at a mediterranean site provided an opportunity to investigate variability in soil moisture at multiple time scales ranging from hours to more than a decade a unique feature of this data set is that measured precipitation main source of soil moisture and eddy covariance measured et main sink of soil moisture are roughly but not precisely out of phase with each other the spectrum of measured θ evaluated with fourier analysis showed spectral peaks at diurnal to daily and close to annual time scales 341 d beyond those peaks e θ f attains a near lorentzian shape analogous to what was computed by gcms fig 2c delworth and manabe 1988 katul et al 2007 nakai et al 2014 ghannam et al 2016 but with some differences unlike the gcm spectra the measured spectrum of θ here does not attain a well defined constant value independent of frequency at low frequencies 1 year though longer records are needed to reliably resolve this issue that the measured soil moisture spectrum appears reasonably approximated by a near lorentzian shape perturbed by two well defined peaks may lead to the conclusion that a linearized mass balance analysis driven by rainfall only suffices to explain the key drivers of e θ f partial support for this conclusion stems from the fact that variability in the key hydrometeorological variables fig 2 had minor impact on the shape of the normalized θ variability and rainfall variability remains the most influential factor explaining the shape of the normalized soil moisture spectrum koster and suarez 2001 wei et al 2006 dong et al 2007 katul et al 2007 nakai et al 2014 indeed the use of a linear model for e θ f i e eq 5 where the variability of external drivers are not included but only the spectrum of modeled throughfall is used recovers both the overall features of the measured spectrum of soil moisture as well as those obtained from a detailed land surface formulation that accommodates variability in hydrometeorological drivers and land cover type however this conclusion is premature and naive on 2 accounts the memory inferred from the measured peak of the pre multiplied lorentzian spectrum 340 d appears commensurate with expected interpolated values from gcms for such a mediterranean climate the memory inferred from the loss function of the linearized mass balance approach leading to a lorentzian spectrum where eddy covariance measured et and root zone depth are used lead to a much smaller value 50 d this finding points to the fact that weak non stationarity or low frequency modes introduce appreciable shifts in soil memory by a factor of 7 here moreover the scaling laws at high frequency do not strictly abide by predictions from the linearized mass balance analysis at sub daily time scale the spectrum of rainfall exhibits a scaling law commensurate with f 0 75 hence the linearized mass balance analysis predicts that the spectrum of soil moisture scales as f 2 75 the exponent estimate here from the measured soil moisture spectrum remains consistent with an f 2 moving to time scales commensurate with 10 days the precipitation spectrum scales as f 0 3 and thus the predicted soil moisture spectral scaling exponent from linearized mass balance analysis is f 2 3 once again the measured soil moisture spectrum maintains its approximate f 2 range for those time scales these deviations between measured and modeled soil moisture fourier spectra suggest that during summer months trees may be withdrawing water from much deeper layers and this withdrawal generates an effective root zone depth that can exceed the assumed root zone depth here constrained by soil depth above the fractured rock layer an increase in the effective root zone depth increases the memory predicted from the linearized mass balance γ η d r et max there is already partial evidence that trees are withdrawing water from well below the assumed rooting zone during summer months as noted earlier here and in prior studies corona and montaldo 2020 montaldo et al 2021 this analysis ignores the more significant effect that such a withdrawal can also be non stationary i e d r fluctuates at low frequency whether the non stationarity in d r alone is sufficient to shift the soil moisture memory by a factor of 7 alone remains unclear and requires targeted experiments hence differences in the two soil moisture memory estimates here peak in the spectrum and γ η d r et max point to an under appreciated role of a vertically dynamic root water extraction in addition we speculate that the relation between measured rainfall and measured increases in spatially averaged stored water during rainfall is noisy supplementary fig s3a and b pointing to some randomization effect in both time and space if so this randomization implies that short term correlations in rainfall described by the rainfall spectral exponent are partially destroyed by throughfall and subsequent infiltration process as detected by increases in stored water in individual fdr probes during rainfall this conjectured randomization may explain why the measured soil moisture spectral exponent remains close to f 2 red noise and not f 2 3 to f 2 8 black noise as predicted from the fourier transformed linear hydrological balance at short to intermediate time scales at least for the probe locations analyzed here again the role of throughfall appears to play a role in shaping the normalized soil moisture spectral exponent from sub daily to monthly time scales not withstanding these issues it is clear that deviations between measured and modeled spectra offer a new perspective about two eco hydrological processes specifically intermittent extraction of water by deep roots i e memory deviations on long time scales and the role of randomness in infiltration destroying rainfall memory within the root zone at short to intermediate time scales warrant directed explorations in the future declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments rc and nm acknowledge support by the ministry of education university and research miur through the altos european project of prima med cup n f24d19000020006 the swatch european project of the prima med program cup n f24d19000010006 and the fluxmed european project of the water jpi program cup n f24d19000030001 gk acknowledges support from the u s national science foundation nsf ags 2028633 nsf ios 1754893 and the department of energy de sc0022072 we also acknowledge riccardo piras for his support in data analysis finally we thank the meteoclimatic department of arpa sardegna for providing the meteorological data and the sardinian water authority enas for supporting the eddy covariance tower installation and maintenance appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2022 127757 supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 
3414,flood prediction across scales and more specifically in ungauged areas remains a great challenge that limits the efficiency of flood risk mitigation strategies and disaster preparedness building upon the recent success of machine learning ml models on streamflow prediction this work presents a prototype ml based framework for flood warning and flood peak prediction the fundamental elements of the proposed system consist of a a long short term memory lstm model for classifying storm events to flood no flood given a threshold based on the 90th flow percentile and b the flood peak prediction models the selected ml models for flood peak prediction are the histogram based gradient boosting regressor and the random forest one of the strengths and reason for selection of these decision tree models is their degree of interpretability this is exploited in the study to help us spatially disentangle the role of both the static and dynamic drivers of flood peak response our analysis is presented for 18 distinct hydroclimatic regions across the contiguous us results reveal a significant regional dependence on both predictive performance and dominant flood predictors which emphasize the variability in the complexity of a catchment s hydrologic behavior as well as its impact on forecasting flood response evaluation of the drivers of flood peaks noted distinct dependencies among the dynamic and static predictors considered in our models for flood peaks of different severity specifically low moderate flood events showed a clear preponderance for the static catchment attributes over dynamic predictors like precipitation whereas precipitation was the dominant driver for the highest flood peaks the proposed flood peak prediction models were compared against a state of the art lstm model and were shown to outperform in ungauged basins for the majority of basins overall the proposed system classified storms correctly for 80 in all cases and exhibited a percent relative difference in flood peak estimates of 30 in most cases keywords flood peak prediction machine learning ungauged basins flood warning 1 introduction to date floods are the most recurring and devastating natural hazard affecting the contiguous united states conus posing significant risk to lives and livelihoods dougherty and rasmussen 2019 knight 2010 perry 2000 flood impacts within conus alone are associated with a significant toll on human life and annual incurred costs of 6 2 billion usd for damages over the past decade ncei 2020 these are facts which enunciate the need to accurately predict flood events everywhere streamflow primarily in heavily and growing urbanized regions across conus has been increasing a trend noted for the last 50 years lins and slack 2005 in addition studies investigating the impacts of current and future climate extremes lins and slack 2005 milly et al 2002 indicate that the u s population is becoming alarmingly vulnerable to flood associated risks naz et al 2016 wing et al 2018 these trends are particular not only to conus but have been observed in other parts of the world including europe jarosińska and pierzga 2017 teuling et al 2019 central asia gulakhmadov et al 2020 and south america lara et al 2017 under various growth scenarios for future climate as prescribed by global climate models and despite local and regional scale complexities this continual upward intensification of median and high flows remains a consistent find in these studies the factors that lead to increase in peak flow are many arguably precipitation is the dominant driver controlling peak flow response prein et al 2017 seneviratne et al 2012 slater and villarini 2017 and there is virtually unanimous acknowledgement of current and future precipitation intensity patterns intensifying exceptions to precipitation controlling peak flow response do exist ivancic and shaw 2015 westra et al 2013 due to other atmospheric variables like temperature wasko and sharma 2017 or potential evapotranspiration mallakpour and villarini 2015 the argument regarding these exceptions continues that some other variables attributable to modulating extreme flood response hall et al 2014 merz et al 2012 include regional and catchment specific hydrogeomorphic parameters water management schemes national research council et al 2007 soil and hydraulic parameters as well as land cover changes ahn et al 2014 kim and kim 2020 tomer and schilling 2009 to name a few in unique cases we may see a specific factor controlling streamflow response but the interaction among any of the above drivers is what makes the prediction of flood peaks i e very high streamflow a complex process hrachowitz et al 2013 saghafian et al 2014 todini 2007 the ability to accurately predict streamflow across spatial scales has been an ongoing topic of research for several decades kratzert et al 2018 mosavi et al 2018 tara and paulin 2013 remesan and mathew 2014 slater and villarini 2017 among others indeed accounting for the complexity and nonlinear interactions of land surface properties with dynamic forcing precipitation temperature and state variables soil moisture to be able to accurately predict flood response still remains a challenging task traditional approaches to simulating streamflow or peak discharge have been centered around the development of empirical as well as physics based distributed hydrologic models decharme et al 2012 getirana et al 2012 ivanov et al 2004 lin et al 2018 wilson et al 2007 yamazaki et al 2012 we recommend the two review papers for references to further physics based conceptual rainfall runoff models tara and paulin 2013 todini 2007 the capability of accounting for spatial variability within a catchment and extensively informing on its hydrologic system are clear advantages of these approaches costabile and macchione 2015 in return the physics based models specifically require extensive computational resources and high resolution spatial data related to catchment attributes and initial boundary conditions samaniego et al 2010 for these reasons physics based models are shied away from for large sample studies and applications with the growing concern of flood hazards increasing not only in severity but also in frequency and large areas still being ungauged which poses a great limitation on parameterization of physics based models the hydrologic community has started investigating alternative models that has the potential to efficiently predict flood peaks especially for ungauged catchments such investigations led to the implementation of data driven models utilizing machine learning ml algorithms kratzert et al 2018 kratzert et al 2019 mosavi et al 2018 remesan and mathew 2014 xiang et al 2020 the potential for ml based approaches towards simulating streamflow among other hydrologic applications elshorbagy et al 2010 kasiviswanathan et al 2016 schoppa et al 2020 has been noted for well over a decade now but broader exploration was attempted only recently over the last few years the availability of large sample high resolution observed and simulated hydrometeorological datasets have enabled the analysis of various flood generation processes at the catchment scale along with their drivers ml based models alleviate the intensive computational resources required of physics based distributed models whilst maintaining the necessary design and processing complexity and predictive strength desired mosavi et al 2018 todini 2007 however accurate peak flow prediction remains challenging for example the lstm based neural network of kratzert et al 2018 requires vast meteorological historic data as input and is able to capture exceptionally well the signals of low to moderate level flows most recently kratzert et al 2019 has advanced the lstm model kratzert et al 2018 to a true ensemble based model that now incorporates a wide array of static catchment attributes aforementioned as the other drivers of peak flow response however accurate predictions of very high flow events remain challenging the devastating aftermath of missing these events has been outlined above which underlines the pressing need for improved prediction of such events for individual catchments the overarching goal of this study is to develop ml based models that a accurately predict flood peaks b are as less complex in terms of data demand as possible and c maintain a high degree of interpretability in contrast to the recent works published on the topic of ml based streamflow prediction where the target contains the prediction of the entire spectrum of streamflow values we develop a framework that is based on rainfall to flood peak events and focuses solely on the prediction of flood peaks i e single max flow value per rainfall runoff event our framework also includes an ml based classifier that separates storms into flood and no flood inducing events integration of those elements is proposed as an alternative framework for flood forecasting in ungauged basins en route to this goal we also seek to understand the dominant drivers of flood response and their dependence on hydroclimatic regime and flood severity the remainder of this paper is organized as follows the study area and key steps to pre process the data for peak flow analysis are described in section 2 the methodological framework which explores two approaches to developing models capable of predicting flood peaks in ungauged basins is detailed in section 3 section 4 presents the results of our ml based models for different hydroclimatic zones and flow severities and discusses inferences drawn related to drivers of flood response including the potential thereafter for advancing early warning systems on floods future directions for building on this research and the main conclusions follow in section 5 2 study area and data this study utilized the conus wide dataset catchment attributes and meteorology for large sample studies camels which contains data for approximately 670 catchments addor et al 2017 newman et al 2015 a study supported by the national center for atmospheric research it boasts a long record of daily streamflow data derived from united states geological services usgs from 1980 to 2014 with the same temporal horizon hydrometeorological forcing data are provided from daymet thornton et al 2012 nldas xia et al 2012 and maurer et al 2002 which includes precipitation temperature and vapor pressure to name a few additionally available are 30 static catchment attributes subdivided into hydrological climatic vegetative soil and topographical features see addor et al 2017 newman et al 2015 for details our study selected and utilized the daymet derived gridded estimates of daily weather parameters for these catchments across the 34 year record the main reason for our selection is based on newman et al 2015 who posited that daymet had overall better performance for modeling compared to maurer and nldas postulating the result likely related to the higher spatial resolution of daymet analysis was performed at a regional scale by clustering the catchments according to the regional watershed boundaries established by the usgs across conus there are 18 distinct hydroclimatic regions designated by their two digit hydrologic unit code huc 02 the spread of the 670 catchments within each region is shown in fig 1 the drainage areas of these catchments range from 3 km2 to 25 524 km2 with an average of 589 km2 2 1 pre processing from the foregoing discussion of our source dataset camels we have three main sections of data to pre process given our objectives our output at the end of preprocessing is a flood peak dataset that contains the data pertaining to all flood events we identify from the 670 catchments across conus see fig 1 these three main sections of data are available uniquely for each catchment the observed streamflow the meteorological data and catchment attributes the first two are dynamic in nature as they are provided as timeseries sourced from the usgs and daymet respectively the last section are static variables describing each catchment such as forested fraction soil porosity and mean potential evapotranspiration pet to name a few to reinforce the variables are static since they do not vary in time for the period during which the dynamic variables were observed or collected the preprocessing is carried out per catchment and to aid our explanation let s consider a catchment named catchment c 2 1 1 identification of flood peaks the first section we process is the observed streamflow for catchment c all peaks in the streamflow signal are isolated and regarded as potential flood events tailored to our study we considered an event a flood event if the recorded streamflow exceeded the 90th quantile q90 streamflow value in the catchment strictly speaking this does not necessarily mean that every peak above this threshold has resulted in actual flooding i e inundation within floodplain so we use the term flood peak throughout this study in a relatively loose sense just to signify that we are only concerned with high peak flows i e peak flows that belong at the top 10 percent of flow values all other peaks previously isolated that fell short of this q90 threshold were removed our rationale is that the peak flows above this threshold allowed us to capture and focus our analysis on the highest flow conditions relevant to flood events thereafter we ensured that each remaining peak corresponded to an independent flood event this second screening of the peaks was completed following the work of hu et al 2020 where the criterion of independence among the flood peaks or flood events identified in catchment c is satisfied if the flood peaks were separated by a minimum distance in time this parameter time separation θ is a function of the area of the catchment where 1 θ 5 d a y s 2 59 log a and a is the catchment area measured in km2 2 1 2 attributing triggering storm the meteorological data was pre processed next specifically the precipitation time series first we needed to identify the storm event that likely triggered each peak we screened for catchment c in section 2 1 1 we refer to this as the triggering precipitation fig 2 illustrates this step where all storms for catchment c were first separated by user defined thresholds 1 the minimum inter storm period considered was one day which corresponded also to the minimum available temporal resolution since we were dealing with daily time series and 2 precipitation must record at least 1 mm day to be considered a part of a storm both thresholds are to some extent subjective but at the same time they are realistic and certainly within the range of values found in relevant literature dunkerley 2008 nikolopoulos et al 2014 having identified all unique storms across the length of the precipitation series we then matched the streamflow time series with the precipitation storm series taking note of start and end times of all storms as shown in fig 2 we looked for the storm that preceded the selected peak more specifically a storm whose start preceded the beginning of the rising limb of the peak some storms continued past the peak we were interested in but this extra precipitation does not contribute to the triggering precipitation that caused the flood peak and in these instances we considered precipitation only up to the time of the peak recalling that both precipitation and streamflow were available at daily timesteps further any selected peak corresponding to a triggering storm event that exceeded 14 days in duration was excluded from the dataset exploratory analysis of peaks against the duration of the corresponding triggering storms showed that less than 1 of the peaks had triggering storms that lasted longer than 14 days for the occasions that θ was small for a catchment resulting in two peaks near each other then the attribution of triggering precipitation to a given peak resolved this issue at this step any peak with a triggering precipitation 14 days in length was removed equivalently if the identified triggering precipitation for the second of the two nearby but still independent peak events encroached on the time at which the first peak event occurred then this second peak was eliminated selected characteristics of the triggering precipitation identified for each peak event corresponded to the maximum and mean precipitation based on the days attributed as part of the triggering storm the other meteorological forcing data was the daily maximum temperature taken as the average over the triggering period it is worthy to mention that repetition of the steps outlined in sections 2 1 1 and 2 1 2 for each catchment in the camels dataset yielded flood peaks extracted across 34 full water years for 598 catchments the temporal record of streamflow observations for the remaining catchments was shorter if the gauge station was established later than 1980 or ceased operation before 2014 for these catchments the meteorological forcing time series precipitation and temperature was trimmed to match the shortened temporal extents of the streamflow record by this procedure we were able to retain data pertaining to the 670 catchments identified in fig 1 such that we have all regions represented 2 1 3 accounting for antecedent wetness the last dynamic variable considered and reported in our peak event delineated datasets or flood peak database is a measure of antecedent wetness condition awc information on the awc of the soil is one factor that modulates runoff generation and hence affects peak flow while its importance is expected to vary for different catchments its impact on peak flow generation has been clearly demonstrated in several past studies nikolopoulos et al 2011 pathiraja et al 2012 saadi et al 2020 the antecedent precipitation index api was the chosen proxy for representing the recent moisture state of the catchment right before the start of the triggering storm it s definition in the subsequent equation follows the work presented by kohler and linsley 1951 and is the basis for the retained rainfall model by singh 1988 2 api j 0 i p t j k j where i total number of antecedent days j lag or antecedent time of interest days pt the precipitation recorded on day t and k decay constant which ranges from 0 8 to 0 98 viessman and lewis 1996 with 0 9 used as the estimate for this study we also considered the use of the normalized antecedent precipitation index which factors in its estimate the catchment s mean recorded precipitation thereby allowing for sounder regional comparisons ali et al 2010 heggen 2001 however preliminary findings not shown here revealed that api was a stronger predictor of flood peak than the normalized api and thus we decided to employ api as the proxy for awc of the catchments the api was constructed across a 30 day time frame prior to and ending the day just before the start of the triggering storm for any identified peak in the dataset applicable temporal lengths for expressing api typically include 7 14 or 30 days with meteorological and hydroclimatic variables influencing this choice from one catchment to the next not discounting seasonal variances we investigated the aforementioned api durations and observed that a 30 day period on average better captured the variations across all 18 regions it is worth noting that while api may have certain limitations in characterizing antecedent wetness i e it is only a proxy of soil moisture state and not an estimate of soil water content it is considered in this work instead of other alternatives such as satellite based soil moisture estimates to maintain the data requirements and thus complexity of the proposed system as low as possible 2 1 4 the resulting flood peak database following the pre processing phase of the dynamic variables the static attributes corresponding to the respective catchments were incorporated into the dataset see section 3 2 and table s2 1 this final combination formed the flood peak database which this study then used our flood peak database numbered approximately 67 000 entries at the end of processing the time series with an average of 100 flood peaks identified per catchment table 1 details the distribution of flood peaks in each of the 18 regions given that flood peak magnitude depends on catchment size each flood peak was normalized by the area of the respective catchment to allow development of a single regional scale model thus our responding variable or output was normalized peak flow ft3 s km2 reported hereafter as mm day 3 methodology 3 1 analysis framework one of the main goals of this work was the development of regional models for predicting flood peaks based on hydrometeorological data and catchment attributes our choice for developing a single model per region instead of per catchment is based on the fact that a an adequate sample size for the model training requires the aggregation of multiple catchments and b hydrologic reasoning dictates that catchments within a hydrologically similar region will respond similarly patil and stieglitz 2011 in fact accuracy in prediction at catchment scale has been posited for models aggregating hydrologically homogeneous basins kratzert et al 2019 tara and paulin 2013 this similarity in behavior at regional scale can be learned by carefully designed models to then predict at the local scale our study area emphasized 18 distinct hydroclimatic regions fig 1 corresponding to 18 models for every chosen ml model the ml based models were used to predict the normalized to catchment area flood peaks there were two experiments designed to evaluate the peak prediction abilities of the models in ungauged catchments the design of experiments 1 and 2 fig 3 differed in the data available as input for the prediction models the training and validation datasets prepared for experiment 1 ensured that events from each of the 670 catchments were contained in each dataset in simpler terms experiment 1 prepared the datasets for a gauged catchment scenario i e ml models were used to predict flood peaks for catchments that were included in the training data experiment 2 instead had unique catchments in each of the datasets prepared emulating an ungauged catchment scenario as such the models performance in this experiment were validated for ungauged catchments since they were not present during the training phase with this approach we were able to check for catchment dependencies affecting model prediction capability experiment 1 had the additional role as a benchmark for comparing the peak prediction performance of the regional models in the ungauged scenario experiment 2 to evaluate the overall added value of the developed models their performance was compared against a state of the art approach see section 3 4 for details notably the flood peak database was split three ways with 60 for training 30 for validation and 10 as the final test set or generalization dataset the 30 for validation was specifically used for selecting good model hyper parameter values the resulting models generalization performance was assessed on the final test set henceforth called generalization dataset which are presented in this study 3 2 selection of predictor variables we utilized three derivations of precipitation and one of temperature as dynamic inputs for our models these were narrowed to i the maximum precipitation ii the mean precipitation iii the mean daily maximum temperature recorded during the period of each triggering storm and iv api as a measure of antecedent wetness condition see section 2 1 3 table s2 1 presents details of these input variables other dynamic inputs during exploratory analysis had considered variables related to minimum temperature vapor pressure and accumulated triggering precipitation these however did not markedly improve predictions and hence were omitted from further consideration a similar procedure as taken with the time series was tried for the static attributes following the work of kratzert et al 2019 hall et al 2014 merz et al 2012 among others we noted very specific instances of improvement with a higher dimensioned dataset i e larger quantity of features used by models albeit on average improvement was negligible across the 18 regional models as such over the negligible decreased performance we prioritized the reduced complexity of the models by using only 3 static attributes the static attributes selected considered the forested fraction the soil porosity and the mean potential evapotranspiration record for each catchment these are in fact variables that other studies hall et al 2014 merz et al 2012 have alluded to as key catchment specific drivers of peak flow response and allows the hydrologist to draw understanding of hydrologic behavior based on model performance to evaluate the role of these predictors within each region a measure of predictor importance was assessed during modeling the details of which are provided in section 3 3 below 3 3 development of predictive models an important motivation when utilizing ml based approaches for regression is their generalization ability and their interpretability while decision tree regressors are highly interpretable compared to their deep learning counterparts we required our models to be accurate while at the same time less prone to overfitting ensemble based learning models are used to improve weak base learners such as decision trees typically stumps thereof by aggregating their predictions in a variety of different ways ensemble learning of tree structured regressors aims at constructively combining predictions of multiple models in order to improve upon any individual model in the ensemble ensemble learning methods form ensembles consisting of simple models in our case tree based regressors and fall into two main categories i bagging bootstrap aggregating approaches such as the one utilized in rf random forest models each model is trained on bootstrap replicates of training samples and tree construction proceeds usually by considering random features subsets finally modeling predictions are simply averaged and ii boosting approaches such as the one adopted in hgbr histogram based gradient boosting regression which grow the ensemble incrementally from simple models just as in the former category but without resampling each model s prediction is weighted so that the ensemble s prediction is rendered more accurate moreover each model added to the ensemble is trained with a weighted loss function casting importance to samples which models already existing in the ensemble do not predict well in particular hgbr is a type of gradient boosting learning algorithm according to which models added to the ensemble have predictions that are maximally correlated to the negative gradient of the ensemble s overall loss function we adopted hgbr ke et al 2017 which is a boosting method and rf random forest breiman 2001 ho 1995 which uses bagging rule extraction from such ensemble based learning models is much more difficult and is an np hard problem i e it is not guaranteed to be solved in polynomial time see cormen et al 2001 although there have been attempts to approximate these rules cui et al 2015 however these models do allow for the computation of permutation feature importance breiman 2001 which helped us compare their relative importance as they pertained to flood response physics based models are by construction interpretable a task that is non trivial for ml based models such as lstm based neural networks our selected ml models however by virtue of these feature importance were able to retain some attribution as interpretable models permutation feature importance measures were obtained by permuting individual feature values among the training samples and evaluating the error induced as a result feature value permutations that produced higher errors under a trained model were deemed important such feedback offered the additional advantage of allowing us to improve our understanding about the drivers of peak flow events and their relative significance across different hydroclimatic regions in order to tune the hgbr s hyper parameters we employed gp ei mcmc a bayesian optimization technique described in snoek et al 2012 according to this method a model s hold out performance viewed as a function of the model s hyper parameters is modeled as a gaussian process and via a fully bayesian treatment the technique aims at sampling ever improving hyper parameter values from a suitable formulation of the posterior distribution among similar methods perhaps its main attraction is that it is computationally highly parallelizable as described in section 3 2 we used 7 variables all of which were continuous variables the objective function being minimized was the mean square error mse and as a result it was used as a metric to compare the performance of models in each region a second metric the percent relative difference prd will be used for inter model comparisons which is computed according to the following equation 3 p r d e x prediction x observation x observation where x is a peak event and e corresponds to the mathematical average in the region in addition to the models that considered all available flood peaks in the dataset all flows we developed models for two unique subsets of the flood peak dataset low moderate lm flows and high flows h flows the threshold for discriminating between these two types of flows was set to the 75th percentile recorded among the normalized flood peaks in each region we hypothesized that although the events in our flood peak database captured the highest 10 percent of flows in any given catchment the role of the predictors we later selected as input for our models varied even within this limited range the rf technique is a bagging method that involves bootstrapping the data training several base learners decision trees and aggregating the results from these base learners to extract predictions this ensemble tree based method has seen previous applications in this field of study in particular rf models in the field of hydrology have proven useful in flood risk analysis and susceptibility mapping zhao et al 2018 rainfall forecasting taksande and mohod 2015 with performance close to that of support vector machines yu et al 2017 mosavi et al 2018 and in recent studies seen as advantageous in large scale flood discharge simulations schoppa et al 2020 these models are less prone to overfit since an increasing number of base learners leads to a converging generalization error see theorem 1 2 in breiman 2001 as opposed to the standard splitting criteria for decision trees of gini impurity employed by classification and regression trees see breiman et al 1984 these base learners determine splits using generalized unbiased interaction and detection estimation see loh 2002 more specifically the selected method chooses a split that minimizes the p value of a chi square test of pairwise independence among all possible splits following tuning of the size of the ensemble we observed that using 150 trees for rf minimized the validation mse for each region the hgbr method is a gradient boosting machine friedman 2001 that aims to learn the underlying function as a linear combination of regression trees also referred to as base learners this is approached in a stagewise fashion that involves adjusting the previously learned function using a greedy step gradient based line search method towards the data based estimate of the function gradient boosting is one such model that aims at learning a linear combination of base learners optimizing each successive learner using the gradient of the loss function with respect to the current function estimate which in our case was mse every new learner attempts to improve upon the shortcomings of its predecessors several applications in the hydrological domain have reaped the benefits of gradient boosting extreme gradient boosting has been used to assess flood susceptibility mirzaei et al 2021 and groundwater spring potential naghibi et al 2020 gradient boosting was also used in conjunction with gaussian mixture models for streamflow forecasting ni et al 2020 we have adopted a more scalable version of the gradient boosting algorithm namely the hgbr model inspired by the lightgbm model ke et al 2017 more specifically we used the algorithm implemented in scikit learn pedregosa et al 2011 which is a ml library for the python programming language the splitting criterion for each node in the tree follows the standard method which aims to choose the split that minimizes the residual sum of squares hyper parameters such as number of estimators maximum number of leaves per learner the ℓ2 regularization parameter for the learned weights and the learning rate were fine tuned for each hgbr model per region and were selected to minimize the validation mse 3 4 lstm based approach current state of the art in the ml based prediction of continuous streamflow has utilized lstm cells in the design of neural networks kratzert et al 2018 kratzert et al 2019 xiang et al 2020 to the task at hand although our study is focused on predicting the peak streamflow during storm events these prior lstm based works that predict continuous streamflow serve to provide benchmark performances that we can compare with additionally to the best of our knowledge there is a lack of literature that directly predicts the peaks as a result we resort to models that have an overarching objective of time series prediction that could perform well in this setting lstms are recurrent neural networks architectures capable of learning time series with long term dependencies hochreiter and schmidhuber 1997 prior such models seemed to perform well in the time points related to low and moderate level flows however for the time instances that are identified as flood peaks i e extreme values performance decreases and oftentimes associates with underestimation of the high flows as has been verified in our experiments refer to section 4 1 for more details the methodology for streamflow prediction in kratzert et al 2019 was adopted for this study and as such we used the same lstm architecture provided by the authors of kratzert et al 2019 as well as the spatial application of the models to conus notably kratzert et al 2019 also used the camels dataset specifically the nldas hydrometeorological timeseries however this study used daymet derived data for the reason mentioned in section 2 for each of the 18 hydroclimatic regions the hydrometeorological time series including precipitation minimum and maximum temperatures solar radiation and vapor pressure of all catchments in addition to 27 static catchment attributes see kratzert et al 2019 in the training dataset were stacked preprocessed then fed to the lstm model to be trained having trained the model the lstm forecasts the validation data for each catchment as per kratzert et al 2019 the sequence length of the input to the lstm layer is 365 days kratzert et al 2019 used a two layer lstm network with each layer having 20 lstm cells between the layers a dropout layer with a rate of 0 1 was added as a measure to prevent overfitting srivastava et al 2014 the batch size was 2048 and each lstm model was trained for 20 epochs the lstm based approach used the rmsprop optimizer with a learning rate of 0 001 we also maintained output based on the 10 member ensemble lstm architecture as in kratzert et al 2019 while all facets of the code provided by kratzert et al 2019 remained intact the meteorological forcing data input and the hyper parameters used are different in our work 3 5 a proposed framework for flood warning systems as a final integrative step of this work we proposed a framework that combines a flood detector with the flood peak predictive models developed for flood warning applications we provide a methodology on aggregating and systematically processing relevant meteorological data to detect storms likely to deliver flood peaks for the demonstration of the flood detector we maintained the definition of a flood peak as one above the 90th quantile streamflow in a given catchment spatial analyses bearing on the idea behind using 18 distinct hydroclimatic regions was maintained for the detector meteorological forcing constitutes the only data used as input for the flood detector see table s2 2 precipitation mm day daily minimum and maximum temperatures c and solar radiation w m2 were the specific dynamic predictors input as time series this selection was narrowed from available time series including vapor pressure antecedent precipitation index a derivative of precipitation as well as static catchment attributes these final variable choices despite their importance to the detector s task are all easily accessible via remotely sensed datasets today be it as historic recent past or near future numerical weather prediction forecasts timeseries the dependence of the flood detector on these variables was thus justified hydrologically as they greatly impact streamflow generation and operationally as they can be conveniently sourced at reasonable temporal and spatial resolutions from remote sensing systems and atmospheric models output from this flood detector was in binary form no flood no peak expected or flood peak expected in the first response case the system continued to monitor the incoming meteorological data inputs and was ready to predict for the next timestep if the latter the follow up was to employ a peak prediction model detailed in foregoing sections to then quantitatively estimate the peak flow expected the detector incorporates lstm cells to process multiple meteorological time series for a given window size these meteorological time series variables are each passed through an lstm layer consisting of 20 cells the outputs of these lstm layers are then concatenated and propagated through a series of dense layers to produce the output label the flood detector model used the rmsprop optimizer with a learning rate of 0 001 batch size of 2000 trained for 30 epochs and a binary cross entropy loss function the loss function was weighted by the inverse of class samples to balance the two classes since there was a prevalence of no flood events in the dataset for each catchment such a weighting scheme is important for the detector since it needs to have reduced false negatives i e the total instances where the detector failed to classify floods as such with time series as input the window size indicates the temporal span of data required by the detector to produce predictions notable to mention is that while one could consider existing lstm models to be used as detectors such as kratzert et al 2019 our choice for developing the proposed lstm was driven by simplicity in the data input that provides a globally applicable character to our model we therefore do not provide a baseline measure for our flood detector recognizing and highlighting that the best choice of individual model components to be used in such a framework is open for additional research our final step to complete the warning system was to predict the peak flow magnitude of any impending flood event flagged by the detector using either of the flood peak prediction models we developed for this study hgbr or rf this step is performed for results issued for both experiments 1 and 2 receiver operating characteristic roc curves are useful for assessing detection performance specifically performance was gauged by comparing the estimated hit rate proportion of flood events successfully detected also referred to as true positive rate given different window sizes for a fixed 20 estimated false alarm rate proportion of events that were erroneously labeled as flood events 4 results discussion this section is subdivided into the following four parts first we illustrate and discuss the results of our peak prediction models compared to the lstm based approach for both experiments 1 and 2 second we evaluate the models performance for different flood severity levels the third section disentangles the results of the peak flow models to explain the role of the hydrometeorological and catchment specific predictors employed the fourth subsection presents the framework for incorporating the flood detector such as the one we developed as an early warning tool 4 1 regional performance of prediction models 4 1 1 experiment 1 a comparison of the hgbr rf and the lstm based peak prediction models for experiment 1 is shown in fig 4 regional model performances are indicated for the all flows scenario and measured using the root mean squared error rmse metric to expound on the differences between the three models we employed the wilcoxon signed rank wsr test with the null hypothesis being that the models perform indistinguishably i e rmse samples for all models are drawn from the same distribution non parametric wsr tests were selected after conducting shapiro wilks tests where the results rejected the null hypothesis that the data distribution was normal at 5 significance for any given region 10 equally spaced quantile rmse scores at 10th 20th 90th and 100th quantiles to represent all the events in each region are computed and paired wsr tests were carried out at 95 confidence level the tests revealed statistically significant differences between the performances of the lstm and hgbr models for 10 regions of these the lstm has the most difficulty along the pacific northwest and southwest coasts which see most instances of flood peaks concentrated during the winter and early spring seasons a consequence of the atmospheric rivers that traverse the regions during these periods the null hypothesis was not rejected for regions 4 6 9 13 15 and 16 indicating similar performance at the same confidence level the lstm and rf models performed significantly dissimilar for all regions except regions 6 10 and 13 these u s southeast and west central regions have fewer flood events with a heavy skew towards flash floods brought about by warmer convective atmospheric conditions during the summer these flood peaks are among the lowest recorded across conus and may explain the similar performance between the lstm and the peak prediction models since the lstm better simulates low moderate peaks the regional wilcoxon signed rank tests revealed that there were no significant differences between the performance of the hgbr and rf for 15 regions p value 0 05 the 3 other regions primarily located in the us east and the last in the great basin negated this trend and showed that there were significant differences in the performance of the two models for these regions 4 1 2 experiment 2 experiment 2 was designed specifically to represent an ungauged scenario where the catchments in the training and validation datasets were different however regional representation of catchments was ensured see section 3 1 for details thus fulfilling the criteria of being able to predict in ungauged catchments the rmse performance per region represented by boxplots is shown in fig 5 similar to experiment 1 wilcoxon signed rank tests were carried out for the regional models comparing the lstm and hgbr the lstm and rf and the hgbr and rf at 95 confidence level the tests revealed significant differences in performance for most regions against the lstm based on the generalization dataset the peak prediction models and lstm for this experiment shared similar performance for the us east regions results for regions 3 4 7 8 and 10 in the lstm and hgbr comparison failed to reject the null hypothesis similarly results for regions 3 7 and 10 along with some us west regions 12 13 and 18 in the lstm and rf comparison failed to reject the null hypothesis however comparing the hgbr and rf models the wilcoxon signed rank tests indicated that there were significant differences between the performance of the two models for 8 of the 18 modeled regions these regions mainly lie along the us east and central plains a multiple comparison test applying the holm bonferroni method holm 1979 which controls family wise error rate was performed for each region at 5 significance level resultantly the hgbr model was simultaneously better than the lstm and rf models in all regions for both experiments figure 6 presents scatter plots of the predicted peak flow against the observed peak flow for the lstm the hgbr and the rf owing to space constraints only two sampled regions are shown per experiment sections 3 2 1 2 of the supplementary material contains scattered plots for all regions and both experiments fig 6a shows region 17 as having almost similar performance among the three models a trend reflected in the box plot of rmse scores in fig 4 for the said region conversely in region 18 there is greater underestimation of the peaks by the lstm unlike the hgbr and rf models where the pearson correlation coefficient pcc was 0 42 0 89 and 0 85 respectively specifically for region 18 we note wide variability in rmse performance by the lstm see fig 4 there is better correlation between the smaller magnitude flood peaks than the higher flood peaks where underprediction is more likely than over prediction a similar trend is noted for experiment 2 in fig 6b where the three models are comparable for region 17 but the underestimation of flood peaks by the lstm more pronounced for region 5 this large variance is also captured in the boxplot in fig 5 for the said region table s4 1 provides the pcc values for both experiments 1 and 2 for the peak prediction models and the lstm overall the main problematic regions in both experiments for the hgbr and rf with low pcc values were parts of the western and northern central regions which identify with drier climates and have one of the lowest annual precipitation totals across conus potentially explaining the performance of the models for these regions section 4 3 below offers more on understanding the predictors 4 2 evaluation of model performance across peak flow quantiles the preceding discussion looked at performance for models considering all events in the respective datasets all flows scenario now that we have established the predictive abilities of our peak flow models we will turn our attention to addressing the results of mainly the hgbr and rf models considering the flood severity classes namely lm flows and h flows in addition to the prd plots shown in fig 6 a quantile quantile comparison from 1st to 99th quantile is included in fig 7 specific to the hgbr and rf models fig 7a for the hgbr model showed better agreement in predicted peak flow quantiles compared to the rf model fig 7b for both models and for both experiments we noted a tendency towards underestimation a trend pronounced for the h flows scenario the same was true for the all flows scenario but for the low moderate flood severity the rf distinctly overestimated hgbr for lm flows had the closest agreement between the observed and predicted flood peaks with averaged absolute relative difference values of 7 7 and 22 0 for experiments 1 and 2 respectively figure 8 provides regional prd comparisons for lm flows and h flows for the two peak prediction models aside from the lm flows scenario of experiment 1 the hgbr did not have a defined trend of under or over predicting conversely the rf mostly overestimated low moderate flood peaks and underestimated the high flood severity evidently hgbr is the better model for performing consistently across flood severities and further discussion will focus on the results of this model for the ungauged experiment the hgbr seemingly has difficulty for regions 9 11 13 and 16 the last two especially for lm flows 4 3 understanding predictors notwithstanding the relative importance assigned to predictors as a product of using rule based models we only aimed to evaluate the role they play in flood response from one region to another and across differing flow severities fig 9 presents the relative importance of the predictors segmented by static and dynamic predictors for both lm flows a and h flows b attention is focused on the selected hgbr model from the foregoing sections on performance evaluation 4 3 1 dynamic predictors with reference to fig 9 for h flows the dynamic predictors held greater importance at influencing peak prediction compared to the static catchment attributes the opposite was true for lm flows maximum and mean precipitation the relative weights of triggering precipitation were clearly higher for h flows than lm flows but for both severity levels the maximum triggering precipitation having high feature importance implied a strong causal influence on flood peaks analyses of the intensity of the precipitation events as a ratio of the maximum precipitation to the total triggering precipitation of the regions indicated that on average the us northeastern southeastern north central and upper colorado regions had a greater number of h flows that were triggered by short duration intensity dominated storm events than lm flows knowing that flood inducing precipitation and their sources across conus are regionally defined these identified precipitation patterns coincide with for example the recorded higher occurrences of flash type floods in the southeastern region dobur 2006 brought about by short duration high intensity air thunderstorms a consequence of the moisture passages from the gulf of mexico hirschboeck 1991 the presence of tropical storms and cyclone related flood inducing precipitation events that the southeastern us region is susceptible to especially during the warmer late spring and early summer seasons may also justify this trend in addition to convective storms mainly occurring in the late summer early fall seasons the northeastern regions berghuijs et al 2016 are vulnerable to flood inducing precipitation resulting from snowmelt or extra tropical cyclones and their associated fronts vicinity of the atlantic ocean influenced by warmer temperatures the mountainous terrains at 1 the junction of the northeastern and southeastern regions and 2 along the intermountain west regions notably upper colorado are also susceptible to local flash floods resulting from similar convective storms enhanced by orographic lifting the u s north central regions with drier climates and low soil moisture retention capabilities record the lowest magnitude of flood peaks overall with flash type floods classed as h flows being the result of majority short convective precipitation events in the region berghuijs et al 2016 hirschboeck 1991 conversely h flows in other regions whilst being triggered by higher magnitude total precipitation these storm events persisted for a longer duration with one example being the great basin here floods with higher rise times occur in the steep glacial terrain saharia et al 2017 given the influence of snowmelt the reduced importance of precipitation for lm flows point instead to the other drivers see remaining discussion that better support the precipitation to peak flow relationship mean maximum temperature two general regions placed emphasis in addition to or instead of the trend of precipitation as the controlling predictor the northeastern and some parts of the intermountain west regions respectively h flows in the energy limited catchments of the u s northeast are more influenced by temperature indeed the distinct four season climate of the u s northeast has been changing over time with the increasing oceanic and atmospheric temperatures the declining snow and ice density the rising sea levels and strain on the ecosystem and hydrologic systems brought about by heavy urbanization of the region assessment 2018 pan et al 2004 as for the intermountain west regions temperature shares a similar magnitude of importance as precipitation for improving peak flow predictions these regions are more water limited but increasing daily minimum temperatures and increased early summer rainfall which mitigated daily maximum temperatures from rising translated to higher flood peaks recorded kunkel et al 2013 pryor 2013 antecedent precipitation index on average the importance of api was weighted higher for lm flows generally this class of flood severity is not driven by high intensity short duration storms as is most often the case for h flows where the sheer magnitude of runoff generated by the current storm is not affected by preceding precipitation unexpectedly for h flows particularly within the north and central east regions and the west coast the inclusion of api mapped to better peak flow predictions this finding may be rationalized by the influence of snowmelt in the region which increases in the warmer seasons of the year and coincides with the time that most flood peaks are observed high flood peaks but with slow rise time i e not intensity dominated flows for lm flows however the current wetness condition of the catchment as a result of preceding storm events greatly affects the flood response in the catchment and the models particularly for the southern east central and west regions viewed api as an important dynamic predictor as an interface between the extreme precipitation regimes of the eastern and western conus regions given proximity to the atlantic or pacific oceans and gulf of mexico the hydrologic signature in these regions is influenced accordingly by pre event precipitation excess wetness brought about by thunderstorms common in the region during the monsoon periods 4 3 2 static predictors forest fraction for lm flows the relative importance of forest fraction was on average greater in the us west regions than east this trend is best rationalized by placing into perspective the changes in land use over the last few decades alig et al 2003 the northeastern us is deemed a heavily urbanized region therefore we see little to no influence from forest fraction on flood peak prediction instead the south and southwest regions including the west intermountain areas which have seen growing populations especially within the last two decades have recorded decreased fractions in forest cover as the rural to urban shift is made alig et al 2004 kunkel et al 2013 it is within these recently changing regions that the variability of forest cover among catchments heightened and thus played an important role in flood peak prediction especially for low moderate flows conversely the prediction of h flows in the northeastern regions saw heightened importance of forest fraction compared to lm flows deciphering this contrast of forest cover importance per flow magnitude between these regions is not straightforward speculations based on hydrologic reasoning suggest potential differences in precipitation interception dynamics in these regions but a valid answer on this merits subsequent investigation which is not within the scope of this work soil porosity the physics behind soil hydraulic characteristics impacting streamflow response is complex of the catchment attributes related to soil from the camels dataset soil porosity aided better predictions overall relative importance was higher among the lm flows with relatively higher impact in the northern central northern great plains and the intermountain west regions interestingly the total precipitation in these regions was among the lowest of the 18 regions in this study a plausible explanation for the importance of this feature to flood response may be attributed to the presence of wetlands in the areas which lie within the steep glacial moraine uplands verry and kolka 2003 seepage from these saturated bodies of water regulated in part by the soil hydraulic features like soil porosity of the surrounding areas eventually feed to channels causing the higher flood peaks recorded dahl 2014 sucik and marks 2015 an additional explanation may be offered when looking at the weighted importance of this attribute in conjunction with mean pet for those regions which have a drier climate given elevated temperatures surface infiltration rates are higher with increased dried pore space mean pet lm flows in the u s west were more responsive to pet than the u s east fig 9a upon closer observation the intermountain west and pacific regions were the most affected and duly so given their arid steppe and mediterranean like climates respectively the summers for both are especially hot leading to water limited catchments i e with higher pet values as for higher flood severities fig 9b the trend in pet was scattered across the regions but the models for the northeast region saw an unexpected emphasis on the mean pet with annual precipitation in excess of evapotranspiration catchments in the northeastern regions are traditionally categorized as energy limited recent analyses have shown however that opposite to temperature precipitation controls evapotranspiration vadeboncoeur et al 2018 with summer precipitation having the highest correlation with evapotranspiration than summer temperature moreover the interplay between precipitation and evapotranspiration modulates antecedent wetness and can therefore have an important impact on flood response in humid catchments nikolopoulos et al 2011 4 4 flood detector the length of the time series or time window required for the detection of flood inducing storms was obtained experimentally by conducting analyses of varying time lengths 3 to 60 days within each region from roc curves performance was gauged by comparing the hit rate given different window sizes for a 20 false alarm rate the flood detector provided optimal results across the 18 regions with a window size of 30 days the results of which are presented in fig 10 fig 10 also shows the corresponding area under the roc curves auc for the 18 regions see legend the true positive rate tpr or sensitivity is the detector s ability to correctly identify a flood peak event with the exception of three regions tpr 75 all other regions were associated with a tpr above 80 for 20 false detections accounting for the detector s ability to accurately identify flood events all regions recorded auc scores of 88 and higher notably with a window size of 30 days performance from the detector eventually reported the inclusion of api as negligible this is understandable as the construction of this index for the study was based on a 30 day duration precipitation made available to the detector as a time series inherently accounts for antecedent moisture condition with a 30 day window size acknowledging that the actual duration of a flood inducing storm is at the order of one to few days much less than the optimal 30 day window clearly emphasizes the importance of antecedent conditions on the classification of the storms in addition to dynamic variables static catchment attributes were tried as inputs following analyses the impact of catchment attributes on the binary classification of flood inducing storms was not significant wide variability was expected as the region under study changed but given the above discussion on understanding the predictors of flood peaks a sound basis for further exploring and developing this input arm of the flood detector exists to complete the evaluation of the flood detector and our proposed pseudo operational flood warning system we performed a coupled analysis of the flood detector and peak prediction model the hgbr for any positive output from the detector i e a flood warning has been issued we gathered the variables required by the hgbr see section 2 corresponding to the impending flood event and applied the hgbr regional models to predict the magnitude of the flood event fig 11 provides the regional boxplot rmse performance for both experiments 1 a and 2 b of all flood events true or false the detector flagged results were comparable to that of experiment 1 see fig 4 and experiment 2 see fig 5 with the problematic regions coinciding and for the same rationale we offered in sections 4 1 and 4 2 figure 12 provides an example of the operational flow for the proposed flood warning system the example is based on a selected catchment from the generalization dataset id 01073000 located along the oyster river near durham nh region 1 this framework asks two main questions 1 at a time t do we expect a flood and 2 if we are to expect a flood what is the predicted magnitude of the peak following the discussion on the duration number of timesteps of the input required by the detector we first identified the 30 days of precipitation minimum and maximum temperatures and solar radiation before time t see fig 12 top to reiterate on the basic steps of the procedure regarding precipitation and peak flow prediction the flood peak prediction models hgbr were trained based on precipitation peak flow pairs that include precipitation input up to the time of peak flow this was derived from the camels dataset that was used for training when applied in an operational mode indeed we cannot possibly know exactly when a precipitation event should end because we don t know the time of the peak flow in that case our framework followed a stepwise procedure in which when the flood detector identifies that precipitation conditions can generate a flood peak according to our definition we use the triggering precipitation event s start and end time up to the latest available forecasting time step taken again from camels but treated as pseudo forecasts i e as if we don t know what is coming next to extract the relevant meteorological inputs see table s2 2 and issue a prediction for the potential peak flow that corresponds to that triggering precipitation event note that we treat precipitation from camels data as our pseudo forecast because our purpose is to demonstrate how the proposed framework would work under the assumption of having accurate precipitation forecasts i e focus solely on the performance of the framework excluding other uncertainty sources in real world conditions consideration of the uncertainty of quantitative precipitation forecasts and its impact on flood prediction is very important but it is beyond the scope of the current work returning to our example portrayed in fig 12 the hgbr issued a prediction if the detector warned of an expected flood as was the case from may 24 26 2013 among other instances in the next forecasting step precipitation is updated by new forecasted values the detector runs again and if the precipitation signal within the forecasting window remains a flood inducing storm according to the detector we update the peak flow prediction again for comparison the observed streamflow is plotted along with the relevant predicted flood peaks the threshold distinguishing flood peaks is plotted at the 90th quantile streamflow for the catchment from observation false positives issued by the detector are usually within the vicinity of the 90th quantile threshold as seen in fig 12 bottom this is often the case for timesteps just preceding a major flood event june 11 2013 or on the recession limb of the flood hydrograph as flow level drops below the threshold may 29 2013 but there was a short burst of precipitation during this recession period the case noted on june 11 2013 is surmised as an artifact of regional detector modeling where the 90th quantile streamflow rates of catchments within a region are similar but not the same thus a range of uncertainty is present for each catchment within any given region note that as long as the flood inducing storm remained close to forecasted time t the detector identified potential flood conditions even when actual flood was in recession equivalently the hgbr model kept providing peak flow predictions that were close in magnitude as a reminder this framework was developed to provide peak flow prediction whenever a flood was imminent and was not intended to predict the shape of the flood hydrograph as such the most appropriate use of such system should be to provide expected max flood conditions during the entire period of the detected flood event the duration of such an event can be derived from the flood detector 5 conclusions and future directions a ml based framework that addresses the detection of flood inducing storms and the prediction of flood peak magnitudes was developed and presented model training and validation were completed for 18 hydroclimatic regions across conus it was demonstrated that ml models such as rf and hgbr are suitable for predicting flood peaks at ungauged basins using a relatively small number of inputs specifically derivatives of precipitation and temperature time series together with catchment attributes such as soil porosity pet and forest fraction provided enough information to achieve flood peak predictions with less than 30 prd in most regions across conus hgbr performed overall better than rf and both of them performed relatively better in the majority of hydroclimatic regions than a state of the art lstm that was used for comparison to a certain degree this is to be expected considering that rf and hgbr were developed solely for flood peak prediction while the lstm was originally developed for predicting the entire flow spectrum this fact therefore does not point necessarily to the best model but simply highlights that if having a skillful model for flood prediction is the objective then it is preferable to develop predictive models only for flood events to avoid stretching them to accurately predict parts of the flow timeseries that may not be of importance for the lstm it was shown that due to the latter predictions for flood peaks were generally underestimated the relative simplicity of rule based models such as rf and hgbr combined with their level of interpretability make them an attractive solution for developing predictive models in hydrology through analysis of the relative feature importance it was shown that the factors influencing the generation of floods exhibit a strong regional dependence whilst precipitation derived variables such as the maximum precipitation triggering a flood peak was found to control flood response significantly in most regions catchment specific attributes considering land cover forest fraction soil hydraulic features soil porosity and potential evapotranspiration also impact and improve the prediction of flood peaks notably the impact of these highlighted drivers varied in response to the flood severity classes with catchment specific attributes showing a higher degree of importance in the prediction of low moderate flows than for high flows where instead precipitation dominated flood response the dimension of seasonality was not considered but previous research posits the ability to increase streamflow prediction the inclusion of this dimension could potentially help to explain the residual behavior of the models in some regions such as those along the northwest coast and upper northern regions of conus where precipitation regimes are unique machine learning based algorithms hold much potential for advancing flood predictions in ungauged catchments and therefore inform decisions on mitigation strategies for flood hazard our attempts at proactively dealing with the rise in extreme natural hazards have been focused on implementing and improving early warning systems in this work we propose a prototype flood warning system that combines a flood detector and the flood magnitude predictor the detector based on a lstm is able to monitor meteorological conditions and issue warnings in case of an imminent flood which subsequently triggers the peak prediction model hgbr that predicts the magnitude of the expected flood peak such a framework combined with remote sensing and numerical weather predictions can offer a potential solution for flood warning applications in areas where in situ observations are sparse or inexistent results from this work demonstrated that in all areas examined such a system would achieve a hit rate of 80 for 20 false detections and while this recommends that there is definitely room for improvement at the same time demonstrates arguably a lot of promise moving forward there are several steps that can be taken to further advance ml based flood prediction and the development of warning procedures first of all integration of higher spatial and temporal variability of features considered is one important step towards advancing model development so far this and many other studies have used daily forcing data and catchment averaged values while we know that dynamics of sub daily precipitation as well as its spatial distribution over a catchment affect flood response therefore incorporating such information should be included in subsequent developments also the choice of api for characterizing antecedent wetness has limitations crow et al 2009 tramblay et al 2012 and thus can be improved by considering additional sources of soil moisture information e g from satellite based sensors massari et al 2014a b lastly the transferability of the models produced in this and other works based on camels dataset should be evaluated globally by other similar datasets that have been recently developed alvarez garreton et al 2018 coxon et al 2020 credit authorship contribution statement zimeena rasheed data curation formal analysis writing original draft akshay aravamudan software validation writing review editing ali gorji sefidmazgi software georgios c anagnostopoulos methodology supervision writing review editing efthymios i nikolopoulos conceptualization funding acquisition supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank dr frederic kratzert for sharing via github the lstm code used in kratzert et al 2019 rasheed and nikolopoulos were supported by the national science foundation united states under grant no 1934712 we would like to acknowledge high performance computing support from cheyenne doi 10 5065 d6rx99hx provided by ncar s computational and information systems laboratory sponsored by the national science foundation rasheed and aravamudan acknowledge partial support by an fit college of engineering sciences institutional research incentive seed grant appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127736 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3414,flood prediction across scales and more specifically in ungauged areas remains a great challenge that limits the efficiency of flood risk mitigation strategies and disaster preparedness building upon the recent success of machine learning ml models on streamflow prediction this work presents a prototype ml based framework for flood warning and flood peak prediction the fundamental elements of the proposed system consist of a a long short term memory lstm model for classifying storm events to flood no flood given a threshold based on the 90th flow percentile and b the flood peak prediction models the selected ml models for flood peak prediction are the histogram based gradient boosting regressor and the random forest one of the strengths and reason for selection of these decision tree models is their degree of interpretability this is exploited in the study to help us spatially disentangle the role of both the static and dynamic drivers of flood peak response our analysis is presented for 18 distinct hydroclimatic regions across the contiguous us results reveal a significant regional dependence on both predictive performance and dominant flood predictors which emphasize the variability in the complexity of a catchment s hydrologic behavior as well as its impact on forecasting flood response evaluation of the drivers of flood peaks noted distinct dependencies among the dynamic and static predictors considered in our models for flood peaks of different severity specifically low moderate flood events showed a clear preponderance for the static catchment attributes over dynamic predictors like precipitation whereas precipitation was the dominant driver for the highest flood peaks the proposed flood peak prediction models were compared against a state of the art lstm model and were shown to outperform in ungauged basins for the majority of basins overall the proposed system classified storms correctly for 80 in all cases and exhibited a percent relative difference in flood peak estimates of 30 in most cases keywords flood peak prediction machine learning ungauged basins flood warning 1 introduction to date floods are the most recurring and devastating natural hazard affecting the contiguous united states conus posing significant risk to lives and livelihoods dougherty and rasmussen 2019 knight 2010 perry 2000 flood impacts within conus alone are associated with a significant toll on human life and annual incurred costs of 6 2 billion usd for damages over the past decade ncei 2020 these are facts which enunciate the need to accurately predict flood events everywhere streamflow primarily in heavily and growing urbanized regions across conus has been increasing a trend noted for the last 50 years lins and slack 2005 in addition studies investigating the impacts of current and future climate extremes lins and slack 2005 milly et al 2002 indicate that the u s population is becoming alarmingly vulnerable to flood associated risks naz et al 2016 wing et al 2018 these trends are particular not only to conus but have been observed in other parts of the world including europe jarosińska and pierzga 2017 teuling et al 2019 central asia gulakhmadov et al 2020 and south america lara et al 2017 under various growth scenarios for future climate as prescribed by global climate models and despite local and regional scale complexities this continual upward intensification of median and high flows remains a consistent find in these studies the factors that lead to increase in peak flow are many arguably precipitation is the dominant driver controlling peak flow response prein et al 2017 seneviratne et al 2012 slater and villarini 2017 and there is virtually unanimous acknowledgement of current and future precipitation intensity patterns intensifying exceptions to precipitation controlling peak flow response do exist ivancic and shaw 2015 westra et al 2013 due to other atmospheric variables like temperature wasko and sharma 2017 or potential evapotranspiration mallakpour and villarini 2015 the argument regarding these exceptions continues that some other variables attributable to modulating extreme flood response hall et al 2014 merz et al 2012 include regional and catchment specific hydrogeomorphic parameters water management schemes national research council et al 2007 soil and hydraulic parameters as well as land cover changes ahn et al 2014 kim and kim 2020 tomer and schilling 2009 to name a few in unique cases we may see a specific factor controlling streamflow response but the interaction among any of the above drivers is what makes the prediction of flood peaks i e very high streamflow a complex process hrachowitz et al 2013 saghafian et al 2014 todini 2007 the ability to accurately predict streamflow across spatial scales has been an ongoing topic of research for several decades kratzert et al 2018 mosavi et al 2018 tara and paulin 2013 remesan and mathew 2014 slater and villarini 2017 among others indeed accounting for the complexity and nonlinear interactions of land surface properties with dynamic forcing precipitation temperature and state variables soil moisture to be able to accurately predict flood response still remains a challenging task traditional approaches to simulating streamflow or peak discharge have been centered around the development of empirical as well as physics based distributed hydrologic models decharme et al 2012 getirana et al 2012 ivanov et al 2004 lin et al 2018 wilson et al 2007 yamazaki et al 2012 we recommend the two review papers for references to further physics based conceptual rainfall runoff models tara and paulin 2013 todini 2007 the capability of accounting for spatial variability within a catchment and extensively informing on its hydrologic system are clear advantages of these approaches costabile and macchione 2015 in return the physics based models specifically require extensive computational resources and high resolution spatial data related to catchment attributes and initial boundary conditions samaniego et al 2010 for these reasons physics based models are shied away from for large sample studies and applications with the growing concern of flood hazards increasing not only in severity but also in frequency and large areas still being ungauged which poses a great limitation on parameterization of physics based models the hydrologic community has started investigating alternative models that has the potential to efficiently predict flood peaks especially for ungauged catchments such investigations led to the implementation of data driven models utilizing machine learning ml algorithms kratzert et al 2018 kratzert et al 2019 mosavi et al 2018 remesan and mathew 2014 xiang et al 2020 the potential for ml based approaches towards simulating streamflow among other hydrologic applications elshorbagy et al 2010 kasiviswanathan et al 2016 schoppa et al 2020 has been noted for well over a decade now but broader exploration was attempted only recently over the last few years the availability of large sample high resolution observed and simulated hydrometeorological datasets have enabled the analysis of various flood generation processes at the catchment scale along with their drivers ml based models alleviate the intensive computational resources required of physics based distributed models whilst maintaining the necessary design and processing complexity and predictive strength desired mosavi et al 2018 todini 2007 however accurate peak flow prediction remains challenging for example the lstm based neural network of kratzert et al 2018 requires vast meteorological historic data as input and is able to capture exceptionally well the signals of low to moderate level flows most recently kratzert et al 2019 has advanced the lstm model kratzert et al 2018 to a true ensemble based model that now incorporates a wide array of static catchment attributes aforementioned as the other drivers of peak flow response however accurate predictions of very high flow events remain challenging the devastating aftermath of missing these events has been outlined above which underlines the pressing need for improved prediction of such events for individual catchments the overarching goal of this study is to develop ml based models that a accurately predict flood peaks b are as less complex in terms of data demand as possible and c maintain a high degree of interpretability in contrast to the recent works published on the topic of ml based streamflow prediction where the target contains the prediction of the entire spectrum of streamflow values we develop a framework that is based on rainfall to flood peak events and focuses solely on the prediction of flood peaks i e single max flow value per rainfall runoff event our framework also includes an ml based classifier that separates storms into flood and no flood inducing events integration of those elements is proposed as an alternative framework for flood forecasting in ungauged basins en route to this goal we also seek to understand the dominant drivers of flood response and their dependence on hydroclimatic regime and flood severity the remainder of this paper is organized as follows the study area and key steps to pre process the data for peak flow analysis are described in section 2 the methodological framework which explores two approaches to developing models capable of predicting flood peaks in ungauged basins is detailed in section 3 section 4 presents the results of our ml based models for different hydroclimatic zones and flow severities and discusses inferences drawn related to drivers of flood response including the potential thereafter for advancing early warning systems on floods future directions for building on this research and the main conclusions follow in section 5 2 study area and data this study utilized the conus wide dataset catchment attributes and meteorology for large sample studies camels which contains data for approximately 670 catchments addor et al 2017 newman et al 2015 a study supported by the national center for atmospheric research it boasts a long record of daily streamflow data derived from united states geological services usgs from 1980 to 2014 with the same temporal horizon hydrometeorological forcing data are provided from daymet thornton et al 2012 nldas xia et al 2012 and maurer et al 2002 which includes precipitation temperature and vapor pressure to name a few additionally available are 30 static catchment attributes subdivided into hydrological climatic vegetative soil and topographical features see addor et al 2017 newman et al 2015 for details our study selected and utilized the daymet derived gridded estimates of daily weather parameters for these catchments across the 34 year record the main reason for our selection is based on newman et al 2015 who posited that daymet had overall better performance for modeling compared to maurer and nldas postulating the result likely related to the higher spatial resolution of daymet analysis was performed at a regional scale by clustering the catchments according to the regional watershed boundaries established by the usgs across conus there are 18 distinct hydroclimatic regions designated by their two digit hydrologic unit code huc 02 the spread of the 670 catchments within each region is shown in fig 1 the drainage areas of these catchments range from 3 km2 to 25 524 km2 with an average of 589 km2 2 1 pre processing from the foregoing discussion of our source dataset camels we have three main sections of data to pre process given our objectives our output at the end of preprocessing is a flood peak dataset that contains the data pertaining to all flood events we identify from the 670 catchments across conus see fig 1 these three main sections of data are available uniquely for each catchment the observed streamflow the meteorological data and catchment attributes the first two are dynamic in nature as they are provided as timeseries sourced from the usgs and daymet respectively the last section are static variables describing each catchment such as forested fraction soil porosity and mean potential evapotranspiration pet to name a few to reinforce the variables are static since they do not vary in time for the period during which the dynamic variables were observed or collected the preprocessing is carried out per catchment and to aid our explanation let s consider a catchment named catchment c 2 1 1 identification of flood peaks the first section we process is the observed streamflow for catchment c all peaks in the streamflow signal are isolated and regarded as potential flood events tailored to our study we considered an event a flood event if the recorded streamflow exceeded the 90th quantile q90 streamflow value in the catchment strictly speaking this does not necessarily mean that every peak above this threshold has resulted in actual flooding i e inundation within floodplain so we use the term flood peak throughout this study in a relatively loose sense just to signify that we are only concerned with high peak flows i e peak flows that belong at the top 10 percent of flow values all other peaks previously isolated that fell short of this q90 threshold were removed our rationale is that the peak flows above this threshold allowed us to capture and focus our analysis on the highest flow conditions relevant to flood events thereafter we ensured that each remaining peak corresponded to an independent flood event this second screening of the peaks was completed following the work of hu et al 2020 where the criterion of independence among the flood peaks or flood events identified in catchment c is satisfied if the flood peaks were separated by a minimum distance in time this parameter time separation θ is a function of the area of the catchment where 1 θ 5 d a y s 2 59 log a and a is the catchment area measured in km2 2 1 2 attributing triggering storm the meteorological data was pre processed next specifically the precipitation time series first we needed to identify the storm event that likely triggered each peak we screened for catchment c in section 2 1 1 we refer to this as the triggering precipitation fig 2 illustrates this step where all storms for catchment c were first separated by user defined thresholds 1 the minimum inter storm period considered was one day which corresponded also to the minimum available temporal resolution since we were dealing with daily time series and 2 precipitation must record at least 1 mm day to be considered a part of a storm both thresholds are to some extent subjective but at the same time they are realistic and certainly within the range of values found in relevant literature dunkerley 2008 nikolopoulos et al 2014 having identified all unique storms across the length of the precipitation series we then matched the streamflow time series with the precipitation storm series taking note of start and end times of all storms as shown in fig 2 we looked for the storm that preceded the selected peak more specifically a storm whose start preceded the beginning of the rising limb of the peak some storms continued past the peak we were interested in but this extra precipitation does not contribute to the triggering precipitation that caused the flood peak and in these instances we considered precipitation only up to the time of the peak recalling that both precipitation and streamflow were available at daily timesteps further any selected peak corresponding to a triggering storm event that exceeded 14 days in duration was excluded from the dataset exploratory analysis of peaks against the duration of the corresponding triggering storms showed that less than 1 of the peaks had triggering storms that lasted longer than 14 days for the occasions that θ was small for a catchment resulting in two peaks near each other then the attribution of triggering precipitation to a given peak resolved this issue at this step any peak with a triggering precipitation 14 days in length was removed equivalently if the identified triggering precipitation for the second of the two nearby but still independent peak events encroached on the time at which the first peak event occurred then this second peak was eliminated selected characteristics of the triggering precipitation identified for each peak event corresponded to the maximum and mean precipitation based on the days attributed as part of the triggering storm the other meteorological forcing data was the daily maximum temperature taken as the average over the triggering period it is worthy to mention that repetition of the steps outlined in sections 2 1 1 and 2 1 2 for each catchment in the camels dataset yielded flood peaks extracted across 34 full water years for 598 catchments the temporal record of streamflow observations for the remaining catchments was shorter if the gauge station was established later than 1980 or ceased operation before 2014 for these catchments the meteorological forcing time series precipitation and temperature was trimmed to match the shortened temporal extents of the streamflow record by this procedure we were able to retain data pertaining to the 670 catchments identified in fig 1 such that we have all regions represented 2 1 3 accounting for antecedent wetness the last dynamic variable considered and reported in our peak event delineated datasets or flood peak database is a measure of antecedent wetness condition awc information on the awc of the soil is one factor that modulates runoff generation and hence affects peak flow while its importance is expected to vary for different catchments its impact on peak flow generation has been clearly demonstrated in several past studies nikolopoulos et al 2011 pathiraja et al 2012 saadi et al 2020 the antecedent precipitation index api was the chosen proxy for representing the recent moisture state of the catchment right before the start of the triggering storm it s definition in the subsequent equation follows the work presented by kohler and linsley 1951 and is the basis for the retained rainfall model by singh 1988 2 api j 0 i p t j k j where i total number of antecedent days j lag or antecedent time of interest days pt the precipitation recorded on day t and k decay constant which ranges from 0 8 to 0 98 viessman and lewis 1996 with 0 9 used as the estimate for this study we also considered the use of the normalized antecedent precipitation index which factors in its estimate the catchment s mean recorded precipitation thereby allowing for sounder regional comparisons ali et al 2010 heggen 2001 however preliminary findings not shown here revealed that api was a stronger predictor of flood peak than the normalized api and thus we decided to employ api as the proxy for awc of the catchments the api was constructed across a 30 day time frame prior to and ending the day just before the start of the triggering storm for any identified peak in the dataset applicable temporal lengths for expressing api typically include 7 14 or 30 days with meteorological and hydroclimatic variables influencing this choice from one catchment to the next not discounting seasonal variances we investigated the aforementioned api durations and observed that a 30 day period on average better captured the variations across all 18 regions it is worth noting that while api may have certain limitations in characterizing antecedent wetness i e it is only a proxy of soil moisture state and not an estimate of soil water content it is considered in this work instead of other alternatives such as satellite based soil moisture estimates to maintain the data requirements and thus complexity of the proposed system as low as possible 2 1 4 the resulting flood peak database following the pre processing phase of the dynamic variables the static attributes corresponding to the respective catchments were incorporated into the dataset see section 3 2 and table s2 1 this final combination formed the flood peak database which this study then used our flood peak database numbered approximately 67 000 entries at the end of processing the time series with an average of 100 flood peaks identified per catchment table 1 details the distribution of flood peaks in each of the 18 regions given that flood peak magnitude depends on catchment size each flood peak was normalized by the area of the respective catchment to allow development of a single regional scale model thus our responding variable or output was normalized peak flow ft3 s km2 reported hereafter as mm day 3 methodology 3 1 analysis framework one of the main goals of this work was the development of regional models for predicting flood peaks based on hydrometeorological data and catchment attributes our choice for developing a single model per region instead of per catchment is based on the fact that a an adequate sample size for the model training requires the aggregation of multiple catchments and b hydrologic reasoning dictates that catchments within a hydrologically similar region will respond similarly patil and stieglitz 2011 in fact accuracy in prediction at catchment scale has been posited for models aggregating hydrologically homogeneous basins kratzert et al 2019 tara and paulin 2013 this similarity in behavior at regional scale can be learned by carefully designed models to then predict at the local scale our study area emphasized 18 distinct hydroclimatic regions fig 1 corresponding to 18 models for every chosen ml model the ml based models were used to predict the normalized to catchment area flood peaks there were two experiments designed to evaluate the peak prediction abilities of the models in ungauged catchments the design of experiments 1 and 2 fig 3 differed in the data available as input for the prediction models the training and validation datasets prepared for experiment 1 ensured that events from each of the 670 catchments were contained in each dataset in simpler terms experiment 1 prepared the datasets for a gauged catchment scenario i e ml models were used to predict flood peaks for catchments that were included in the training data experiment 2 instead had unique catchments in each of the datasets prepared emulating an ungauged catchment scenario as such the models performance in this experiment were validated for ungauged catchments since they were not present during the training phase with this approach we were able to check for catchment dependencies affecting model prediction capability experiment 1 had the additional role as a benchmark for comparing the peak prediction performance of the regional models in the ungauged scenario experiment 2 to evaluate the overall added value of the developed models their performance was compared against a state of the art approach see section 3 4 for details notably the flood peak database was split three ways with 60 for training 30 for validation and 10 as the final test set or generalization dataset the 30 for validation was specifically used for selecting good model hyper parameter values the resulting models generalization performance was assessed on the final test set henceforth called generalization dataset which are presented in this study 3 2 selection of predictor variables we utilized three derivations of precipitation and one of temperature as dynamic inputs for our models these were narrowed to i the maximum precipitation ii the mean precipitation iii the mean daily maximum temperature recorded during the period of each triggering storm and iv api as a measure of antecedent wetness condition see section 2 1 3 table s2 1 presents details of these input variables other dynamic inputs during exploratory analysis had considered variables related to minimum temperature vapor pressure and accumulated triggering precipitation these however did not markedly improve predictions and hence were omitted from further consideration a similar procedure as taken with the time series was tried for the static attributes following the work of kratzert et al 2019 hall et al 2014 merz et al 2012 among others we noted very specific instances of improvement with a higher dimensioned dataset i e larger quantity of features used by models albeit on average improvement was negligible across the 18 regional models as such over the negligible decreased performance we prioritized the reduced complexity of the models by using only 3 static attributes the static attributes selected considered the forested fraction the soil porosity and the mean potential evapotranspiration record for each catchment these are in fact variables that other studies hall et al 2014 merz et al 2012 have alluded to as key catchment specific drivers of peak flow response and allows the hydrologist to draw understanding of hydrologic behavior based on model performance to evaluate the role of these predictors within each region a measure of predictor importance was assessed during modeling the details of which are provided in section 3 3 below 3 3 development of predictive models an important motivation when utilizing ml based approaches for regression is their generalization ability and their interpretability while decision tree regressors are highly interpretable compared to their deep learning counterparts we required our models to be accurate while at the same time less prone to overfitting ensemble based learning models are used to improve weak base learners such as decision trees typically stumps thereof by aggregating their predictions in a variety of different ways ensemble learning of tree structured regressors aims at constructively combining predictions of multiple models in order to improve upon any individual model in the ensemble ensemble learning methods form ensembles consisting of simple models in our case tree based regressors and fall into two main categories i bagging bootstrap aggregating approaches such as the one utilized in rf random forest models each model is trained on bootstrap replicates of training samples and tree construction proceeds usually by considering random features subsets finally modeling predictions are simply averaged and ii boosting approaches such as the one adopted in hgbr histogram based gradient boosting regression which grow the ensemble incrementally from simple models just as in the former category but without resampling each model s prediction is weighted so that the ensemble s prediction is rendered more accurate moreover each model added to the ensemble is trained with a weighted loss function casting importance to samples which models already existing in the ensemble do not predict well in particular hgbr is a type of gradient boosting learning algorithm according to which models added to the ensemble have predictions that are maximally correlated to the negative gradient of the ensemble s overall loss function we adopted hgbr ke et al 2017 which is a boosting method and rf random forest breiman 2001 ho 1995 which uses bagging rule extraction from such ensemble based learning models is much more difficult and is an np hard problem i e it is not guaranteed to be solved in polynomial time see cormen et al 2001 although there have been attempts to approximate these rules cui et al 2015 however these models do allow for the computation of permutation feature importance breiman 2001 which helped us compare their relative importance as they pertained to flood response physics based models are by construction interpretable a task that is non trivial for ml based models such as lstm based neural networks our selected ml models however by virtue of these feature importance were able to retain some attribution as interpretable models permutation feature importance measures were obtained by permuting individual feature values among the training samples and evaluating the error induced as a result feature value permutations that produced higher errors under a trained model were deemed important such feedback offered the additional advantage of allowing us to improve our understanding about the drivers of peak flow events and their relative significance across different hydroclimatic regions in order to tune the hgbr s hyper parameters we employed gp ei mcmc a bayesian optimization technique described in snoek et al 2012 according to this method a model s hold out performance viewed as a function of the model s hyper parameters is modeled as a gaussian process and via a fully bayesian treatment the technique aims at sampling ever improving hyper parameter values from a suitable formulation of the posterior distribution among similar methods perhaps its main attraction is that it is computationally highly parallelizable as described in section 3 2 we used 7 variables all of which were continuous variables the objective function being minimized was the mean square error mse and as a result it was used as a metric to compare the performance of models in each region a second metric the percent relative difference prd will be used for inter model comparisons which is computed according to the following equation 3 p r d e x prediction x observation x observation where x is a peak event and e corresponds to the mathematical average in the region in addition to the models that considered all available flood peaks in the dataset all flows we developed models for two unique subsets of the flood peak dataset low moderate lm flows and high flows h flows the threshold for discriminating between these two types of flows was set to the 75th percentile recorded among the normalized flood peaks in each region we hypothesized that although the events in our flood peak database captured the highest 10 percent of flows in any given catchment the role of the predictors we later selected as input for our models varied even within this limited range the rf technique is a bagging method that involves bootstrapping the data training several base learners decision trees and aggregating the results from these base learners to extract predictions this ensemble tree based method has seen previous applications in this field of study in particular rf models in the field of hydrology have proven useful in flood risk analysis and susceptibility mapping zhao et al 2018 rainfall forecasting taksande and mohod 2015 with performance close to that of support vector machines yu et al 2017 mosavi et al 2018 and in recent studies seen as advantageous in large scale flood discharge simulations schoppa et al 2020 these models are less prone to overfit since an increasing number of base learners leads to a converging generalization error see theorem 1 2 in breiman 2001 as opposed to the standard splitting criteria for decision trees of gini impurity employed by classification and regression trees see breiman et al 1984 these base learners determine splits using generalized unbiased interaction and detection estimation see loh 2002 more specifically the selected method chooses a split that minimizes the p value of a chi square test of pairwise independence among all possible splits following tuning of the size of the ensemble we observed that using 150 trees for rf minimized the validation mse for each region the hgbr method is a gradient boosting machine friedman 2001 that aims to learn the underlying function as a linear combination of regression trees also referred to as base learners this is approached in a stagewise fashion that involves adjusting the previously learned function using a greedy step gradient based line search method towards the data based estimate of the function gradient boosting is one such model that aims at learning a linear combination of base learners optimizing each successive learner using the gradient of the loss function with respect to the current function estimate which in our case was mse every new learner attempts to improve upon the shortcomings of its predecessors several applications in the hydrological domain have reaped the benefits of gradient boosting extreme gradient boosting has been used to assess flood susceptibility mirzaei et al 2021 and groundwater spring potential naghibi et al 2020 gradient boosting was also used in conjunction with gaussian mixture models for streamflow forecasting ni et al 2020 we have adopted a more scalable version of the gradient boosting algorithm namely the hgbr model inspired by the lightgbm model ke et al 2017 more specifically we used the algorithm implemented in scikit learn pedregosa et al 2011 which is a ml library for the python programming language the splitting criterion for each node in the tree follows the standard method which aims to choose the split that minimizes the residual sum of squares hyper parameters such as number of estimators maximum number of leaves per learner the ℓ2 regularization parameter for the learned weights and the learning rate were fine tuned for each hgbr model per region and were selected to minimize the validation mse 3 4 lstm based approach current state of the art in the ml based prediction of continuous streamflow has utilized lstm cells in the design of neural networks kratzert et al 2018 kratzert et al 2019 xiang et al 2020 to the task at hand although our study is focused on predicting the peak streamflow during storm events these prior lstm based works that predict continuous streamflow serve to provide benchmark performances that we can compare with additionally to the best of our knowledge there is a lack of literature that directly predicts the peaks as a result we resort to models that have an overarching objective of time series prediction that could perform well in this setting lstms are recurrent neural networks architectures capable of learning time series with long term dependencies hochreiter and schmidhuber 1997 prior such models seemed to perform well in the time points related to low and moderate level flows however for the time instances that are identified as flood peaks i e extreme values performance decreases and oftentimes associates with underestimation of the high flows as has been verified in our experiments refer to section 4 1 for more details the methodology for streamflow prediction in kratzert et al 2019 was adopted for this study and as such we used the same lstm architecture provided by the authors of kratzert et al 2019 as well as the spatial application of the models to conus notably kratzert et al 2019 also used the camels dataset specifically the nldas hydrometeorological timeseries however this study used daymet derived data for the reason mentioned in section 2 for each of the 18 hydroclimatic regions the hydrometeorological time series including precipitation minimum and maximum temperatures solar radiation and vapor pressure of all catchments in addition to 27 static catchment attributes see kratzert et al 2019 in the training dataset were stacked preprocessed then fed to the lstm model to be trained having trained the model the lstm forecasts the validation data for each catchment as per kratzert et al 2019 the sequence length of the input to the lstm layer is 365 days kratzert et al 2019 used a two layer lstm network with each layer having 20 lstm cells between the layers a dropout layer with a rate of 0 1 was added as a measure to prevent overfitting srivastava et al 2014 the batch size was 2048 and each lstm model was trained for 20 epochs the lstm based approach used the rmsprop optimizer with a learning rate of 0 001 we also maintained output based on the 10 member ensemble lstm architecture as in kratzert et al 2019 while all facets of the code provided by kratzert et al 2019 remained intact the meteorological forcing data input and the hyper parameters used are different in our work 3 5 a proposed framework for flood warning systems as a final integrative step of this work we proposed a framework that combines a flood detector with the flood peak predictive models developed for flood warning applications we provide a methodology on aggregating and systematically processing relevant meteorological data to detect storms likely to deliver flood peaks for the demonstration of the flood detector we maintained the definition of a flood peak as one above the 90th quantile streamflow in a given catchment spatial analyses bearing on the idea behind using 18 distinct hydroclimatic regions was maintained for the detector meteorological forcing constitutes the only data used as input for the flood detector see table s2 2 precipitation mm day daily minimum and maximum temperatures c and solar radiation w m2 were the specific dynamic predictors input as time series this selection was narrowed from available time series including vapor pressure antecedent precipitation index a derivative of precipitation as well as static catchment attributes these final variable choices despite their importance to the detector s task are all easily accessible via remotely sensed datasets today be it as historic recent past or near future numerical weather prediction forecasts timeseries the dependence of the flood detector on these variables was thus justified hydrologically as they greatly impact streamflow generation and operationally as they can be conveniently sourced at reasonable temporal and spatial resolutions from remote sensing systems and atmospheric models output from this flood detector was in binary form no flood no peak expected or flood peak expected in the first response case the system continued to monitor the incoming meteorological data inputs and was ready to predict for the next timestep if the latter the follow up was to employ a peak prediction model detailed in foregoing sections to then quantitatively estimate the peak flow expected the detector incorporates lstm cells to process multiple meteorological time series for a given window size these meteorological time series variables are each passed through an lstm layer consisting of 20 cells the outputs of these lstm layers are then concatenated and propagated through a series of dense layers to produce the output label the flood detector model used the rmsprop optimizer with a learning rate of 0 001 batch size of 2000 trained for 30 epochs and a binary cross entropy loss function the loss function was weighted by the inverse of class samples to balance the two classes since there was a prevalence of no flood events in the dataset for each catchment such a weighting scheme is important for the detector since it needs to have reduced false negatives i e the total instances where the detector failed to classify floods as such with time series as input the window size indicates the temporal span of data required by the detector to produce predictions notable to mention is that while one could consider existing lstm models to be used as detectors such as kratzert et al 2019 our choice for developing the proposed lstm was driven by simplicity in the data input that provides a globally applicable character to our model we therefore do not provide a baseline measure for our flood detector recognizing and highlighting that the best choice of individual model components to be used in such a framework is open for additional research our final step to complete the warning system was to predict the peak flow magnitude of any impending flood event flagged by the detector using either of the flood peak prediction models we developed for this study hgbr or rf this step is performed for results issued for both experiments 1 and 2 receiver operating characteristic roc curves are useful for assessing detection performance specifically performance was gauged by comparing the estimated hit rate proportion of flood events successfully detected also referred to as true positive rate given different window sizes for a fixed 20 estimated false alarm rate proportion of events that were erroneously labeled as flood events 4 results discussion this section is subdivided into the following four parts first we illustrate and discuss the results of our peak prediction models compared to the lstm based approach for both experiments 1 and 2 second we evaluate the models performance for different flood severity levels the third section disentangles the results of the peak flow models to explain the role of the hydrometeorological and catchment specific predictors employed the fourth subsection presents the framework for incorporating the flood detector such as the one we developed as an early warning tool 4 1 regional performance of prediction models 4 1 1 experiment 1 a comparison of the hgbr rf and the lstm based peak prediction models for experiment 1 is shown in fig 4 regional model performances are indicated for the all flows scenario and measured using the root mean squared error rmse metric to expound on the differences between the three models we employed the wilcoxon signed rank wsr test with the null hypothesis being that the models perform indistinguishably i e rmse samples for all models are drawn from the same distribution non parametric wsr tests were selected after conducting shapiro wilks tests where the results rejected the null hypothesis that the data distribution was normal at 5 significance for any given region 10 equally spaced quantile rmse scores at 10th 20th 90th and 100th quantiles to represent all the events in each region are computed and paired wsr tests were carried out at 95 confidence level the tests revealed statistically significant differences between the performances of the lstm and hgbr models for 10 regions of these the lstm has the most difficulty along the pacific northwest and southwest coasts which see most instances of flood peaks concentrated during the winter and early spring seasons a consequence of the atmospheric rivers that traverse the regions during these periods the null hypothesis was not rejected for regions 4 6 9 13 15 and 16 indicating similar performance at the same confidence level the lstm and rf models performed significantly dissimilar for all regions except regions 6 10 and 13 these u s southeast and west central regions have fewer flood events with a heavy skew towards flash floods brought about by warmer convective atmospheric conditions during the summer these flood peaks are among the lowest recorded across conus and may explain the similar performance between the lstm and the peak prediction models since the lstm better simulates low moderate peaks the regional wilcoxon signed rank tests revealed that there were no significant differences between the performance of the hgbr and rf for 15 regions p value 0 05 the 3 other regions primarily located in the us east and the last in the great basin negated this trend and showed that there were significant differences in the performance of the two models for these regions 4 1 2 experiment 2 experiment 2 was designed specifically to represent an ungauged scenario where the catchments in the training and validation datasets were different however regional representation of catchments was ensured see section 3 1 for details thus fulfilling the criteria of being able to predict in ungauged catchments the rmse performance per region represented by boxplots is shown in fig 5 similar to experiment 1 wilcoxon signed rank tests were carried out for the regional models comparing the lstm and hgbr the lstm and rf and the hgbr and rf at 95 confidence level the tests revealed significant differences in performance for most regions against the lstm based on the generalization dataset the peak prediction models and lstm for this experiment shared similar performance for the us east regions results for regions 3 4 7 8 and 10 in the lstm and hgbr comparison failed to reject the null hypothesis similarly results for regions 3 7 and 10 along with some us west regions 12 13 and 18 in the lstm and rf comparison failed to reject the null hypothesis however comparing the hgbr and rf models the wilcoxon signed rank tests indicated that there were significant differences between the performance of the two models for 8 of the 18 modeled regions these regions mainly lie along the us east and central plains a multiple comparison test applying the holm bonferroni method holm 1979 which controls family wise error rate was performed for each region at 5 significance level resultantly the hgbr model was simultaneously better than the lstm and rf models in all regions for both experiments figure 6 presents scatter plots of the predicted peak flow against the observed peak flow for the lstm the hgbr and the rf owing to space constraints only two sampled regions are shown per experiment sections 3 2 1 2 of the supplementary material contains scattered plots for all regions and both experiments fig 6a shows region 17 as having almost similar performance among the three models a trend reflected in the box plot of rmse scores in fig 4 for the said region conversely in region 18 there is greater underestimation of the peaks by the lstm unlike the hgbr and rf models where the pearson correlation coefficient pcc was 0 42 0 89 and 0 85 respectively specifically for region 18 we note wide variability in rmse performance by the lstm see fig 4 there is better correlation between the smaller magnitude flood peaks than the higher flood peaks where underprediction is more likely than over prediction a similar trend is noted for experiment 2 in fig 6b where the three models are comparable for region 17 but the underestimation of flood peaks by the lstm more pronounced for region 5 this large variance is also captured in the boxplot in fig 5 for the said region table s4 1 provides the pcc values for both experiments 1 and 2 for the peak prediction models and the lstm overall the main problematic regions in both experiments for the hgbr and rf with low pcc values were parts of the western and northern central regions which identify with drier climates and have one of the lowest annual precipitation totals across conus potentially explaining the performance of the models for these regions section 4 3 below offers more on understanding the predictors 4 2 evaluation of model performance across peak flow quantiles the preceding discussion looked at performance for models considering all events in the respective datasets all flows scenario now that we have established the predictive abilities of our peak flow models we will turn our attention to addressing the results of mainly the hgbr and rf models considering the flood severity classes namely lm flows and h flows in addition to the prd plots shown in fig 6 a quantile quantile comparison from 1st to 99th quantile is included in fig 7 specific to the hgbr and rf models fig 7a for the hgbr model showed better agreement in predicted peak flow quantiles compared to the rf model fig 7b for both models and for both experiments we noted a tendency towards underestimation a trend pronounced for the h flows scenario the same was true for the all flows scenario but for the low moderate flood severity the rf distinctly overestimated hgbr for lm flows had the closest agreement between the observed and predicted flood peaks with averaged absolute relative difference values of 7 7 and 22 0 for experiments 1 and 2 respectively figure 8 provides regional prd comparisons for lm flows and h flows for the two peak prediction models aside from the lm flows scenario of experiment 1 the hgbr did not have a defined trend of under or over predicting conversely the rf mostly overestimated low moderate flood peaks and underestimated the high flood severity evidently hgbr is the better model for performing consistently across flood severities and further discussion will focus on the results of this model for the ungauged experiment the hgbr seemingly has difficulty for regions 9 11 13 and 16 the last two especially for lm flows 4 3 understanding predictors notwithstanding the relative importance assigned to predictors as a product of using rule based models we only aimed to evaluate the role they play in flood response from one region to another and across differing flow severities fig 9 presents the relative importance of the predictors segmented by static and dynamic predictors for both lm flows a and h flows b attention is focused on the selected hgbr model from the foregoing sections on performance evaluation 4 3 1 dynamic predictors with reference to fig 9 for h flows the dynamic predictors held greater importance at influencing peak prediction compared to the static catchment attributes the opposite was true for lm flows maximum and mean precipitation the relative weights of triggering precipitation were clearly higher for h flows than lm flows but for both severity levels the maximum triggering precipitation having high feature importance implied a strong causal influence on flood peaks analyses of the intensity of the precipitation events as a ratio of the maximum precipitation to the total triggering precipitation of the regions indicated that on average the us northeastern southeastern north central and upper colorado regions had a greater number of h flows that were triggered by short duration intensity dominated storm events than lm flows knowing that flood inducing precipitation and their sources across conus are regionally defined these identified precipitation patterns coincide with for example the recorded higher occurrences of flash type floods in the southeastern region dobur 2006 brought about by short duration high intensity air thunderstorms a consequence of the moisture passages from the gulf of mexico hirschboeck 1991 the presence of tropical storms and cyclone related flood inducing precipitation events that the southeastern us region is susceptible to especially during the warmer late spring and early summer seasons may also justify this trend in addition to convective storms mainly occurring in the late summer early fall seasons the northeastern regions berghuijs et al 2016 are vulnerable to flood inducing precipitation resulting from snowmelt or extra tropical cyclones and their associated fronts vicinity of the atlantic ocean influenced by warmer temperatures the mountainous terrains at 1 the junction of the northeastern and southeastern regions and 2 along the intermountain west regions notably upper colorado are also susceptible to local flash floods resulting from similar convective storms enhanced by orographic lifting the u s north central regions with drier climates and low soil moisture retention capabilities record the lowest magnitude of flood peaks overall with flash type floods classed as h flows being the result of majority short convective precipitation events in the region berghuijs et al 2016 hirschboeck 1991 conversely h flows in other regions whilst being triggered by higher magnitude total precipitation these storm events persisted for a longer duration with one example being the great basin here floods with higher rise times occur in the steep glacial terrain saharia et al 2017 given the influence of snowmelt the reduced importance of precipitation for lm flows point instead to the other drivers see remaining discussion that better support the precipitation to peak flow relationship mean maximum temperature two general regions placed emphasis in addition to or instead of the trend of precipitation as the controlling predictor the northeastern and some parts of the intermountain west regions respectively h flows in the energy limited catchments of the u s northeast are more influenced by temperature indeed the distinct four season climate of the u s northeast has been changing over time with the increasing oceanic and atmospheric temperatures the declining snow and ice density the rising sea levels and strain on the ecosystem and hydrologic systems brought about by heavy urbanization of the region assessment 2018 pan et al 2004 as for the intermountain west regions temperature shares a similar magnitude of importance as precipitation for improving peak flow predictions these regions are more water limited but increasing daily minimum temperatures and increased early summer rainfall which mitigated daily maximum temperatures from rising translated to higher flood peaks recorded kunkel et al 2013 pryor 2013 antecedent precipitation index on average the importance of api was weighted higher for lm flows generally this class of flood severity is not driven by high intensity short duration storms as is most often the case for h flows where the sheer magnitude of runoff generated by the current storm is not affected by preceding precipitation unexpectedly for h flows particularly within the north and central east regions and the west coast the inclusion of api mapped to better peak flow predictions this finding may be rationalized by the influence of snowmelt in the region which increases in the warmer seasons of the year and coincides with the time that most flood peaks are observed high flood peaks but with slow rise time i e not intensity dominated flows for lm flows however the current wetness condition of the catchment as a result of preceding storm events greatly affects the flood response in the catchment and the models particularly for the southern east central and west regions viewed api as an important dynamic predictor as an interface between the extreme precipitation regimes of the eastern and western conus regions given proximity to the atlantic or pacific oceans and gulf of mexico the hydrologic signature in these regions is influenced accordingly by pre event precipitation excess wetness brought about by thunderstorms common in the region during the monsoon periods 4 3 2 static predictors forest fraction for lm flows the relative importance of forest fraction was on average greater in the us west regions than east this trend is best rationalized by placing into perspective the changes in land use over the last few decades alig et al 2003 the northeastern us is deemed a heavily urbanized region therefore we see little to no influence from forest fraction on flood peak prediction instead the south and southwest regions including the west intermountain areas which have seen growing populations especially within the last two decades have recorded decreased fractions in forest cover as the rural to urban shift is made alig et al 2004 kunkel et al 2013 it is within these recently changing regions that the variability of forest cover among catchments heightened and thus played an important role in flood peak prediction especially for low moderate flows conversely the prediction of h flows in the northeastern regions saw heightened importance of forest fraction compared to lm flows deciphering this contrast of forest cover importance per flow magnitude between these regions is not straightforward speculations based on hydrologic reasoning suggest potential differences in precipitation interception dynamics in these regions but a valid answer on this merits subsequent investigation which is not within the scope of this work soil porosity the physics behind soil hydraulic characteristics impacting streamflow response is complex of the catchment attributes related to soil from the camels dataset soil porosity aided better predictions overall relative importance was higher among the lm flows with relatively higher impact in the northern central northern great plains and the intermountain west regions interestingly the total precipitation in these regions was among the lowest of the 18 regions in this study a plausible explanation for the importance of this feature to flood response may be attributed to the presence of wetlands in the areas which lie within the steep glacial moraine uplands verry and kolka 2003 seepage from these saturated bodies of water regulated in part by the soil hydraulic features like soil porosity of the surrounding areas eventually feed to channels causing the higher flood peaks recorded dahl 2014 sucik and marks 2015 an additional explanation may be offered when looking at the weighted importance of this attribute in conjunction with mean pet for those regions which have a drier climate given elevated temperatures surface infiltration rates are higher with increased dried pore space mean pet lm flows in the u s west were more responsive to pet than the u s east fig 9a upon closer observation the intermountain west and pacific regions were the most affected and duly so given their arid steppe and mediterranean like climates respectively the summers for both are especially hot leading to water limited catchments i e with higher pet values as for higher flood severities fig 9b the trend in pet was scattered across the regions but the models for the northeast region saw an unexpected emphasis on the mean pet with annual precipitation in excess of evapotranspiration catchments in the northeastern regions are traditionally categorized as energy limited recent analyses have shown however that opposite to temperature precipitation controls evapotranspiration vadeboncoeur et al 2018 with summer precipitation having the highest correlation with evapotranspiration than summer temperature moreover the interplay between precipitation and evapotranspiration modulates antecedent wetness and can therefore have an important impact on flood response in humid catchments nikolopoulos et al 2011 4 4 flood detector the length of the time series or time window required for the detection of flood inducing storms was obtained experimentally by conducting analyses of varying time lengths 3 to 60 days within each region from roc curves performance was gauged by comparing the hit rate given different window sizes for a 20 false alarm rate the flood detector provided optimal results across the 18 regions with a window size of 30 days the results of which are presented in fig 10 fig 10 also shows the corresponding area under the roc curves auc for the 18 regions see legend the true positive rate tpr or sensitivity is the detector s ability to correctly identify a flood peak event with the exception of three regions tpr 75 all other regions were associated with a tpr above 80 for 20 false detections accounting for the detector s ability to accurately identify flood events all regions recorded auc scores of 88 and higher notably with a window size of 30 days performance from the detector eventually reported the inclusion of api as negligible this is understandable as the construction of this index for the study was based on a 30 day duration precipitation made available to the detector as a time series inherently accounts for antecedent moisture condition with a 30 day window size acknowledging that the actual duration of a flood inducing storm is at the order of one to few days much less than the optimal 30 day window clearly emphasizes the importance of antecedent conditions on the classification of the storms in addition to dynamic variables static catchment attributes were tried as inputs following analyses the impact of catchment attributes on the binary classification of flood inducing storms was not significant wide variability was expected as the region under study changed but given the above discussion on understanding the predictors of flood peaks a sound basis for further exploring and developing this input arm of the flood detector exists to complete the evaluation of the flood detector and our proposed pseudo operational flood warning system we performed a coupled analysis of the flood detector and peak prediction model the hgbr for any positive output from the detector i e a flood warning has been issued we gathered the variables required by the hgbr see section 2 corresponding to the impending flood event and applied the hgbr regional models to predict the magnitude of the flood event fig 11 provides the regional boxplot rmse performance for both experiments 1 a and 2 b of all flood events true or false the detector flagged results were comparable to that of experiment 1 see fig 4 and experiment 2 see fig 5 with the problematic regions coinciding and for the same rationale we offered in sections 4 1 and 4 2 figure 12 provides an example of the operational flow for the proposed flood warning system the example is based on a selected catchment from the generalization dataset id 01073000 located along the oyster river near durham nh region 1 this framework asks two main questions 1 at a time t do we expect a flood and 2 if we are to expect a flood what is the predicted magnitude of the peak following the discussion on the duration number of timesteps of the input required by the detector we first identified the 30 days of precipitation minimum and maximum temperatures and solar radiation before time t see fig 12 top to reiterate on the basic steps of the procedure regarding precipitation and peak flow prediction the flood peak prediction models hgbr were trained based on precipitation peak flow pairs that include precipitation input up to the time of peak flow this was derived from the camels dataset that was used for training when applied in an operational mode indeed we cannot possibly know exactly when a precipitation event should end because we don t know the time of the peak flow in that case our framework followed a stepwise procedure in which when the flood detector identifies that precipitation conditions can generate a flood peak according to our definition we use the triggering precipitation event s start and end time up to the latest available forecasting time step taken again from camels but treated as pseudo forecasts i e as if we don t know what is coming next to extract the relevant meteorological inputs see table s2 2 and issue a prediction for the potential peak flow that corresponds to that triggering precipitation event note that we treat precipitation from camels data as our pseudo forecast because our purpose is to demonstrate how the proposed framework would work under the assumption of having accurate precipitation forecasts i e focus solely on the performance of the framework excluding other uncertainty sources in real world conditions consideration of the uncertainty of quantitative precipitation forecasts and its impact on flood prediction is very important but it is beyond the scope of the current work returning to our example portrayed in fig 12 the hgbr issued a prediction if the detector warned of an expected flood as was the case from may 24 26 2013 among other instances in the next forecasting step precipitation is updated by new forecasted values the detector runs again and if the precipitation signal within the forecasting window remains a flood inducing storm according to the detector we update the peak flow prediction again for comparison the observed streamflow is plotted along with the relevant predicted flood peaks the threshold distinguishing flood peaks is plotted at the 90th quantile streamflow for the catchment from observation false positives issued by the detector are usually within the vicinity of the 90th quantile threshold as seen in fig 12 bottom this is often the case for timesteps just preceding a major flood event june 11 2013 or on the recession limb of the flood hydrograph as flow level drops below the threshold may 29 2013 but there was a short burst of precipitation during this recession period the case noted on june 11 2013 is surmised as an artifact of regional detector modeling where the 90th quantile streamflow rates of catchments within a region are similar but not the same thus a range of uncertainty is present for each catchment within any given region note that as long as the flood inducing storm remained close to forecasted time t the detector identified potential flood conditions even when actual flood was in recession equivalently the hgbr model kept providing peak flow predictions that were close in magnitude as a reminder this framework was developed to provide peak flow prediction whenever a flood was imminent and was not intended to predict the shape of the flood hydrograph as such the most appropriate use of such system should be to provide expected max flood conditions during the entire period of the detected flood event the duration of such an event can be derived from the flood detector 5 conclusions and future directions a ml based framework that addresses the detection of flood inducing storms and the prediction of flood peak magnitudes was developed and presented model training and validation were completed for 18 hydroclimatic regions across conus it was demonstrated that ml models such as rf and hgbr are suitable for predicting flood peaks at ungauged basins using a relatively small number of inputs specifically derivatives of precipitation and temperature time series together with catchment attributes such as soil porosity pet and forest fraction provided enough information to achieve flood peak predictions with less than 30 prd in most regions across conus hgbr performed overall better than rf and both of them performed relatively better in the majority of hydroclimatic regions than a state of the art lstm that was used for comparison to a certain degree this is to be expected considering that rf and hgbr were developed solely for flood peak prediction while the lstm was originally developed for predicting the entire flow spectrum this fact therefore does not point necessarily to the best model but simply highlights that if having a skillful model for flood prediction is the objective then it is preferable to develop predictive models only for flood events to avoid stretching them to accurately predict parts of the flow timeseries that may not be of importance for the lstm it was shown that due to the latter predictions for flood peaks were generally underestimated the relative simplicity of rule based models such as rf and hgbr combined with their level of interpretability make them an attractive solution for developing predictive models in hydrology through analysis of the relative feature importance it was shown that the factors influencing the generation of floods exhibit a strong regional dependence whilst precipitation derived variables such as the maximum precipitation triggering a flood peak was found to control flood response significantly in most regions catchment specific attributes considering land cover forest fraction soil hydraulic features soil porosity and potential evapotranspiration also impact and improve the prediction of flood peaks notably the impact of these highlighted drivers varied in response to the flood severity classes with catchment specific attributes showing a higher degree of importance in the prediction of low moderate flows than for high flows where instead precipitation dominated flood response the dimension of seasonality was not considered but previous research posits the ability to increase streamflow prediction the inclusion of this dimension could potentially help to explain the residual behavior of the models in some regions such as those along the northwest coast and upper northern regions of conus where precipitation regimes are unique machine learning based algorithms hold much potential for advancing flood predictions in ungauged catchments and therefore inform decisions on mitigation strategies for flood hazard our attempts at proactively dealing with the rise in extreme natural hazards have been focused on implementing and improving early warning systems in this work we propose a prototype flood warning system that combines a flood detector and the flood magnitude predictor the detector based on a lstm is able to monitor meteorological conditions and issue warnings in case of an imminent flood which subsequently triggers the peak prediction model hgbr that predicts the magnitude of the expected flood peak such a framework combined with remote sensing and numerical weather predictions can offer a potential solution for flood warning applications in areas where in situ observations are sparse or inexistent results from this work demonstrated that in all areas examined such a system would achieve a hit rate of 80 for 20 false detections and while this recommends that there is definitely room for improvement at the same time demonstrates arguably a lot of promise moving forward there are several steps that can be taken to further advance ml based flood prediction and the development of warning procedures first of all integration of higher spatial and temporal variability of features considered is one important step towards advancing model development so far this and many other studies have used daily forcing data and catchment averaged values while we know that dynamics of sub daily precipitation as well as its spatial distribution over a catchment affect flood response therefore incorporating such information should be included in subsequent developments also the choice of api for characterizing antecedent wetness has limitations crow et al 2009 tramblay et al 2012 and thus can be improved by considering additional sources of soil moisture information e g from satellite based sensors massari et al 2014a b lastly the transferability of the models produced in this and other works based on camels dataset should be evaluated globally by other similar datasets that have been recently developed alvarez garreton et al 2018 coxon et al 2020 credit authorship contribution statement zimeena rasheed data curation formal analysis writing original draft akshay aravamudan software validation writing review editing ali gorji sefidmazgi software georgios c anagnostopoulos methodology supervision writing review editing efthymios i nikolopoulos conceptualization funding acquisition supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank dr frederic kratzert for sharing via github the lstm code used in kratzert et al 2019 rasheed and nikolopoulos were supported by the national science foundation united states under grant no 1934712 we would like to acknowledge high performance computing support from cheyenne doi 10 5065 d6rx99hx provided by ncar s computational and information systems laboratory sponsored by the national science foundation rasheed and aravamudan acknowledge partial support by an fit college of engineering sciences institutional research incentive seed grant appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127736 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
