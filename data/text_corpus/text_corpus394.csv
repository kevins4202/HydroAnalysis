index,text
1970,disturbances in tropical peat swamp forests greatly impact water transport into the atmosphere through evapotranspiration et however transpiration t and evaporation e are affected by disturbances in different manners based on eddy fluxes and meteorological data we used three methods to estimate t and e separately at three tropical peat swamp forest sites with different degrees of disturbance each method utilizes the i water use efficiency ii linear relationship between et and gross primary production and iii conductance of t and e in each the results showed that the conductance method was the most reasonable for estimating t and e the other two methods could not be applied because of the large variance in the water use efficiency and lack of a strong relationship between et and gross primary production among other reasons inter site comparisons suggested that lowering the groundwater level gwl reduced t but t subsequently recovered this was likely because the trees acclimated to the dry environment there was no clear difference in e among the three sites under conditions of lower gwls the mean t et in the almost undisturbed forest 0 60 was greater than that at the burned site with sparse vegetation 0 21 overall el niño events decreased both t and e during the dry season at all sites in the almost undisturbed forest t and e decreased by 1 14 and 0 27 mm day 1 respectively during el niño events precipitation decreased to near zero fire sizes increased and the downward photosynthetic photon flux density decreased the decreases in t and e were mainly due to attenuation of incoming radiation by the fire induced haze in addition significant soil desiccation due to lowered gwl impaired root water uptake resulting in decreased t in addition e was decreased by soil surface drying however the direct effect of further atmospheric drying on e and t was small during the dry season our results show that both drainage and el niño events reduced t and e in different manners abbreviations gwl groundwater level et evapotranspiration t transpiration e evaporation soi southern oscillation index uwuep potential underlying water use efficiency uwuea apparent underlying water use efficiency uwuedry underlying water use efficiency under extremely dry condition gsoil soil conductance gveg canopy conductance keywords drainage el niño evapotranspiration partition method groundwater level haze southeast asia data availability no data was used for the research described in the article 1 introduction tropical peat swamp forests are widely distributed in insular southeast asia and function as large carbon reservoirs e g dommain et al 2011 jaenicke et al 2008 page et al 2004 tropical peat swamp forests have existed for many years and have maintained a high groundwater table in recent decades land conversion has expanded mainly for agricultural land use particularly for palm oil plantations for example in 2001 2017 the forest area in borneo decreased by 14 6 04 mha whereas the plantation area increased by 170 6 20 mha gaveau et al 2019 when preparing land to install plantations drainage channels are typically excavated to lower the groundwater level gwl these activities have led to environmental concerns as lowering of the gwl can dry the soil and result in the release of large amounts of co2 because of peat decomposition moreover soil drying increases the risk of fire and large fires attenuate incoming solar radiation by generating haze for example large scale fire events occurred during the extremely dry conditions of strong el niño events in 2015 these fires caused thick smoke to cover much of sumatra and kalimantan with the haze extending to singapore malaysia and thailand field et al 2016 according to cai et al 2014 2015 the frequency of extreme el niño la niña events will continue to increase with climate change causing major disturbances however the effects of el niño la niña events on evapotranspiration et which plays an important role in the water balance in tropical peat swamp forests are not well understood in southeast asia et and precipitation levels are relatively higher than those observed on a global scale therefore disturbances significantly impact the quantitative changes in et kobayashi et al 2015 wang et al 2012 long term continuous observations using the eddy covariance ec technique can be used to evaluate the effects of disturbances on et and is widely used to examine terrestrial ecosystems two studies on et in tropical peat swamp forests were conducted in central kalimantan indonesia using the ec technique over long periods of time hirano et al 2015 measured et for 4 6 years and observed seasonal variations linked to net radiation r n changes which were significantly influenced by the dense haze caused by large fires in addition they showed that et decreased as the gwl decreased with drainage ohkubo et al 2021c continued observations at the drained burnt site for approximately 13 years during which fires and nearby ditch excavation occurred they confirmed that et was strongly positively correlated with r n and positively correlated with vapor pressure deficits vpds of 20 hpa they also attributed the decrease in et under conditions of precipitation et and gwl 0 5 m to a decrease in transpiration t because of reduced root water uptake in addition under waterlogged conditions an increased vpd decreased t because of partial stomatal closure of plants although this effect was compensated by increased evaporation e from the free water surface however these assumptions were not based on observations of t and e leading to uncertainty in the results furthermore et measurements using the ec technique have recently been performed in peatlands e g gunawardhana et al 2021 morison et al 2020 volik et al 2021 and tropical forests e g kuricheva et al 2021 uuh sonda et al 2022 von randow et al 2020 in these studies data from long term continuous observations were used to evaluate seasonal and annual changes by examining how environmental factors affect et however the ec technique cannot directly measure t and e in dominant tropical peatland species t is typically regulated by physiological factors such as plant stomatal behavior which is controlled by the leaf water status whereas e is determined by physical environmental factors such as the soil surface moisture and atmospheric dryness thus responses to environmental changes generally differed between t and e various methods have been used to evaluate t or e based on the sap flow velocity thermography and isotope ratios stoy et al 2019 other methods use eddy fluxes and meteorological data and have the advantage of being able to evaluate t and e over a long period under varying environmental conditions using the linear relationship between gross primary production gpp vpd0 5 and et named as the water use efficiency wue method zhou et al 2016 found that t et was largest in croplands followed by that in grasslands and forests additionally the enhanced vegetation index evi and t et were strongly correlated in deciduous forests scott and biederman 2017 evaluated t by assuming that t and gpp have a linear relationship named as the lr method they found that this method is applicable to water limited locations they observed that t et peaked in summer with an increasing gpp and leaf area index and decreased with an increasing number of rainy days in shrubland savanna and grassland in southern arizona eichelmann et al 2022 applied data from four restored wetlands using the lr method their estimated t values agreed well with the evaluated t values using an artificial neural network during winter they also found that t increased during the growing season li et al 2019 used the conductances t and e named as the conductance method and found that t et in evergreen needleleaf forests was larger than that in cropland and grassland in addition t et tended to increase as the leaf area index increased at all sites although some studies using wue lr and conductance methods have shown reasonable results these methods are unsuitable in several cases for example in the wue method the presence of multiple vegetation types at a site violates the assumption of constant wue in the lr method linear regression fails when the data are not within an appropriate range an insufficient amount of data leads to uncertainty in the parameters obtained from nonlinear regression because the number of studies using wue lr and conductance methods are limited their usefulness should be verified on a case by case basis in this study we evaluated the influence of drainage and el niño la niña events on t and e in tropical peat swamp forests using eddy flux and meteorological data three methods wue lr and conductance methods were applied to evaluate and validate t and e based on the derivation process the most appropriate method was used to determine the final t and e for analysis t and e were estimated at three sites with varying degrees of disturbance the impact of disturbances on t and e was evaluated using time series variations relationships with environmental factors and inter site comparisons 2 materials and methods 2 1 site description the three study sites were in peat soils within 15 km of central kalimantan indonesia and exhibited different disturbance levels hirano et al 2012 2015 the sites were a slightly drained peat swamp forest uf site 2 32 s 113 90 e drained peat swamp forest df site 2 35 s 114 04 e and burned degraded swamp forest db site 2 34 s 114 04 e ohkubo et al 2021a in 2002 2018 the mean air temperature above the forest canopy was 26 2 c with little seasonal variation the mean annual precipitation was 2565 mm and the dry season is typically from july to october the uf site was selectively logged until the late 1990 s although small canals were excavated for logging they have remained relatively untouched since being designated as national parks in 2006 the dominant species were evergreen broad leaved trees with rich shrubbery in june 2006 the canopy height and plant area index were 23 m and 5 0 m2 m 2 respectively defoliation occurred at the end of the dry season hirano et al 2015 similar to at the uf site the df site was selectively logged a large canal was excavated in 1996 1997 for use as a drainage system in june 2006 the canopy height and plant area index were 26 m and 5 6 m2 m 2 respectively the dominant species were the same as those found at the uf site hirano et al 2015 the db site was a degraded swamp forest with drainage and repeated fires the site suffered a stand replacing fire in 2002 and burned again in 2009 and 2014 the site was drained using a nearby ditch that was excavated in 2014 the dominant vegetation transitioned from ferns and sedges to young trees after the 2002 fire the details of these three sites have been described by hirano et al 2015 and ohkubo et al 2021a 2 2 measurements field experiments were conducted from july 2004 to december 2018 at the uf site july 2001 to june 2017 at the df site and april 2004 to december 2016 at the db site according to the disturbance events the db site measurement period was separated into three periods april 2004 to september 2009 i december 2009 to june 2014 ii and july 2014 to december 2016 iii ohkubo et al 2021b r n was measured using a radiometer cnr 1 kipp zonen delft the netherlands and the downward photosynthetic photon flux density ppfd was measured using a quantum sensor li 190s li cor lincoln ne usa at heights of 36 3 40 6 and 3 3 m at the uf df and db sites respectively at the db site the height increased to 6 8 m in march 2012 and 13 m in december 2013 because of vegetation growth the air temperature and relative humidity were measured using a platinum resistance thermometer and capacitive hygrometer hmp45 vaisala helsinki finland at heights of 36 3 41 7 and 1 5 m at the uf df and db sites respectively precipitation was measured using a tipping bucket rain gauge te525 campbell scientific logan ut usa at heights of 36 3 41 0 and 1 5 m at the uf df and db sites respectively meteorological data were recorded every 30 min using a data logger cr10x or cr1000 campbell scientific gwl was measured every 30 min using a water level logger dl n sensor technik sirnach ag sirnach switzerland or dcx 22 vg keller ag winterthur switzerland at the three sites a water level logger was installed at one location in the hollows within 5 m of the observation tower at each site the data were corrected to obtain the relative distance to the ground surface using occasional on site measurements to remove the effect of peat subsidence the eddy fluxes of co2 sensible heat h and latent heat λe were measured using the ec technique with a sonic anemometer thermometer csat3 campbell scientific and an open path co2 h2o analyzer li7500 li cor at 36 5 41 3 and 3 0 m at the uf df and db sites respectively at the db site the height increased to 3 6 m in february 2011 7 2 m in march 2012 and 13 6 m in december 2013 because of vegetation growth the sensor signals were recorded using a datalogger 8421 hioki e e corp ueda japan or cr1000 campbell scientific at 10 hz the change in co2 storage below the eddy sensors was calculated every 30 min from the co2 concentrations at six heights measured using a co2 analyzer li800 or li820 li cor the details have been described by hirano et al 2012 2015 and ohkubo et al 2021b 2 3 flux calculation the half hourly fluxes of co2 h and λe were calculated using flux calculator software ueyama et al 2012 with the following procedures 1 removal of noise spikes vickers and mahrt 1997 2 double rotation for tilt angles 3 correction for high frequency loss massman 2000 massman 2001 and 4 correction for air density fluctuations webb et al 1980 for quality control flux data with wind directions where the tower caused flow distortion were removed rainfall data were excluded from analysis net ecosystem exchange nee was calculated as the sum of eddy co2 flux and co2 storage change to prevent underestimation of the nighttime nee ppfd 20 μmol m 2 s 1 the change point method barr et al 2013 was applied using the standard deviation of the vertical wind speed σw rather than the friction velocity acevedo et al 2009 outliers in nee h and λe were removed using the smirnov grubbs test for nighttime and daytime a stationarity test was also applied for each half hour flux foken and wichura 1996 further information has been described by ohkubo et al 2021b nee was partitioned into ecosystem respiration re and gpp using the lookup table method nighttime nee which is regarded as re was binned equally into seven classes according to the gwl lookup tables were created annually by averaging the binned re data and gwl for each class gpp was calculated as the difference between nee and daytime re estimated from the gwl using the lookup tables the gaps in all flux data were filled using the marginal distribution sampling method reichstein et al 2005 except for the nighttime nee re data which were filled using lookup tables gwl was added as an environmental variable along with air temperature and vpd with the acceptable deviation set to 0 2 m as a radiation condition a downward ppfd of 100 μmol m 2 s 1 was used rather than using r n 50 w m 2 et was calculated from the adjusted λe after h λe was forced to balance with r n daily using the bowen ratio of daily h and λe twine et al 2000 ohkubo et al 2021c this approach was adopted because changes in heat storage in the soil and canopy were not measured the daily integrated values of changes in heat storage are expected to be zero because there is little seasonal variation in the air and thus in the soil temperature at our study sites the mean 1 standard deviation of the daily ratio of eddy energy flux h λe r n was 0 95 0 22 0 84 0 18 and 0 82 0 12 at the uf df and db sites respectively 2 4 additional data the evi from moderate resolution imaging spectroradiometer data was used as a proxy for aboveground biomass anaya et al 2009 huete et al 2002 sixteen day composite evi data with a spatial resolution of 250 m were downloaded from the land processes distributed active archive center https lpdaac usgs gov products mod13q1v006 the respective pixel data enclosing the three sites were used if the quality was greater than or equal to useful southern oscillation index soi data were used as indicators of el niño and la niña events the soi was negative during an el niño event and positive during a la niña event monthly soi data were collected from the national oceanic and atmospheric administration https www ncdc noaa gov teleconnections enso indicators soi the aerosol optical depth was used as an indicator of the attenuation of solar radiation caused by haze the aerosol optical depth was measured using a photometer at a height of 27 m at the palangkaraya aeronet site 2 23 s 113 95 e which was approximately 11 km from the uf site and 16 km from the df and db sites the data were downloaded from the aeronet database https aeronet gsfc nasa gov new web aerosols html which became available on july 19 2012 data categorized as the highest quality level 2 0 cloud cleared and quality assured were used for analysis the date and location of the fire spots were downloaded from the fire information resource management system https firms modaps eosdis nasa gov 2 5 partitioning approaches we applied the following three methods table s1 to partition et into t and e we first calculated t after which e was determined as a residual 2 5 1 wue method the wue method is based on the linear relationship between gpp vpd0 5 and et zhou et al 2016 daytime half hourly data were used data during and after rainfall were removed to exclude the interception of evaporation the removal time after rainfall was determined as described by zhou et al 2015 the accumulated precipitation over the past 24 h was calculated and the time of removal was determined according as the ratio of the accumulated potential et over the same period zhou et al 2015 this method assumes that e becomes zero when the ratio of gpp vpd0 5 et is ranked in the top 5 of the dataset thus the 95th percentile of gpp vpd0 5 et was defined as the potential underlying wue uwuep95 which was determined for the whole period at the uf and df sites and the i ii and iii periods at the db site the 90th percentile of gpp vpd0 5 et uwuep90 was also calculated and the apparent underlying wue uwuea was determined via linear regression of gpp vpd0 5 and et linear regression was also applied for datasets with gwl 1 5 m where the soil surface was so dry that e was assumed to be negligible to determine the uwue under extremely dry soil conditions uwuedry at the df site and in period iii at the db site where the data could be obtained t was calculated for every 30 min using the following equation 1 t gpp vpd 0 5 uwue where uwue is uwuep95 uwuep90 or uwuedry 2 5 2 lr method the lr method is based on a linear relationship between the monthly t and gpp scott and biederman 2017 t gpp was determined as the slope of the regression between the monthly values of et and gpp and the intercept was e according to precipitation seasonality regression was conducted quarterly from february to april may to july august to october and november to january to determine t gpp t was calculated monthly as the product of the measured gpp and regression slope t gpp to perform regression with more data linear regression was conducted using daily values for each month to calculate the daily t 2 5 3 conductance method this method li et al 2019 uses the following conductance equation 2 g s g soil g veg 3 g soil g 0 4 g veg g 1 gpp vpd l m 5 vpd l γ λ e ρ c p g s where g s g soil and g veg are the ecosystem soil and canopy conductance mol m 2 s 1 respectively g soil and g veg denote the conductance for e and t g 0 mol m 2 s 1 g 1 kpam mol μmol 1 and m are fitting parameters vpdl is the leaf level vpd at the ecosystem scale g s was calculated using the following inverted penman monteith equation by replacing r n g soil heat flux with h λe because g was not available hirano et al 2015 6 g s γ g a λ e δ h λ e ρ c p g a v p d δ γ λ e where γ is the psychrometric constant kpa k 1 g a is the aerodynamic conductance m s 1 δ is the slope of the saturated vpd curve kpa k 1 ρ is the air density kg m 3 and c p is the specific heat of air j kg 1 k 1 and vpd is measured in units of kpa the units of g s m s 1 were converted to mol m 2 s 1 using the ideal gas law the parameters were determined by curve fitting among g s gpp and vpdl using daytime half hourly data for five to seven gwl classes depending on the range of the gwl data from during and within 6 h of rainfall were excluded to remove the interception of evaporation finally the half hourly t was calculated from the et g soil constant and g veg eq 4 of the corresponding gwl classes eq 7 7 t e t g veg g soil g veg the method has been described in detail by li et al 2019 3 results 3 1 seasonal variations in measured and additional variables seasonal variations in the measured field data and additional data are shown in fig 1 and fig s1 respectively the overall trend across all sites focusing on the dry season july october when the soi was negative showed that precipitation was extremely low vpd increased gwl decreased and many fire spots were near each site in addition the aerosol optical depth was increased and ppfd was decreased the decrease in ppfd was prominent in 2015 when the monthly ppfd was lowest at all sites which was 56 64 lower than the mean ppfd in october of other years the gwl at the df site was lower than that at the uf site throughout the observation period at the db site the gwl remained high until ditch excavation in 2014 because the soil surface was burned by fire before the observation started and the ground surface level was sufficiently low to maintain waterlogged conditions however the gwl decreased after ditch excavation and never returned to the ground surface level ohkubo et al 2021a the number of fire spots around the df and db sites was higher than that around the uf site the closest fire spot from the db site was 0 19 km in 2009 which is consistent with the fact that the db site experienced severe fire damage ohkubo et al 2021bc at the db site the evi decreased in 2002 when there was a large amount of fire damage and the evi slightly and gradually increased after the fires in 2002 2009 and 2014 no notable changes were observed during other periods or at other sites 3 2 derivation process and comparison of methods 3 2 1 wue method the uwuea at the forest sites uf and df was greater than that at the db site fig s2 and table s2 the uwuea in period iii was larger than that in periods i and ii at the db site uwuep95 at forest sites was more than twice as large as those at db sites uwuedry was less than half of uwuep95 at the df site and in period iii at the db site 3 2 2 lr method in the seasonal regression analysis using monthly values significant regression was found in the dry season august october at all sites but was not observed during other seasons and at other sites fig s3a and table s3 r 2 for the dry season was generally higher than those for the other seasons at all sites at the df site where significant regression was observed in all seasons the maximum regression slope was approximately five fold the minimum value indicating wide seasonal variation in the slope however most of the monthly linear regression was significant except for that in may july in period i at the db site fig s3b and table s3 whereas r 2 for the monthly regression did not improve compared to that for the seasonal regressions 3 2 3 conductance method g soil tended to decrease with decreasing gwls fig 2 a the scale of the horizontal axis differed among sites and periods depending on the measured gwl ranges for the db site the average gsoil in a gwl range of 0 4 gwl 0 m decreased over time period i period ii period iii note that the gwl bin section differed between periods in fig 2a in period iii g soil was close to 0 mol m 2 s 1 in the range of 0 8 gwl 0 6 m the g veg of the uf site was larger than that of the df site at a gwl 0 6 m but was smaller in the range of 1 0 gwl 0 6 m uf data not shown in this range fig 2b with decreasing gwl g veg decreased at a gwl 0 1 m at the uf site and gwl 0 6 m at the df site at the uf site gveg at 0 1 gwl 0 m and gwl 0 m were significantly p 0 01 smaller than gveg at 0 2 gwl 0 1 m the g veg values of the forest sites uf and df were higher than those of the db site at the db site the average gveg in the gwl range of 0 4 gwl 0 m increased over time period i period ii period iii note that the gwl bin section differed between periods in fig 2b in contrast to the behavior of gsoil over the same gwl range 3 2 4 comparison of estimated t the time series of the estimated t values was compared to evaluate the performance of the methods fig s4 the mean t calculated using uwuep95 and uwuep90 were 0 80 and 1 45 mm day 1 at the uf site and 0 72 and 1 30 mm day 1 at the df site respectively the mean t determined using uwuep95 was 1 8 fold greater than that determined using uwuep90 at both sites at the db site the estimated t using uwuep95 and uwuep90 frequently exceeded the et particularly in period ii using uwuedry t occasionally exceeded et at the df site and always exceeded et during period iii at the db site t calculated using the lr method showed periodic and large seasonal variations at all sites and occasionally exceeded the et t estimated using the conductance method varied within the range of et because of its derivation process 3 3 partition of et into t and e as discussed in section 4 1 3 the conductance method showed the most reasonably explainable results thus the results calculated using the conductance method are presented fig 3 shows the monthly variations in t and e both t and e decreased sharply in 2006 2009 2014 and 2015 when strong el niño events significantly decreased the gwl at the uf site t tended to be larger and e tended to be smaller than those at the df site whereas et was similar throughout the experimental period fig 1 the mean monthly t and e from august 2004 to december 2016 the common period of available data at the three sites were 2 47 and 1 63 mm day 1 at the uf site and 2 06 and 1 95 mm day 1 at the df site respectively table s5 the monthly t and e values at the uf and df sites were significantly different p 0 001 at the db site t increased with vegetation recovery after the fire in 2009 whereas e decreased the mean t et was 0 60 at the uf 0 51 at df 0 21 in period i 0 40 in period ii and 0 60 in period iii at the db site table s5 the annual t and e for the years ranged from 735 to 1029 and 515 to 653 mm year 1 for 2005 2018 at the uf site 618 to 827 and 601 to 797 mm year 1 for 2002 2016 at the df site and 187 to 937 and 506 to 1201 mm year 1 for 2005 2016 at the db site table s6 3 4 relationships of t and e with environmental factors to determine the impact of drainage el niño induced drought and fire the relationships between t and e ppfd gwl and vpd were examined figs 4 6 a significant p 0 001 positive linear relationship was observed for t and e with ppfd at all sites fig 4 at the db site in period iii grouped plots were observed around e 0 mm day 1 the regression slope of t at the uf site 0 058 kgh2o mol 1 was larger than that at the df site 0 048 kgh2o mol 1 at the db site the slope increased with vegetation recovery period i 0 018 kgh2o mol 1 ii 0 034 kgh2o mol 1 iii 0 067 kgh2o mol 1 in contrast the slope of e was largest in period ii at the db site 0 071 kgh2o mol 1 during periods i and ii e was larger under waterlogged conditions blue at the same ppfd which was not the case at the uf site t peaked at different gwl among sites fig 5 the peak gwl estimated using quadratic regression was 0 66 m at the df site which is lower than those at the other sites e decreased linearly as gwl decreased at gwl 0 11 m period i of db gwl 0 56 m df and gwl 0 89 m uf the rate of the decrease in e relative to the decrease in gwl was largest during period i at the db site at 2 24 mm day 1 m 1 in period ii no clear trend was observed because of the narrow range of the variation in the gwl in period iii at approximately 0 8 gwl 0 6 m t increased and e decreased large scale artificial drainage would lower the gwl over a wide area we estimated the drainage impact on t and e by assuming that the lowered gwl is the typical gwl 0 85 0 60 m at an oil palm plantation which is the main type of converted agricultural land dislich et al 2017 the mean of t and e under 0 85 gwl 0 60 m were 1 90 and 1 90 mm day 1 at the uf site 2 44 and 1 84 mm day 1 at the df site and 0 98 mm and 1 86 mm day 1 in period i at the db site respectively compared to the maximum t 2 68 mm day 1 of the regression curve at a gwl 0 20 m at the uf site the mean t under 0 85 gwl 0 60 m decreased by 0 78 mm day 1 at the uf site 0 24 mm day 1 at the df site and 1 70 mm day 1 in period i at the db site respectively in contrast under 0 85 gwl 0 60 m the mean e at the df and db period i sites only slightly differed from the mean e at the uf site the relationships between t e and vpd are shown in fig 6 commonly used logarithmic regression was applied to evaluate each site e g ewers et al 2002 luo et al 2016 overall t increased with increasing vpd but gradually plateaued at a high vpd range in contrast t and e showed no significant correlation with evi r 0 18 0 46 at all sites 3 5 relationship of t and e with soi the relationship between soi and environmental factors precipitation vpd ppfd number of fire spots and gwl is shown in fig 7 no clear relationship was observed on a monthly scale however some relationships were observed during the dry season july october during the dry season there was a positive relationship r 0 68 between precipitation and soi when soi 0 however precipitation was consistently low when soi 0 fig 4 also during the dry season vpd was negatively correlated with soi for all soi ranges r 0 62 ppfd decreased significantly as the soi changed from 1 to 2 and ppfd around soi 2 was smaller than that for 1 soi 1 the number of hotspots increased significantly as the soi decreased for soi 0 whereas no hotspots were detected when soi 0 gwl was positively correlated with soi in the dry season at all sites fig 7b however in period iii at the db site the gwl decreased when soi 0 and deviated from this trend the relationship between t e and the soi is shown in fig 8 during the dry season t generally decreased with as the soi decreased to 0 whereas little change was observed at soi 0 the mean t for 2 soi 1 was decreased by 1 14 mm day 1 at the uf site 0 96 mm day 1 at the df site 0 37 mm day 1 in period i at the db site and 1 78 mm day 1 in period iii compared to those for soi 0 table s4 in contrast e generally decreased with decreasing soi for soi 0 but this trend was not observed in period iii at the db site compared to the mean e for soi 0 that for 2 soi 1 was decreased by 0 27 mm day 1 at the uf site 0 75 mm day 1 at the df site and 1 37 mm day 1 in period i at the db site 4 discussion 4 1 evaluation of methods 4 1 1 wue method uwuea gc hpa0 5 kgh2o values at the forest site used in this study uf 7 65 df 6 56 table s2 were similar to those in tropical evergreen broadleaf forests in brazil 7 00 and french guiana 7 85 gan et al 2021 uwuea values at the db site 3 80 5 29 were smaller than those at our forest site one possible reason for the smaller uwuea at the db site is the presence of a free water surface with sparsely distributed vegetation particularly during periods i and ii the uwuea in period iii when vegetative growth was more advanced was greater than that during periods i and ii supporting this possibility in other words e is large and significantly increases et resulting in a small uwuea compared with the average uwuep95 gc hpa0 5 kgh2o in croplands deciduous broadleaf forests evergreen needle leaf forests and grasslands 12 48 13 40 reported by zhou et al 2016 the values in our forest sites uf 43 08 df 39 57 were much larger and uwuep90 values gc hpa0 5 kgh2o uf 23 84 df 21 92 were also larger table s1 if et was calculated using the unadjusted λe without energy balance correction the estimated et would have been smaller leading the estimated uwuep95 at the forest sites uf and df to be larger than the adjusted values thus the difference from the estimated values reported by zhou et al 2016 was larger one possible reason for the large uwuep95 at this site is the wide variance in the data and the top 5th percentile of the datasets showed higher values than those with the same mean and smaller variance for the same reason t was highly dependent on the number of percentile values of gpp vpd0 5 et as demonstrated by the large difference in the estimated t with uwuep95 and uwuep90 at df and in period iii at the db site in their time series variations fig s4 however there is no established method for determining a reasonable percentile value for example ma et al 2020 reported that the 80th percentile was most appropriate for oak grass savannah and not the 95th percentile used by zhou et al 2016 moreover the values of uwuep95 and uwuedry greatly differed therefore the top few percentile data cannot be considered as being in an environment in which e can be ignored thus the wue method cannot be applied to this study site to separate t from et 4 1 2 lr method in seasonal regressions significant regression and higher r 2 compared to those in other seasons were typically observed in the dry season august october at all sites our results are supported by those of eichelmann et al 2022 who showed that the lr method is not applicable in flooded environments where the contribution of e is large this is because et and gpp are not strongly related in non water limited environments law et al 2002 thus the lr method can only be applied in the dry season in our peat swamp ecosystem in contrast r 2 did not improve even when the amount of data was increased using daily values although significant regression was observed in most cases this result indicates that our regression failed because it was applied to the flooding environment rather because of a lack of data a large interseasonal difference in the regression slope was observed at the df site this result was manifested in the periodic and large seasonal changes in the time series variation of t at all sites fig s4 indicating that the regression slope significantly affects t nevertheless the r 2 value of the regression was unsatisfactory indicating that this method is not suitable for estimating t if et was calculated using unadjusted λe without energy balance correction the slope of the regression of gpp on et would decrease and the r 2 value of the regression and seasonality of the regression slope would be unaffected 4 1 3 conductance method the clear decreasing trend in g soil with decreasing gwl in period i at the db site reflects that much of the wet soil surface is exposed to the atmosphere and the soil surface dries quickly as gwl decreases fig 2a within the comparable range of 0 4 gwl 0 m at the db site the decrease in g soil over time period i period ii period iii can be explained by the decrease in the exposed soil surface area with flourishing vegetation one possible reason for the near zero g soil in the bin of 0 8 gwl 0 6 m in period iii at the db site is the mixed data from the 2014 fire as this fire was not severe the top of the standing trees remained green whereas the understory was burned ohkubo et al 2021b thus the extreme dryness of the soil surface layer regardless of the gwl may have affected the parameter fitting at the df site we began to detect the effect of soil drying on g veg with decreasing gwl at lower gwl and g veg was larger at 1 0 gwl 0 6 m compared to those at the uf site uf data not shown in this gwl range fig 2b this may be because of acclimation of the trees after several years of exposure to a dry environment for example karimi and ehterami fini 2021 reported that pre exposure of walnut trees to soil drying conditions resulted in higher t values than those of control plants under subsequent drought conditions in contrast g veg decreased at the uf sites with gwl 0 1 m fig 2b and stomatal conductance was decreased under waterlogged conditions in many plants rodríguez gamir et al 2011 schmull and thomas 2000 soleh et al 2018 terazawa et al 1992 xiao and jespersen 2019 these results support that waterlogged conditions are a stressor for tree transpiration at this study site g veg at the forest sites uf and df was higher than g veg at the db site this result also explains the increasing g veg with vegetation transition approaching the forest over time at the db site however the estimated t was consistently smaller than et showing plausible time series variation at all sites fig s4 although the energy balance corrections to h and λe in eqs 5 and 6 may have some effect on gveg gsoil gveg in eq 7 the increase in et with increasing λe would have a greater impact on t when using the value of et without energy balance correction both t and e would be approximately 0 95 0 84 and 0 82 fold the adjusted values for the uf df and db sites respectively however the presence of energy balance correction is not expected to strongly influence the time series changes or relationships with environmental variables we found that the conductance method is appropriate for evaluating this study site based on the results showing that g soil increased as vegetative cover increased g veg in a dry soil environment was greater at the df site than at the uf site because of acclimation g veg decreased because of waterlogging stress g veg at the forest site uf and df sites was larger than that at the db site and the estimated t showed plausible variation 4 2 evaluation of calculated t and e the annual t at our forest sites uf 735 1029 mm year 1 df 618 827 mm year 1 table s6 tended to be lower than that in other tropical rain forests 885 1285 mm year 1 bruijnzeel 1990 calder et al 1986 kumagai et al 2005 kume et al 2011 leopoldo et al 1995 in contrast e at the studied forest sites uf 515 653 mm year 1 df 601 797 mm year 1 tended to be larger than that in other tropical rain forests calder et al 1986 595 mm year 1 kumagai et al 2005 352 mm year 1 unlike other forest sites the wetter soil characteristics with a high gwl at the forest sites were evident in the relatively larger e and smaller t in contrast the annual t and e for one year in which data were available in period i at the db site t 187 303 mm year 1 e 791 1201 mm year 1 table s6 were similar to those obtained at the tules and cattail dominated wetland sites with 45 vegetation cover t 300 mm year 1 e 1100 mm year 1 eichelmann et al 2022 compared with these t and e values larger t and smaller e values were observed in period iii at the db site t 695 937 mm year 1 e 506 518 mm year 1 and the tule and cattail dominated sites with 97 vegetation cover t 700 800 mm year 1 e 200 300 mm year 1 the estimated t and e values agreed well with values reported previously the decrease in t during fire in the time series variation fig 3 was mainly due to the decrease in ppfd associated with haze impaired root water uptake due to an excessively low gwl may be an additional reason for the decrease in t the decrease in e may be related to the decrease in available water for evaporation as soil drying exceeded the effect of increased driving force for evaporation owing to the increase in the water vapor concentration gradient t was larger at the uf site possibly because the trees had greater access to water with a higher gwl whereas e at the df site was larger possibly because it compensated for the smaller t to respond to the atmospheric demand for water fig 3 table s5 the mean et values were similar for the uf site 4 10 mm day 1 and df site 4 02 mm day 1 at the db site t was increased after the fire in 2009 because of the increase in aboveground biomass fig 3 the decrease in e have resulted from the decrease in the exposed soil surface area associated with vegetation recovery e was also decreased in the middle of 2014 because of the lowered gwl due to ditch excavation the results showing a greater t et in forests than in grasslands table s5 are similar to those reported by li et al 2019 however compared with the t et during the growing season in forests and grasslands reported by li et al 2019 the values at this study site were smaller overall site specific wet ground conditions which increased the contribution of e to et may explain the small t et at the db site 4 3 relationship of t and e with environmental factors analysis of the relationship between e and ppfd gwl and vpd showed that some plots of e 0 mm day 1 did not follow the overall trend in period iii at the db site figs 4 6 because of the small g soil 0 mol m 2 s 1 used to calculate e at 0 8 gwl 0 6 m where the data were obtained as explained in section 4 1 3 the relationships between t e and ppfd were linear at all sites fig 4 indicating that fire induced haze decreased t and e by decreasing ppfd for example in october 2015 when a large fire occurred t and e decreased from the october mean by 12 62 and 21 41 respectively these decreases were calculated from the deviation in the ppfd from the october mean and slope of the regression line at each site these values indicate that fire induced haze significantly affects the transport of water into the atmosphere during period i at the db site for the same ppfd e under gwl 0 m was greater than e under other conditions this result indicates that the evaporation enhancement effect of the increased ppfd is greater under waterlogged conditions when the water surface is exposed to the atmosphere regarding the relationship between t and gwl t showed a positive peak for changes in the gwl at the uf df and db period i sites fig 5 the decrease in t at a high gwl may have been caused by waterlogging stress mezbahuddin et al 2015 apers et al 2022 decreases in t under waterlogging stress have been observed in several plants geng et al 2021 tiryakioglu et al 2015 xiao and jespersen 2019 which is consistent with the result showing that g veg decreased under waterlogged conditions fig 2b a depression in et under waterlogged conditions was also reported at this study site by hirano et al 2015 for the relationship between e and gwl e decreased with decreasing gwl at a gwl 0 89 m at the uf site at a gwl 0 56 m at the df site and at a gwl 0 11 m in period i at the db site and the decreasing rate in e was larger at the db site than at the forest sites fig 5 the exposed ground surface during period i at the db site may also explain this the regression results showed that there was a slight increase in t at high vpd ranges particularly under low gwl conditions fig 6 considering that the mean vpd during the dry season july october was around 8 hpa uf 7 68 hpa df 8 09 hpa db 7 95 hpa further atmospheric drying in el niño years had a small impact on t in contrast e gradually increased in regions with a high vpd however given that the gwl is typically lower during el niño events the slight increase in e under low gwl conditions suggests that e is less affected by further atmospheric drying due to el niño events during the dry season however we found no clear relationship between t and evi data not shown this may be because there was no clear time series change in the evi except for an obvious decline in 2002 and a slightly increasing trend since the fire in 2009 and 2014 near the db site fig s1 therefore the satellite data used likely did not have sufficient spatiotemporal resolution to capture biomass variability in our analysis although we did not measure the vegetation index a relationship between t and the vegetation index may have been observed if continuous on site data were available in summary t and e were positively correlated with the ppfd gwl and vpd the relationship between t and ppfd was clear but that between t and gwl or vpd was complex and varied among sites 4 4 influence of drainage the results described above show that the responses of t and e to gwl vary between sites fig 5 therefore the land use history and land cover must be considered when evaluating the impact of drainage using this study site as an example the three sites with a lowered gwl can be assumed as follows uf forest immediately after drainage df forest long after drainage db abandoned land where the forest was cleared after drainage in addition unlike the temporary decrease in the gwl during the dry season drainage permanently decreases the gwl therefore the soil moisture content is not necessarily the same at the same gwl at 0 85 gwl 0 60 m which is the typical gwl associated with drainage for land conversion the decreased t at the uf site was associated with soil drought stress in contrast root elongation can begin as an adaptive response to prolonged soil drought kramer and boyer 1995 tauc et al 2020 root elongation to deeper depths to access water may explain why t at the df site 2 44 mm day 1 was greater than t at the uf site 1 90 mm day 1 at 0 85 gwl 0 60 m fig 5 in other words t decreases once because of drainage but then recovers over time however there was no clear site to site difference in e at a lower gwl when the site was conventionally drained these results indicate that et in forests decreases with drainage and recovers to some extent over time in contrast because t at 0 85 gwl 0 60 m in period i at the db site 0 98 mm day 1 was much smaller than t at the df site 2 44 mm day 1 the impact of forest loss on t with the smaller reduction in gwl was large 4 5 influence of el niño and la niña events according to cai et al 2014 2015 global warming will increase the frequency of extreme el niño and la niña events and accompanying environmental changes will greatly influence t and e during the dry season an soi 1 indicates that an el niño can significantly change the environment as a sharp decrease in the ppfd and an increase in the number of fire spots were observed at an soi 1 fig 7a in contrast the ppfd also decreased during la niña events soi 1 5 likely because of an increase in the number of rainy days or decrease in the number of sunny days although gwl showed an overall decreasing trend with decreasing soi at all sites this trend was not observed at soi 0 in period iii at the db site fig 7b this may be because gwl was undergoing recovery although the la niña event had already begun and canal excavation in 2014 may have delayed the recovery of the gwl at all sites t and e tended to decrease with decreasing soi during the el niño events fig 8 however a decreasing trend was not observed in period iii at the db site suggesting that further data must be accumulated based on these results both t and e decreased with the el niño event during the dry season the extent of which depended on the drainage history and vegetation cover la niña events did not significantly impact t or e 5 conclusions three methods for estimating t and e from eddy flux and meteorological data were tested the method introduced by li et al 2019 using canopy and soil conductance provided a reasonable evaluation at this study site el niño affects t and e during the dry season as an el niño became stronger the fires became larger and haze attenuating incoming solar radiation worsened at this time t and e were reduced because t and e were positively correlated with the ppfd extreme atmospheric drying associated with el niño significantly decreased the gwl and inhibited root water uptake resulting in a decrease in t however further atmospheric drying had little effect on t and e overall el niño decreased the et during the dry season in contrast drainage that lowered the gwl generally decreased the et in almost undisturbed forests t decreased as the gwl decreased except for in environments where the gwl was near the ground surface however t was considered to have recovered somewhat as the trees acclimatized to drought after the gwl was lowered there were no obvious differences in e with a decreased gwl among sites with different disturbances in this study the decrease in t associated with forest loss and increase in t and decrease in e during the vegetation recovery process were quantified to more reliably and accurately evaluate t and e further validation studies of direct t measurements and the usefulness of the approach based on observation data in various environments are needed credit authorship contribution statement shinjiro ohkubo conceptualization formal analysis writing original draft visualization takashi hirano conceptualization investigation resources data curation writing review editing supervision project administration funding acquisition kitso kusin investigation data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the jsps core university program jsps kakenhi grant numbers 13375011 15255001 18403001 21255001 25257401 19h05666 jst jica project satreps wild fire and carbon management in peat forest in indonesia and technology development fund grant number 2 1504 by the environmental restoration and conservation agency and ministry of the environment japan we thank the late dr suwido limin for site establishment and the staff of cimtrop dr yosuke okimoto kiwamu ishikura and masayuki itoh for providing field assistance we also thank dr herizeal for the efforts in establishing and maintaining the palangkaraya aeronet site we acknowledge the use of data from fire information resource management system operated by nasa s earth science data and information system esdis with funding provided by the nasa headquarters appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129523 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1970,disturbances in tropical peat swamp forests greatly impact water transport into the atmosphere through evapotranspiration et however transpiration t and evaporation e are affected by disturbances in different manners based on eddy fluxes and meteorological data we used three methods to estimate t and e separately at three tropical peat swamp forest sites with different degrees of disturbance each method utilizes the i water use efficiency ii linear relationship between et and gross primary production and iii conductance of t and e in each the results showed that the conductance method was the most reasonable for estimating t and e the other two methods could not be applied because of the large variance in the water use efficiency and lack of a strong relationship between et and gross primary production among other reasons inter site comparisons suggested that lowering the groundwater level gwl reduced t but t subsequently recovered this was likely because the trees acclimated to the dry environment there was no clear difference in e among the three sites under conditions of lower gwls the mean t et in the almost undisturbed forest 0 60 was greater than that at the burned site with sparse vegetation 0 21 overall el niño events decreased both t and e during the dry season at all sites in the almost undisturbed forest t and e decreased by 1 14 and 0 27 mm day 1 respectively during el niño events precipitation decreased to near zero fire sizes increased and the downward photosynthetic photon flux density decreased the decreases in t and e were mainly due to attenuation of incoming radiation by the fire induced haze in addition significant soil desiccation due to lowered gwl impaired root water uptake resulting in decreased t in addition e was decreased by soil surface drying however the direct effect of further atmospheric drying on e and t was small during the dry season our results show that both drainage and el niño events reduced t and e in different manners abbreviations gwl groundwater level et evapotranspiration t transpiration e evaporation soi southern oscillation index uwuep potential underlying water use efficiency uwuea apparent underlying water use efficiency uwuedry underlying water use efficiency under extremely dry condition gsoil soil conductance gveg canopy conductance keywords drainage el niño evapotranspiration partition method groundwater level haze southeast asia data availability no data was used for the research described in the article 1 introduction tropical peat swamp forests are widely distributed in insular southeast asia and function as large carbon reservoirs e g dommain et al 2011 jaenicke et al 2008 page et al 2004 tropical peat swamp forests have existed for many years and have maintained a high groundwater table in recent decades land conversion has expanded mainly for agricultural land use particularly for palm oil plantations for example in 2001 2017 the forest area in borneo decreased by 14 6 04 mha whereas the plantation area increased by 170 6 20 mha gaveau et al 2019 when preparing land to install plantations drainage channels are typically excavated to lower the groundwater level gwl these activities have led to environmental concerns as lowering of the gwl can dry the soil and result in the release of large amounts of co2 because of peat decomposition moreover soil drying increases the risk of fire and large fires attenuate incoming solar radiation by generating haze for example large scale fire events occurred during the extremely dry conditions of strong el niño events in 2015 these fires caused thick smoke to cover much of sumatra and kalimantan with the haze extending to singapore malaysia and thailand field et al 2016 according to cai et al 2014 2015 the frequency of extreme el niño la niña events will continue to increase with climate change causing major disturbances however the effects of el niño la niña events on evapotranspiration et which plays an important role in the water balance in tropical peat swamp forests are not well understood in southeast asia et and precipitation levels are relatively higher than those observed on a global scale therefore disturbances significantly impact the quantitative changes in et kobayashi et al 2015 wang et al 2012 long term continuous observations using the eddy covariance ec technique can be used to evaluate the effects of disturbances on et and is widely used to examine terrestrial ecosystems two studies on et in tropical peat swamp forests were conducted in central kalimantan indonesia using the ec technique over long periods of time hirano et al 2015 measured et for 4 6 years and observed seasonal variations linked to net radiation r n changes which were significantly influenced by the dense haze caused by large fires in addition they showed that et decreased as the gwl decreased with drainage ohkubo et al 2021c continued observations at the drained burnt site for approximately 13 years during which fires and nearby ditch excavation occurred they confirmed that et was strongly positively correlated with r n and positively correlated with vapor pressure deficits vpds of 20 hpa they also attributed the decrease in et under conditions of precipitation et and gwl 0 5 m to a decrease in transpiration t because of reduced root water uptake in addition under waterlogged conditions an increased vpd decreased t because of partial stomatal closure of plants although this effect was compensated by increased evaporation e from the free water surface however these assumptions were not based on observations of t and e leading to uncertainty in the results furthermore et measurements using the ec technique have recently been performed in peatlands e g gunawardhana et al 2021 morison et al 2020 volik et al 2021 and tropical forests e g kuricheva et al 2021 uuh sonda et al 2022 von randow et al 2020 in these studies data from long term continuous observations were used to evaluate seasonal and annual changes by examining how environmental factors affect et however the ec technique cannot directly measure t and e in dominant tropical peatland species t is typically regulated by physiological factors such as plant stomatal behavior which is controlled by the leaf water status whereas e is determined by physical environmental factors such as the soil surface moisture and atmospheric dryness thus responses to environmental changes generally differed between t and e various methods have been used to evaluate t or e based on the sap flow velocity thermography and isotope ratios stoy et al 2019 other methods use eddy fluxes and meteorological data and have the advantage of being able to evaluate t and e over a long period under varying environmental conditions using the linear relationship between gross primary production gpp vpd0 5 and et named as the water use efficiency wue method zhou et al 2016 found that t et was largest in croplands followed by that in grasslands and forests additionally the enhanced vegetation index evi and t et were strongly correlated in deciduous forests scott and biederman 2017 evaluated t by assuming that t and gpp have a linear relationship named as the lr method they found that this method is applicable to water limited locations they observed that t et peaked in summer with an increasing gpp and leaf area index and decreased with an increasing number of rainy days in shrubland savanna and grassland in southern arizona eichelmann et al 2022 applied data from four restored wetlands using the lr method their estimated t values agreed well with the evaluated t values using an artificial neural network during winter they also found that t increased during the growing season li et al 2019 used the conductances t and e named as the conductance method and found that t et in evergreen needleleaf forests was larger than that in cropland and grassland in addition t et tended to increase as the leaf area index increased at all sites although some studies using wue lr and conductance methods have shown reasonable results these methods are unsuitable in several cases for example in the wue method the presence of multiple vegetation types at a site violates the assumption of constant wue in the lr method linear regression fails when the data are not within an appropriate range an insufficient amount of data leads to uncertainty in the parameters obtained from nonlinear regression because the number of studies using wue lr and conductance methods are limited their usefulness should be verified on a case by case basis in this study we evaluated the influence of drainage and el niño la niña events on t and e in tropical peat swamp forests using eddy flux and meteorological data three methods wue lr and conductance methods were applied to evaluate and validate t and e based on the derivation process the most appropriate method was used to determine the final t and e for analysis t and e were estimated at three sites with varying degrees of disturbance the impact of disturbances on t and e was evaluated using time series variations relationships with environmental factors and inter site comparisons 2 materials and methods 2 1 site description the three study sites were in peat soils within 15 km of central kalimantan indonesia and exhibited different disturbance levels hirano et al 2012 2015 the sites were a slightly drained peat swamp forest uf site 2 32 s 113 90 e drained peat swamp forest df site 2 35 s 114 04 e and burned degraded swamp forest db site 2 34 s 114 04 e ohkubo et al 2021a in 2002 2018 the mean air temperature above the forest canopy was 26 2 c with little seasonal variation the mean annual precipitation was 2565 mm and the dry season is typically from july to october the uf site was selectively logged until the late 1990 s although small canals were excavated for logging they have remained relatively untouched since being designated as national parks in 2006 the dominant species were evergreen broad leaved trees with rich shrubbery in june 2006 the canopy height and plant area index were 23 m and 5 0 m2 m 2 respectively defoliation occurred at the end of the dry season hirano et al 2015 similar to at the uf site the df site was selectively logged a large canal was excavated in 1996 1997 for use as a drainage system in june 2006 the canopy height and plant area index were 26 m and 5 6 m2 m 2 respectively the dominant species were the same as those found at the uf site hirano et al 2015 the db site was a degraded swamp forest with drainage and repeated fires the site suffered a stand replacing fire in 2002 and burned again in 2009 and 2014 the site was drained using a nearby ditch that was excavated in 2014 the dominant vegetation transitioned from ferns and sedges to young trees after the 2002 fire the details of these three sites have been described by hirano et al 2015 and ohkubo et al 2021a 2 2 measurements field experiments were conducted from july 2004 to december 2018 at the uf site july 2001 to june 2017 at the df site and april 2004 to december 2016 at the db site according to the disturbance events the db site measurement period was separated into three periods april 2004 to september 2009 i december 2009 to june 2014 ii and july 2014 to december 2016 iii ohkubo et al 2021b r n was measured using a radiometer cnr 1 kipp zonen delft the netherlands and the downward photosynthetic photon flux density ppfd was measured using a quantum sensor li 190s li cor lincoln ne usa at heights of 36 3 40 6 and 3 3 m at the uf df and db sites respectively at the db site the height increased to 6 8 m in march 2012 and 13 m in december 2013 because of vegetation growth the air temperature and relative humidity were measured using a platinum resistance thermometer and capacitive hygrometer hmp45 vaisala helsinki finland at heights of 36 3 41 7 and 1 5 m at the uf df and db sites respectively precipitation was measured using a tipping bucket rain gauge te525 campbell scientific logan ut usa at heights of 36 3 41 0 and 1 5 m at the uf df and db sites respectively meteorological data were recorded every 30 min using a data logger cr10x or cr1000 campbell scientific gwl was measured every 30 min using a water level logger dl n sensor technik sirnach ag sirnach switzerland or dcx 22 vg keller ag winterthur switzerland at the three sites a water level logger was installed at one location in the hollows within 5 m of the observation tower at each site the data were corrected to obtain the relative distance to the ground surface using occasional on site measurements to remove the effect of peat subsidence the eddy fluxes of co2 sensible heat h and latent heat λe were measured using the ec technique with a sonic anemometer thermometer csat3 campbell scientific and an open path co2 h2o analyzer li7500 li cor at 36 5 41 3 and 3 0 m at the uf df and db sites respectively at the db site the height increased to 3 6 m in february 2011 7 2 m in march 2012 and 13 6 m in december 2013 because of vegetation growth the sensor signals were recorded using a datalogger 8421 hioki e e corp ueda japan or cr1000 campbell scientific at 10 hz the change in co2 storage below the eddy sensors was calculated every 30 min from the co2 concentrations at six heights measured using a co2 analyzer li800 or li820 li cor the details have been described by hirano et al 2012 2015 and ohkubo et al 2021b 2 3 flux calculation the half hourly fluxes of co2 h and λe were calculated using flux calculator software ueyama et al 2012 with the following procedures 1 removal of noise spikes vickers and mahrt 1997 2 double rotation for tilt angles 3 correction for high frequency loss massman 2000 massman 2001 and 4 correction for air density fluctuations webb et al 1980 for quality control flux data with wind directions where the tower caused flow distortion were removed rainfall data were excluded from analysis net ecosystem exchange nee was calculated as the sum of eddy co2 flux and co2 storage change to prevent underestimation of the nighttime nee ppfd 20 μmol m 2 s 1 the change point method barr et al 2013 was applied using the standard deviation of the vertical wind speed σw rather than the friction velocity acevedo et al 2009 outliers in nee h and λe were removed using the smirnov grubbs test for nighttime and daytime a stationarity test was also applied for each half hour flux foken and wichura 1996 further information has been described by ohkubo et al 2021b nee was partitioned into ecosystem respiration re and gpp using the lookup table method nighttime nee which is regarded as re was binned equally into seven classes according to the gwl lookup tables were created annually by averaging the binned re data and gwl for each class gpp was calculated as the difference between nee and daytime re estimated from the gwl using the lookup tables the gaps in all flux data were filled using the marginal distribution sampling method reichstein et al 2005 except for the nighttime nee re data which were filled using lookup tables gwl was added as an environmental variable along with air temperature and vpd with the acceptable deviation set to 0 2 m as a radiation condition a downward ppfd of 100 μmol m 2 s 1 was used rather than using r n 50 w m 2 et was calculated from the adjusted λe after h λe was forced to balance with r n daily using the bowen ratio of daily h and λe twine et al 2000 ohkubo et al 2021c this approach was adopted because changes in heat storage in the soil and canopy were not measured the daily integrated values of changes in heat storage are expected to be zero because there is little seasonal variation in the air and thus in the soil temperature at our study sites the mean 1 standard deviation of the daily ratio of eddy energy flux h λe r n was 0 95 0 22 0 84 0 18 and 0 82 0 12 at the uf df and db sites respectively 2 4 additional data the evi from moderate resolution imaging spectroradiometer data was used as a proxy for aboveground biomass anaya et al 2009 huete et al 2002 sixteen day composite evi data with a spatial resolution of 250 m were downloaded from the land processes distributed active archive center https lpdaac usgs gov products mod13q1v006 the respective pixel data enclosing the three sites were used if the quality was greater than or equal to useful southern oscillation index soi data were used as indicators of el niño and la niña events the soi was negative during an el niño event and positive during a la niña event monthly soi data were collected from the national oceanic and atmospheric administration https www ncdc noaa gov teleconnections enso indicators soi the aerosol optical depth was used as an indicator of the attenuation of solar radiation caused by haze the aerosol optical depth was measured using a photometer at a height of 27 m at the palangkaraya aeronet site 2 23 s 113 95 e which was approximately 11 km from the uf site and 16 km from the df and db sites the data were downloaded from the aeronet database https aeronet gsfc nasa gov new web aerosols html which became available on july 19 2012 data categorized as the highest quality level 2 0 cloud cleared and quality assured were used for analysis the date and location of the fire spots were downloaded from the fire information resource management system https firms modaps eosdis nasa gov 2 5 partitioning approaches we applied the following three methods table s1 to partition et into t and e we first calculated t after which e was determined as a residual 2 5 1 wue method the wue method is based on the linear relationship between gpp vpd0 5 and et zhou et al 2016 daytime half hourly data were used data during and after rainfall were removed to exclude the interception of evaporation the removal time after rainfall was determined as described by zhou et al 2015 the accumulated precipitation over the past 24 h was calculated and the time of removal was determined according as the ratio of the accumulated potential et over the same period zhou et al 2015 this method assumes that e becomes zero when the ratio of gpp vpd0 5 et is ranked in the top 5 of the dataset thus the 95th percentile of gpp vpd0 5 et was defined as the potential underlying wue uwuep95 which was determined for the whole period at the uf and df sites and the i ii and iii periods at the db site the 90th percentile of gpp vpd0 5 et uwuep90 was also calculated and the apparent underlying wue uwuea was determined via linear regression of gpp vpd0 5 and et linear regression was also applied for datasets with gwl 1 5 m where the soil surface was so dry that e was assumed to be negligible to determine the uwue under extremely dry soil conditions uwuedry at the df site and in period iii at the db site where the data could be obtained t was calculated for every 30 min using the following equation 1 t gpp vpd 0 5 uwue where uwue is uwuep95 uwuep90 or uwuedry 2 5 2 lr method the lr method is based on a linear relationship between the monthly t and gpp scott and biederman 2017 t gpp was determined as the slope of the regression between the monthly values of et and gpp and the intercept was e according to precipitation seasonality regression was conducted quarterly from february to april may to july august to october and november to january to determine t gpp t was calculated monthly as the product of the measured gpp and regression slope t gpp to perform regression with more data linear regression was conducted using daily values for each month to calculate the daily t 2 5 3 conductance method this method li et al 2019 uses the following conductance equation 2 g s g soil g veg 3 g soil g 0 4 g veg g 1 gpp vpd l m 5 vpd l γ λ e ρ c p g s where g s g soil and g veg are the ecosystem soil and canopy conductance mol m 2 s 1 respectively g soil and g veg denote the conductance for e and t g 0 mol m 2 s 1 g 1 kpam mol μmol 1 and m are fitting parameters vpdl is the leaf level vpd at the ecosystem scale g s was calculated using the following inverted penman monteith equation by replacing r n g soil heat flux with h λe because g was not available hirano et al 2015 6 g s γ g a λ e δ h λ e ρ c p g a v p d δ γ λ e where γ is the psychrometric constant kpa k 1 g a is the aerodynamic conductance m s 1 δ is the slope of the saturated vpd curve kpa k 1 ρ is the air density kg m 3 and c p is the specific heat of air j kg 1 k 1 and vpd is measured in units of kpa the units of g s m s 1 were converted to mol m 2 s 1 using the ideal gas law the parameters were determined by curve fitting among g s gpp and vpdl using daytime half hourly data for five to seven gwl classes depending on the range of the gwl data from during and within 6 h of rainfall were excluded to remove the interception of evaporation finally the half hourly t was calculated from the et g soil constant and g veg eq 4 of the corresponding gwl classes eq 7 7 t e t g veg g soil g veg the method has been described in detail by li et al 2019 3 results 3 1 seasonal variations in measured and additional variables seasonal variations in the measured field data and additional data are shown in fig 1 and fig s1 respectively the overall trend across all sites focusing on the dry season july october when the soi was negative showed that precipitation was extremely low vpd increased gwl decreased and many fire spots were near each site in addition the aerosol optical depth was increased and ppfd was decreased the decrease in ppfd was prominent in 2015 when the monthly ppfd was lowest at all sites which was 56 64 lower than the mean ppfd in october of other years the gwl at the df site was lower than that at the uf site throughout the observation period at the db site the gwl remained high until ditch excavation in 2014 because the soil surface was burned by fire before the observation started and the ground surface level was sufficiently low to maintain waterlogged conditions however the gwl decreased after ditch excavation and never returned to the ground surface level ohkubo et al 2021a the number of fire spots around the df and db sites was higher than that around the uf site the closest fire spot from the db site was 0 19 km in 2009 which is consistent with the fact that the db site experienced severe fire damage ohkubo et al 2021bc at the db site the evi decreased in 2002 when there was a large amount of fire damage and the evi slightly and gradually increased after the fires in 2002 2009 and 2014 no notable changes were observed during other periods or at other sites 3 2 derivation process and comparison of methods 3 2 1 wue method the uwuea at the forest sites uf and df was greater than that at the db site fig s2 and table s2 the uwuea in period iii was larger than that in periods i and ii at the db site uwuep95 at forest sites was more than twice as large as those at db sites uwuedry was less than half of uwuep95 at the df site and in period iii at the db site 3 2 2 lr method in the seasonal regression analysis using monthly values significant regression was found in the dry season august october at all sites but was not observed during other seasons and at other sites fig s3a and table s3 r 2 for the dry season was generally higher than those for the other seasons at all sites at the df site where significant regression was observed in all seasons the maximum regression slope was approximately five fold the minimum value indicating wide seasonal variation in the slope however most of the monthly linear regression was significant except for that in may july in period i at the db site fig s3b and table s3 whereas r 2 for the monthly regression did not improve compared to that for the seasonal regressions 3 2 3 conductance method g soil tended to decrease with decreasing gwls fig 2 a the scale of the horizontal axis differed among sites and periods depending on the measured gwl ranges for the db site the average gsoil in a gwl range of 0 4 gwl 0 m decreased over time period i period ii period iii note that the gwl bin section differed between periods in fig 2a in period iii g soil was close to 0 mol m 2 s 1 in the range of 0 8 gwl 0 6 m the g veg of the uf site was larger than that of the df site at a gwl 0 6 m but was smaller in the range of 1 0 gwl 0 6 m uf data not shown in this range fig 2b with decreasing gwl g veg decreased at a gwl 0 1 m at the uf site and gwl 0 6 m at the df site at the uf site gveg at 0 1 gwl 0 m and gwl 0 m were significantly p 0 01 smaller than gveg at 0 2 gwl 0 1 m the g veg values of the forest sites uf and df were higher than those of the db site at the db site the average gveg in the gwl range of 0 4 gwl 0 m increased over time period i period ii period iii note that the gwl bin section differed between periods in fig 2b in contrast to the behavior of gsoil over the same gwl range 3 2 4 comparison of estimated t the time series of the estimated t values was compared to evaluate the performance of the methods fig s4 the mean t calculated using uwuep95 and uwuep90 were 0 80 and 1 45 mm day 1 at the uf site and 0 72 and 1 30 mm day 1 at the df site respectively the mean t determined using uwuep95 was 1 8 fold greater than that determined using uwuep90 at both sites at the db site the estimated t using uwuep95 and uwuep90 frequently exceeded the et particularly in period ii using uwuedry t occasionally exceeded et at the df site and always exceeded et during period iii at the db site t calculated using the lr method showed periodic and large seasonal variations at all sites and occasionally exceeded the et t estimated using the conductance method varied within the range of et because of its derivation process 3 3 partition of et into t and e as discussed in section 4 1 3 the conductance method showed the most reasonably explainable results thus the results calculated using the conductance method are presented fig 3 shows the monthly variations in t and e both t and e decreased sharply in 2006 2009 2014 and 2015 when strong el niño events significantly decreased the gwl at the uf site t tended to be larger and e tended to be smaller than those at the df site whereas et was similar throughout the experimental period fig 1 the mean monthly t and e from august 2004 to december 2016 the common period of available data at the three sites were 2 47 and 1 63 mm day 1 at the uf site and 2 06 and 1 95 mm day 1 at the df site respectively table s5 the monthly t and e values at the uf and df sites were significantly different p 0 001 at the db site t increased with vegetation recovery after the fire in 2009 whereas e decreased the mean t et was 0 60 at the uf 0 51 at df 0 21 in period i 0 40 in period ii and 0 60 in period iii at the db site table s5 the annual t and e for the years ranged from 735 to 1029 and 515 to 653 mm year 1 for 2005 2018 at the uf site 618 to 827 and 601 to 797 mm year 1 for 2002 2016 at the df site and 187 to 937 and 506 to 1201 mm year 1 for 2005 2016 at the db site table s6 3 4 relationships of t and e with environmental factors to determine the impact of drainage el niño induced drought and fire the relationships between t and e ppfd gwl and vpd were examined figs 4 6 a significant p 0 001 positive linear relationship was observed for t and e with ppfd at all sites fig 4 at the db site in period iii grouped plots were observed around e 0 mm day 1 the regression slope of t at the uf site 0 058 kgh2o mol 1 was larger than that at the df site 0 048 kgh2o mol 1 at the db site the slope increased with vegetation recovery period i 0 018 kgh2o mol 1 ii 0 034 kgh2o mol 1 iii 0 067 kgh2o mol 1 in contrast the slope of e was largest in period ii at the db site 0 071 kgh2o mol 1 during periods i and ii e was larger under waterlogged conditions blue at the same ppfd which was not the case at the uf site t peaked at different gwl among sites fig 5 the peak gwl estimated using quadratic regression was 0 66 m at the df site which is lower than those at the other sites e decreased linearly as gwl decreased at gwl 0 11 m period i of db gwl 0 56 m df and gwl 0 89 m uf the rate of the decrease in e relative to the decrease in gwl was largest during period i at the db site at 2 24 mm day 1 m 1 in period ii no clear trend was observed because of the narrow range of the variation in the gwl in period iii at approximately 0 8 gwl 0 6 m t increased and e decreased large scale artificial drainage would lower the gwl over a wide area we estimated the drainage impact on t and e by assuming that the lowered gwl is the typical gwl 0 85 0 60 m at an oil palm plantation which is the main type of converted agricultural land dislich et al 2017 the mean of t and e under 0 85 gwl 0 60 m were 1 90 and 1 90 mm day 1 at the uf site 2 44 and 1 84 mm day 1 at the df site and 0 98 mm and 1 86 mm day 1 in period i at the db site respectively compared to the maximum t 2 68 mm day 1 of the regression curve at a gwl 0 20 m at the uf site the mean t under 0 85 gwl 0 60 m decreased by 0 78 mm day 1 at the uf site 0 24 mm day 1 at the df site and 1 70 mm day 1 in period i at the db site respectively in contrast under 0 85 gwl 0 60 m the mean e at the df and db period i sites only slightly differed from the mean e at the uf site the relationships between t e and vpd are shown in fig 6 commonly used logarithmic regression was applied to evaluate each site e g ewers et al 2002 luo et al 2016 overall t increased with increasing vpd but gradually plateaued at a high vpd range in contrast t and e showed no significant correlation with evi r 0 18 0 46 at all sites 3 5 relationship of t and e with soi the relationship between soi and environmental factors precipitation vpd ppfd number of fire spots and gwl is shown in fig 7 no clear relationship was observed on a monthly scale however some relationships were observed during the dry season july october during the dry season there was a positive relationship r 0 68 between precipitation and soi when soi 0 however precipitation was consistently low when soi 0 fig 4 also during the dry season vpd was negatively correlated with soi for all soi ranges r 0 62 ppfd decreased significantly as the soi changed from 1 to 2 and ppfd around soi 2 was smaller than that for 1 soi 1 the number of hotspots increased significantly as the soi decreased for soi 0 whereas no hotspots were detected when soi 0 gwl was positively correlated with soi in the dry season at all sites fig 7b however in period iii at the db site the gwl decreased when soi 0 and deviated from this trend the relationship between t e and the soi is shown in fig 8 during the dry season t generally decreased with as the soi decreased to 0 whereas little change was observed at soi 0 the mean t for 2 soi 1 was decreased by 1 14 mm day 1 at the uf site 0 96 mm day 1 at the df site 0 37 mm day 1 in period i at the db site and 1 78 mm day 1 in period iii compared to those for soi 0 table s4 in contrast e generally decreased with decreasing soi for soi 0 but this trend was not observed in period iii at the db site compared to the mean e for soi 0 that for 2 soi 1 was decreased by 0 27 mm day 1 at the uf site 0 75 mm day 1 at the df site and 1 37 mm day 1 in period i at the db site 4 discussion 4 1 evaluation of methods 4 1 1 wue method uwuea gc hpa0 5 kgh2o values at the forest site used in this study uf 7 65 df 6 56 table s2 were similar to those in tropical evergreen broadleaf forests in brazil 7 00 and french guiana 7 85 gan et al 2021 uwuea values at the db site 3 80 5 29 were smaller than those at our forest site one possible reason for the smaller uwuea at the db site is the presence of a free water surface with sparsely distributed vegetation particularly during periods i and ii the uwuea in period iii when vegetative growth was more advanced was greater than that during periods i and ii supporting this possibility in other words e is large and significantly increases et resulting in a small uwuea compared with the average uwuep95 gc hpa0 5 kgh2o in croplands deciduous broadleaf forests evergreen needle leaf forests and grasslands 12 48 13 40 reported by zhou et al 2016 the values in our forest sites uf 43 08 df 39 57 were much larger and uwuep90 values gc hpa0 5 kgh2o uf 23 84 df 21 92 were also larger table s1 if et was calculated using the unadjusted λe without energy balance correction the estimated et would have been smaller leading the estimated uwuep95 at the forest sites uf and df to be larger than the adjusted values thus the difference from the estimated values reported by zhou et al 2016 was larger one possible reason for the large uwuep95 at this site is the wide variance in the data and the top 5th percentile of the datasets showed higher values than those with the same mean and smaller variance for the same reason t was highly dependent on the number of percentile values of gpp vpd0 5 et as demonstrated by the large difference in the estimated t with uwuep95 and uwuep90 at df and in period iii at the db site in their time series variations fig s4 however there is no established method for determining a reasonable percentile value for example ma et al 2020 reported that the 80th percentile was most appropriate for oak grass savannah and not the 95th percentile used by zhou et al 2016 moreover the values of uwuep95 and uwuedry greatly differed therefore the top few percentile data cannot be considered as being in an environment in which e can be ignored thus the wue method cannot be applied to this study site to separate t from et 4 1 2 lr method in seasonal regressions significant regression and higher r 2 compared to those in other seasons were typically observed in the dry season august october at all sites our results are supported by those of eichelmann et al 2022 who showed that the lr method is not applicable in flooded environments where the contribution of e is large this is because et and gpp are not strongly related in non water limited environments law et al 2002 thus the lr method can only be applied in the dry season in our peat swamp ecosystem in contrast r 2 did not improve even when the amount of data was increased using daily values although significant regression was observed in most cases this result indicates that our regression failed because it was applied to the flooding environment rather because of a lack of data a large interseasonal difference in the regression slope was observed at the df site this result was manifested in the periodic and large seasonal changes in the time series variation of t at all sites fig s4 indicating that the regression slope significantly affects t nevertheless the r 2 value of the regression was unsatisfactory indicating that this method is not suitable for estimating t if et was calculated using unadjusted λe without energy balance correction the slope of the regression of gpp on et would decrease and the r 2 value of the regression and seasonality of the regression slope would be unaffected 4 1 3 conductance method the clear decreasing trend in g soil with decreasing gwl in period i at the db site reflects that much of the wet soil surface is exposed to the atmosphere and the soil surface dries quickly as gwl decreases fig 2a within the comparable range of 0 4 gwl 0 m at the db site the decrease in g soil over time period i period ii period iii can be explained by the decrease in the exposed soil surface area with flourishing vegetation one possible reason for the near zero g soil in the bin of 0 8 gwl 0 6 m in period iii at the db site is the mixed data from the 2014 fire as this fire was not severe the top of the standing trees remained green whereas the understory was burned ohkubo et al 2021b thus the extreme dryness of the soil surface layer regardless of the gwl may have affected the parameter fitting at the df site we began to detect the effect of soil drying on g veg with decreasing gwl at lower gwl and g veg was larger at 1 0 gwl 0 6 m compared to those at the uf site uf data not shown in this gwl range fig 2b this may be because of acclimation of the trees after several years of exposure to a dry environment for example karimi and ehterami fini 2021 reported that pre exposure of walnut trees to soil drying conditions resulted in higher t values than those of control plants under subsequent drought conditions in contrast g veg decreased at the uf sites with gwl 0 1 m fig 2b and stomatal conductance was decreased under waterlogged conditions in many plants rodríguez gamir et al 2011 schmull and thomas 2000 soleh et al 2018 terazawa et al 1992 xiao and jespersen 2019 these results support that waterlogged conditions are a stressor for tree transpiration at this study site g veg at the forest sites uf and df was higher than g veg at the db site this result also explains the increasing g veg with vegetation transition approaching the forest over time at the db site however the estimated t was consistently smaller than et showing plausible time series variation at all sites fig s4 although the energy balance corrections to h and λe in eqs 5 and 6 may have some effect on gveg gsoil gveg in eq 7 the increase in et with increasing λe would have a greater impact on t when using the value of et without energy balance correction both t and e would be approximately 0 95 0 84 and 0 82 fold the adjusted values for the uf df and db sites respectively however the presence of energy balance correction is not expected to strongly influence the time series changes or relationships with environmental variables we found that the conductance method is appropriate for evaluating this study site based on the results showing that g soil increased as vegetative cover increased g veg in a dry soil environment was greater at the df site than at the uf site because of acclimation g veg decreased because of waterlogging stress g veg at the forest site uf and df sites was larger than that at the db site and the estimated t showed plausible variation 4 2 evaluation of calculated t and e the annual t at our forest sites uf 735 1029 mm year 1 df 618 827 mm year 1 table s6 tended to be lower than that in other tropical rain forests 885 1285 mm year 1 bruijnzeel 1990 calder et al 1986 kumagai et al 2005 kume et al 2011 leopoldo et al 1995 in contrast e at the studied forest sites uf 515 653 mm year 1 df 601 797 mm year 1 tended to be larger than that in other tropical rain forests calder et al 1986 595 mm year 1 kumagai et al 2005 352 mm year 1 unlike other forest sites the wetter soil characteristics with a high gwl at the forest sites were evident in the relatively larger e and smaller t in contrast the annual t and e for one year in which data were available in period i at the db site t 187 303 mm year 1 e 791 1201 mm year 1 table s6 were similar to those obtained at the tules and cattail dominated wetland sites with 45 vegetation cover t 300 mm year 1 e 1100 mm year 1 eichelmann et al 2022 compared with these t and e values larger t and smaller e values were observed in period iii at the db site t 695 937 mm year 1 e 506 518 mm year 1 and the tule and cattail dominated sites with 97 vegetation cover t 700 800 mm year 1 e 200 300 mm year 1 the estimated t and e values agreed well with values reported previously the decrease in t during fire in the time series variation fig 3 was mainly due to the decrease in ppfd associated with haze impaired root water uptake due to an excessively low gwl may be an additional reason for the decrease in t the decrease in e may be related to the decrease in available water for evaporation as soil drying exceeded the effect of increased driving force for evaporation owing to the increase in the water vapor concentration gradient t was larger at the uf site possibly because the trees had greater access to water with a higher gwl whereas e at the df site was larger possibly because it compensated for the smaller t to respond to the atmospheric demand for water fig 3 table s5 the mean et values were similar for the uf site 4 10 mm day 1 and df site 4 02 mm day 1 at the db site t was increased after the fire in 2009 because of the increase in aboveground biomass fig 3 the decrease in e have resulted from the decrease in the exposed soil surface area associated with vegetation recovery e was also decreased in the middle of 2014 because of the lowered gwl due to ditch excavation the results showing a greater t et in forests than in grasslands table s5 are similar to those reported by li et al 2019 however compared with the t et during the growing season in forests and grasslands reported by li et al 2019 the values at this study site were smaller overall site specific wet ground conditions which increased the contribution of e to et may explain the small t et at the db site 4 3 relationship of t and e with environmental factors analysis of the relationship between e and ppfd gwl and vpd showed that some plots of e 0 mm day 1 did not follow the overall trend in period iii at the db site figs 4 6 because of the small g soil 0 mol m 2 s 1 used to calculate e at 0 8 gwl 0 6 m where the data were obtained as explained in section 4 1 3 the relationships between t e and ppfd were linear at all sites fig 4 indicating that fire induced haze decreased t and e by decreasing ppfd for example in october 2015 when a large fire occurred t and e decreased from the october mean by 12 62 and 21 41 respectively these decreases were calculated from the deviation in the ppfd from the october mean and slope of the regression line at each site these values indicate that fire induced haze significantly affects the transport of water into the atmosphere during period i at the db site for the same ppfd e under gwl 0 m was greater than e under other conditions this result indicates that the evaporation enhancement effect of the increased ppfd is greater under waterlogged conditions when the water surface is exposed to the atmosphere regarding the relationship between t and gwl t showed a positive peak for changes in the gwl at the uf df and db period i sites fig 5 the decrease in t at a high gwl may have been caused by waterlogging stress mezbahuddin et al 2015 apers et al 2022 decreases in t under waterlogging stress have been observed in several plants geng et al 2021 tiryakioglu et al 2015 xiao and jespersen 2019 which is consistent with the result showing that g veg decreased under waterlogged conditions fig 2b a depression in et under waterlogged conditions was also reported at this study site by hirano et al 2015 for the relationship between e and gwl e decreased with decreasing gwl at a gwl 0 89 m at the uf site at a gwl 0 56 m at the df site and at a gwl 0 11 m in period i at the db site and the decreasing rate in e was larger at the db site than at the forest sites fig 5 the exposed ground surface during period i at the db site may also explain this the regression results showed that there was a slight increase in t at high vpd ranges particularly under low gwl conditions fig 6 considering that the mean vpd during the dry season july october was around 8 hpa uf 7 68 hpa df 8 09 hpa db 7 95 hpa further atmospheric drying in el niño years had a small impact on t in contrast e gradually increased in regions with a high vpd however given that the gwl is typically lower during el niño events the slight increase in e under low gwl conditions suggests that e is less affected by further atmospheric drying due to el niño events during the dry season however we found no clear relationship between t and evi data not shown this may be because there was no clear time series change in the evi except for an obvious decline in 2002 and a slightly increasing trend since the fire in 2009 and 2014 near the db site fig s1 therefore the satellite data used likely did not have sufficient spatiotemporal resolution to capture biomass variability in our analysis although we did not measure the vegetation index a relationship between t and the vegetation index may have been observed if continuous on site data were available in summary t and e were positively correlated with the ppfd gwl and vpd the relationship between t and ppfd was clear but that between t and gwl or vpd was complex and varied among sites 4 4 influence of drainage the results described above show that the responses of t and e to gwl vary between sites fig 5 therefore the land use history and land cover must be considered when evaluating the impact of drainage using this study site as an example the three sites with a lowered gwl can be assumed as follows uf forest immediately after drainage df forest long after drainage db abandoned land where the forest was cleared after drainage in addition unlike the temporary decrease in the gwl during the dry season drainage permanently decreases the gwl therefore the soil moisture content is not necessarily the same at the same gwl at 0 85 gwl 0 60 m which is the typical gwl associated with drainage for land conversion the decreased t at the uf site was associated with soil drought stress in contrast root elongation can begin as an adaptive response to prolonged soil drought kramer and boyer 1995 tauc et al 2020 root elongation to deeper depths to access water may explain why t at the df site 2 44 mm day 1 was greater than t at the uf site 1 90 mm day 1 at 0 85 gwl 0 60 m fig 5 in other words t decreases once because of drainage but then recovers over time however there was no clear site to site difference in e at a lower gwl when the site was conventionally drained these results indicate that et in forests decreases with drainage and recovers to some extent over time in contrast because t at 0 85 gwl 0 60 m in period i at the db site 0 98 mm day 1 was much smaller than t at the df site 2 44 mm day 1 the impact of forest loss on t with the smaller reduction in gwl was large 4 5 influence of el niño and la niña events according to cai et al 2014 2015 global warming will increase the frequency of extreme el niño and la niña events and accompanying environmental changes will greatly influence t and e during the dry season an soi 1 indicates that an el niño can significantly change the environment as a sharp decrease in the ppfd and an increase in the number of fire spots were observed at an soi 1 fig 7a in contrast the ppfd also decreased during la niña events soi 1 5 likely because of an increase in the number of rainy days or decrease in the number of sunny days although gwl showed an overall decreasing trend with decreasing soi at all sites this trend was not observed at soi 0 in period iii at the db site fig 7b this may be because gwl was undergoing recovery although the la niña event had already begun and canal excavation in 2014 may have delayed the recovery of the gwl at all sites t and e tended to decrease with decreasing soi during the el niño events fig 8 however a decreasing trend was not observed in period iii at the db site suggesting that further data must be accumulated based on these results both t and e decreased with the el niño event during the dry season the extent of which depended on the drainage history and vegetation cover la niña events did not significantly impact t or e 5 conclusions three methods for estimating t and e from eddy flux and meteorological data were tested the method introduced by li et al 2019 using canopy and soil conductance provided a reasonable evaluation at this study site el niño affects t and e during the dry season as an el niño became stronger the fires became larger and haze attenuating incoming solar radiation worsened at this time t and e were reduced because t and e were positively correlated with the ppfd extreme atmospheric drying associated with el niño significantly decreased the gwl and inhibited root water uptake resulting in a decrease in t however further atmospheric drying had little effect on t and e overall el niño decreased the et during the dry season in contrast drainage that lowered the gwl generally decreased the et in almost undisturbed forests t decreased as the gwl decreased except for in environments where the gwl was near the ground surface however t was considered to have recovered somewhat as the trees acclimatized to drought after the gwl was lowered there were no obvious differences in e with a decreased gwl among sites with different disturbances in this study the decrease in t associated with forest loss and increase in t and decrease in e during the vegetation recovery process were quantified to more reliably and accurately evaluate t and e further validation studies of direct t measurements and the usefulness of the approach based on observation data in various environments are needed credit authorship contribution statement shinjiro ohkubo conceptualization formal analysis writing original draft visualization takashi hirano conceptualization investigation resources data curation writing review editing supervision project administration funding acquisition kitso kusin investigation data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the jsps core university program jsps kakenhi grant numbers 13375011 15255001 18403001 21255001 25257401 19h05666 jst jica project satreps wild fire and carbon management in peat forest in indonesia and technology development fund grant number 2 1504 by the environmental restoration and conservation agency and ministry of the environment japan we thank the late dr suwido limin for site establishment and the staff of cimtrop dr yosuke okimoto kiwamu ishikura and masayuki itoh for providing field assistance we also thank dr herizeal for the efforts in establishing and maintaining the palangkaraya aeronet site we acknowledge the use of data from fire information resource management system operated by nasa s earth science data and information system esdis with funding provided by the nasa headquarters appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129523 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1971,significant climate variations have decreased the stability of water resource systems leading to multiple uncertainties in streamflow response reservoir operation optimization decision making and adaptive adjustments for water resource scheduling understanding the impact of climate change on reginal streamflow is necessary and crucial to identifying reservoir operation strategies and decision making responses in this study we created an integrated systematic uncertain streamflow responses reservoir operation optimization decision making risk analysis chain three bias corrected and downscaled general circulation models gcms were used to analyze the inter model uncertainties under three representative concentration pathways rcps the streamflow responses and uncertainty in the future were determined using a distributed hydrological model and the fuzzy extension principle under predefined scenarios and uncertainty levels then a stochastic simulation model and modified stochastic multi criteria decision making model were applied to identify the effects of climate change projections and streamflow responses on reservoir multi objective operation and decision making moreover risk quantification indices were used to determine the uncertainty propagation and potential risks accumulated in the chain we applied this framework to cascade reservoirs in the qing river basin the results indicate that the mean annual streamflow projected using selected gcms will increase enhancing the hydropower response and weakening the ecological benefit response the pareto non dominated solutions optimized based on the streamflow projections obtained using the gcms under the same rcp and hydrological model are more distinct than those based on different rcps and the same gcm moreover a high emission scenario may increase the uncertainty of the streamflow projections and reservoir operation responses which is consistent with the finding that the decision making process becomes more variable and sensitive with increasing streamflow uncertainty finally we identified the preferred solutions for reservoir operation under different uncertainties the respective expected values and the 95 confidence interval bands to enhance the adaptability of future reservoir operation keywords climate change uncertain streamflow responses adaptive reservoir operation stochastic decision making risk analysis data availability data will be made available on request 1 introduction in recent decades under the drastic influence of climate change extreme climate events and human activities the uncertainties of meteorological factors hydrological regimes and water resource elements with runoff as the main factor have been increasing leading to significant changes in water cycle processes at the regional and watershed scales and destabilizing the stationary nature of hydrological and water resource systems milly et al 2008 in addition the spatial and temporal distributions and evolution processes of water resources under the influence of changing climate and streamflow regimes involve multiple uncertainties and fuzziness single or multi objective reservoir operation is an important and effective regulation measure to realize optimal and sustainable control of water resources xu et al 2019 wang et al 2019a as the input information for reservoir operation the uncertain climate change induced runoff responses lead to challenges in the adaptive adjustment of multi objective reservoir cooperative operation and produce potential risks in comprehensive decision making and scheduling strategy formulation in the context of the stated uncertainties and risks caused by climate change and streamflow responses the following three topics have gradually become hotspots in water resource scheduling and decision making management 1 identifying the streamflow responses to climate change and analyze the response uncertainty 2 formulating adaptive strategies by using optimization tools for reservoir reservoir group operation through the cooperation of multiple scheduling objectives and 3 determining the uncertainty propagation process and quantify the potential decision making risks in terms of these stated three topics scholars have conducted related studies and achieved a series of theoretical and methodological results however most of the related studies failed to integrate the three points into a framework even though they attained multiple achievements by studying them separately or integrating two of them the representative studies and findings are summarized below however further research is still necessary especially regarding the development of a systematic framework using the general circulation model gcms data from the climate model inter comparison project cmip and a series of downscaling methods and hydrological models scholars have conducted qualitative and quantitative analyses of streamflow responses to regional climate change under representative concentration pathways rcps milly et al 2005 chase et al 2016 zheng et al 2018 the results have revealed that the runoff response exhibits spatial and temporal variability and uncertainty eisner et al 2017 created an ensemble of nine reginal hydrological models driven by climate projections derived from five gcms under four rcps to analyze the seasonality of streamflow responses in 11 river basins shrestha et al 2018 studied future streamflow responses to future climate change and environmental changes in thailand their results showed that under rcp scenarios 4 5 and 8 5 the streamflow in thailand will decrease by 19 5 and 24 respectively however a study on southwestern china showed that the runoff will increase as both the temperature and precipitation increase wen et al 2018 guo et al 2020 projected the effects of both climate and land use cover changes on the streamflow in the xinanjiang basin their results based on five gcms three rcps and three land use cover change scenarios revealed that the changes in the annual mean streamflow will mainly be driven by the latter which may decrease due to the influence of climate change based on studies of climate and environment changes and corresponding streamflow responses some scholars have projected or predicted the effects of future streamflow on reservoir operations using some adaptive strategies ahmadi et al 2015 adopted an adaptive model to adjust the reservoir operation scheme for the karoon 4 reservoir in iran using a strategy that is adaptive to climate change under multiple scenarios xu et al 2015 proposed rules for multistage optimal hedging operations incorporating uncertain predictions that consider hydrological nonstationary inflows van vliet et al 2016 established a coupled hydrological electricity modelling framework using representative global data for hydropower and thermoelectric power plants using the coupled model they assessed the responses and vulnerability of the current global hydropower and thermoelectric power generation system to changing climate and water resources wu et al 2017 evaluated the adaptive regulation of the xinanjiang reservoir under the influence of climate change to improve hydropower generation and water resource utilization benefits wan 2018 proposed a hedging reservoir operation model of water storage risk and adaptive strategies to handle future drought changes influenced by future climate change and human activities to adapt to future climate change feng et al 2018 assessed the impacts of future climate changes on long term future hydropower generation in the jinsha river and pursued the maximization of hydropower generation in cascade reservoirs using the gravitational search algorithm gsa he et al 2020 derived adaptive operation rules with a good performance compared with those designed for cascade reservoir systems based on future projections 2021 2100 of two typical gcms zhou 2020 verified the effects of reservoir storage and climate change on the nonstationary nature of worldwide flood peaks and evaluated the flood risk using the frequency analysis approach ahmadianfar and zamani 2020 evaluated the agricultural irrigation based reservoir operation responses to regional drought caused by climate change and adopted two stage hedging model to buffer the negative effects of droughts in comparison with standard operation policy sop this work can explore profound academic achievements by further discussing the uncertainty propagation from future streamflow response under climate change to the hedging rules of reservoir operation and quantifying potential risk information nourani et al 2020 adopted the wavelet analysis wa decision tree m5 model and genetic algorithm ga to simulate the runoff process and adaptive scheduling regulation of the shahrchay reservoir in iran under rcp emission scenarios 4 5 and 8 5 their results showed that both the annual runoff and water resource availability decreased in the distant future and the reservoir operation curves exhibited different shapes under the selected scenarios the lu s work coupled a two dimensional hydrodynamic model with a rainfall runoff model and integrated the ecological operation scheme into the hydrodynamic simulation system considering ecological flow lu et al 2022 this work considers reservoir ecological operation for adaptation to climate change it is encouraged to further conduct the streamflow process uncertainty and its effect on reservoir operation adaptability quantified risk in terms of optimization methods for multiple time scale single or multi objective reservoir operation various methods have been widely used mainly including dynamic programing dp he et al 2021 mixed integer linear programming cheng et al 2018 zhang et al 2021 mathura et al 2021 evolutionary algorithms eas and bionic intelligent algorithms bia lu et al 2015 cavazzini et al 2018 zhu et al 2020 parallel computing pc is frequently used for efficient computation based on increased cores and the high performance of computer technology pc helps to alleviate the computation burden based on the cooperative work of multiple cores threads the shuffled frog leaping algorithm sfla is a well established population based evolutionary optimization method which simulates the hunting behavior of the frog population the sfla assigns frogs to multiple relatively independent sub populations local search and shuffles them to communicate global prey information based on the inherent compatibility with parallel computing design the multi core pc was adopted to develop modified parallel multi objective sfla based on a well established fork join framework moreover some modifications were incorporated to further enhance the optimization efficiency of the proposed optimization solver regarding the studies described above most of them merely considered one or two points and they usually ignored some of the details in the adaptive reservoir operation and decision making process under changing climate and streamflow responses in real world application multiple uncertainties exist in the streamflow responses optimal reservoir operation and decision making process leading to risks in making multi objective reservoir operation decisions the uncertainty and potential risks propagated from the streamflow situation under climate change to the reservoir operation optimization or simulation models and to the final water resource decision decision making process increases as the uncertainty level of the streamflow responses to the future climate increases ignoring these uncertainties make it difficult to identify the potential decision error risks for future reservoir operation when we select the most preferred reservoir operation solution in confidence however the true smart solution is another solution which is assigned an arbitrary rank impacted by the stochastic decision criteria values cvs consequently the future reservoir operation benefit such as the clean power generation ecological protection and flood control will be damaged and may even include great loss and risk thus it is significant to develop a systematic framework that integrates these seemingly separate points into a well established simulation chain the framework should incorporate a series of methodologies and models for making more robust risk informed reservoir operation decisions with a higher reliability in this study we established a changing climate uncertain streamflow responses reservoir operation optimization decision error risk framework which integrates 1 the streamflow responses to climate change derived by using representative gcms and rcps coupled with the soil and water assessment tool swat hydrological model 2 modified parallel computing based on the multi objective shuffling frog leaping algorithm mpcmosfla 3 stochastic simulation for adaptive multi objective reservoir operation amoro considering uncertain streamflow responses using the fuzzy extension principle fep and 4 novel stochastic multi criteria acceptability analysis smaa for incorporating stochastic decision making and risk quantification indices into the simulation chain the qing river basin which contains a connected reservoir group system was selected as the study area we conducted numerical experiments based on three gcms and rcps two ecological modes and four uncertainty levels based on the fuzzy alpha level cut α cut to investigate the effects of uncertain streamflow responses on optimal reservoir operation including the downstream ecological benefit and hydropower generation and the potential decision making error risk finally the most preferred adaptive scheduling solutions referred as pareto optimal solutions under multiple uncertainty levels were identified to help managers and decision makers dms make robust decisions for adapting to climate change and streamflow responses in the distant future 2 methodology in this section the established framework and systematic simulation chain are elaborated with six sub sections where the data methods and models adopted and modified are elaborated the flowchart of systematic framework is shown as fig 1 2 1 the gcms and bias correction method the gcm climate projections are reached by the earth system grid federation https esgf node llnl gov the cesm1 cam5 miroc esm and noresm1 m 1 1 are selected from multiple gcms whose model performance are premier verified by previous study chen et al 2014 the low resolution problem of raw gcms may not possess the statistical characteristics of the observed data implying that bias correction operation is necessary and critical to construct relationship between high resolution gcm and local climate the raw gcm projections and observations are first interpolated to produce the meteorological variables including the daily precipitation maximum and minimum air temperatures at multiple meteorological stations by the well established inverse distance weighted idw then in this work the future rainfall data projected by gcms are downscaled to reproduce reginal climate features based on multivariate 3 dimensional bias correction 3dbc and station observations the 3dbc approach extends quantile matching qm by applying rank correction rc and rank shuffling ss procedures it can correct the biases in distribution and dependence attributes across multiple variables locations and time scales simultaneously mehrotra and sharma 2019 more details of 3dbc can be reached in hu et al 2020 where the future water energy situation is studied to develop adaptive strategies the projections of gcms with bias correction are used to drive the calibrated swat for future streamflow response simulation 2 2 the swat model for far future streamflow projection the swat is verified a high performance and commonly used distributed hydrological model based on the principle of water balance in this study the swat model is adopted to simulate and project future streamflow process of study area under climate change the swat divides basin into several sub basins and generates a hydrological response unit hru which is the smallest unit by overlaying the land use soil and slope type data the water flow in each hru is simulated based on the water budget formula and the total runoff of the whole basin is calculated more details can be reached in wang et al 2019b and guo et al 2020 the procedures of parameter calibration verification and sensitivity analysis in the swat model are conducted by the swat calibration and uncertainty programs swat cup abbaspour et al 2007 the larger absolute value of t statistics and smaller value of p value represent more sensitive parameter in swat model moreover to quantificationally evaluate model performance the nash sutcliffe efficiency nse dile et al 2016 coefficients of determination r2 woldesenbet et al 2017 and root mean square error rmse is utilized in this study 2 3 uncertainty analysis for streamflow simulation the multiple drivers in gcms and rcps introduce many uncertainties assumptions and simplifications due to inadequate information leading to unstable and uncontrolled outcomes for managers and dms identifying the uncertainty and fluctuation range of the predicted streamflow driven by different gcms is beneficial for comprehensive water resources management fuzzy set fs theory can handle problems involving multiple uncertainties and random factors especially problems associated with indeterminate information zadeh 1994 zadeh s extension principle zep is a fundamental concept in fs theory and it enables crisp mathematical operation in fss islam et al 2021 in this study we adopted the fep wambura et al 2015 to assess and implicitly quantify the uncertainty in future streamflow processes projected using gcms a horizontal line referred to as fuzzy alpha level cut α cut is used in fep to describe the elements belonging to a certainty level from the membership function the membership level has values of 0 to 1 and is expressed using a triangular type membership function 1 β a x 0 x a x a b a a x b c x c b b x c 0 x c where β a x is the degree of membership of x in fuzzy subset a a and c are the lower and upper bounds respectively while the b is the core mean level of the triangular fuzzy number ayağ and özdemir 2012 the x has no membership β a x 0 when its value is smaller than the a and larger than c the β a x 1 represents the full membership of x the α cut is the certainty level ranging from zero to one which can be characterized using the triangular fuzzy number as follows 2 m α b a α b c α b a α a c b α c α 0 1 where the value of α can be determined by the dms or experts which indicates the confidence over their judgements or decisions the high α cut usually corresponds to higher confidence degree and the lower uncertainty level assume that the α cut is valued with 0 50 and 100 corresponding uncertainty levels will be 100 50 and 0 respectively 2 4 multi objective optimization solver 2 4 1 basic shuffled frog leaping algorithm sfla the sfla is a well established population based evolutionary optimization method which imitates frog hunting activity in swamps the prey positions denote the potential solutions for optimization problem frogs in each swamp represent a sub population frogs in sub populations stalked its prey by leaping through stones distributed in swamps the prey positions are continuously updated by frog communication in respective sub populations the continuously updated positions can be defined as local search process then frogs from different sub populations are shuffled and shared respective prey positions with other frogs i e global shuffling process more details of sfla can be found in previous studies sun et al 2016 yang et al 2019a in sfla only the worst frogs ranked based on its fitness in each sub population 3 d i r a n d f u n u b u w 4 u wupd u w d i d min d i d max where rand denotes a random number in the interval 0 1 d i is frog leap step i 1 2 3 m d min and d max are the minimum and maximum frog leap steps respectively u wupd is the updated positions attached by frogs u b and u w represent the optimal and worst frog positions in each sub population respectively 2 4 2 modified parallel computing based multi objective sfla mpcmosfla to solve an adaptive multi objective reservoir operation problem involving multiple optimization goals and complex constraints it is necessary to convert the single objective version of the sfla into the multi objective version and boost the optimization precision to efficiently locate the preferred solutions i e the non dominated solutions in addition the computing tasks are burdensome due to high dimension coding for the joint operation of cascade reservoirs and the algorithm s complexity thus in this study we modified two aspects of the multi objective version of the sfla 1 the computing process was accelerated and 2 the performance of the algorithm performance was enhanced in terms of the acceleration of the computing process the multi core parallel computing pc based on the well established fork join framework was adopted in this work the parallel mode of the algorithm sacrifices the spatial complexity for temporal complexity to complete the computation task through simultaneous use of multiple central processing units cpus or computers the schematic diagram of fork join parallel computing framework is shown in fig 2 from the perspective of performance enhancement the external elite frog set eefs is adopted to maintain and update the excellent frog individuals based on simulated binary crossover moreover we modified the local search strategy to improve the algorithm s exploration performance and proposed a frog mutation mechanism based on chaos theory to avoid falling to the local optima the details of these modifications and the parallel computing execution and performance assessment can be found in appendix a it is evident that the sub population division strategy and frog shuffling operation in sfla coincide with the pc process based on the fork join framework using fork join framework based pc the performance of the modified multi objective sfla was enhanced and the overall computation speed was remarkably accelerated 2 5 stochastic simulation for adaptive multi objective reservoir operation the reservoir operation and decision making process involved information on multiple factors such as the weather streamflow situations water conservancy project status and decision making consultation between managers or experts moreover the future weather and streamflow processes projected using gcms under rcps were affected by the uncertainty of the information the model assumptions and the simplifications thus reservoir managers work in an uncertain and changing environment especially the complex situations associated with climate change to handle climate induced uncertainty problems perera et al 2020 adopted a stochastic optimization model for quantifying the impacts of extreme climate change and non extreme conditions on the energy system they obtained a set of non dominated solutions across the pareto front that consider two competing levels of the grid integration and present net value inspired by previous studies in this study we constructed a stochastic simulation model for adaptive multi objective reservoir operation based on future reservoir inflow projected using representative gcms in addition the various levels of uncertainty resulting from the uncertainties or ranges of in the gcm projections were simulated and analyzed then we quantified the effect of the uncertainties of the streamflow projections on the reservoir operation by generating a set of future inflow scenarios and a multi objective stochastic model as was previously stated the uncertainties or ranges of the future streamflow projected using gcms were analyzed at different levels based on the streamflow uncertainty analysis the inflow scenarios were generated then the stochastic multi objective simulation model was repeatedly executed to simultaneously maximize the hydropower generation and minimize the ecological water spill and shortage ewss under all future inflow scenarios thus the noninferior solutions optimized using the stochastic model had a statistical distribution for two competing goals hydropower and ecology instead of single points along the pareto front 2 5 1 objective functions 1 hydropower generation hpg 108 kwh 5 m a x e hpg i 1 g t 1 t n i t δ t n i t k i q i t hpg h i t 2 ecological water spill and shortage ewss 108 m3 6 min e eflow t 1 t q sx t q eflow t δ t where e hpg and e eflow are the hydropower generation and ecological water spill and shortage respectively δ t is the operation time intervals g and t are the total reservoirs and operation time intervals 12 months respectively n i t is the power output of the i th hydropower station during the t th time interval and h i t is the water head of the i th hydropower station during the t th time interval k i is the efficiency coefficient of the unit in the i th hydropower station q i t hpg is the flow of hydropower generation for the i th reservoir during the t th time interval q sx t is the water discharge corresponding to the most downstream reservoir in the cascade reservoir group and q eflow t denotes the different levels of ecological water requirements downstream of the reservoir 2 5 2 key constraints the key constraints include the 1 water balance constraint 2 hydraulic connection 3 reservoir storage and reservoir discharge 4 reservoir water level constraint and 5 hydro unit output constraint details can be reached in yang et al 2020 2 6 smaa 2 and its modifications for stochastic decision making as was previously stated we obtained a group of feasible solutions for adaptive multi objective reservoir operation using the stochastic simulation the corresponding stochastic decision making model is also necessary for finding the most preferred solution for multiple scenarios the effect of the various levels of streamflow projections on the decision making process should also be disclosed to this end we used the stochastic multi criteria acceptability analysis smaa to complete these tasks the details of the stochastic decision making model are presented in the following sections 2 6 1 basic smaa 2 model the inverse weight space analysis iwsa in the smaa 2 helps dms to determine the most preferred alternative or solution under the stochastic environment using the preferred uncertainty criteria values cvs and criteria weights cws of the dms the smaa 2 generalized the analysis to a common utility or value function to include various types of preference information and to consider all of the ranks holistically lahdelma salminen 2001 if there are total of m alternatives and n assessment criteria for decision making the cws vector can be expressed as ω j ω 1 ω 2 ω 3 ω n the cvs in the smaa 2 are represented by the stochastic variable v ij the probability distribution function of which is defined as f v sv the cws are represented by the weight probability distribution function f w w in the feasible space w s the alternatives are mapped to the utility function values by the real value utility function 7 u i u v i ω j 1 n v ij ω j 8 w s ω r n j 1 n ω j 1 ω 0 where v ij is the value of the j th criteria in terms of the i th alternative and u i is the utility function which is a function of the cws and cvs the favorable weight fw set w i r v is one of the critical concepts in the smaa 2 any weight combination from the weight set will allocate the utility value to the alternative to make its preferred ranking r in the smaa 2 two core indices are used to assess the alternatives the rank acceptability index rai and the holistic acceptability index hai the rai can be used to measure the variation in the different preferences or evaluations which give each alternative specific ranks and corresponding acceptable probabilities the hai can investigate the overall acceptable degree of the alternatives by combining all of the rank acceptability indices it can be defined as a second order decision process the details of these indices are described in appendix b 2 6 2 novel smaa 2 variant the utility function in the smaa 2 usually suffers from relative weak alternative differentiation fortunately the series of smaa models is flexible enough to combine with multiple mcdm models such as the technique for order of preference by similarity to ideal solution topsis grey relational analysis gra and bidirectional projection method bpm by replacing the original utility functions in this study the smaa 2 model was boosted in conjunction with the proposed coupling mcdm model by adopting a new form of utility function based on the modified gra mgra and bpm 9 updated u i m g r a b p m v i ω where the mgra b p m is the updated utility function relative to the original utility function the new utility function for the smaa 2 model can efficiently utilize the respective strengths of the modified gra and bpm the bpm can improve the alternative discrimination and avert unidirectional deviation that occurs in the conventional projection method while the mgra can handle the grey information derived from random hydrological processes and uncertain reservoir operation and decision making the details of the novel utility function can be found in appendix c 1 2 6 3 smaa o model it is difficult to calculate utility function values of the smaa 2 series of models directly since the performance values of the qualitative criteria are usually non linear to solve this problem the smaa o was designed for problems where the criteria information is totally or partially ordinal and is difficult to precisely quantify i e qualitative or ordinal criteria instead of a quantified series of cvs some quantitative cardinal values such as 1 2 5 are provided as alternatives to ensure consistency with their qualitative descriptions and rankings assigned by managers or experts here the monte carlo mc simulation was adopted to generate distinct random numbers from 0 to 1 with a uniform distribution which were then ranked in descending order to map the qualitative rankings to the quantitative values if the alternatives are equally preferred the same rankings are assigned to these alternatives and the other alternatives will be assigned the remaining rankings consecutively based on their qualitative descriptions fig c1 in appendix c 2 shows an example of mapping of the quantitative values with total of eleven alternatives more details of the smaa o can be reached in appendix c 2 2 6 4 potential risks quantification as was described above the optimized noninferior solutions possess statistical distribution for two competing goals resulting in potential uncertainties in the decision making process in which we build decision matrix data based on two competing goals moreover the space of the cws is also fuzzy and uncertain due to the coordination between multiple experts and managers in this study the cws following a uniform normal distributions ucws ncws and random cws distributed in the feasible weight space rcws are discussed these uncertainties further increase the risk of decision error that is of the solutions getting the other rankings instead of the rankings confirmed by the rais and hais to address this problem the decision error risk der and rank uncertainty degree rud were adopted to assess and quantify the risk information both the interconnected der and rud are cost criteria i e the smaller the value is the better the result 10 der r 2 m β r i a r rfirst β r r r 2 m r 11 rud i 1 m r 1 r r f i n a l m i a i r i 1 m r 1 m i a i r i 1 m i a i rank m i 1 m i a i rank where β r denotes the risk weights representing the contributions of all of the solutions to the der and i a r rfirst is the acceptability of the most preferred solution that obtains the r th rank according to the hais m is the total number of solutions and the rank denotes the rankings of each solution obtained based on their hais the rud is utilized to further assess the overall ranking uncertainty based on the rais by summarizing the probabilities that each solution obtains the other rankings 3 case study 3 1 study area the qing river basin is dominated by subtropical monsoon climate with mean annual temperature between 15 c and 16 c and about 1400 mm of average annual precipitation based on data during1960 2009 the storm in qing river basin mostly occurs in june to september and the storm flood peak emerges mainly in june july and september the shuibuya geheyan and gaobazhou construct a series connection reservoir system as shown in fig 3 with total installation capacity of 332 2 104kw the cascade reservoirs play important role in hydropower generation flood control water supply and agricultural irrigation yang et al 2019b 3 2 ecological scheduling mode and streamflow uncertainty level settings in this work the ecological flow demands are computed for downstream gaobazhou by setting two ecological scheduling modes i e the suitable ecological flow sef and ideal ecological flow ief the ecological flows are computed based on well established tennant method considering influence factors such as runoff regime water quality aquatic ecosystem and vegetation coverage combined with the basic ecological flow the following fig 4 is drawn to show sef and ief intervals for the downstream control section here the sef and ief intervals are defined as corresponding ecological modes in terms of the streamflow uncertainty level as stated above the fuzzy alpha level cut α cut method is adopted to define four uncertainty levels α 25 50 75 100 to disclose effect of uncertain streamflow projections on the reservoir operation and decision making process 3 3 data information and swat model establishment the swat model establishment sensitivity analysis calibration and validation are conducted in appendix g also the data information including the dem digital elevation model land use data meteorological data and gcm climate projections are listed in this paper we used the 3dbc method and observed station data to correct and downscale the gcm temperature and precipitation during the period of baseline and far future in the upstream of cascade reservoirs the raw and 3dbc downscaling of gcm projections are compared by evaluation indexes results indicate that the performance indexes for precipitation and temperature are improved implying that 3dbc downscaling can correct the gcm temperature and precipitation the uncertainty will be reduced and results are more reliable and accurate to reflect the ground truth the observed and simulated daily streamflow process under typical calibration and validation periods nse 0 85 and r2 0 87 are shown in following fig 5 3 4 modelling the streamflow and amoro responses modelling under various climate change scenarios in this section the future streamflow 2021 2100 under various downscaled gcms and rcp scenarios is projected using the calibrated swat model the results of the mean monthly streamflow responses and the corresponding projected changes in the mean annual streamflow are presented in fig 6 and table 1 analysis section can be found in appendix h h 1 then we obtained a series of non dominated solutions from no 1 to 50 by running the mpcmosfla based on the simulated streamflow in baseline and mean streamflow under all of the selected models the ecological flow goals including the ief and sef were considered simultaneously the corresponding trade off solutions distributed in the pareto front pareto non dominated solutions are shown in fig 7 in which both the ewss and hpg goals are exhibited analysis section can be found in appendix h h 2 since we defined the scale of the pareto solution as 50 several non dominated solutions were selected uniformly as typical samples for further analysis these sampled solutions are labeled s1 s10 with an interval of five furthermore we compared them from the aspect of the gcms and rcps the ief mode was chosen as an example for the analysis and discussion since the comparison results of the two ecological flow modes are similar the simulated pareto non dominated solutions based on different gcms cesm1 cam5 miroc esm and noresm1 m are shown in fig 8 a c the corresponding results under rcps 2 6 4 5 and 8 5 are compared in fig 9 a c analysis section can be found in appendix h h 2 in addition the results simulated based on the baseline and mean level for all of the gcms and rcps were compared moreover the projections under the selected gcms and rcps scenarios are shown to further reveal the mechanisms of the hpg and ewss responses to the projected reservoir inflow under climate change fig 10 shows the corresponding hpg and ewss responses under the ief and sef modes simultaneously it can be seen that there are near linear relationships can be identified between the projected changes in the reservoir inflow with the projected hpg and ewss usually the reservoir inflow process is the energy source for the hpg in addition the reservoir s discharge and surplus water direct influence the downstream ewss based on the hydraulic connection constraint the linear relationship between the reservoir discharge and the surplus water under the inflow process is acceptable therefore we can identify the similar responses of the hpg and ewss to changes in the reservoir inflow 3 5 stochastic decision making using the modified smaa in the previous section we analyzed and quantified the propagation of the uncertainty from the future streamflow simulated based on the gcms and swat to the pareto non dominated solutions optimized using the mpcmosfla in this section we identify the effects of the uncertainty information on the decision making and quantify the potential decision error risk the decision matrix for the smaa is developed based on two quantitative and qualitative assessment criteria these two criteria are the hpg and ewss while power generation reliability pgr and river ecology security res are the qualitative criteria the cvs are computed based on the pareto non dominated solutions optimized under the baseline and gcms ief and sef ecological modes the deterministic and stochastic weighting matrixes are also critical input information for the smaa which is constructed using the coordinated weighting method then we run the smaa repeatedly based on the decision matrix and weighting matrixes developed a total of 10 000 monte carlo simulations are used to solve the model to find the most preferred solutions under the stochastic environment in contrast the rais hais and ders are calculated based on the input information on the historical baseline and the future projection represented by the mean level of the selected gcms the comparison under the ief mode is presented as an example figs 11 13 analysis section can be found in appendix h h 3 furthermore the deterministic and stochastic cws are considered to disclose the risk information der under the different gcms and rcp scenarios the ders under the selected rcps and four types of cws are exhibited in the order of the gcms fig 14 in addition under the different types of cws the ders of the rcps and gcms adopted are shown in fig 15 figs 14 15 explicitly show the decision error risk caused by the propagation of the uncertain information from the streamflow simulation and pareto non dominated solutions analysis section can be found in appendix h h 3 fig 16 appendix h h 3 presents the corresponding der and rud responses to the projected changes in the inflow under climate change instead of linear relationship fig 10 non linear relationships are obtained between the projected changes in the inflow and the der and rud based on the information of the multiple cws it is known that multiple uncertain sources and factors are involved in the framework which contains the projected climate change inflow process reservoir operation and decision making thus the responses of the der and rud to the model inputs of the projected reservoir inflow are more complex compared with the reservoir hpg and ewss optimization goals 3 6 uncertainty analysis it is quite clear that the streamflow simulated based on the gcm projections is affected by the uncertainty and ranges at the various levels due to the distinct mechanisms and assumptions these uncertain factors are propagated to the multi objective reservoir operation and the comprehensive decision making leading to inevitable uncertainties in scientific reservoir operation and decision error risks therefore in this study the fep method was adopted to describe the future streamflow uncertainty which was computed for α cut values of 0 25 50 and 75 finally the corresponding uncertainty levels for the projected streamflow based on the selected gcms and rcps were determined to be 100 75 50 and 25 the uncertainty ranges are denoted by the colored strips in fig 17 as is shown in fig 17 the variation orange stripe in the monthly streamflow reaches the maximum in july and ranges from 475 28 to 776 23 m3 s the streamflow in may also fluctuates between 634 58 and 817 25 m3 s while the variations are less than 100 m3 s for the streamflow in november december january and february the minimum deviation occurs in december and january with values of 39 54 and 39 24 m3 s respectively the baseline streamflow 1990 1999 exceeds the upper bounds in february and august main flood season and the lower bounds at the end of the flood and non flood seasons from september to november from the runoff distribution the streamflow in both the baseline and future periods is mainly concentrated from april to september it should be noticed that the future streamflow migrates from february to march june and july and from august to september resulting in a higher earlier peak and a more uniformly distributed streamflow in the main flood seasons therefore the flood season may be prolonged and extreme flooding events in the main flood seasons may be underestimated by the gcms to further demonstrate the effect of the uncertainty levels on the multi objective reservoir operation pareto non dominated solution the mean monthly streamflow scenarios are generated based on a normal random function within each uncertainty range the quantity of the streamflow scenarios were defined as 40 according to the 2σ rule of the normal distribution these scenarios were made to have a probability of 95 44 to fall within the respective intervals here we adopted the latin hypercube sampling lhs monte carlo simulation to synthesize the monthly streamflow scenarios following a normal distribution then we use the simulated streamflow scenarios under different uncertainty levels as the inputs of the stochastic model for the amoro the ecological modes included the ief and sef the stochastic model was executed repeatedly with predefined iterations to obtain the pareto non dominated solutions numbered 1 to 50 corresponding to each streamflow scenario here we selected s6 number 28 from the 10 solutions s1 s10 as an example the corresponding s6s optimized based on the projected streamflow scenarios under each uncertainty level are shown in fig 18 with the hpg and ewss as goals as we expected fig 18 shows that the ranges of the hpg and ewss boxes gradually expand as the uncertainty level increases the results disclose the propagation process of the streamflow uncertainty and its effect on the multi objective optimization process the effect of the uncertainty is transmitted to the final multi criteria decision making process leading to risk information which make it difficult for dms to make reliable operation decisions for reservoirs the uncertainty and risk information are analyzed and disclosed for the dms they can actively adapt to the uncertainties of the future climate change and gcm simulations using the available informed risk information next we investigated the effect of the uncertain pareto non dominated solutions on the decision making process owing to the different uncertainty levels of the streamflow simulation each streamflow scenario implies a distinct decision for multi objective reservoir operation to coordinates the expected value of multiple objectives over all of the scenarios by inputting the optimized non dominated solutions based on different streamflow scenarios the decision matrixes of the cvs simultaneously consist of random variables with certain statistical distributions and constants in this section a set of criteria including two quantitative criteria of the reservoir operation objectives and two risk criteria are developed to comprehensively measure the performance of the solutions the former two quantitative criteria represent the hydropower benefit hpg and ecological benefit ewss respectively it is acceptable for both to follow a normal distribution according to the results of the kolmogorov smirnova and shapiro wilk tests the two risk criteria are defined as insufficient hydropower risk ihr and ecological water overtopping risk ewor these criteria are a mixture of the benefit hpg and cost criteria ewss ewor and ihr furthermore we introduce two qualitative criteria ranked by the dms and experts the first is the hydropower reliability hr which is used to assess the reliability and effectiveness of the hydropower benefits the other is the downstream ecology security des which estimates the overall security of the health of the downstream ecosystem here we take the 25 uncertainty level ief mode as an example the stochastic decision matrix of the cvs containing the quantitative qualitative and risk criteria is presented in table 2 the decision matrixes of the cws are constructed using the determined criteria weights dcws rcws and two types of stochastic cws ucws and ncws the decision making results including the rais hais and ders based on the respective cvs and four types of cws are computed using the proposed smaa model similarly two ecological modes are simulated and analyzed the results are shown in fig 19 analysis section can be found in appendix i fig i1 the rais are integrated to obtain the corresponding hais fig 20 so that we can identify the holistic ranking information and measure the overall performance of each solution it is evident that the holistic acceptability of the deterministic and stochastic cws is distinct the hais are more strikingly discriminated for the deterministic cws compared with that of the two stochastic cws the hais of the 25 uncertainty level are discriminated overall with a higher holistic acceptability but the discrimination significantly decreases as the uncertainty level increases the hais are coherent with the rais which helps to comprehensively evaluate the non dominated solutions under each uncertainty level table 3 presents the most preferred non dominated solutions under the uncertainty levels the data in table 3 discloses the changes in the decision making process when different cws and the uncertainty levels are considered except for the rcws s8 s9 s4 and s9 we selected as the most preferred non dominated solutions under the four types of uncertainty levels the results suggest that uncertain information will exist in the streamflow simulation and multi objective optimization and will have a great effect on the final decision made by the dms in this stage the dms can select the corresponding most preferred solution according to the rais and hais under different uncertain situations however the dms should note that the error risk still exists in the mcdm due to the uncertainties of the future streamflow projections and cws thus the ders are computed fig 21 to quantify the risk of erroneous decisions and to reveal the risk transmission for the dms the corresponding ders of the dcws ucws and ncws under the uncertainty levels are higher than those of the mean of the gcms 0 0247 0 0269 and 0 0248 as was expected fig 21 indicates that a high streamflow uncertainty level results in a higher decision error risk fig 21 b clearly illustrates the risk distribution and propagation between the different uncertainty levels and cws using a colored surface map it shows that higher decision error risks red color are mainly associated with the high uncertainty level for the streamflow simulation and the stochastic cws which are the major uncertainty sources discussed the interconnected ruds provide the same conclusion this conclusion indicates that the uncertain information can propagate from the streamflow simulation to the non dominated solution optimization and ultimately affects the decision process ultimately if dms ignore this information the final decision released may be completely erroneous coherent conclusions can be drawn when we investigate the results e g the rais and hais under the sef ecological mode appendix e figs e1 e2 and table e1 in the pre decision process s1 and s2 are prominent with unclear decision information rcws for the dms then given the deterministic and two stochastic cws information s9 outperforms the others in terms of the rais and hais under the 25 50 and 75 uncertainty levels while the decision changes from s9 to s3 when the uncertainty level increases to 100 in terms of the ders fig 22 the decision error risk increases when the cws are stochastic and the uncertainty level increases the sd surface map describes the phenomenon more clearly suggesting that the uncertain factors in the reservoir operation and decision making should not be omitted 3 7 preferred non dominated solutions under uncertainty levels in this section the most preferred non dominated solutions are explored using the novel smaa model and considering different uncertain and fuzzy levels of the streamflow scenarios according to the streamflow projected using the gcms the monthly distribution of runoff increases from the short term 2021 2035 to the medium term 2046 2065 and then it decreases from the medium term to the long term 2081 2100 nevertheless the runoff in the entire future period from 2021 to 2100 still increases and the increase mainly occurs in the pre flood and non flood seasons therefore to enhance the adaptability of future flood control in the pre flood season and to alleviate the potential risk of flooding in the non flood season especially in the downstream shuibuya reservoir the water levels from june to september are strictly confined to the flood control water level in terms of the ief mode figs 23 26 appendix j figs j1 j4 shows the detailed scheduling process of the amoro with the expected values and 95 confidence interval bands which are computed using the multiple preferred solutions optimized based on the streamflow scenarios figs 23 26 not only provides the expected values but also provide the confidence interval range of the most preferred solution selected for each uncertainty level for example we selected s8 as the most preferred solution under the 25 uncertainty level ief ecological mode fig 23 shows the details reservoir water level discharge and hydropower output of the optimized s8s based on each individual streamflow scenario the red lines with circles in fig 23 a c represent the expected preferred values of the reservoir water level discharge process and hydropower output respectively the orange bands denote the corresponding 95 confidence interval which provide the possible ranges for reservoir adaptive operation in the future the results corresponding to the sef mode can be found in appendix f figs f1 f4 obviously the reservoir water level reservoir discharge and hydropower output exhibit stochastic characteristic when explicitly incorporating the uncertainty of the future streamflow simulation into the multi objective optimization process for the mcdm process the uncertainties of the cws are simultaneously incorporated resulting in the decision making being more uncertain and difficult thus to enhance the adaptability of the uncertain information to multi objective reservoir operation the stochastic amoro simulation is conducted to obtain a series of preferred non dominated solutions for each streamflow scenario generated under different uncertainty levels these solutions help to ensure that on average the values of the multiple objective can be optimally coordinated the expected preferred solutions figs 23 26 are not necessarily optimal for each scenario but they represent the most reliable solutions on average if dms consider all of the streamflow scenarios which have different probabilities of occurrence simultaneously more details can be found in appendix j through comparison it was found that the non dominated solution under the 100 uncertainty level fig 25 the 95 confidence bands of the water levels of the shuibuya and geheyan reservoirs are narrower than those of the 75 uncertainty level especially the ief ecological mode the uncertainty of the discharge and hydropower generation for the geheyan reservoir slightly increases during the flood season however for the water levels of the gaobazhou reservoir in specific months from march to june under the 75 and 100 uncertainty levels it is significant that the 95 confidence bands corresponding to the former uncertainty level are strikingly narrower than that of the 100 uncertainty level the results of the comparison suggest that the geheyan reservoir has a greater effect on the effect of uncertainty of the future streamflow when the uncertainty increases to a high level in addition the results shown in fig 27 appendix j indicate that the water levels in the pre flood season corresponding to the ief mode are more sensitive to the effect of the extremely uncertain inflow process compared with the sef mode in fact to satisfy the ief demand for downstream river health the optimized non dominated solutions increase the reservoir discharge in several pre flood months and the water levels of the gaobazhou reservoir fall in faster in this scenario however compared with the ief mode the corresponding discharge for the sef mode can be decreased when a lower ecological flow demand needs to be satisfied therefore the confidence ranges of the water levels in the pre flood season are wider than those of the sef mode 4 discussion in this study a framework for supporting multi objective operation and decision making for cascade reservoirs under changing climate and future streamflow processes is proposed the cascade reservoirs on the qing river were selected as a case study to demonstrate the proposed methods and models the framework integrates by four sub parts 1 streamflow response identification and uncertainty analysis 2 reservoir multi objective optimization 3 stochastic decision making and 4 uncertainty propagation and risk analysis finally the most preferred non dominated reservoir scheduling solutions under varying uncertainty levels 25 50 75 and 100 are formulated with expected values and 95 confidence interval bands the proposed framework helps dms and managers to investigate the robustness of their final decisions for future reservoir operation adjustment and allows risk informed water energy exploration and ecological system protection decisions to be made with higher reliabilities to be made in this section some of the important results we obtained are discussed and the potential limitations and weaknesses are identified 4 1 future streamflow response relative to the baseline the future streamflow under three representatives downscaled gcms and rcps indicates that the flood periods will occur earlier and be longer compared to the baseline period the mean streamflow from may to september is 561 98 m3 s which is an increase of 7 94 relative to that during the baseline period in addition an increase in the monthly streamflow will occur observed in the non flood periods compared to the baseline the changes in the streamflow will lead to numerous uncertainties in the joint operation of the cascade reservoirs on the qing river therefore it is critical to adjust the current reservoir operation scheme to cope with future streamflow reservoir inflow and enhance the adaptability of the water energy utilization and downstream ecological system protection 4 2 optimized non dominated scheduling solution under gcms and rcps under the changing climate and future streamflow situation the non dominated solutions optimized using the mpcmosfla are uniformly distributed in the pareto fronts fig 7 the ewss and hpg exhibit a competing and contradicting relationship when these goals are simultaneously considered the main difference between the two types of ecological goals is in the ewss especially the couple of solutions after s9 we marked while the hpgs of the goals are obviously similar nevertheless when we consider the sef mode the hydropower benefit hpg is weaker to a certain extent due to the relatively amount of water used for river ecosystem health comparison from the perspective of the gcms fig 8 revealed that the responses of the hpg to the selected gcms are enhanced under rcps 2 6 4 5 and 8 5 compared to the baseline period this phenomenon is consistent with the future streamflow processes projected using the three gcms comparison of the three gcms revealed that the cesm1 cam5 outperforms in terms of the hpg since this model has the most pronounced increase in future streamflow compared with those of the miroc esm and noresm1 m in terms of the three rcps fig 8 the responses of the hpg to all of the gcms are the largest under rcp 4 5 while the ewss increases simultaneously except in noresm1 m under rcp 8 5 which increases the hpg these results indicate that a high emission scenario will increase the uncertainty of the future precipitation streamflow projections and reservoir operation responses to some extent in addition it should be noted that loss of the ecological protection benefit ewss is also significant when the future hydropower generation increases 4 3 two stage stochastic decision making and quantified risk the two stage decision making process was adopted to make the reservoir multi objective operation based on the future streamflow situation more robust and reliable in the first stage managers and dms from different interests stakeholders and departments are unwilling or hesitant to share their decision preferences criteria preference since they need detailed discussion and information for collaborative decision making the policies of ecological protection and hydropower exploration are also key points in the decision consultation conducted by different interest groups and departments in the second stage more adequate information for decision making is available and managers and dms start to express their decision preferences confidently the dcws are acquired which coordinate the different decision preferences the rais indicate that s9 has the largest probability of obtaining the best rank in both the baseline and future time periods mean of the gcms when the dcws are input however in real world applications perfect negotiation is usually hard to achieve leading to fluctuating and uncertain cws information the stochastic coordinated cws with normal and uniform distributions were adopted to quantify the effect of the uncertain cws on decision making the simulation results show that the rais are consistent and less differentiated at a given level compared with those of the dcws the decision error risk we quantified based on the der and rud indicators is still worthy of attention because it is influenced by the inherently uncertain streamflow in the baseline and future periods since the global environment changes drastically we should consider the risk information according to which we can adjust the management strategies to adapt to the uncertain environment in the future the der comparison suggests that the decision error risk is smaller in the future compared with the baseline period this smaller risk may be caused by the relatively dominated future streamflow in the flood season and the decreased streamflow in the late non flood season however the propagation of the risk from the streamflow uncertainty to the decision error should be followed to improve the risk awareness and adjust the ability of the reservoir operation 4 4 streamflow uncertainty and preferred non dominated solutions analysis under uncertainty levels the fep method was adopted to describe the future streamflow uncertainty for four typical uncertainty levels we identified the effects of the uncertainty levels on the multi objective reservoir operation pareto non dominated solution decision making and quantified decision error risk the most preferred non dominated solutions selected changed when different cws and uncertainty levels were considered implying that we should place emphasis on the uncertain information which can propagate from the streamflow simulation to the non dominated solution optimization and ultimately affects the decision process the goal of the proposed framework and methodologies was to explore the adaptive future reservoir multi objective operation solutions based on different uncertain and fuzzy levels of streamflow scenarios possible ranges of 1 the reservoir water level 2 reservoir discharge process and 3 hydropower output plan are provided to managers and dms this detailed solution information enables managers and dms to make more robust and reliable reservoir operation adjustment plans based on informed potential risks under the 25 uncertainty level fig 23 the monthly mean water levels of the shuibuya and geheyan reservoirs are distinct from march to may while they exhibit similar trends in the other months this is explained by the fact that the flood control task is undertaken by cascade reservoirs in the flood season resulting in limited optimization space therefore the main differences occur in the non flood season the water level of the geheyan reservoir changes more dramatically than that of the shuibuya reservoir implying that the effects of the uncertain factors on the water level of the geheyan reservoir before the flood season are more pronounced nevertheless the discharge of the shuibuya reservoir fluctuates sharply compared with that of the geheyan reservoir since the hydropower outputs are correlated with the water head and discharge similar variation trends and confidence intervals can be identified between the reservoir discharge and hydropower outputs in both the ief and sef modes as the uncertainty level of the streamflow simulation increases to 50 and 75 fig 24 fig 25 the upper and lower bounds of the confidence intervals gradually extend due to the incorporation of more uncertain information into the amoro process for the 75 uncertainty level fig 25 the fluctuation range of the water level in may is close to 4 m in the shuibuya and geheyan reservoirs the range of the reservoir discharge is also larger than that of the other uncertainty levels especially in april and may the hydropower outputs of the shuibuya reservoir in the pre flood and later flood seasons also vary widely compared with those at the lower uncertainty levels the hydropower generation of the geheyan reservoir in the flood season fluctuates significantly as the uncertainty level increases influenced by the high uncertainty level of the future streamflow the corresponding discharge process is adjusted to enhance the adaptability of the uncertain reservoir inflow even though the water levels in the flood season are strictly limited 4 5 potential limitations and future research although we obtained a series of important results and conclusions by proposed systematic framework more applications can be found in appendix k potential limitations should be identified to conduct deep research in the future it should be noticed that in real world applications a future extreme flood prediction model would be required if we conduct related studies for reservoir flood control operation and decision making three representative gcms are adopted in this work to analyze the uncertain future streamflow situation by swat model and uncertainty analysis tool except for the uncertainties in gcms the hydrological model also suffered with uncertain factors such as the input information structure of model and parameter calibration also factors in the reservoir multi objective operation are uncertain such as the hydropower unit output characteristic curves of reservoir so it is promising to consider these complex uncertainties simultaneously and quantify their effects on reservoir operation and decision making in future research 5 conclusions since the drastic influence of climate change and human activities the uncertainties exist in meteorological factors hydrological regime and water resource elements leading to significant changes and uncertainties in water cycle processes the uncertain climate change induced runoff responses lead to challenges in adaptive adjustment of multi objective reservoir cooperative operation and potential risks for comprehensive decision making and scheduling strategy formulation implementing reservoir multi objective operation based on future streamflow situation usually needs three steps 1 future streamflow responses and uncertainty analysis upstream 2 reservoir operation optimization downstream 3 decision making and risk analysis downstream previous studies usually considered one or two points we stated above the step 1 attracts the most attention against a background of the changing climate and environment researchers adopted multiple downscaling method to improve the resolution of gcms and make it more applicable for driving hydrological model some researchers focus on step 2 by exploring high efficiency optimization method without considering the potential risks and uncertain factors for future reservoir operation caused by uncertain streamflow process in terms of risk analysis some researchers evaluate the effect of streamflow forecast uncertainty on reservoir operation however fixed operation rules without optimization are applied to disclose the risks from uncertain streamflow process in fact operation rules are not constant and it should be replaced by optimization models which are more flexible and efficient for utilizing future streamflow information previous studies devote to establishing an integrated chain including the forecast reservoir operation optimization decision making for reservoir operation and decision making under uncertainties however under the changing environment the gap is existing that how can we adjust water resources management strategy smartly with identifying effects of future streamflow response on reservoir multi objective operation and decision making also risk propagation mechanism caused by multiple uncertainties in future streamflow response reservoir operation and decision making should be disclosed to improve the robustness of water resources utilization and awareness of risk under the changing environment thus it is necessary and beneficial to construct the integrated framework for supporting the smart water resources scheduling and management based on identifying uncertain far future streamflow situation in this study a systematic framework including the climate change projection streamflow responses stochastic reservoir operation and decision making models streamflow uncertainty analysis and risk quantification was developed to characterize the far future streamflow variations under climate change and to determine the transmission of multi source uncertainties and the cumulative effects on the adaptive regulations of future reservoir operation and the decision making error risk the main conclusions of this study are as follows 1 the future annual mean streamflow projections obtained using all of the gcms and rcps exhibit increasing trends under the different rcps and the larger peak value of the monthly streamflow projected using the miroc esm and noresm1 m occurs earlier than in the baseline period the flood periods in the future tend to occur earlier and have longer durations than during the baseline period the mean streamflow from may to september increases by 7 94 while the increase in the mean streamflow from october to february next year is more significant relative to that during the baseline period even though the trend decreases from january to february 2 the responses of the hpg to all of the gcms are larger under rcps 2 6 4 5 and 8 5 compared to the baseline which is consistent with the future streamflow projected using the gcms the responses of the hpg for the noresm1 m increase with increasing emission concentration while the response of the hpg to rcp 4 5 is the most significant under cesm1 cam5 and miroc esm overall the pareto non dominated solutions optimized based on the streamflow projections obtained using the gcms the same rcp and hydrological model are more distinct than those obtained using different rcps and the same gcm the high emission scenario may increase the uncertainty of the future streamflow projections and the reservoir operation responses 3 the smaa simulation indicates that the ders and ruds potential risk increase as both the emission concentration and uncertainty of the cws increase based on the reservoir inflow projected by the cesm1 cam5 this is consistent with conclusion 2 that is the higher emission scenario leads to more complex and uncertain reservoir operation and decision making responses especially when the uncertain cws information is incorporated the distinct distribution of the risk information obtained using the noresm1 m also implies that the uncertainties among the gcm projections are striking these results suggest that it is necessary to consider the effects of both the uncertain streamflow and the cws on the decision making process in real world applications 4 the uncertainty analysis based on the fuzzy extension principle revealed that the multi level uncertainties propagate from the uncertain streamflow projections to the reservoir operation and decision making processes the cumulative effect of the uncertain information in the simulation chain on the final scheduling solution selection and potential decision error risk was quantified the results suggest that as the uncertainty level increases decision making fluctuates more and is more sensitive to the uncertain streamflow and the decision matrixes of the cvs and cws 5 using the proposed systematic framework dms can make more robust decisions by determining the most preferred scheduling solutions under different uncertainty levels and the corresponding risk information instead of the single most preferred scheduling solution the details of the reservoir operation processes such as the reservoir water level discharge and hydropower output are provided to the dms with respective expected values and 95 confidence interval bands which provide the possible ranges of the reservoir adaptive operation in the future declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is supported by the national natural science foundation of china grant no 52109034 chinese universities scientific fund grant nos 2452021085 2452021086 shaanxi province department of science and technology grant no 2023 jc qn 0572 cyrus tang foundation state key laboratory of hydraulics and mountain river engineering sichuan university grant no skhl2112 and key laboratory of resource environment and sustainable development of oasis gansu province grant no gors202101 the authors appreciated for the insightful comments and suggestions from editors and anonymous reviewers appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129518 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 supplementary data 5 supplementary data 6 supplementary data 7 supplementary data 8 supplementary data 9 supplementary data 10 supplementary data 11 
1971,significant climate variations have decreased the stability of water resource systems leading to multiple uncertainties in streamflow response reservoir operation optimization decision making and adaptive adjustments for water resource scheduling understanding the impact of climate change on reginal streamflow is necessary and crucial to identifying reservoir operation strategies and decision making responses in this study we created an integrated systematic uncertain streamflow responses reservoir operation optimization decision making risk analysis chain three bias corrected and downscaled general circulation models gcms were used to analyze the inter model uncertainties under three representative concentration pathways rcps the streamflow responses and uncertainty in the future were determined using a distributed hydrological model and the fuzzy extension principle under predefined scenarios and uncertainty levels then a stochastic simulation model and modified stochastic multi criteria decision making model were applied to identify the effects of climate change projections and streamflow responses on reservoir multi objective operation and decision making moreover risk quantification indices were used to determine the uncertainty propagation and potential risks accumulated in the chain we applied this framework to cascade reservoirs in the qing river basin the results indicate that the mean annual streamflow projected using selected gcms will increase enhancing the hydropower response and weakening the ecological benefit response the pareto non dominated solutions optimized based on the streamflow projections obtained using the gcms under the same rcp and hydrological model are more distinct than those based on different rcps and the same gcm moreover a high emission scenario may increase the uncertainty of the streamflow projections and reservoir operation responses which is consistent with the finding that the decision making process becomes more variable and sensitive with increasing streamflow uncertainty finally we identified the preferred solutions for reservoir operation under different uncertainties the respective expected values and the 95 confidence interval bands to enhance the adaptability of future reservoir operation keywords climate change uncertain streamflow responses adaptive reservoir operation stochastic decision making risk analysis data availability data will be made available on request 1 introduction in recent decades under the drastic influence of climate change extreme climate events and human activities the uncertainties of meteorological factors hydrological regimes and water resource elements with runoff as the main factor have been increasing leading to significant changes in water cycle processes at the regional and watershed scales and destabilizing the stationary nature of hydrological and water resource systems milly et al 2008 in addition the spatial and temporal distributions and evolution processes of water resources under the influence of changing climate and streamflow regimes involve multiple uncertainties and fuzziness single or multi objective reservoir operation is an important and effective regulation measure to realize optimal and sustainable control of water resources xu et al 2019 wang et al 2019a as the input information for reservoir operation the uncertain climate change induced runoff responses lead to challenges in the adaptive adjustment of multi objective reservoir cooperative operation and produce potential risks in comprehensive decision making and scheduling strategy formulation in the context of the stated uncertainties and risks caused by climate change and streamflow responses the following three topics have gradually become hotspots in water resource scheduling and decision making management 1 identifying the streamflow responses to climate change and analyze the response uncertainty 2 formulating adaptive strategies by using optimization tools for reservoir reservoir group operation through the cooperation of multiple scheduling objectives and 3 determining the uncertainty propagation process and quantify the potential decision making risks in terms of these stated three topics scholars have conducted related studies and achieved a series of theoretical and methodological results however most of the related studies failed to integrate the three points into a framework even though they attained multiple achievements by studying them separately or integrating two of them the representative studies and findings are summarized below however further research is still necessary especially regarding the development of a systematic framework using the general circulation model gcms data from the climate model inter comparison project cmip and a series of downscaling methods and hydrological models scholars have conducted qualitative and quantitative analyses of streamflow responses to regional climate change under representative concentration pathways rcps milly et al 2005 chase et al 2016 zheng et al 2018 the results have revealed that the runoff response exhibits spatial and temporal variability and uncertainty eisner et al 2017 created an ensemble of nine reginal hydrological models driven by climate projections derived from five gcms under four rcps to analyze the seasonality of streamflow responses in 11 river basins shrestha et al 2018 studied future streamflow responses to future climate change and environmental changes in thailand their results showed that under rcp scenarios 4 5 and 8 5 the streamflow in thailand will decrease by 19 5 and 24 respectively however a study on southwestern china showed that the runoff will increase as both the temperature and precipitation increase wen et al 2018 guo et al 2020 projected the effects of both climate and land use cover changes on the streamflow in the xinanjiang basin their results based on five gcms three rcps and three land use cover change scenarios revealed that the changes in the annual mean streamflow will mainly be driven by the latter which may decrease due to the influence of climate change based on studies of climate and environment changes and corresponding streamflow responses some scholars have projected or predicted the effects of future streamflow on reservoir operations using some adaptive strategies ahmadi et al 2015 adopted an adaptive model to adjust the reservoir operation scheme for the karoon 4 reservoir in iran using a strategy that is adaptive to climate change under multiple scenarios xu et al 2015 proposed rules for multistage optimal hedging operations incorporating uncertain predictions that consider hydrological nonstationary inflows van vliet et al 2016 established a coupled hydrological electricity modelling framework using representative global data for hydropower and thermoelectric power plants using the coupled model they assessed the responses and vulnerability of the current global hydropower and thermoelectric power generation system to changing climate and water resources wu et al 2017 evaluated the adaptive regulation of the xinanjiang reservoir under the influence of climate change to improve hydropower generation and water resource utilization benefits wan 2018 proposed a hedging reservoir operation model of water storage risk and adaptive strategies to handle future drought changes influenced by future climate change and human activities to adapt to future climate change feng et al 2018 assessed the impacts of future climate changes on long term future hydropower generation in the jinsha river and pursued the maximization of hydropower generation in cascade reservoirs using the gravitational search algorithm gsa he et al 2020 derived adaptive operation rules with a good performance compared with those designed for cascade reservoir systems based on future projections 2021 2100 of two typical gcms zhou 2020 verified the effects of reservoir storage and climate change on the nonstationary nature of worldwide flood peaks and evaluated the flood risk using the frequency analysis approach ahmadianfar and zamani 2020 evaluated the agricultural irrigation based reservoir operation responses to regional drought caused by climate change and adopted two stage hedging model to buffer the negative effects of droughts in comparison with standard operation policy sop this work can explore profound academic achievements by further discussing the uncertainty propagation from future streamflow response under climate change to the hedging rules of reservoir operation and quantifying potential risk information nourani et al 2020 adopted the wavelet analysis wa decision tree m5 model and genetic algorithm ga to simulate the runoff process and adaptive scheduling regulation of the shahrchay reservoir in iran under rcp emission scenarios 4 5 and 8 5 their results showed that both the annual runoff and water resource availability decreased in the distant future and the reservoir operation curves exhibited different shapes under the selected scenarios the lu s work coupled a two dimensional hydrodynamic model with a rainfall runoff model and integrated the ecological operation scheme into the hydrodynamic simulation system considering ecological flow lu et al 2022 this work considers reservoir ecological operation for adaptation to climate change it is encouraged to further conduct the streamflow process uncertainty and its effect on reservoir operation adaptability quantified risk in terms of optimization methods for multiple time scale single or multi objective reservoir operation various methods have been widely used mainly including dynamic programing dp he et al 2021 mixed integer linear programming cheng et al 2018 zhang et al 2021 mathura et al 2021 evolutionary algorithms eas and bionic intelligent algorithms bia lu et al 2015 cavazzini et al 2018 zhu et al 2020 parallel computing pc is frequently used for efficient computation based on increased cores and the high performance of computer technology pc helps to alleviate the computation burden based on the cooperative work of multiple cores threads the shuffled frog leaping algorithm sfla is a well established population based evolutionary optimization method which simulates the hunting behavior of the frog population the sfla assigns frogs to multiple relatively independent sub populations local search and shuffles them to communicate global prey information based on the inherent compatibility with parallel computing design the multi core pc was adopted to develop modified parallel multi objective sfla based on a well established fork join framework moreover some modifications were incorporated to further enhance the optimization efficiency of the proposed optimization solver regarding the studies described above most of them merely considered one or two points and they usually ignored some of the details in the adaptive reservoir operation and decision making process under changing climate and streamflow responses in real world application multiple uncertainties exist in the streamflow responses optimal reservoir operation and decision making process leading to risks in making multi objective reservoir operation decisions the uncertainty and potential risks propagated from the streamflow situation under climate change to the reservoir operation optimization or simulation models and to the final water resource decision decision making process increases as the uncertainty level of the streamflow responses to the future climate increases ignoring these uncertainties make it difficult to identify the potential decision error risks for future reservoir operation when we select the most preferred reservoir operation solution in confidence however the true smart solution is another solution which is assigned an arbitrary rank impacted by the stochastic decision criteria values cvs consequently the future reservoir operation benefit such as the clean power generation ecological protection and flood control will be damaged and may even include great loss and risk thus it is significant to develop a systematic framework that integrates these seemingly separate points into a well established simulation chain the framework should incorporate a series of methodologies and models for making more robust risk informed reservoir operation decisions with a higher reliability in this study we established a changing climate uncertain streamflow responses reservoir operation optimization decision error risk framework which integrates 1 the streamflow responses to climate change derived by using representative gcms and rcps coupled with the soil and water assessment tool swat hydrological model 2 modified parallel computing based on the multi objective shuffling frog leaping algorithm mpcmosfla 3 stochastic simulation for adaptive multi objective reservoir operation amoro considering uncertain streamflow responses using the fuzzy extension principle fep and 4 novel stochastic multi criteria acceptability analysis smaa for incorporating stochastic decision making and risk quantification indices into the simulation chain the qing river basin which contains a connected reservoir group system was selected as the study area we conducted numerical experiments based on three gcms and rcps two ecological modes and four uncertainty levels based on the fuzzy alpha level cut α cut to investigate the effects of uncertain streamflow responses on optimal reservoir operation including the downstream ecological benefit and hydropower generation and the potential decision making error risk finally the most preferred adaptive scheduling solutions referred as pareto optimal solutions under multiple uncertainty levels were identified to help managers and decision makers dms make robust decisions for adapting to climate change and streamflow responses in the distant future 2 methodology in this section the established framework and systematic simulation chain are elaborated with six sub sections where the data methods and models adopted and modified are elaborated the flowchart of systematic framework is shown as fig 1 2 1 the gcms and bias correction method the gcm climate projections are reached by the earth system grid federation https esgf node llnl gov the cesm1 cam5 miroc esm and noresm1 m 1 1 are selected from multiple gcms whose model performance are premier verified by previous study chen et al 2014 the low resolution problem of raw gcms may not possess the statistical characteristics of the observed data implying that bias correction operation is necessary and critical to construct relationship between high resolution gcm and local climate the raw gcm projections and observations are first interpolated to produce the meteorological variables including the daily precipitation maximum and minimum air temperatures at multiple meteorological stations by the well established inverse distance weighted idw then in this work the future rainfall data projected by gcms are downscaled to reproduce reginal climate features based on multivariate 3 dimensional bias correction 3dbc and station observations the 3dbc approach extends quantile matching qm by applying rank correction rc and rank shuffling ss procedures it can correct the biases in distribution and dependence attributes across multiple variables locations and time scales simultaneously mehrotra and sharma 2019 more details of 3dbc can be reached in hu et al 2020 where the future water energy situation is studied to develop adaptive strategies the projections of gcms with bias correction are used to drive the calibrated swat for future streamflow response simulation 2 2 the swat model for far future streamflow projection the swat is verified a high performance and commonly used distributed hydrological model based on the principle of water balance in this study the swat model is adopted to simulate and project future streamflow process of study area under climate change the swat divides basin into several sub basins and generates a hydrological response unit hru which is the smallest unit by overlaying the land use soil and slope type data the water flow in each hru is simulated based on the water budget formula and the total runoff of the whole basin is calculated more details can be reached in wang et al 2019b and guo et al 2020 the procedures of parameter calibration verification and sensitivity analysis in the swat model are conducted by the swat calibration and uncertainty programs swat cup abbaspour et al 2007 the larger absolute value of t statistics and smaller value of p value represent more sensitive parameter in swat model moreover to quantificationally evaluate model performance the nash sutcliffe efficiency nse dile et al 2016 coefficients of determination r2 woldesenbet et al 2017 and root mean square error rmse is utilized in this study 2 3 uncertainty analysis for streamflow simulation the multiple drivers in gcms and rcps introduce many uncertainties assumptions and simplifications due to inadequate information leading to unstable and uncontrolled outcomes for managers and dms identifying the uncertainty and fluctuation range of the predicted streamflow driven by different gcms is beneficial for comprehensive water resources management fuzzy set fs theory can handle problems involving multiple uncertainties and random factors especially problems associated with indeterminate information zadeh 1994 zadeh s extension principle zep is a fundamental concept in fs theory and it enables crisp mathematical operation in fss islam et al 2021 in this study we adopted the fep wambura et al 2015 to assess and implicitly quantify the uncertainty in future streamflow processes projected using gcms a horizontal line referred to as fuzzy alpha level cut α cut is used in fep to describe the elements belonging to a certainty level from the membership function the membership level has values of 0 to 1 and is expressed using a triangular type membership function 1 β a x 0 x a x a b a a x b c x c b b x c 0 x c where β a x is the degree of membership of x in fuzzy subset a a and c are the lower and upper bounds respectively while the b is the core mean level of the triangular fuzzy number ayağ and özdemir 2012 the x has no membership β a x 0 when its value is smaller than the a and larger than c the β a x 1 represents the full membership of x the α cut is the certainty level ranging from zero to one which can be characterized using the triangular fuzzy number as follows 2 m α b a α b c α b a α a c b α c α 0 1 where the value of α can be determined by the dms or experts which indicates the confidence over their judgements or decisions the high α cut usually corresponds to higher confidence degree and the lower uncertainty level assume that the α cut is valued with 0 50 and 100 corresponding uncertainty levels will be 100 50 and 0 respectively 2 4 multi objective optimization solver 2 4 1 basic shuffled frog leaping algorithm sfla the sfla is a well established population based evolutionary optimization method which imitates frog hunting activity in swamps the prey positions denote the potential solutions for optimization problem frogs in each swamp represent a sub population frogs in sub populations stalked its prey by leaping through stones distributed in swamps the prey positions are continuously updated by frog communication in respective sub populations the continuously updated positions can be defined as local search process then frogs from different sub populations are shuffled and shared respective prey positions with other frogs i e global shuffling process more details of sfla can be found in previous studies sun et al 2016 yang et al 2019a in sfla only the worst frogs ranked based on its fitness in each sub population 3 d i r a n d f u n u b u w 4 u wupd u w d i d min d i d max where rand denotes a random number in the interval 0 1 d i is frog leap step i 1 2 3 m d min and d max are the minimum and maximum frog leap steps respectively u wupd is the updated positions attached by frogs u b and u w represent the optimal and worst frog positions in each sub population respectively 2 4 2 modified parallel computing based multi objective sfla mpcmosfla to solve an adaptive multi objective reservoir operation problem involving multiple optimization goals and complex constraints it is necessary to convert the single objective version of the sfla into the multi objective version and boost the optimization precision to efficiently locate the preferred solutions i e the non dominated solutions in addition the computing tasks are burdensome due to high dimension coding for the joint operation of cascade reservoirs and the algorithm s complexity thus in this study we modified two aspects of the multi objective version of the sfla 1 the computing process was accelerated and 2 the performance of the algorithm performance was enhanced in terms of the acceleration of the computing process the multi core parallel computing pc based on the well established fork join framework was adopted in this work the parallel mode of the algorithm sacrifices the spatial complexity for temporal complexity to complete the computation task through simultaneous use of multiple central processing units cpus or computers the schematic diagram of fork join parallel computing framework is shown in fig 2 from the perspective of performance enhancement the external elite frog set eefs is adopted to maintain and update the excellent frog individuals based on simulated binary crossover moreover we modified the local search strategy to improve the algorithm s exploration performance and proposed a frog mutation mechanism based on chaos theory to avoid falling to the local optima the details of these modifications and the parallel computing execution and performance assessment can be found in appendix a it is evident that the sub population division strategy and frog shuffling operation in sfla coincide with the pc process based on the fork join framework using fork join framework based pc the performance of the modified multi objective sfla was enhanced and the overall computation speed was remarkably accelerated 2 5 stochastic simulation for adaptive multi objective reservoir operation the reservoir operation and decision making process involved information on multiple factors such as the weather streamflow situations water conservancy project status and decision making consultation between managers or experts moreover the future weather and streamflow processes projected using gcms under rcps were affected by the uncertainty of the information the model assumptions and the simplifications thus reservoir managers work in an uncertain and changing environment especially the complex situations associated with climate change to handle climate induced uncertainty problems perera et al 2020 adopted a stochastic optimization model for quantifying the impacts of extreme climate change and non extreme conditions on the energy system they obtained a set of non dominated solutions across the pareto front that consider two competing levels of the grid integration and present net value inspired by previous studies in this study we constructed a stochastic simulation model for adaptive multi objective reservoir operation based on future reservoir inflow projected using representative gcms in addition the various levels of uncertainty resulting from the uncertainties or ranges of in the gcm projections were simulated and analyzed then we quantified the effect of the uncertainties of the streamflow projections on the reservoir operation by generating a set of future inflow scenarios and a multi objective stochastic model as was previously stated the uncertainties or ranges of the future streamflow projected using gcms were analyzed at different levels based on the streamflow uncertainty analysis the inflow scenarios were generated then the stochastic multi objective simulation model was repeatedly executed to simultaneously maximize the hydropower generation and minimize the ecological water spill and shortage ewss under all future inflow scenarios thus the noninferior solutions optimized using the stochastic model had a statistical distribution for two competing goals hydropower and ecology instead of single points along the pareto front 2 5 1 objective functions 1 hydropower generation hpg 108 kwh 5 m a x e hpg i 1 g t 1 t n i t δ t n i t k i q i t hpg h i t 2 ecological water spill and shortage ewss 108 m3 6 min e eflow t 1 t q sx t q eflow t δ t where e hpg and e eflow are the hydropower generation and ecological water spill and shortage respectively δ t is the operation time intervals g and t are the total reservoirs and operation time intervals 12 months respectively n i t is the power output of the i th hydropower station during the t th time interval and h i t is the water head of the i th hydropower station during the t th time interval k i is the efficiency coefficient of the unit in the i th hydropower station q i t hpg is the flow of hydropower generation for the i th reservoir during the t th time interval q sx t is the water discharge corresponding to the most downstream reservoir in the cascade reservoir group and q eflow t denotes the different levels of ecological water requirements downstream of the reservoir 2 5 2 key constraints the key constraints include the 1 water balance constraint 2 hydraulic connection 3 reservoir storage and reservoir discharge 4 reservoir water level constraint and 5 hydro unit output constraint details can be reached in yang et al 2020 2 6 smaa 2 and its modifications for stochastic decision making as was previously stated we obtained a group of feasible solutions for adaptive multi objective reservoir operation using the stochastic simulation the corresponding stochastic decision making model is also necessary for finding the most preferred solution for multiple scenarios the effect of the various levels of streamflow projections on the decision making process should also be disclosed to this end we used the stochastic multi criteria acceptability analysis smaa to complete these tasks the details of the stochastic decision making model are presented in the following sections 2 6 1 basic smaa 2 model the inverse weight space analysis iwsa in the smaa 2 helps dms to determine the most preferred alternative or solution under the stochastic environment using the preferred uncertainty criteria values cvs and criteria weights cws of the dms the smaa 2 generalized the analysis to a common utility or value function to include various types of preference information and to consider all of the ranks holistically lahdelma salminen 2001 if there are total of m alternatives and n assessment criteria for decision making the cws vector can be expressed as ω j ω 1 ω 2 ω 3 ω n the cvs in the smaa 2 are represented by the stochastic variable v ij the probability distribution function of which is defined as f v sv the cws are represented by the weight probability distribution function f w w in the feasible space w s the alternatives are mapped to the utility function values by the real value utility function 7 u i u v i ω j 1 n v ij ω j 8 w s ω r n j 1 n ω j 1 ω 0 where v ij is the value of the j th criteria in terms of the i th alternative and u i is the utility function which is a function of the cws and cvs the favorable weight fw set w i r v is one of the critical concepts in the smaa 2 any weight combination from the weight set will allocate the utility value to the alternative to make its preferred ranking r in the smaa 2 two core indices are used to assess the alternatives the rank acceptability index rai and the holistic acceptability index hai the rai can be used to measure the variation in the different preferences or evaluations which give each alternative specific ranks and corresponding acceptable probabilities the hai can investigate the overall acceptable degree of the alternatives by combining all of the rank acceptability indices it can be defined as a second order decision process the details of these indices are described in appendix b 2 6 2 novel smaa 2 variant the utility function in the smaa 2 usually suffers from relative weak alternative differentiation fortunately the series of smaa models is flexible enough to combine with multiple mcdm models such as the technique for order of preference by similarity to ideal solution topsis grey relational analysis gra and bidirectional projection method bpm by replacing the original utility functions in this study the smaa 2 model was boosted in conjunction with the proposed coupling mcdm model by adopting a new form of utility function based on the modified gra mgra and bpm 9 updated u i m g r a b p m v i ω where the mgra b p m is the updated utility function relative to the original utility function the new utility function for the smaa 2 model can efficiently utilize the respective strengths of the modified gra and bpm the bpm can improve the alternative discrimination and avert unidirectional deviation that occurs in the conventional projection method while the mgra can handle the grey information derived from random hydrological processes and uncertain reservoir operation and decision making the details of the novel utility function can be found in appendix c 1 2 6 3 smaa o model it is difficult to calculate utility function values of the smaa 2 series of models directly since the performance values of the qualitative criteria are usually non linear to solve this problem the smaa o was designed for problems where the criteria information is totally or partially ordinal and is difficult to precisely quantify i e qualitative or ordinal criteria instead of a quantified series of cvs some quantitative cardinal values such as 1 2 5 are provided as alternatives to ensure consistency with their qualitative descriptions and rankings assigned by managers or experts here the monte carlo mc simulation was adopted to generate distinct random numbers from 0 to 1 with a uniform distribution which were then ranked in descending order to map the qualitative rankings to the quantitative values if the alternatives are equally preferred the same rankings are assigned to these alternatives and the other alternatives will be assigned the remaining rankings consecutively based on their qualitative descriptions fig c1 in appendix c 2 shows an example of mapping of the quantitative values with total of eleven alternatives more details of the smaa o can be reached in appendix c 2 2 6 4 potential risks quantification as was described above the optimized noninferior solutions possess statistical distribution for two competing goals resulting in potential uncertainties in the decision making process in which we build decision matrix data based on two competing goals moreover the space of the cws is also fuzzy and uncertain due to the coordination between multiple experts and managers in this study the cws following a uniform normal distributions ucws ncws and random cws distributed in the feasible weight space rcws are discussed these uncertainties further increase the risk of decision error that is of the solutions getting the other rankings instead of the rankings confirmed by the rais and hais to address this problem the decision error risk der and rank uncertainty degree rud were adopted to assess and quantify the risk information both the interconnected der and rud are cost criteria i e the smaller the value is the better the result 10 der r 2 m β r i a r rfirst β r r r 2 m r 11 rud i 1 m r 1 r r f i n a l m i a i r i 1 m r 1 m i a i r i 1 m i a i rank m i 1 m i a i rank where β r denotes the risk weights representing the contributions of all of the solutions to the der and i a r rfirst is the acceptability of the most preferred solution that obtains the r th rank according to the hais m is the total number of solutions and the rank denotes the rankings of each solution obtained based on their hais the rud is utilized to further assess the overall ranking uncertainty based on the rais by summarizing the probabilities that each solution obtains the other rankings 3 case study 3 1 study area the qing river basin is dominated by subtropical monsoon climate with mean annual temperature between 15 c and 16 c and about 1400 mm of average annual precipitation based on data during1960 2009 the storm in qing river basin mostly occurs in june to september and the storm flood peak emerges mainly in june july and september the shuibuya geheyan and gaobazhou construct a series connection reservoir system as shown in fig 3 with total installation capacity of 332 2 104kw the cascade reservoirs play important role in hydropower generation flood control water supply and agricultural irrigation yang et al 2019b 3 2 ecological scheduling mode and streamflow uncertainty level settings in this work the ecological flow demands are computed for downstream gaobazhou by setting two ecological scheduling modes i e the suitable ecological flow sef and ideal ecological flow ief the ecological flows are computed based on well established tennant method considering influence factors such as runoff regime water quality aquatic ecosystem and vegetation coverage combined with the basic ecological flow the following fig 4 is drawn to show sef and ief intervals for the downstream control section here the sef and ief intervals are defined as corresponding ecological modes in terms of the streamflow uncertainty level as stated above the fuzzy alpha level cut α cut method is adopted to define four uncertainty levels α 25 50 75 100 to disclose effect of uncertain streamflow projections on the reservoir operation and decision making process 3 3 data information and swat model establishment the swat model establishment sensitivity analysis calibration and validation are conducted in appendix g also the data information including the dem digital elevation model land use data meteorological data and gcm climate projections are listed in this paper we used the 3dbc method and observed station data to correct and downscale the gcm temperature and precipitation during the period of baseline and far future in the upstream of cascade reservoirs the raw and 3dbc downscaling of gcm projections are compared by evaluation indexes results indicate that the performance indexes for precipitation and temperature are improved implying that 3dbc downscaling can correct the gcm temperature and precipitation the uncertainty will be reduced and results are more reliable and accurate to reflect the ground truth the observed and simulated daily streamflow process under typical calibration and validation periods nse 0 85 and r2 0 87 are shown in following fig 5 3 4 modelling the streamflow and amoro responses modelling under various climate change scenarios in this section the future streamflow 2021 2100 under various downscaled gcms and rcp scenarios is projected using the calibrated swat model the results of the mean monthly streamflow responses and the corresponding projected changes in the mean annual streamflow are presented in fig 6 and table 1 analysis section can be found in appendix h h 1 then we obtained a series of non dominated solutions from no 1 to 50 by running the mpcmosfla based on the simulated streamflow in baseline and mean streamflow under all of the selected models the ecological flow goals including the ief and sef were considered simultaneously the corresponding trade off solutions distributed in the pareto front pareto non dominated solutions are shown in fig 7 in which both the ewss and hpg goals are exhibited analysis section can be found in appendix h h 2 since we defined the scale of the pareto solution as 50 several non dominated solutions were selected uniformly as typical samples for further analysis these sampled solutions are labeled s1 s10 with an interval of five furthermore we compared them from the aspect of the gcms and rcps the ief mode was chosen as an example for the analysis and discussion since the comparison results of the two ecological flow modes are similar the simulated pareto non dominated solutions based on different gcms cesm1 cam5 miroc esm and noresm1 m are shown in fig 8 a c the corresponding results under rcps 2 6 4 5 and 8 5 are compared in fig 9 a c analysis section can be found in appendix h h 2 in addition the results simulated based on the baseline and mean level for all of the gcms and rcps were compared moreover the projections under the selected gcms and rcps scenarios are shown to further reveal the mechanisms of the hpg and ewss responses to the projected reservoir inflow under climate change fig 10 shows the corresponding hpg and ewss responses under the ief and sef modes simultaneously it can be seen that there are near linear relationships can be identified between the projected changes in the reservoir inflow with the projected hpg and ewss usually the reservoir inflow process is the energy source for the hpg in addition the reservoir s discharge and surplus water direct influence the downstream ewss based on the hydraulic connection constraint the linear relationship between the reservoir discharge and the surplus water under the inflow process is acceptable therefore we can identify the similar responses of the hpg and ewss to changes in the reservoir inflow 3 5 stochastic decision making using the modified smaa in the previous section we analyzed and quantified the propagation of the uncertainty from the future streamflow simulated based on the gcms and swat to the pareto non dominated solutions optimized using the mpcmosfla in this section we identify the effects of the uncertainty information on the decision making and quantify the potential decision error risk the decision matrix for the smaa is developed based on two quantitative and qualitative assessment criteria these two criteria are the hpg and ewss while power generation reliability pgr and river ecology security res are the qualitative criteria the cvs are computed based on the pareto non dominated solutions optimized under the baseline and gcms ief and sef ecological modes the deterministic and stochastic weighting matrixes are also critical input information for the smaa which is constructed using the coordinated weighting method then we run the smaa repeatedly based on the decision matrix and weighting matrixes developed a total of 10 000 monte carlo simulations are used to solve the model to find the most preferred solutions under the stochastic environment in contrast the rais hais and ders are calculated based on the input information on the historical baseline and the future projection represented by the mean level of the selected gcms the comparison under the ief mode is presented as an example figs 11 13 analysis section can be found in appendix h h 3 furthermore the deterministic and stochastic cws are considered to disclose the risk information der under the different gcms and rcp scenarios the ders under the selected rcps and four types of cws are exhibited in the order of the gcms fig 14 in addition under the different types of cws the ders of the rcps and gcms adopted are shown in fig 15 figs 14 15 explicitly show the decision error risk caused by the propagation of the uncertain information from the streamflow simulation and pareto non dominated solutions analysis section can be found in appendix h h 3 fig 16 appendix h h 3 presents the corresponding der and rud responses to the projected changes in the inflow under climate change instead of linear relationship fig 10 non linear relationships are obtained between the projected changes in the inflow and the der and rud based on the information of the multiple cws it is known that multiple uncertain sources and factors are involved in the framework which contains the projected climate change inflow process reservoir operation and decision making thus the responses of the der and rud to the model inputs of the projected reservoir inflow are more complex compared with the reservoir hpg and ewss optimization goals 3 6 uncertainty analysis it is quite clear that the streamflow simulated based on the gcm projections is affected by the uncertainty and ranges at the various levels due to the distinct mechanisms and assumptions these uncertain factors are propagated to the multi objective reservoir operation and the comprehensive decision making leading to inevitable uncertainties in scientific reservoir operation and decision error risks therefore in this study the fep method was adopted to describe the future streamflow uncertainty which was computed for α cut values of 0 25 50 and 75 finally the corresponding uncertainty levels for the projected streamflow based on the selected gcms and rcps were determined to be 100 75 50 and 25 the uncertainty ranges are denoted by the colored strips in fig 17 as is shown in fig 17 the variation orange stripe in the monthly streamflow reaches the maximum in july and ranges from 475 28 to 776 23 m3 s the streamflow in may also fluctuates between 634 58 and 817 25 m3 s while the variations are less than 100 m3 s for the streamflow in november december january and february the minimum deviation occurs in december and january with values of 39 54 and 39 24 m3 s respectively the baseline streamflow 1990 1999 exceeds the upper bounds in february and august main flood season and the lower bounds at the end of the flood and non flood seasons from september to november from the runoff distribution the streamflow in both the baseline and future periods is mainly concentrated from april to september it should be noticed that the future streamflow migrates from february to march june and july and from august to september resulting in a higher earlier peak and a more uniformly distributed streamflow in the main flood seasons therefore the flood season may be prolonged and extreme flooding events in the main flood seasons may be underestimated by the gcms to further demonstrate the effect of the uncertainty levels on the multi objective reservoir operation pareto non dominated solution the mean monthly streamflow scenarios are generated based on a normal random function within each uncertainty range the quantity of the streamflow scenarios were defined as 40 according to the 2σ rule of the normal distribution these scenarios were made to have a probability of 95 44 to fall within the respective intervals here we adopted the latin hypercube sampling lhs monte carlo simulation to synthesize the monthly streamflow scenarios following a normal distribution then we use the simulated streamflow scenarios under different uncertainty levels as the inputs of the stochastic model for the amoro the ecological modes included the ief and sef the stochastic model was executed repeatedly with predefined iterations to obtain the pareto non dominated solutions numbered 1 to 50 corresponding to each streamflow scenario here we selected s6 number 28 from the 10 solutions s1 s10 as an example the corresponding s6s optimized based on the projected streamflow scenarios under each uncertainty level are shown in fig 18 with the hpg and ewss as goals as we expected fig 18 shows that the ranges of the hpg and ewss boxes gradually expand as the uncertainty level increases the results disclose the propagation process of the streamflow uncertainty and its effect on the multi objective optimization process the effect of the uncertainty is transmitted to the final multi criteria decision making process leading to risk information which make it difficult for dms to make reliable operation decisions for reservoirs the uncertainty and risk information are analyzed and disclosed for the dms they can actively adapt to the uncertainties of the future climate change and gcm simulations using the available informed risk information next we investigated the effect of the uncertain pareto non dominated solutions on the decision making process owing to the different uncertainty levels of the streamflow simulation each streamflow scenario implies a distinct decision for multi objective reservoir operation to coordinates the expected value of multiple objectives over all of the scenarios by inputting the optimized non dominated solutions based on different streamflow scenarios the decision matrixes of the cvs simultaneously consist of random variables with certain statistical distributions and constants in this section a set of criteria including two quantitative criteria of the reservoir operation objectives and two risk criteria are developed to comprehensively measure the performance of the solutions the former two quantitative criteria represent the hydropower benefit hpg and ecological benefit ewss respectively it is acceptable for both to follow a normal distribution according to the results of the kolmogorov smirnova and shapiro wilk tests the two risk criteria are defined as insufficient hydropower risk ihr and ecological water overtopping risk ewor these criteria are a mixture of the benefit hpg and cost criteria ewss ewor and ihr furthermore we introduce two qualitative criteria ranked by the dms and experts the first is the hydropower reliability hr which is used to assess the reliability and effectiveness of the hydropower benefits the other is the downstream ecology security des which estimates the overall security of the health of the downstream ecosystem here we take the 25 uncertainty level ief mode as an example the stochastic decision matrix of the cvs containing the quantitative qualitative and risk criteria is presented in table 2 the decision matrixes of the cws are constructed using the determined criteria weights dcws rcws and two types of stochastic cws ucws and ncws the decision making results including the rais hais and ders based on the respective cvs and four types of cws are computed using the proposed smaa model similarly two ecological modes are simulated and analyzed the results are shown in fig 19 analysis section can be found in appendix i fig i1 the rais are integrated to obtain the corresponding hais fig 20 so that we can identify the holistic ranking information and measure the overall performance of each solution it is evident that the holistic acceptability of the deterministic and stochastic cws is distinct the hais are more strikingly discriminated for the deterministic cws compared with that of the two stochastic cws the hais of the 25 uncertainty level are discriminated overall with a higher holistic acceptability but the discrimination significantly decreases as the uncertainty level increases the hais are coherent with the rais which helps to comprehensively evaluate the non dominated solutions under each uncertainty level table 3 presents the most preferred non dominated solutions under the uncertainty levels the data in table 3 discloses the changes in the decision making process when different cws and the uncertainty levels are considered except for the rcws s8 s9 s4 and s9 we selected as the most preferred non dominated solutions under the four types of uncertainty levels the results suggest that uncertain information will exist in the streamflow simulation and multi objective optimization and will have a great effect on the final decision made by the dms in this stage the dms can select the corresponding most preferred solution according to the rais and hais under different uncertain situations however the dms should note that the error risk still exists in the mcdm due to the uncertainties of the future streamflow projections and cws thus the ders are computed fig 21 to quantify the risk of erroneous decisions and to reveal the risk transmission for the dms the corresponding ders of the dcws ucws and ncws under the uncertainty levels are higher than those of the mean of the gcms 0 0247 0 0269 and 0 0248 as was expected fig 21 indicates that a high streamflow uncertainty level results in a higher decision error risk fig 21 b clearly illustrates the risk distribution and propagation between the different uncertainty levels and cws using a colored surface map it shows that higher decision error risks red color are mainly associated with the high uncertainty level for the streamflow simulation and the stochastic cws which are the major uncertainty sources discussed the interconnected ruds provide the same conclusion this conclusion indicates that the uncertain information can propagate from the streamflow simulation to the non dominated solution optimization and ultimately affects the decision process ultimately if dms ignore this information the final decision released may be completely erroneous coherent conclusions can be drawn when we investigate the results e g the rais and hais under the sef ecological mode appendix e figs e1 e2 and table e1 in the pre decision process s1 and s2 are prominent with unclear decision information rcws for the dms then given the deterministic and two stochastic cws information s9 outperforms the others in terms of the rais and hais under the 25 50 and 75 uncertainty levels while the decision changes from s9 to s3 when the uncertainty level increases to 100 in terms of the ders fig 22 the decision error risk increases when the cws are stochastic and the uncertainty level increases the sd surface map describes the phenomenon more clearly suggesting that the uncertain factors in the reservoir operation and decision making should not be omitted 3 7 preferred non dominated solutions under uncertainty levels in this section the most preferred non dominated solutions are explored using the novel smaa model and considering different uncertain and fuzzy levels of the streamflow scenarios according to the streamflow projected using the gcms the monthly distribution of runoff increases from the short term 2021 2035 to the medium term 2046 2065 and then it decreases from the medium term to the long term 2081 2100 nevertheless the runoff in the entire future period from 2021 to 2100 still increases and the increase mainly occurs in the pre flood and non flood seasons therefore to enhance the adaptability of future flood control in the pre flood season and to alleviate the potential risk of flooding in the non flood season especially in the downstream shuibuya reservoir the water levels from june to september are strictly confined to the flood control water level in terms of the ief mode figs 23 26 appendix j figs j1 j4 shows the detailed scheduling process of the amoro with the expected values and 95 confidence interval bands which are computed using the multiple preferred solutions optimized based on the streamflow scenarios figs 23 26 not only provides the expected values but also provide the confidence interval range of the most preferred solution selected for each uncertainty level for example we selected s8 as the most preferred solution under the 25 uncertainty level ief ecological mode fig 23 shows the details reservoir water level discharge and hydropower output of the optimized s8s based on each individual streamflow scenario the red lines with circles in fig 23 a c represent the expected preferred values of the reservoir water level discharge process and hydropower output respectively the orange bands denote the corresponding 95 confidence interval which provide the possible ranges for reservoir adaptive operation in the future the results corresponding to the sef mode can be found in appendix f figs f1 f4 obviously the reservoir water level reservoir discharge and hydropower output exhibit stochastic characteristic when explicitly incorporating the uncertainty of the future streamflow simulation into the multi objective optimization process for the mcdm process the uncertainties of the cws are simultaneously incorporated resulting in the decision making being more uncertain and difficult thus to enhance the adaptability of the uncertain information to multi objective reservoir operation the stochastic amoro simulation is conducted to obtain a series of preferred non dominated solutions for each streamflow scenario generated under different uncertainty levels these solutions help to ensure that on average the values of the multiple objective can be optimally coordinated the expected preferred solutions figs 23 26 are not necessarily optimal for each scenario but they represent the most reliable solutions on average if dms consider all of the streamflow scenarios which have different probabilities of occurrence simultaneously more details can be found in appendix j through comparison it was found that the non dominated solution under the 100 uncertainty level fig 25 the 95 confidence bands of the water levels of the shuibuya and geheyan reservoirs are narrower than those of the 75 uncertainty level especially the ief ecological mode the uncertainty of the discharge and hydropower generation for the geheyan reservoir slightly increases during the flood season however for the water levels of the gaobazhou reservoir in specific months from march to june under the 75 and 100 uncertainty levels it is significant that the 95 confidence bands corresponding to the former uncertainty level are strikingly narrower than that of the 100 uncertainty level the results of the comparison suggest that the geheyan reservoir has a greater effect on the effect of uncertainty of the future streamflow when the uncertainty increases to a high level in addition the results shown in fig 27 appendix j indicate that the water levels in the pre flood season corresponding to the ief mode are more sensitive to the effect of the extremely uncertain inflow process compared with the sef mode in fact to satisfy the ief demand for downstream river health the optimized non dominated solutions increase the reservoir discharge in several pre flood months and the water levels of the gaobazhou reservoir fall in faster in this scenario however compared with the ief mode the corresponding discharge for the sef mode can be decreased when a lower ecological flow demand needs to be satisfied therefore the confidence ranges of the water levels in the pre flood season are wider than those of the sef mode 4 discussion in this study a framework for supporting multi objective operation and decision making for cascade reservoirs under changing climate and future streamflow processes is proposed the cascade reservoirs on the qing river were selected as a case study to demonstrate the proposed methods and models the framework integrates by four sub parts 1 streamflow response identification and uncertainty analysis 2 reservoir multi objective optimization 3 stochastic decision making and 4 uncertainty propagation and risk analysis finally the most preferred non dominated reservoir scheduling solutions under varying uncertainty levels 25 50 75 and 100 are formulated with expected values and 95 confidence interval bands the proposed framework helps dms and managers to investigate the robustness of their final decisions for future reservoir operation adjustment and allows risk informed water energy exploration and ecological system protection decisions to be made with higher reliabilities to be made in this section some of the important results we obtained are discussed and the potential limitations and weaknesses are identified 4 1 future streamflow response relative to the baseline the future streamflow under three representatives downscaled gcms and rcps indicates that the flood periods will occur earlier and be longer compared to the baseline period the mean streamflow from may to september is 561 98 m3 s which is an increase of 7 94 relative to that during the baseline period in addition an increase in the monthly streamflow will occur observed in the non flood periods compared to the baseline the changes in the streamflow will lead to numerous uncertainties in the joint operation of the cascade reservoirs on the qing river therefore it is critical to adjust the current reservoir operation scheme to cope with future streamflow reservoir inflow and enhance the adaptability of the water energy utilization and downstream ecological system protection 4 2 optimized non dominated scheduling solution under gcms and rcps under the changing climate and future streamflow situation the non dominated solutions optimized using the mpcmosfla are uniformly distributed in the pareto fronts fig 7 the ewss and hpg exhibit a competing and contradicting relationship when these goals are simultaneously considered the main difference between the two types of ecological goals is in the ewss especially the couple of solutions after s9 we marked while the hpgs of the goals are obviously similar nevertheless when we consider the sef mode the hydropower benefit hpg is weaker to a certain extent due to the relatively amount of water used for river ecosystem health comparison from the perspective of the gcms fig 8 revealed that the responses of the hpg to the selected gcms are enhanced under rcps 2 6 4 5 and 8 5 compared to the baseline period this phenomenon is consistent with the future streamflow processes projected using the three gcms comparison of the three gcms revealed that the cesm1 cam5 outperforms in terms of the hpg since this model has the most pronounced increase in future streamflow compared with those of the miroc esm and noresm1 m in terms of the three rcps fig 8 the responses of the hpg to all of the gcms are the largest under rcp 4 5 while the ewss increases simultaneously except in noresm1 m under rcp 8 5 which increases the hpg these results indicate that a high emission scenario will increase the uncertainty of the future precipitation streamflow projections and reservoir operation responses to some extent in addition it should be noted that loss of the ecological protection benefit ewss is also significant when the future hydropower generation increases 4 3 two stage stochastic decision making and quantified risk the two stage decision making process was adopted to make the reservoir multi objective operation based on the future streamflow situation more robust and reliable in the first stage managers and dms from different interests stakeholders and departments are unwilling or hesitant to share their decision preferences criteria preference since they need detailed discussion and information for collaborative decision making the policies of ecological protection and hydropower exploration are also key points in the decision consultation conducted by different interest groups and departments in the second stage more adequate information for decision making is available and managers and dms start to express their decision preferences confidently the dcws are acquired which coordinate the different decision preferences the rais indicate that s9 has the largest probability of obtaining the best rank in both the baseline and future time periods mean of the gcms when the dcws are input however in real world applications perfect negotiation is usually hard to achieve leading to fluctuating and uncertain cws information the stochastic coordinated cws with normal and uniform distributions were adopted to quantify the effect of the uncertain cws on decision making the simulation results show that the rais are consistent and less differentiated at a given level compared with those of the dcws the decision error risk we quantified based on the der and rud indicators is still worthy of attention because it is influenced by the inherently uncertain streamflow in the baseline and future periods since the global environment changes drastically we should consider the risk information according to which we can adjust the management strategies to adapt to the uncertain environment in the future the der comparison suggests that the decision error risk is smaller in the future compared with the baseline period this smaller risk may be caused by the relatively dominated future streamflow in the flood season and the decreased streamflow in the late non flood season however the propagation of the risk from the streamflow uncertainty to the decision error should be followed to improve the risk awareness and adjust the ability of the reservoir operation 4 4 streamflow uncertainty and preferred non dominated solutions analysis under uncertainty levels the fep method was adopted to describe the future streamflow uncertainty for four typical uncertainty levels we identified the effects of the uncertainty levels on the multi objective reservoir operation pareto non dominated solution decision making and quantified decision error risk the most preferred non dominated solutions selected changed when different cws and uncertainty levels were considered implying that we should place emphasis on the uncertain information which can propagate from the streamflow simulation to the non dominated solution optimization and ultimately affects the decision process the goal of the proposed framework and methodologies was to explore the adaptive future reservoir multi objective operation solutions based on different uncertain and fuzzy levels of streamflow scenarios possible ranges of 1 the reservoir water level 2 reservoir discharge process and 3 hydropower output plan are provided to managers and dms this detailed solution information enables managers and dms to make more robust and reliable reservoir operation adjustment plans based on informed potential risks under the 25 uncertainty level fig 23 the monthly mean water levels of the shuibuya and geheyan reservoirs are distinct from march to may while they exhibit similar trends in the other months this is explained by the fact that the flood control task is undertaken by cascade reservoirs in the flood season resulting in limited optimization space therefore the main differences occur in the non flood season the water level of the geheyan reservoir changes more dramatically than that of the shuibuya reservoir implying that the effects of the uncertain factors on the water level of the geheyan reservoir before the flood season are more pronounced nevertheless the discharge of the shuibuya reservoir fluctuates sharply compared with that of the geheyan reservoir since the hydropower outputs are correlated with the water head and discharge similar variation trends and confidence intervals can be identified between the reservoir discharge and hydropower outputs in both the ief and sef modes as the uncertainty level of the streamflow simulation increases to 50 and 75 fig 24 fig 25 the upper and lower bounds of the confidence intervals gradually extend due to the incorporation of more uncertain information into the amoro process for the 75 uncertainty level fig 25 the fluctuation range of the water level in may is close to 4 m in the shuibuya and geheyan reservoirs the range of the reservoir discharge is also larger than that of the other uncertainty levels especially in april and may the hydropower outputs of the shuibuya reservoir in the pre flood and later flood seasons also vary widely compared with those at the lower uncertainty levels the hydropower generation of the geheyan reservoir in the flood season fluctuates significantly as the uncertainty level increases influenced by the high uncertainty level of the future streamflow the corresponding discharge process is adjusted to enhance the adaptability of the uncertain reservoir inflow even though the water levels in the flood season are strictly limited 4 5 potential limitations and future research although we obtained a series of important results and conclusions by proposed systematic framework more applications can be found in appendix k potential limitations should be identified to conduct deep research in the future it should be noticed that in real world applications a future extreme flood prediction model would be required if we conduct related studies for reservoir flood control operation and decision making three representative gcms are adopted in this work to analyze the uncertain future streamflow situation by swat model and uncertainty analysis tool except for the uncertainties in gcms the hydrological model also suffered with uncertain factors such as the input information structure of model and parameter calibration also factors in the reservoir multi objective operation are uncertain such as the hydropower unit output characteristic curves of reservoir so it is promising to consider these complex uncertainties simultaneously and quantify their effects on reservoir operation and decision making in future research 5 conclusions since the drastic influence of climate change and human activities the uncertainties exist in meteorological factors hydrological regime and water resource elements leading to significant changes and uncertainties in water cycle processes the uncertain climate change induced runoff responses lead to challenges in adaptive adjustment of multi objective reservoir cooperative operation and potential risks for comprehensive decision making and scheduling strategy formulation implementing reservoir multi objective operation based on future streamflow situation usually needs three steps 1 future streamflow responses and uncertainty analysis upstream 2 reservoir operation optimization downstream 3 decision making and risk analysis downstream previous studies usually considered one or two points we stated above the step 1 attracts the most attention against a background of the changing climate and environment researchers adopted multiple downscaling method to improve the resolution of gcms and make it more applicable for driving hydrological model some researchers focus on step 2 by exploring high efficiency optimization method without considering the potential risks and uncertain factors for future reservoir operation caused by uncertain streamflow process in terms of risk analysis some researchers evaluate the effect of streamflow forecast uncertainty on reservoir operation however fixed operation rules without optimization are applied to disclose the risks from uncertain streamflow process in fact operation rules are not constant and it should be replaced by optimization models which are more flexible and efficient for utilizing future streamflow information previous studies devote to establishing an integrated chain including the forecast reservoir operation optimization decision making for reservoir operation and decision making under uncertainties however under the changing environment the gap is existing that how can we adjust water resources management strategy smartly with identifying effects of future streamflow response on reservoir multi objective operation and decision making also risk propagation mechanism caused by multiple uncertainties in future streamflow response reservoir operation and decision making should be disclosed to improve the robustness of water resources utilization and awareness of risk under the changing environment thus it is necessary and beneficial to construct the integrated framework for supporting the smart water resources scheduling and management based on identifying uncertain far future streamflow situation in this study a systematic framework including the climate change projection streamflow responses stochastic reservoir operation and decision making models streamflow uncertainty analysis and risk quantification was developed to characterize the far future streamflow variations under climate change and to determine the transmission of multi source uncertainties and the cumulative effects on the adaptive regulations of future reservoir operation and the decision making error risk the main conclusions of this study are as follows 1 the future annual mean streamflow projections obtained using all of the gcms and rcps exhibit increasing trends under the different rcps and the larger peak value of the monthly streamflow projected using the miroc esm and noresm1 m occurs earlier than in the baseline period the flood periods in the future tend to occur earlier and have longer durations than during the baseline period the mean streamflow from may to september increases by 7 94 while the increase in the mean streamflow from october to february next year is more significant relative to that during the baseline period even though the trend decreases from january to february 2 the responses of the hpg to all of the gcms are larger under rcps 2 6 4 5 and 8 5 compared to the baseline which is consistent with the future streamflow projected using the gcms the responses of the hpg for the noresm1 m increase with increasing emission concentration while the response of the hpg to rcp 4 5 is the most significant under cesm1 cam5 and miroc esm overall the pareto non dominated solutions optimized based on the streamflow projections obtained using the gcms the same rcp and hydrological model are more distinct than those obtained using different rcps and the same gcm the high emission scenario may increase the uncertainty of the future streamflow projections and the reservoir operation responses 3 the smaa simulation indicates that the ders and ruds potential risk increase as both the emission concentration and uncertainty of the cws increase based on the reservoir inflow projected by the cesm1 cam5 this is consistent with conclusion 2 that is the higher emission scenario leads to more complex and uncertain reservoir operation and decision making responses especially when the uncertain cws information is incorporated the distinct distribution of the risk information obtained using the noresm1 m also implies that the uncertainties among the gcm projections are striking these results suggest that it is necessary to consider the effects of both the uncertain streamflow and the cws on the decision making process in real world applications 4 the uncertainty analysis based on the fuzzy extension principle revealed that the multi level uncertainties propagate from the uncertain streamflow projections to the reservoir operation and decision making processes the cumulative effect of the uncertain information in the simulation chain on the final scheduling solution selection and potential decision error risk was quantified the results suggest that as the uncertainty level increases decision making fluctuates more and is more sensitive to the uncertain streamflow and the decision matrixes of the cvs and cws 5 using the proposed systematic framework dms can make more robust decisions by determining the most preferred scheduling solutions under different uncertainty levels and the corresponding risk information instead of the single most preferred scheduling solution the details of the reservoir operation processes such as the reservoir water level discharge and hydropower output are provided to the dms with respective expected values and 95 confidence interval bands which provide the possible ranges of the reservoir adaptive operation in the future declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is supported by the national natural science foundation of china grant no 52109034 chinese universities scientific fund grant nos 2452021085 2452021086 shaanxi province department of science and technology grant no 2023 jc qn 0572 cyrus tang foundation state key laboratory of hydraulics and mountain river engineering sichuan university grant no skhl2112 and key laboratory of resource environment and sustainable development of oasis gansu province grant no gors202101 the authors appreciated for the insightful comments and suggestions from editors and anonymous reviewers appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129518 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 supplementary data 5 supplementary data 6 supplementary data 7 supplementary data 8 supplementary data 9 supplementary data 10 supplementary data 11 
1972,the hydrological response of sloping catchments is strongly conditioned by the connectivity of subsurface preferential flows the objective of this paper is to investigate the role played by stemflow infiltration in subsurface water flow dynamics focusing on a forested hillslope located in an aleppo pine mediterranean forest pinus halepensis mill located at sierra calderona valencia province spain we combined stemflow artificial experiments with the ground penetrating radar gpr as a non invasive technique to investigate stemflow induced preferential flow paths activated by different trees and the related hydrological connectivity at the hillslope scale our observations allowed us to identify different dynamics associated with the initiation of stemflow and then lateral preferential flow including the activation of connected preferential flow paths that received stemflow water from different trees these observations provided empirical evidence of the role of stemflow in the formation of lateral preferential flow networks our measurements also provided estimations for flow velocities which provided new insight on the magnitude of stem induced lateral preferential flow paths the applied protocol offers a simple repeatable and non invasive way to conceptualize hillslope responses to rainstorms keywords gpr connectivity water infiltration stemflow preferential flow data availability data will be made available on request 1 introduction changing climatic conditions are threatening the health and longevity of many forests while also affecting related hydrological and biogeochemical processes calheiros et al 2021 optimizing the remanence and longevity of forests is of prime ecological importance in fact forests play a crucial role in hydrological and biogeochemical processes forests regulate water access to the soil surface and infiltration into the soil profile tree canopies partition the incident gross precipitation into three components i the intercepted rainfall that is lost by evaporation directly from the canopies ii the throughfall that passes through the canopies and reaches the soil surface and iii the stemflow that is concentrated from the canopies to the stems llorens and domingo 2007 investigations from different environments and forest types reported that stemflow often preferentially infiltrates around the stem base and once belowground becomes funneled by tree roots levia and frost 2003 this two stages water flow process which starts with the formation of the stemflow aboveground and continues with the redistribution of the infiltrated water in the subsurface is known as the double funneling effect johnson and lehmann 2006 following this concept the trees may be regarded as hydrologically active agents with their tree roots constituting initiation points from which preferential flow paths can originate uchida et al 2001 during particularly intense rainstorms as large volumes of stemflow are funneled by the roots these paths may connect together in a subsurface flow network that controls the hydrological response of the hillslope lehmann et al 2007 this subsurface water dynamic agrees with the connect and react mechanism proposed by bachmair and weiler 2011 and it is behind the flashy response observed in some steep forested hillslopes e g schwärzel et al 2012 although previous work has highlighted the importance of this process and of the degree of connectivity in determining the hillslope s response to rainstorms until now the formation of stemflow induced preferential flow paths has mainly been investigated at the scale of the single tree e g guo et al 2020 in this work we investigated this process at the hillslope scale by performing an artificial stemflow experiment on a steep forested hillslope located in the valencia province spain in the sierra calderona natural park the site was chosen because previous studies provided evidence of later subsurface flow occurrence and hypothesized the presence of preferential flow networks determining the rapid response of the hillslope del campo et al 2019 however the factors involved in the initiation of the process remain poorly investigated the aim of our study was to bridge this gap focusing on stemflow infiltration as a main factor of preferential flow initiation to gain insight on subsurface water dynamics we combined time lapse ground penetrating radar gpr surveys with stemflow simulations involving three rows of trees separated by a few meters to interpret the results we designed a protocol to detect stemflow induced preferential flow paths activated by the trees we then generalized our results to better understand hydrological connectivity at the hillslope scale 2 material and methods 2 1 experimental site and artificial stemflow experiment the calderona site 39 42 29 n 0 27 25 w is an aleppo pine pinus halepensis mill semiarid forest located in the valencia province east spain in the sierra calderona natural park this experimental site was previously the location of an assessment of ecohydrological effects of forest management del campo et al 2018 two plots of the forest underwent contrasting treatments after a wildfire occurred in 1992 the first was allowed to evolve naturally by ecological succession the second was planted and tree density was controlled the climate is characterized by high temporal rainfall variability and intense droughts the mean annual temperature is 14 0 c while the mean annual rainfall is 342 mm with rainfall events scattered along the year and mainly associated to convective rainfall del campo et al 2018 the soil is loamy textured and relatively shallow 10 40 cm and has a basic ph and a high calcium carbonate content the last forest management occurred between january and october 2012 the objective of the treatment was to achieve a homogeneous forest cover distribution by removing double stemmed trees and the trees with smaller diameters the tree density reduction was 94 with a total basal area removal of 74 more details about the forest stand can be found in del campo et al 2018 the field experiment used simulated stemflow events to provide evidence of stemflow induced preferential flow pathways and flow connectivity the experiment was conducted in october 2021 which is a favorable period to high intensity rainfall camarasa belmonte and soriano 2014 the initial soil water content was determined to be 0 20 cm3 cm 3 via the gravimetric method on undisturbed soil cores 100 cm3 we firstly selected a 100 m2 subplot area within the treated plot that included eight aleppo pine trees two trees named trees 1 and 2 were located in the upper part of the subplot three trees trees 3 4 and 5 were located in the central part and three trees trees 6 7 and 8 were located in the lower part fig 1 to setup the artificial stemflow experiment on each tree we followed the procedure described in guo et al 2020 and di prima et al 2022 the water application was carried out using a pvc pipe with a 1 mm diameter hole every 50 mm fig 2 c the pipe was connected to a plastic funnel and positioned around the tree trunk at 0 2 m from the soil surface fig 2a water application in the experiment consisted of two stages fig 3 in the first stage we applied 50 l of water to each trunk of trees 1 and 2 during the second stage the same amount of water was applied on the trunks of trees 3 4 and 5 this amount of water corresponded to the expected volume collected by a tree crown for a rainfall intensity of 40 4 mm h 1 and represented a mean stemflow rate of 0 35 l mm 1 stemflow volume drained per amount of precipitation as estimated for the calderona site by del campo et al 2018 and a duration of the simulated event of 3 h and 20 min these features define a very strong rainfall event however the mediterranean climate is known for its extreme rainfall events with common intensities over 100 mm h 1 at the storm peak camarasa belmonte and soriano 2014 2 2 time lapse gpr surveys two cross slope oriented gpr survey lines were established in the subplot using measuring tapes fig 2b and following the sampling scheme reported in fig 1 the first survey line sl1 had a length of 8 6 m and was placed on the downhill side of trees 1 5 fig 1 whereas the second survey line sl2 had a length of 7 4 m and was placed on the downhill side of trees 6 8 the gpr surveys were carried out using a gssi geophysical survey system inc salem nh sir 4000 system with a 900 mhz antenna a total of 22 radargrams 11 gpr surveys 2 survey lines were collected in time mode by moving the antenna along the survey lines and recording markers every 0 2 m of the measuring tapes fig 2b the first gpr survey was carried out just before the artificial stemflow events radargrams in fig 1a while the other 11 surveys were carried out during the experiment fig 3a this experimental design was aimed to detect stemflow induced preferential flow paths activated by different trees and the related hydrological connectivity throughout the hillslope fig 3a depicts the timeline of the artificial stemflow experiment with the stemflow volumes poured on the five selected trees through repeated pulses blue lines in the timeline are also visible the gpr surveys carried out on sl1 and sl2 yellow lines the artificial stemflow experiment started after the first gpr survey when the first water volumes were poured into the funnels fig 2a during this first stage five stemflow pulses each of 10 l were poured into the funnels connected to trees 1 and 2 at times of 0 00 0 50 1 40 2 30 and 3 20 from the beginning of the experiment with a rate of 0 5 l min 1 each water application lasted 20 min the gpr surveys alternated with water applications and occurred at 0 30 1 20 2 10 3 00 and 3 50 from the beginning of the experiment for sl1 and for sl2 at 0 40 1 30 2 20 3 10 and 4 00 from the beginning of the experiment during the second stage five stemflow pulses each of 10 l were poured into the funnels connected to trees 3 4 and 5 at a rate of 0 5 l min 1 water additions were performed 4 20 5 00 5 40 6 20 and 7 00 from the beginning of the experiment the other five gpr surveys again occurred after each water applications at 4 40 5 20 6 00 6 40 and 7 20 from the beginning of the experiment for sl1 and for sl2 at 4 50 5 30 6 10 6 50 and 7 30 from the beginning of the experiment overland flow was collected by small v shaped aluminum channels placed into a groove previously scraped on the downhill side of the five trees fig 2d the water volumes were firstly collected in 25 l cans and then after the experiment measured by graduated beakers given that only the 0 3 of the applied stemflow generated overland flow while the majority infiltrated into the soil 99 7 these data are not presented in the result section 2 3 estimation of subsurface flow velocity we also estimated approximate values of subsurface flow velocity v sf velocity of first appearance of reflection changes at the gpr survey lines the time was calculated between the time when stemflow artificial experiment started and the first reflection changes appearance weiler and mcdonnell 2007 the length of the preferential flow path was calculated as the linear distance along the slope direction between the gpr survey line and the nearest upslope tree we considered the nearest upslope tree for the length calculation because it was not possible to determine the true source of the preferential flow paths among the trees involved during the stemflow simulation experiment the experimental setup on the other hand was designed to differentiate between the preferential flow paths activated by the trees involved during the first stage trees 1 2 and those involved during the second stage 3 4 5 in addition because the true path is likely tortuous the linear distance is a minimum distance generating maximum v sf values 2 4 dye staining experiment direct observation of the wetting patterns after the simulation was necessary to corroborate the role played by the course roots in promoting subsurface lateral flow therefore we performed an additional artificial stemflow experiment using a dye tracer followed by destructive soil excavation to expose the dyed patterns since the calderona site is a long term monitoring experimental area in which major soil disturbance is discouraged for this test we selected an aleppo pine tree located at around 0 7 m from a roadcutbank just outside of the experimental site the roots observed on the roadcut were characterized by recording their diameter and depth we applied on the tree trunk five stemflow pulses of brilliant blue dye e133 solution 4 g l 1 with each pulse consisting of 10 l two gpr surveys were carried out before and after the execution of the stemflow simulation on a 1 5 m long survey line at the end of the experiment we photographed the dyed pattern and recorded its position and extension 2 5 gpr data processing we processed each collected radargram i e a time depth cross section using the reflexw software version 9 5 sandmeier scientific software karlsruhe germany the processing steps included i a reflection trace a scan interpolation for obtaining an equal distance e g equal number of traces between the marks taken every 0 2 m ii a static time shift to align direct ground wave arrival to 0 ns iii an energy decay filter to compensate gpr energy attenuation with propagation depth iv a subtract mean filter for eliminating low frequency parts dewow v an average xy filter for removing both distance and time dependent noise and vi a compression to reduce the sizes of the final matrixes to determine the appropriate velocity for converting two way travel times into actual depths we performed a common mid point cmp acquisition based on the determined velocity profile we assumed in our analysis a uniform wave velocity of v 0 18 m ns 1 in addition we confirmed the estimated velocity by measuring the real depth of the observed roots at the roadcut section which were also detected by the gpr more specifically we calculated the wave velocity as v 2 d t where d l is the measured depth of observed roots and t t is the two ways travel time in correspondence of the hyperbola vertex coarse roots are manifested as reflection hyperbolas because of the conical shape of the emitted radiowave signals indeed previous work has demonstrated that when the antenna moves along a survey line approaching a root target the two way travel time decreases towards its minimum value coinciding with the position of the antenna vertically above the target then as the antenna moves away from the target the two way travel time increases guo et al 2013 finally we checked the estimated velocity through hyperbola adaptations using this approach we obtained one pre wetting and ten post wetting radargrams for each survey line next we created other ten matrixes based on absolute differences between pre and post wetting amplitude values higher differenced values occurred as a consequence of amplitude changes and time shifts specifically water imbibition by the soil caused a variation of the dielectric contrast between layers this variation altered the reflection coefficient and caused the amplitude changes time shifts occurred because the water imbibition caused an increase in bulk dielectric constant which reduced the velocity and increased the two way travel time as a consequence the reflectors appeared at later recording times as the soil became wet truss et al 2007 3 results 3 1 detection of preferential flow pathways for each survey line the first five differenced matrixes highlighted amplitude fluctuations during the first stage of the artificial stemflow experiment when the stemflow pulses were poured on trees 1 and 2 fig 3b whereas the last five differenced matrixes highlighted amplitude fluctuations during the second stage when the stemflow pulses were poured on trees 3 4 and 5 fig 3c fig 4 c l shows reflection changes that occurred during the whole infiltration experiment on sl 1 during the first stage of water application when stemflow pulses were applied on trees 1 and 2 we observed significant difference on three different zones blue rectangles and roman numerals iact iiact and ivact in fig 4c where the subscript act stands for active preferential flow path with moderate increase in signal amplitude 30 min after infiltration started i e after the first stemflow pulse during the second stage of water application when stemflow pulses were applied on trees 3 4 and 5 two other zones blue rectangles and roman numerals iiiact and vact in fig 4h showed reflection changes 20 min after the first stemflow pulse of the second series 280 min from the beginning of the experiment on survey line 2 all reflection changes started to appear during the first stage of water application when stemflow pulses were applied on trees 1 and 2 fig 5 c g more specifically we measured reflection changes on three different zones blue rectangles and numerals viiact viiiact and xiact in fig 5c with moderate increase in signal amplitude 40 min after infiltration started i e after the first stemflow pulses three other zones showed reflection changes later during the experiment occurring at 140 blue rectangle and numeral ixact in fig 5e 190 blue rectangle and xact in fig 5f and 240 min blue rectangle and viact in fig 5g after infiltration started using the data in figs 4 and 5 we also estimated approximate values of subsurface flow velocity v sf the estimated v sf values ranged from 1 9 103 to 1 2 104 mm h 1 table 1 these values do not reflect the velocity through the macropores but integrate the mean velocity of the infiltrated stemflow along its flow path through the hillslope to the survey lines anderson et al 2009 3 2 detection of coarse roots comparison between the differenced figs 4c l and 5c l and pre wetting figs 4b and 5b radargrams collected on survey lines 1 and 2 allowed us to identify the source of spatial heterogeneity that triggered preferential flow paths black rectangles and roman numerals i ii iii iv v in fig 4b and vi vii viii ix x xi in fig 5b on the pre wetting radargrams hyperbolic reflections were associated to coarse roots growing perpendicular to the survey lines which were oriented parallel to the slope direction e g iv in fig 4b and viii in fig 5b these coarse roots triggered preferential flow paths that were manifested as strongest reflection differences on the differenced radargrams e g blue rectangles ivact in fig 4c l and viiiact in fig 5c l in some cases reflection changes due to moisture variations were also detected in correspondence of reflectors that did not show a clear hyperbolic shape e g blue rectangles and roman numerals iact iiact iiiact vact in fig 4c l and viact viiact ixact xact xiact in fig 5c l more specifically these isolated reflectors were associated with coarse roots that obliquely crossed the survey lines e g numeral i in fig 4b and vii in fig 5b multiple reflectors by contrast were associated with the presence of many roots of different size and orientation e g numeral v in fig 4b and xi fig 5b 3 3 dye staining experiment the dye staining experiment was aimed at providing evidence of root induced preferential flow during the artificial stemflow experiment the dye tracer was observed flowing along a 0 01 m diameter root located at a depth of 0 31 m along the roadcut section red rectangles in fig 6 a c thus a certain volume of stemflow arriving from the tree trunk was funneled by this root as lateral subsurface flow reflection traces a scans collected before and after the execution of the artificial stemflow experiment at 0 75 m of the survey line x direction also indicate this preferential water movement fig 6e and g here the reflection change measured at a depth of 0 3 m coincides with the position of the root that funneled the dyed stemflow water red rectangles in fig 6 the radargrams b scans collected before and after the execution of the artificial stemflow experiment also showed changes due to subsurface water movement fig 6d and f at 0 7 m of the survey line x direction the prewetting radargram shows a main reflection hyperbola yellow cross in fig 6d corresponding to an observed coarse root with a diameter of 0 07 m yellow cross in fig 6a within the same zone we measured strong reflection changes at a depth of 0 05 0 2 m fig 6h here the infiltrated water extended within the downhill border of roadcut section without generating lateral flow but revealed a zone of imbibition surrounding the coarse root in the proximity of the trunk base consequently no dye patches were observed at this 0 05 0 2 m depth interval 4 discussion 4 1 evidence of flow connectivity the analysis of the differenced radargrams allowed us to develop a conceptual model that explains the signals obtained for sl1 fig 7 this model identifies three different cases that occurred during the activation of stemflow induced preferential flow paths during the two stages of the infiltration experiments note that the delineated paths in fig 7 are hypothetical because as discussed above section 2 3 it was not possible to determine from which trees the preferential flow paths originated in the first case we identified a preferential flow path crossing sl1 via detection of the wet patch indicated with the numeral iiact in fig 7a this flow path was activated during the first stage of the experiment by the stemflow infiltrated from tree 1 during this stage the signal amplitude increased until achieving maximum differences between pre and post wetting conditions after the fifth stemflow pulse i e 230 min after infiltration started fig 4c g numeral iiact this change in behavior signaled that the partially saturated transmission zone surrounding the fast flow region had achieved its maximum extension in this zone the water pressure head decreased as the wetting front moved away due to soil capillarity and imbibition of water from preferential paths di prima et al 2022 thus although water mainly moved along preferential flow paths infiltrated water also moved outward from stems due to water exchange between preferential flow pathways and matrix regions lassabatere et al 2019 2014 this process was influenced by the pressure gradient akay et al 2008 thus we can expect higher rates of water exchange between the two regions under drier conditions on the contrary lower rates are expected under initially wetter conditions and during natural storms that is when water also infiltrates from the soil surface more specifically when it rains the advancement of the wetting front through the soil matrix changes the water content in the matrix pore system and consequently the water exchange rate between the two regions gerke and genuchten 1993 during the second experimental stage when water was poured on trees 3 5 the signal amplitude decreased signaling the occurrence of an exhaustion stage fig 4h l numeral iiexh where the subscript exh stands for exhaustion stage with a general reduction of soil moisture within and around the feature fig 7a numeral iiexh and red line this observation implies that this preferential path was only activated when stemflow infiltrated from the upslope trees e g tree 1 in the hypothetical example in fig 7 this dynamic was also detected in correspondence to the wet patches viact viexh ixact ixexh and xact xexh of sl2 fig 5 in the second example we consider the preferential flow path crossing sl1 that corresponds to the detected wet patch indicated with numeral ivact in fig 7b this flow path was activated during the first stage of the experiment by the stemflow infiltrating from tree 2 however the signal amplitude also continued to increase during the second stage of the experiment fig 4h l numeral ivact thereby providing evidence that infiltrating water from trees 3 5 e g tree 5 in the hypothetical example in fig 7b helped to keep this preferential flow path active from this observation we deduced that the two paths that are hydraulically connected with trees 2 and 5 intersect each other at some point in the subsurface and form a network node fig 7b thus while we observed a constant increase of the signal amplitude at sl1 during the second stage fig 7b numeral ivact the branch of the network extending from the node to tree 2 likely experienced an exhaustion stage fig 7b red line we can hypothesize that this node is located somewhere downslope from tree 5 or it may also coincide with tree 5 location in the latter case during a natural storm the stemflows infiltrated from trees 2 and 5 converge directly below the tree 5 location this second dynamic was also detected as revealed by the wet patches iact of sl1 fig 4 and viiact viiiact and xiact of sl2 fig 5 in the third case we consider a preferential flow path crossing sl1 that was detected from the wet patch indicated with numeral iiiact in figs 7c and 4 this flow path was activated only during the second stage of the experiment by the stemflow infiltrated from tree 3 5 thereby providing evidence that one or more of these trees acted as the source of this preferential flow path e g tree 4 in the hypothetical example in fig 7c this second dynamic was also detected in correspondence of the wet patch vact of sl1 fig 4h l 4 2 comparison with previous measurements of lateral subsurface flow our findings allowed us to conceptualize the subsurface flow dynamics at the calderona site and to support the hypothesis made by del campo et al 2019 about the presence of preferential flow networks affecting the hydrological response of the hillslope the del campo et al 2019 study was focused on long term monitoring activity at the experimental site that spanned the period from the 1st of october 2013 to the 30th of september 2016 as an example of the likely presence of stemflow induced preferential flow we selected two events from their work one on the 9th of may 2016 and the other one on the 10th of august 2016 which produced 12 and 15 mm of subsurface lateral flow after 17 and 19 mm rainfalls the maximum recorded rainfall intensities were 4 2 mm h 1 for the first event and 8 6 mm h 1 for the second δt 30 min during these events subsurface lateral flow and increased water levels in the piezometers were detected almost immediately after the onset of rainfall fig 8 signaling the presence of preferential flow networks with a high capacity to drain the soil in both the lateral and vertical directions the subsurface velocity values in table 1 are in line with the rapid hydrological response evidenced during these storms in addition they were comparable to those measured by tracer experiments in many other investigations for instance noguchi et al 1999 measured values of preferential flow velocity ranging from 8 6 103 to 1 4 104 mm h 1 through dye experiments conducted in a forested hillslope however while previous studies allowed measuring subsurface flow velocity using methods that are labor intensive e g pirastru et al 2022 or invasive and non repeatable e g noguchi et al 1999 the present approach offered a non invasive or minimally invasive repeatable and accurate way to investigate subsurface flow in hillslopes to detect preferential flow paths and to estimate flow velocities given these realistic velocities and the flashy response observed in fig 8 it is likely that stemflow infiltration is a main factor involved in lateral preferential flow initiation at the calderona experimental site in line with our main hypothesis the rate at which stemflow accumulates depends on storm characteristics as well as tree size crown and coarse roots levia and frost 2003 the latter can be affected by forest management which highlights the importance of water oriented forest treatments del campo et al 2014 the study site has been subjected to two forest management strategies one plot was allowed to naturally regenerate following a wildfire in 1992 whereas another plot was controlled by strategically removing trees to limit tree density previous work in this site del campo et al 2018 2019 revealed that medium large sized trees in the thinned plot showed higher stemflow volume 2 3 and 1 7 l tree 1 in thinning and control respectively greater stemflow coefficients 0 44 and 0 30 l tree 1 in thinning and control respectively and more deep drainage than the un thinned plot 5 summary and conclusions in this study the time lapse gpr surveys carried out during the artificial stemflow experiment allowed us to detect stemflow induced preferential flow paths activated by different trees and the related hydrological connectivity at the hillslope spatial scale to our knowledge this is the first study that gets insight on this process at the hillslope scale involving five trees in the stemflow artificial experiment the analysis of the differenced radargrams helped us to identify different dynamics in the initiation of lateral preferential flow including the activation of connected preferential flow paths that received stemflow water from different trees during the simulation these observations provided empirical evidence of preferential flow networks induced by root systems and also their interconnection and contributions to flashy responses of the hillslope these findings also imply that considering stemflow infiltration in hillslope hydrological models would improve our capacity to simulate and predict subsurface flow processes the results can also help to guide specific forest treatments in these semiarid forests than enhance water retention and provisioning the applied protocol can be used to gain more comprehensive understanding of the ecohydrological role played by stemflow infiltration credit authorship contribution statement simone di prima conceptualization methodology investigation data curation formal analysis validation visualization writing original draft writing review editing funding acquisition gersende fernandes investigation writing review editing elisa marras investigation writing review editing filippo giadrossich investigation writing review editing ryan d stewart investigation writing review editing majdi r abou najm investigation writing review editing thierry winiarski investigation writing review editing brice mourier investigation writing review editing rafael angulo jaramillo investigation writing review editing alessandro comegna writing review editing antonio del campo writing review editing funding acquisition laurent lassabatere investigation writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank maria burguet marimon daniel donze rim maamouri and imen mhimdi for their contribution during the field activity s d p also thanks the h f c and s o w for their contribution to keeping everyone s spirits up and toni for helping in a moment of need funding this work was supported through i the miur project prin 2020 unravelling interactions between water and carbon cycles during drought and their impact on water resources and forest and grassland ecosystems in the mediterranean climate waterstem protocol code 20202wf53z ii the european regional development fund erdf and the italian ministry of education university and research miur through the programma operativo nazionale pon ricerca e innovazione 2014 2020 linea 1 mobilità dei ricercatori aim1853149 cup j54i18000120001 iii the infiltron project anr 17 ce04 0010 package for assessing infiltration filtration functions of urban soils in stormwater management and iv cehyrfo med cgl2017 86839 c3 2 r funded by mcin aei https doi org 10 13039 501100011033 and feder 
1972,the hydrological response of sloping catchments is strongly conditioned by the connectivity of subsurface preferential flows the objective of this paper is to investigate the role played by stemflow infiltration in subsurface water flow dynamics focusing on a forested hillslope located in an aleppo pine mediterranean forest pinus halepensis mill located at sierra calderona valencia province spain we combined stemflow artificial experiments with the ground penetrating radar gpr as a non invasive technique to investigate stemflow induced preferential flow paths activated by different trees and the related hydrological connectivity at the hillslope scale our observations allowed us to identify different dynamics associated with the initiation of stemflow and then lateral preferential flow including the activation of connected preferential flow paths that received stemflow water from different trees these observations provided empirical evidence of the role of stemflow in the formation of lateral preferential flow networks our measurements also provided estimations for flow velocities which provided new insight on the magnitude of stem induced lateral preferential flow paths the applied protocol offers a simple repeatable and non invasive way to conceptualize hillslope responses to rainstorms keywords gpr connectivity water infiltration stemflow preferential flow data availability data will be made available on request 1 introduction changing climatic conditions are threatening the health and longevity of many forests while also affecting related hydrological and biogeochemical processes calheiros et al 2021 optimizing the remanence and longevity of forests is of prime ecological importance in fact forests play a crucial role in hydrological and biogeochemical processes forests regulate water access to the soil surface and infiltration into the soil profile tree canopies partition the incident gross precipitation into three components i the intercepted rainfall that is lost by evaporation directly from the canopies ii the throughfall that passes through the canopies and reaches the soil surface and iii the stemflow that is concentrated from the canopies to the stems llorens and domingo 2007 investigations from different environments and forest types reported that stemflow often preferentially infiltrates around the stem base and once belowground becomes funneled by tree roots levia and frost 2003 this two stages water flow process which starts with the formation of the stemflow aboveground and continues with the redistribution of the infiltrated water in the subsurface is known as the double funneling effect johnson and lehmann 2006 following this concept the trees may be regarded as hydrologically active agents with their tree roots constituting initiation points from which preferential flow paths can originate uchida et al 2001 during particularly intense rainstorms as large volumes of stemflow are funneled by the roots these paths may connect together in a subsurface flow network that controls the hydrological response of the hillslope lehmann et al 2007 this subsurface water dynamic agrees with the connect and react mechanism proposed by bachmair and weiler 2011 and it is behind the flashy response observed in some steep forested hillslopes e g schwärzel et al 2012 although previous work has highlighted the importance of this process and of the degree of connectivity in determining the hillslope s response to rainstorms until now the formation of stemflow induced preferential flow paths has mainly been investigated at the scale of the single tree e g guo et al 2020 in this work we investigated this process at the hillslope scale by performing an artificial stemflow experiment on a steep forested hillslope located in the valencia province spain in the sierra calderona natural park the site was chosen because previous studies provided evidence of later subsurface flow occurrence and hypothesized the presence of preferential flow networks determining the rapid response of the hillslope del campo et al 2019 however the factors involved in the initiation of the process remain poorly investigated the aim of our study was to bridge this gap focusing on stemflow infiltration as a main factor of preferential flow initiation to gain insight on subsurface water dynamics we combined time lapse ground penetrating radar gpr surveys with stemflow simulations involving three rows of trees separated by a few meters to interpret the results we designed a protocol to detect stemflow induced preferential flow paths activated by the trees we then generalized our results to better understand hydrological connectivity at the hillslope scale 2 material and methods 2 1 experimental site and artificial stemflow experiment the calderona site 39 42 29 n 0 27 25 w is an aleppo pine pinus halepensis mill semiarid forest located in the valencia province east spain in the sierra calderona natural park this experimental site was previously the location of an assessment of ecohydrological effects of forest management del campo et al 2018 two plots of the forest underwent contrasting treatments after a wildfire occurred in 1992 the first was allowed to evolve naturally by ecological succession the second was planted and tree density was controlled the climate is characterized by high temporal rainfall variability and intense droughts the mean annual temperature is 14 0 c while the mean annual rainfall is 342 mm with rainfall events scattered along the year and mainly associated to convective rainfall del campo et al 2018 the soil is loamy textured and relatively shallow 10 40 cm and has a basic ph and a high calcium carbonate content the last forest management occurred between january and october 2012 the objective of the treatment was to achieve a homogeneous forest cover distribution by removing double stemmed trees and the trees with smaller diameters the tree density reduction was 94 with a total basal area removal of 74 more details about the forest stand can be found in del campo et al 2018 the field experiment used simulated stemflow events to provide evidence of stemflow induced preferential flow pathways and flow connectivity the experiment was conducted in october 2021 which is a favorable period to high intensity rainfall camarasa belmonte and soriano 2014 the initial soil water content was determined to be 0 20 cm3 cm 3 via the gravimetric method on undisturbed soil cores 100 cm3 we firstly selected a 100 m2 subplot area within the treated plot that included eight aleppo pine trees two trees named trees 1 and 2 were located in the upper part of the subplot three trees trees 3 4 and 5 were located in the central part and three trees trees 6 7 and 8 were located in the lower part fig 1 to setup the artificial stemflow experiment on each tree we followed the procedure described in guo et al 2020 and di prima et al 2022 the water application was carried out using a pvc pipe with a 1 mm diameter hole every 50 mm fig 2 c the pipe was connected to a plastic funnel and positioned around the tree trunk at 0 2 m from the soil surface fig 2a water application in the experiment consisted of two stages fig 3 in the first stage we applied 50 l of water to each trunk of trees 1 and 2 during the second stage the same amount of water was applied on the trunks of trees 3 4 and 5 this amount of water corresponded to the expected volume collected by a tree crown for a rainfall intensity of 40 4 mm h 1 and represented a mean stemflow rate of 0 35 l mm 1 stemflow volume drained per amount of precipitation as estimated for the calderona site by del campo et al 2018 and a duration of the simulated event of 3 h and 20 min these features define a very strong rainfall event however the mediterranean climate is known for its extreme rainfall events with common intensities over 100 mm h 1 at the storm peak camarasa belmonte and soriano 2014 2 2 time lapse gpr surveys two cross slope oriented gpr survey lines were established in the subplot using measuring tapes fig 2b and following the sampling scheme reported in fig 1 the first survey line sl1 had a length of 8 6 m and was placed on the downhill side of trees 1 5 fig 1 whereas the second survey line sl2 had a length of 7 4 m and was placed on the downhill side of trees 6 8 the gpr surveys were carried out using a gssi geophysical survey system inc salem nh sir 4000 system with a 900 mhz antenna a total of 22 radargrams 11 gpr surveys 2 survey lines were collected in time mode by moving the antenna along the survey lines and recording markers every 0 2 m of the measuring tapes fig 2b the first gpr survey was carried out just before the artificial stemflow events radargrams in fig 1a while the other 11 surveys were carried out during the experiment fig 3a this experimental design was aimed to detect stemflow induced preferential flow paths activated by different trees and the related hydrological connectivity throughout the hillslope fig 3a depicts the timeline of the artificial stemflow experiment with the stemflow volumes poured on the five selected trees through repeated pulses blue lines in the timeline are also visible the gpr surveys carried out on sl1 and sl2 yellow lines the artificial stemflow experiment started after the first gpr survey when the first water volumes were poured into the funnels fig 2a during this first stage five stemflow pulses each of 10 l were poured into the funnels connected to trees 1 and 2 at times of 0 00 0 50 1 40 2 30 and 3 20 from the beginning of the experiment with a rate of 0 5 l min 1 each water application lasted 20 min the gpr surveys alternated with water applications and occurred at 0 30 1 20 2 10 3 00 and 3 50 from the beginning of the experiment for sl1 and for sl2 at 0 40 1 30 2 20 3 10 and 4 00 from the beginning of the experiment during the second stage five stemflow pulses each of 10 l were poured into the funnels connected to trees 3 4 and 5 at a rate of 0 5 l min 1 water additions were performed 4 20 5 00 5 40 6 20 and 7 00 from the beginning of the experiment the other five gpr surveys again occurred after each water applications at 4 40 5 20 6 00 6 40 and 7 20 from the beginning of the experiment for sl1 and for sl2 at 4 50 5 30 6 10 6 50 and 7 30 from the beginning of the experiment overland flow was collected by small v shaped aluminum channels placed into a groove previously scraped on the downhill side of the five trees fig 2d the water volumes were firstly collected in 25 l cans and then after the experiment measured by graduated beakers given that only the 0 3 of the applied stemflow generated overland flow while the majority infiltrated into the soil 99 7 these data are not presented in the result section 2 3 estimation of subsurface flow velocity we also estimated approximate values of subsurface flow velocity v sf velocity of first appearance of reflection changes at the gpr survey lines the time was calculated between the time when stemflow artificial experiment started and the first reflection changes appearance weiler and mcdonnell 2007 the length of the preferential flow path was calculated as the linear distance along the slope direction between the gpr survey line and the nearest upslope tree we considered the nearest upslope tree for the length calculation because it was not possible to determine the true source of the preferential flow paths among the trees involved during the stemflow simulation experiment the experimental setup on the other hand was designed to differentiate between the preferential flow paths activated by the trees involved during the first stage trees 1 2 and those involved during the second stage 3 4 5 in addition because the true path is likely tortuous the linear distance is a minimum distance generating maximum v sf values 2 4 dye staining experiment direct observation of the wetting patterns after the simulation was necessary to corroborate the role played by the course roots in promoting subsurface lateral flow therefore we performed an additional artificial stemflow experiment using a dye tracer followed by destructive soil excavation to expose the dyed patterns since the calderona site is a long term monitoring experimental area in which major soil disturbance is discouraged for this test we selected an aleppo pine tree located at around 0 7 m from a roadcutbank just outside of the experimental site the roots observed on the roadcut were characterized by recording their diameter and depth we applied on the tree trunk five stemflow pulses of brilliant blue dye e133 solution 4 g l 1 with each pulse consisting of 10 l two gpr surveys were carried out before and after the execution of the stemflow simulation on a 1 5 m long survey line at the end of the experiment we photographed the dyed pattern and recorded its position and extension 2 5 gpr data processing we processed each collected radargram i e a time depth cross section using the reflexw software version 9 5 sandmeier scientific software karlsruhe germany the processing steps included i a reflection trace a scan interpolation for obtaining an equal distance e g equal number of traces between the marks taken every 0 2 m ii a static time shift to align direct ground wave arrival to 0 ns iii an energy decay filter to compensate gpr energy attenuation with propagation depth iv a subtract mean filter for eliminating low frequency parts dewow v an average xy filter for removing both distance and time dependent noise and vi a compression to reduce the sizes of the final matrixes to determine the appropriate velocity for converting two way travel times into actual depths we performed a common mid point cmp acquisition based on the determined velocity profile we assumed in our analysis a uniform wave velocity of v 0 18 m ns 1 in addition we confirmed the estimated velocity by measuring the real depth of the observed roots at the roadcut section which were also detected by the gpr more specifically we calculated the wave velocity as v 2 d t where d l is the measured depth of observed roots and t t is the two ways travel time in correspondence of the hyperbola vertex coarse roots are manifested as reflection hyperbolas because of the conical shape of the emitted radiowave signals indeed previous work has demonstrated that when the antenna moves along a survey line approaching a root target the two way travel time decreases towards its minimum value coinciding with the position of the antenna vertically above the target then as the antenna moves away from the target the two way travel time increases guo et al 2013 finally we checked the estimated velocity through hyperbola adaptations using this approach we obtained one pre wetting and ten post wetting radargrams for each survey line next we created other ten matrixes based on absolute differences between pre and post wetting amplitude values higher differenced values occurred as a consequence of amplitude changes and time shifts specifically water imbibition by the soil caused a variation of the dielectric contrast between layers this variation altered the reflection coefficient and caused the amplitude changes time shifts occurred because the water imbibition caused an increase in bulk dielectric constant which reduced the velocity and increased the two way travel time as a consequence the reflectors appeared at later recording times as the soil became wet truss et al 2007 3 results 3 1 detection of preferential flow pathways for each survey line the first five differenced matrixes highlighted amplitude fluctuations during the first stage of the artificial stemflow experiment when the stemflow pulses were poured on trees 1 and 2 fig 3b whereas the last five differenced matrixes highlighted amplitude fluctuations during the second stage when the stemflow pulses were poured on trees 3 4 and 5 fig 3c fig 4 c l shows reflection changes that occurred during the whole infiltration experiment on sl 1 during the first stage of water application when stemflow pulses were applied on trees 1 and 2 we observed significant difference on three different zones blue rectangles and roman numerals iact iiact and ivact in fig 4c where the subscript act stands for active preferential flow path with moderate increase in signal amplitude 30 min after infiltration started i e after the first stemflow pulse during the second stage of water application when stemflow pulses were applied on trees 3 4 and 5 two other zones blue rectangles and roman numerals iiiact and vact in fig 4h showed reflection changes 20 min after the first stemflow pulse of the second series 280 min from the beginning of the experiment on survey line 2 all reflection changes started to appear during the first stage of water application when stemflow pulses were applied on trees 1 and 2 fig 5 c g more specifically we measured reflection changes on three different zones blue rectangles and numerals viiact viiiact and xiact in fig 5c with moderate increase in signal amplitude 40 min after infiltration started i e after the first stemflow pulses three other zones showed reflection changes later during the experiment occurring at 140 blue rectangle and numeral ixact in fig 5e 190 blue rectangle and xact in fig 5f and 240 min blue rectangle and viact in fig 5g after infiltration started using the data in figs 4 and 5 we also estimated approximate values of subsurface flow velocity v sf the estimated v sf values ranged from 1 9 103 to 1 2 104 mm h 1 table 1 these values do not reflect the velocity through the macropores but integrate the mean velocity of the infiltrated stemflow along its flow path through the hillslope to the survey lines anderson et al 2009 3 2 detection of coarse roots comparison between the differenced figs 4c l and 5c l and pre wetting figs 4b and 5b radargrams collected on survey lines 1 and 2 allowed us to identify the source of spatial heterogeneity that triggered preferential flow paths black rectangles and roman numerals i ii iii iv v in fig 4b and vi vii viii ix x xi in fig 5b on the pre wetting radargrams hyperbolic reflections were associated to coarse roots growing perpendicular to the survey lines which were oriented parallel to the slope direction e g iv in fig 4b and viii in fig 5b these coarse roots triggered preferential flow paths that were manifested as strongest reflection differences on the differenced radargrams e g blue rectangles ivact in fig 4c l and viiiact in fig 5c l in some cases reflection changes due to moisture variations were also detected in correspondence of reflectors that did not show a clear hyperbolic shape e g blue rectangles and roman numerals iact iiact iiiact vact in fig 4c l and viact viiact ixact xact xiact in fig 5c l more specifically these isolated reflectors were associated with coarse roots that obliquely crossed the survey lines e g numeral i in fig 4b and vii in fig 5b multiple reflectors by contrast were associated with the presence of many roots of different size and orientation e g numeral v in fig 4b and xi fig 5b 3 3 dye staining experiment the dye staining experiment was aimed at providing evidence of root induced preferential flow during the artificial stemflow experiment the dye tracer was observed flowing along a 0 01 m diameter root located at a depth of 0 31 m along the roadcut section red rectangles in fig 6 a c thus a certain volume of stemflow arriving from the tree trunk was funneled by this root as lateral subsurface flow reflection traces a scans collected before and after the execution of the artificial stemflow experiment at 0 75 m of the survey line x direction also indicate this preferential water movement fig 6e and g here the reflection change measured at a depth of 0 3 m coincides with the position of the root that funneled the dyed stemflow water red rectangles in fig 6 the radargrams b scans collected before and after the execution of the artificial stemflow experiment also showed changes due to subsurface water movement fig 6d and f at 0 7 m of the survey line x direction the prewetting radargram shows a main reflection hyperbola yellow cross in fig 6d corresponding to an observed coarse root with a diameter of 0 07 m yellow cross in fig 6a within the same zone we measured strong reflection changes at a depth of 0 05 0 2 m fig 6h here the infiltrated water extended within the downhill border of roadcut section without generating lateral flow but revealed a zone of imbibition surrounding the coarse root in the proximity of the trunk base consequently no dye patches were observed at this 0 05 0 2 m depth interval 4 discussion 4 1 evidence of flow connectivity the analysis of the differenced radargrams allowed us to develop a conceptual model that explains the signals obtained for sl1 fig 7 this model identifies three different cases that occurred during the activation of stemflow induced preferential flow paths during the two stages of the infiltration experiments note that the delineated paths in fig 7 are hypothetical because as discussed above section 2 3 it was not possible to determine from which trees the preferential flow paths originated in the first case we identified a preferential flow path crossing sl1 via detection of the wet patch indicated with the numeral iiact in fig 7a this flow path was activated during the first stage of the experiment by the stemflow infiltrated from tree 1 during this stage the signal amplitude increased until achieving maximum differences between pre and post wetting conditions after the fifth stemflow pulse i e 230 min after infiltration started fig 4c g numeral iiact this change in behavior signaled that the partially saturated transmission zone surrounding the fast flow region had achieved its maximum extension in this zone the water pressure head decreased as the wetting front moved away due to soil capillarity and imbibition of water from preferential paths di prima et al 2022 thus although water mainly moved along preferential flow paths infiltrated water also moved outward from stems due to water exchange between preferential flow pathways and matrix regions lassabatere et al 2019 2014 this process was influenced by the pressure gradient akay et al 2008 thus we can expect higher rates of water exchange between the two regions under drier conditions on the contrary lower rates are expected under initially wetter conditions and during natural storms that is when water also infiltrates from the soil surface more specifically when it rains the advancement of the wetting front through the soil matrix changes the water content in the matrix pore system and consequently the water exchange rate between the two regions gerke and genuchten 1993 during the second experimental stage when water was poured on trees 3 5 the signal amplitude decreased signaling the occurrence of an exhaustion stage fig 4h l numeral iiexh where the subscript exh stands for exhaustion stage with a general reduction of soil moisture within and around the feature fig 7a numeral iiexh and red line this observation implies that this preferential path was only activated when stemflow infiltrated from the upslope trees e g tree 1 in the hypothetical example in fig 7 this dynamic was also detected in correspondence to the wet patches viact viexh ixact ixexh and xact xexh of sl2 fig 5 in the second example we consider the preferential flow path crossing sl1 that corresponds to the detected wet patch indicated with numeral ivact in fig 7b this flow path was activated during the first stage of the experiment by the stemflow infiltrating from tree 2 however the signal amplitude also continued to increase during the second stage of the experiment fig 4h l numeral ivact thereby providing evidence that infiltrating water from trees 3 5 e g tree 5 in the hypothetical example in fig 7b helped to keep this preferential flow path active from this observation we deduced that the two paths that are hydraulically connected with trees 2 and 5 intersect each other at some point in the subsurface and form a network node fig 7b thus while we observed a constant increase of the signal amplitude at sl1 during the second stage fig 7b numeral ivact the branch of the network extending from the node to tree 2 likely experienced an exhaustion stage fig 7b red line we can hypothesize that this node is located somewhere downslope from tree 5 or it may also coincide with tree 5 location in the latter case during a natural storm the stemflows infiltrated from trees 2 and 5 converge directly below the tree 5 location this second dynamic was also detected as revealed by the wet patches iact of sl1 fig 4 and viiact viiiact and xiact of sl2 fig 5 in the third case we consider a preferential flow path crossing sl1 that was detected from the wet patch indicated with numeral iiiact in figs 7c and 4 this flow path was activated only during the second stage of the experiment by the stemflow infiltrated from tree 3 5 thereby providing evidence that one or more of these trees acted as the source of this preferential flow path e g tree 4 in the hypothetical example in fig 7c this second dynamic was also detected in correspondence of the wet patch vact of sl1 fig 4h l 4 2 comparison with previous measurements of lateral subsurface flow our findings allowed us to conceptualize the subsurface flow dynamics at the calderona site and to support the hypothesis made by del campo et al 2019 about the presence of preferential flow networks affecting the hydrological response of the hillslope the del campo et al 2019 study was focused on long term monitoring activity at the experimental site that spanned the period from the 1st of october 2013 to the 30th of september 2016 as an example of the likely presence of stemflow induced preferential flow we selected two events from their work one on the 9th of may 2016 and the other one on the 10th of august 2016 which produced 12 and 15 mm of subsurface lateral flow after 17 and 19 mm rainfalls the maximum recorded rainfall intensities were 4 2 mm h 1 for the first event and 8 6 mm h 1 for the second δt 30 min during these events subsurface lateral flow and increased water levels in the piezometers were detected almost immediately after the onset of rainfall fig 8 signaling the presence of preferential flow networks with a high capacity to drain the soil in both the lateral and vertical directions the subsurface velocity values in table 1 are in line with the rapid hydrological response evidenced during these storms in addition they were comparable to those measured by tracer experiments in many other investigations for instance noguchi et al 1999 measured values of preferential flow velocity ranging from 8 6 103 to 1 4 104 mm h 1 through dye experiments conducted in a forested hillslope however while previous studies allowed measuring subsurface flow velocity using methods that are labor intensive e g pirastru et al 2022 or invasive and non repeatable e g noguchi et al 1999 the present approach offered a non invasive or minimally invasive repeatable and accurate way to investigate subsurface flow in hillslopes to detect preferential flow paths and to estimate flow velocities given these realistic velocities and the flashy response observed in fig 8 it is likely that stemflow infiltration is a main factor involved in lateral preferential flow initiation at the calderona experimental site in line with our main hypothesis the rate at which stemflow accumulates depends on storm characteristics as well as tree size crown and coarse roots levia and frost 2003 the latter can be affected by forest management which highlights the importance of water oriented forest treatments del campo et al 2014 the study site has been subjected to two forest management strategies one plot was allowed to naturally regenerate following a wildfire in 1992 whereas another plot was controlled by strategically removing trees to limit tree density previous work in this site del campo et al 2018 2019 revealed that medium large sized trees in the thinned plot showed higher stemflow volume 2 3 and 1 7 l tree 1 in thinning and control respectively greater stemflow coefficients 0 44 and 0 30 l tree 1 in thinning and control respectively and more deep drainage than the un thinned plot 5 summary and conclusions in this study the time lapse gpr surveys carried out during the artificial stemflow experiment allowed us to detect stemflow induced preferential flow paths activated by different trees and the related hydrological connectivity at the hillslope spatial scale to our knowledge this is the first study that gets insight on this process at the hillslope scale involving five trees in the stemflow artificial experiment the analysis of the differenced radargrams helped us to identify different dynamics in the initiation of lateral preferential flow including the activation of connected preferential flow paths that received stemflow water from different trees during the simulation these observations provided empirical evidence of preferential flow networks induced by root systems and also their interconnection and contributions to flashy responses of the hillslope these findings also imply that considering stemflow infiltration in hillslope hydrological models would improve our capacity to simulate and predict subsurface flow processes the results can also help to guide specific forest treatments in these semiarid forests than enhance water retention and provisioning the applied protocol can be used to gain more comprehensive understanding of the ecohydrological role played by stemflow infiltration credit authorship contribution statement simone di prima conceptualization methodology investigation data curation formal analysis validation visualization writing original draft writing review editing funding acquisition gersende fernandes investigation writing review editing elisa marras investigation writing review editing filippo giadrossich investigation writing review editing ryan d stewart investigation writing review editing majdi r abou najm investigation writing review editing thierry winiarski investigation writing review editing brice mourier investigation writing review editing rafael angulo jaramillo investigation writing review editing alessandro comegna writing review editing antonio del campo writing review editing funding acquisition laurent lassabatere investigation writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank maria burguet marimon daniel donze rim maamouri and imen mhimdi for their contribution during the field activity s d p also thanks the h f c and s o w for their contribution to keeping everyone s spirits up and toni for helping in a moment of need funding this work was supported through i the miur project prin 2020 unravelling interactions between water and carbon cycles during drought and their impact on water resources and forest and grassland ecosystems in the mediterranean climate waterstem protocol code 20202wf53z ii the european regional development fund erdf and the italian ministry of education university and research miur through the programma operativo nazionale pon ricerca e innovazione 2014 2020 linea 1 mobilità dei ricercatori aim1853149 cup j54i18000120001 iii the infiltron project anr 17 ce04 0010 package for assessing infiltration filtration functions of urban soils in stormwater management and iv cehyrfo med cgl2017 86839 c3 2 r funded by mcin aei https doi org 10 13039 501100011033 and feder 
1973,reservoir operation is an effective measure for flood disaster reduction previous studies focused on minimizing flood risk to reduce potential flood damage however failure and recovery processes are not considered to address this shortcoming this study introduces the concept of resilience to measure the ability of flood control systems to maintain or return to the original states after an extreme flood the quantitative expression of resilience resilience metric is proposed based on the system performance and defined as the summation of system functionality loss throughout the entire flood process based on the proposed resilience metric a multi objective optimization model with flood risk represented by maximum reservoir water level and downstream peak flow and flood resilience as objectives is established nierji reservoir located in northeast china is taken as a case study results show that the proposed method can improve resilience without increasing flood risks i e maximum reservoir water level and downstream peak flow compared with the traditional model pareto optimates of the optimization model show that there exist tradeoffs between risk and resilience improving resilience inevitably reducing risk the resilience improvement is large when the flood risk of the reservoir or downstream is medium and is limited when the flood risk is high moreover the resilience improvement is higher for a smaller flood the improvement is achieved through pre releasing at the early stage of the flood and releasing slowly at the recession stage of the flood six typical schemes selected referring to the existing scheme are comprehensively compared and an operation rule for flood control with the highest resilience but without reducing risks is recommended this study provides a new way for flood control management keywords flood resilience flood risk multi objective optimization reservoir operation data availability the data that has been used is confidential 1 introduction flooding is the most frequent natural hazard causing enormous economic loss environmental damage and human fatalities teng et al 2017 the world disasters report in 2018 highlighted that the number of floods by far outstrips the number of storms and all other disasters recorded from 2008 to 2017 fisher et al 2018 the frequency intensity and consequences of flood events will further increase due to climate change social and economic development apurv et al 2015 dottori et al 2018 svetlana et al 2015 the reservoir is an effective engineering measure for flood disaster reduction labadie 2004 windsor 1973 flood control operation is the key to achieving flood reduction and mitigation effects of reservoirs jia et al 2016 moridi and yazdi 2017 zhu et al 2017 reservoir operation rules for flood control determine how much water is to be released at each time step during flood seasons flood control needs to consider the safety of upstream catchments the reservoir itself and downstream catchments thus the determination of the reservoir operation rule for flood control is a multi objective decision making problem hsu et al 2015 the critical issue is how to balance the damage or risk among the safety of the dam or reservoir itself downstream and upstream during flooding and also to balance flood control and flood water resources utilization ding et al 2015 hsu and wei 2007 lei et al 2018 wei and hsu 2008 chou and wu 2015 presented a framework of release rule for reservoir flood control operations aiming at maximizing flood mitigation without elevating the reservoir water level beyond the design flood water level at the flood peak stage qi et al 2017 established a multi objective optimization model for reservoir flood control operation by minimizing the highest upstream water level and the largest water release volume previous research focused on the extreme value of maximum flood water level and downstream peak flow i e the risk chang et al 2010 lei et al 2018 windsor 1973 however the damage of flooding is affected by the hydrodynamic process including the duration of high downstream flow or high reservoir water level and the recovery time for example meng et al 2019 established a flood control operation model by minimizing the maximum water level and its time duration however there is a lack of research on considering flood resilience that can describe the hydrodynamic process in reservoir operation resilience is a concept that measures the capacity of a system to resist withstand recover from and adapt to exceptional conditions cimellaro et al 2010 deangelis 1980 gunderson 2000 it was first introduced to the ecosystem but has been expanded to many engineering and social systems in recent years meerow et al 2016 in water supply systems many researchers incorporated resilience in reservoir water supply systems to investigate the relationship among reliability vulnerability and resilience under different operation strategies hashimoto et al 1982 moy et al 1986 ren et al 2020 zhang et al 2017 and investigate the system resilience change in response to changing environment including climate change population growth and urbanization mereu et al 2016 zhao et al 2018 in flood control systems previous research focused on urban flood resilience with different frameworks and resilience evaluation metrics bertilsson et al 2019 juan garcia et al 2017 liao 2012 mugume et al 2015 djordjevic et al 2011 defined urban resilience as the capacity of a system community or society potentially exposed to hazards to adapt by resisting or changing in order to reach and maintain an acceptable level of functioning and structure wang et al 2019 proposed a grid cell based resilience metric to assess urban flood resilience identify vulnerable catchments and assist in developing an effective adaptation strategy however there is a lack of research on incorporating resilience into reservoir flood operations in the last several years a few attempts have been made including the development of a qualitative resilience matrix under different phases of the decision making process of reservoir operation for flood control through workshops and surveys mustajoki and marttunen 2019 and the development of a resilience assessment framework to evaluate dam safety upgrade options from a flood damage mitigation perspective kim et al 2017 this paper defines and quantifies flood resilience for reservoir flood control operations a resilience based reservoir operation approach for flood control has been proposed the nierji reservoir system is taken as a case study to demonstrate the advantages of the proposed method the relationship among the upstream reservoir risk downstream risk and the resilience of the downstream system are analyzed and the impact of rainfall and flood hydrograph is discussed the reason for how the operation rules generated from the proposed method increase the downstream resilience in the flood control process is explored finally optimal flood control operation rules comprehensively considering flood risk upstream and downstream and the resilience of the downstream system is recommended 2 methodology 2 1 definition and quantification of flood resilience in terms of a flood event the reservoir should utilize its flood control capacity to regulate the flood hydrograph to ensure the safety of the system usually the safety of the system includes the safety of upstream catchments the reservoir itself and downstream catchments and the safety of the reservoir has the highest priority for a large flood inundation might happen in downstream communities which might induce flood damage the extent of damage to the downstream community is related to the magnitude and duration of flooding which are key aspects of resilience timmerman 1981 the quantitative and qualitative assessment methods of flood resilience mainly include a multi criteria method and a performance based metrics method fu et al 2020 the multi criteria method focused on how to evaluate the resilience from multi attribute such as economic indicators and social indicators in resisting absorbing recovering from and adapting to an extreme flood event kotzee and reyers 2016 the performance based metrics method described the magnitude change of the system during the whole process of extreme flood events through system functions which is widely used bruneau et al 2003 wang et al 2019 in this study system resilience is defined as the ability of the downstream community to resist absorb recover from and adapt to an extreme flood event and considering the extent of downstream damage is relevant to the downstream flow the downstream flow is used to measure system performance ganin et al 2016 the schematic diagram of resilience is shown in fig 1 where fig 1 a represents the streamflow hydrograph downstream q initial is the operational threshold of the system below which the system is considered normal i e no system functionality loss there is system functionality loss when the flow exceeds q initial q max is the flow that the downstream system is completely destructed that is the system functionality is lost this study defines the normal system functionality as 1 the system performance is defined as the proportion of the streamflow exceeding the threshold q initial as expressed in equation 1 fig 1 b shows the variation of system functionality with the flow the system experiences a flood at ts and its performance drops with the increase of discharge the system performance reaches a minimum value of pf at tfs then recovers gradually and comes back to normal at time te the value of the system performance of the downstream system at any time t is defined as 1 p t 1 q t q initial q max q t q max q initial q initial q t q max 0 q t q max where q t represents the downstream flow at time t the loss of system functionality throughout the entire flood event is measured by the index of severity s s is estimated as the aggregation of system functionality loss and shown as the dark shaded area in fig 1 b s quantifies the failure magnitude and duration and can be presented by 2 s 1 t n t e t s 1 p t d t the resilience metric r which is a measure of system residual functionality is estimated as the aggregation of the system performance during the entire process or one minus the severity shown as 3 r 1 s 1 t n t n 0 p t d t 2 2 optimization model for flood control operation 2 2 1 objective function a traditional optimization model for flood control operation rule generally has two objectives i e minimize the maximum reservoir water level and minimize the peak flow at the selected downstream control point in this study we introduce downstream resilience maximization into the optimization model as the new objective so there is a total of three objectives first reservoir operation for flood control aims to minimize the maximum reservoir water level during a flood event for the optimization of operation rules the objective is to minimize the expected value of the maximum reservoir water levels of design floods under different frequencies 4 m i n 1 n i 0 n m a x z i t t 0 t n where n represents the number of design floods max z i t t 0 t n represents the maximum reservoir water level for the i th design flood second minimize the peak flow at the selected downstream control point here the objective is to minimize the average of the peak flow at the downstream point for different design floods shown as follows 5 m i n 1 n i 0 n m a x q i t t 0 t n where max q i t t 0 t n represents the downstream peak flow for the i th design flood third maximize the downstream resilience 6 m a x 1 n i 0 n r i where r i represents the value of downstream resilience for the ith design flood which can be calculated by equation 3 2 2 2 constraints 2 2 2 1 reservoir mass balance equation 7 v t v t 1 i t o t δ t where δt is the time interval a short period for flood routing i t and o t are the inflow and outflow for the reservoir at time t respectively v t and v t 1 are the reservoir s initial and ending storage at time t the evaporation and leakage loss are ignored since they are small compared with inflow 2 2 2 2 water level constraint 8 z min z t z max where z t represents the reservoir water level at time t z min and z max represent the minimum and maximum water level at time t respectively 2 2 2 3 reservoir discharge constraint 9 o t o max z t where o max z t represents the maximum discharge ability corresponding to reservoir water level zt 2 2 2 4 the maximum flow constraint at downstream 10 q t o t q int e r t q max where q t is the discharge for the downstream flood control point at time t o t is the flow of reservoir release after flood routing to the downstream flood control point q int e r t is the intermediate flow between the reservoir and the downstream flood control point q max is the maximum allowed flow at the downstream flood control point 2 2 3 optimization algorithms a widely used many objective evolutionary algorithm the non dominated sorting genetic algorithm ii nsga ii is adopted to obtain the pareto optimal solutions of the simulation optimization model deb et al 2002 wei et al 2022 zhang et al 2017 the decision variables of the optimization model are the releases and the discriminative index indicating the release in the paper the number of iterations is 1000000 and the population size is 10000 which is determined by the abundance of optimal solutions the probability of mutation is 0 1 the probability of crossover is 0 9 and the distribution index for crossover and the distribution index for mutation is set to 20 3 case study 3 1 overview nierji reservoir located in nen river northeast china is taken as a case study the primary task of the reservoir is flood control with hydropower generation water supply for industry agriculture and wetland as well as navigation as the secondary tasks as an important part of the songhua river and nen river flood control system nierji reservoir with a flood control storage of 2 368 billion m3 complied with the downstream dikes undertakes the flood control task in the mainstream of nen river and improves the flood standards of qiqihaer city from the 50 year return period with a frequency of 2 to the 100 year return period with a frequency of 1 the qiqihaer hydrological station the streamflow of which consists of release from nierji reservoir and streamflow from nuomin river and namoer river represents the flood in qiqihaer city as shown in fig 2 the maximum allowable streamflow at qiqihaer hydrological station is 8850 m3 s with a flood control standard of a 50 year return period protecting the farmland from flooding and it is 12000 m3 s with a flood control standard of a 100 year return period protecting the flood safety of qiqihaer city the flood limited water level and the flood prevention level are 213 37 m and 218 15 m respectively which are the minimum and maximum water levels for equation 8 3 2 the design floods the principle of flood control operation for nierji reservoir is that the reservoir should release flood water based on the intermediate flow between the reservoir and the flood control point to reduce the flood peak at qiqihaer hydrologic station there exist two most unfavorable flood combinations a the flood frequencies of the nierji reservoir basin and downstream are the same defined as rainfall pattern i in this pattern the flood at qiqihaer hydrologic station mainly comes from the reservoir there are three typical floods type 1969 type 1988 and type 1998 6 respectively as shown in fig 3 a 3b and 3c b the flood frequencies of the intermediate basin and downstream are the same defined as rainfall pattern ii in this pattern the flood at qiqihaer mainly comes from the intermediate basin between the reservoir and the downstream flood control point the typical flood is type 1998 8 fig 3d the design flood hydrographs with frequencies of 2 and 1 i e with a return period of 50 year and 100 year are included to derive the optimal flood control rules 3 3 flood control operation rule the conventional operation rule of nierji reservoir during flood season is identified by the reservoir water level and the combination of flow at three rivers shown in table 1 and table 4 in table 1 the q 3 s is the sum of the nierji inflow the flow at the guchengzi station in nuomin river and the flow at the dedu station in namoer river of the last period as shown in fig 2 z is the reservoir water level x i i 1 2 14 represents the reservoir release i is the reservoir forecast inflow for the current period lim qi is the discriminative index indicating the release the variables in table 1 including lim qi and x i are optimized with the optimization model regulating 8 design flood hydrographs mentioned in section 3 2 3 4 parameters related to resilience the streamflow at qiqihaer a hydrologic station is equal to the sum of flow routed from the upstream reservoir release nuomin river and namoer river the muskingum method is used for the channel flow routing from the nierji reservoir and guchengzi hydrologic station in namoer river to the downstream control point i e qiqihaer hydrologic station the streamflow in the nuomin river represented by the flow at dedu hydrological station is routed to qiqihaer hydrological station with no deformation but traveling for seven days when the streamflow at qiqihaer hydrologic station is larger than 6580 m3 s the dikes will be flooded that is the performance functionality of the flood control system is smaller than 1 when the streamflow is larger than 14300 m3 s the farmland and qiqihear city will be flooded i e the performance functionality is zero therefore the q initial and q max in equation 1 are 6580 m3 s and 14300 m3 s respectively 3 5 system performance under the existing flood control operation rules table 2 shows the maximum reservoir water level the downstream peak flow and the resilience at downstream under the conventional flood control operation rules 4 results and discussion 4 1 improvement of resilience this section aims to analyze the improvement of resilience of the proposed model compared with the traditional method which is to optimize the operating rule with the minimization of reservoir water level and downstream peak flow as the objectives named the two objective optimization model fig 4 shows the pareto approximates from the proposed and traditional models for rainfall pattern i in the figures the triangle points represent the solutions of the two objective optimization model and the corresponding downstream resilience of the optimal solutions is calculated based on the reservoir operation simulation the diamond point represents the conventional operation rule under a conventional scenario cs as can be seen from fig 4 a that the optimization model can greatly improve the three objectives compared to the current operation rule solution since the diamond point locates above the optimal solutions fig 4 b d show the tradeoffs among the three objectives in the two dimensional axis and there exists a conflicting relationship between any two objectives fig 4 b shows that the three objective optimization model can improve resilience compared to the two objective optimization model and the improvement is higher with a higher maximum reservoir water level meanwhile increasing downstream peak flow i e higher flood risk downstream can also improve resilience shown in fig 4 d that is improving the system resilience will inevitably bring higher downstream or reservoir flood risks under the optimization model in fig 4 d different curves represent the tradeoffs between downstream resilience and peak flow under different maximum reservoir water levels as can be seen the tradeoff curves are narrowed down with a high reservoir water level or downstream peak flow that is to say the variation of resilience is limited when the safety requirement upstream or downstream is high 4 2 impacts of rainfall and flood hydrographs fig 5 shows the tradeoffs among the maximum reservoir water level the downstream peak flow and downstream resilience in the two dimensional axis for rainfall pattern ii as can be seen under rainfall pattern ii the three objective model can also improve resilience but the improvement is not as high as that in rainfall pattern i as shown in fig 5 b d the relationships between the three objectives from the three objective case are the same as that in rainfall pattern i however there exists a difference in the objectives and their relationship compared with fig 4 c and 5 c the maximum water level ranges in a narrow range of 217 20 m 218 15 m in rainfall pattern ii which ranges within 215 30 m 218 15 m in rainfall pattern i besides there is a horizontal line with a maximum water level of 218 15 m subject to the maximum water level constraint the reason is that under rainfall pattern ii the flood from the basin between nierji reservoir and qiqihaer hydrologic station is large and hence the reservoir has to utilize the flood control storage to retain and detent flood as much as possible to guarantee downstream safety and even utilize all the flood control storage to guarantee a relatively small downstream flow when downstream undertakes a larger flow there exists a larger decision space shown in the right part of fig 5 c fig 6 displays the objectives of the eight design flood hydrographs for the three objective optimization model all the subfigures show that there exists a tradeoff relationship between downstream resilience and peak flow that is downstream resilience increases with the increase of downstream peak flow and the tradeoff range is high with a medium reservoir water level or peak flow but for a specific typical flood the value of resilience and its variation range is higher for a flood with a frequency of 2 than that of 1 the reason is that flood with a frequency of 1 is larger and brings a higher risk to the flood control system and thus there is limited space for improving resilience comparing the results of different rainfall patterns it can be seen that the resilience improvement is smaller and the maximum water level is high in rainfall pattern ii the reason is that in rainfall pattern ii there is large rainfall in the intermediate region and thus the improvement by the reservoir operation is limited in the meantime the reservoir needs to retain more floodwater which leads to a high reservoir water level i e basically above 216 5 m comparing the results of different flood types in rainfall pattern i the variation of the maximum water level in flood type1998 6 is smaller than that in the 1969 and 1988 floods the reason is that the peak flow duration in type 1998 6 flood is longer so the reservoir needs to reduce release for the safety of downstream resulting in the decrease of the capacity of the reservoir s flood control to sum up when the downstream floodwater volume is smaller there will be relatively more solutions for the reservoir to improve the downstream resilience to a greater extent 4 3 operations to improve resilience this section investigates how resilience is improved through a flood regulation process fig 7 shows the regulation process of two solutions selected from the three objective optimal solution set and the two objective optimal solutions set with the same maximum water level and downstream peak flow it shows that the three objective case slows down the release at the receding stage of the flood by retaining floodwater in the reservoir i e emptying the flood control storage slowly thereby improving the system performance and increasing downstream flood resilience in the meantime three scenarios are designed to further investigate how to improve resilience fig 8 scenario 1 4 schemes with the same downstream peak flow represented by solq 1 solq 2 solq 3 and solq 4 are selected from the three objective optimization sets scenario 2 4 schemes with the same maximum reservoir water level represented by solz 1 solz 2 solz 3 and solz 4 are selected from the three objective optimization sets scenario 3 4 schemes with the same downstream resilience represented by solr 1 solr 2 solr 3 and solr 4 are selected from the three objective optimization sets it can be seen from panel a that when given a certain downstream peak flow that is the same downstream peak flow i e 10606 m3 s in panel a the reservoir can improve resilience by using more flood control storage i e a higher reservoir water level the releases of these different schemes are different after the occurrence of the downstream peak flow scheme solq 4 has the highest resilience and makes full use of the flood control capacity with a higher reservoir water level in panel b when given a certain upstream maximum water level that is the water level is the same i e 218 02 m in panel b the reservoir can improve the resilience by sacrificing downstream peak flow as shown in fig 6b solz 1 releases more floodwater in the flood rising stage and release less water in the recession stage which is a longer period for the high water level to improve resilience in panel c when given a certain downstream resilience that is downstream resilience are the same i e 0 93 in panel c different operation process induces different downstream and reservoir risk scheme solr 4 releases less floodwater discharge in the early stage and more floodwater in the later stage which leads to a smaller downstream peak and a larger downstream flow scheme solr 1 releases more floodwater in the early stage to increase the flood control capacity for the later flood so that the maximum water level 216 93 m of scheme flood z 1 is the lowest among the 4 schemes to sum up pre releasing at the early stage of a flood and slowing down the release process at the recession stage of a flood are the two ways to improve resilience 4 4 optimal scheduling schemes 4 4 1 schemes setting six schemes are selected in the three objective optimization solutions based on the existing operation scheme to further explore the feasibility and superiority of the optimization scheme considering the resilience of downstream protection points the schemes are as follows and shown in figures a1 and a2 in appendix a scheme 1 the maximum reservoir water level equals that of the current operation rule and the downstream peak flow is the largest scheme 2 the maximum reservoir water level equals that of the current operation rule and the downstream peak flow is the smallest scheme 3 the downstream peak flow equals that of the current operation rule and the maximum reservoir water level is the highest scheme 4 the downstream peak flow equals that of the current operation rule and the maximum reservoir water level is the lowest scheme 5 the downstream peak flow and maximum reservoir water level both equal that of the current operation rule scheme 6 the downstream peak flow and maximum reservoir water level both approach that of the current operation rule but the number of floods in which the downstream peak flow exceeds the design value is the smallest 4 4 2 comparisons of the objective values the objectives under the selected six schemes are listed in table 3 and the objectives for each design flood are listed in table a1 4 4 2 1 rainfall pattern i comparing schemes 1 and 2 higher downstream peak streamflow results in a higher resilience when the maximum reservoir water level is constant which demonstrates that sacrifice in downstream risk can improve downstream resilience also comparing schemes 3 and 4 one can find that when the downstream peak flow is constant a higher maximum reservoir water level induces a higher resilience demonstrating that sacrifice upstream can improve downstream resilience comparing schemes cs and 5 the proposed method provides schemes with a higher value of resilience while the risks upstream and downstream are the same although the resilience value for scenario 6 is 86 82 10 2 a bit smaller than that of scenario 5 the downstream streamflow is smaller meanwhile only one flood with a maximum reservoir water level reaching 218 15 m while there are two for scenario 5 as listed in table a1 therefore scenario 6 is preferable the resilience for schemes 1 and 3 is the best which can be chosen when decision makers are more concerned about downstream flood resilience scheme 4 can reduce the upstream risk and the mean maximum water level has been decreased by 0 34 m with the same downstream risk and flood resilience compared with scheme cs and this scheme should be recommended when the decision maker is concerned more about reservoir flood risk schemes 2 and 6 achieve the smallest downstream peak flow which are the optimal decisions for a lower downstream risk 4 4 2 2 rainfall pattern ii under this case the maximum reservoir water level of scenario cs reaches the maximum value of 218 15 m and there is no improvement space for the reservoir risk hence there is no difference between schemes 3 4 and 5 4 4 3 recommended scheme as listed in table a1 in appendix a for rainfall pattern i the maximum reservoir water level and the downstream peak flow for scheme 6 are similar to that of scheme cs the downstream resilience for all floods except flood type 1988 with a frequency of 1 is higher for rainfall pattern ii the resilience for all design floods in scheme 6 is higher than that of scheme cs mainly through pre release at the early stage of flood or slowly empty of the reservoir capacity after the flood peak thereby reducing the overall damage during floods and increasing the system resilience at the same time compared with scheme cs scheme 6 has only one flood with the maximum reservoir water level reaching 218 15 m while scheme 5 has two floods therefore scheme 6 is recommended when the upstream and downstream flood risks are close to the cs that is scheme 6 can increase the downstream resilience without increasing flood risks the indicators of the scheduling rules under the recommended scheme are shown in table 4 as can be seen that the release for the recommended rule is higher than scheme cs when the flow is relatively small because the increase of the release volume in the early stage can provide more storage capacity for the arrival of flood peaks achieving the goal of increasing the resilience of the downstream flood control system and reducing the downstream peak flow finally a real flood event 2013 flood event has been used to verify the advantage of the recommended rule as shown in fig 9 the results show that the recommended rule can make more full use of the storage of the reservoir to reduce the peak flow and increase the downstream resilience under the condition of ensuring the safety of the upstream reservoir 5 conclusion this paper introduces resilience into reservoir flood control operation for determining the reservoir flood control operation rules the definition and the quantification of resilience are elaborated the resilience metric is measured with system functionality which is defined as the ratio of discharge exceeding the threshold a multi objective optimization model with objectives of minimization of maximum reservoir water level and downstream peak flow and maximization of downstream flood resilience is established nierji reservoir located in northeast china is taken as a case study to investigate the effectiveness and advantages of the proposed method the following conclusions are drawn 1 the multi objective optimization algorithm of nsgaii was applied to obtain the flood control operation rules with eight design flood hydrographs from 4 typical floods the results show that compared with the conventional operation rule the proposed method can improve the downstream resilience without increasing reservoir and downstream flood risk 2 there exist tradeoffs among maximum reservoir water level downstream peak flow and downstream resilience the tradeoff interval between downstream resilience and downstream peak flow narrows with high flood risk i e with a large maximum water level or downstream streamflow the tradeoff relationship demonstrates that resilience improvement inevitably sacrifices flood risk and the improvement is related to flood risk magnitudes 3 resilience improvement is also related to the magnitudes and types of floods for the flood with a high interval flood the resilience improvement is limited resilience improvement is achieved through pre releasing at the early stage of a flood and slowing down the release process at the recession stage of a flood the resilience metric in this study is simplified with the magnitude of streamflow resilience is closely related to the inundation area and depth which is a further study credit authorship contribution statement wei ding conceptualization writing review editing supervision funding acquisition guozhen wei methodology software formal analysis writing original draft visualization huicheng zhou project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is supported by the national natural science foundation of china grant no 52079015 u2240204 and the key base platform research project of dalian university of technology in china dut22lab118 appendix a the results of different schemes table a1 fig a1 fig a2 
1973,reservoir operation is an effective measure for flood disaster reduction previous studies focused on minimizing flood risk to reduce potential flood damage however failure and recovery processes are not considered to address this shortcoming this study introduces the concept of resilience to measure the ability of flood control systems to maintain or return to the original states after an extreme flood the quantitative expression of resilience resilience metric is proposed based on the system performance and defined as the summation of system functionality loss throughout the entire flood process based on the proposed resilience metric a multi objective optimization model with flood risk represented by maximum reservoir water level and downstream peak flow and flood resilience as objectives is established nierji reservoir located in northeast china is taken as a case study results show that the proposed method can improve resilience without increasing flood risks i e maximum reservoir water level and downstream peak flow compared with the traditional model pareto optimates of the optimization model show that there exist tradeoffs between risk and resilience improving resilience inevitably reducing risk the resilience improvement is large when the flood risk of the reservoir or downstream is medium and is limited when the flood risk is high moreover the resilience improvement is higher for a smaller flood the improvement is achieved through pre releasing at the early stage of the flood and releasing slowly at the recession stage of the flood six typical schemes selected referring to the existing scheme are comprehensively compared and an operation rule for flood control with the highest resilience but without reducing risks is recommended this study provides a new way for flood control management keywords flood resilience flood risk multi objective optimization reservoir operation data availability the data that has been used is confidential 1 introduction flooding is the most frequent natural hazard causing enormous economic loss environmental damage and human fatalities teng et al 2017 the world disasters report in 2018 highlighted that the number of floods by far outstrips the number of storms and all other disasters recorded from 2008 to 2017 fisher et al 2018 the frequency intensity and consequences of flood events will further increase due to climate change social and economic development apurv et al 2015 dottori et al 2018 svetlana et al 2015 the reservoir is an effective engineering measure for flood disaster reduction labadie 2004 windsor 1973 flood control operation is the key to achieving flood reduction and mitigation effects of reservoirs jia et al 2016 moridi and yazdi 2017 zhu et al 2017 reservoir operation rules for flood control determine how much water is to be released at each time step during flood seasons flood control needs to consider the safety of upstream catchments the reservoir itself and downstream catchments thus the determination of the reservoir operation rule for flood control is a multi objective decision making problem hsu et al 2015 the critical issue is how to balance the damage or risk among the safety of the dam or reservoir itself downstream and upstream during flooding and also to balance flood control and flood water resources utilization ding et al 2015 hsu and wei 2007 lei et al 2018 wei and hsu 2008 chou and wu 2015 presented a framework of release rule for reservoir flood control operations aiming at maximizing flood mitigation without elevating the reservoir water level beyond the design flood water level at the flood peak stage qi et al 2017 established a multi objective optimization model for reservoir flood control operation by minimizing the highest upstream water level and the largest water release volume previous research focused on the extreme value of maximum flood water level and downstream peak flow i e the risk chang et al 2010 lei et al 2018 windsor 1973 however the damage of flooding is affected by the hydrodynamic process including the duration of high downstream flow or high reservoir water level and the recovery time for example meng et al 2019 established a flood control operation model by minimizing the maximum water level and its time duration however there is a lack of research on considering flood resilience that can describe the hydrodynamic process in reservoir operation resilience is a concept that measures the capacity of a system to resist withstand recover from and adapt to exceptional conditions cimellaro et al 2010 deangelis 1980 gunderson 2000 it was first introduced to the ecosystem but has been expanded to many engineering and social systems in recent years meerow et al 2016 in water supply systems many researchers incorporated resilience in reservoir water supply systems to investigate the relationship among reliability vulnerability and resilience under different operation strategies hashimoto et al 1982 moy et al 1986 ren et al 2020 zhang et al 2017 and investigate the system resilience change in response to changing environment including climate change population growth and urbanization mereu et al 2016 zhao et al 2018 in flood control systems previous research focused on urban flood resilience with different frameworks and resilience evaluation metrics bertilsson et al 2019 juan garcia et al 2017 liao 2012 mugume et al 2015 djordjevic et al 2011 defined urban resilience as the capacity of a system community or society potentially exposed to hazards to adapt by resisting or changing in order to reach and maintain an acceptable level of functioning and structure wang et al 2019 proposed a grid cell based resilience metric to assess urban flood resilience identify vulnerable catchments and assist in developing an effective adaptation strategy however there is a lack of research on incorporating resilience into reservoir flood operations in the last several years a few attempts have been made including the development of a qualitative resilience matrix under different phases of the decision making process of reservoir operation for flood control through workshops and surveys mustajoki and marttunen 2019 and the development of a resilience assessment framework to evaluate dam safety upgrade options from a flood damage mitigation perspective kim et al 2017 this paper defines and quantifies flood resilience for reservoir flood control operations a resilience based reservoir operation approach for flood control has been proposed the nierji reservoir system is taken as a case study to demonstrate the advantages of the proposed method the relationship among the upstream reservoir risk downstream risk and the resilience of the downstream system are analyzed and the impact of rainfall and flood hydrograph is discussed the reason for how the operation rules generated from the proposed method increase the downstream resilience in the flood control process is explored finally optimal flood control operation rules comprehensively considering flood risk upstream and downstream and the resilience of the downstream system is recommended 2 methodology 2 1 definition and quantification of flood resilience in terms of a flood event the reservoir should utilize its flood control capacity to regulate the flood hydrograph to ensure the safety of the system usually the safety of the system includes the safety of upstream catchments the reservoir itself and downstream catchments and the safety of the reservoir has the highest priority for a large flood inundation might happen in downstream communities which might induce flood damage the extent of damage to the downstream community is related to the magnitude and duration of flooding which are key aspects of resilience timmerman 1981 the quantitative and qualitative assessment methods of flood resilience mainly include a multi criteria method and a performance based metrics method fu et al 2020 the multi criteria method focused on how to evaluate the resilience from multi attribute such as economic indicators and social indicators in resisting absorbing recovering from and adapting to an extreme flood event kotzee and reyers 2016 the performance based metrics method described the magnitude change of the system during the whole process of extreme flood events through system functions which is widely used bruneau et al 2003 wang et al 2019 in this study system resilience is defined as the ability of the downstream community to resist absorb recover from and adapt to an extreme flood event and considering the extent of downstream damage is relevant to the downstream flow the downstream flow is used to measure system performance ganin et al 2016 the schematic diagram of resilience is shown in fig 1 where fig 1 a represents the streamflow hydrograph downstream q initial is the operational threshold of the system below which the system is considered normal i e no system functionality loss there is system functionality loss when the flow exceeds q initial q max is the flow that the downstream system is completely destructed that is the system functionality is lost this study defines the normal system functionality as 1 the system performance is defined as the proportion of the streamflow exceeding the threshold q initial as expressed in equation 1 fig 1 b shows the variation of system functionality with the flow the system experiences a flood at ts and its performance drops with the increase of discharge the system performance reaches a minimum value of pf at tfs then recovers gradually and comes back to normal at time te the value of the system performance of the downstream system at any time t is defined as 1 p t 1 q t q initial q max q t q max q initial q initial q t q max 0 q t q max where q t represents the downstream flow at time t the loss of system functionality throughout the entire flood event is measured by the index of severity s s is estimated as the aggregation of system functionality loss and shown as the dark shaded area in fig 1 b s quantifies the failure magnitude and duration and can be presented by 2 s 1 t n t e t s 1 p t d t the resilience metric r which is a measure of system residual functionality is estimated as the aggregation of the system performance during the entire process or one minus the severity shown as 3 r 1 s 1 t n t n 0 p t d t 2 2 optimization model for flood control operation 2 2 1 objective function a traditional optimization model for flood control operation rule generally has two objectives i e minimize the maximum reservoir water level and minimize the peak flow at the selected downstream control point in this study we introduce downstream resilience maximization into the optimization model as the new objective so there is a total of three objectives first reservoir operation for flood control aims to minimize the maximum reservoir water level during a flood event for the optimization of operation rules the objective is to minimize the expected value of the maximum reservoir water levels of design floods under different frequencies 4 m i n 1 n i 0 n m a x z i t t 0 t n where n represents the number of design floods max z i t t 0 t n represents the maximum reservoir water level for the i th design flood second minimize the peak flow at the selected downstream control point here the objective is to minimize the average of the peak flow at the downstream point for different design floods shown as follows 5 m i n 1 n i 0 n m a x q i t t 0 t n where max q i t t 0 t n represents the downstream peak flow for the i th design flood third maximize the downstream resilience 6 m a x 1 n i 0 n r i where r i represents the value of downstream resilience for the ith design flood which can be calculated by equation 3 2 2 2 constraints 2 2 2 1 reservoir mass balance equation 7 v t v t 1 i t o t δ t where δt is the time interval a short period for flood routing i t and o t are the inflow and outflow for the reservoir at time t respectively v t and v t 1 are the reservoir s initial and ending storage at time t the evaporation and leakage loss are ignored since they are small compared with inflow 2 2 2 2 water level constraint 8 z min z t z max where z t represents the reservoir water level at time t z min and z max represent the minimum and maximum water level at time t respectively 2 2 2 3 reservoir discharge constraint 9 o t o max z t where o max z t represents the maximum discharge ability corresponding to reservoir water level zt 2 2 2 4 the maximum flow constraint at downstream 10 q t o t q int e r t q max where q t is the discharge for the downstream flood control point at time t o t is the flow of reservoir release after flood routing to the downstream flood control point q int e r t is the intermediate flow between the reservoir and the downstream flood control point q max is the maximum allowed flow at the downstream flood control point 2 2 3 optimization algorithms a widely used many objective evolutionary algorithm the non dominated sorting genetic algorithm ii nsga ii is adopted to obtain the pareto optimal solutions of the simulation optimization model deb et al 2002 wei et al 2022 zhang et al 2017 the decision variables of the optimization model are the releases and the discriminative index indicating the release in the paper the number of iterations is 1000000 and the population size is 10000 which is determined by the abundance of optimal solutions the probability of mutation is 0 1 the probability of crossover is 0 9 and the distribution index for crossover and the distribution index for mutation is set to 20 3 case study 3 1 overview nierji reservoir located in nen river northeast china is taken as a case study the primary task of the reservoir is flood control with hydropower generation water supply for industry agriculture and wetland as well as navigation as the secondary tasks as an important part of the songhua river and nen river flood control system nierji reservoir with a flood control storage of 2 368 billion m3 complied with the downstream dikes undertakes the flood control task in the mainstream of nen river and improves the flood standards of qiqihaer city from the 50 year return period with a frequency of 2 to the 100 year return period with a frequency of 1 the qiqihaer hydrological station the streamflow of which consists of release from nierji reservoir and streamflow from nuomin river and namoer river represents the flood in qiqihaer city as shown in fig 2 the maximum allowable streamflow at qiqihaer hydrological station is 8850 m3 s with a flood control standard of a 50 year return period protecting the farmland from flooding and it is 12000 m3 s with a flood control standard of a 100 year return period protecting the flood safety of qiqihaer city the flood limited water level and the flood prevention level are 213 37 m and 218 15 m respectively which are the minimum and maximum water levels for equation 8 3 2 the design floods the principle of flood control operation for nierji reservoir is that the reservoir should release flood water based on the intermediate flow between the reservoir and the flood control point to reduce the flood peak at qiqihaer hydrologic station there exist two most unfavorable flood combinations a the flood frequencies of the nierji reservoir basin and downstream are the same defined as rainfall pattern i in this pattern the flood at qiqihaer hydrologic station mainly comes from the reservoir there are three typical floods type 1969 type 1988 and type 1998 6 respectively as shown in fig 3 a 3b and 3c b the flood frequencies of the intermediate basin and downstream are the same defined as rainfall pattern ii in this pattern the flood at qiqihaer mainly comes from the intermediate basin between the reservoir and the downstream flood control point the typical flood is type 1998 8 fig 3d the design flood hydrographs with frequencies of 2 and 1 i e with a return period of 50 year and 100 year are included to derive the optimal flood control rules 3 3 flood control operation rule the conventional operation rule of nierji reservoir during flood season is identified by the reservoir water level and the combination of flow at three rivers shown in table 1 and table 4 in table 1 the q 3 s is the sum of the nierji inflow the flow at the guchengzi station in nuomin river and the flow at the dedu station in namoer river of the last period as shown in fig 2 z is the reservoir water level x i i 1 2 14 represents the reservoir release i is the reservoir forecast inflow for the current period lim qi is the discriminative index indicating the release the variables in table 1 including lim qi and x i are optimized with the optimization model regulating 8 design flood hydrographs mentioned in section 3 2 3 4 parameters related to resilience the streamflow at qiqihaer a hydrologic station is equal to the sum of flow routed from the upstream reservoir release nuomin river and namoer river the muskingum method is used for the channel flow routing from the nierji reservoir and guchengzi hydrologic station in namoer river to the downstream control point i e qiqihaer hydrologic station the streamflow in the nuomin river represented by the flow at dedu hydrological station is routed to qiqihaer hydrological station with no deformation but traveling for seven days when the streamflow at qiqihaer hydrologic station is larger than 6580 m3 s the dikes will be flooded that is the performance functionality of the flood control system is smaller than 1 when the streamflow is larger than 14300 m3 s the farmland and qiqihear city will be flooded i e the performance functionality is zero therefore the q initial and q max in equation 1 are 6580 m3 s and 14300 m3 s respectively 3 5 system performance under the existing flood control operation rules table 2 shows the maximum reservoir water level the downstream peak flow and the resilience at downstream under the conventional flood control operation rules 4 results and discussion 4 1 improvement of resilience this section aims to analyze the improvement of resilience of the proposed model compared with the traditional method which is to optimize the operating rule with the minimization of reservoir water level and downstream peak flow as the objectives named the two objective optimization model fig 4 shows the pareto approximates from the proposed and traditional models for rainfall pattern i in the figures the triangle points represent the solutions of the two objective optimization model and the corresponding downstream resilience of the optimal solutions is calculated based on the reservoir operation simulation the diamond point represents the conventional operation rule under a conventional scenario cs as can be seen from fig 4 a that the optimization model can greatly improve the three objectives compared to the current operation rule solution since the diamond point locates above the optimal solutions fig 4 b d show the tradeoffs among the three objectives in the two dimensional axis and there exists a conflicting relationship between any two objectives fig 4 b shows that the three objective optimization model can improve resilience compared to the two objective optimization model and the improvement is higher with a higher maximum reservoir water level meanwhile increasing downstream peak flow i e higher flood risk downstream can also improve resilience shown in fig 4 d that is improving the system resilience will inevitably bring higher downstream or reservoir flood risks under the optimization model in fig 4 d different curves represent the tradeoffs between downstream resilience and peak flow under different maximum reservoir water levels as can be seen the tradeoff curves are narrowed down with a high reservoir water level or downstream peak flow that is to say the variation of resilience is limited when the safety requirement upstream or downstream is high 4 2 impacts of rainfall and flood hydrographs fig 5 shows the tradeoffs among the maximum reservoir water level the downstream peak flow and downstream resilience in the two dimensional axis for rainfall pattern ii as can be seen under rainfall pattern ii the three objective model can also improve resilience but the improvement is not as high as that in rainfall pattern i as shown in fig 5 b d the relationships between the three objectives from the three objective case are the same as that in rainfall pattern i however there exists a difference in the objectives and their relationship compared with fig 4 c and 5 c the maximum water level ranges in a narrow range of 217 20 m 218 15 m in rainfall pattern ii which ranges within 215 30 m 218 15 m in rainfall pattern i besides there is a horizontal line with a maximum water level of 218 15 m subject to the maximum water level constraint the reason is that under rainfall pattern ii the flood from the basin between nierji reservoir and qiqihaer hydrologic station is large and hence the reservoir has to utilize the flood control storage to retain and detent flood as much as possible to guarantee downstream safety and even utilize all the flood control storage to guarantee a relatively small downstream flow when downstream undertakes a larger flow there exists a larger decision space shown in the right part of fig 5 c fig 6 displays the objectives of the eight design flood hydrographs for the three objective optimization model all the subfigures show that there exists a tradeoff relationship between downstream resilience and peak flow that is downstream resilience increases with the increase of downstream peak flow and the tradeoff range is high with a medium reservoir water level or peak flow but for a specific typical flood the value of resilience and its variation range is higher for a flood with a frequency of 2 than that of 1 the reason is that flood with a frequency of 1 is larger and brings a higher risk to the flood control system and thus there is limited space for improving resilience comparing the results of different rainfall patterns it can be seen that the resilience improvement is smaller and the maximum water level is high in rainfall pattern ii the reason is that in rainfall pattern ii there is large rainfall in the intermediate region and thus the improvement by the reservoir operation is limited in the meantime the reservoir needs to retain more floodwater which leads to a high reservoir water level i e basically above 216 5 m comparing the results of different flood types in rainfall pattern i the variation of the maximum water level in flood type1998 6 is smaller than that in the 1969 and 1988 floods the reason is that the peak flow duration in type 1998 6 flood is longer so the reservoir needs to reduce release for the safety of downstream resulting in the decrease of the capacity of the reservoir s flood control to sum up when the downstream floodwater volume is smaller there will be relatively more solutions for the reservoir to improve the downstream resilience to a greater extent 4 3 operations to improve resilience this section investigates how resilience is improved through a flood regulation process fig 7 shows the regulation process of two solutions selected from the three objective optimal solution set and the two objective optimal solutions set with the same maximum water level and downstream peak flow it shows that the three objective case slows down the release at the receding stage of the flood by retaining floodwater in the reservoir i e emptying the flood control storage slowly thereby improving the system performance and increasing downstream flood resilience in the meantime three scenarios are designed to further investigate how to improve resilience fig 8 scenario 1 4 schemes with the same downstream peak flow represented by solq 1 solq 2 solq 3 and solq 4 are selected from the three objective optimization sets scenario 2 4 schemes with the same maximum reservoir water level represented by solz 1 solz 2 solz 3 and solz 4 are selected from the three objective optimization sets scenario 3 4 schemes with the same downstream resilience represented by solr 1 solr 2 solr 3 and solr 4 are selected from the three objective optimization sets it can be seen from panel a that when given a certain downstream peak flow that is the same downstream peak flow i e 10606 m3 s in panel a the reservoir can improve resilience by using more flood control storage i e a higher reservoir water level the releases of these different schemes are different after the occurrence of the downstream peak flow scheme solq 4 has the highest resilience and makes full use of the flood control capacity with a higher reservoir water level in panel b when given a certain upstream maximum water level that is the water level is the same i e 218 02 m in panel b the reservoir can improve the resilience by sacrificing downstream peak flow as shown in fig 6b solz 1 releases more floodwater in the flood rising stage and release less water in the recession stage which is a longer period for the high water level to improve resilience in panel c when given a certain downstream resilience that is downstream resilience are the same i e 0 93 in panel c different operation process induces different downstream and reservoir risk scheme solr 4 releases less floodwater discharge in the early stage and more floodwater in the later stage which leads to a smaller downstream peak and a larger downstream flow scheme solr 1 releases more floodwater in the early stage to increase the flood control capacity for the later flood so that the maximum water level 216 93 m of scheme flood z 1 is the lowest among the 4 schemes to sum up pre releasing at the early stage of a flood and slowing down the release process at the recession stage of a flood are the two ways to improve resilience 4 4 optimal scheduling schemes 4 4 1 schemes setting six schemes are selected in the three objective optimization solutions based on the existing operation scheme to further explore the feasibility and superiority of the optimization scheme considering the resilience of downstream protection points the schemes are as follows and shown in figures a1 and a2 in appendix a scheme 1 the maximum reservoir water level equals that of the current operation rule and the downstream peak flow is the largest scheme 2 the maximum reservoir water level equals that of the current operation rule and the downstream peak flow is the smallest scheme 3 the downstream peak flow equals that of the current operation rule and the maximum reservoir water level is the highest scheme 4 the downstream peak flow equals that of the current operation rule and the maximum reservoir water level is the lowest scheme 5 the downstream peak flow and maximum reservoir water level both equal that of the current operation rule scheme 6 the downstream peak flow and maximum reservoir water level both approach that of the current operation rule but the number of floods in which the downstream peak flow exceeds the design value is the smallest 4 4 2 comparisons of the objective values the objectives under the selected six schemes are listed in table 3 and the objectives for each design flood are listed in table a1 4 4 2 1 rainfall pattern i comparing schemes 1 and 2 higher downstream peak streamflow results in a higher resilience when the maximum reservoir water level is constant which demonstrates that sacrifice in downstream risk can improve downstream resilience also comparing schemes 3 and 4 one can find that when the downstream peak flow is constant a higher maximum reservoir water level induces a higher resilience demonstrating that sacrifice upstream can improve downstream resilience comparing schemes cs and 5 the proposed method provides schemes with a higher value of resilience while the risks upstream and downstream are the same although the resilience value for scenario 6 is 86 82 10 2 a bit smaller than that of scenario 5 the downstream streamflow is smaller meanwhile only one flood with a maximum reservoir water level reaching 218 15 m while there are two for scenario 5 as listed in table a1 therefore scenario 6 is preferable the resilience for schemes 1 and 3 is the best which can be chosen when decision makers are more concerned about downstream flood resilience scheme 4 can reduce the upstream risk and the mean maximum water level has been decreased by 0 34 m with the same downstream risk and flood resilience compared with scheme cs and this scheme should be recommended when the decision maker is concerned more about reservoir flood risk schemes 2 and 6 achieve the smallest downstream peak flow which are the optimal decisions for a lower downstream risk 4 4 2 2 rainfall pattern ii under this case the maximum reservoir water level of scenario cs reaches the maximum value of 218 15 m and there is no improvement space for the reservoir risk hence there is no difference between schemes 3 4 and 5 4 4 3 recommended scheme as listed in table a1 in appendix a for rainfall pattern i the maximum reservoir water level and the downstream peak flow for scheme 6 are similar to that of scheme cs the downstream resilience for all floods except flood type 1988 with a frequency of 1 is higher for rainfall pattern ii the resilience for all design floods in scheme 6 is higher than that of scheme cs mainly through pre release at the early stage of flood or slowly empty of the reservoir capacity after the flood peak thereby reducing the overall damage during floods and increasing the system resilience at the same time compared with scheme cs scheme 6 has only one flood with the maximum reservoir water level reaching 218 15 m while scheme 5 has two floods therefore scheme 6 is recommended when the upstream and downstream flood risks are close to the cs that is scheme 6 can increase the downstream resilience without increasing flood risks the indicators of the scheduling rules under the recommended scheme are shown in table 4 as can be seen that the release for the recommended rule is higher than scheme cs when the flow is relatively small because the increase of the release volume in the early stage can provide more storage capacity for the arrival of flood peaks achieving the goal of increasing the resilience of the downstream flood control system and reducing the downstream peak flow finally a real flood event 2013 flood event has been used to verify the advantage of the recommended rule as shown in fig 9 the results show that the recommended rule can make more full use of the storage of the reservoir to reduce the peak flow and increase the downstream resilience under the condition of ensuring the safety of the upstream reservoir 5 conclusion this paper introduces resilience into reservoir flood control operation for determining the reservoir flood control operation rules the definition and the quantification of resilience are elaborated the resilience metric is measured with system functionality which is defined as the ratio of discharge exceeding the threshold a multi objective optimization model with objectives of minimization of maximum reservoir water level and downstream peak flow and maximization of downstream flood resilience is established nierji reservoir located in northeast china is taken as a case study to investigate the effectiveness and advantages of the proposed method the following conclusions are drawn 1 the multi objective optimization algorithm of nsgaii was applied to obtain the flood control operation rules with eight design flood hydrographs from 4 typical floods the results show that compared with the conventional operation rule the proposed method can improve the downstream resilience without increasing reservoir and downstream flood risk 2 there exist tradeoffs among maximum reservoir water level downstream peak flow and downstream resilience the tradeoff interval between downstream resilience and downstream peak flow narrows with high flood risk i e with a large maximum water level or downstream streamflow the tradeoff relationship demonstrates that resilience improvement inevitably sacrifices flood risk and the improvement is related to flood risk magnitudes 3 resilience improvement is also related to the magnitudes and types of floods for the flood with a high interval flood the resilience improvement is limited resilience improvement is achieved through pre releasing at the early stage of a flood and slowing down the release process at the recession stage of a flood the resilience metric in this study is simplified with the magnitude of streamflow resilience is closely related to the inundation area and depth which is a further study credit authorship contribution statement wei ding conceptualization writing review editing supervision funding acquisition guozhen wei methodology software formal analysis writing original draft visualization huicheng zhou project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is supported by the national natural science foundation of china grant no 52079015 u2240204 and the key base platform research project of dalian university of technology in china dut22lab118 appendix a the results of different schemes table a1 fig a1 fig a2 
1974,uncertainty in environmental modeling predictions stemming from parameter estimation is a crucial challenge that must be addressed to ensure effective decision making limited field measurements high computational costs and a lack of guidance in estimating measurement uncertainty further compound this challenge particularly for highly parameterized complex models in this study we propose a novel and computationally efficient framework for quantifying predictive uncertainty that can be applied to a range of environmental modeling contexts the novel components of the framework include efficient parameter space sampling using an optimized latin hypercube sampling strategy and applying the null space monte carlo method nsmc along with a developed filtering technique the nsmc generates sample sets to calibrate the model while exploring the null space this space contains parameter combinations that are not sufficiently supported by observations the filtering technique omits low potential parameter sets from undergoing model calibration the framework was tested on the seawater intrusion swi model of wadi ham aquifer in the united arab emirates uae to investigate aquifer sustainability in 2050 our results demonstrate the importance of incorporating direct and indirect measurements of heads salinity and geophysical survey data into the calibration dataset to reduce uncertainty in salinity predictions the extent of swi for multiple calibrated parameter sets varied by 4 5 to 11 relative to their means at two main pumping fields we conclude with a moderate to a high degree of certainty that swi is a serious threat to these fields and actions are needed to protect the aquifer from salinization additionally variations in swi length under different geological conditions illustrate regions of high uncertainty that require further data collection our framework effectively reduced and quantified prediction uncertainty and provides decision makers with critical information to inform risk management strategies keywords seawater intrusion parameter estimation data worth parameter identifiability optimized latin hypercube sampling uncertainty analysis data availability the authors do not have permission to share data 1 introduction groundwater is a vital source of freshwater for over two thirds of the world s population living in coastal regions singh 2014 however this resource is threatened by seawater intrusion swi werner et al 2013 to mitigate the negative impacts of swi numerical models are used to develop effective management strategies however these models are only as reliable as the input some data such as aquifer geometry hydraulic properties and boundary conditions are often uncertain due to a lack of field measurements aquifer heterogeneity regional flow systems and forecasted salinization drivers this uncertainty leads to uncertain predictions doherty 2016 making it imperative for stakeholders and decision makers to quantify the prediction uncertainty doherty and moore 2020 in order to make informed decisions to address this issue predictive uncertainty analysis is required to characterize the potential variability in a prediction model output through the identification of multiple parameter sets input variables that can be used by the model dausman et al 2010 table 1 summarizes the main methods for quantifying the prediction uncertainty in swi the three methods for predictive uncertainty analysis include monte carlo simulations conditional monte carlo simulations and linear uncertainty analysis monte carlo simulations method which has been used in both conceptual e g ketabchi and jahangir 2021 rajabi and ataie ashtiani 2014 zhao et al 2016 and real world studies e g miao et al 2019 mostafaei avandari and ketabchi 2020 it repeatedly runs the model with different sets of parameters to generate multiple realizations of the model output the conditional monte carlo simulations method on the other hand conditions the input variables to observed data the approach has two perspectives the first perspective considers the non uniqueness of the parameter sets through the model calibration in a stochastic inverse modeling framework such as markov chain monte carlo mcmc rajabi and ataie ashtiani 2016 zeng et al 2016 self calibrating pool et al 2015 gradual conditioning llopis albert et al 2016 and iterative ensemble smoother ies hugman and doherty 2022 methods the second perspective seeks uniqueness by implementing regularization to incorporate prior information on parameters within model calibration depending on the inferred single calibrated parameter set the null space monte carlo nsmc tonkin and doherty 2009 method generates multiple realizations to estimate the prediction uncertainty e g herckenrath et al 2011 linear uncertainty analysis assumes linear model behavior and represents the relationship between parameters and predictions with a matrix that is independent of parameter values e g coulon et al 2021 table 1 also highlights two other key features the considered number of uncertain parameters and the adopted ways to alleviate the computational burden associated with the prediction uncertainty analysis although most of the previous investigations have limited the model parameters to a small number ketabchi and jahangir 2021 miao et al 2019 mostafaei avandari and ketabchi 2020 pool et al 2015 rajabi and ataie ashtiani 2014 rajabi and ataie ashtiani 2016 yang et al 2021 zhao et al 2016 to reduce the computational cost rajabi et al 2018 highly parameterized models are necessary to reduce predictive uncertainty by incorporating parameters that are salient to the model predictions doherty and moore 2021 and to recognize the small scale variability of the hydraulic property that greatly influences the hydrodynamic process for instance the degree of the aquifer heterogeneity has a considerable effect on the swi wedge length and seawater volume ketabchi and jahangir 2021 among the methods used nsmc and ies can reduce the computational burden and handle nonlinear highly parameterized models despite the computational efficiency of ies its success is highly dependent on the quality and size of the ensemble of realizations that are sampled from the prior parameter distributions thus its prior parameter distribution needs special considerations delottier et al 2022 additionally for highly non linear problems the ensemble based method may produce instability and run failures omagbon et al 2021 previous studies have shown the effectiveness of the nsmc method in a highly parameterized swi model and its efficiency in reducing the computational burden keating et al 2010 compared the performance of the nsmc method to the mcmc a statistically rigorous and computationally demanding method in terms of model calibration estimating parameters and prediction uncertainties on a high dimensional parameter estimation groundwater problem the outcomes had a high degree of similarity however nsmc obtained the results with much less computational time herckenrath et al 2011 proved the efficiency of the nsmc method in quantifying the uncertainty in the prediction of the location of the swi interface due to the inflow reduction using a synthetic swi model based on henry problem safi et al 2019 designed a monitoring network in beirut aquifer lebanon to capture the swi behavior through the optimization of the best potential locations of the observation wells to reduce the uncertainty in the prediction of the interface location using the realizations generated by nsmc method however further improvement in computational efficiency is needed three promising ways are found in the literature to address this issue table1 including 1 parallelization and grid computing e g mostafaei avandari and ketabchi 2020 2 efficient sampling strategies that decrease the required number of simulation runs to obtain a stable statistical mean and variance for the prediction probability distribution janssen 2013 with an acceptable accuracy e g rajabi and ataie ashtiani 2016 zhao et al 2016 and 3 development of a surrogate model to act as a simplification to the complex model lower fidelity models were used in highly parameterized models burrows and doherty 2015 hugman and doherty 2022 although data driven surrogate models have been used to handle models with a limited number of parameters e g miao et al 2019 rajabi and ataie ashtiani 2014 they have limitations for highly parameterized models where the number of samples required to capture the behavior grows prohibitively fast with the number of parameters asher et al 2015 and can increase prediction uncertainty especially for large scale and complex models mostafaei avandari and ketabchi 2020 decreasing the unnecessary simulation runs in monte carlo based methods via implementing more efficient sampling strategies that combine the innovative space filling criteria and optimization schemes is not widely used in the literature rajabi et al 2015 despite its popularity in limiting the required number of evaluation points to represent the design space wang et al 2020 while simple random sampling srs is the standard method e g herckenrath et al 2011 pool et al 2015 it does not ensure space filling which means that one element may be chosen more than once conversely latin hypercube sampling lhs approach mckay et al 1979 divides the range of each input variable into equally probable intervals the number of which is equal to the sample size within each interval a random sample is selected for each variable then the drawn samples are paired with each other randomly therefore lhs requires a smaller sample size than srs for space filling applying space filling optimality criterion to lhs will i enhance its performance especially in large dimensions ii ensure the filling of the input space properly avoiding close points damblin et al 2013 and iii minimize the number of the monte carlo simulation runs to reach the target accuracy janssen 2013 rajabi and ataie ashtiani 2014 showed that using optimized latin hypercube sampling olhs based on the enhanced stochastic evolutionary ese optimization and employing the uniformity criterion was the most efficient approach in terms of the consumed time for monte carlo simulations this was concluded based on a comparison of this strategy to srs lhs and eight other olhs strategies differ in the optimization method and or the space filling criterion on two test cases involving swi models mostafaei avandari and ketabchi 2020 employed olhs based on ese optimization and the uniformity criterion in monte carlo simulations to study the uncertainty in permeability and assess its impact on swi of ajabshir coastal aquifer iran uncertainty quantification is critical for accurately predicting seawater intrusion swi in coastal aquifers but often hindered herrera et al 2022 by the limitations of traditional methods particularly in terms of computational efficiency a critical research gap in previous studies table 1 that needs to be explored is how to efficiently quantify uncertainty in highly parameterized strongly nonlinear swi models caused by uncertain aquifer parameters this study presents a novel and efficient framework for quantifying uncertainty in swi prediction by combining the benefits of the optimized latin hypercube sampling olhs and null space monte carlo nsmc methods the framework is applied to the coastal aquifer of wadi ham in uae which is facing severe swi due to over exploitation to the best of the authors knowledge this study is the first to consider the combined advantages of olhs and nsmc for efficient uncertainty quantification in highly parameterized nonlinear swi models particularly in heterogeneous coastal aquifers the proposed framework includes i calibrating a highly parameterized model using regularized inversion ii defining the calibration solution space using matrix decomposition techniques iii sampling the parameter space efficiently using olhs iv applying the nsmc method to generate parameter sets with the same calibration space v filtering less likely parameter sets from the recalibration using a proposed rejection sampling algorithm vi generating posterior parameter and predictive probability distributions using the ensemble of the calibration constrained parameter sets this study provides a further improvement in computational efficiency for the nsmc method and makes a valuable contribution to the field by providing a practical and computationally efficient framework for quantifying uncertainty in swi prediction 2 methodology a six step general framework has been developed to quantify the prediction uncertainty a flowchart showing the overall methodology is presented in fig 1 each step is described below 2 1 step 1 uncertainties of the calibration dataset the uncertainty values reflect the noise in the measurements their values are assigned based on the used equipment to collect the data expert knowledge and or from other studies with similar site conditions the sources of the uncertainty in the calibration dataset of groundwater head and salinity concentration at each observation well and the earth resistivity imaging data were estimated as follows 2 1 1 groundwater head observations the piezometric heads were collected as the measured depths to the water table at the observation wells data were extracted from available sources as discussed in section 3 the depths were taken manually using a calibrated measuring tape while satellite mapping was used to identify the elevation of the top of each well casing this was done to obtain the head of the fluid within each well with the obtained heads being related to the actual fluid density to compare with simulated heads a conversion to equivalent freshwater heads was carried out using eq 1 1 h f ρ ρ 0 h α z 2 α ρ ρ 0 ρ 0 where h f is piezometric head of the equivalent freshwater head m which is given by h f p ρ 0 g z p is the fluid pressure n m2 h is the measured head m α is the density ratio ρ ρ 0 are the actual fluid density and freshwater density respectively kg m3 z is the elevation at the midpoint of the screen length inside the observation well m the datum of the hydraulic heads is the mean sea level the total uncertainty of the equivalent freshwater heads was calculated eq 3 based on eq 1 assuming that ρ 0 is constant and the errors in the measurements are random and uncorrelated post et al 2018 3 σ h ρ ρ f h σ ρ ρ 2 σ h measured h 2 2 α z σ ρ ρ ρ 0 2 σ z z 2 2 σ pump 2 where the first and second terms represent the uncertainties propagated from the first and second terms of eq 1 and the third term considers the modeled to measured misfit at the observation well which is near a pumping field symbols used in eq 3 are defined in table 2 2 1 2 salinity concentration observations the measured electrical conductivity for the water samples collected from the observation wells was converted to salinity concentration data the uncertainty associated with the measurements is shown in table 2 2 1 3 earth resistivity tomography ert data the average length of swi was estimated from ert transects data measured from the coastline to the start of the freshwater zone total dissolved solids of 1000 mg l and was used to constrain the coupled flow and transport model as indirect observations for the salinity distribution the uncertainty associated with the ert intrusion length σ ert observations is presented in table 2 a custom python script was used to include the indirect observation of the intrusion length in fepest during the parameter estimation fepest links pest and feflow diersch 2013 pest is a model independent non linear parameter estimation software doherty 2016 feflow solves the system of partial differential equations for groundwater flow and for variable density flow coupled with the mass transport equation table 2 shows the standard deviation values for the above mentioned sources of uncertainty associated with the field measurements the measurement noise is assumed to show no spatial or temporal correlation and is characterized by a multigaussian distribution this distribution is defined by mean function observed values of the calibration dataset and covariance function diagonal elements of the covariance matrix are the weights assigned to the various field measurements and are the inverse of the standard deviation values since the calibration dataset which included observations of heads salinity and ert survey data was used in the parameter estimation problem a multi component objective function resulted eq 4 due to the wide range of values in the heads and concentration measurements they were partitioned internally with each hydrograph or salinity concentration forming a separate group that represented a component to filter out structural noise in groundwater models a strategy proposed by doherty and welter 2010 was adopted the model to measurement misfit is dominated by structural noise doherty and welter 2010 the strategy gives equal recognition to each component in the objective function by assigning different weights to each group the weights were estimated as the squared inverse of the standard deviation 1 s t d e v 2 table 2 multiplied by a coefficient that differed between groups to ensure equality 2 2 step 2 data worth assessment a prior step to the parameter estimation is to evaluate the worth of the information in the calibration dataset to reduce the prediction uncertainty to examine the worthiness of the data each observation group from the calibration dataset was removed successively and the incurred increase in the uncertainty of the predictions was calculated doherty et al 2011 the data worth was assessed using linear uncertainty analysis first order second moment based analysis as an approximate and low computational cost analysis tool detailed descriptions of the used equations and their derivations can be found in dausman et al 2010 the assessment of the data worth of each observation group in all observation types was done by processing pest files and implementing them in python using the pyemu python framework for environmental modeling uncertainty analyses library white et al 2016 2 3 step 3 model calibration using regularized pilot points method the mass transport process in the saltwater wedge is influenced by heterogeneities in the aquifer leading to preferential flow pathways and spatial variations in transport velocity to account for small scale variability the pilot point method was used by distributing predefined points in the model domain on a pseudo regular grid with a minimum of five points per correlation range alcolea et al 2006 the parameters were estimated at these points and then spatially interpolated using a selected geostatistical model variogram function to obtain aquifer properties at all model elements the pilot point method was then incorporated with tikhonov regularization to penalize the model parameters deviation from their prior estimates only to an extent that provided an acceptable fit to field measurements doherty 2016 these prior estimates were derived from pumping test results prior geological knowledge and previous studies the regularized inversion i e model calibration attempted to minimize the global objective function φ doherty 2016 which was defined as 4 φ φ m μ φ r 5 φ m c x p t q m c x p 6 φ r d r p t q r d r p where φ m is the measurement objective function φ r is the regularization objective function c is the vector of the measurement observations p is the vector of the parameters requiring estimation x is the calibration sensitivity matrix jacobian matrix of size m n where m and n are the numbers of field observations used in the calibration dataset and the model parameters respectively each element of the matrix expresses the sensitivity of each model output corresponding to the field observations to each parameter q m is the matrix of the weights assigned to the different observations it represents the noise associated with the measurements and induced by model imperfection structural noise q r is the inverse of the pilot point covariance matrix whose elements were calculated based on the selected geostatistical model t denotes the transpose operation d is the vector of the regularization observations which expresses a preferred condition r is the matrix that encapsulates the regularization equations it represents constraints on parameter values in the present study r is the identity matrix for preferred values constraints μ is the tikhonov regularization parameter model calibration was conducted using fepest beopest was used to achieve further computational efficiency by running a model simultaneously on different cores of the same computer the sensitivity matrix was filled based on finite differences with a 1 5 parameter perturbation the tikhonov regularization parameter μ was calculated in every optimization iteration during the inversion process by pest to achieve a target level of model to measurement fit pest viewed the problem as a constrained optimization problem where the objective was to minimize φ r subject to the constraint that φ m should be less than the maximum acceptable misfit between model outputs and the field data truncated singular value decomposition svd and tikhonov regularization were combined using hybrid regularization to address their weaknesses and benefit from their strengths tonkin and doherty 2005 svd separated inestimable parameter combinations zero and low singular values residing them in the calibration null space and created a super parameter set of estimable parameters residing them in the calibration solution space this reduced dimensionality stabilized the inversion process and reduced computation time the model calibration performance was evaluated using statistical indices including root mean square error rmse coefficient of determination rsq and the nash sutcliffe model efficiency nse these indices provided measures of the difference similarity and fit between the observed and simulated datasets respectively 2 4 step 4 parameter identifiability to reduce the computational time the parameter estimation was performed in two phases in phase 1 head data were used and in phase 2 the salinity concentrations and geophysics survey data were used in phase 1 the parameters which had a high identifiability value parid greater than 0 75 were identified as adequately estimated by considering these parameter values as fixed parameters in the next phase a reduction in the computational burden was achieved the parameter identifiability parid was estimated to provide insight into how much information was extracted from the observations to inform the model parameters during the calibration using eq 7 doherty and hunt 2009 parid has a moderate computational burden considers the parameter correlation and approximates the relationship between the model outputs and the parameters as linear doherty et al 2010 parid value varies between zero and 1 zero indicates completely non identified parameters and one indicates that they lie in the calibration solution space and are fully identified the weighted sensitivity matrix q m 1 2 x was computed based on calibrated parameter values and the inverse of the measurements noise it was subjected to svd employing genlinpred utility doherty 2016 svd divides the parameter space into solution subspace v1 and null subspace v2 the threshold of truncation between the solution and null subspaces was calculated using the supcalc utility doherty 2016 the identifiability of a parameter is calculated as the sum of the squared components of all the eigenvectors spanning the solution subspace v1 corresponding to that parameter as follows 7 p a r i d v 1 2 2 5 step 5 model validation the calibrated parameter set was assigned a different observation dataset than that used in model calibration was considered for the validation the performance of the model validation was evaluated using the above mentioned statistical indices of rmse rsq and nse 2 6 step 6 prediction uncertainty analysis the nsmc method developed by tonkin and doherty 2009 was used for prediction uncertainty analysis a brief description of the method s steps is presented in the supplementary material s a the method is based on generating random fields p from the prior parameter probability distributions using a stochastic parameter generator srs is commonly used however in this study optimized latin hypercube sampling olhs was used to improve the sampling efficiency the difference between the stochastic parameters p and the calibrated parameters p was projected onto the calibration null space v2 the projected difference field was then added to the calibrated parameters the new set of parameters p new did not produce exactly the calibrated parameter set due to model nonlinearity and the considered truncation threshold between the solution and null subspaces the model was then executed using p new and re calibrated if the mismatch exceeded an acceptable level the existing sensitivities estimated using the calibrated parameter set were used in the first optimization iteration to save computational time if additional iterations were required for the recalibration the sensitivities were recalculated based on the newly obtained parameter set the objective function threshold was considered 10 higher than the achieved objective function during the calibration in the present work a maximum of two iterations were conducted for each realization the prediction uncertainty was assessed using the resulting parameter sets after the recalibration a flowchart of the nsmc method is shown in fig 1 drawing samples from a prior parameter probability distribution which is too wide may lead to few potential parameter sets that can be accepted while reducing the span of the prior parameter space can sacrifice the integrity of the process doherty et al 2011 in this study a straightforward filtering technique was proposed to screen out from recalibration the parameter sets that were less likely to reach the acceptable objective function in the second iteration without reducing the parameter space a flow chart for the filtering process is presented in fig 2 the details are described below 1 the achieved objective functions of the parameter sets that need to undertake additional iterations after the first iteration are sorted in descending order to form a ranked list 2 the second iteration is carried out first using the parameter set that corresponded to the objective function in the middle of the list in this way the whole list is split into upper and lower lists 3 after the second iteration if the achieved objective function is acceptable step 2 is repeated using the parameter set which was associated with the objective function in the middle of the upper list otherwise this parameter set and the others associated with higher objective functions are excluded from the list step 2 is repeated using the parameter set in the middle of the lower list and so on this procedure is stopped when reaching the top of the list which had undergone the second iteration and succeeded in satisfying the threshold objective function 4 the second iteration is performed on all the remaining parameter sets step 6 is divided into six substeps fig 1 further descriptions of substeps 6 iii and 6 vii are shown as follows 2 7 optimized latin hypercube sampling step 6 iii the efficiency of monte carlo methods is highly dependent on the space filling characteristics of the sampling strategy janssen 2013 rajabi and ataie ashtiani 2014 latin hypercube sampling aims to ensure that each of the input variables has its range well scanned based on a probability distribution the quality of filling can be further improved by optimizing the distribution of the sample points the selected space filling criterion was a point distance criterion φp criterion which controlled the distance between the design points themselves or the input domain and the points damblin et al 2013 in order to optimize the selected criterion the enhanced stochastic evolutionary ese technique was employed φ p criterion was proposed by morris and mitchell 1995 and is calculated as follows 8 φ p i 1 s j i d i p 1 p by sorting all the inter sited distances d ij 1 i j n i j for a given lhs design a distance list d 1 d 2 d s and an index list j 1 j 2 j s are obtained d ij is the euclidean distance between two sample points i j n is the number of sample points each sample point represents the parameters vector d i represents the distinct distance value the elements in the distance list are sorted in ascending order d 1 d s j i represents the number of pairs of sites separated by d i in the design and s is the number of the distinct distance values p was taken as 10 the enhanced stochastic evolutionary ese algorithm was used to generate an lhs design satisfying the φ p criterion the method began with an initial design and tried to find better designs by iteratively changing the current design the method consisted of an inner loop and an outer loop in the inner loop the new designs were explored while the outer loop controlled the acceptance of the new design using a threshold based acceptance criterion the acceptance criterion was as follows 9 δ f t h r a n d o m 0 1 where δ f is the amount of improvement made by the new design compared to the current design r a n d o m 0 1 is a function that generates uniform random numbers between 0 and 1 and t h is the threshold the threshold value was controlled by the outer loop in such a way that if the improvement made in the inner loop was less than a certain level the threshold value was first increased sharply to initiate the exploration process avoid local optimum and then decreased slowly to discover better designs on the other hand if the improvement made was above a certain level the improvement process was initiated attempting to find a local optimum quickly detailed descriptions of the ese algorithm can be found in jin et al 2005 the parameters of the algorithm were assigned with the values suggested in jin et al 2005 the olhs was implemented in smt surrogate modeling toolbox an open source python package bouhlel et al 2019 the run batch file in the pest software suite was edited to read the sample sets generated by olhs and to implement the nsmc method doherty 2016 2 8 generation of posterior parameter uncertainty step 6 vii after recalibration an ensemble of the calibration constrained parameter sets was obtained the values of each parameter were used to determine the best fit probability distribution pd that this data followed after selecting the pd its distribution parameters mean and standard deviation were estimated consequently the posterior pd of each parameter was defined the magnitude of the distribution parameters was used to 1 assess the degree to which the posterior pd became narrower than its prior pd and 2 provide some evidence on characterizing the parameter and predictive uncertainty despite the sample size number of calibrated parameter sets being generally small to derive a true posterior parameter pd sampling the true posterior parameter pd in the context of highly parameterized nonlinear and underdetermined inverse problems is not guaranteed even by using full bayesian approaches and generating thousands of parameter sets keating et al 2010 bayesian approaches formulate the parameter estimation problem in a probabilistic framework considering model inputs and outputs as random variables and including prior information and regularization terms in the inference process rajabi et al 2018 the anderson darling hypothesis test was used to select the best fit pd the test compared the fit of the cumulative distribution function of the observed data to the expected cumulative distribution function ten probability distributions normal lognormal exponential 2 parameter exponential weibull gumbel maximum gumbel minimum gamma logistic and loglogistic were tested as the expected distributions the distribution test that had p values less than 0 005 indicated that it was statistically significant to reject the null hypothesis the null hypothesis stated that the observed data followed this hypothesized distribution among the distributions that had strong evidence to be retained the distribution of the highest p value was chosen to be the best fit distribution minitab statistical package was used to perform the distribution tests arend 1993 3 application of the proposed framework to a real world case study 3 1 study site and numerical modeling wadi ham aquifer a coastal aquifer in an arid region is located in the northeastern part of the uae limited surface water resources the prevalence of drought conditions for successive years and excessive abstractions have placed tremendous pressure on the aquifer and have resulted in severe seawater intrusion problems sherif et al 2014 sowe et al 2020 the total area of the aquifer system is 61 km2 to simulate the groundwater flow and solute transport in the wadi ham aquifer feflow diersch 2013 was employed the set of governing equations and boundary conditions of density dependent fluid flow and solute transport in soils is briefly presented in supplementary material s b2 table 3 shows the considered hydraulic and transport parameters hydrogeological and geological information and the aquifer model discretization details table 4 presents the values of the imposed flow and transport boundary conditions in the simulation model the 3d view of the coastal aquifer model showing the assigned initial and boundary conditions is presented in fig 3 b c 3 2 available observation dataset and estimation of parameters using regularized pilot points method the available data include transient heads salinity concentrations and geophysical survey data table 5 presents the available observation dataset for model calibration and validation following the data worth assessment a decision was taken to conduct the model calibration in two phases will be discussed in section 4 1 december 1988 to september 1994 using hydraulic head values with a single fluid constant density model and october 1994 to march 2005 using salinity concentration and intrusion length estimated from ert survey data a coupled flow and solute transport model was used in phase 2 the final parameter set was from phase 2 and adequately estimated parameters with parid 0 75 from phase 1 their values in the second phase of calibration were fixed the model was validated from october 1994 to april 2005 against the hydraulic heads computational time for one run was 10 and 27 min for phases 1 and 2 respectively on a desktop pc with 3 4 ghz intel r xeon r cpu and 192 gb ram using 10 cores via beopest the target objective functions for phase 1 and phase 2 were estimated to be 18 236 and 197 respectively using the assigned weights described in the supplementary materials s c3 which consider measurement uncertainty and ensure equal visibility for each observation group and eq 10 10 targetobjectivefunction i 1 n i 1 m s t d e v assigned w e i g h t 2 where stdev is the uncertainty in measurements listed in table 2 n is the number of the observation groups and m is the number of readings per group the standard deviation of the head measurements noise varies slightly between different readings of the same observation group average values were considered while a global standard deviation for the salinity concentration measurements at the observation well was used σ sal σ s a l s a m p l e s 2 σ s a l r a s t e r 2 since the salinity observation group consisted of readings from two different sources the pilot points method was used to describe the spatial characterization of the hydrogeological properties horizontal hydraulic conductivity khz and the specific yield sy table 5 in order to generate spatially correlated fields for them geostatistical models were initially fitted to the measurement data for both hydraulic conductivity and specific yield prior information the geostatistical parameters sill and range were optimized so that the interpolated field minimized the misfit between the model outputs and the observation measurements residuals the ordinary kriging interpolation method was used to obtain the parameters values table 5 shows the selected geostatistical models and their initial parameters the regularization constraints which were imposed on the parameters were the preferred values deduced from the prior information the singular value truncation threshold was at a singular value that exhibited the ratio between the lowest to the highest eigenvalue of greater than 1 0 10 6 the mean and the standard deviation describing the prior parameter distributions are listed in table 5 fig 4 displays the mean of the prior parameter distributions at the pilot point locations as interpolated fields 3 3 future prediction of seawater intrusion the model predictive uncertainty was quantified for the average seawater intrusion length l5 the length is measured from the coastline to the 5 isochlor the contour line of 2000 mg l at the quaternary aquifer bottom along the aquifer width the 5 ischlor was selected as the upper acceptable salinity limit for irrigation according to the food and agriculture organization of the united nations ayers et al 1985 the nsmc method was applied to the swi model from december 1988 to september 1994 using the transient hydraulic heads from 1988 to 1994 and the salinity concentrations measurements in 1994 to construct the calibration dataset the objective function was estimated at 2455 considering the achieved residuals using the obtained calibrated parameter set and the assigned weights for each observation group 1 s t d e v table 2 however for equal visibility for each observation group salinity weights were multiplied by 20 since the magnitudes of salinity and hydraulic heads were vastly different a threshold of 2700 was set for the target objective function prior parameters probability distributions were centered on the calibrated set with standard deviation bounds and type as listed in table 5 250 stochastic parameter sets were generated the samples in the olhs design were drawn from a uniform distribution on 0 1 and then mapped onto the prior distributions respecting the assigned parameters bounds the chosen number of generated parameter sets was based on computation time and is comparable to other studies pollicino et al 2021 rajabi et al 2015 the ensemble was used to estimate the uncertainty range in l5 prediction for 2050 current abstraction was assumed to persist due to groundwater deterioration and terminated pumping wells sowe et al 2020 recharge and storage depth at the dam site followed the same trend while inflow across the boundaries was maintained constant over the prediction period 4 results 4 1 data worth analysis the data worth analysis was performed on the period of 1988 to 1994 considering prior information on parameter values the observations data of transient heads from 1988 to 1994 546 monthly head measurements salinity measurements in 1994 11 salinity observations and the length of intrusion retrieved from ert survey data fig 5 shows the results of this assessment for salinity concentration prediction at 121 uniformly distributed points the maximum percentage of increase in the prediction uncertainty variance which was incurred by successive removal of each observation group was contoured fig 5a the analysis showed that despite the small number of salinity observations they had high information content the predictive uncertainty of 56 points was increased by the maximum compared to the removal of the other observation types affecting the prediction uncertainty the most in the eastern part of the aquifer near the coast the hydraulic head observations had a greater impact on reducing the uncertainty in salinity predictions upstream of the seawater wedge generally across the aquifer domain the uncertainty in the prediction increased the most near the observation points that were omitted except near the salinity observations at s15 s16 and s20 and head observations at bhf9a bhf4 and bhf17 thus they did not have information that was relevant to the prediction and or not repeated in other groups it is evident that even though the concentration observations are scarce it is worth including them in the calibration dataset this requires combining groundwater equations with salt transport equations by using the variable density flow and solute transport models the low values of scaled rmse rmse divided by the range in the simulated heads between the simulated hydraulic heads using constant density and variable density models ranged from 0 86 to 6 4 for all the observation wells this suggests that the groundwater flow model could be used in phase 1 for parameter estimation benefitting from its fast run time with the consideration of the variable density effect in phase 2 using the salinity concentration and ert survey data the standard deviation of the post calibration predictive uncertainty was reduced compared to its pre calibration uncertainty fig 5b c however the salinity prediction uncertainty was still high indicating the need for acquiring more complementary data 4 2 parameter identifiability of the hydrogeological parameters at different phases the ability of the calibration dataset to constrain the model parameters in phases 1 and 2 was expressed by the parameter identifiability parid out of 242 parameters 86 were adequately identified with a parid cut off value of 0 75 38 were adequately identified in phase 1 and assumed fixed and an additional 48 were adequately identified in phase 2 fig 6 shows the parid of 121 pilot points used to estimate hydraulic conductivity and specific yield in phases 1 and 2 the transient heads in phase 1 constrained the hydraulic conductivity at the pilot points close to the observation measurements with higher identifiability 9 out of 121 pilot points were considered adequately identified the specific yield parameters are more influenced by soil texture in fine sediments of the western part 29 out of 121 pilot points were considered adequately identified in phase 1 however in coarser sediments east the hydraulic heads in the calibration dataset could not identify specific yield in phase 1 the salinity observations and ert survey data significantly increased the number of identified hydraulic conductivities to 47 38 in phase 2 and 9 in phase 1 the specific yield was less constrained by salinity observations with a slight increase of 10 parameters resulting in 39 adequately identified parameters in total 29 in phase 1 and 10 in phase 2 4 3 model calibration and validation the model performance was evaluated using the calibrated parameter dataset after the model calibration the goodness of fit of the transient head and salinity measurements evaluated using rmse nsh and rsq showed overall satisfactory results for the model calibration and validation the error statistics of the model calibration and validation are shown in fig 7 and table 6 the mismatch of all the simulated heads and salinity concentrations represented by rmse was located within the estimated 95 confidence interval ci of the measurements except for two observations wells bhf1 under the validation and bhf15 under the calibration and validation a high correlation was identified between the observed and simulated measurements at different observation groups 0 7 indicating a significant and positive relationship however for bhf10 the correlation value was 0 12 indicating no similarity in the pattern of variation between the two datasets considering nse coefficients a value of 1 corresponds to a perfect match values between 0 and 1 are viewed as acceptable performance while negative values represent unacceptable performance good model performance can be seen the lower values approaching zero were reported in the salinity measurements this is due to the small number of measurements 2 measurements in each observation group approaching zero means that the average value of the observed dataset is better than the predictions simulated by the model the performance criteria proved that the extracted information from the calibration datasets and the additional information in the form of the prior information imposed on the parameters were able to efficiently constrain the parameters to achieve an acceptable reproduction for the observations the estimated parameter values for the horizontal hydraulic conductivity and the specific yield are presented in fig 4 together with their initial values estimated from the site data the heterogeneity in the hydraulic conductivity was captured and the values were reliable with small departures from their initial values the values of the specific yield varied from their initial values which was expected due to the high uncertainty in their estimates 4 4 analysis of posterior parameter uncertainty the nsmc method was combined with the olhs and filtering rejection sampling techniques to perform a two step re calibration of the swi model the first iteration was performed after generating 250 stochastic parameter sets with 31 sets having an objective function value below the threshold of 2700 these 31 sets were added to the ensemble of calibration constrained parameter sets and 120 sets passed the filtering process to proceed to the second iteration the second iteration resulted in 78 parameter sets that satisfied the objective function threshold bringing the total number of well calibrated parameter sets to 110 1 calibrated set and 31 and 78 sets from the first and second iterations respectively the average value of the multi component objective function for these 110 sets was reduced from 27 000 to 2560 demonstrating the effectiveness of the proposed method a calculated objective function higher than 50 000 was found to be unsatisfactory and was discarded the probabilistic coverage of input space of each parameter provided by olhs strategy was calculated using eq 11 and compared to that generated by srs strategy the probabilistic coverage can be used as guidance hardyanto and merkel 2007 to choose which strategy is preferable eq 11 was used to calculate the probabilistic coverage for each strategy and considered each parameter as a lognormal distributed independent variable the mean and standard deviation were calculated from drawn samples of size 250 11 p l x i x i u x i in eq 11 l x i and u x i are the minimum and maximum values for each parameter xi the probabilistic coverage for each parameter generated by the olhs strategy was approximately 92 and ranged from 71 to 91 for the srs strategy olhs strategy provided better probabilistic coverage compared to the srs strategy the application of the nsmc method resulted in an ensemble of calibration constrained parameter sets obtained by exploring the null space where the parameters were not well constrained by observations and adjusting the solution space parameters the results indicate that the method was effective in constraining the parameters of khz and sy in regions near observation measurements with a reduced ability to constrain in coarse sediments for sy the posterior parameter values were found to be significantly different from their prior values generated by olhs particularly in specific regions near the southeast boundary and northwestern part of the aquifer the highest hydraulic conductivity values were observed near the southeast boundary ranging from 167 to 209 m day while lower values were found in the northwestern part ranging from 10 to 48 m day near the shaarah pumping field which represented fine grained soil the inversion process also constrained a small number of sy parameters near observation measurements in fine grained soil but with reduced ability to constraint in coarse sediments away from the regions with constrained parameters the parameters were allowed to take different values in order to achieve an acceptable level of misfit these results emphasize the significance of defining the null space for the integrity of the prediction uncertainty analysis and considering both prior knowledge and observation data in the parameter calibration process the findings are presented in fig 8 with five randomly selected posterior realizations assumed to represent samples drawn from the posterior parameter distribution the values taken by each parameter in the 110 calibration constrained parameter sets were used to identify the probability distribution pd that this data followed the posterior parameter pd of the logarithm of the hydraulic conductivity was found to fit a normal distribution with an average p value of 0 05 considering 121 pilot points while the specific yield was fitted best by the gumbel maximum probability distribution with an average value of 0 082 the maximum likelihood estimates of the parameters describing each distribution location and scale are equivalent to the mean μ and the standard deviation σ of the parameter variability were calculated and the coefficient of variation cv was utilized to represent the posterior variance of the parameters the cv was calculated for lognormal and gumbel maximum distributions using eq 12 and 13 respectively 12 c v logmormal e σ 2 1 13 c v gumbelmaximum σ μ 0 5772 σ 6 π fig 9 depicts the posterior mean and cv of the khz and specific yield the mean posterior conductivity values fig 9a c agreed well with the results of the pumping tests and the aquifer geology fig 4 the cv of the logarithm of the conductivity field ranged from 7 to 76 fig 9b while its prior cv was 112 a lower dispersion around the mean was shown near the observation data but higher uncertainty near the southern boundary and the uncertainty due to the lack of available observations for the specific yield parameters the parameter estimation reduced the prior cv from an average of 315 to 85 the area of higher certainty was found near the observation data within the fine grained soil of the western part of the aquifer the mean of the specific yield posterior pd at each pilot point was significantly different than its value in the parameter set of the minimum error variance obtained by the model calibration this was due to the large prior uncertainty considered to account for the lack of data the prior parameter pd at 242 pilot points describing the logarithm of khz and sy was assumed normal distribution and their distribution parameters are shown in table 5 the correlation between the identifiability parid and the reduction in the standard deviation of the probability distribution σ red was calculated to investigate the extent to which the parameter identifiability is valid for nonlinear model behavior it was found to be moderate and negative with correlation coefficients of 0 56 for khz and 0 68 for sy the identifiability and the reduction in standard deviation are approximately consistent fig 10 demonstrates the reduction in uncertainty for 8 parameters from different identifiability categories 0 0 25 0 25 0 5 0 5 0 75 and 0 75 1 the reduction in uncertainty is visualized by comparing the height of the posterior and prior distributions at the median the ratio between posterior and prior values indicates the amount of additional knowledge gained from the inversion the results showed that the identifiability and the reduction in standard deviation are approximately consistent 4 5 quantifying the risk of seawater intrusion at pumping fields the 110 calibration constrained parameter sets were used to delineate the uncertainty range in the prediction of l5 2000 mg l isoline for the year 2050 the dispersion of the posterior prediction distributions was quantified with values less than 10 representing high certainty and values between 10 and 20 representing moderate certainty high certainty was found near kalba pumping field σ μ 4 5 while moderate certainty was found near fujyarh pumping field σ μ 11 fig 11 a the wider distribution is the direct outcome of the ill informed parameters by the measurements of the system state as depicted in fig 9 the posterior predictive uncertainty distributions of the intrusion length measured from the coastline at the two pumping fields are shown in fig 11 b c the 95 percentiles of the two distributions showed that it was possible to advance the l5 to the centers of the two pumping fields however the maximum prediction of l5 completely encompassed the kalba pumping field and reached a portion of the fujayrah field leading to salinity levels exceeding the acceptable limit for irrigation purposes 5 discussion 5 1 data worth and their impact on prediction uncertainty the useful feature of analyzing the data worth of the observation data following the method described by dausman et al 2010 is that the predictive uncertainty is independent of the actual values of both the measurements in the calibration dataset and the model parameters however it depends on the stochastic characterization of parameter variability measurement noise and model output sensitivity to parameters accordingly the worthiness of ert survey data was assessed although the data were not available during the analysis period the findings highlight the importance of including salinity observations in the calibration dataset to better constrain the predictions which is consistent with refsgaard et al 2012 they argued that the salinity predictions made by a constant density model are associated with high uncertainty as the predictions are not constrained by the calibration dataset the hydraulic head observations had a greater impact on reducing the uncertainty upstream of the seawater wedge where freshwater inflows hald stream and wadi ham stream and the infiltration from the dam reservoir mainly governed the salinity the uncertainty in the salinity predictions increased by losing these data by an average of 70 on the other hand in the region near the coast enclosed by the contour line of 5000 mg l fig 5a the salinity observation data had the higher influence where the effect of freshwater inflow from the western part of the aquifer decreased and the effect of the inland lateral flow from the sea increased the post calibration uncertainty was reduced indicating the effectiveness of the available information however the salinity prediction uncertainty was still high in the eastern part of the aquifer with an average value of 1000 mg l and exceeding 8000 mg l near hyal stream suggesting a need for acquiring more complementary data hence all the available data for the salinity concentrations were used in the model calibration this analysis suggests areas for further investigation to improve the understanding of the aquifer system making it an essential prior step to the parameter estimation process the groundwater model was used to provide reliable initial parameter estimates to reduce the computational demand of the model calibration in phase 2 using variable density and solute transport model including the salinity observations the accuracy of its usage was evaluated by obtaining the low values of the scale rmse between using constant and variable density hydraulic heads these values can be attributed to the aquifer being shallow and the western part being governed by the freshwater inflow over the calibration period this study adopts simpler models to reduce computational cost without sacrificing accuracy other techniques such as combining fast running model based on non physical parameters and a complex model to estimate equivalent values for the non physical parameters hugman and doherty 2022 increasing grid size burrows and doherty 2015 using 2d models sherif et al 2012b or assuming a sharp interface coulon et al 2021 have also been used however caution should be exercised as these techniques are site specific and may not be universally applicable 5 2 evaluation of the parameter estimability under the linear assumption parameter identifiability was used to evaluate the parameter estimability the analysis showed that 86 out of 242 parameters were adequately identified the transient heads in the calibration dataset identified the hydraulic conductivities near the observation locations while soil texture had a larger impact on specific yield in the western part of the aquifer with fine sediments and steep water level gradients which was indicated from the field measurements at the observation wells of average fluctuation in the water levels of 18 m sherif et al 2014 the specific yield was better identified in coarser sediments east the mild hydraulic head gradient the average fluctuation in the water levels was 1 m made the model outputs insensitive to specific yield the salinity and ert survey data improved the identification of hydraulic conductivities this can be attributed to the key role of hydraulic conductivity in controlling the extent of the swi ketabchi and jahangir 2021 where the model outputs of salinity concentrations were sensitive to those parameters accordingly they displayed high identifiability fig 6 however the specific yield was less constrained by the salinity observations this finding agrees with other studies delsman et al 2017 zhang et al 2020 previous studies on swi models have employed a phased approach to parameter estimation to mitigate computational complexity abd elaty et al 2021 sanford and pope 2010 in this study we utilized fixed adequately identified parameters in the second phase of the model calibration process resulting in a further reduction in computational effort the linearity assumption made by the parid method was assessed in light of potential nonlinearities in the model our results indicate that the parid methodology provides valuable insights into the informativeness of the calibration data and the extent to which prediction uncertainty is reduced as shown in fig 10 5 3 model calibration validation and parameterization the model calibration was performed using the observations of transient heads salinity and ert survey data the tikhonov regularization method was used to incorporate prior information and svd to simplify the calibration process by reducing the number of parameters to those that were sensitive to the observations the results showed an overall reduction in the objective function for head and salinity measurements by 84 and 58 respectively table c3 1 supplementary material however it should be noted that the limited number of salinity measurements in each observation group led to an approach of zero in the nse coefficients indicating that further measurements are needed to improve the accuracy of the model additionally the observed misfit in head measurements in two observation wells near the shaarah pumping field bhf1 under validation and bhf15 under calibration and validation may be attributed to the significant fluctuation in pumping schedules than the assigned average values the proximity of bhf10 to wadi hyal stream resulted in a model structural error due to the assigned fixed boundary condition which did not account for the seasonal fluctuations in the stream water level minimization of the objective function alone is not a sufficient criterion to evaluate the efficiency of the calibration the reliability of the parameter estimates must also be considered to ensure the geological plausibility of the results the spatial variability of the hydraulic conductivity was found to be geologically realistic and preserved the aquifer heterogeneity while the specific yield values varied from their initial estimates but were still acceptable in the geological context specific yield values in similar alluvial aquifers have been measured to range from 0 05 to 0 15 chen et al 2010 and in ophiolite formations the values have ranged from near zero to 0 01 lachassagne et al 2021 the results contribute to the understanding of the geological formation of the system and highlight the importance of considering both the minimization of the objective function and the reliability of the parameter estimates in model calibration 5 4 calibration constrained parameter sets ensemble the implementation of the nsmc method linked with olhs and the filtering technique has successfully generated multiple hydrologically reasonable parameter sets that are in agreement with the available head and salinity observations the filtering technique removed 40 of the generated parameter sets during the recalibration which greatly reduced the computational time of the optimization process this novel approach offers a promising solution for the calibration of swi models and could be applied to other hydrological models the complex nature of swi modeling in heterogeneous aquifers can pose challenges in accurately estimating uncertainty in cases where the calibration dataset does not provide enough information to estimate model complexity such as seen in fig 9 where hydraulic conductivities were only constrained in two regions and a limited number of sy parameters near observation measurements in fine grained soil it is still important to include this complexity in the uncertainty analysis to accurately reflect the uncertainty in the predictions this study highlights the efficiency of nsmc in exploring the null space which is where the insetimated parameters reside and hence is the primary source of uncertainty in the predictions moore and doherty 2005 exploring the null space is based on the prior realization that spans the entirety of parameter space the generated prior realizations by olhs were substantially different from each other fig 9 resulting in a more comprehensive probabilistic coverage than the traditionally used sampling strategy srs a 110 calibration constrained parameter set has resulted from the application of the nsmc method and was used to derive the posterior parameter probability distribution of log khz and sy at each of 121 pilot points the posterior probability distributions of log khz and sy were found to fit normal and gumbel maximum distributions respectively the derived parameter probability distributions can be used to identify areas of high uncertainty in predictions and guide the expansion of the calibration dataset the coefficient of variation was used to compare different types of probability distributions and magnitudes with lower values indicating lower dispersion around the mean and higher certainty fig 10 in general the lower cv values were obtained close to the observation data indicating that the information content in the observations is sufficient to inform constrain the model parameters the certainty in parameter estimation is high and consequently the uncertainty in the predictions that are sensitive to those parameters is low on the other hand the parameters that were not informed by the observation data were constrained by prior information 5 5 analysis of the future prediction of swi the model s performance in predicting swi was compared to hussain et al 2015 who predicted the inland encroachment of 50 ischlor in 2015 under similar abstraction and recharge conditions 81 of their prediction fell within the minimum and maximum prediction range fig 11d indicating the model was calibrated correctly and provides reasonable uncertainty estimates the model was then used to predict swi in 2050 and further deterioration of water quality was revealed due to limited water availability and continued abstraction protective measures must be taken to protect the aquifer s resilience and sustainability despite the associated costs and challenges this finding is crucial for decision makers especially considering the potential exacerbation of future threats from sea level rise and reduced recharge due to rainfall scarcity under the conditions of climate change bolleter et al 2021 this study offers new insights into the parameter estimation and uncertainty analysis of swi models building upon previous studies that have used computationally expensive methods with limited parameters e g llopis albert et al 2016 miao et al 2019 zeng et al 2016 and assumed linear model behavior e g coulon et al 2021 dausman et al 2010 the findings of this study are site specific and model dependent as the results indicate that the parameter uncertainty is influenced by various factors such as the uncertainty in the observations their number and locations relative to the predictions of interest and the aquifer geological and hydrogeological parameters despite this some of the findings can be generalized and the proposed method applies to other cases 5 6 limitations of the model and future directions uncertainty in swi models is caused by factors such as tidal effects recharge variability geology solute dispersivity and anthropogenic influences this study aimed to quantify uncertainty in two main parameters that impact swi progression namely hydraulic conductivity and specific yield the results indicate high uncertainty in specific yield estimation due to limited head measurement data in fine grained soils further data collection of head measurements in fine grained soil or laboratory tests for coarse grained soil could reduce uncertainty uncertainty intervals and prediction distributions were estimated highlighting regions of high uncertainty but may be overestimated due to the small sample size zhang and shields 2018 in high dimensional and nonlinear models optimization algorithms can get stuck in local minima which reduces the efficacy of the nsmc method using multiple random initial parameters in the calibration process can help overcome this challenge another cause of efficacy reduction is fixing calibrated parameters in some cases which adds uncertainty to the prediction but reduces computational effort the nsmc method is preferred for its computational efficiency in highly parametrized swi models however it may not accurately represent bayesian posterior probabilities and may not accurately estimate uncertainty keating et al 2010 to improve accuracy in both model calibration and uncertainty analysis a high computational effort is needed in future studies the use of surrogate models can be considered as approximations to highly parametrized models reducing the computational effort one such surrogate model is gaussian process regression gpr which has been demonstrated to accurately capture swi behavior and estimate approximations and their uncertainty saad et al 2022 although gpr has been recently adapted to handle high dimensional problems its application to highly parametrized swi models has not yet been tested 6 conclusions a novel model independent framework was successfully developed to quantify the uncertainty associated with the estimation of model parameters and their propagation to the predictions of seawater intrusion swi in the wadi ham aquifer uae the parameter estimation process considered the aquifer heterogeneity in terms of horizontal hydraulic conductivity and specific yield using measurements of transient heads salinity concentrations and geophysical survey data along with prior knowledge of the geological formation to maximize the computational efficiency parameter estimation was conducted in two phases using constant and variable density models adequately identified parameters were considered fixed in the second phase the olhs was incorporated in the nsmc method and with the aid of the filtering technique an ensemble of constrained calibrated parameter sets was attained to derive the predictive probability distribution of swi length the following conclusions can be drawn from the findings of this research 1 data worth analysis provided a basis for the model calibration phasing and emphasized the importance of including salinity observations and geophysical surveys in the parameter estimation process to reduce predictive uncertainties despite their limited number compared to head observations this analysis is an essential prior step to the parameter estimation process 2 the transient heads only were able to identify some of the hydraulic conductivities in their proximity 9 when the salinity observations and the geophysical surveys were included the adequately identified parameters increased to 39 of the total parameters 3 for the specific yield the adequately identified parameters were found within the fine grained soil and near observation locations head observations contained more information to constrain them relative to salinity observations 4 the significant decrease in parameter and predictive uncertainty in any subregion of the model domain was strongly controlled by the density of the observations located within that subregion however constraining the specific yield using head data was more affected by the soil texture 5 the non redundant information contained in the calibration dataset constrained the highly identifiable parameters while the remaining parameters were more strongly constrained by prior knowledge reasonable a priori bounds were essential for obtaining acceptable parameter values in the geological context svd combined with tikhonov regularization helped to stabilize and constrain the inversion process to yield a plausible geological distribution 6 even though the uncertainties in the seawater intrusion length inferred from the geophysical surveys were considerably high nonredundant information was encapsulated in them on their removal the uncertainty in the salinity prediction increased geophysical observations are valuable for their wide spatial coverage and low cost 7 the space filling scheme of olhs based on ese optimization was more efficient in terms of probabilistic coverage compared to the srs scheme 8 the proposed filtering technique is a straightforward procedure to save computational time within the recalibration process and is favored over narrowing the possible parameter space intervals which may lead to the nsmc calibrated parameter sets being significantly constrained to the parameter set obtained through model calibration 40 of the generated parameter sets were omitted from the recalibration 9 a moderate correlation was observed between the parid which assumed model linearity and the reduction in the standard deviation of the prior parameter distribution to its posterior that was estimated considering model nonlinearity parid can give useful insights into the extracted information from the calibration dataset and reduce parameter uncertainty 10 the posterior predictive probability distribution determined the maximum and minimum predictions of the 5 isochlor position the resulting uncertainty intervals near kalba and fujyarh pumping fields varied by 4 5 and 11 from their means respectively which indicates with a high to moderate certainty that the aquifer would be vulnerable to salinization and the water quality at these pumping fields would be unsuitable for irrigation the framework presented in this study for probabilistic assessment of seawater intrusion swi due to input uncertainties has broad applicability beyond the site and model studied where it could be applied to other hydrological models improving predictions of water levels quantities and quality it can help identify data gaps and improve prediction certainty allowing for more accurate assessments of swi and the impact of management strategies on the aquifer system the resulting probability distribution can be used to estimate prediction intervals assess the reliability of management strategies and evaluate the probability of exceeding critical swi thresholds future research should address uncertain inputs beyond hydraulic conductivity and specific yield including boundary conditions such as sea level rise recharge variations and abstractions this is crucial for assessing future swi under climate change conditions integrating the proposed framework with simulation optimization based groundwater management models will help mitigate swi under uncertainty and propose a sustainable coastal management strategy in summary the highly parameterized regularized inversion allowed the extraction of information from the historical field measurements achieving reliable parameter estimates and a sufficient level of heterogeneity the nsmc method linked with olhs and filtering techniques was computationally efficient and succeeded in quantifying the prediction uncertainty of 5 isochlor intrusion length the framework proposed in this study can be generally applied in different coastal areas credit authorship contribution statement samia saad conceptualization methodology software formal analysis investigation validation resources visualization writing original draft writing review editing funding acquisition akbar a javadi supervision conceptualization writing review editing raziyeh farmani supervision writing review editing mohsen sherif writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the first author is funded by the ministry of higher education of the arab republic of egypt netwon mosharafa scholarship id nmm26 17 the authors would also like to express their gratitude to the dhi group for providing the free license of feflow data and information related to the wadi ham aquifer were provided by the national water and energy center united arab emirates university we would like to take this opportunity to thank the reviewers and the associate editor for their valuable comments that have certainly improved the quality of the paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129496 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1974,uncertainty in environmental modeling predictions stemming from parameter estimation is a crucial challenge that must be addressed to ensure effective decision making limited field measurements high computational costs and a lack of guidance in estimating measurement uncertainty further compound this challenge particularly for highly parameterized complex models in this study we propose a novel and computationally efficient framework for quantifying predictive uncertainty that can be applied to a range of environmental modeling contexts the novel components of the framework include efficient parameter space sampling using an optimized latin hypercube sampling strategy and applying the null space monte carlo method nsmc along with a developed filtering technique the nsmc generates sample sets to calibrate the model while exploring the null space this space contains parameter combinations that are not sufficiently supported by observations the filtering technique omits low potential parameter sets from undergoing model calibration the framework was tested on the seawater intrusion swi model of wadi ham aquifer in the united arab emirates uae to investigate aquifer sustainability in 2050 our results demonstrate the importance of incorporating direct and indirect measurements of heads salinity and geophysical survey data into the calibration dataset to reduce uncertainty in salinity predictions the extent of swi for multiple calibrated parameter sets varied by 4 5 to 11 relative to their means at two main pumping fields we conclude with a moderate to a high degree of certainty that swi is a serious threat to these fields and actions are needed to protect the aquifer from salinization additionally variations in swi length under different geological conditions illustrate regions of high uncertainty that require further data collection our framework effectively reduced and quantified prediction uncertainty and provides decision makers with critical information to inform risk management strategies keywords seawater intrusion parameter estimation data worth parameter identifiability optimized latin hypercube sampling uncertainty analysis data availability the authors do not have permission to share data 1 introduction groundwater is a vital source of freshwater for over two thirds of the world s population living in coastal regions singh 2014 however this resource is threatened by seawater intrusion swi werner et al 2013 to mitigate the negative impacts of swi numerical models are used to develop effective management strategies however these models are only as reliable as the input some data such as aquifer geometry hydraulic properties and boundary conditions are often uncertain due to a lack of field measurements aquifer heterogeneity regional flow systems and forecasted salinization drivers this uncertainty leads to uncertain predictions doherty 2016 making it imperative for stakeholders and decision makers to quantify the prediction uncertainty doherty and moore 2020 in order to make informed decisions to address this issue predictive uncertainty analysis is required to characterize the potential variability in a prediction model output through the identification of multiple parameter sets input variables that can be used by the model dausman et al 2010 table 1 summarizes the main methods for quantifying the prediction uncertainty in swi the three methods for predictive uncertainty analysis include monte carlo simulations conditional monte carlo simulations and linear uncertainty analysis monte carlo simulations method which has been used in both conceptual e g ketabchi and jahangir 2021 rajabi and ataie ashtiani 2014 zhao et al 2016 and real world studies e g miao et al 2019 mostafaei avandari and ketabchi 2020 it repeatedly runs the model with different sets of parameters to generate multiple realizations of the model output the conditional monte carlo simulations method on the other hand conditions the input variables to observed data the approach has two perspectives the first perspective considers the non uniqueness of the parameter sets through the model calibration in a stochastic inverse modeling framework such as markov chain monte carlo mcmc rajabi and ataie ashtiani 2016 zeng et al 2016 self calibrating pool et al 2015 gradual conditioning llopis albert et al 2016 and iterative ensemble smoother ies hugman and doherty 2022 methods the second perspective seeks uniqueness by implementing regularization to incorporate prior information on parameters within model calibration depending on the inferred single calibrated parameter set the null space monte carlo nsmc tonkin and doherty 2009 method generates multiple realizations to estimate the prediction uncertainty e g herckenrath et al 2011 linear uncertainty analysis assumes linear model behavior and represents the relationship between parameters and predictions with a matrix that is independent of parameter values e g coulon et al 2021 table 1 also highlights two other key features the considered number of uncertain parameters and the adopted ways to alleviate the computational burden associated with the prediction uncertainty analysis although most of the previous investigations have limited the model parameters to a small number ketabchi and jahangir 2021 miao et al 2019 mostafaei avandari and ketabchi 2020 pool et al 2015 rajabi and ataie ashtiani 2014 rajabi and ataie ashtiani 2016 yang et al 2021 zhao et al 2016 to reduce the computational cost rajabi et al 2018 highly parameterized models are necessary to reduce predictive uncertainty by incorporating parameters that are salient to the model predictions doherty and moore 2021 and to recognize the small scale variability of the hydraulic property that greatly influences the hydrodynamic process for instance the degree of the aquifer heterogeneity has a considerable effect on the swi wedge length and seawater volume ketabchi and jahangir 2021 among the methods used nsmc and ies can reduce the computational burden and handle nonlinear highly parameterized models despite the computational efficiency of ies its success is highly dependent on the quality and size of the ensemble of realizations that are sampled from the prior parameter distributions thus its prior parameter distribution needs special considerations delottier et al 2022 additionally for highly non linear problems the ensemble based method may produce instability and run failures omagbon et al 2021 previous studies have shown the effectiveness of the nsmc method in a highly parameterized swi model and its efficiency in reducing the computational burden keating et al 2010 compared the performance of the nsmc method to the mcmc a statistically rigorous and computationally demanding method in terms of model calibration estimating parameters and prediction uncertainties on a high dimensional parameter estimation groundwater problem the outcomes had a high degree of similarity however nsmc obtained the results with much less computational time herckenrath et al 2011 proved the efficiency of the nsmc method in quantifying the uncertainty in the prediction of the location of the swi interface due to the inflow reduction using a synthetic swi model based on henry problem safi et al 2019 designed a monitoring network in beirut aquifer lebanon to capture the swi behavior through the optimization of the best potential locations of the observation wells to reduce the uncertainty in the prediction of the interface location using the realizations generated by nsmc method however further improvement in computational efficiency is needed three promising ways are found in the literature to address this issue table1 including 1 parallelization and grid computing e g mostafaei avandari and ketabchi 2020 2 efficient sampling strategies that decrease the required number of simulation runs to obtain a stable statistical mean and variance for the prediction probability distribution janssen 2013 with an acceptable accuracy e g rajabi and ataie ashtiani 2016 zhao et al 2016 and 3 development of a surrogate model to act as a simplification to the complex model lower fidelity models were used in highly parameterized models burrows and doherty 2015 hugman and doherty 2022 although data driven surrogate models have been used to handle models with a limited number of parameters e g miao et al 2019 rajabi and ataie ashtiani 2014 they have limitations for highly parameterized models where the number of samples required to capture the behavior grows prohibitively fast with the number of parameters asher et al 2015 and can increase prediction uncertainty especially for large scale and complex models mostafaei avandari and ketabchi 2020 decreasing the unnecessary simulation runs in monte carlo based methods via implementing more efficient sampling strategies that combine the innovative space filling criteria and optimization schemes is not widely used in the literature rajabi et al 2015 despite its popularity in limiting the required number of evaluation points to represent the design space wang et al 2020 while simple random sampling srs is the standard method e g herckenrath et al 2011 pool et al 2015 it does not ensure space filling which means that one element may be chosen more than once conversely latin hypercube sampling lhs approach mckay et al 1979 divides the range of each input variable into equally probable intervals the number of which is equal to the sample size within each interval a random sample is selected for each variable then the drawn samples are paired with each other randomly therefore lhs requires a smaller sample size than srs for space filling applying space filling optimality criterion to lhs will i enhance its performance especially in large dimensions ii ensure the filling of the input space properly avoiding close points damblin et al 2013 and iii minimize the number of the monte carlo simulation runs to reach the target accuracy janssen 2013 rajabi and ataie ashtiani 2014 showed that using optimized latin hypercube sampling olhs based on the enhanced stochastic evolutionary ese optimization and employing the uniformity criterion was the most efficient approach in terms of the consumed time for monte carlo simulations this was concluded based on a comparison of this strategy to srs lhs and eight other olhs strategies differ in the optimization method and or the space filling criterion on two test cases involving swi models mostafaei avandari and ketabchi 2020 employed olhs based on ese optimization and the uniformity criterion in monte carlo simulations to study the uncertainty in permeability and assess its impact on swi of ajabshir coastal aquifer iran uncertainty quantification is critical for accurately predicting seawater intrusion swi in coastal aquifers but often hindered herrera et al 2022 by the limitations of traditional methods particularly in terms of computational efficiency a critical research gap in previous studies table 1 that needs to be explored is how to efficiently quantify uncertainty in highly parameterized strongly nonlinear swi models caused by uncertain aquifer parameters this study presents a novel and efficient framework for quantifying uncertainty in swi prediction by combining the benefits of the optimized latin hypercube sampling olhs and null space monte carlo nsmc methods the framework is applied to the coastal aquifer of wadi ham in uae which is facing severe swi due to over exploitation to the best of the authors knowledge this study is the first to consider the combined advantages of olhs and nsmc for efficient uncertainty quantification in highly parameterized nonlinear swi models particularly in heterogeneous coastal aquifers the proposed framework includes i calibrating a highly parameterized model using regularized inversion ii defining the calibration solution space using matrix decomposition techniques iii sampling the parameter space efficiently using olhs iv applying the nsmc method to generate parameter sets with the same calibration space v filtering less likely parameter sets from the recalibration using a proposed rejection sampling algorithm vi generating posterior parameter and predictive probability distributions using the ensemble of the calibration constrained parameter sets this study provides a further improvement in computational efficiency for the nsmc method and makes a valuable contribution to the field by providing a practical and computationally efficient framework for quantifying uncertainty in swi prediction 2 methodology a six step general framework has been developed to quantify the prediction uncertainty a flowchart showing the overall methodology is presented in fig 1 each step is described below 2 1 step 1 uncertainties of the calibration dataset the uncertainty values reflect the noise in the measurements their values are assigned based on the used equipment to collect the data expert knowledge and or from other studies with similar site conditions the sources of the uncertainty in the calibration dataset of groundwater head and salinity concentration at each observation well and the earth resistivity imaging data were estimated as follows 2 1 1 groundwater head observations the piezometric heads were collected as the measured depths to the water table at the observation wells data were extracted from available sources as discussed in section 3 the depths were taken manually using a calibrated measuring tape while satellite mapping was used to identify the elevation of the top of each well casing this was done to obtain the head of the fluid within each well with the obtained heads being related to the actual fluid density to compare with simulated heads a conversion to equivalent freshwater heads was carried out using eq 1 1 h f ρ ρ 0 h α z 2 α ρ ρ 0 ρ 0 where h f is piezometric head of the equivalent freshwater head m which is given by h f p ρ 0 g z p is the fluid pressure n m2 h is the measured head m α is the density ratio ρ ρ 0 are the actual fluid density and freshwater density respectively kg m3 z is the elevation at the midpoint of the screen length inside the observation well m the datum of the hydraulic heads is the mean sea level the total uncertainty of the equivalent freshwater heads was calculated eq 3 based on eq 1 assuming that ρ 0 is constant and the errors in the measurements are random and uncorrelated post et al 2018 3 σ h ρ ρ f h σ ρ ρ 2 σ h measured h 2 2 α z σ ρ ρ ρ 0 2 σ z z 2 2 σ pump 2 where the first and second terms represent the uncertainties propagated from the first and second terms of eq 1 and the third term considers the modeled to measured misfit at the observation well which is near a pumping field symbols used in eq 3 are defined in table 2 2 1 2 salinity concentration observations the measured electrical conductivity for the water samples collected from the observation wells was converted to salinity concentration data the uncertainty associated with the measurements is shown in table 2 2 1 3 earth resistivity tomography ert data the average length of swi was estimated from ert transects data measured from the coastline to the start of the freshwater zone total dissolved solids of 1000 mg l and was used to constrain the coupled flow and transport model as indirect observations for the salinity distribution the uncertainty associated with the ert intrusion length σ ert observations is presented in table 2 a custom python script was used to include the indirect observation of the intrusion length in fepest during the parameter estimation fepest links pest and feflow diersch 2013 pest is a model independent non linear parameter estimation software doherty 2016 feflow solves the system of partial differential equations for groundwater flow and for variable density flow coupled with the mass transport equation table 2 shows the standard deviation values for the above mentioned sources of uncertainty associated with the field measurements the measurement noise is assumed to show no spatial or temporal correlation and is characterized by a multigaussian distribution this distribution is defined by mean function observed values of the calibration dataset and covariance function diagonal elements of the covariance matrix are the weights assigned to the various field measurements and are the inverse of the standard deviation values since the calibration dataset which included observations of heads salinity and ert survey data was used in the parameter estimation problem a multi component objective function resulted eq 4 due to the wide range of values in the heads and concentration measurements they were partitioned internally with each hydrograph or salinity concentration forming a separate group that represented a component to filter out structural noise in groundwater models a strategy proposed by doherty and welter 2010 was adopted the model to measurement misfit is dominated by structural noise doherty and welter 2010 the strategy gives equal recognition to each component in the objective function by assigning different weights to each group the weights were estimated as the squared inverse of the standard deviation 1 s t d e v 2 table 2 multiplied by a coefficient that differed between groups to ensure equality 2 2 step 2 data worth assessment a prior step to the parameter estimation is to evaluate the worth of the information in the calibration dataset to reduce the prediction uncertainty to examine the worthiness of the data each observation group from the calibration dataset was removed successively and the incurred increase in the uncertainty of the predictions was calculated doherty et al 2011 the data worth was assessed using linear uncertainty analysis first order second moment based analysis as an approximate and low computational cost analysis tool detailed descriptions of the used equations and their derivations can be found in dausman et al 2010 the assessment of the data worth of each observation group in all observation types was done by processing pest files and implementing them in python using the pyemu python framework for environmental modeling uncertainty analyses library white et al 2016 2 3 step 3 model calibration using regularized pilot points method the mass transport process in the saltwater wedge is influenced by heterogeneities in the aquifer leading to preferential flow pathways and spatial variations in transport velocity to account for small scale variability the pilot point method was used by distributing predefined points in the model domain on a pseudo regular grid with a minimum of five points per correlation range alcolea et al 2006 the parameters were estimated at these points and then spatially interpolated using a selected geostatistical model variogram function to obtain aquifer properties at all model elements the pilot point method was then incorporated with tikhonov regularization to penalize the model parameters deviation from their prior estimates only to an extent that provided an acceptable fit to field measurements doherty 2016 these prior estimates were derived from pumping test results prior geological knowledge and previous studies the regularized inversion i e model calibration attempted to minimize the global objective function φ doherty 2016 which was defined as 4 φ φ m μ φ r 5 φ m c x p t q m c x p 6 φ r d r p t q r d r p where φ m is the measurement objective function φ r is the regularization objective function c is the vector of the measurement observations p is the vector of the parameters requiring estimation x is the calibration sensitivity matrix jacobian matrix of size m n where m and n are the numbers of field observations used in the calibration dataset and the model parameters respectively each element of the matrix expresses the sensitivity of each model output corresponding to the field observations to each parameter q m is the matrix of the weights assigned to the different observations it represents the noise associated with the measurements and induced by model imperfection structural noise q r is the inverse of the pilot point covariance matrix whose elements were calculated based on the selected geostatistical model t denotes the transpose operation d is the vector of the regularization observations which expresses a preferred condition r is the matrix that encapsulates the regularization equations it represents constraints on parameter values in the present study r is the identity matrix for preferred values constraints μ is the tikhonov regularization parameter model calibration was conducted using fepest beopest was used to achieve further computational efficiency by running a model simultaneously on different cores of the same computer the sensitivity matrix was filled based on finite differences with a 1 5 parameter perturbation the tikhonov regularization parameter μ was calculated in every optimization iteration during the inversion process by pest to achieve a target level of model to measurement fit pest viewed the problem as a constrained optimization problem where the objective was to minimize φ r subject to the constraint that φ m should be less than the maximum acceptable misfit between model outputs and the field data truncated singular value decomposition svd and tikhonov regularization were combined using hybrid regularization to address their weaknesses and benefit from their strengths tonkin and doherty 2005 svd separated inestimable parameter combinations zero and low singular values residing them in the calibration null space and created a super parameter set of estimable parameters residing them in the calibration solution space this reduced dimensionality stabilized the inversion process and reduced computation time the model calibration performance was evaluated using statistical indices including root mean square error rmse coefficient of determination rsq and the nash sutcliffe model efficiency nse these indices provided measures of the difference similarity and fit between the observed and simulated datasets respectively 2 4 step 4 parameter identifiability to reduce the computational time the parameter estimation was performed in two phases in phase 1 head data were used and in phase 2 the salinity concentrations and geophysics survey data were used in phase 1 the parameters which had a high identifiability value parid greater than 0 75 were identified as adequately estimated by considering these parameter values as fixed parameters in the next phase a reduction in the computational burden was achieved the parameter identifiability parid was estimated to provide insight into how much information was extracted from the observations to inform the model parameters during the calibration using eq 7 doherty and hunt 2009 parid has a moderate computational burden considers the parameter correlation and approximates the relationship between the model outputs and the parameters as linear doherty et al 2010 parid value varies between zero and 1 zero indicates completely non identified parameters and one indicates that they lie in the calibration solution space and are fully identified the weighted sensitivity matrix q m 1 2 x was computed based on calibrated parameter values and the inverse of the measurements noise it was subjected to svd employing genlinpred utility doherty 2016 svd divides the parameter space into solution subspace v1 and null subspace v2 the threshold of truncation between the solution and null subspaces was calculated using the supcalc utility doherty 2016 the identifiability of a parameter is calculated as the sum of the squared components of all the eigenvectors spanning the solution subspace v1 corresponding to that parameter as follows 7 p a r i d v 1 2 2 5 step 5 model validation the calibrated parameter set was assigned a different observation dataset than that used in model calibration was considered for the validation the performance of the model validation was evaluated using the above mentioned statistical indices of rmse rsq and nse 2 6 step 6 prediction uncertainty analysis the nsmc method developed by tonkin and doherty 2009 was used for prediction uncertainty analysis a brief description of the method s steps is presented in the supplementary material s a the method is based on generating random fields p from the prior parameter probability distributions using a stochastic parameter generator srs is commonly used however in this study optimized latin hypercube sampling olhs was used to improve the sampling efficiency the difference between the stochastic parameters p and the calibrated parameters p was projected onto the calibration null space v2 the projected difference field was then added to the calibrated parameters the new set of parameters p new did not produce exactly the calibrated parameter set due to model nonlinearity and the considered truncation threshold between the solution and null subspaces the model was then executed using p new and re calibrated if the mismatch exceeded an acceptable level the existing sensitivities estimated using the calibrated parameter set were used in the first optimization iteration to save computational time if additional iterations were required for the recalibration the sensitivities were recalculated based on the newly obtained parameter set the objective function threshold was considered 10 higher than the achieved objective function during the calibration in the present work a maximum of two iterations were conducted for each realization the prediction uncertainty was assessed using the resulting parameter sets after the recalibration a flowchart of the nsmc method is shown in fig 1 drawing samples from a prior parameter probability distribution which is too wide may lead to few potential parameter sets that can be accepted while reducing the span of the prior parameter space can sacrifice the integrity of the process doherty et al 2011 in this study a straightforward filtering technique was proposed to screen out from recalibration the parameter sets that were less likely to reach the acceptable objective function in the second iteration without reducing the parameter space a flow chart for the filtering process is presented in fig 2 the details are described below 1 the achieved objective functions of the parameter sets that need to undertake additional iterations after the first iteration are sorted in descending order to form a ranked list 2 the second iteration is carried out first using the parameter set that corresponded to the objective function in the middle of the list in this way the whole list is split into upper and lower lists 3 after the second iteration if the achieved objective function is acceptable step 2 is repeated using the parameter set which was associated with the objective function in the middle of the upper list otherwise this parameter set and the others associated with higher objective functions are excluded from the list step 2 is repeated using the parameter set in the middle of the lower list and so on this procedure is stopped when reaching the top of the list which had undergone the second iteration and succeeded in satisfying the threshold objective function 4 the second iteration is performed on all the remaining parameter sets step 6 is divided into six substeps fig 1 further descriptions of substeps 6 iii and 6 vii are shown as follows 2 7 optimized latin hypercube sampling step 6 iii the efficiency of monte carlo methods is highly dependent on the space filling characteristics of the sampling strategy janssen 2013 rajabi and ataie ashtiani 2014 latin hypercube sampling aims to ensure that each of the input variables has its range well scanned based on a probability distribution the quality of filling can be further improved by optimizing the distribution of the sample points the selected space filling criterion was a point distance criterion φp criterion which controlled the distance between the design points themselves or the input domain and the points damblin et al 2013 in order to optimize the selected criterion the enhanced stochastic evolutionary ese technique was employed φ p criterion was proposed by morris and mitchell 1995 and is calculated as follows 8 φ p i 1 s j i d i p 1 p by sorting all the inter sited distances d ij 1 i j n i j for a given lhs design a distance list d 1 d 2 d s and an index list j 1 j 2 j s are obtained d ij is the euclidean distance between two sample points i j n is the number of sample points each sample point represents the parameters vector d i represents the distinct distance value the elements in the distance list are sorted in ascending order d 1 d s j i represents the number of pairs of sites separated by d i in the design and s is the number of the distinct distance values p was taken as 10 the enhanced stochastic evolutionary ese algorithm was used to generate an lhs design satisfying the φ p criterion the method began with an initial design and tried to find better designs by iteratively changing the current design the method consisted of an inner loop and an outer loop in the inner loop the new designs were explored while the outer loop controlled the acceptance of the new design using a threshold based acceptance criterion the acceptance criterion was as follows 9 δ f t h r a n d o m 0 1 where δ f is the amount of improvement made by the new design compared to the current design r a n d o m 0 1 is a function that generates uniform random numbers between 0 and 1 and t h is the threshold the threshold value was controlled by the outer loop in such a way that if the improvement made in the inner loop was less than a certain level the threshold value was first increased sharply to initiate the exploration process avoid local optimum and then decreased slowly to discover better designs on the other hand if the improvement made was above a certain level the improvement process was initiated attempting to find a local optimum quickly detailed descriptions of the ese algorithm can be found in jin et al 2005 the parameters of the algorithm were assigned with the values suggested in jin et al 2005 the olhs was implemented in smt surrogate modeling toolbox an open source python package bouhlel et al 2019 the run batch file in the pest software suite was edited to read the sample sets generated by olhs and to implement the nsmc method doherty 2016 2 8 generation of posterior parameter uncertainty step 6 vii after recalibration an ensemble of the calibration constrained parameter sets was obtained the values of each parameter were used to determine the best fit probability distribution pd that this data followed after selecting the pd its distribution parameters mean and standard deviation were estimated consequently the posterior pd of each parameter was defined the magnitude of the distribution parameters was used to 1 assess the degree to which the posterior pd became narrower than its prior pd and 2 provide some evidence on characterizing the parameter and predictive uncertainty despite the sample size number of calibrated parameter sets being generally small to derive a true posterior parameter pd sampling the true posterior parameter pd in the context of highly parameterized nonlinear and underdetermined inverse problems is not guaranteed even by using full bayesian approaches and generating thousands of parameter sets keating et al 2010 bayesian approaches formulate the parameter estimation problem in a probabilistic framework considering model inputs and outputs as random variables and including prior information and regularization terms in the inference process rajabi et al 2018 the anderson darling hypothesis test was used to select the best fit pd the test compared the fit of the cumulative distribution function of the observed data to the expected cumulative distribution function ten probability distributions normal lognormal exponential 2 parameter exponential weibull gumbel maximum gumbel minimum gamma logistic and loglogistic were tested as the expected distributions the distribution test that had p values less than 0 005 indicated that it was statistically significant to reject the null hypothesis the null hypothesis stated that the observed data followed this hypothesized distribution among the distributions that had strong evidence to be retained the distribution of the highest p value was chosen to be the best fit distribution minitab statistical package was used to perform the distribution tests arend 1993 3 application of the proposed framework to a real world case study 3 1 study site and numerical modeling wadi ham aquifer a coastal aquifer in an arid region is located in the northeastern part of the uae limited surface water resources the prevalence of drought conditions for successive years and excessive abstractions have placed tremendous pressure on the aquifer and have resulted in severe seawater intrusion problems sherif et al 2014 sowe et al 2020 the total area of the aquifer system is 61 km2 to simulate the groundwater flow and solute transport in the wadi ham aquifer feflow diersch 2013 was employed the set of governing equations and boundary conditions of density dependent fluid flow and solute transport in soils is briefly presented in supplementary material s b2 table 3 shows the considered hydraulic and transport parameters hydrogeological and geological information and the aquifer model discretization details table 4 presents the values of the imposed flow and transport boundary conditions in the simulation model the 3d view of the coastal aquifer model showing the assigned initial and boundary conditions is presented in fig 3 b c 3 2 available observation dataset and estimation of parameters using regularized pilot points method the available data include transient heads salinity concentrations and geophysical survey data table 5 presents the available observation dataset for model calibration and validation following the data worth assessment a decision was taken to conduct the model calibration in two phases will be discussed in section 4 1 december 1988 to september 1994 using hydraulic head values with a single fluid constant density model and october 1994 to march 2005 using salinity concentration and intrusion length estimated from ert survey data a coupled flow and solute transport model was used in phase 2 the final parameter set was from phase 2 and adequately estimated parameters with parid 0 75 from phase 1 their values in the second phase of calibration were fixed the model was validated from october 1994 to april 2005 against the hydraulic heads computational time for one run was 10 and 27 min for phases 1 and 2 respectively on a desktop pc with 3 4 ghz intel r xeon r cpu and 192 gb ram using 10 cores via beopest the target objective functions for phase 1 and phase 2 were estimated to be 18 236 and 197 respectively using the assigned weights described in the supplementary materials s c3 which consider measurement uncertainty and ensure equal visibility for each observation group and eq 10 10 targetobjectivefunction i 1 n i 1 m s t d e v assigned w e i g h t 2 where stdev is the uncertainty in measurements listed in table 2 n is the number of the observation groups and m is the number of readings per group the standard deviation of the head measurements noise varies slightly between different readings of the same observation group average values were considered while a global standard deviation for the salinity concentration measurements at the observation well was used σ sal σ s a l s a m p l e s 2 σ s a l r a s t e r 2 since the salinity observation group consisted of readings from two different sources the pilot points method was used to describe the spatial characterization of the hydrogeological properties horizontal hydraulic conductivity khz and the specific yield sy table 5 in order to generate spatially correlated fields for them geostatistical models were initially fitted to the measurement data for both hydraulic conductivity and specific yield prior information the geostatistical parameters sill and range were optimized so that the interpolated field minimized the misfit between the model outputs and the observation measurements residuals the ordinary kriging interpolation method was used to obtain the parameters values table 5 shows the selected geostatistical models and their initial parameters the regularization constraints which were imposed on the parameters were the preferred values deduced from the prior information the singular value truncation threshold was at a singular value that exhibited the ratio between the lowest to the highest eigenvalue of greater than 1 0 10 6 the mean and the standard deviation describing the prior parameter distributions are listed in table 5 fig 4 displays the mean of the prior parameter distributions at the pilot point locations as interpolated fields 3 3 future prediction of seawater intrusion the model predictive uncertainty was quantified for the average seawater intrusion length l5 the length is measured from the coastline to the 5 isochlor the contour line of 2000 mg l at the quaternary aquifer bottom along the aquifer width the 5 ischlor was selected as the upper acceptable salinity limit for irrigation according to the food and agriculture organization of the united nations ayers et al 1985 the nsmc method was applied to the swi model from december 1988 to september 1994 using the transient hydraulic heads from 1988 to 1994 and the salinity concentrations measurements in 1994 to construct the calibration dataset the objective function was estimated at 2455 considering the achieved residuals using the obtained calibrated parameter set and the assigned weights for each observation group 1 s t d e v table 2 however for equal visibility for each observation group salinity weights were multiplied by 20 since the magnitudes of salinity and hydraulic heads were vastly different a threshold of 2700 was set for the target objective function prior parameters probability distributions were centered on the calibrated set with standard deviation bounds and type as listed in table 5 250 stochastic parameter sets were generated the samples in the olhs design were drawn from a uniform distribution on 0 1 and then mapped onto the prior distributions respecting the assigned parameters bounds the chosen number of generated parameter sets was based on computation time and is comparable to other studies pollicino et al 2021 rajabi et al 2015 the ensemble was used to estimate the uncertainty range in l5 prediction for 2050 current abstraction was assumed to persist due to groundwater deterioration and terminated pumping wells sowe et al 2020 recharge and storage depth at the dam site followed the same trend while inflow across the boundaries was maintained constant over the prediction period 4 results 4 1 data worth analysis the data worth analysis was performed on the period of 1988 to 1994 considering prior information on parameter values the observations data of transient heads from 1988 to 1994 546 monthly head measurements salinity measurements in 1994 11 salinity observations and the length of intrusion retrieved from ert survey data fig 5 shows the results of this assessment for salinity concentration prediction at 121 uniformly distributed points the maximum percentage of increase in the prediction uncertainty variance which was incurred by successive removal of each observation group was contoured fig 5a the analysis showed that despite the small number of salinity observations they had high information content the predictive uncertainty of 56 points was increased by the maximum compared to the removal of the other observation types affecting the prediction uncertainty the most in the eastern part of the aquifer near the coast the hydraulic head observations had a greater impact on reducing the uncertainty in salinity predictions upstream of the seawater wedge generally across the aquifer domain the uncertainty in the prediction increased the most near the observation points that were omitted except near the salinity observations at s15 s16 and s20 and head observations at bhf9a bhf4 and bhf17 thus they did not have information that was relevant to the prediction and or not repeated in other groups it is evident that even though the concentration observations are scarce it is worth including them in the calibration dataset this requires combining groundwater equations with salt transport equations by using the variable density flow and solute transport models the low values of scaled rmse rmse divided by the range in the simulated heads between the simulated hydraulic heads using constant density and variable density models ranged from 0 86 to 6 4 for all the observation wells this suggests that the groundwater flow model could be used in phase 1 for parameter estimation benefitting from its fast run time with the consideration of the variable density effect in phase 2 using the salinity concentration and ert survey data the standard deviation of the post calibration predictive uncertainty was reduced compared to its pre calibration uncertainty fig 5b c however the salinity prediction uncertainty was still high indicating the need for acquiring more complementary data 4 2 parameter identifiability of the hydrogeological parameters at different phases the ability of the calibration dataset to constrain the model parameters in phases 1 and 2 was expressed by the parameter identifiability parid out of 242 parameters 86 were adequately identified with a parid cut off value of 0 75 38 were adequately identified in phase 1 and assumed fixed and an additional 48 were adequately identified in phase 2 fig 6 shows the parid of 121 pilot points used to estimate hydraulic conductivity and specific yield in phases 1 and 2 the transient heads in phase 1 constrained the hydraulic conductivity at the pilot points close to the observation measurements with higher identifiability 9 out of 121 pilot points were considered adequately identified the specific yield parameters are more influenced by soil texture in fine sediments of the western part 29 out of 121 pilot points were considered adequately identified in phase 1 however in coarser sediments east the hydraulic heads in the calibration dataset could not identify specific yield in phase 1 the salinity observations and ert survey data significantly increased the number of identified hydraulic conductivities to 47 38 in phase 2 and 9 in phase 1 the specific yield was less constrained by salinity observations with a slight increase of 10 parameters resulting in 39 adequately identified parameters in total 29 in phase 1 and 10 in phase 2 4 3 model calibration and validation the model performance was evaluated using the calibrated parameter dataset after the model calibration the goodness of fit of the transient head and salinity measurements evaluated using rmse nsh and rsq showed overall satisfactory results for the model calibration and validation the error statistics of the model calibration and validation are shown in fig 7 and table 6 the mismatch of all the simulated heads and salinity concentrations represented by rmse was located within the estimated 95 confidence interval ci of the measurements except for two observations wells bhf1 under the validation and bhf15 under the calibration and validation a high correlation was identified between the observed and simulated measurements at different observation groups 0 7 indicating a significant and positive relationship however for bhf10 the correlation value was 0 12 indicating no similarity in the pattern of variation between the two datasets considering nse coefficients a value of 1 corresponds to a perfect match values between 0 and 1 are viewed as acceptable performance while negative values represent unacceptable performance good model performance can be seen the lower values approaching zero were reported in the salinity measurements this is due to the small number of measurements 2 measurements in each observation group approaching zero means that the average value of the observed dataset is better than the predictions simulated by the model the performance criteria proved that the extracted information from the calibration datasets and the additional information in the form of the prior information imposed on the parameters were able to efficiently constrain the parameters to achieve an acceptable reproduction for the observations the estimated parameter values for the horizontal hydraulic conductivity and the specific yield are presented in fig 4 together with their initial values estimated from the site data the heterogeneity in the hydraulic conductivity was captured and the values were reliable with small departures from their initial values the values of the specific yield varied from their initial values which was expected due to the high uncertainty in their estimates 4 4 analysis of posterior parameter uncertainty the nsmc method was combined with the olhs and filtering rejection sampling techniques to perform a two step re calibration of the swi model the first iteration was performed after generating 250 stochastic parameter sets with 31 sets having an objective function value below the threshold of 2700 these 31 sets were added to the ensemble of calibration constrained parameter sets and 120 sets passed the filtering process to proceed to the second iteration the second iteration resulted in 78 parameter sets that satisfied the objective function threshold bringing the total number of well calibrated parameter sets to 110 1 calibrated set and 31 and 78 sets from the first and second iterations respectively the average value of the multi component objective function for these 110 sets was reduced from 27 000 to 2560 demonstrating the effectiveness of the proposed method a calculated objective function higher than 50 000 was found to be unsatisfactory and was discarded the probabilistic coverage of input space of each parameter provided by olhs strategy was calculated using eq 11 and compared to that generated by srs strategy the probabilistic coverage can be used as guidance hardyanto and merkel 2007 to choose which strategy is preferable eq 11 was used to calculate the probabilistic coverage for each strategy and considered each parameter as a lognormal distributed independent variable the mean and standard deviation were calculated from drawn samples of size 250 11 p l x i x i u x i in eq 11 l x i and u x i are the minimum and maximum values for each parameter xi the probabilistic coverage for each parameter generated by the olhs strategy was approximately 92 and ranged from 71 to 91 for the srs strategy olhs strategy provided better probabilistic coverage compared to the srs strategy the application of the nsmc method resulted in an ensemble of calibration constrained parameter sets obtained by exploring the null space where the parameters were not well constrained by observations and adjusting the solution space parameters the results indicate that the method was effective in constraining the parameters of khz and sy in regions near observation measurements with a reduced ability to constrain in coarse sediments for sy the posterior parameter values were found to be significantly different from their prior values generated by olhs particularly in specific regions near the southeast boundary and northwestern part of the aquifer the highest hydraulic conductivity values were observed near the southeast boundary ranging from 167 to 209 m day while lower values were found in the northwestern part ranging from 10 to 48 m day near the shaarah pumping field which represented fine grained soil the inversion process also constrained a small number of sy parameters near observation measurements in fine grained soil but with reduced ability to constraint in coarse sediments away from the regions with constrained parameters the parameters were allowed to take different values in order to achieve an acceptable level of misfit these results emphasize the significance of defining the null space for the integrity of the prediction uncertainty analysis and considering both prior knowledge and observation data in the parameter calibration process the findings are presented in fig 8 with five randomly selected posterior realizations assumed to represent samples drawn from the posterior parameter distribution the values taken by each parameter in the 110 calibration constrained parameter sets were used to identify the probability distribution pd that this data followed the posterior parameter pd of the logarithm of the hydraulic conductivity was found to fit a normal distribution with an average p value of 0 05 considering 121 pilot points while the specific yield was fitted best by the gumbel maximum probability distribution with an average value of 0 082 the maximum likelihood estimates of the parameters describing each distribution location and scale are equivalent to the mean μ and the standard deviation σ of the parameter variability were calculated and the coefficient of variation cv was utilized to represent the posterior variance of the parameters the cv was calculated for lognormal and gumbel maximum distributions using eq 12 and 13 respectively 12 c v logmormal e σ 2 1 13 c v gumbelmaximum σ μ 0 5772 σ 6 π fig 9 depicts the posterior mean and cv of the khz and specific yield the mean posterior conductivity values fig 9a c agreed well with the results of the pumping tests and the aquifer geology fig 4 the cv of the logarithm of the conductivity field ranged from 7 to 76 fig 9b while its prior cv was 112 a lower dispersion around the mean was shown near the observation data but higher uncertainty near the southern boundary and the uncertainty due to the lack of available observations for the specific yield parameters the parameter estimation reduced the prior cv from an average of 315 to 85 the area of higher certainty was found near the observation data within the fine grained soil of the western part of the aquifer the mean of the specific yield posterior pd at each pilot point was significantly different than its value in the parameter set of the minimum error variance obtained by the model calibration this was due to the large prior uncertainty considered to account for the lack of data the prior parameter pd at 242 pilot points describing the logarithm of khz and sy was assumed normal distribution and their distribution parameters are shown in table 5 the correlation between the identifiability parid and the reduction in the standard deviation of the probability distribution σ red was calculated to investigate the extent to which the parameter identifiability is valid for nonlinear model behavior it was found to be moderate and negative with correlation coefficients of 0 56 for khz and 0 68 for sy the identifiability and the reduction in standard deviation are approximately consistent fig 10 demonstrates the reduction in uncertainty for 8 parameters from different identifiability categories 0 0 25 0 25 0 5 0 5 0 75 and 0 75 1 the reduction in uncertainty is visualized by comparing the height of the posterior and prior distributions at the median the ratio between posterior and prior values indicates the amount of additional knowledge gained from the inversion the results showed that the identifiability and the reduction in standard deviation are approximately consistent 4 5 quantifying the risk of seawater intrusion at pumping fields the 110 calibration constrained parameter sets were used to delineate the uncertainty range in the prediction of l5 2000 mg l isoline for the year 2050 the dispersion of the posterior prediction distributions was quantified with values less than 10 representing high certainty and values between 10 and 20 representing moderate certainty high certainty was found near kalba pumping field σ μ 4 5 while moderate certainty was found near fujyarh pumping field σ μ 11 fig 11 a the wider distribution is the direct outcome of the ill informed parameters by the measurements of the system state as depicted in fig 9 the posterior predictive uncertainty distributions of the intrusion length measured from the coastline at the two pumping fields are shown in fig 11 b c the 95 percentiles of the two distributions showed that it was possible to advance the l5 to the centers of the two pumping fields however the maximum prediction of l5 completely encompassed the kalba pumping field and reached a portion of the fujayrah field leading to salinity levels exceeding the acceptable limit for irrigation purposes 5 discussion 5 1 data worth and their impact on prediction uncertainty the useful feature of analyzing the data worth of the observation data following the method described by dausman et al 2010 is that the predictive uncertainty is independent of the actual values of both the measurements in the calibration dataset and the model parameters however it depends on the stochastic characterization of parameter variability measurement noise and model output sensitivity to parameters accordingly the worthiness of ert survey data was assessed although the data were not available during the analysis period the findings highlight the importance of including salinity observations in the calibration dataset to better constrain the predictions which is consistent with refsgaard et al 2012 they argued that the salinity predictions made by a constant density model are associated with high uncertainty as the predictions are not constrained by the calibration dataset the hydraulic head observations had a greater impact on reducing the uncertainty upstream of the seawater wedge where freshwater inflows hald stream and wadi ham stream and the infiltration from the dam reservoir mainly governed the salinity the uncertainty in the salinity predictions increased by losing these data by an average of 70 on the other hand in the region near the coast enclosed by the contour line of 5000 mg l fig 5a the salinity observation data had the higher influence where the effect of freshwater inflow from the western part of the aquifer decreased and the effect of the inland lateral flow from the sea increased the post calibration uncertainty was reduced indicating the effectiveness of the available information however the salinity prediction uncertainty was still high in the eastern part of the aquifer with an average value of 1000 mg l and exceeding 8000 mg l near hyal stream suggesting a need for acquiring more complementary data hence all the available data for the salinity concentrations were used in the model calibration this analysis suggests areas for further investigation to improve the understanding of the aquifer system making it an essential prior step to the parameter estimation process the groundwater model was used to provide reliable initial parameter estimates to reduce the computational demand of the model calibration in phase 2 using variable density and solute transport model including the salinity observations the accuracy of its usage was evaluated by obtaining the low values of the scale rmse between using constant and variable density hydraulic heads these values can be attributed to the aquifer being shallow and the western part being governed by the freshwater inflow over the calibration period this study adopts simpler models to reduce computational cost without sacrificing accuracy other techniques such as combining fast running model based on non physical parameters and a complex model to estimate equivalent values for the non physical parameters hugman and doherty 2022 increasing grid size burrows and doherty 2015 using 2d models sherif et al 2012b or assuming a sharp interface coulon et al 2021 have also been used however caution should be exercised as these techniques are site specific and may not be universally applicable 5 2 evaluation of the parameter estimability under the linear assumption parameter identifiability was used to evaluate the parameter estimability the analysis showed that 86 out of 242 parameters were adequately identified the transient heads in the calibration dataset identified the hydraulic conductivities near the observation locations while soil texture had a larger impact on specific yield in the western part of the aquifer with fine sediments and steep water level gradients which was indicated from the field measurements at the observation wells of average fluctuation in the water levels of 18 m sherif et al 2014 the specific yield was better identified in coarser sediments east the mild hydraulic head gradient the average fluctuation in the water levels was 1 m made the model outputs insensitive to specific yield the salinity and ert survey data improved the identification of hydraulic conductivities this can be attributed to the key role of hydraulic conductivity in controlling the extent of the swi ketabchi and jahangir 2021 where the model outputs of salinity concentrations were sensitive to those parameters accordingly they displayed high identifiability fig 6 however the specific yield was less constrained by the salinity observations this finding agrees with other studies delsman et al 2017 zhang et al 2020 previous studies on swi models have employed a phased approach to parameter estimation to mitigate computational complexity abd elaty et al 2021 sanford and pope 2010 in this study we utilized fixed adequately identified parameters in the second phase of the model calibration process resulting in a further reduction in computational effort the linearity assumption made by the parid method was assessed in light of potential nonlinearities in the model our results indicate that the parid methodology provides valuable insights into the informativeness of the calibration data and the extent to which prediction uncertainty is reduced as shown in fig 10 5 3 model calibration validation and parameterization the model calibration was performed using the observations of transient heads salinity and ert survey data the tikhonov regularization method was used to incorporate prior information and svd to simplify the calibration process by reducing the number of parameters to those that were sensitive to the observations the results showed an overall reduction in the objective function for head and salinity measurements by 84 and 58 respectively table c3 1 supplementary material however it should be noted that the limited number of salinity measurements in each observation group led to an approach of zero in the nse coefficients indicating that further measurements are needed to improve the accuracy of the model additionally the observed misfit in head measurements in two observation wells near the shaarah pumping field bhf1 under validation and bhf15 under calibration and validation may be attributed to the significant fluctuation in pumping schedules than the assigned average values the proximity of bhf10 to wadi hyal stream resulted in a model structural error due to the assigned fixed boundary condition which did not account for the seasonal fluctuations in the stream water level minimization of the objective function alone is not a sufficient criterion to evaluate the efficiency of the calibration the reliability of the parameter estimates must also be considered to ensure the geological plausibility of the results the spatial variability of the hydraulic conductivity was found to be geologically realistic and preserved the aquifer heterogeneity while the specific yield values varied from their initial estimates but were still acceptable in the geological context specific yield values in similar alluvial aquifers have been measured to range from 0 05 to 0 15 chen et al 2010 and in ophiolite formations the values have ranged from near zero to 0 01 lachassagne et al 2021 the results contribute to the understanding of the geological formation of the system and highlight the importance of considering both the minimization of the objective function and the reliability of the parameter estimates in model calibration 5 4 calibration constrained parameter sets ensemble the implementation of the nsmc method linked with olhs and the filtering technique has successfully generated multiple hydrologically reasonable parameter sets that are in agreement with the available head and salinity observations the filtering technique removed 40 of the generated parameter sets during the recalibration which greatly reduced the computational time of the optimization process this novel approach offers a promising solution for the calibration of swi models and could be applied to other hydrological models the complex nature of swi modeling in heterogeneous aquifers can pose challenges in accurately estimating uncertainty in cases where the calibration dataset does not provide enough information to estimate model complexity such as seen in fig 9 where hydraulic conductivities were only constrained in two regions and a limited number of sy parameters near observation measurements in fine grained soil it is still important to include this complexity in the uncertainty analysis to accurately reflect the uncertainty in the predictions this study highlights the efficiency of nsmc in exploring the null space which is where the insetimated parameters reside and hence is the primary source of uncertainty in the predictions moore and doherty 2005 exploring the null space is based on the prior realization that spans the entirety of parameter space the generated prior realizations by olhs were substantially different from each other fig 9 resulting in a more comprehensive probabilistic coverage than the traditionally used sampling strategy srs a 110 calibration constrained parameter set has resulted from the application of the nsmc method and was used to derive the posterior parameter probability distribution of log khz and sy at each of 121 pilot points the posterior probability distributions of log khz and sy were found to fit normal and gumbel maximum distributions respectively the derived parameter probability distributions can be used to identify areas of high uncertainty in predictions and guide the expansion of the calibration dataset the coefficient of variation was used to compare different types of probability distributions and magnitudes with lower values indicating lower dispersion around the mean and higher certainty fig 10 in general the lower cv values were obtained close to the observation data indicating that the information content in the observations is sufficient to inform constrain the model parameters the certainty in parameter estimation is high and consequently the uncertainty in the predictions that are sensitive to those parameters is low on the other hand the parameters that were not informed by the observation data were constrained by prior information 5 5 analysis of the future prediction of swi the model s performance in predicting swi was compared to hussain et al 2015 who predicted the inland encroachment of 50 ischlor in 2015 under similar abstraction and recharge conditions 81 of their prediction fell within the minimum and maximum prediction range fig 11d indicating the model was calibrated correctly and provides reasonable uncertainty estimates the model was then used to predict swi in 2050 and further deterioration of water quality was revealed due to limited water availability and continued abstraction protective measures must be taken to protect the aquifer s resilience and sustainability despite the associated costs and challenges this finding is crucial for decision makers especially considering the potential exacerbation of future threats from sea level rise and reduced recharge due to rainfall scarcity under the conditions of climate change bolleter et al 2021 this study offers new insights into the parameter estimation and uncertainty analysis of swi models building upon previous studies that have used computationally expensive methods with limited parameters e g llopis albert et al 2016 miao et al 2019 zeng et al 2016 and assumed linear model behavior e g coulon et al 2021 dausman et al 2010 the findings of this study are site specific and model dependent as the results indicate that the parameter uncertainty is influenced by various factors such as the uncertainty in the observations their number and locations relative to the predictions of interest and the aquifer geological and hydrogeological parameters despite this some of the findings can be generalized and the proposed method applies to other cases 5 6 limitations of the model and future directions uncertainty in swi models is caused by factors such as tidal effects recharge variability geology solute dispersivity and anthropogenic influences this study aimed to quantify uncertainty in two main parameters that impact swi progression namely hydraulic conductivity and specific yield the results indicate high uncertainty in specific yield estimation due to limited head measurement data in fine grained soils further data collection of head measurements in fine grained soil or laboratory tests for coarse grained soil could reduce uncertainty uncertainty intervals and prediction distributions were estimated highlighting regions of high uncertainty but may be overestimated due to the small sample size zhang and shields 2018 in high dimensional and nonlinear models optimization algorithms can get stuck in local minima which reduces the efficacy of the nsmc method using multiple random initial parameters in the calibration process can help overcome this challenge another cause of efficacy reduction is fixing calibrated parameters in some cases which adds uncertainty to the prediction but reduces computational effort the nsmc method is preferred for its computational efficiency in highly parametrized swi models however it may not accurately represent bayesian posterior probabilities and may not accurately estimate uncertainty keating et al 2010 to improve accuracy in both model calibration and uncertainty analysis a high computational effort is needed in future studies the use of surrogate models can be considered as approximations to highly parametrized models reducing the computational effort one such surrogate model is gaussian process regression gpr which has been demonstrated to accurately capture swi behavior and estimate approximations and their uncertainty saad et al 2022 although gpr has been recently adapted to handle high dimensional problems its application to highly parametrized swi models has not yet been tested 6 conclusions a novel model independent framework was successfully developed to quantify the uncertainty associated with the estimation of model parameters and their propagation to the predictions of seawater intrusion swi in the wadi ham aquifer uae the parameter estimation process considered the aquifer heterogeneity in terms of horizontal hydraulic conductivity and specific yield using measurements of transient heads salinity concentrations and geophysical survey data along with prior knowledge of the geological formation to maximize the computational efficiency parameter estimation was conducted in two phases using constant and variable density models adequately identified parameters were considered fixed in the second phase the olhs was incorporated in the nsmc method and with the aid of the filtering technique an ensemble of constrained calibrated parameter sets was attained to derive the predictive probability distribution of swi length the following conclusions can be drawn from the findings of this research 1 data worth analysis provided a basis for the model calibration phasing and emphasized the importance of including salinity observations and geophysical surveys in the parameter estimation process to reduce predictive uncertainties despite their limited number compared to head observations this analysis is an essential prior step to the parameter estimation process 2 the transient heads only were able to identify some of the hydraulic conductivities in their proximity 9 when the salinity observations and the geophysical surveys were included the adequately identified parameters increased to 39 of the total parameters 3 for the specific yield the adequately identified parameters were found within the fine grained soil and near observation locations head observations contained more information to constrain them relative to salinity observations 4 the significant decrease in parameter and predictive uncertainty in any subregion of the model domain was strongly controlled by the density of the observations located within that subregion however constraining the specific yield using head data was more affected by the soil texture 5 the non redundant information contained in the calibration dataset constrained the highly identifiable parameters while the remaining parameters were more strongly constrained by prior knowledge reasonable a priori bounds were essential for obtaining acceptable parameter values in the geological context svd combined with tikhonov regularization helped to stabilize and constrain the inversion process to yield a plausible geological distribution 6 even though the uncertainties in the seawater intrusion length inferred from the geophysical surveys were considerably high nonredundant information was encapsulated in them on their removal the uncertainty in the salinity prediction increased geophysical observations are valuable for their wide spatial coverage and low cost 7 the space filling scheme of olhs based on ese optimization was more efficient in terms of probabilistic coverage compared to the srs scheme 8 the proposed filtering technique is a straightforward procedure to save computational time within the recalibration process and is favored over narrowing the possible parameter space intervals which may lead to the nsmc calibrated parameter sets being significantly constrained to the parameter set obtained through model calibration 40 of the generated parameter sets were omitted from the recalibration 9 a moderate correlation was observed between the parid which assumed model linearity and the reduction in the standard deviation of the prior parameter distribution to its posterior that was estimated considering model nonlinearity parid can give useful insights into the extracted information from the calibration dataset and reduce parameter uncertainty 10 the posterior predictive probability distribution determined the maximum and minimum predictions of the 5 isochlor position the resulting uncertainty intervals near kalba and fujyarh pumping fields varied by 4 5 and 11 from their means respectively which indicates with a high to moderate certainty that the aquifer would be vulnerable to salinization and the water quality at these pumping fields would be unsuitable for irrigation the framework presented in this study for probabilistic assessment of seawater intrusion swi due to input uncertainties has broad applicability beyond the site and model studied where it could be applied to other hydrological models improving predictions of water levels quantities and quality it can help identify data gaps and improve prediction certainty allowing for more accurate assessments of swi and the impact of management strategies on the aquifer system the resulting probability distribution can be used to estimate prediction intervals assess the reliability of management strategies and evaluate the probability of exceeding critical swi thresholds future research should address uncertain inputs beyond hydraulic conductivity and specific yield including boundary conditions such as sea level rise recharge variations and abstractions this is crucial for assessing future swi under climate change conditions integrating the proposed framework with simulation optimization based groundwater management models will help mitigate swi under uncertainty and propose a sustainable coastal management strategy in summary the highly parameterized regularized inversion allowed the extraction of information from the historical field measurements achieving reliable parameter estimates and a sufficient level of heterogeneity the nsmc method linked with olhs and filtering techniques was computationally efficient and succeeded in quantifying the prediction uncertainty of 5 isochlor intrusion length the framework proposed in this study can be generally applied in different coastal areas credit authorship contribution statement samia saad conceptualization methodology software formal analysis investigation validation resources visualization writing original draft writing review editing funding acquisition akbar a javadi supervision conceptualization writing review editing raziyeh farmani supervision writing review editing mohsen sherif writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the first author is funded by the ministry of higher education of the arab republic of egypt netwon mosharafa scholarship id nmm26 17 the authors would also like to express their gratitude to the dhi group for providing the free license of feflow data and information related to the wadi ham aquifer were provided by the national water and energy center united arab emirates university we would like to take this opportunity to thank the reviewers and the associate editor for their valuable comments that have certainly improved the quality of the paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129496 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
