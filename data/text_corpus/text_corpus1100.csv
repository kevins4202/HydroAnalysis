index,text
5500,the rapid increase in production and application of nanoparticles nps across a wide range of commercial and industrial processes has resulted in the extensive invasion of nps into subsurface environments accurately predicting the transport and release of nps in subsurface environments is important for assessing a wide range of environmental and human health risks in this study a two dimensional np transport and release model was proposed to investigate the behavior of nps in a layered heterogeneous medium with transient ionic strength is the layered heterogeneous porous medium comprised a slow flow domain sfd and a fast flow domain ffd the transport of nps in the two layers was described by two coupled advection dispersion equations ades the np deposition and release were related to the is of the electrolyte solution es in the medium and were represented by reversible and irreversible deposition terms in the ades the results indicated that heterogeneity has a significant impact on the transport and release of nps when nps pass through the two layer medium initially part of the nps in the ffd will migrate into the sfd a larger amount of nps are deposited in the sfd than the ffd owing to the higher filtration capacity of the sfd the retained nps in both the sfd and ffd will be released when the is declines the release of the retained nps in the ffd is faster than that in the sfd because the ffd has a higher intrinsic release rate and lower is owing to the more rapid transport of es in the ffd the proposed model was applied to laboratory experiments and compared to the double region model the proposed model fitted the experimental breakthrough curves better than the double region model and it is capable of fitting the release of nps which cannot be accomplished with the double region model keywords nanoparticle transport and release layered heterogeneous media numerical model nomenclature b 1 b 2 thickness of the sfd and ffd m b d dimensionless thickness of the sfd and ffd c 1 c 2 np concentration in pore water in the sfd and ffd m g l c 1 d c 2 d dimensionless np concentration in pore water in the sfd and ffd c 0 injected constant np concentration m g l c t 1 c t 2 es concentration in pore water in the sfd and ffd mm c t 1 d c t 2 d dimensionless es concentration in pore water in the sfd and ffd c t 0 injected constant es concentration during the deposition and elution phases mm c tr injected constant es concentration during the release phase mm c tr d dimensionless injected constant es concentration during the release phase mm c ad dimensionless np concentration for both domains c a 1 d c a 2 d dimensionless np concentration for the sfd and ffd c d c 1 c d c 2 critical deposition concentrations for the sfd and ffd mm c d c 1 d c d c 2 d dimensionless critical deposition concentrations for the sfd and ffd c r c 1 c r c 2 critical release concentrations for the sfd and ffd mm c r c 1 d c r c 2 d dimensionless critical release concentrations for the sfd and ffd d g 1 d g 2 grain diameters of the porous media in the sfd and ffd μ m d x 1 d x 2 np longitudinal dispersion coefficients in the sfd and ffd c m 2 m i n d y 1 d y 2 np transverse dispersion coefficients in the sfd and ffd c m 2 m i n d x t 1 d x t 2 es longitudinal dispersion coefficients in the sfd and ffd c m 2 m i n d y t 1 d y t 2 es transverse dispersion coefficients in the sfd and ffd c m 2 m i n d xd dimensionless longitudinal dispersion coefficient d yd dimensionless transverse dispersion coefficient k d 1 r k d 2 r np reversible deposition rate 1 min k d 1 r d k d 2 r d dimensionless np reversible deposition rate k d 1 r 0 k d 2 r 0 intrinsic np reversible deposition rate 1 min k d 1 r 0 d k d 2 r 0 d dimensionless intrinsic np reversible deposition rate k r 1 r k r 2 r np release rate 1 min k r 1 r d k r 2 r d dimensionless np release rate k r 1 r 0 k r 2 r 0 intrinsic np release rate 1 min k r 1 r 0 d k r 2 r 0 d dimensionless intrinsic np release rate k d 1 i r k d 2 i r np irreversible deposition rate 1 min k d 1 i r d k d 2 i r d dimensionless np irreversible deposition rate p 1 p 2 péclet numbers for the sfd and ffd r p dimensionless mass flux of nps between the two domains r t dimensionless mass flux of es between the two domains s 1 r s 2 r concentration of nps reversibly retained in the sfd and ffd mg l s 1 r d s 2 r d dimensionless concentration of nps reversibly retained in the sfd and ffd s 1 i r s 2 i r concentration of nps irreversibly retained in the sfd and ffd mg l s 1 i r d s 2 i r d dimensionless concentration of nps irreversibly retained in the sfd and ffd t time min t d dimensionless time v 1 v 2 pore water velocities for the sfd and ffd x horizontal coordinate m x d dimensionless horizontal coordinate x 1 x 2 maximum concentration of nps reversibly retained in the sfd and ffd mg l x 1 d x 2 d dimensionless maximum concentration of nps reversibly retained in the sfd and ffd y vertical coordinate m y d dimensionless vertical coordinate β a 1 β a 2 empirical coefficients in the is dependent deposition and release model for the sfd and ffd β d 1 β d 2 empirical coefficients in the is dependent deposition and release model for the sfd and ffd β s 1 β s 2 empirical coefficients in the is dependent deposition and release model for the sfd and ffd γ s 1 γ s 2 intrinsic maximum np deposition γ s 1 d γ s 2 d dimensionless intrinsic maximum np deposition θ 1 θ 2 porosity of the sfd and ffd θ d dimensionless porosity of the ffd 1 introduction with recent developments in manufacturing techniques for nanoparticles nps engineered nps have rapidly been introduced across a wide range of commercial and industrial processes however engineered nps used in industrial processes and commercial products can be released into subsurface environments throughout their life cycle keller et al 2013 engineered nps entering subsurface environments e g aquifers can have beneficial or adverse environmental impacts some engineered nps are emerging environmental contaminants such as graphene oxide go which can be toxic toward a variety of organisms including bacteria animals and humans akhavan and ghaderi 2010 ouyang et al 2019 the migration of hazardous nps in aquifers will cause groundwater pollution and further threaten the safety of drinking water in addition engineered nps in groundwater can serve as carriers for toxic substances thus facilitating the transport of dissolved contaminants jiang et al 2018 chen et al 2019 in contrast some engineered nps e g nano zero valent iron are designed and produced as remediation materials for soils and groundwater contaminated by chlorinated organic compounds and heavy metals raychoudhury et al 2014 cai et al 2019 however these engineered nps can easily be deposited on soil grain surfaces and clog the pores because the nps have high densities and tend to aggregate in micro sized clusters hotze et al 2010 these characteristics inhibit the transport of nps in aquifers and reduce their remediation efficiency releasing these deposited nps is a key approach to improve the remediation efficiency of engineered nps therefore understanding the transport and release mechanisms for nps in aquifers is important for assessing a wide range of risks related to the environment and human health enhancing the mobility of engineered nps and improving on site nano remediation techniques shen et al 2018 in porous media the deposition and release of nps occur in the region near the grain surface np behaviors are mainly governed by hydrodynamic forces and interaction forces between the particle and the grain surface the surface interaction forces include attractive van der waals and electric double layer interaction forces based on derjaguin landau verwey overbeek dlvo theory derjaguin and landau 1993 verwey and overbeek 1947 when the surface adhesive torque exceeds the hydrodynamic torque nps will be immobilized on the grain surface otherwise the retained nps will be mobilized vanness et al 2018 burdick et al 2005 bradford et al 2015 in addition molecular diffusion mechanisms can also drive the release of nps when surface adhesion is weak wang et al 2016 ma et al 2011 it has been established that a change in the solution ionic strength is will impact the thickness of the electric double layer and thus alter the electrostatic interactions bradford et al 2012 based on the classical colloid filtration and dlvo theories the escape of retained nps from primary energy minima would seem to be impossible molnar et al 2015 thus the release of nps has typically been considered to occur primarily among particles that are unstably retained at secondary energy minima tosco et al 2009 canseco et al 2009 however in recent years many researchers have found that the release of nps can also occur among particles retained at primary energy minima when nano to micro scale physical and chemical heterogeneity on the surfaces of porous media are considered bradford et al 2013 bradford and torkzaban 2015 2013 2012 torkzaban and bradford 2016 ma et al 2011 pazmino et al 2014a 2014b rasmuson et al 2019 2017 ron et al 2019 vanness et al 2018 shen et al 2018 2015 2014 this phenomenon is caused by both physical and chemical heterogeneities which can locally reduce the magnitude of the primary energy minimum and energy barrier even eliminating the energy barrier numerical modeling is an important method for quantifying the transport and release behaviors of nps in porous media these numerical models include pore and darcy scale models pore scale models are commonly developed by modifying the lagrangian particle trajectory model based on computational fluid dynamics johnson et al 2018 pazmino et al 2014b rasmuson et al 2019 ron et al 2019 vanness et al 2018 for darcy scale models the transport of nps in porous media is described by advection dispersion equations the deposition and release of nps is represented by coupling the transport equation of the solution chemistry as np deposition and release is dependent on the solution is bradford et al 2015 2012 mesticou et al 2014 tosco et al 2009 darcy scale models are widely used to investigate np transport and release behaviors in the laboratory and the field however these models are limited to the investigation of np transport and release in homogenous media heterogeneity is an intrinsic property of aquifers producing non uniform flow fields with widely varying velocities in the aquifer previous studies have indicated that the heterogeneity of porous media has an important impact on the transport and fate of solutions and nps bai and li 2012 berkowitz et al 2000 2006 skopp et al 1981 seuntjens 2002 zhan 1998 developed a stochastic model to investigate contaminant transport behaviors in a strongly heterogeneous stratified formation in different waste leakage scenarios and found that the heterogeneity significantly influenced both the concentrations and variances of concentration distributions zhou et al 2018 developed transport models with scale dependent and independent dispersion schemes to describe reactive solute transport in a stratified system their results indicated that diffusion in the low permeable layers could not be neglected and the diffusion coefficients in the low permeable layers were dependent on the advective time in the high permeable layer recently several studies have investigated the transport and release of nps in heterogeneous media dong et al 2019 2016 zhao et al 2019 dong et al 2016 conducted a series of go transport and release experiments in two layer heterogeneous sand columns in their experiments two peaks were observed in the breakthrough curves btcs during the go transport processes the second peak represented the impact of the heterogeneity the release process indicated that the mobility of go decreased with increasing is and the previously retained particles were released by reducing the solution is two peaks were also observed in the btcs of go during the release process to interpret the observed data dong et al 2016 applied a one dimensional 1 d double domain model to fit the experimental data however the 1 d double domain model has two deficiencies first the 1 d double domain model does not consider the release of go with decreasing is as mentioned above the particle grain surface interaction energies are strongly affected by the solution is thus np transport and release involves the co transport of electrolyte solute es and nps tosco et al 2009 as a result the impact of heterogeneity on np release will be more notable and complex second the 1 d double domain model neglects transverse dispersion and uses a constant mass transfer coefficient to represent the interaction between two zones a recent study liang et al 2019 indicated that the concentration gradients along the transverse direction are non negligible when there is a discrepancy between the péclet numbers in the two domains the mass exchange between the two zones is induced by the difference in the properties of the two zones and determined by the transverse dispersion across the interface this suggests that a two dimensional 2 d model considering the transverse dispersion is more appropriate for describing solute transport in layered heterogeneous media than the 1 d model for homogeneous media a few models have been proposed to describe the transport and release of nps as previously described for heterogeneous layered media however while the existing models can be used to simulate the np transport and retention processes they cannot be used to describe the release process under transient chemistry conditions e g dong et al 2016 2019 in this study a numerical model was developed to provide insight into the transport and release behaviors of nps in layered media and to understand the impacts of media heterogeneity on the np transport and release in this model a heterogeneous medium was formed from two layers of porous media the np transport in each layer was described by a 2 d advection dispersion equation ade while the mass interaction between the two layers was represented using the continuity of concentration and mass flux across the interface the np deposition and release processes were related to the is of the electrolyte solution in the media and were described by the reversible and irreversible deposition terms in the ades the is for each layer was obtained by solving a 2 d ade describing the electrolyte solution transport in the medium the effects of heterogeneity were investigated based on the proposed model the proposed model was applied to laboratory go transport and release experiments the remainder of this paper is organized as follows the mathematical model and numerical solution are presented in section 2 the results are described and discussed in section 3 the numerical model is applied to laboratory experimental data in section 4 finally a summary and conclusions are presented in section 5 2 methodology 2 1 problem a schematic diagram of np transport and release in a semi infinite layered heterogeneous porous medium is shown in fig 1 the thicknesses of the upper and lower domains are b 1 and b 2 respectively the materials comprising the two domains are different which leads to different permeabilities pore water velocities dispersion coefficients and deposition and release rates for np transport in the two domains the permeability of the upper domain is assumed to be lower than that of the lower domain thus the upper and lower domains are referred to as the slow flow domain sfd and the fast flow domain ffd respectively to investigate np transport and release in layered porous media we assumed that nps with a constant concentration were injected into the medium at the inlet for a certain amount of time after which the solute is in the medium was reduced to observe the np release behavior this conceptual model was designed based on np transport and release experiments dong et al 2016 zhao et al 2019 the layered medium was initially saturated with a high concentration electrolyte solution e g 100 mm nacl creating relatively strong surface adhesion for np deposition the modeling process for the transport and release of nps in this study included three phases i both an np suspension with a constant concentration c 0 and es with a high concentration c t 0 are injected into the layered medium at the inlet x 0 during the period from t 0 t1 and part of the nps are deposited on the grain surfaces and grain grain contacts of the porous medium this phase is called the deposition phase ii es with the same concentration c t 0 but without nps is injected into the layered medium after the deposition phase during the period from t t 1 t2 this phase is called the elution phase iii finally deionized di water is injected into the layered medium the is in the layered medium begins to decrease and the np grain surface adhesion also decreases gradually the nps retained in the layered medium during the previous two phases are partially released to the pore water this phase is called the release phase 2 2 numerical modeling based on the conceptual model described above a two domain mathematical model was used to describe the np transport and release in the layered heterogeneous porous medium the governing equations can be expressed as two 2 d ades with reversible and irreversible deposition terms hendry et al 1997 ma et al 2017 tosco et al 2009 dong et al 2016 as follows 1a c 1 t s 1 r t s 1 i r t d x 1 2 c 1 x 2 d y 1 2 c 1 y 2 v 1 c 1 x 1b c 2 t s 2 r t s 2 i r t d x 2 2 c 2 x 2 d y 2 2 c 2 y 2 v 2 c 2 x where the subscripts 1 and 2 refer to the sfd and ffd respectively c is the np concentration in pore water m l 3 v is the pore water velocity l t d x and d y are the np longitudinal and transverse dispersion coefficients l 2 t respectively further s r t represents the reversible deposition term where s r is the concentration of nps reversibly retained on the porous medium m l 3 this term describes the process in which nps are deposited on the porous medium when the is is high and are released into the pore water from the medium when the is decreases in addition s ir t represents the irreversible deposition term where s ir is the concentration of nps irreversibly retained on the porous medium m l 3 this term describes the process in which a part of the nps deposited on the porous medium cannot ever be released in this study we focus on the np transport and fate in layered media the flow fields were assumed to be steady state and uniform in each domain the constant fluid velocities v 1 and v 2 for each domain were assigned directly each domain has a different velocity induced by the heterogeneous layered medium this assumption has commonly been made to describe solute transport in layered media in previous studies e g lv et al 2016 dong et al 2016 2019 liang et al 2019 this assumption is valid for the case of a constant hydraulic gradient which can be achieved by imposing constant hydraulic heads on the two sides of the layered medium bai and li 2012 moreover the dispersion coefficients are assumed to be scale independent in this model which is reasonable based on the previous studies e g zhou et al 2018 the reversible and irreversible deposition terms in the two domains can be expressed as follows hendry et al 1997 ma et al 2017 in the sfd 2a s 1 r t 1 s 1 r x 1 k d 1 r c 1 k r 1 r s 1 r 2b s 1 i r t k d 1 i r c 1 in the ffd 2c s 2 r t 1 s 2 r x 2 k d 2 r c 2 k r 2 r s 2 r 2d s 2 i r t k d 2 i r c 2 where k d r and k r r are the np reversible deposition and release rate respectively 1 t x is the maximum concentration of nps reversibly retained on the porous medium m l 3 and k d i r is the np irreversible deposition rate 1 t the sfd has a lower permeability and higher filtration capacity than the ffd therefore k d 1 r and x 1 are larger than k d 2 r and x 2 respectively moreover the lower flow velocity in the sfd results in weaker hydrodynamic drags therefore k r 1 r is smaller than k r 2 r according to the dlvo theory np deposition and release processes are largely dependent on the is therefore k d r k r r and x are commonly expressed as semi empirical functions of c t bianco et al 2016 tosco et al 2009 in the sfd 3a k d 1 r k d 1 r 0 1 c d c 1 c t 1 β a 1 3b k r 1 r k r 1 r 0 1 c t 1 c r c 1 β d 1 3c x 1 γ s 1 c t 1 β s 1 in the ffd 3d k d 2 r k d 2 r 0 1 c d c 2 c t 2 β a 2 3e k r 2 r k r 2 r 0 1 c t 2 c r c 2 β d 2 3f x 2 γ s 2 c t 2 β s 2 where c t is the es concentration n l3 which is typically used to represent the solution is k d r 0 c d c β a k r r 0 c r c β d γ s and β s are empirical coefficients among these coefficients k d r 0 k r r 0 and γ s are linearly proportional to k d r k r r and x respectively of these k d r 0 represents the intrinsic reversible deposition rate of the porous medium k r r 0 represents the intrinsic release rate of the porous medium and γ s represents the maximum reversible deposition of the porous medium both k d r 0 and γ s generally increase with decreasing median grain size of the porous medium ma et al 2018 xu et al 2006 sun et al 2015 while k r r 0 increases with increasing flow velocity ma et al 2017 based on the above equations both k d r and x increase with increasing c t while k r r decreases with c t these relationships reflect the mechanism in which the surface adhesion between the nps and grains increases with increasing is based on the conceptual model the initial and boundary conditions of the np transport can be expressed as follows 4a c 1 x y t 0 c 2 x y t 0 0 4b c 1 x 0 y t c 2 x 0 y t c 0 t t 1 0 t t 1 4c c 1 x x y t x c 2 x x y t x 0 4d c 1 y x y t y b 1 c 2 y x y t y b 2 0 where c 0 is the np injection concentration based on continuity of the concentration and mass flux across the interface the interface conditions of the two domains at y 0 can be expressed as follows 5a c 1 x y 0 t c 2 x y 0 t 5b θ 1 d y 1 c 1 y x y t y 0 θ 2 d y 2 c 2 y x y t y 0 where θ is the porosity l 3 l 3 as described in section 2 1 di water is injected into the porous medium instead of es in the release phase as a result the is in the layered medium gradually decreases similar to the np transport the es transport in the layered medium can be described by the following two 2 d ades 6a c t 1 t d x t 1 2 c t 1 x 2 d y t 1 2 c t 1 y 2 v 1 c t 1 x 6b c t 2 t d x t 2 2 c t 2 x 2 d y t 2 2 c t 2 y 2 v 2 c t 2 x where d xt and d yt are the es longitudinal and transverse dispersion coefficients l 2 t respectively in this study we focus on the impacts of heterogeneity on the np transport and assume that the es dispersion coefficients are equal to the np dispersion coefficients which has also been assumed in some previous studies xu et al 2006 tosco et al 2009 tosco and sethi 2010 the initial and boundary conditions for es transport in the layered media can be written as follows 7a c t 1 x y t 0 c t 2 x y t 0 0 7b c t 1 x 0 y t c t 2 x 0 y t c t 0 t t 2 c t r t t 2 7c c t 1 x x y t x c t 2 x x y t x 0 7d c t 1 y x y t y b 1 c t 2 y x y t y b 2 0 where c tr is the concentration of es at the inlet in the release phase n l3 this concentration should be equal to zero because we are assuming that only di water is pumped into the layered medium during the release phase however k a m cannot be correctly calculated if c tr 0 therefore we replaced c tr 0 with c tr 0 1 mm in the modeling which was also adopted in tosco et al 2009 for the purpose of mathematical convenience we transformed eqs 1 7 into dimensionless forms appendix the definitions of the dimensionless variables are summarized in table 1 the effluent np concentration in the layered medium can be written as the average concentration along the y direction at a fixed x d more specifically the dimensionless np concentrations for the sfd ffd and both domains can be written as follows 8a c a 1 d 0 1 c 1 d d y d 8b c a 2 d b d 0 c 2 d d y d b d 8c c ad p 1 0 1 c 1 d d y d p 2 θ d b d 0 c 2 d d y d p 1 p 2 θ d b d where the subscript d denotes dimensionless terms hereinafter the dimensionless mass fluxes between the two domains can be written for np and es respectively as follows 9a r p c 1 d y d x d y d t d y d 0 9b r t c t 1 d y d x d y d t d y d 0 where positive r p and r t represent the np and es respectively migrating from the ffd into the sfd and vice versa the mathematical models for the np transport and release and es transport were numerically solved using comsol multiphysics the convection diffusion equation module in the mathematics classical pdes menu was used to simulate the np and solute transport two convection diffusion equations are coupled to model the np and solute transport in the sfd and ffd the interface mass transfer is represented by the continuity of concentrations and mass fluxes across the interface eqs 5a and 5b which is handled by comsol itself nothing else needs to be done for this boundary for the numerical treatment the semi infinite geometry size 0 x d was replaced by a finite range 0 x d 10 to represent the infinite boundary x d an infinite element domain was added at x d 10 which is a component of comsol and is designed to represent infinite geometry the two domains were discretized into triangular mesh elements to ensure sufficient accuracy of the obtained solutions elements near the interface of the two domains and at the left boundary were refined with a minimum element size of 0 00315 the maximum growth rate is 1 3 for the element size the number of triangular elements was 78 760 a total of 2400 constant time steps were analyzed with a total simulation time of t d 1 2 3 results and discussion 3 1 effects of layered heterogeneity to gain insight into the impacts of the differing sfd and ffd properties on np transport and release we conducted three simulations with different péclet numbers for the sfd p 1 and ffd p 2 as described in table 2 for convenience of the discussion we assume an sfd with a fixed p 1 5 and an ffd with p 2 5 20 o r 30 the deposition and release parameters k d r 0 d k r i r d k r r 0 d and γ s d are relative to the péclet numbers therefore we assume these parameters are constants for the sfd and vary with p 2 for the ffd more specifically k d r 0 d k d i r d and γ s d decrease with increasing péclet number because porous media with high péclet numbers typically have high permeability and low filtration capacity in contrast k r r 0 d increases with increasing péclet number a high péclet number represents a rapid pore fluid flow and strong hydrodynamic drag which facilitate the release of nps the values of k d r 0 d k d i r d γ s d and k r r 0 d for different péclet numbers are summarized in table 2 the other deposition and release parameters used in the models are fixed and are presented in table 2 the other parameters for the models are b d θ d 1 and d xd d yd 1 4 and 6 for p 2 5 20 a n d 30 respectively the injected dimensionless concentrations of np and es vary with time at the inlet in the deposition phase 0 t d 0 1 nps with a concentration of ctd xd 0 1 suspended in an es concentration of ctd xd 0 1 were injected into the layered media in the elution phase 0 1 t d 0 3 the np free cd xd 0 0 es with a concentration of ctd xd 0 1 was injected into the layered media finally in the release phase t d 0 3 di water ctd xd 0 0 and c td r 0 001 was injected into the layered media fig 2 a shows the btcs for the combination of both domains c ad with different p 2 two peaks are observed in the btcs the first peak corresponds to the np transport in the media at high is during the deposition and elution phases 0 t d 0 3 the second peak corresponds to the release of the reversibly retained nps when the is decreases during the release phase t d 0 3 for the cases with a greater contrast in properties between the two domains larger p 2 c ad is higher in the deposition and elution phases owing to the smaller deposition parameters of the ffd k d 2 r 0 d k d 2 i r d and γ 2 s d and the shorter residence time of the nps in the ffd in addition the remarkable increase in c ad implies that fewer nps are deposited on the media during this period as a result fewer nps will be released in the release phase and thus c ad is generally lower for the second peak moreover the emergence of the second peak occurs much earlier owing to the higher transport speed of the released nps in the ffd when p 2 is larger this indicates that the preferential pathway markedly accelerates the overall np transport in porous media these phenomena indicate that the heterogeneity has significant impacts on the transport and release of nps to further investigate the impacts of heterogeneity the np transport and release behaviors in each domain will be discussed below fig 2b and c show the btcs for the sfd c a 1 d and ffd c a 2 d respectively with different values of p 2 fig 2b and c show that c 2 a d is generally closer to c ad than c 1 a d owing to the rapid flow in the ffd in the deposition and elution phases both c a 1 d and c a 2 d increase with increasing p 2 especially for c a 2 d where the increase is significant as discussed above the higher c a 2 d results from the higher media filtration capacity and shorter np residence time in the ffd when p 2 is larger the higher c a 2 d represents a higher suspended np concentration in the ffd implying that more of the nps in the ffd can enter the sfd forced by the transverse dispersion this results in an increase in c a 1 d with increasing p 2 even though sfd has fixed p 1 and deposition parameters fig 2b in addition the higher c a 2 d implies that the amount of nps retained in the ffd is smaller during the deposition and elution phases thus fewer nps in the ffd will be released into the pore water during the release phase with a larger p 2 in the release phase the profiles of the three btcs in the sfd are similar except that the curve is shifted slightly to the left when p 2 5 indicating that the rapid transport in the ffd might affect the np transport and release in the sfd unlike the sfd the profiles of the three btcs in the ffd are very different fig 2b for large p 2 the emergence of the peak is early and the concentration rapidly climbs to the peak and then decreases to a low value within a short time this phenomenon is ascribed to the fast transport speed and high release rate k r r d in the ffd when p 2 is large fig 2c also shows that for the larger p 2 the total amount of nps released from the ffd is small because the amount of nps retained in the ffd in the deposition phase is less in addition extended tailings are clearly observed in the btcs for the ffd when p 2 5 implying that the concentration of suspended nps in the sfd is higher than that in the ffd after t d 0 6 and part of the nps in the sfd migrate into the ffd 3 2 spatiotemporal distribution of nps in heterogeneous porous media to further investigate the impacts of heterogeneity on the transport and release of nps spatial distributions of the dimensionless np concentration c d dimensionless reversible deposition s r d and es concentration c t in the layered media p 1 5 p 2 20 at different dimensionless times t d 0 1 0 3 and 0 7 are shown in fig 3 the other parameters are the same as for the case with p 1 5 p 2 20 in fig 2 fig 3a shows that a larger number of suspended nps migrate into the ffd at t d 0 1 owing to the larger flow rate relative to the sfd the suspended nps in the sfd exhibit a significant concentration gradient along the y direction thus part of the suspended nps in the ffd will migrate into the sfd via the transverse dispersion mechanism the transverse dispersion also causes a non uniform distribution of the np concentration in the sfd near the interface of the two domains unlike the suspended nps the amount of retained nps is less in the ffd than in the sfd fig 3d with increasing time t d 0 3 c d in both the sfd and ffd declines to 0 indicating that almost all of the suspended nps have been deposited on the porous media similar to t d 0 1 a greater amount of nps are deposited in the sfd relative to the ffd due to the higher filtration capacity in the sfd after t d 0 3 di water is injected into the media instead of high concentration es as a result the is in the media gradually declines inducing the release of the reversibly retained nps the released nps in both the sfd and ffd at t d 0 7 are shown in fig 3c fig 3c clearly shows that the release of the retained nps is faster in the ffd than the sfd owing to a higher intrinsic release rate and lower is in addition owing to the high flow rate in the ffd the nps in the ffd have been transported a greater distance from the inlet in contrast the concentration of nps near the inlet in the sfd is much higher compared to that in the ffd as a result part of the nps in the sfd migrate into the ffd in this zone via the transverse dispersion mechanism the transverse migration from the sfd to ffd results in extended tailing in the btcs for the ffd fig 2c moreover in the zone away from the inlet part of the nps in the ffd migrate into the sfd due to the fast transport of nps in the ffd in the release phase the released nps will re deposit on the media when they encounter the high is solution fig 3f shows the distribution of np deposition in the layered media the amount of retained nps in the sfd is greater than that in the ffd owing to the higher intrinsic deposition rate and the generally higher is in the sfd high deposition is observed near the interface in the sfd in the zone away from the inlet fig 3f indicating that a large amount of nps are retained in this area when they migrate into the sfd from the ffd this phenomenon can be ascribed to i the high intrinsic filtration capacity of the sfd and ii the high k d r d and low k r r d due to the high is in this area based on the above analysis the np release process involves the transport of both es and nps therefore during the release phase the impacts of heterogeneity on the np behaviors are much more complex than these impacts during the deposition and elution phases first the heterogeneity affects the transport of nps via the transverse dispersion mechanism between the two domains second the heterogeneity also affects the transport of es as mentioned above the deposition and release rates are largely determined by the is of the solution therefore the es transport in layered heterogeneous media controls the process of np release and re deposition to discuss the impacts of heterogeneity on np behaviors during the release phase in more detail the np release in the layered medium p 1 5 p 2 20 is compared with that in two homogeneous media referred to as hom1 and hom2 hom1 has a small péclet number p 1 p 2 5 while hom2 has a large péclet number p 1 p 2 20 the other parameters of hom1 and hom2 are same as those for the sfd and ffd in the layered medium fig 4 shows the spatial distributions of c d s r d and c t at t d 0 7 for hom1 hom2 and the layered medium fig 4b shows that the transport of nps in the ffd is slower than that in hom2 fig 4g there are two reasons for this phenomenon first part of the released nps in the zone near the inlet in the sfd migrate into the ffd slowing down the np transport in the ffd second the is in the sfd near the outlet is higher than that in the ffd and thus the es in the sfd migrates into the ffd owing to the transverse migration of es the is in the ffd fig 4f is generally higher than that in hom2 fig 4i as previously mentioned the release rate is small when the is is high therefore the release of nps in the ffd is slower than that in hom2 3 3 mass transfer at the two domain interface the heterogeneity of a layered medium will cause significant mass transfer between the two domains which will further affect the transport and release of nps to investigate the mass transfer pattern the dimensionless mass flux of nps r p and es r t across the interface of the two domains are displayed in fig 5 at different times the parameters are the same as the case of p 1 5 and p 2 20 in fig 2 fig 5a shows that positive r p were observed near the left boundary at t d 0 1 indicating that nps in the ffd migrate into the sfd after t d 0 1 without the continuous injection of nps from the inlet r p sharply declines and becomes negligible in the whole interface at t d 0 3 indicating that the mass transfer between the two domains is very weak in the release phase t d 0 3 the mass fluxes are negative near the inlet and positive away from the inlet indicating that nps in the sfd migrate into the ffd near the inlet and the inverse pattern occurs near the outlet with respect to r t fig 5b during 0 t d 0 3 r t is equal to 0 because the c t in the two domains are equal after t d 0 3 r t is always less than zero indicating that es in the sfd continuously enter the ffd the area where the mass transfer between the two domains occurs becomes wider with increasing time because the es in the ffd gradually migrates out 4 application to laboratory experiments in this section the proposed model was employed to interpret the measured btcs for go transport and release from a series of laboratory experiments conducted in six sand columns referred to as s1 s6 by dong et al 2016 each column had a diameter of 2 5 cm and a height of 15 cm each column was separated into two identical domains along the longitudinal direction by placing a thin walled acrylic plate in the center of the column two types of quartz sand with different median grain diameters finer and coarser sands were packed in the two domains to construct the sfd and ffd of the layered heterogeneous media respectively the grain diameters d g of the packed sands for the six columns are presented in table 3 each column was first saturated with a particle free 20 mm solution of nacl the breakthrough experiment was conducted by injecting a go suspension for approximately 40 min followed by elution with a particle free solution of 20 mm nacl after 100 min di water was pumped into the column to remobilize the previously retained particles until the effluent go concentration was not measurable effluent samples were collected every two minutes using a fraction collector at the column outlet the go concentrations in the samples at different times were measured using a uv 2000 spectrophotometer to obtain the btcs for the experiments the measured btcs for the go transport and release from the six columns were fitted using the model proposed in the present study fig 6 the go transport and release parameters were estimated by minimizing the sum of the squared differences between the calculated and measured go concentrations the estimated parameters are summarized in table 3 six parameters v d x k d r 0 k r r 0 k d i r 0 and γ s for each layer were estimated by fitting the observed btcs these parameters are closely related to the heterogeneity of the porous medium and weakly related to the solute chemistry conditions their values were estimated using the levenberg marquardt algorithm which is implemented using an l m least squares code in matlab gavin 2013 the numerical model built with comsol is transformed to a matlab function and the parameter estimation is implemented using the module comsol with matlab the other parameters c d c c r c β a β d and β s are commonly used to describe the impacts of the solute is on np retention and release therefore the values of these parameters were obtained by referring to a previous study tosco et al 2009 and are c d c 247 m m c r c 1 3 m m β a 0 5 β d 2 5 and β s 0 54 for both the sfd and ffd fig 6 shows that there is good agreement between the modeling and experimental data in the three phases in all cases as mentioned above the btcs were fitted using the 1 d double domain model in dong et al 2016 comparing the fitting results of the 1 d and 2 d models reveals that the 2 d model fitted the observed btcs better than the 1 d model for all columns during the deposition and elution phases this is because the 1 d model neglects the transverse dispersion and uses a constant mass transfer coefficient to approach the interaction between the two zones in addition because it does not consider the np release with decreasing is the 1 d model is not capable of fitting the experimental data during the release phase fig 6 shows that all of the btcs have two peaks during the release phase t 100 min indicating the effects of the layered heterogeneity on the go more specifically the first peak of the release phase represents the go release from the ffd due to the more rapid flow and release in this domain while the second peak represents the go release from the sfd due to the slower flow and release in this domain when the difference between the properties of the two domains increased the second peak lagged farther behind the first peak in the release phase and the amplitude of the second peak decreased considerably e g for s3 and s6 these phenomena are a result of the increase in the discrepancy between the flow velocities and filtration capacity of the two domains 5 conclusions in this study the transport and release of nps under conditions of a transient solution is in a layered heterogeneous medium were investigated a 2 d numerical model describing the np transport and release was developed the layered heterogeneous porous medium consisted of an sfd and an ffd the np transport in each layer was described by a 2 d ade and these were coupled by the continuity of concentration and mass flux across the interface between the two domains np deposition and release behaviors were described by reversible and irreversible deposition terms which coupled the ades the impacts of the transient solution is on the particle deposition and release were characterized by is dependent deposition and release rates the proposed model was applied to laboratory np transport and release experiments the conclusions can be summarized as follows 1 the impacts of layered heterogeneity on np release and transport are complex because the np release and transport involved co transport of es and nps it was necessary to employ a 2 d model to visually display the complex transport patterns 2 in the deposition and elution phases the increase in the np concentration in the ffd with increasing péclet numbers of the ffd results in a greater amount of nps migrating into the sfd and thus an increase in the np concentration in the sfd a greater amount of nps are deposited in the sfd relative to the ffd owing to the higher filtration capacity of the sfd 3 the retained nps in both the sfd and ffd will be released when the is declines as a result of the injection of deionized water into the medium the release of the retained nps in the ffd is faster than that in the sfd because the ffd has a higher intrinsic release rate and lower is due to the more rapid transport of es in the ffd 4 the mass transfer of nps between the two domains varies with the location of the interface nps in the sfd migrate into the ffd near the inlet and inversely near the outlet the np migration from the sfd to ffd becomes dominant when a majority of the nps in the ffd are transported out resulting in a long tail in the btcs for the ffd 5 the proposed model was in good agreement with the experimental breakthrough curves in both the np transport and release phases the proposed model matched the experimental breakthrough curves better than the double region model and it is capable of fitting the np release which cannot be accomplished with the double region model the proposed model could be used to investigate np transport and release in layered heterogeneous media in 2 d spaces and to interpret the btcs observed in laboratory experiments author contributions jin liu performed research and wrote the paper xiankui zeng enze ma designed research and revised the paper jichun wu you kuan zhang reviewed and edited the paper yuanyuan sun xiuyu liang analyzed data chunmiao zheng provided resources for laboratory and numerical experiments declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was partially supported by research grants from the national natural science foundation of china 41730856 41977165 41830861 and the guangdong provincial key laboratory of soil and groundwater pollution control 2017b030301012 we thank the anonymous reviewers for their constructive comments the manuscript has been significantly improved by incorporating their suggestions appendix a dimensionless governing equations for nanoparticle and electrolyte solute transport the system of equations can be rewritten in dimensionless form by introducing the following dimensionless variables table 1 the dimensionless governing equations for np transport and release are written as follows for np transport in the sfd a1a c 1 d t d s 1 r d t d s 1 i r d t d p 1 c 1 d x d 2 c 1 d x d 2 2 c 1 d y d 2 a1b s 1 r d t d 1 s 1 r d x 1 d k d 1 r d c 1 d k r 1 r d s 1 r d a1c s 1 i r d t d k d 1 i r d c 1 d for np transport in the ffd a1d c 2 d t d s 2 r d t d s 2 i r d t d p 2 c 2 d x d d xd 2 c 2 d x d 2 d yd 2 c 2 d y d 2 a1e s 2 r d t d 1 s 2 r d x 2 d k d 2 r d c 2 d k r 2 r d s 2 r d a1f s 2 i r d t d k d 2 i r d c 2 d where k d r d k d r 0 d 1 c d c d c td β a k r r d k r r 0 d 1 c td c r c d β d and x d γ s d c td β s the interface conditions are as follows a2a c 1 d x d y d 0 t d c 2 d x d y d 0 t d a2b c 1 d y d x d y d t d y d 0 θ d d yd c 2 d y d x d y d t d y d 0 the initial and boundary conditions are a3a c 1 d x d y d t d 0 c 2 d x d y d t d 0 0 a3b c 1 d x d 0 y d t d c 2 d x d 0 y d t d c d 0 t t 1 d 0 t t 1 d a3c c 1 d x d x d y d t d x d c 2 d x d x d y d t d x d 0 a3d c 1 d y d x d y d t d y d 1 c 2 d y d x d y d t d y d b d 0 the dimensionless governing equations for the es transport can be written as follows a4a c t 1 d t d 2 c t 1 d x d 2 2 c t 1 d y d 2 p 1 c t 1 d x d a4b c t 2 d t d d xd 2 c t 2 d x d 2 d yd 2 c t 2 d y d 2 p 2 c t 2 d x d the interface conditions are a5a c t 1 d x d y d 0 t d c t 2 d x d y d 0 t d a5b c t 1 d y d x d y d t d y d 0 θ d d yd c t 2 d y d x d y d t d y d 0 the initial and boundary conditions are a6a c t 1 d x d y d t d 0 c t 2 d x d y d t d 0 0 a6b c t 1 d x d 0 y d t d c t 2 d x d 0 y d t d 1 t t 2 d c td r t t 2 d a6c c t 1 d x d x d y d t d x d c t 2 d x d x d y d t d x d 0 a6d c t 1 d y d x d y d t d y d 1 c t 2 d y d x d y d t d y d b d 0 
5500,the rapid increase in production and application of nanoparticles nps across a wide range of commercial and industrial processes has resulted in the extensive invasion of nps into subsurface environments accurately predicting the transport and release of nps in subsurface environments is important for assessing a wide range of environmental and human health risks in this study a two dimensional np transport and release model was proposed to investigate the behavior of nps in a layered heterogeneous medium with transient ionic strength is the layered heterogeneous porous medium comprised a slow flow domain sfd and a fast flow domain ffd the transport of nps in the two layers was described by two coupled advection dispersion equations ades the np deposition and release were related to the is of the electrolyte solution es in the medium and were represented by reversible and irreversible deposition terms in the ades the results indicated that heterogeneity has a significant impact on the transport and release of nps when nps pass through the two layer medium initially part of the nps in the ffd will migrate into the sfd a larger amount of nps are deposited in the sfd than the ffd owing to the higher filtration capacity of the sfd the retained nps in both the sfd and ffd will be released when the is declines the release of the retained nps in the ffd is faster than that in the sfd because the ffd has a higher intrinsic release rate and lower is owing to the more rapid transport of es in the ffd the proposed model was applied to laboratory experiments and compared to the double region model the proposed model fitted the experimental breakthrough curves better than the double region model and it is capable of fitting the release of nps which cannot be accomplished with the double region model keywords nanoparticle transport and release layered heterogeneous media numerical model nomenclature b 1 b 2 thickness of the sfd and ffd m b d dimensionless thickness of the sfd and ffd c 1 c 2 np concentration in pore water in the sfd and ffd m g l c 1 d c 2 d dimensionless np concentration in pore water in the sfd and ffd c 0 injected constant np concentration m g l c t 1 c t 2 es concentration in pore water in the sfd and ffd mm c t 1 d c t 2 d dimensionless es concentration in pore water in the sfd and ffd c t 0 injected constant es concentration during the deposition and elution phases mm c tr injected constant es concentration during the release phase mm c tr d dimensionless injected constant es concentration during the release phase mm c ad dimensionless np concentration for both domains c a 1 d c a 2 d dimensionless np concentration for the sfd and ffd c d c 1 c d c 2 critical deposition concentrations for the sfd and ffd mm c d c 1 d c d c 2 d dimensionless critical deposition concentrations for the sfd and ffd c r c 1 c r c 2 critical release concentrations for the sfd and ffd mm c r c 1 d c r c 2 d dimensionless critical release concentrations for the sfd and ffd d g 1 d g 2 grain diameters of the porous media in the sfd and ffd μ m d x 1 d x 2 np longitudinal dispersion coefficients in the sfd and ffd c m 2 m i n d y 1 d y 2 np transverse dispersion coefficients in the sfd and ffd c m 2 m i n d x t 1 d x t 2 es longitudinal dispersion coefficients in the sfd and ffd c m 2 m i n d y t 1 d y t 2 es transverse dispersion coefficients in the sfd and ffd c m 2 m i n d xd dimensionless longitudinal dispersion coefficient d yd dimensionless transverse dispersion coefficient k d 1 r k d 2 r np reversible deposition rate 1 min k d 1 r d k d 2 r d dimensionless np reversible deposition rate k d 1 r 0 k d 2 r 0 intrinsic np reversible deposition rate 1 min k d 1 r 0 d k d 2 r 0 d dimensionless intrinsic np reversible deposition rate k r 1 r k r 2 r np release rate 1 min k r 1 r d k r 2 r d dimensionless np release rate k r 1 r 0 k r 2 r 0 intrinsic np release rate 1 min k r 1 r 0 d k r 2 r 0 d dimensionless intrinsic np release rate k d 1 i r k d 2 i r np irreversible deposition rate 1 min k d 1 i r d k d 2 i r d dimensionless np irreversible deposition rate p 1 p 2 péclet numbers for the sfd and ffd r p dimensionless mass flux of nps between the two domains r t dimensionless mass flux of es between the two domains s 1 r s 2 r concentration of nps reversibly retained in the sfd and ffd mg l s 1 r d s 2 r d dimensionless concentration of nps reversibly retained in the sfd and ffd s 1 i r s 2 i r concentration of nps irreversibly retained in the sfd and ffd mg l s 1 i r d s 2 i r d dimensionless concentration of nps irreversibly retained in the sfd and ffd t time min t d dimensionless time v 1 v 2 pore water velocities for the sfd and ffd x horizontal coordinate m x d dimensionless horizontal coordinate x 1 x 2 maximum concentration of nps reversibly retained in the sfd and ffd mg l x 1 d x 2 d dimensionless maximum concentration of nps reversibly retained in the sfd and ffd y vertical coordinate m y d dimensionless vertical coordinate β a 1 β a 2 empirical coefficients in the is dependent deposition and release model for the sfd and ffd β d 1 β d 2 empirical coefficients in the is dependent deposition and release model for the sfd and ffd β s 1 β s 2 empirical coefficients in the is dependent deposition and release model for the sfd and ffd γ s 1 γ s 2 intrinsic maximum np deposition γ s 1 d γ s 2 d dimensionless intrinsic maximum np deposition θ 1 θ 2 porosity of the sfd and ffd θ d dimensionless porosity of the ffd 1 introduction with recent developments in manufacturing techniques for nanoparticles nps engineered nps have rapidly been introduced across a wide range of commercial and industrial processes however engineered nps used in industrial processes and commercial products can be released into subsurface environments throughout their life cycle keller et al 2013 engineered nps entering subsurface environments e g aquifers can have beneficial or adverse environmental impacts some engineered nps are emerging environmental contaminants such as graphene oxide go which can be toxic toward a variety of organisms including bacteria animals and humans akhavan and ghaderi 2010 ouyang et al 2019 the migration of hazardous nps in aquifers will cause groundwater pollution and further threaten the safety of drinking water in addition engineered nps in groundwater can serve as carriers for toxic substances thus facilitating the transport of dissolved contaminants jiang et al 2018 chen et al 2019 in contrast some engineered nps e g nano zero valent iron are designed and produced as remediation materials for soils and groundwater contaminated by chlorinated organic compounds and heavy metals raychoudhury et al 2014 cai et al 2019 however these engineered nps can easily be deposited on soil grain surfaces and clog the pores because the nps have high densities and tend to aggregate in micro sized clusters hotze et al 2010 these characteristics inhibit the transport of nps in aquifers and reduce their remediation efficiency releasing these deposited nps is a key approach to improve the remediation efficiency of engineered nps therefore understanding the transport and release mechanisms for nps in aquifers is important for assessing a wide range of risks related to the environment and human health enhancing the mobility of engineered nps and improving on site nano remediation techniques shen et al 2018 in porous media the deposition and release of nps occur in the region near the grain surface np behaviors are mainly governed by hydrodynamic forces and interaction forces between the particle and the grain surface the surface interaction forces include attractive van der waals and electric double layer interaction forces based on derjaguin landau verwey overbeek dlvo theory derjaguin and landau 1993 verwey and overbeek 1947 when the surface adhesive torque exceeds the hydrodynamic torque nps will be immobilized on the grain surface otherwise the retained nps will be mobilized vanness et al 2018 burdick et al 2005 bradford et al 2015 in addition molecular diffusion mechanisms can also drive the release of nps when surface adhesion is weak wang et al 2016 ma et al 2011 it has been established that a change in the solution ionic strength is will impact the thickness of the electric double layer and thus alter the electrostatic interactions bradford et al 2012 based on the classical colloid filtration and dlvo theories the escape of retained nps from primary energy minima would seem to be impossible molnar et al 2015 thus the release of nps has typically been considered to occur primarily among particles that are unstably retained at secondary energy minima tosco et al 2009 canseco et al 2009 however in recent years many researchers have found that the release of nps can also occur among particles retained at primary energy minima when nano to micro scale physical and chemical heterogeneity on the surfaces of porous media are considered bradford et al 2013 bradford and torkzaban 2015 2013 2012 torkzaban and bradford 2016 ma et al 2011 pazmino et al 2014a 2014b rasmuson et al 2019 2017 ron et al 2019 vanness et al 2018 shen et al 2018 2015 2014 this phenomenon is caused by both physical and chemical heterogeneities which can locally reduce the magnitude of the primary energy minimum and energy barrier even eliminating the energy barrier numerical modeling is an important method for quantifying the transport and release behaviors of nps in porous media these numerical models include pore and darcy scale models pore scale models are commonly developed by modifying the lagrangian particle trajectory model based on computational fluid dynamics johnson et al 2018 pazmino et al 2014b rasmuson et al 2019 ron et al 2019 vanness et al 2018 for darcy scale models the transport of nps in porous media is described by advection dispersion equations the deposition and release of nps is represented by coupling the transport equation of the solution chemistry as np deposition and release is dependent on the solution is bradford et al 2015 2012 mesticou et al 2014 tosco et al 2009 darcy scale models are widely used to investigate np transport and release behaviors in the laboratory and the field however these models are limited to the investigation of np transport and release in homogenous media heterogeneity is an intrinsic property of aquifers producing non uniform flow fields with widely varying velocities in the aquifer previous studies have indicated that the heterogeneity of porous media has an important impact on the transport and fate of solutions and nps bai and li 2012 berkowitz et al 2000 2006 skopp et al 1981 seuntjens 2002 zhan 1998 developed a stochastic model to investigate contaminant transport behaviors in a strongly heterogeneous stratified formation in different waste leakage scenarios and found that the heterogeneity significantly influenced both the concentrations and variances of concentration distributions zhou et al 2018 developed transport models with scale dependent and independent dispersion schemes to describe reactive solute transport in a stratified system their results indicated that diffusion in the low permeable layers could not be neglected and the diffusion coefficients in the low permeable layers were dependent on the advective time in the high permeable layer recently several studies have investigated the transport and release of nps in heterogeneous media dong et al 2019 2016 zhao et al 2019 dong et al 2016 conducted a series of go transport and release experiments in two layer heterogeneous sand columns in their experiments two peaks were observed in the breakthrough curves btcs during the go transport processes the second peak represented the impact of the heterogeneity the release process indicated that the mobility of go decreased with increasing is and the previously retained particles were released by reducing the solution is two peaks were also observed in the btcs of go during the release process to interpret the observed data dong et al 2016 applied a one dimensional 1 d double domain model to fit the experimental data however the 1 d double domain model has two deficiencies first the 1 d double domain model does not consider the release of go with decreasing is as mentioned above the particle grain surface interaction energies are strongly affected by the solution is thus np transport and release involves the co transport of electrolyte solute es and nps tosco et al 2009 as a result the impact of heterogeneity on np release will be more notable and complex second the 1 d double domain model neglects transverse dispersion and uses a constant mass transfer coefficient to represent the interaction between two zones a recent study liang et al 2019 indicated that the concentration gradients along the transverse direction are non negligible when there is a discrepancy between the péclet numbers in the two domains the mass exchange between the two zones is induced by the difference in the properties of the two zones and determined by the transverse dispersion across the interface this suggests that a two dimensional 2 d model considering the transverse dispersion is more appropriate for describing solute transport in layered heterogeneous media than the 1 d model for homogeneous media a few models have been proposed to describe the transport and release of nps as previously described for heterogeneous layered media however while the existing models can be used to simulate the np transport and retention processes they cannot be used to describe the release process under transient chemistry conditions e g dong et al 2016 2019 in this study a numerical model was developed to provide insight into the transport and release behaviors of nps in layered media and to understand the impacts of media heterogeneity on the np transport and release in this model a heterogeneous medium was formed from two layers of porous media the np transport in each layer was described by a 2 d advection dispersion equation ade while the mass interaction between the two layers was represented using the continuity of concentration and mass flux across the interface the np deposition and release processes were related to the is of the electrolyte solution in the media and were described by the reversible and irreversible deposition terms in the ades the is for each layer was obtained by solving a 2 d ade describing the electrolyte solution transport in the medium the effects of heterogeneity were investigated based on the proposed model the proposed model was applied to laboratory go transport and release experiments the remainder of this paper is organized as follows the mathematical model and numerical solution are presented in section 2 the results are described and discussed in section 3 the numerical model is applied to laboratory experimental data in section 4 finally a summary and conclusions are presented in section 5 2 methodology 2 1 problem a schematic diagram of np transport and release in a semi infinite layered heterogeneous porous medium is shown in fig 1 the thicknesses of the upper and lower domains are b 1 and b 2 respectively the materials comprising the two domains are different which leads to different permeabilities pore water velocities dispersion coefficients and deposition and release rates for np transport in the two domains the permeability of the upper domain is assumed to be lower than that of the lower domain thus the upper and lower domains are referred to as the slow flow domain sfd and the fast flow domain ffd respectively to investigate np transport and release in layered porous media we assumed that nps with a constant concentration were injected into the medium at the inlet for a certain amount of time after which the solute is in the medium was reduced to observe the np release behavior this conceptual model was designed based on np transport and release experiments dong et al 2016 zhao et al 2019 the layered medium was initially saturated with a high concentration electrolyte solution e g 100 mm nacl creating relatively strong surface adhesion for np deposition the modeling process for the transport and release of nps in this study included three phases i both an np suspension with a constant concentration c 0 and es with a high concentration c t 0 are injected into the layered medium at the inlet x 0 during the period from t 0 t1 and part of the nps are deposited on the grain surfaces and grain grain contacts of the porous medium this phase is called the deposition phase ii es with the same concentration c t 0 but without nps is injected into the layered medium after the deposition phase during the period from t t 1 t2 this phase is called the elution phase iii finally deionized di water is injected into the layered medium the is in the layered medium begins to decrease and the np grain surface adhesion also decreases gradually the nps retained in the layered medium during the previous two phases are partially released to the pore water this phase is called the release phase 2 2 numerical modeling based on the conceptual model described above a two domain mathematical model was used to describe the np transport and release in the layered heterogeneous porous medium the governing equations can be expressed as two 2 d ades with reversible and irreversible deposition terms hendry et al 1997 ma et al 2017 tosco et al 2009 dong et al 2016 as follows 1a c 1 t s 1 r t s 1 i r t d x 1 2 c 1 x 2 d y 1 2 c 1 y 2 v 1 c 1 x 1b c 2 t s 2 r t s 2 i r t d x 2 2 c 2 x 2 d y 2 2 c 2 y 2 v 2 c 2 x where the subscripts 1 and 2 refer to the sfd and ffd respectively c is the np concentration in pore water m l 3 v is the pore water velocity l t d x and d y are the np longitudinal and transverse dispersion coefficients l 2 t respectively further s r t represents the reversible deposition term where s r is the concentration of nps reversibly retained on the porous medium m l 3 this term describes the process in which nps are deposited on the porous medium when the is is high and are released into the pore water from the medium when the is decreases in addition s ir t represents the irreversible deposition term where s ir is the concentration of nps irreversibly retained on the porous medium m l 3 this term describes the process in which a part of the nps deposited on the porous medium cannot ever be released in this study we focus on the np transport and fate in layered media the flow fields were assumed to be steady state and uniform in each domain the constant fluid velocities v 1 and v 2 for each domain were assigned directly each domain has a different velocity induced by the heterogeneous layered medium this assumption has commonly been made to describe solute transport in layered media in previous studies e g lv et al 2016 dong et al 2016 2019 liang et al 2019 this assumption is valid for the case of a constant hydraulic gradient which can be achieved by imposing constant hydraulic heads on the two sides of the layered medium bai and li 2012 moreover the dispersion coefficients are assumed to be scale independent in this model which is reasonable based on the previous studies e g zhou et al 2018 the reversible and irreversible deposition terms in the two domains can be expressed as follows hendry et al 1997 ma et al 2017 in the sfd 2a s 1 r t 1 s 1 r x 1 k d 1 r c 1 k r 1 r s 1 r 2b s 1 i r t k d 1 i r c 1 in the ffd 2c s 2 r t 1 s 2 r x 2 k d 2 r c 2 k r 2 r s 2 r 2d s 2 i r t k d 2 i r c 2 where k d r and k r r are the np reversible deposition and release rate respectively 1 t x is the maximum concentration of nps reversibly retained on the porous medium m l 3 and k d i r is the np irreversible deposition rate 1 t the sfd has a lower permeability and higher filtration capacity than the ffd therefore k d 1 r and x 1 are larger than k d 2 r and x 2 respectively moreover the lower flow velocity in the sfd results in weaker hydrodynamic drags therefore k r 1 r is smaller than k r 2 r according to the dlvo theory np deposition and release processes are largely dependent on the is therefore k d r k r r and x are commonly expressed as semi empirical functions of c t bianco et al 2016 tosco et al 2009 in the sfd 3a k d 1 r k d 1 r 0 1 c d c 1 c t 1 β a 1 3b k r 1 r k r 1 r 0 1 c t 1 c r c 1 β d 1 3c x 1 γ s 1 c t 1 β s 1 in the ffd 3d k d 2 r k d 2 r 0 1 c d c 2 c t 2 β a 2 3e k r 2 r k r 2 r 0 1 c t 2 c r c 2 β d 2 3f x 2 γ s 2 c t 2 β s 2 where c t is the es concentration n l3 which is typically used to represent the solution is k d r 0 c d c β a k r r 0 c r c β d γ s and β s are empirical coefficients among these coefficients k d r 0 k r r 0 and γ s are linearly proportional to k d r k r r and x respectively of these k d r 0 represents the intrinsic reversible deposition rate of the porous medium k r r 0 represents the intrinsic release rate of the porous medium and γ s represents the maximum reversible deposition of the porous medium both k d r 0 and γ s generally increase with decreasing median grain size of the porous medium ma et al 2018 xu et al 2006 sun et al 2015 while k r r 0 increases with increasing flow velocity ma et al 2017 based on the above equations both k d r and x increase with increasing c t while k r r decreases with c t these relationships reflect the mechanism in which the surface adhesion between the nps and grains increases with increasing is based on the conceptual model the initial and boundary conditions of the np transport can be expressed as follows 4a c 1 x y t 0 c 2 x y t 0 0 4b c 1 x 0 y t c 2 x 0 y t c 0 t t 1 0 t t 1 4c c 1 x x y t x c 2 x x y t x 0 4d c 1 y x y t y b 1 c 2 y x y t y b 2 0 where c 0 is the np injection concentration based on continuity of the concentration and mass flux across the interface the interface conditions of the two domains at y 0 can be expressed as follows 5a c 1 x y 0 t c 2 x y 0 t 5b θ 1 d y 1 c 1 y x y t y 0 θ 2 d y 2 c 2 y x y t y 0 where θ is the porosity l 3 l 3 as described in section 2 1 di water is injected into the porous medium instead of es in the release phase as a result the is in the layered medium gradually decreases similar to the np transport the es transport in the layered medium can be described by the following two 2 d ades 6a c t 1 t d x t 1 2 c t 1 x 2 d y t 1 2 c t 1 y 2 v 1 c t 1 x 6b c t 2 t d x t 2 2 c t 2 x 2 d y t 2 2 c t 2 y 2 v 2 c t 2 x where d xt and d yt are the es longitudinal and transverse dispersion coefficients l 2 t respectively in this study we focus on the impacts of heterogeneity on the np transport and assume that the es dispersion coefficients are equal to the np dispersion coefficients which has also been assumed in some previous studies xu et al 2006 tosco et al 2009 tosco and sethi 2010 the initial and boundary conditions for es transport in the layered media can be written as follows 7a c t 1 x y t 0 c t 2 x y t 0 0 7b c t 1 x 0 y t c t 2 x 0 y t c t 0 t t 2 c t r t t 2 7c c t 1 x x y t x c t 2 x x y t x 0 7d c t 1 y x y t y b 1 c t 2 y x y t y b 2 0 where c tr is the concentration of es at the inlet in the release phase n l3 this concentration should be equal to zero because we are assuming that only di water is pumped into the layered medium during the release phase however k a m cannot be correctly calculated if c tr 0 therefore we replaced c tr 0 with c tr 0 1 mm in the modeling which was also adopted in tosco et al 2009 for the purpose of mathematical convenience we transformed eqs 1 7 into dimensionless forms appendix the definitions of the dimensionless variables are summarized in table 1 the effluent np concentration in the layered medium can be written as the average concentration along the y direction at a fixed x d more specifically the dimensionless np concentrations for the sfd ffd and both domains can be written as follows 8a c a 1 d 0 1 c 1 d d y d 8b c a 2 d b d 0 c 2 d d y d b d 8c c ad p 1 0 1 c 1 d d y d p 2 θ d b d 0 c 2 d d y d p 1 p 2 θ d b d where the subscript d denotes dimensionless terms hereinafter the dimensionless mass fluxes between the two domains can be written for np and es respectively as follows 9a r p c 1 d y d x d y d t d y d 0 9b r t c t 1 d y d x d y d t d y d 0 where positive r p and r t represent the np and es respectively migrating from the ffd into the sfd and vice versa the mathematical models for the np transport and release and es transport were numerically solved using comsol multiphysics the convection diffusion equation module in the mathematics classical pdes menu was used to simulate the np and solute transport two convection diffusion equations are coupled to model the np and solute transport in the sfd and ffd the interface mass transfer is represented by the continuity of concentrations and mass fluxes across the interface eqs 5a and 5b which is handled by comsol itself nothing else needs to be done for this boundary for the numerical treatment the semi infinite geometry size 0 x d was replaced by a finite range 0 x d 10 to represent the infinite boundary x d an infinite element domain was added at x d 10 which is a component of comsol and is designed to represent infinite geometry the two domains were discretized into triangular mesh elements to ensure sufficient accuracy of the obtained solutions elements near the interface of the two domains and at the left boundary were refined with a minimum element size of 0 00315 the maximum growth rate is 1 3 for the element size the number of triangular elements was 78 760 a total of 2400 constant time steps were analyzed with a total simulation time of t d 1 2 3 results and discussion 3 1 effects of layered heterogeneity to gain insight into the impacts of the differing sfd and ffd properties on np transport and release we conducted three simulations with different péclet numbers for the sfd p 1 and ffd p 2 as described in table 2 for convenience of the discussion we assume an sfd with a fixed p 1 5 and an ffd with p 2 5 20 o r 30 the deposition and release parameters k d r 0 d k r i r d k r r 0 d and γ s d are relative to the péclet numbers therefore we assume these parameters are constants for the sfd and vary with p 2 for the ffd more specifically k d r 0 d k d i r d and γ s d decrease with increasing péclet number because porous media with high péclet numbers typically have high permeability and low filtration capacity in contrast k r r 0 d increases with increasing péclet number a high péclet number represents a rapid pore fluid flow and strong hydrodynamic drag which facilitate the release of nps the values of k d r 0 d k d i r d γ s d and k r r 0 d for different péclet numbers are summarized in table 2 the other deposition and release parameters used in the models are fixed and are presented in table 2 the other parameters for the models are b d θ d 1 and d xd d yd 1 4 and 6 for p 2 5 20 a n d 30 respectively the injected dimensionless concentrations of np and es vary with time at the inlet in the deposition phase 0 t d 0 1 nps with a concentration of ctd xd 0 1 suspended in an es concentration of ctd xd 0 1 were injected into the layered media in the elution phase 0 1 t d 0 3 the np free cd xd 0 0 es with a concentration of ctd xd 0 1 was injected into the layered media finally in the release phase t d 0 3 di water ctd xd 0 0 and c td r 0 001 was injected into the layered media fig 2 a shows the btcs for the combination of both domains c ad with different p 2 two peaks are observed in the btcs the first peak corresponds to the np transport in the media at high is during the deposition and elution phases 0 t d 0 3 the second peak corresponds to the release of the reversibly retained nps when the is decreases during the release phase t d 0 3 for the cases with a greater contrast in properties between the two domains larger p 2 c ad is higher in the deposition and elution phases owing to the smaller deposition parameters of the ffd k d 2 r 0 d k d 2 i r d and γ 2 s d and the shorter residence time of the nps in the ffd in addition the remarkable increase in c ad implies that fewer nps are deposited on the media during this period as a result fewer nps will be released in the release phase and thus c ad is generally lower for the second peak moreover the emergence of the second peak occurs much earlier owing to the higher transport speed of the released nps in the ffd when p 2 is larger this indicates that the preferential pathway markedly accelerates the overall np transport in porous media these phenomena indicate that the heterogeneity has significant impacts on the transport and release of nps to further investigate the impacts of heterogeneity the np transport and release behaviors in each domain will be discussed below fig 2b and c show the btcs for the sfd c a 1 d and ffd c a 2 d respectively with different values of p 2 fig 2b and c show that c 2 a d is generally closer to c ad than c 1 a d owing to the rapid flow in the ffd in the deposition and elution phases both c a 1 d and c a 2 d increase with increasing p 2 especially for c a 2 d where the increase is significant as discussed above the higher c a 2 d results from the higher media filtration capacity and shorter np residence time in the ffd when p 2 is larger the higher c a 2 d represents a higher suspended np concentration in the ffd implying that more of the nps in the ffd can enter the sfd forced by the transverse dispersion this results in an increase in c a 1 d with increasing p 2 even though sfd has fixed p 1 and deposition parameters fig 2b in addition the higher c a 2 d implies that the amount of nps retained in the ffd is smaller during the deposition and elution phases thus fewer nps in the ffd will be released into the pore water during the release phase with a larger p 2 in the release phase the profiles of the three btcs in the sfd are similar except that the curve is shifted slightly to the left when p 2 5 indicating that the rapid transport in the ffd might affect the np transport and release in the sfd unlike the sfd the profiles of the three btcs in the ffd are very different fig 2b for large p 2 the emergence of the peak is early and the concentration rapidly climbs to the peak and then decreases to a low value within a short time this phenomenon is ascribed to the fast transport speed and high release rate k r r d in the ffd when p 2 is large fig 2c also shows that for the larger p 2 the total amount of nps released from the ffd is small because the amount of nps retained in the ffd in the deposition phase is less in addition extended tailings are clearly observed in the btcs for the ffd when p 2 5 implying that the concentration of suspended nps in the sfd is higher than that in the ffd after t d 0 6 and part of the nps in the sfd migrate into the ffd 3 2 spatiotemporal distribution of nps in heterogeneous porous media to further investigate the impacts of heterogeneity on the transport and release of nps spatial distributions of the dimensionless np concentration c d dimensionless reversible deposition s r d and es concentration c t in the layered media p 1 5 p 2 20 at different dimensionless times t d 0 1 0 3 and 0 7 are shown in fig 3 the other parameters are the same as for the case with p 1 5 p 2 20 in fig 2 fig 3a shows that a larger number of suspended nps migrate into the ffd at t d 0 1 owing to the larger flow rate relative to the sfd the suspended nps in the sfd exhibit a significant concentration gradient along the y direction thus part of the suspended nps in the ffd will migrate into the sfd via the transverse dispersion mechanism the transverse dispersion also causes a non uniform distribution of the np concentration in the sfd near the interface of the two domains unlike the suspended nps the amount of retained nps is less in the ffd than in the sfd fig 3d with increasing time t d 0 3 c d in both the sfd and ffd declines to 0 indicating that almost all of the suspended nps have been deposited on the porous media similar to t d 0 1 a greater amount of nps are deposited in the sfd relative to the ffd due to the higher filtration capacity in the sfd after t d 0 3 di water is injected into the media instead of high concentration es as a result the is in the media gradually declines inducing the release of the reversibly retained nps the released nps in both the sfd and ffd at t d 0 7 are shown in fig 3c fig 3c clearly shows that the release of the retained nps is faster in the ffd than the sfd owing to a higher intrinsic release rate and lower is in addition owing to the high flow rate in the ffd the nps in the ffd have been transported a greater distance from the inlet in contrast the concentration of nps near the inlet in the sfd is much higher compared to that in the ffd as a result part of the nps in the sfd migrate into the ffd in this zone via the transverse dispersion mechanism the transverse migration from the sfd to ffd results in extended tailing in the btcs for the ffd fig 2c moreover in the zone away from the inlet part of the nps in the ffd migrate into the sfd due to the fast transport of nps in the ffd in the release phase the released nps will re deposit on the media when they encounter the high is solution fig 3f shows the distribution of np deposition in the layered media the amount of retained nps in the sfd is greater than that in the ffd owing to the higher intrinsic deposition rate and the generally higher is in the sfd high deposition is observed near the interface in the sfd in the zone away from the inlet fig 3f indicating that a large amount of nps are retained in this area when they migrate into the sfd from the ffd this phenomenon can be ascribed to i the high intrinsic filtration capacity of the sfd and ii the high k d r d and low k r r d due to the high is in this area based on the above analysis the np release process involves the transport of both es and nps therefore during the release phase the impacts of heterogeneity on the np behaviors are much more complex than these impacts during the deposition and elution phases first the heterogeneity affects the transport of nps via the transverse dispersion mechanism between the two domains second the heterogeneity also affects the transport of es as mentioned above the deposition and release rates are largely determined by the is of the solution therefore the es transport in layered heterogeneous media controls the process of np release and re deposition to discuss the impacts of heterogeneity on np behaviors during the release phase in more detail the np release in the layered medium p 1 5 p 2 20 is compared with that in two homogeneous media referred to as hom1 and hom2 hom1 has a small péclet number p 1 p 2 5 while hom2 has a large péclet number p 1 p 2 20 the other parameters of hom1 and hom2 are same as those for the sfd and ffd in the layered medium fig 4 shows the spatial distributions of c d s r d and c t at t d 0 7 for hom1 hom2 and the layered medium fig 4b shows that the transport of nps in the ffd is slower than that in hom2 fig 4g there are two reasons for this phenomenon first part of the released nps in the zone near the inlet in the sfd migrate into the ffd slowing down the np transport in the ffd second the is in the sfd near the outlet is higher than that in the ffd and thus the es in the sfd migrates into the ffd owing to the transverse migration of es the is in the ffd fig 4f is generally higher than that in hom2 fig 4i as previously mentioned the release rate is small when the is is high therefore the release of nps in the ffd is slower than that in hom2 3 3 mass transfer at the two domain interface the heterogeneity of a layered medium will cause significant mass transfer between the two domains which will further affect the transport and release of nps to investigate the mass transfer pattern the dimensionless mass flux of nps r p and es r t across the interface of the two domains are displayed in fig 5 at different times the parameters are the same as the case of p 1 5 and p 2 20 in fig 2 fig 5a shows that positive r p were observed near the left boundary at t d 0 1 indicating that nps in the ffd migrate into the sfd after t d 0 1 without the continuous injection of nps from the inlet r p sharply declines and becomes negligible in the whole interface at t d 0 3 indicating that the mass transfer between the two domains is very weak in the release phase t d 0 3 the mass fluxes are negative near the inlet and positive away from the inlet indicating that nps in the sfd migrate into the ffd near the inlet and the inverse pattern occurs near the outlet with respect to r t fig 5b during 0 t d 0 3 r t is equal to 0 because the c t in the two domains are equal after t d 0 3 r t is always less than zero indicating that es in the sfd continuously enter the ffd the area where the mass transfer between the two domains occurs becomes wider with increasing time because the es in the ffd gradually migrates out 4 application to laboratory experiments in this section the proposed model was employed to interpret the measured btcs for go transport and release from a series of laboratory experiments conducted in six sand columns referred to as s1 s6 by dong et al 2016 each column had a diameter of 2 5 cm and a height of 15 cm each column was separated into two identical domains along the longitudinal direction by placing a thin walled acrylic plate in the center of the column two types of quartz sand with different median grain diameters finer and coarser sands were packed in the two domains to construct the sfd and ffd of the layered heterogeneous media respectively the grain diameters d g of the packed sands for the six columns are presented in table 3 each column was first saturated with a particle free 20 mm solution of nacl the breakthrough experiment was conducted by injecting a go suspension for approximately 40 min followed by elution with a particle free solution of 20 mm nacl after 100 min di water was pumped into the column to remobilize the previously retained particles until the effluent go concentration was not measurable effluent samples were collected every two minutes using a fraction collector at the column outlet the go concentrations in the samples at different times were measured using a uv 2000 spectrophotometer to obtain the btcs for the experiments the measured btcs for the go transport and release from the six columns were fitted using the model proposed in the present study fig 6 the go transport and release parameters were estimated by minimizing the sum of the squared differences between the calculated and measured go concentrations the estimated parameters are summarized in table 3 six parameters v d x k d r 0 k r r 0 k d i r 0 and γ s for each layer were estimated by fitting the observed btcs these parameters are closely related to the heterogeneity of the porous medium and weakly related to the solute chemistry conditions their values were estimated using the levenberg marquardt algorithm which is implemented using an l m least squares code in matlab gavin 2013 the numerical model built with comsol is transformed to a matlab function and the parameter estimation is implemented using the module comsol with matlab the other parameters c d c c r c β a β d and β s are commonly used to describe the impacts of the solute is on np retention and release therefore the values of these parameters were obtained by referring to a previous study tosco et al 2009 and are c d c 247 m m c r c 1 3 m m β a 0 5 β d 2 5 and β s 0 54 for both the sfd and ffd fig 6 shows that there is good agreement between the modeling and experimental data in the three phases in all cases as mentioned above the btcs were fitted using the 1 d double domain model in dong et al 2016 comparing the fitting results of the 1 d and 2 d models reveals that the 2 d model fitted the observed btcs better than the 1 d model for all columns during the deposition and elution phases this is because the 1 d model neglects the transverse dispersion and uses a constant mass transfer coefficient to approach the interaction between the two zones in addition because it does not consider the np release with decreasing is the 1 d model is not capable of fitting the experimental data during the release phase fig 6 shows that all of the btcs have two peaks during the release phase t 100 min indicating the effects of the layered heterogeneity on the go more specifically the first peak of the release phase represents the go release from the ffd due to the more rapid flow and release in this domain while the second peak represents the go release from the sfd due to the slower flow and release in this domain when the difference between the properties of the two domains increased the second peak lagged farther behind the first peak in the release phase and the amplitude of the second peak decreased considerably e g for s3 and s6 these phenomena are a result of the increase in the discrepancy between the flow velocities and filtration capacity of the two domains 5 conclusions in this study the transport and release of nps under conditions of a transient solution is in a layered heterogeneous medium were investigated a 2 d numerical model describing the np transport and release was developed the layered heterogeneous porous medium consisted of an sfd and an ffd the np transport in each layer was described by a 2 d ade and these were coupled by the continuity of concentration and mass flux across the interface between the two domains np deposition and release behaviors were described by reversible and irreversible deposition terms which coupled the ades the impacts of the transient solution is on the particle deposition and release were characterized by is dependent deposition and release rates the proposed model was applied to laboratory np transport and release experiments the conclusions can be summarized as follows 1 the impacts of layered heterogeneity on np release and transport are complex because the np release and transport involved co transport of es and nps it was necessary to employ a 2 d model to visually display the complex transport patterns 2 in the deposition and elution phases the increase in the np concentration in the ffd with increasing péclet numbers of the ffd results in a greater amount of nps migrating into the sfd and thus an increase in the np concentration in the sfd a greater amount of nps are deposited in the sfd relative to the ffd owing to the higher filtration capacity of the sfd 3 the retained nps in both the sfd and ffd will be released when the is declines as a result of the injection of deionized water into the medium the release of the retained nps in the ffd is faster than that in the sfd because the ffd has a higher intrinsic release rate and lower is due to the more rapid transport of es in the ffd 4 the mass transfer of nps between the two domains varies with the location of the interface nps in the sfd migrate into the ffd near the inlet and inversely near the outlet the np migration from the sfd to ffd becomes dominant when a majority of the nps in the ffd are transported out resulting in a long tail in the btcs for the ffd 5 the proposed model was in good agreement with the experimental breakthrough curves in both the np transport and release phases the proposed model matched the experimental breakthrough curves better than the double region model and it is capable of fitting the np release which cannot be accomplished with the double region model the proposed model could be used to investigate np transport and release in layered heterogeneous media in 2 d spaces and to interpret the btcs observed in laboratory experiments author contributions jin liu performed research and wrote the paper xiankui zeng enze ma designed research and revised the paper jichun wu you kuan zhang reviewed and edited the paper yuanyuan sun xiuyu liang analyzed data chunmiao zheng provided resources for laboratory and numerical experiments declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was partially supported by research grants from the national natural science foundation of china 41730856 41977165 41830861 and the guangdong provincial key laboratory of soil and groundwater pollution control 2017b030301012 we thank the anonymous reviewers for their constructive comments the manuscript has been significantly improved by incorporating their suggestions appendix a dimensionless governing equations for nanoparticle and electrolyte solute transport the system of equations can be rewritten in dimensionless form by introducing the following dimensionless variables table 1 the dimensionless governing equations for np transport and release are written as follows for np transport in the sfd a1a c 1 d t d s 1 r d t d s 1 i r d t d p 1 c 1 d x d 2 c 1 d x d 2 2 c 1 d y d 2 a1b s 1 r d t d 1 s 1 r d x 1 d k d 1 r d c 1 d k r 1 r d s 1 r d a1c s 1 i r d t d k d 1 i r d c 1 d for np transport in the ffd a1d c 2 d t d s 2 r d t d s 2 i r d t d p 2 c 2 d x d d xd 2 c 2 d x d 2 d yd 2 c 2 d y d 2 a1e s 2 r d t d 1 s 2 r d x 2 d k d 2 r d c 2 d k r 2 r d s 2 r d a1f s 2 i r d t d k d 2 i r d c 2 d where k d r d k d r 0 d 1 c d c d c td β a k r r d k r r 0 d 1 c td c r c d β d and x d γ s d c td β s the interface conditions are as follows a2a c 1 d x d y d 0 t d c 2 d x d y d 0 t d a2b c 1 d y d x d y d t d y d 0 θ d d yd c 2 d y d x d y d t d y d 0 the initial and boundary conditions are a3a c 1 d x d y d t d 0 c 2 d x d y d t d 0 0 a3b c 1 d x d 0 y d t d c 2 d x d 0 y d t d c d 0 t t 1 d 0 t t 1 d a3c c 1 d x d x d y d t d x d c 2 d x d x d y d t d x d 0 a3d c 1 d y d x d y d t d y d 1 c 2 d y d x d y d t d y d b d 0 the dimensionless governing equations for the es transport can be written as follows a4a c t 1 d t d 2 c t 1 d x d 2 2 c t 1 d y d 2 p 1 c t 1 d x d a4b c t 2 d t d d xd 2 c t 2 d x d 2 d yd 2 c t 2 d y d 2 p 2 c t 2 d x d the interface conditions are a5a c t 1 d x d y d 0 t d c t 2 d x d y d 0 t d a5b c t 1 d y d x d y d t d y d 0 θ d d yd c t 2 d y d x d y d t d y d 0 the initial and boundary conditions are a6a c t 1 d x d y d t d 0 c t 2 d x d y d t d 0 0 a6b c t 1 d x d 0 y d t d c t 2 d x d 0 y d t d 1 t t 2 d c td r t t 2 d a6c c t 1 d x d x d y d t d x d c t 2 d x d x d y d t d x d 0 a6d c t 1 d y d x d y d t d y d 1 c t 2 d y d x d y d t d y d b d 0 
5501,data driven models for streamflow forecasting have attracted considerable attention as they are independent of physical system features the physical features of the river basin are extremely hard to collect especially for large rivers empirical data driven models such as stochastic and regression models have been widely used in the field of streamflow forecasting however they suffered limited accuracy in predicting extreme streamflow they also required raw data pre processing prior to the modeling process especially for lengthy data records and for large time scale increments e g monthly resolution to overcome these challenges data driven forecasting models based on artificial intelligence ai have been widely used and resulted in enhancing the forecasting accuracy nevertheless ai based models required augmentation with proper optimization schemes to adjust the model parameters for optimal accuracy furthermore in some cases due to unsuitability of the optimization model there is high possibility for overfitting of the ai model which might cause poor prediction of input patterns that were not adequately mimicked this study introduces a new approach to streamflow forecasting based on nonlinear system identification the proposed technique employs fast orthogonal search fos to develop a nonlinear model of stream flow the main advantage of using fos is eliminating the requirement of raw data pre processing and the need for an optimization scheme for model parameter adjustment since the fos algorithm takes this into account while building the model in addition the fos algorithm includes a pole zero cancellation procedure that can detect and avoid the over fitted models the fos based nonlinear modeling approach was adopted in this research for the development of a streamflow forecasting model at aswan high dam using monthly basis natural streamflow records for 130 years the results indicated that the proposed fos algorithm outperformed the previously developed ai models of streamflow forecasting for large data records and for large time scale increment monthly resolution keywords nonlinear system identification streamflow forecasting aswan high dam river nile multi lead forecasting 1 introduction to have optimal water resource management and planning it is vital to have an accurate forecasting model for streamflow streamflow forecasting provides the necessary information for understanding and estimation of suspended sediment generation of hydropower design of a proper irrigation system for particular crop patterns and optimal release policy from reservoirs kisi and cimen 2011 liu et al 2014 liu et al 2018 terzi and ergin 2013 wu et al 2009 2005 in addition having long term accurate streamflow forecasting provides the decision makers of water resources with valuable machination to reduce side effects of flooding on infrastructure and human life box and jenkins 1970 kagoda et al 2010 kalman et al 1960 kisi 2010 salas et al 1980 shiri and kisi 2010 valipour et al 2012 valipour 2015 allawi et al 2017 utilized the modified co active neuro fuzzy inference system canfis model for reservoir inflow forecasting the modified canfis model has been compared to other data driven models the authors found that the canfis model is better than other models in providing high forecasting accuracy streamflow the problem of streamflow forecasting can be generally formulated in the nonlinear system identification problem chen and dyke 2007 danandeh mehr 2018 the main drawback of using ai modeling techniques such as adaptive neuro fuzzy inference system anfis and ann is the variation of the forecasting model performance based on the complexity of the modeled system in fact unpretentious models comprising fewer parameters and simple mathematical procedures e g ordinary least squares solution typically might be more appropriate for streamflow forecasting billings 2013 in the last three decades several streamflow forecasting models were developed based on various methods conventional methods cms such as autoregressive ar moving average and autoregressive moving average arma modeling have been examined in several cases these methods exhibited considerable potential for accurate forecasting of medium streamflow classes billings 2013 chen and dyke 2007 clark et al 2008 husain 1985 kalman et al 1960 moradkhani et al 2005 noureldin et al 2007 schreider et al 2001 valipour et al 2012 veiga et al 2014 however it has been reported that there are several drawbacks in developing these models clark et al 2008 el shafie et al 2012 husain 1985 ju et al 2009 maier et al 2004 noureldin et al 2011 2007 schreider et al 2001 the main meagerness associated streamflow forecasting models based on cms is the stipulation to integrate it with a pre formulation of the trustful stochastic model to ascertain the source of uncertainty for the model input and output moreover cms require erstwhile analysis of the raw data related to the covariance between the mode variables in the last two decades ai streamflow forecasting models were introduced to overcome the drawbacks of cm based models ai methods mimic a complex time series with its nonlinear modeling capabilities which is the major feature of any historical streamflow record asadi et al 2013 balestrassi et al 2009 graves and pedrycz 2009 han and qiao 2013 ju et al 2009 additionally the development of the streamflow forecasting model using ai methods does not require pre formulation and analysis of the stochastic pattern for the raw streamflow data to be modeled these requirements are mandatory for the development of streamflow forecasting models using cms danandeh mehr et al 2013 el shafie et al 2008a graves and pedrycz 2009 guo et al 2011 jothiprakash and magar 2012 katambara and ndiritu 2010 kisi et al 2012 sang 2013 whigham and crapper 2001 yaseen et al 2015 nevertheless the ai model encountered numerous disputes in its architecture because of the need to inaugurate it with a proper pre treatment method for data noise reduction additionally the process of ai modeling requires an optimization procedure for its parameters to enhance the forecasting accuracy labat 2005 maier and dandy 2000 nourani et al 2014 sang 2013 in the last 5 years the authors introduced several ai models for streamflow forecasting at aswan high dam ahd these models included anfis radial basis function neural network high order response surface method hors and multi layer perceptron neural network with the ensemble procedure allawi and el shafie 2016 el shafie and noureldin 2011 keshtegar et al 2016 these models revealed appropriate prospective to achieve moderate accuracy for streamflow forecasting especially for most of the peak events at ahd noticeably these ai models had a worthwhile tendency of mimicking the input output pattern in circumstances that with no need for inclusion of any other influence parameters affecting the streamflow although these ai models proved to be proficient they are considered to be sub optimal search techniques because of the slow convergence of the forecasting model during training calibration in most of the ann models developed the back propagation algorithm was used for optimizing the ann key parameters elzwayie et al 2016 the back propagation algorithm experienced several drawbacks such as local optima and slowness there are many advanced methods offered by researchers to partially overcome these drawbacks especially the local optima such as particle swarm optimization and genetic algorithms gas however these optimization algorithms introduced other challenges such as overfitting of the streamflow forecasting model accordingly the ai streamflow forecasting models were unable to generalize and maintain consistent accuracy for the examined data patterns the limitations of the cms and ai based streamflow forecasting models motivated the search for other methods to establish robust stream forecasting models adaptive fast orthogonal search fos was selected in this research as a robust algorithm for modeling nonlinear systems korenberg 1988 that can be represented by the nonlinear arma model with exogenous inputs narmax billings 2013 korenberg et al 1989 generally fewer terms form the model and thus the selection of model terms one at a time are more convenient for efficient operation of the modeling process this selection technique is achieved in this research using fos to enable the efficient building of the nonlinear auto regression moving average exogenous narmax model for streamflow orthogonal search korenberg 1989 1988 tseng and powers 1993 is a highly efficient technique designed originally for efficient nonlinear system modeling the modeling process is mainly based on gram schmidt orthogonalization algorithm to enable the representation of a system model using an arbitrary set of functions this enhances the accuracy of the system modeling procedure as it offers a wider selection of functions to represent the system model tseng and powers 1993 fos is a modification of the orthogonal search that accelerates the process of system modeling through the elimination of some intermediate procedures inside orthogonal search algorithm korenberg 1988 in this study fos is employed to provide enhanced streamflow forecasting fos selection was motivated by fos s reported capabilities and extensively efficient performance in accurate system modeling korenberg 1989 1988 this research investigates the potential of utilizing the adaptive fast orthogonal search fos method to develop streamflow forecasting model that achieve highly accurate results based on popular indicators to measure the level of error the study mainly focused on the ability of the proposed model to achieve appropriate forecasting accuracy for the streamflow in the large river and large time scale increment monthly resolution the proposed method was applied for the nile river streamflow at ahd for 130 years streamflow data on a monthly basis during the period between 1870 and 2000 one of the major advantages of the proposed fos method is its flexibility in managing the data set to be applicable for different training approaches in this context three different training approaches were examined a comparative analysis with the previous ai models developed by the authors was carried out to assess the contribution of the novel streamflow forecasting technique the rest of the manuscript is arranged in the following fashion section 2 gives the description of the case studies and data sets the subsequent section illustrates the methodology part results and discussions are given in section 4 finally in section 5 we conclude the paper and outline our current lines of research 2 data collection and pre analysis the nile river is approximately 6853 km long flows from the south to the north eastern part of the african continent and covers almost 3 million km2 which is around 10 of the african continent area the nile river runs through 10 countries over 35 of latitude there are two major sources of the nile river systems the first is the white nile which originates from the equatorial lake plateau and the second is the blue nile which stems from the ethiopian highland these two sources are located in humid tropical regions with an annual rainfall of more than 1000 mm however there are two countries located partially in the arid region namely sudan and egypt in fact sudan could be divided into three different regions humid in south semi arid in the middle and arid in the north the main objective of this research is to forecast the natural streamflow pattern for the nile river in egypt at the ahd area demonstrated in fig 1 the high aswan dam is located in the south of egypt with coordinates 23 58 14 n 32 52 40 e consequently it is important to study the above phenomenon at egypt which is located completely in the arid region the average annual precipitation in egypt is typically less than 20 mm around 97 of the egyptian water resources originate outside the border which is mainly dependent on the nile river ninety percent of all water reaching egypt during the peak seasons is received from ethiopian catchment and the remaining 10 is received from the white nile system by contrast during the low streamflow months 30 of the water is received from ethiopian catchment and the rest of the water feed is received from white nile therefore it could be realized that the streamflow at ahd that is located at the south part of egypt almost the entrance of nile river to the egypt border has an extremely variable stochastic pattern the data set used in this research was based on historical natural streamflow data records at ahd for 130 years between 1870 and 2000 these data records were obtained from the nile water authority at the egyptian ministry of water resources and irrigation the data records experienced two different phases of measurement techniques the first phase took place during the period between 1870 and 1902 and the second phase took place over the remaining period of the data set initially the data for the streamflow has been recorded by the general stage discharge table this table was designed from the aswan downstream gage afterwards starting from 1903 the egyptian and sudanese governments constructed several dams and hydraulic structures along the nile river based on these new structures the natural streamflow records at ahd were calculated from the stage discharge relationship at ahd this was followed by fine tuning of the streamflow records to be free from all the losses from the manmade upstream lakes water withdrawn in sudan and the influence of the sennar reservoir the analysis of the data records illustrated in fig 2 indicated that the recorded streamflow values were highly random and stochastic in nature using cms to develop the forecasting model would require examination of the auto correlation sequence for each month and the cross correlation between consequent months however when the proposed model fos is utilized there is no need to examine such correlation analysis or develop a pre formulation for the data time series the degree of fluctuations was computed by using the equation dq o we observed that the fluctuation pattern of streamflow was relatively high where the maximum gradient degree fluctuation ranged between 8 65 and 0 00975 bcm the monthly statistical indices of the ahd streamflow data records were evaluated for the assessment of the proposed streamflow forecasting approach this included the mean xmean standard deviation sx maximum value xmax and minimum value xmin table 1 presents the four proposed indices for each month and the fifth column presents the range which is the difference between xmax and xmin for each month it can be depicted from the table that the september streamflow had the highest xmax and xmin with the wider range while the streamflow records for may had the lowest xmax and xmin accordingly a categorization for the streamflow of each was established based on the xmax values the low category is considered for the months that experienced maximum streamflow values less than 8 0 bcm and the maximum range between the maximum and the minimum streamflow is less than 4 bcm by contrast the high category is taken when the maximum streamflow value is higher than 20 bcm and the maximum range is more than 10 bcm finally the medium category is identified in case the maximum streamflow values and the maximum ranges were located within the ranges of the other two categories the months of august september and october were categorized as high streamflow july november and december were regarded as medium streamflow and the other months were regarded as low streamflow the standard deviation sx values were used to examine the performance of the proposed streamflow forecasting model this is because the standard deviation is typically used to enumerate the values of variation for a particular data set 3 methodology 3 1 narmax modeling using fos the narmax model is defined as 1 y n f y n 1 y n 2 y n n y x n d x n d 1 x n d n x e n 1 e n 2 e n n e e n where y n x n and e n are the system output input and noise sequences respectively n y n x and n e are the maximum lags for the system output input and noise respectively f is some nonlinear function and d is a time delay typically set to d 1 the model is essentially an expansion of past inputs outputs and noise terms in this research the noise terms e n 1 e n 2 e n n e are neglected to simplify the modeling process hence the narmax model is reduced to the following form 2 y n f y n 1 y n 2 y n n y x n 1 x n 2 x n n x 1 e n the above model terms and their corresponding coefficients are estimated using the fos algorithm the algorithm uses an arbitrary set of non orthogonal candidate functions p m n and finds a functional expansion of an input y n to minimize the mean squared error mse between the input and the functional expansion the functional expansion of the input y n in terms of the arbitrary candidate functions p m n is given by 3 y n m 0 m a m p m n e n a m m 0 m are the weights of the functional expansion and e n is the modeling error by using non orthogonal candidate functions there is no sole solution for eq 2 however fos could classify the input with fewer model terms than an orthogonal functional expansion korenberg 1989 fos enables the adequate selection of model terms based on the mse reduction introduced by each term the selected term is the one that results in the maximum mse reduction the fos algorithm can be stopped by 1 setting a limitation on the model maximum number of terms 2 setting a pre defined threshold for the minimum ratio between mean square of the input parameters and the mse and 3 examining the mse reduction introduced by each term and stooping when the maximum mse reduction of the remaining term is less than the mse reduction anticipated from a white noise term korenberg 1989 narmax modeling using fos is accomplished by selecting candidate functions pm n that are combinations of delayed versions of inputs and outputs accordingly pm n is given by 4 p m n p x p x x p y p y y p x y p x represents the set all possible terms of the input with different delays and different orders p x x represent the set all possible combinations of the input terms with different delays and different orders p y represents the set all possible terms of the output with different delays and different orders p y y represents the set of all possible combinations of the output terms with different delays and different orders p x y represents the set of all possible combinations of the input terms and output terms with different delays and different orders the maximum delays for the inputs and outputs are determined by the training approach 3 2 model structure as highlighted in the previous section the proposed model is designed to be suitable for forecasting the large time scale of the streamflow data that were allocated in the large river the main reasons for developing the proposed model on monthly basis are as follows first limitation of data availability at a less time increment as the model has been developed using data since the 19th century and includes data for the whole 20th century this due to the fact that during this time the technology for obtaining reliable daily monitoring data for river streamflow was not available second the reason for developing forecasting model for the streamflow at ahd is to provide the decision makers with an accurate tool for better management and operation for the dam which is a monthly operation and management rule according the ahd authority the first step in developing the forecasting model is to study and analyze the data used to select training calibration and testing validation data sets in this context in this study the first 10 years of the streamflow data between 1871 and 1881 had a more stable trend for annual streamflow as illustrated in fig 3 it is essential for the training data to experience most of the streamflow pattern which was clearly observed in the variation of monthly data over the first 10 years and had a higher rate of variations for the second 10 years for the period between 1881 and 1891 as illustrated in fig 4 in this research the forecasting of streamflow is achieved using a polynomial expansion of the historical streamflow that determines the streamflow as a function of the month index hence the forecast model is given by 5 r m n f n m where r m n is the forecasted streamflow of the nth year and month m 1 2 12 and f n m is the polynomial expansion of the nth year as a function of the month index as fos models the pattern of the input data it implicitly performs the aforementioned tasks of transforming and thresholding fos performs thresholding when it evaluates whether the addition of a candidate function will result in sufficient mse reduction specified by a threshold parameter the challenge of non stationary streamflow data fluctuation of the data is addressed by taking windows of streamflow and applying the fos to each window fig 5 is a schematic of the fos algorithm developed in this research the bullets indicate variables or operating parameters that have to be set in the algorithm fos windows the training period data input time series denoted as x n representing streamflow records into smaller analysis windows that can be treated as stationary data each window is analyzed using fos to extract components that represent the candidate function of the true component which is the of the historical streamflow pattern the residual mse threshold value is an important parameter as it is a stopping criterion that can prevent fos from modeling the error terms to avoid the possibility of occurrence of overfitting the output of this stage is the fos model terms which provide information on frequency magnitude and phase for that window of data the fos model terms can then be used to synthesize an estimation of the true component for that window thus creating an accuracy enhanced window denoted as x k n this process repeats for all windows and all of the enhanced windows are recombined to create the overall accuracy enhanced streamflow time series in fact one of the major advantages of the fos algorithm and the proposed structure is the consideration of as much as possible smaller data window size during the training to avoid the complexity that might be experienced because of the non stationary feature within the longer time inputs an intermediate step between the windowing block and the fos detection and synthesis loop is the testing of the data window for non stationarity changes in the streamflow value this would enable true components of particular window to be modeled using a certain set of fos operating parameters whereas the non stationary window can be treated with a different set of operating parameters thus the parameters can be selected to optimally treat these two cases to reduce the likelihood of modeling the value of the streamflow fos is generally attributed to be a data dependent algorithm as it could be noticed from the fos algorithm that uses an arbitrary set of non orthogonal candidate functions pm n and finds a functional expansion of an input y n to minimize the mse between the input and the functional expansion therefore the accuracy of the model achieved by fos depends on one of the following three conditions first the data records being modeled in this study the natural river streamflow second the calculation of the candidate functions used to compute correlations between the input and the candidate function which is a closed form equation and third the stopping condition which is represented by residual mse threshold to allow the model to switch from the training process to the testing process in this context the residual mse threshold is one of the required fos s parameters to be pre defined to start its searching operation however in this study the fos search algorithm is stopped in one of three cases the first case is when a certain maximum number of terms are fitted the second case is when the ratio of mse to the mean squared value of the input signal is below a pre defined threshold the third case is when adding another term to the model reduces the mse below the pre defined performance goal as a result there are only two parameters within the fos algorithm structure that should be selected pre defined before starting the operation of the fos algorithm the performance goal for the mse and the thresholds in this study the performance goal for the mse value has been selected to be 10 4 to avoid the possibility of occurrence of overfitting by contrast the threshold permits fos to model the motion dynamics and reject frequency terms that model the unnecessary noise component in fact the residual mse threshold is considered to be the major fos parameter that has the major impact on the overall model performance several trials have been performed to reach a balanced model that can identify the real features of the input historical streamflow pattern included in the data window during training a residual mse threshold of 0 8 was selected for training approaches finally there is one more parameter that should be pre defined before the start of modeling the window size in fact the smaller the window size is the longer is the time consumption for training the model by contrast the larger window size leads to more complexity in the data window for training to consider non stationary features in this context several trials and errors for the window size selection that ranged between 6 and 24 which represents the range between 6 months and 2 years historical natural streamflow records have been carried out the model performance during training has been examined to identify the suitable window size that could minimize the time consumption during training and minimize the possibility of occurrence for the non stationary components in training data a window size of 10 historical natural streamflows 10 months exhibited the best performance out of all other alternatives 3 3 training approach the cross correlation analysis for the monthly natural streamflow pattern for subsequent years indicated that relatively poor monthly cross correlation if we go more than 1 year behind the forecast year based on this observation the establishment of the forecasting model was based on the previous years streamflow pattern for all training approaches el shafie and noureldin 2011 thus the narmax model was reduced to the nonlinear autoregressive nlar model moreover the assessment of the different training approach can be used later on to determine the accuracy of long term streamflow forecasting that can be achieved by each training approach according to the previous study at ahd it was experienced that the accuracy deteriorates when the forecasting term goes behind 3 months ahead el shafie et al 2006 the model construction starts by building a relation between the vectors of actual streamflow rates of the first year r m 1 and month indices m 1 2 12 fig 6 a illustrates the timeline for the first training approach the model is improved each year by using the previous years to construct the current year flow rate model f n m the model training of nth year is achieved by feeding the actual vectors of flow rates r m n n 1 n 1 to fos system identification algorithm to obtain a polynomial relation between the month index and the streamflow rate hence fos creates a model that describes the curve of the annual readings and this model is updated each year for the second training approach a new model is created after a defined number of years and provides a prediction for a fixed number of years ten years of data were selected for both training and prediction the model training for the nth year is achieved by feeding the vector of flow rates for the previous 10 years i e r m n n n 10 n 1 to fos system identification algorithm to obtain a polynomial relation between the month index and streamflow for the next 10 years therefore fos builds a new model every 10 years independent on the previous models fig 6 b illustrates the testing and training data for 130 years note that the first 10 years were used as input hence the testing period is exactly equal to the training period the third approach is similar to the second one as it uses the data of the previous years for training to predict the current year s streamflow the input in this case is the flow rate of previous 10 years and the output is the flow rate of the next year at the first run the first 10 years are used for training and 11th year is predicted next the 10 years actual starting from the second year to the 11th year are used for training and 12th year is predicted and so on until year 130 fig 6 c illustrates the timeline of the third approach for both training and prediction phases the evaluation of the performance index has been carried out to check the ability of the proposed model to address the forecasted streamflow harmonization with the changes in the streamflow values throughout the testing period 4 model evaluation one of the most important steps in developing a forecasting prediction model is to examine the model s performance for the model s predictive capabilities in this study five performance indicators have been calculated to evaluate the performance of the proposed fos model the reason for selecting these five indicators is the fact that each indicator examines a specific capability of the model the first indicator is the root mean square error rmse which is used to measure the variation between values observed for the variable being modeled and the values predicted by the model the rmse aggregates the individual differences into a single measure of the model forecasting accuracy the second indicator is the normalized rmse nmrse which is the non dimensional form of the rmse normalized root mean square error nrmse examines the model performance by relating the rmse to the mean of the observed actual data the nrmse provides a clear evaluation of the accuracy of the prediction variable relative to the range of its values to examine the power and the course of the linear relationship between the actual and the predicted values the coefficient of determination r2 is used r2 is calculated by dividing the covariance of the predicted and actual values by the product of the standard deviations of those values such this indicator indicates the precision of the linear fitting representation of the variance between the predicted and actual values for evaluation of the efficiency of the proposed model the nash sutcliffe coefficient which is called the efficiency coefficient e was used to analyze the model s capability to achieve a perfect prediction the closer the value of e to 1 the more is the prediction accuracy of the proposed model the relative error re was considered to examine how the outputs of the model are biased with the actual values in addition the re provides the maximum difference between the predicted and actual values which is important for ensuring that the model output error is within the acceptable range furthermore re indicates the error distribution for the validation session and demonstrates how the model is underestimating or overestimating the actual values the last indicator used to examine the performance of the proposed model is the bias bias the bias is a representation of the behavior of the data driven model the long term error where its positive value indicates to overestimation and its negative value indicates underestimation the equations for all the indicators mentioned above are presented hereafter in the same order 6 rmse i 1 n x a i x p i 2 n 7 nrmse rmse x a max x a min 8 r 2 i 1 n x a i x a x p i x p i 1 n x a i x a 2 i 1 n x p i x p 2 2 9 e 1 i 1 n x a i x p i 2 i 1 n x a i x a 2 10 r e x p x a x a 100 11 mbe 1 n t 1 n p t a t a t in these equations a is the actual streamflow data p represents the predicted streamflow and n is the number of the testing database 5 results and discussions the proposed fos based streamflow forecasting algorithm was examined using an ahd streamflow data set the fos algorithm was implemented using matlab on an icore 7 3 4 ghz processor utilizing a 16 gb ram three models were constructed based on the training approaches presented in the previous section in this research a comprehensive analysis of the training approaches was carried out to ensure proper training this is vital for the proposed approach as it depends solely on historical streamflow records furthermore the performance of the proposed model will be examined for different streamflow pattern s low medium and high 5 1 training approach 1 the results of examining the fos model s performance constructed using training approach 1 are illustrated in figs 7 and 8 for each month fig 7 represent the actual and prediction values for 129 years of monthly records it can be noted from fig 7 that the fos algorithm could not provide high accuracy using training approach 1 this point is observed in examining the peak values where obviously there is a significant error in prediction of the peak values of this scenario it is also remarkable that some errors were double in most cases furthermore the triple error in the predicted values occurred in the other odd cases especially during the extreme streamflow events whether peak or low streamflow patterns the odd here is referring to number the study considered events where the number of event that the fos algorithm provides triple times of the actual value to be odd cases as the percentage of the number of these events to the total number of events for the whole period of testing events is very low 16 cases out of 1548 cases the overall performance of this training approach is imprecise as it has 9 7922 for mse and 10 5451 for nmse it should be noted that 12 months forecasting ahead depending on the previous 12 months is considered to be very long term streamflow forecasting practically forecasting streamflow for 12 months ahead is not common and most of the existing forecasting models support seasonal time increment prediction for more exploration of the fos performance in this scenario the flow rate has been divided into three groups low medium and high based on figs 2 and 3 the low streamflow rate class included six months january february june whereas august september and october represent the high streamflow class fig 8 illustrates the performance of fos in three different scales low medium and high of flow rate in general it can be observed that the performance of the fos model was less accurate over the long term forecasting period tables 2 demonstrate the performance metrics used in this study to evaluate the proposed model and each table is for a specific training approach it could be obvious from table 2 that performance in general is low as that nrmse is very high and the max re is very high although the rmse is relatively low for months such as february and may it misrepresents the fact that the model performs well with this training approach because the monitored streamflow is low during these two months compared to the other months of the year the mean bias error indicator reveals that the proposed model tends to provide underestimation forecasts in several cases 5 2 training approach 2 in this approach 10 years are forecasted using the previous 10 years this type of training is regarded as long term prediction fig 9 illustrates the predicted versus the actual values for 120 years of prediction starting from year 11 when the performance was compared with that obtained through training approach 1 a slight improvement in the result was observed with lower values of mse 9 0807 and nmse 0 38414 however fos encountered difficulty in accurate estimation of the peak values fig 9 illustrates clearly the underestimation of the peak values this is attributed to the increased probability of encountering different streamflow patterns during a long term of 10 years it is observable that in most cases of the peak values the proposed fos algorithm underestimated the actual values at most of the peak values over the testing period this is due to the fact that the peak streamflow events occurred during the high class of the streamflow which is only experienced in 3 months out of 12 months as a result the model during the training period mostly experienced low and medium classes of streamflow events that mainly drive the model when switching to the testing period to not attain matching or overestimation for the peak values fig 10 illustrates the actual and predicted values in various scales of the streamflow rate by categorizing the prediction period into three groups high medium and low the unsatisfactory performance for fos in the training approach 2 was observed the fos model was trained on a streamflow type different from what was experienced during the period of forecasting therefore the fos model was accurately updated to mimic this stochastic pattern of the streamflow thus relatively large streamflow errors of estimation were detected slight enhancement for the level of accuracy based on the evaluation metrics in table 3 is examined it could be depicted that the performances for all the evaluation metrics are slightly better for all months except two months that belong to the low class of streamflow march and april such enhancement is attributable to the including larger size of the input data pattern for thus the fos model turned out to be more understandable for the stochastic feature of the streamflow pattern and resulted in more accurate forecasting for the unseen pattern during the testing however the accuracy is still relatively low this is due to the fact that the testing period is relatively long it can be observed that the developed model attained overestimation forecasts in the case of medium streamflow values in fact the longer the testing period the more highly it is possible to experience a significant change in the streamflow pattern that the model could not detect then the model could provide a less accurate forecasting streamflow value 5 3 training approach 3 this approach predicted 1 year ahead based on the previous 10 years which is different from the two training approaches therefore it can be considered as a short term prediction the results of this approach had superior performance to those of approaches 1 and 2 fig 11 illustrates the prediction versus actual values for 130 years nevertheless some odd cases were detected with under and overestimation these cases had a minimal effect on the overall performance of fos prediction mse 9 5518 and nmse 0 050576 fig 12 illustrates the actual and predicted data for first 20 years of streamflow which included abrupt changes of streamflow records the abrupt changes of streamflow over 240 records first 20 years were considered to be those events that had fluctuation of up to 300 of the actual data the high changes that were observed in numerous of the months are july 1884 august 1888 august 1889 july 1891 august 1892 august 1893 and august 1900 where the fluctuation degrees were 4 54 3 208 3 442 3 086 3 219 3 543 4 751 bcm respectively the percentage of the re at each previous event was 38 84 42 52 16 81 10 16 6 06 13 43 32 78 respectively when training approach 1 was used whereas the proposed method with training approach 2 provided 18 74 41 65 12 36 4 34 5 34 15 64 16 59 percentage errors at those months respectively by contrast the percentage res that were obtained using the third training approach for those months were 16 47 34 14 10 49 2 74 0 2 13 29 15 74 respectively it is observable that there is a significant enhancement in the percentage of re when training approach 3 is used fos overcame these changes using the third training approach the prediction of these abrupt changes is considered to be one of the greatest challenges in the prediction of time series values it can be depicted that the fos model based on the third training approach was accurately updated to mimic the stochastic pattern of the streamflow thus the prediction errors were significantly reduced a further analysis of the fos model performance at different streamflow categories high medium and low is demonstrated in fig 13 by examining this figure it can be depicted that the fos streamflow forecasting model had a significantly better performance at low and medium streamflow categories than at the high streamflow category the above observations suggest that training approach 3 had a superior performance compared to the training approaches 1 and 2 therefore the 10 years of input is more adequate for predicting 1 year ahead in general the performance attained by fos based streamflow forecasting at ahd indicates that the fos modeling technique is pertinent in such hydrological application and can significantly improve the process of water resource planning moreover it is hoped that the fos algorithm with further enhancement can be applied in prediction engineering problems which comprise several input parameters to predict particular output variable these capabilities enable the application of fos in other forecasting tasks in water resources and the hydrological field such as evapotranspiration evaporation sediment transpose and rainfall finally table 4 demonstrates the evaluation metrics for the fos model using the third training approach obviously significant enhancement of all evaluation metrics has been achieved based on the mean bias error values the suggested model provided overestimation results within the low category and underestimation forecasts in most of other cases apparently the third training approach is balanced for training and testing patterns and thus introduces enough input patterns for the streamflow to be available for the model to detect these different patterns and when switching to the test session the model would be able to provide a high level of accuracy 5 4 comparative analysis in this study a further analysis was carried out for more comprehensive comparison of the result from the suggested approaches with the actual data as illustrated in fig 14 the mean and the standard deviation as first order statistical indicators and the variance as the second order indicator in addition to the skewness and kurtosis as higher order statistics have been presented fig 14 presents histograms and boxplots for each approach all the statistics indicate that the results from approach 3 have the closest statistic to the actual data in the low and high order statistics and the data distribution as illustrated in the histograms and boxplots therefore it can be concluded that the third approach has the best performance in terms of statistical indicators fig 13 summary for the statistical indicators for the suggested approaches with the comparison with actual data the flow duration curve presents the percentage of time exceedance for a specific streamflow discharge which is calculated form the cumulative frequency of data the flow duration curve is a combination of the characteristic of stream within the range of discharge regardless of the sequence of occurrence the flow duration curve can be used effectively for many studies that require a prediction for the long term of streamflow such as waterpower generation in dams management of water storage of reservoirs water supply and water pollution research therefore it is essential to present such type of curves with comparison of the result from the predictive model which can illustrate the accuracy of the model fig 15 illustrates the flow duration curves for the three approaches with comparison of the actual data in this figure it can be seen clearly that approach 1 has low accuracy compared with the second and third approaches the second approach as illustrated in fig 15b has more fluctuation between the actual and predicted values with ranges of 20 50 and 80 100 whereas the third approach has the best prediction alone side all the time flow exceedance in all ranges of stream discharge hence it can be declared that the proposed model can be utilized by the decision makers for planning projects that require streamflow prediction over long terms 5 5 comparison of the fos technique with other previous studies to ensure the validity of the proposed model the study conducted a comparison between the proposed model fos with models in previous studies that addressed streamflow forecasting in nile river first an analysis between the fos with the mlp nn introduced by el shafie et al 2008b will be investigated the comparison will be focused on the best results provided by the current model and the previous model second a comparison analysis is conducted with the rbf nn proposed by el shafie et al 2008a two different statistical indicators were selected to examine the model in the testing stage including nrmse and correlation coefficient r2 the first indicator was selected to present the amount of enhancement accuracy in the error whereas the second index represents the range association between predicted and actual streamflow table 5 presents these statistical criteria for both models with every month as well as the accuracy improvement percentage ai indicator the accuracy improvement is measured for both indicators to determine the significance of the proposed fos model over mlp nn and rbf nn models the measured accuracy improvement could be expressed as follows ai i current i previous i current where i current is the value of the statistical indicator given by the current model fos and i current represents the same statistical index given by previous models mlp nn hors anfis and rbf nn the positive values of ai indicate enhancement of the model when the correlation coefficient r2 is used whereas the negative values of ai denote improvement of the current model when nrmse is used it can be observed from table 5 that the fos algorithm provided highly accurate statistical indexes for every month compared to mlp nn and provided less accurate ones for 2 months only august and september compared to the rbf nn model these months august and september represent the high streamflow class and this point approves for the above note that the fos method introduced low accuracy at the high streamflow pattern however the accuracy improvement using the current model fos was highly significant for other months compared to previous models by comparing the results of the proposed model with hors and anfis it is noticeable that the fos method has outstanding performance in terms of nrmse of up to 550 ai the correlation coefficient indicates a very minimalistic decrease in the performance of fos compared with hors and anfis with maximum ai 5 6 where this minor enhancement can be ignored because r2 is not only the indicator that can reflect the accuracy of the model in all cases in spite of that the hors and anfis have higher r2 for some months such as august and september by contrast nrmse has better results for fos in the same months table 6 presents the time required for running the method with the best model the maximum of total elapsed time application for the fos method has been precisely 10 61 s which indicates a very high speed of the model however the maximum time consumption in using mlp nn and rbf nn models is 64 24 s and 34 82 s respectively thus if time is to be considered for comparison purposes with other methods this implies that the fos approach is outperformed by the previous methods in this matter the current state of the art in streamflow forecasting for accuracy enhancement includes artificial intelligent methods ai which have had limited success in forecasting the long term streamflow thus there still exists a requirement for a streamflow accuracy enhancement technique that can mimic the streamflow non stationary pattern for both the short and long term errors in addition the suitability of the fos algorithm to accommodate different training approaches that might be more advantageous for a particular river case study over the other river cases to successfully achieve better forecasting accuracy this successful training approach while using fos might be difficult to be adapted while using ai algorithms such advantage in the fos algorithm which is invalid in the ai algorithms is of importance in the hydrological process specifically for streamflow in fact a particular training approach used with ai algorithm might cause redundance in the input data pattern and mislead the model in attaining an acceptable level of accuracy in addition for some training approaches the ai algorithms might be time consuming and thus inappropriate for real time application such as the application under this study for streamflow forecasting in fact the major reason for slightly poor accuracy for the peak streamflow forecasting based on the re values is due to the necessity to use small window size data for training the model to lessen the time consumed by training in fact increasing the size of the data window significantly increases the time needed to complete the training process to achieve the performance goal 6 conclusion this research introduced a new streamflow forecasting approach based on fos to enhance the accuracy for the streamflow forecasting fos offered a simple and efficient system modeling by using an arbitrary set of functions to represent data patterns the proposed fos based streamflow forecasting model was examined with three different training approaches using 130 years of natural streamflow historical data recorded on a monthly basis the results demonstrated the ability of fos based forecasting to achieve a relatively high level of streamflow forecasting accuracy for all the streamflow categories low medium and high while using the third training approach fos based streamflow forecasting provided a relatively poor level of accuracy for the high streamflow category this is probably due to the frequent fluctuations observed in the natural streamflow pattern of the high streamflow category the reported results demonstrated the capability of the fos based model in long term forecasting as it achieved close predictions with observed streamflow data according to the several statistical indicators for one year ahead forecasting for the natural streamflow this is a significant advantage of fos given that the vast majority of algorithms typically adopted for streamflow modeling are more suited for short term forecasting nevertheless the proposed fos based forecasting model experienced some of the common challenges of the existing forecasting models the major challenge encountered by fos based modeling was the requirement of relatively long historical data records to provide streamflow predictions with appropriate accuracy levels however this note was observed in streamflow patterns of the nile river hence another streamflow may behave differently where a shorter data record maybe sufficient for the fos method to mimic the behavior of a streamflow in addition the hydrological features of the nile river basin were missing in the model implementation as the study only focused on exploring fos capabilities in streamflow forecasting thus the proposed fos model was developed independently of the system s physical and or hydrological behavior the major advantage of this method is its ability to predict the system behavior without analytical prediction rules hydrological physical however comprising such hydrological behaviors in the forecasting model development can provide further enhancement the streamflow forecasting model s performance it should be noted here that there is no guarantee that the proposed model could be successfully applied for different case studies around the world however it should be noted that it is not related to the framework of the model but it might relate to how to structure and adapt the model to be suitable for a case study in other words in our case study training approach 3 has successful achieved the best results however in other case studies one of the other two training approaches presented in this study could achieve better results over the third approach by contrast it should be noted that the training process is the major component of developing any data driven model that definitely influences the whole performance of the model whatever its framework and its mathematical procedure in this context it is highly recommended for future research to investigate the potential of other training approaches that might be more suitable for different case studies furthermore there is no confirmation that the performance of the proposed model would be poorer when applied for a smaller time increment or scale for streamflow such observation should be first investigated by examining the proposed model in other case studies that experienced a daily or even hourly time scale for river streamflow it could be observed that the proposed model provided slightly low level accuracy in some of the peak streamflow points according to the re indicator the suggested model achieved poor consistency in the re over testing data therefore there is a need to improve the proposed fos algorithm to overcome such a weak point and this should be considered in future studies these limitations of the current modeling structure could be considered as a challenge to be implemented in future studies credit authorship contribution statement abdalla osman conceptualization methodology software writing original draft software writing review editing haitham abdulmohsin afan conceptualization methodology software writing original draft software writing review editing mohammed falah allawi data curation writing original draft software writing review editing othman jaafar writing original draft visualization investigation software writing review editing aboelmagd noureldin conceptualization methodology software writing original draft visualization investigation software writing review editing firdaus mohamad hamzah writing original draft visualization investigation software writing review editing ali najah ahmed writing original draft software validation writing review editing ahmed el shafie writing original draft supervision software writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors thankfully acknowledge ministry of higher education malaysia for fundamental research grant scheme frgs grant no frgs 1 2019 tk01 uniten 02 3 in addition the authors would like to thank university of malaya for the technical and financial support received from gpf082a 2018 the authors would like to thank enago www enago com for the english language review 
5501,data driven models for streamflow forecasting have attracted considerable attention as they are independent of physical system features the physical features of the river basin are extremely hard to collect especially for large rivers empirical data driven models such as stochastic and regression models have been widely used in the field of streamflow forecasting however they suffered limited accuracy in predicting extreme streamflow they also required raw data pre processing prior to the modeling process especially for lengthy data records and for large time scale increments e g monthly resolution to overcome these challenges data driven forecasting models based on artificial intelligence ai have been widely used and resulted in enhancing the forecasting accuracy nevertheless ai based models required augmentation with proper optimization schemes to adjust the model parameters for optimal accuracy furthermore in some cases due to unsuitability of the optimization model there is high possibility for overfitting of the ai model which might cause poor prediction of input patterns that were not adequately mimicked this study introduces a new approach to streamflow forecasting based on nonlinear system identification the proposed technique employs fast orthogonal search fos to develop a nonlinear model of stream flow the main advantage of using fos is eliminating the requirement of raw data pre processing and the need for an optimization scheme for model parameter adjustment since the fos algorithm takes this into account while building the model in addition the fos algorithm includes a pole zero cancellation procedure that can detect and avoid the over fitted models the fos based nonlinear modeling approach was adopted in this research for the development of a streamflow forecasting model at aswan high dam using monthly basis natural streamflow records for 130 years the results indicated that the proposed fos algorithm outperformed the previously developed ai models of streamflow forecasting for large data records and for large time scale increment monthly resolution keywords nonlinear system identification streamflow forecasting aswan high dam river nile multi lead forecasting 1 introduction to have optimal water resource management and planning it is vital to have an accurate forecasting model for streamflow streamflow forecasting provides the necessary information for understanding and estimation of suspended sediment generation of hydropower design of a proper irrigation system for particular crop patterns and optimal release policy from reservoirs kisi and cimen 2011 liu et al 2014 liu et al 2018 terzi and ergin 2013 wu et al 2009 2005 in addition having long term accurate streamflow forecasting provides the decision makers of water resources with valuable machination to reduce side effects of flooding on infrastructure and human life box and jenkins 1970 kagoda et al 2010 kalman et al 1960 kisi 2010 salas et al 1980 shiri and kisi 2010 valipour et al 2012 valipour 2015 allawi et al 2017 utilized the modified co active neuro fuzzy inference system canfis model for reservoir inflow forecasting the modified canfis model has been compared to other data driven models the authors found that the canfis model is better than other models in providing high forecasting accuracy streamflow the problem of streamflow forecasting can be generally formulated in the nonlinear system identification problem chen and dyke 2007 danandeh mehr 2018 the main drawback of using ai modeling techniques such as adaptive neuro fuzzy inference system anfis and ann is the variation of the forecasting model performance based on the complexity of the modeled system in fact unpretentious models comprising fewer parameters and simple mathematical procedures e g ordinary least squares solution typically might be more appropriate for streamflow forecasting billings 2013 in the last three decades several streamflow forecasting models were developed based on various methods conventional methods cms such as autoregressive ar moving average and autoregressive moving average arma modeling have been examined in several cases these methods exhibited considerable potential for accurate forecasting of medium streamflow classes billings 2013 chen and dyke 2007 clark et al 2008 husain 1985 kalman et al 1960 moradkhani et al 2005 noureldin et al 2007 schreider et al 2001 valipour et al 2012 veiga et al 2014 however it has been reported that there are several drawbacks in developing these models clark et al 2008 el shafie et al 2012 husain 1985 ju et al 2009 maier et al 2004 noureldin et al 2011 2007 schreider et al 2001 the main meagerness associated streamflow forecasting models based on cms is the stipulation to integrate it with a pre formulation of the trustful stochastic model to ascertain the source of uncertainty for the model input and output moreover cms require erstwhile analysis of the raw data related to the covariance between the mode variables in the last two decades ai streamflow forecasting models were introduced to overcome the drawbacks of cm based models ai methods mimic a complex time series with its nonlinear modeling capabilities which is the major feature of any historical streamflow record asadi et al 2013 balestrassi et al 2009 graves and pedrycz 2009 han and qiao 2013 ju et al 2009 additionally the development of the streamflow forecasting model using ai methods does not require pre formulation and analysis of the stochastic pattern for the raw streamflow data to be modeled these requirements are mandatory for the development of streamflow forecasting models using cms danandeh mehr et al 2013 el shafie et al 2008a graves and pedrycz 2009 guo et al 2011 jothiprakash and magar 2012 katambara and ndiritu 2010 kisi et al 2012 sang 2013 whigham and crapper 2001 yaseen et al 2015 nevertheless the ai model encountered numerous disputes in its architecture because of the need to inaugurate it with a proper pre treatment method for data noise reduction additionally the process of ai modeling requires an optimization procedure for its parameters to enhance the forecasting accuracy labat 2005 maier and dandy 2000 nourani et al 2014 sang 2013 in the last 5 years the authors introduced several ai models for streamflow forecasting at aswan high dam ahd these models included anfis radial basis function neural network high order response surface method hors and multi layer perceptron neural network with the ensemble procedure allawi and el shafie 2016 el shafie and noureldin 2011 keshtegar et al 2016 these models revealed appropriate prospective to achieve moderate accuracy for streamflow forecasting especially for most of the peak events at ahd noticeably these ai models had a worthwhile tendency of mimicking the input output pattern in circumstances that with no need for inclusion of any other influence parameters affecting the streamflow although these ai models proved to be proficient they are considered to be sub optimal search techniques because of the slow convergence of the forecasting model during training calibration in most of the ann models developed the back propagation algorithm was used for optimizing the ann key parameters elzwayie et al 2016 the back propagation algorithm experienced several drawbacks such as local optima and slowness there are many advanced methods offered by researchers to partially overcome these drawbacks especially the local optima such as particle swarm optimization and genetic algorithms gas however these optimization algorithms introduced other challenges such as overfitting of the streamflow forecasting model accordingly the ai streamflow forecasting models were unable to generalize and maintain consistent accuracy for the examined data patterns the limitations of the cms and ai based streamflow forecasting models motivated the search for other methods to establish robust stream forecasting models adaptive fast orthogonal search fos was selected in this research as a robust algorithm for modeling nonlinear systems korenberg 1988 that can be represented by the nonlinear arma model with exogenous inputs narmax billings 2013 korenberg et al 1989 generally fewer terms form the model and thus the selection of model terms one at a time are more convenient for efficient operation of the modeling process this selection technique is achieved in this research using fos to enable the efficient building of the nonlinear auto regression moving average exogenous narmax model for streamflow orthogonal search korenberg 1989 1988 tseng and powers 1993 is a highly efficient technique designed originally for efficient nonlinear system modeling the modeling process is mainly based on gram schmidt orthogonalization algorithm to enable the representation of a system model using an arbitrary set of functions this enhances the accuracy of the system modeling procedure as it offers a wider selection of functions to represent the system model tseng and powers 1993 fos is a modification of the orthogonal search that accelerates the process of system modeling through the elimination of some intermediate procedures inside orthogonal search algorithm korenberg 1988 in this study fos is employed to provide enhanced streamflow forecasting fos selection was motivated by fos s reported capabilities and extensively efficient performance in accurate system modeling korenberg 1989 1988 this research investigates the potential of utilizing the adaptive fast orthogonal search fos method to develop streamflow forecasting model that achieve highly accurate results based on popular indicators to measure the level of error the study mainly focused on the ability of the proposed model to achieve appropriate forecasting accuracy for the streamflow in the large river and large time scale increment monthly resolution the proposed method was applied for the nile river streamflow at ahd for 130 years streamflow data on a monthly basis during the period between 1870 and 2000 one of the major advantages of the proposed fos method is its flexibility in managing the data set to be applicable for different training approaches in this context three different training approaches were examined a comparative analysis with the previous ai models developed by the authors was carried out to assess the contribution of the novel streamflow forecasting technique the rest of the manuscript is arranged in the following fashion section 2 gives the description of the case studies and data sets the subsequent section illustrates the methodology part results and discussions are given in section 4 finally in section 5 we conclude the paper and outline our current lines of research 2 data collection and pre analysis the nile river is approximately 6853 km long flows from the south to the north eastern part of the african continent and covers almost 3 million km2 which is around 10 of the african continent area the nile river runs through 10 countries over 35 of latitude there are two major sources of the nile river systems the first is the white nile which originates from the equatorial lake plateau and the second is the blue nile which stems from the ethiopian highland these two sources are located in humid tropical regions with an annual rainfall of more than 1000 mm however there are two countries located partially in the arid region namely sudan and egypt in fact sudan could be divided into three different regions humid in south semi arid in the middle and arid in the north the main objective of this research is to forecast the natural streamflow pattern for the nile river in egypt at the ahd area demonstrated in fig 1 the high aswan dam is located in the south of egypt with coordinates 23 58 14 n 32 52 40 e consequently it is important to study the above phenomenon at egypt which is located completely in the arid region the average annual precipitation in egypt is typically less than 20 mm around 97 of the egyptian water resources originate outside the border which is mainly dependent on the nile river ninety percent of all water reaching egypt during the peak seasons is received from ethiopian catchment and the remaining 10 is received from the white nile system by contrast during the low streamflow months 30 of the water is received from ethiopian catchment and the rest of the water feed is received from white nile therefore it could be realized that the streamflow at ahd that is located at the south part of egypt almost the entrance of nile river to the egypt border has an extremely variable stochastic pattern the data set used in this research was based on historical natural streamflow data records at ahd for 130 years between 1870 and 2000 these data records were obtained from the nile water authority at the egyptian ministry of water resources and irrigation the data records experienced two different phases of measurement techniques the first phase took place during the period between 1870 and 1902 and the second phase took place over the remaining period of the data set initially the data for the streamflow has been recorded by the general stage discharge table this table was designed from the aswan downstream gage afterwards starting from 1903 the egyptian and sudanese governments constructed several dams and hydraulic structures along the nile river based on these new structures the natural streamflow records at ahd were calculated from the stage discharge relationship at ahd this was followed by fine tuning of the streamflow records to be free from all the losses from the manmade upstream lakes water withdrawn in sudan and the influence of the sennar reservoir the analysis of the data records illustrated in fig 2 indicated that the recorded streamflow values were highly random and stochastic in nature using cms to develop the forecasting model would require examination of the auto correlation sequence for each month and the cross correlation between consequent months however when the proposed model fos is utilized there is no need to examine such correlation analysis or develop a pre formulation for the data time series the degree of fluctuations was computed by using the equation dq o we observed that the fluctuation pattern of streamflow was relatively high where the maximum gradient degree fluctuation ranged between 8 65 and 0 00975 bcm the monthly statistical indices of the ahd streamflow data records were evaluated for the assessment of the proposed streamflow forecasting approach this included the mean xmean standard deviation sx maximum value xmax and minimum value xmin table 1 presents the four proposed indices for each month and the fifth column presents the range which is the difference between xmax and xmin for each month it can be depicted from the table that the september streamflow had the highest xmax and xmin with the wider range while the streamflow records for may had the lowest xmax and xmin accordingly a categorization for the streamflow of each was established based on the xmax values the low category is considered for the months that experienced maximum streamflow values less than 8 0 bcm and the maximum range between the maximum and the minimum streamflow is less than 4 bcm by contrast the high category is taken when the maximum streamflow value is higher than 20 bcm and the maximum range is more than 10 bcm finally the medium category is identified in case the maximum streamflow values and the maximum ranges were located within the ranges of the other two categories the months of august september and october were categorized as high streamflow july november and december were regarded as medium streamflow and the other months were regarded as low streamflow the standard deviation sx values were used to examine the performance of the proposed streamflow forecasting model this is because the standard deviation is typically used to enumerate the values of variation for a particular data set 3 methodology 3 1 narmax modeling using fos the narmax model is defined as 1 y n f y n 1 y n 2 y n n y x n d x n d 1 x n d n x e n 1 e n 2 e n n e e n where y n x n and e n are the system output input and noise sequences respectively n y n x and n e are the maximum lags for the system output input and noise respectively f is some nonlinear function and d is a time delay typically set to d 1 the model is essentially an expansion of past inputs outputs and noise terms in this research the noise terms e n 1 e n 2 e n n e are neglected to simplify the modeling process hence the narmax model is reduced to the following form 2 y n f y n 1 y n 2 y n n y x n 1 x n 2 x n n x 1 e n the above model terms and their corresponding coefficients are estimated using the fos algorithm the algorithm uses an arbitrary set of non orthogonal candidate functions p m n and finds a functional expansion of an input y n to minimize the mean squared error mse between the input and the functional expansion the functional expansion of the input y n in terms of the arbitrary candidate functions p m n is given by 3 y n m 0 m a m p m n e n a m m 0 m are the weights of the functional expansion and e n is the modeling error by using non orthogonal candidate functions there is no sole solution for eq 2 however fos could classify the input with fewer model terms than an orthogonal functional expansion korenberg 1989 fos enables the adequate selection of model terms based on the mse reduction introduced by each term the selected term is the one that results in the maximum mse reduction the fos algorithm can be stopped by 1 setting a limitation on the model maximum number of terms 2 setting a pre defined threshold for the minimum ratio between mean square of the input parameters and the mse and 3 examining the mse reduction introduced by each term and stooping when the maximum mse reduction of the remaining term is less than the mse reduction anticipated from a white noise term korenberg 1989 narmax modeling using fos is accomplished by selecting candidate functions pm n that are combinations of delayed versions of inputs and outputs accordingly pm n is given by 4 p m n p x p x x p y p y y p x y p x represents the set all possible terms of the input with different delays and different orders p x x represent the set all possible combinations of the input terms with different delays and different orders p y represents the set all possible terms of the output with different delays and different orders p y y represents the set of all possible combinations of the output terms with different delays and different orders p x y represents the set of all possible combinations of the input terms and output terms with different delays and different orders the maximum delays for the inputs and outputs are determined by the training approach 3 2 model structure as highlighted in the previous section the proposed model is designed to be suitable for forecasting the large time scale of the streamflow data that were allocated in the large river the main reasons for developing the proposed model on monthly basis are as follows first limitation of data availability at a less time increment as the model has been developed using data since the 19th century and includes data for the whole 20th century this due to the fact that during this time the technology for obtaining reliable daily monitoring data for river streamflow was not available second the reason for developing forecasting model for the streamflow at ahd is to provide the decision makers with an accurate tool for better management and operation for the dam which is a monthly operation and management rule according the ahd authority the first step in developing the forecasting model is to study and analyze the data used to select training calibration and testing validation data sets in this context in this study the first 10 years of the streamflow data between 1871 and 1881 had a more stable trend for annual streamflow as illustrated in fig 3 it is essential for the training data to experience most of the streamflow pattern which was clearly observed in the variation of monthly data over the first 10 years and had a higher rate of variations for the second 10 years for the period between 1881 and 1891 as illustrated in fig 4 in this research the forecasting of streamflow is achieved using a polynomial expansion of the historical streamflow that determines the streamflow as a function of the month index hence the forecast model is given by 5 r m n f n m where r m n is the forecasted streamflow of the nth year and month m 1 2 12 and f n m is the polynomial expansion of the nth year as a function of the month index as fos models the pattern of the input data it implicitly performs the aforementioned tasks of transforming and thresholding fos performs thresholding when it evaluates whether the addition of a candidate function will result in sufficient mse reduction specified by a threshold parameter the challenge of non stationary streamflow data fluctuation of the data is addressed by taking windows of streamflow and applying the fos to each window fig 5 is a schematic of the fos algorithm developed in this research the bullets indicate variables or operating parameters that have to be set in the algorithm fos windows the training period data input time series denoted as x n representing streamflow records into smaller analysis windows that can be treated as stationary data each window is analyzed using fos to extract components that represent the candidate function of the true component which is the of the historical streamflow pattern the residual mse threshold value is an important parameter as it is a stopping criterion that can prevent fos from modeling the error terms to avoid the possibility of occurrence of overfitting the output of this stage is the fos model terms which provide information on frequency magnitude and phase for that window of data the fos model terms can then be used to synthesize an estimation of the true component for that window thus creating an accuracy enhanced window denoted as x k n this process repeats for all windows and all of the enhanced windows are recombined to create the overall accuracy enhanced streamflow time series in fact one of the major advantages of the fos algorithm and the proposed structure is the consideration of as much as possible smaller data window size during the training to avoid the complexity that might be experienced because of the non stationary feature within the longer time inputs an intermediate step between the windowing block and the fos detection and synthesis loop is the testing of the data window for non stationarity changes in the streamflow value this would enable true components of particular window to be modeled using a certain set of fos operating parameters whereas the non stationary window can be treated with a different set of operating parameters thus the parameters can be selected to optimally treat these two cases to reduce the likelihood of modeling the value of the streamflow fos is generally attributed to be a data dependent algorithm as it could be noticed from the fos algorithm that uses an arbitrary set of non orthogonal candidate functions pm n and finds a functional expansion of an input y n to minimize the mse between the input and the functional expansion therefore the accuracy of the model achieved by fos depends on one of the following three conditions first the data records being modeled in this study the natural river streamflow second the calculation of the candidate functions used to compute correlations between the input and the candidate function which is a closed form equation and third the stopping condition which is represented by residual mse threshold to allow the model to switch from the training process to the testing process in this context the residual mse threshold is one of the required fos s parameters to be pre defined to start its searching operation however in this study the fos search algorithm is stopped in one of three cases the first case is when a certain maximum number of terms are fitted the second case is when the ratio of mse to the mean squared value of the input signal is below a pre defined threshold the third case is when adding another term to the model reduces the mse below the pre defined performance goal as a result there are only two parameters within the fos algorithm structure that should be selected pre defined before starting the operation of the fos algorithm the performance goal for the mse and the thresholds in this study the performance goal for the mse value has been selected to be 10 4 to avoid the possibility of occurrence of overfitting by contrast the threshold permits fos to model the motion dynamics and reject frequency terms that model the unnecessary noise component in fact the residual mse threshold is considered to be the major fos parameter that has the major impact on the overall model performance several trials have been performed to reach a balanced model that can identify the real features of the input historical streamflow pattern included in the data window during training a residual mse threshold of 0 8 was selected for training approaches finally there is one more parameter that should be pre defined before the start of modeling the window size in fact the smaller the window size is the longer is the time consumption for training the model by contrast the larger window size leads to more complexity in the data window for training to consider non stationary features in this context several trials and errors for the window size selection that ranged between 6 and 24 which represents the range between 6 months and 2 years historical natural streamflow records have been carried out the model performance during training has been examined to identify the suitable window size that could minimize the time consumption during training and minimize the possibility of occurrence for the non stationary components in training data a window size of 10 historical natural streamflows 10 months exhibited the best performance out of all other alternatives 3 3 training approach the cross correlation analysis for the monthly natural streamflow pattern for subsequent years indicated that relatively poor monthly cross correlation if we go more than 1 year behind the forecast year based on this observation the establishment of the forecasting model was based on the previous years streamflow pattern for all training approaches el shafie and noureldin 2011 thus the narmax model was reduced to the nonlinear autoregressive nlar model moreover the assessment of the different training approach can be used later on to determine the accuracy of long term streamflow forecasting that can be achieved by each training approach according to the previous study at ahd it was experienced that the accuracy deteriorates when the forecasting term goes behind 3 months ahead el shafie et al 2006 the model construction starts by building a relation between the vectors of actual streamflow rates of the first year r m 1 and month indices m 1 2 12 fig 6 a illustrates the timeline for the first training approach the model is improved each year by using the previous years to construct the current year flow rate model f n m the model training of nth year is achieved by feeding the actual vectors of flow rates r m n n 1 n 1 to fos system identification algorithm to obtain a polynomial relation between the month index and the streamflow rate hence fos creates a model that describes the curve of the annual readings and this model is updated each year for the second training approach a new model is created after a defined number of years and provides a prediction for a fixed number of years ten years of data were selected for both training and prediction the model training for the nth year is achieved by feeding the vector of flow rates for the previous 10 years i e r m n n n 10 n 1 to fos system identification algorithm to obtain a polynomial relation between the month index and streamflow for the next 10 years therefore fos builds a new model every 10 years independent on the previous models fig 6 b illustrates the testing and training data for 130 years note that the first 10 years were used as input hence the testing period is exactly equal to the training period the third approach is similar to the second one as it uses the data of the previous years for training to predict the current year s streamflow the input in this case is the flow rate of previous 10 years and the output is the flow rate of the next year at the first run the first 10 years are used for training and 11th year is predicted next the 10 years actual starting from the second year to the 11th year are used for training and 12th year is predicted and so on until year 130 fig 6 c illustrates the timeline of the third approach for both training and prediction phases the evaluation of the performance index has been carried out to check the ability of the proposed model to address the forecasted streamflow harmonization with the changes in the streamflow values throughout the testing period 4 model evaluation one of the most important steps in developing a forecasting prediction model is to examine the model s performance for the model s predictive capabilities in this study five performance indicators have been calculated to evaluate the performance of the proposed fos model the reason for selecting these five indicators is the fact that each indicator examines a specific capability of the model the first indicator is the root mean square error rmse which is used to measure the variation between values observed for the variable being modeled and the values predicted by the model the rmse aggregates the individual differences into a single measure of the model forecasting accuracy the second indicator is the normalized rmse nmrse which is the non dimensional form of the rmse normalized root mean square error nrmse examines the model performance by relating the rmse to the mean of the observed actual data the nrmse provides a clear evaluation of the accuracy of the prediction variable relative to the range of its values to examine the power and the course of the linear relationship between the actual and the predicted values the coefficient of determination r2 is used r2 is calculated by dividing the covariance of the predicted and actual values by the product of the standard deviations of those values such this indicator indicates the precision of the linear fitting representation of the variance between the predicted and actual values for evaluation of the efficiency of the proposed model the nash sutcliffe coefficient which is called the efficiency coefficient e was used to analyze the model s capability to achieve a perfect prediction the closer the value of e to 1 the more is the prediction accuracy of the proposed model the relative error re was considered to examine how the outputs of the model are biased with the actual values in addition the re provides the maximum difference between the predicted and actual values which is important for ensuring that the model output error is within the acceptable range furthermore re indicates the error distribution for the validation session and demonstrates how the model is underestimating or overestimating the actual values the last indicator used to examine the performance of the proposed model is the bias bias the bias is a representation of the behavior of the data driven model the long term error where its positive value indicates to overestimation and its negative value indicates underestimation the equations for all the indicators mentioned above are presented hereafter in the same order 6 rmse i 1 n x a i x p i 2 n 7 nrmse rmse x a max x a min 8 r 2 i 1 n x a i x a x p i x p i 1 n x a i x a 2 i 1 n x p i x p 2 2 9 e 1 i 1 n x a i x p i 2 i 1 n x a i x a 2 10 r e x p x a x a 100 11 mbe 1 n t 1 n p t a t a t in these equations a is the actual streamflow data p represents the predicted streamflow and n is the number of the testing database 5 results and discussions the proposed fos based streamflow forecasting algorithm was examined using an ahd streamflow data set the fos algorithm was implemented using matlab on an icore 7 3 4 ghz processor utilizing a 16 gb ram three models were constructed based on the training approaches presented in the previous section in this research a comprehensive analysis of the training approaches was carried out to ensure proper training this is vital for the proposed approach as it depends solely on historical streamflow records furthermore the performance of the proposed model will be examined for different streamflow pattern s low medium and high 5 1 training approach 1 the results of examining the fos model s performance constructed using training approach 1 are illustrated in figs 7 and 8 for each month fig 7 represent the actual and prediction values for 129 years of monthly records it can be noted from fig 7 that the fos algorithm could not provide high accuracy using training approach 1 this point is observed in examining the peak values where obviously there is a significant error in prediction of the peak values of this scenario it is also remarkable that some errors were double in most cases furthermore the triple error in the predicted values occurred in the other odd cases especially during the extreme streamflow events whether peak or low streamflow patterns the odd here is referring to number the study considered events where the number of event that the fos algorithm provides triple times of the actual value to be odd cases as the percentage of the number of these events to the total number of events for the whole period of testing events is very low 16 cases out of 1548 cases the overall performance of this training approach is imprecise as it has 9 7922 for mse and 10 5451 for nmse it should be noted that 12 months forecasting ahead depending on the previous 12 months is considered to be very long term streamflow forecasting practically forecasting streamflow for 12 months ahead is not common and most of the existing forecasting models support seasonal time increment prediction for more exploration of the fos performance in this scenario the flow rate has been divided into three groups low medium and high based on figs 2 and 3 the low streamflow rate class included six months january february june whereas august september and october represent the high streamflow class fig 8 illustrates the performance of fos in three different scales low medium and high of flow rate in general it can be observed that the performance of the fos model was less accurate over the long term forecasting period tables 2 demonstrate the performance metrics used in this study to evaluate the proposed model and each table is for a specific training approach it could be obvious from table 2 that performance in general is low as that nrmse is very high and the max re is very high although the rmse is relatively low for months such as february and may it misrepresents the fact that the model performs well with this training approach because the monitored streamflow is low during these two months compared to the other months of the year the mean bias error indicator reveals that the proposed model tends to provide underestimation forecasts in several cases 5 2 training approach 2 in this approach 10 years are forecasted using the previous 10 years this type of training is regarded as long term prediction fig 9 illustrates the predicted versus the actual values for 120 years of prediction starting from year 11 when the performance was compared with that obtained through training approach 1 a slight improvement in the result was observed with lower values of mse 9 0807 and nmse 0 38414 however fos encountered difficulty in accurate estimation of the peak values fig 9 illustrates clearly the underestimation of the peak values this is attributed to the increased probability of encountering different streamflow patterns during a long term of 10 years it is observable that in most cases of the peak values the proposed fos algorithm underestimated the actual values at most of the peak values over the testing period this is due to the fact that the peak streamflow events occurred during the high class of the streamflow which is only experienced in 3 months out of 12 months as a result the model during the training period mostly experienced low and medium classes of streamflow events that mainly drive the model when switching to the testing period to not attain matching or overestimation for the peak values fig 10 illustrates the actual and predicted values in various scales of the streamflow rate by categorizing the prediction period into three groups high medium and low the unsatisfactory performance for fos in the training approach 2 was observed the fos model was trained on a streamflow type different from what was experienced during the period of forecasting therefore the fos model was accurately updated to mimic this stochastic pattern of the streamflow thus relatively large streamflow errors of estimation were detected slight enhancement for the level of accuracy based on the evaluation metrics in table 3 is examined it could be depicted that the performances for all the evaluation metrics are slightly better for all months except two months that belong to the low class of streamflow march and april such enhancement is attributable to the including larger size of the input data pattern for thus the fos model turned out to be more understandable for the stochastic feature of the streamflow pattern and resulted in more accurate forecasting for the unseen pattern during the testing however the accuracy is still relatively low this is due to the fact that the testing period is relatively long it can be observed that the developed model attained overestimation forecasts in the case of medium streamflow values in fact the longer the testing period the more highly it is possible to experience a significant change in the streamflow pattern that the model could not detect then the model could provide a less accurate forecasting streamflow value 5 3 training approach 3 this approach predicted 1 year ahead based on the previous 10 years which is different from the two training approaches therefore it can be considered as a short term prediction the results of this approach had superior performance to those of approaches 1 and 2 fig 11 illustrates the prediction versus actual values for 130 years nevertheless some odd cases were detected with under and overestimation these cases had a minimal effect on the overall performance of fos prediction mse 9 5518 and nmse 0 050576 fig 12 illustrates the actual and predicted data for first 20 years of streamflow which included abrupt changes of streamflow records the abrupt changes of streamflow over 240 records first 20 years were considered to be those events that had fluctuation of up to 300 of the actual data the high changes that were observed in numerous of the months are july 1884 august 1888 august 1889 july 1891 august 1892 august 1893 and august 1900 where the fluctuation degrees were 4 54 3 208 3 442 3 086 3 219 3 543 4 751 bcm respectively the percentage of the re at each previous event was 38 84 42 52 16 81 10 16 6 06 13 43 32 78 respectively when training approach 1 was used whereas the proposed method with training approach 2 provided 18 74 41 65 12 36 4 34 5 34 15 64 16 59 percentage errors at those months respectively by contrast the percentage res that were obtained using the third training approach for those months were 16 47 34 14 10 49 2 74 0 2 13 29 15 74 respectively it is observable that there is a significant enhancement in the percentage of re when training approach 3 is used fos overcame these changes using the third training approach the prediction of these abrupt changes is considered to be one of the greatest challenges in the prediction of time series values it can be depicted that the fos model based on the third training approach was accurately updated to mimic the stochastic pattern of the streamflow thus the prediction errors were significantly reduced a further analysis of the fos model performance at different streamflow categories high medium and low is demonstrated in fig 13 by examining this figure it can be depicted that the fos streamflow forecasting model had a significantly better performance at low and medium streamflow categories than at the high streamflow category the above observations suggest that training approach 3 had a superior performance compared to the training approaches 1 and 2 therefore the 10 years of input is more adequate for predicting 1 year ahead in general the performance attained by fos based streamflow forecasting at ahd indicates that the fos modeling technique is pertinent in such hydrological application and can significantly improve the process of water resource planning moreover it is hoped that the fos algorithm with further enhancement can be applied in prediction engineering problems which comprise several input parameters to predict particular output variable these capabilities enable the application of fos in other forecasting tasks in water resources and the hydrological field such as evapotranspiration evaporation sediment transpose and rainfall finally table 4 demonstrates the evaluation metrics for the fos model using the third training approach obviously significant enhancement of all evaluation metrics has been achieved based on the mean bias error values the suggested model provided overestimation results within the low category and underestimation forecasts in most of other cases apparently the third training approach is balanced for training and testing patterns and thus introduces enough input patterns for the streamflow to be available for the model to detect these different patterns and when switching to the test session the model would be able to provide a high level of accuracy 5 4 comparative analysis in this study a further analysis was carried out for more comprehensive comparison of the result from the suggested approaches with the actual data as illustrated in fig 14 the mean and the standard deviation as first order statistical indicators and the variance as the second order indicator in addition to the skewness and kurtosis as higher order statistics have been presented fig 14 presents histograms and boxplots for each approach all the statistics indicate that the results from approach 3 have the closest statistic to the actual data in the low and high order statistics and the data distribution as illustrated in the histograms and boxplots therefore it can be concluded that the third approach has the best performance in terms of statistical indicators fig 13 summary for the statistical indicators for the suggested approaches with the comparison with actual data the flow duration curve presents the percentage of time exceedance for a specific streamflow discharge which is calculated form the cumulative frequency of data the flow duration curve is a combination of the characteristic of stream within the range of discharge regardless of the sequence of occurrence the flow duration curve can be used effectively for many studies that require a prediction for the long term of streamflow such as waterpower generation in dams management of water storage of reservoirs water supply and water pollution research therefore it is essential to present such type of curves with comparison of the result from the predictive model which can illustrate the accuracy of the model fig 15 illustrates the flow duration curves for the three approaches with comparison of the actual data in this figure it can be seen clearly that approach 1 has low accuracy compared with the second and third approaches the second approach as illustrated in fig 15b has more fluctuation between the actual and predicted values with ranges of 20 50 and 80 100 whereas the third approach has the best prediction alone side all the time flow exceedance in all ranges of stream discharge hence it can be declared that the proposed model can be utilized by the decision makers for planning projects that require streamflow prediction over long terms 5 5 comparison of the fos technique with other previous studies to ensure the validity of the proposed model the study conducted a comparison between the proposed model fos with models in previous studies that addressed streamflow forecasting in nile river first an analysis between the fos with the mlp nn introduced by el shafie et al 2008b will be investigated the comparison will be focused on the best results provided by the current model and the previous model second a comparison analysis is conducted with the rbf nn proposed by el shafie et al 2008a two different statistical indicators were selected to examine the model in the testing stage including nrmse and correlation coefficient r2 the first indicator was selected to present the amount of enhancement accuracy in the error whereas the second index represents the range association between predicted and actual streamflow table 5 presents these statistical criteria for both models with every month as well as the accuracy improvement percentage ai indicator the accuracy improvement is measured for both indicators to determine the significance of the proposed fos model over mlp nn and rbf nn models the measured accuracy improvement could be expressed as follows ai i current i previous i current where i current is the value of the statistical indicator given by the current model fos and i current represents the same statistical index given by previous models mlp nn hors anfis and rbf nn the positive values of ai indicate enhancement of the model when the correlation coefficient r2 is used whereas the negative values of ai denote improvement of the current model when nrmse is used it can be observed from table 5 that the fos algorithm provided highly accurate statistical indexes for every month compared to mlp nn and provided less accurate ones for 2 months only august and september compared to the rbf nn model these months august and september represent the high streamflow class and this point approves for the above note that the fos method introduced low accuracy at the high streamflow pattern however the accuracy improvement using the current model fos was highly significant for other months compared to previous models by comparing the results of the proposed model with hors and anfis it is noticeable that the fos method has outstanding performance in terms of nrmse of up to 550 ai the correlation coefficient indicates a very minimalistic decrease in the performance of fos compared with hors and anfis with maximum ai 5 6 where this minor enhancement can be ignored because r2 is not only the indicator that can reflect the accuracy of the model in all cases in spite of that the hors and anfis have higher r2 for some months such as august and september by contrast nrmse has better results for fos in the same months table 6 presents the time required for running the method with the best model the maximum of total elapsed time application for the fos method has been precisely 10 61 s which indicates a very high speed of the model however the maximum time consumption in using mlp nn and rbf nn models is 64 24 s and 34 82 s respectively thus if time is to be considered for comparison purposes with other methods this implies that the fos approach is outperformed by the previous methods in this matter the current state of the art in streamflow forecasting for accuracy enhancement includes artificial intelligent methods ai which have had limited success in forecasting the long term streamflow thus there still exists a requirement for a streamflow accuracy enhancement technique that can mimic the streamflow non stationary pattern for both the short and long term errors in addition the suitability of the fos algorithm to accommodate different training approaches that might be more advantageous for a particular river case study over the other river cases to successfully achieve better forecasting accuracy this successful training approach while using fos might be difficult to be adapted while using ai algorithms such advantage in the fos algorithm which is invalid in the ai algorithms is of importance in the hydrological process specifically for streamflow in fact a particular training approach used with ai algorithm might cause redundance in the input data pattern and mislead the model in attaining an acceptable level of accuracy in addition for some training approaches the ai algorithms might be time consuming and thus inappropriate for real time application such as the application under this study for streamflow forecasting in fact the major reason for slightly poor accuracy for the peak streamflow forecasting based on the re values is due to the necessity to use small window size data for training the model to lessen the time consumed by training in fact increasing the size of the data window significantly increases the time needed to complete the training process to achieve the performance goal 6 conclusion this research introduced a new streamflow forecasting approach based on fos to enhance the accuracy for the streamflow forecasting fos offered a simple and efficient system modeling by using an arbitrary set of functions to represent data patterns the proposed fos based streamflow forecasting model was examined with three different training approaches using 130 years of natural streamflow historical data recorded on a monthly basis the results demonstrated the ability of fos based forecasting to achieve a relatively high level of streamflow forecasting accuracy for all the streamflow categories low medium and high while using the third training approach fos based streamflow forecasting provided a relatively poor level of accuracy for the high streamflow category this is probably due to the frequent fluctuations observed in the natural streamflow pattern of the high streamflow category the reported results demonstrated the capability of the fos based model in long term forecasting as it achieved close predictions with observed streamflow data according to the several statistical indicators for one year ahead forecasting for the natural streamflow this is a significant advantage of fos given that the vast majority of algorithms typically adopted for streamflow modeling are more suited for short term forecasting nevertheless the proposed fos based forecasting model experienced some of the common challenges of the existing forecasting models the major challenge encountered by fos based modeling was the requirement of relatively long historical data records to provide streamflow predictions with appropriate accuracy levels however this note was observed in streamflow patterns of the nile river hence another streamflow may behave differently where a shorter data record maybe sufficient for the fos method to mimic the behavior of a streamflow in addition the hydrological features of the nile river basin were missing in the model implementation as the study only focused on exploring fos capabilities in streamflow forecasting thus the proposed fos model was developed independently of the system s physical and or hydrological behavior the major advantage of this method is its ability to predict the system behavior without analytical prediction rules hydrological physical however comprising such hydrological behaviors in the forecasting model development can provide further enhancement the streamflow forecasting model s performance it should be noted here that there is no guarantee that the proposed model could be successfully applied for different case studies around the world however it should be noted that it is not related to the framework of the model but it might relate to how to structure and adapt the model to be suitable for a case study in other words in our case study training approach 3 has successful achieved the best results however in other case studies one of the other two training approaches presented in this study could achieve better results over the third approach by contrast it should be noted that the training process is the major component of developing any data driven model that definitely influences the whole performance of the model whatever its framework and its mathematical procedure in this context it is highly recommended for future research to investigate the potential of other training approaches that might be more suitable for different case studies furthermore there is no confirmation that the performance of the proposed model would be poorer when applied for a smaller time increment or scale for streamflow such observation should be first investigated by examining the proposed model in other case studies that experienced a daily or even hourly time scale for river streamflow it could be observed that the proposed model provided slightly low level accuracy in some of the peak streamflow points according to the re indicator the suggested model achieved poor consistency in the re over testing data therefore there is a need to improve the proposed fos algorithm to overcome such a weak point and this should be considered in future studies these limitations of the current modeling structure could be considered as a challenge to be implemented in future studies credit authorship contribution statement abdalla osman conceptualization methodology software writing original draft software writing review editing haitham abdulmohsin afan conceptualization methodology software writing original draft software writing review editing mohammed falah allawi data curation writing original draft software writing review editing othman jaafar writing original draft visualization investigation software writing review editing aboelmagd noureldin conceptualization methodology software writing original draft visualization investigation software writing review editing firdaus mohamad hamzah writing original draft visualization investigation software writing review editing ali najah ahmed writing original draft software validation writing review editing ahmed el shafie writing original draft supervision software writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors thankfully acknowledge ministry of higher education malaysia for fundamental research grant scheme frgs grant no frgs 1 2019 tk01 uniten 02 3 in addition the authors would like to thank university of malaya for the technical and financial support received from gpf082a 2018 the authors would like to thank enago www enago com for the english language review 
5502,when environmental tracers are used to determine groundwater age distributions various factors including measurement error model structural error and sample contamination can affect the outcome in this study we tried to untangle and explain the uncertainties associated with the inference of age distribution for a set of highly utilized production wells in a fractured rock aquifer system a total of 17 samples were collected at various depths 22 150 m from production wells these samples were analyzed for six age tracers including 3h tritiogenic 3he radiogenic 4he cfc 11 cfc 12 and cfc 113 a bayesian approach was used for evaluating age distribution for the samples based on several presumed lumped parameter models lpm s and shape free models it was found that the measured data in most wells could be explained by traditional lpms reasonably well however for five of the 17 wells it was found that the simple lpms were not adequate and the more complex shape free approaches resulted better based on the deviance information criteria dic measure this looked attributed to 1 competition between densely located wells 2 a thick vadose zone layer possibly causing preferential flows 3 fractures allowing a localized production furthermore it was shown that three other factors including tracer contamination non uniform 4he production and the heterogeneity in the travel time in vadose zone added uncertainties to groundwater age dating overall results showed that the combination of bayesian approach with dic criterion can help to identify uncertainties associated with the age distribution for hydrologically complicated systems keywords fractured aquifer age tracers bayesian inference uncertainty analysis lumped parameter models residence time distribution 1 introduction groundwater age is defined as the travel time of a water volume from the precipitation recharge point to a monitoring location in the aquifer the groundwater obtained from a pumping well however is a mixture of various water streams with different residence times this suggests that the groundwater age is not a scalar value but should be considered as a distribution bethke et al 2008 weissmann and fogg 1999 weissmann et al 2002 małoszewski and zuber 1982 suggested the use of lumped parameter models lpms to constraint the age distribution of a groundwater system in this approach a mathematical age distribution is presumed and its parameters are determined using environmental tracers such as chlorofluorocarbons cfcs busenberg and plummer 1992 plummer et al 2000 thompson and hayes 1979 3h and 3he schlosser et al 1988 schlosser et al 1989 solomon et al 2000 and sf6 tracers busenberg and plummer 2000 gooddy et al 2006 zuber et al 2006 the method is a cost effective approach compared to direct simulation of travel time distributions eberts et al 2012 however it is only applicable for the simple systems in which the groundwater mixing structure can be described in a simple mathematical form leray et al 2016 weissmann et al 2002 weissmann et al 2002 suggested that the groundwater mixing problem could be overcome by constructing a high resolution numerical model based on realizations created according to the geostatistical properties of the hydraulic conductivity field however the numerical models may not be capable of reproducing the highly localized flows such as when there is perturbative capture zone competition between production wells which can be crucial for the age dating of an actively developed groundwater system visser et al 2013 to overcome the irregular hydrological mixings originated from a complex aquifer setting and from production well screen visser et al 2013 proposed the shape free age model in contrast to earlier methods this approach doesn t presume a mathematical form shape or demand high resolution geologic data in describing the groundwater age distribution but rather it allows the water fraction to be variable in a pre determined number of age bins that results in the best reproduction of measured data the age tracers with different historical accumulation or decay rates in a groundwater system could explain the various spectra of groundwater residence time and therefore can collectively help infer the age distribution cook et al 2000 massoudieh et al 2012 applied bayes theorem to lpms for quantifying the uncertainties associated with the estimation of groundwater age distributions this way the uncertainties stemming from measurement error and other factors such as subsurface decay microbial degradation and dilution of tracers after groundwater recharge as well as model structural error due to the idealized forms of lpms can be systematically propagated into the inferred parameters of lpms massoudieh et al 2014a used this approach to quantify the improvement in the reliability of age distribution inferences when measured tracers at multiple times are available the bayesian approach was later applied to the shape free approach by allowing a markov chain monte carlo mcmc algorithm to generate a posterior probability distribution of fractions of water in a set of pre determined age bins massoudieh et al 2014b the groundwater system near private wells at the eumseoung site is very complex because of a relatively wide and non uniform unsaturated zone a heterogeneous and anisotropic field of a non uniform fractured system and a production competition among densely located agricultural wells see section of site description for details these can make a reliable estimation of groundwater age challenging in this study an attempt has been made to infer the groundwater mixing mechanism and groundwater mean age of the private wells based on multiple age tracers chorco alvarado et al 2007 plummer et al 2001 reilly et al 1994 visser et al 2013 including 3h 3he 4he cfc 11 cfc 113 and cfc 12 through bayesian inference to handle the possible irregular shape of groundwater age distributions and the fact that the groundwater may be a mixture of young and old groundwater a new free step size model was introduced in this study the bayesian approach is expected to allow us to quantify the uncertainties associated with estimating the age distributions in this complex aquifer system 2 methods 2 1 site description the study site is located in the upper miho river watershed of eumseong south korea fig 1 samples were mainly collected from the southern part of the watershed which has a gentler slope compared to the more rugged landscape in the north k water and molit 2009 71 of the annual precipitation occurs in the rainy season june september korea meteorological administration website www kma go kr groundwater recharge actively occurs in the northern part of the basin and moves downstream to the southern part following a hydraulic gradient of approximately 0 003 the linear groundwater velocity has been estimated to be around 0 06 0 44 m d 1 lee et al 2017 the vertical profile of the study site was revealed by drilling a series of borehole bh wells fig 1 at the location of most boreholes the stratigraphy consists of a top alluvial layer 0 2 m b g s a weathered layer 2 70 m b g s and bedrock 70 m b g s ju et al 2018 the weathered layer can be further characterized by two distinguished layers including a highly fractured zone weathered soil at 2 30 m b g s and a weathered rock layer situated underneath it between 30 and 70 m b g s depths the aquifer is unconfined without any impermeable layer the local permeability field was examined by an electrical resistivity survey near the bh series wells fig 1 in which the horizontal intrinsic permeability ranged from 6 18 10 14 m2 to 1 76 10 12 m2 while the vertical one ranged from 1 24 10 14 m2 to 3 52 10 13 m2 table 4 in lee et al 2017 in korean showing a very heterogeneous and anisotropic system at this site in addition kim et al 2018 identified a non uniform hydraulic conductivity field from push and pull tests using cl and sf6 tracers near the bh series wells fig 1 ranging from 4 0 10 6 m s 1 to 2 0 10 5 m s 1 on four repeated experiments agricultural fields constitute the majority of the land cover in the basin with approximately 70 2 of the land cover near the production wells being agricultural fields table 1 the agricultural paddy and non paddy fields can be differentiated based on their soil permeability the paddy field consists of muddy soil and are able to maintain a shallow water table for cultivating rice fig 1 ju et al 2018 the industrial and residential areas contain impermeable surfaces however the impervious surfaces are not continuously covering the surface within each private well s radius of influence roi but are widely scattered through the study site table 1 the private wells were densely located in the study site bg 01 to 29 and it seems that in many instances their rois overlap as they compete for groundwater fig 3 in ju et al 2018 in this study we were limited to 12 of the 29 private wells due to the restrictions on the gas sampling procedure fig 1 the information on well depth and hydrostratigraphic characteristics is necessary to understand the age distributions of an aquifer system the information was provided by korean government or by performing direct measurements for privately constructed wells table 1 throughout the sampling locations the depth of the unsaturated zone was relatively thick varying between 3 6 m b g s and 27 8 m b g s and the lower elevation of the production well screens ranged between 22 0 m b g s and 150 5 m b g s table 1 the bg 01 and bg 24 private wells didn t have any reported information regarding screen depth just relying on direct measurement it was also found that the well depths of bg 07 bg 14 bg 19 bg 27 and bg 28 differed from the reported ones probably due to poor record keeping by the private well owner we were not able to measure the depth to the water table for bg 03 bg 04 and bg 29 because the tops of the production wells were tightly closed their water table levels however were expected to be consistent with adjacent production wells as judged from a relatively uniform distribution of them through the production points table 1 2 2 water sampling and data acquisition in march of 2015 17 groundwater samples were collected from 5 monitoring wells and 12 private wells using a peristaltic pump after three borehole volumes of water had been purged fig 1 a detailed description of the sampling procedure can be found in ju et al 2018 groundwater samples for cfcs were collected following iaea 2006 protocol busenberg et al 2006 samples were triplicated and contained in glass bottles sealed by caps with metal liners analysis of cfc 11 cfc 12 and cfc 113 were conducted at the university of utah through gas chromatography in a closed system where the cfcs were stripped out from the water sample and measured against a standard gas which following general procedures suggested by the u s geological survey cfc laboratory in reston va busenberg and plummer 1992 the standard deviation of the measured concentrations was found to be less than 2 for cfc 11 and cfc 12 and about 3 for cfc 113 the analytical precision is about 50 near detection limit and about 3 above 25 pg kg 1 dissolved noble gas lab university of utah website http www noblegaslab utah edu the noble gas components such as he ne ar kr and xe and he isotope ratios 3he 4he were also analyzed at the university of utah aeschbach hertig et al 2013 solomon et al 2015 the measurement error for he tracers are estimated to be less than 1 and less than 5 for other noble gases manning et al 2005 solomon et al 2010 approximately 28 cm3 of groundwater was collected in a copper tube and sealed off using stainless steel clamps to avoid contact with the atmosphere gases were first extracted from the groundwater sample and stored in a stainless steel flask bayer et al 1989 before injecting samples into the mass spectrometer excessive water vapor active gases and other condensable gases were removed through a purification process using cryogenic traps lott 2001 and saes getter pumps he tracers were quantified using a quadrupole mass spectrometer stanford research systems rga300 while he and 3he 4he were analyzed by a sector field mass spectrometer mass analyser products model map 215 50 equipped with an electron multiplier to measure low abundance ions in high precision and a faraday cup to measure more abundant ions then electrical responses of six components were converted into the air quantity by comparing to a standard gas dry atmosphere the 3h samples were analyzed in the korea institute of geoscience and mineral resources kigam using low level tritium analysis samples were collected and stored in high density polyethylene hdpe plastic bottles prior to the analysis the electrolytic enrichment method was utilized to lower the detection limit of 3h by adding 4 g of na2o2 and 1 ml of standard solution to 400 ml of groundwater sample the electrolyzed sample 25 ml was washed with high purity co2 to precipitate naoh into na2co3 and remove it from the solution then samples went through a distillation column to be purified the 10 ml of purified sample was mixed with 10 ml of a scintillation solution the spectrum of tritium was measured by liquid scintillation counter lsc method the detection limit of this method is 0 8 tu and lsc counting efficiency is 28 70 0 27 yoon et al 2007 2 3 preparation of the input record cfc 11 cfc 113 and cfc 12 are anthropogenic compounds that were manufactured from the early 1930s to the 1990s therefore the cfcs can act as an age marker for dating relatively young groundwater ekwurzel et al 1994 plummer et al 2000 the atmospheric cfcs are known to have a small spatial variation below 10 around the globe kazemi et al 2006 therefore the data from north america was used for the study site s cfc input the north american atmospheric station is located at an elevation of 3 013 m in the rocky mountains near boulder colorado elkins et al 1996 the 3h is a radioactive isotope of hydrogen naturally produced by cosmic radiation or a nuclear reaction process solomon et al 2000 the current state of 3h in this study site was reconstructed from 3h input history reported by international atomic energy agency iaea iiaea wmo 2015 with the decay rate of 12 43 y lucas and unterweger 2000 missing data in the 3h input history was calculated by correlation analysis between several observatories such as daejeon korea pohang korea tokyo japan vienna austria portland oregon united states washington united states and hong kong china koh et al 2005 the radiogenic 4he is a stable nuclide produced by the alpha decay of th and or u in crustal materials the production rate of radiogenic 4he in this process is slow enough to conserve the contents of the parent material therefore in groundwater systems radiogenic 4he is linearly accumulated along a flow path at a constant rate kipfer et al 2002 the accumulation rate of radiogenic 4he for the study area was reconstructed to calculate the groundwater residence time following the zhou and ballentine 2006 eq 1 and 2 1 4 he in situ production ρ λ j 4 he 1 φ φ t 2 j 4 he 0 2355 10 12 u 1 0 123 th u 4 where ρ is the density of porous rock g cm 3 λ is the parameter defining the efficiency of transfer from the rock matrix to groundwater φ is the rock porosity j 4 he is the source function of radiogenic 4he in the aquifer matrix cm3stp4he g rock 1 y 1 t is the groundwater residence time y and u and th are the u and th concentrations in rock ppm 2 4 bayesian inference and markov chain monte carlo simulation a bayesian inference was used for identifying the age distribution of groundwater samples the simulation was performed using a markov chain monte carlo mcmc algorithm based on massoudieh et al 2012 in bayes theorem the posterior distribution of parameter values for the age distributions can be defined as 3 π θ γ c π c θ γ π θ γ where θ is the vector of model parameters γ is the variance covariance matrix of errors π c θ γ is the likelihood function or the likelihood of observing the measured tracer concentrations c given model parameters θ and the variance covariance matrix γ and π θ γ is the prior distribution of model parameters and the elements of the variance covariance matrix we here assume that the distribution of errors is independent a priori and that the prior distribution of model parameters are also independent the distributions of priors are reported in table 2 and the ranges of them were roughly decided to cover the plausible ranges in typical shallow aquifer system the independent units allow for expressing the prior distribution of model parameters as the multiplication of prior distributions for each model parameter i e π θ k 1 l π θ k it also allows for expressing the likelihood function as 4 π c θ γ g i j c i j i 1 m j 1 n σ i j e j 1 n i 1 m g c i j g c i j 2 2 ln σ i j 2 where c is the predicted tracer concentration based on parameter values θ m is the total number of age tracers n is the total number of production wells σ i j is the standard deviation of tracer i in well j that is error or uncertainty lying on the tracer concentration due to either measurement error or model structural error g is the mapping function that transforms the errors into a designated distribution and g is its derivative for example if the error structure is assumed to be gaussian g x x and if it is assumed to be log normally distributed g x ln x here we assume a tracer to have the same error structure and error standard deviation in all wells and therefore g i j g i and σ i j σ i the metropolis hastings algorithm was used to perform the mcmc sampling hastings 1970 2 5 groundwater mixing models the lumped parameter models lpm can shed light into the groundwater mixing problem małoszewski and zuber 1982 in this study four lpms including the piston flow model pfm exponential mixing model emm dispersion model dm shifted exponential mixing model semm and two alternative shape free models have been used to interpret the groundwater mixing table 2 a pfm represents a system where a minimum level of mixing takes place and that the production well extracts water effectively from a single groundwater stream the emm represents a groundwater system where a maximum level of mixing occurs between various streams the dm assumes an aquifer has a semi infinite recharge medium the semm represents an idealized system where a no dispersion flow path is followed by a fully mixed zone jurgens et al 2012 note that these traditional lpms are referred to as shape models in the results and discussion section according to the definition of a shape free model see the following paragraph visser et al 2013 the shape free models are especially beneficial when 1 a simple mathematical model i e shape model cannot represent the complexity of the age distribution 2 multiple age tracers are available and 3 the input history and or decay rate of the tracers contains information about a substantially different parts of the age distribution 11 bins for both shape free approaches resulting in ten unknown parameters table 2 so considering the fact that four tracers were available the model is clearly over parameterized however the cumulative age distributions are expected to be constrained as stated by massoudieh et al 2014a the shape free models are based on describing the age distribution as a histogram table 2 the shape free histogram model sfhm is based on presuming the bounds of the histogram bins a priori and then treating the bin contents as parameters to be estimated this approach has been previously used by visser et al 2013 and massoudieh et al 2014b the second shape free approach that is introduced here is based on fixing the contents of the histogram bins a priori and then treating the bounds of the histogram bins as parameters to be estimated by the inverse modeling technique we refer to this second approach as the free step size model fssm the second approach is more suitable in cases where the age distribution is highly skewed or heavy tailed due to the fact that its bins can cover the wider age spectrum for the lpms the prior distributions of the model parameters were assumed to be uniform table 2 specifically the prior distribution of mean age θ 1 in all lpms including pfm emm dm and semm was assumed to be uniform from 15 to 220 y while the prior distribution of the dispersion parameter θ 2 in the dm was assumed to range from 0 01 to 50 the shift parameter θ 2 in the semm was also considered to be uniformly distributed from 0 01 to 50 y table 2 the error structure i e g of the residuals between the modeled and observed values were considered to be log normal eq 4 massoudieh et al 2012 2 6 model selection deviance information criterion dic gamerman and lopes 2006 spiegelhalter et al 2002 was used to compare the ability of the model to explain the observed tracer data dic evaluates the goodness of fit based on the difference between the predicted and observed data while penalizing for model complexity eq 5 thus favoring models that cause a lower level of equifinality 5 dic 2 d θ d θ 6 d θ 2 e ln p c θ 2 ln f c 7 d θ 2 ln p c θ 2 ln f c where d θ is the mean deviance d θ is the deviance of the mean f is a standardizing term that is a function of the observation data θ is the random vector distribution corresponding to the posterior distribution and θ is the expected value of the posterior distribution of parameters the tracer concentrations at a discharge point is a function of recharge concentration c i 0 t a age distribution density ρ i a and the sources and sinks of each tracer in a subsurface system małoszewski and zuber 1982 fig 2 cfcs were assumed to undergo no decay and therefore the following equation was used to calculate the concentrations based on the age distribution 8 c i t 0 c i 0 t a ρ i a da for tracers undergoing first order decay such as 3h the concentration is calculated as 9 c i t 0 c i 0 t a e λ i a ρ i a da the tritiogenic 3he is the decay product of the 3h tracer because it is poorly soluble in water most of it is lost back into the atmosphere during the unsaturated zone travel time fig 2 assuming that all the tritiogenic 3he was lost in the unsaturated zone the concentration of 3he in the groundwater can be calculated via 10 c i t 0 c i 0 t a e λ i t us 1 e λ i a t us h a t us ρ i a da where t us is the travel time in the vadose zone and h is the heaviside function assuming that radiogenic 4he accumulates linearly only in the saturated zone fig 2 as with the theoretical rate described in the section 2 3 preparation of the input record its concentration in groundwater can be calculated as 11 c i t 0 c i 0 t a λ i a t us h a t us ρ i a da 3 results and discussion 3 1 groundwater apparent age the concept of apparent age or piston flow age allows the hydrologist to estimate the groundwater age directly by assuming no significant groundwater mixing for a groundwater system bethke et al 2008 three different tracers including event markers i e cfcs radioactive tracer i e 3h 3he and accumulating tracers i e radiogenic 4he were applied to identify the apparent age of this site cook et al 2000 3 1 1 event markers cfcs the cfcs are the age markers for dating relatively young groundwater up to 70 y ekwurzel et al 1994 plummer et al 2000 the gas tracers are however easily subjected to air intrusion during the groundwater recharge period therefore the excess air correction was made for the cfcs using biochemically inert noble gas tracers prior to age determination aeschbach hertig et al 2008 the bh 02 was the most air contaminated sample of which 29 2 of cfc 11 137 0 of cfc 113 and 54 0 of cfc 12 came from the excess air intrusion respectively table 3 and table s1 in supplementary material one thing that needs to be pointed out is that nine cfc 11 samples and three cfc 12 samples still showed a larger value than the historical maximum concentration indicating that the local contaminant source could affect the cfcs in the study site kazemi et al 2006 the groundwater ages calculated using cfcs showed relatively consistent distributions among produced samples such as 28 3 39 2 y for cfc 11 26 8 37 0 y for cfc 113 and 32 2 41 5 y for cfc 12 table 3 3 1 2 radioactive tracer 3h and 3he the decay of 3h accumulates the tritiogenic 3he in the groundwater system with the half life of 12 43 y lucas and unterweger 2000 in a closed system the tritiogenic 3he accumulates in the groundwater system without being lost into the atmosphere this provides another way for dating relatively young groundwater up to 60 y solomon et al 2000 firstly the current state of 3h was reconstructed for the study site see the 2 3 preparation of the input record for details 3h was up to 58 8 tu during the nuclear test period 1954 1964 followed by a drop to the natural background level below 4 0 tu after 1999 fig 3 according to the reconstructed history the existence of an exceptionally low tritium concentration below 1 tu indicates a notable influence of pre modern groundwater i e prior to 1953 fig 3 the old water 1 tu however only could be observed when more than 66 1 of the water is comprised of old water avg of years 1865 1950 0 02 tu if the reminder of the water was recharged since the year 1999 avg 2 90 tu or more than 95 6 with the remainder is recharged during the peak period of 1958 1967 avg 22 02 tu the produced samples however in none of the wells seem to be significantly affected by old groundwater as 3h was maintained larger than 1 42 tu table 4 the apparent groundwater age was calculated for 17 production wells based on the reconstructed input history and a known decay rate τ 1 2 ln 2 following schlosser et al 1988 schlosser et al 1989 12 τ τ 1 2 ln 2 ln 1 he 3 h 3 where τ is groundwater apparent age τ 1 2 is the half life of 3h of 12 43 y lucas and unterweger 2000 and 3he and 3h are the concentrations of each species in a unit of tu the calculation was preceded by a component separation process using noble 90 i e compiled matlab routine of groundwater recharge models to separate the tritiogenic 3he of the 3h beta decay origin from the other atmospheric and radiogenic origins of the total he aeschbach hertig et al 2008 the calculated apparent ages were ranging from 0 y to 48 6 y table 4 the raw data for the analysis can be found in supplementary table s2 the bg 24 showed an erroneous recharge temperature of 47 4 c that is unrealistic for this shallow groundwater condition indicating this sample had been deteriorated by degassing loss table 4 a detailed discussion on the degassing issue was made in the section on bayesian inference influence of heterogeneous geophysical setting on the age distribution 3 1 3 accumulating tracer 4he the radiogenic 4he does not react or adsorb strongly to soil materials but linearly accumulates in the groundwater system after its production from the radioactive crustal element thus it is widely used for the age dating of groundwater water especially for very old water zhou and ballentine 2006 the bedrock of the study site consists of mesozoic granitic rocks containing u of 0 24 4 56 ppm x 2 21 ppm σ 0 76 and th of 0 41 19 12 ppm x 8 32 ppm σ 3 56 with the porosity of 0 06 and bulk density of 2 2 g cm 3 jurgens et al 2012 ju et al 2018 this resulted in an estimated radiogenic 4he accumulation rate of 18 4 micro cm3 m 3 y 1 for this site eq 1 and 2 the radiogenic 4he of the groundwater samples were separated and quantified using noble 90 with noble gas input data table 4 aeschbach hertig et al 2008 the maximum concentration of radiogenic 4he was 3 08 10 8 cm3 stp g 1 corresponding to the groundwater age of 2067 y which clearly contradicts with the young apparent ages from the 3h 3he and cfcs data this value is also unrealistic for the shallow groundwater system indicating an unknown source of the radiogenic 4he that exists in the study site 3 1 4 groundwater mixing scenarios the apparent ages calculated from the three different methods showed mismatches for 17 samples table 3 and 4 putting the assumption that the simple apparent age or piston flow age represents the mean groundwater age into question this was also proved in the spatial distribution of age tracers fig 4 which was expected to show a particular relation to the groundwater flow direction since water age is expected to increase toward the downstream of the study site reilly et al 1994 for example cfcs would gradually decrease toward the downstream of a flow line according to their linearly accumulating input history within the groundwater system in fig 4 six different tracers were presented along with the piezometric head distribution the residence time of the groundwater in this site is expected to increase from the northwest to southeast directions however the tracer distributions did not show any particular relation to the flow direction this fact implies that the mean age is possibly defined by groundwater mixing processes along the screen of each production well not by a piston like flow system jurgens et al 2012 lpms can provide insight into the groundwater mixing structure and the groundwater mean age for individual production wells małoszewski and zuber 1982 the groundwater mixing scenarios associated with each well is depicted in the tracer tracer graphs with the selected mathematical shape models such as the pfm emm dm and binary mixing model bmm jurgens et al 2012 małoszewski and zuber 1982 fig 5 in fig 5 the 3h and cfcs tracers were plotted with their error ranges based on the assumed lpms in the case of cfc 11 11 of 17 samples showed deviations that were too large according to the mathematical mixing models fig 5a and b furthermore the gas tracers tritiogenic 3he and radiogenic 4he showed large errors and many of the samples could not reduce the discrepancies between the observed data and the modeled ones fig s1 in supplementary material indicating that there are unknown factors affecting the tracers distributions not efficiently reproduced by the simple lpms 3 1 5 bayesian inference although the lpms are known to provide a straightforward characterization of hydrologic conditions in the current system the simple shape models were not capable of explaining the variation of observed data showing large discrepancies with what is expected based on lpms fig 5 and fig s1 in supplementary material this can be attributed to 1 lack of flexibility in the lpms to represent the complex groundwater mixing massoudieh et al 2014b and 2 undefined sources and sinks of age tracers such as local contamination degradation degassing or other unknown factors alikhani et al 2016 therefore it was deemed to be necessary to employ more flexible models to explain the tracer data a total of six different models such as two alternative shape free models in addition to the four traditional shape models as explained in section 2 5 were utilized to explain the groundwater mixing and therefore to constrain the distribution of six age tracers including 3h cfcs tritiogenic 3he and radiogenic 4he models with a larger number of unknown parameters however inevitably result in higher levels of non uniqueness and thus uncertainty about the value of the parameters massoudieh et al 2012 massoudieh et al 2014a therefore to evaluate the uncertainty in model performance bayesian mcmc and dic criteria were applied for the groundwater mixing problem bayesian inference influence of groundwater mixing on the age distribution the suitability of various groundwater mixing models are compared using the dic measure gamerman and lopes 2006 massoudieh et al 2012 spiegelhalter et al 2002 for wells bg 14 bg 19 and bg 27 the pfm resulted in the lowest dic value table 5 suggesting those wells contain a relatively narrow range of groundwater ages this may be attributed to narrow screens or a wide impervious surface near the production wells the dic values for wells bg 03 bg 04 and bh 04 points to an emm table 5 implying that the screens are extended through active groundwater mixing zones preferentially capturing a large portion of young groundwater the wells bg 24 bh 01 bh 02 and bh 05 adopted the dm table 5 suggesting the moderate mixing of groundwater the semm was preferred by wells bg 01 and bh 03 the shift parameter of semm the θ 2 indicates that the partial screen of production wells affected the groundwater mixing or that an impermeable land surface resulted in recharge delay table 5 jurgens et al 2012 the shape free model has a higher level of flexibility as compared to the shape models i e traditional lpms table 2 two shape free models including the shape free histogram model sfhm and the free step size model fssm were evaluated bg 02 bg 07 bg 15 bg 28 and bg 29 preferentially were adopting two shape free models table 5 for these wells a narrow confidence range was obtained for shape free models despite the large number of input parameters fig 6 in this site the production wells are located in the agricultural area in which numerous private wells are competing for the groundwater production ju et al 2018 the competition of the production wells was known to make the local hydrological system heterogeneous visser et al 2013 which seems to demand a high level of flexibility for a model to explain the complex groundwater mixing structure furthermore when shape free models were preferred the dic was mostly better for fssm than sfhm which can be attributed to the higher flexibility of the fssm model in capturing different portions of the groundwater age distribution despite having the same number of parameters table 5 even though the age density of the shape free models show some oscillation as compared to the shape models the cumulative distributions are smoother fig 6 for most wells the modeled distributions of shape free models overlapped with that of the simple shape models suggesting that the traditional lpms are also capable of capturing groundwater mixing at this site in some cases the sfhm showed notable deviation with other models e g fig 6c and d for example the sfhm had the abnormal sharp increase in the old recharge period and this was apparent for wells containing older groundwater such as bg 03 and bg 04 fig 6c and d this problem originated from limiting the bounds of the groundwater age to 110 9 y in the sfhm model table 2 this issue was not observed when the fssm approach was used due to the fact that no limits to the age range are imposed on it wells bg 02 bg 07 bg 15 bg 29 and bh 05 showed relatively large dic values 10 4 table 5 the bh 05 had an unrealistic tritiogenic 3he concentration of 0 tu table 4 the others showed a highly elevated cfc 11 concentration which cannot be explained by north american input history table 3 the latter ones looks affected by contamination to see the influence of contamination on the inference of the model parameters another set of simulations was conducted excluding the contaminated samples from input data sets fig 7 as a result most of samples except bg 28 showing improvement in dic however bg 02 bg 15 bg 29 and bh 05 still resulted in large dic values 20 4 fig 7 indicating the errors did not solely originate from the contamination the age tracer distributions in this site could not be explained just by groundwater mixing model it seemed affected by undefined mechanisms note that two simulations showed the overall consistent estimations for tracer concentrations despite the high level of contamination shown in the data set fig s2 in supplementary material which is attributed to the structure of the bayesian likelihood function not allowing the method to assign larger error standard deviations to the tracers that cannot be reproduced effectively in turn assigning those tracers a lower weight i e 2 ln σ i j in eq 4 bayesian inference influence of heterogeneous geological setting on the age distribution the multiple tracers generated a signal to constrain the age distribution for collected groundwater samples however in this site the observed tracer distribution could not be perfectly explained only by groundwater mixing possibly attributed to the other mechanisms in the groundwater system alikhani et al 2016 the current study site is characterized by a wide and variable depth of vadose zone and heterogeneous weathered medium fig 2 the wide vadose zone possibly affect the distributions of the insoluble age tracers i e tritiogenic 3he and radiogenic 4he visser et al 2007 and non uniform fractured system is known to affect the distribution of radiogenic species i e radiogenic 4he solomon et al 1996 we performed four additional sets of mcmc simulations to identify the major processes responsible for the tracer distribution 1 without considering vadose zone delay t us and the non uniform radiogenic 4he accumulation rate λ 4 h e throughout the study site 2 with non uniform vadose zone delay t us 3 a non uniform radiogenic 4he accumulation rate λ 4 he and 4 with inclusion of both parameters two parameters i e t us and λ 4 he should be thoroughly reviewed when the insoluble and radiogenic substances are adopted for age determination kazemi et al 2006 the t us parameter was firstly incorporated in the simulation to see the influence of heterogeneous vadose zone on the tracer distribution in this site after applying the new parameter on the simulation nine of 17 samples showed an improvement in terms of dic value fig 8 a and b three of them considered this version of the estimation as the best one see the third column in table 6 indicating the t us cannot be ignored in explaining the tracer distribution of this site with the incorporation of t us the estimation was improved for the tritiogenic 3he tracer specifically in samples bg 03 bg 07 bg 29 and bh 05 where the bias of modeled ranges to measured value was reduced notably fig 9 a on the other hand some results were overestimating the tritiogenic 3he tracer for bg 04 bg 14 and bh 03 fig 9a this was affected by large amounts of radiogenic 4he in the samples demanding a long residence time for reproducing the measured data which inevitably resulted in the elevation of the tritiogenic 3he fig 9a and b since current simulation can not explain the large amount of radiogenic 4he another parameter is necessary to explain the tracer distribution properly fig 9b note that for bg 02 bg 15 bg 29 and bh 05 a zero value for the modeled he concentrations were obtained fig 9a and b which resulted from a large vadose travel time table 6 the incorporation of λ 4 he in the simulations improved the dic value for 11 of the 17 samples fig 8a and c and seven of the samples considered this version of the estimation as the best one table 6 suggesting the non uniform distribution of λ 4 he throughout the study site when λ 4 he is treated as an unknown parameter the inferred 4he resulted in a better agreement with the measured values for most of the wells as compared to the case when λ 4 he was a constant fig 9b and d this improvement was however not apparent for the samples having a small radiogenic 4he amount for example the samples bg 15 bg 19 bg 29 bh 01 and bh 05 presented relatively highly overestimated values with wide credible intervals fig 9d it is evident that the current simulation demands the additional parameter to compensate the overestimation of tritiogenic 3he and radiogenic 4he tracers such as degassing loss of insoluble tracers during vadose zone delay i e t us in consideration of the geological setting of study site i e the wide vadose zone in many cases the estimated radiogenic 4he had wide credible intervals showing high uncertainty in their estimation fig 9d in the bayesian mcmc the uncertainty of input parameters can propagate into the output distribution and considering the fact the reproduced radiogenic 4he is relying on the λ 4 he parameter the wide distribution of radiogenic 4he could stem from the prior distribution of λ 4 he another set of simulations was performed in which the distribution range of the λ 4 he prior was repeatedly adjusted fig 10 in fig 10a the uncertainty level was gradually improved with reducing the range of the prior distribution however it was not a proper treatment for samples containing the large amount of radiogenic 4he for example in bg 01 the radiogenic 4he could not be accounted for with the small prior ranges below 0 01 20 10 9 cm3 stp g 1 y 1 fig 10a furthermore the uncertainty level of the reproduced values were rather consistent when the prior range contained the measured value that is the prior distribution of 0 01 30 in fig 10a and all ranges in fig 10b indicating the prior distribution was not the primary reason for the wide uncertainty levels according to massoudieh et al 2014b the wide credible interval is also observable when the estimated parameters are correlated however this was also not the case for this study site as significant correlation was not found between estimated parameters fig s3 in supplementary material one obvious thing we can say for this situation is that λ 4 he is currently constrained only by single tracer the radiogenic 4he tracer which could result in the high level of uncertainty in model estimation that is current model has a possibility to be improved by incorporating new tracers related to the radiogenic production in the groundwater system the simulation with both t us and λ 4 he parameters was effective as 14 of 17 samples showed improvement in terms of dic value fig 8a and d these improvements include several samples which previously showed an improvement by incorporating a single parameter in the simulation just t us or λ 4 he in addition although bg 04 did not show any improvement in the previous simulations it is better constrained by using both t us and λ 4 he parameter on the other hand samples such as bg 24 and bh 01 lost the explanatory power for the observation data when treating both t us and λ 4 he as unknown parameters indicating the new parameters added unnecessary complexity in the model rather than constraining the tracer distribution in this set of simulations more than one third of samples i e seven of 17 however resulted in the best dic when vadose zone travel time was considered and λ 4 he was treated as unknown i e the case 4 table 6 confirming the significant influence of both t us and λ 4 he parameters on tracer distributions in this study site note that the overestimation of tritiogenic 3he and radiogenic 4he was still observable even though wide ranges of t us 30 y and enough low λ 4 he 10 11 cm3 stp g 1 were provided for the simulation to improve the bias in our current situation it would be efficient to incorporate new tracers with smaller error than that of current tracers i e σ i j in eq 4 or to apply a transient data set as massoudieh et al 2014a done for their simulation the model identified as best according to the dic are summarized in the last two columns of table 6 though some samples still provided high uncertainty from the bayesian mcmc the dic values showed clear improvement from 10 6 28 1 to 21 1 11 5 for 17 samples after incorporating new parameters which again highlights the significant influence of vadose zone delay t us and radiogenic 4he accumulation λ 4 he on the distribution of age tracers throughout the study site even after including the additional parameters still did the bg 02 bg 07 bg 24 bg 28 and bh 01 exhibit the complex groundwater mixing structures table 6 it looked attributed to the action of the wide and thick vadose zone and fractures to the groundwater residence times the thick and wide vadose layer noticeably delayed the groundwater flow up to 27 6 y in the site table 6 in addition to the flow delay the vadose layer was well known to generate the lateral and preferential flows depending on a heterogeneous permeability distribution in that layer kung 1990 resulting in the various streams of different residence times furthermore fractured unit of the aquifer allowed a localized production through the vertical conduits in the site as evidenced from the wide distribution of 4he accumulation rate of 0 2 7 9 10 10 cm3 stp g 1 y 1 table 6 and which supports the situation that deeper groundwater was added into the shallow production through the vertical conduits resulting in the complex age distributions bayesian inference uncertainties lying on individual age tracers multiple tracers were incorporated into a bayesian simulation to overcome the lack of preliminary knowledge on hydrogeological system the advantage of 3h tracer in groundwater age dating is that since it is a part of the water molecules it is not lost into the atmosphere once it has entered the subsurface system its decay rate is also known with very high accuracy lucas and unterweger 2000 it is not affected by the vadose zone travel and or the excess air intrusion or degassing problem in subsurface system therefore there was no significant improvement after the incorporation of new parameters i e t us and λ 4 he fig 11 a note that the bg 19 looks attributable to analytical failure which cannot be explained within the model structure the modeled cfcs showed a large overestimation compared to measured values indicating the existence of a local unknown source in this site red symbols in fig 11d and f 11 of cfc 11 samples and three of cfc 12 samples were deteriorated by unknown local sources the cfcs could not be improved upon with any new parameters as their bias was originated from unknown sources which can not be described in the conceptual model fig 11d and f the high level of cfc contamination has been reported in agricultural lands of south korea in which the elevation of cfcs was noticeably more than the historical maximum concentration due to the plastic pe or pvc casing of the wells kaown et al 2009 additionally cfcs can also have negative bias when they are affected by microbial degradation in the groundwater system possibly resulting in the overestimation without proper parameters to explain the lost amount sebol et al 2007 in this site however the groundwater system maintains an oxic condition 5 0 ju et al 2018 therefore the degradation of cfcs is a minor issue this statement also can be verified from fig 11d e and f where the estimated values mostly followed the measured data without overestimation contrary to 3h and cfcs tracers the distribution of tritiogenic 3he tracer was not solely constrained by groundwater mixing but significantly affected by vadose zone delay t us in this site table 6 in the first place we observed discrepancies between the cfcs and 3h 3he in apparent age for 13 of 17 samples table 3 and 4 the cfcs ages were older than the 3h 3he ones up to 32 4 y this situation is normally observable in the thick vadose zone system kaown et al 2009 therefore the t us was incorporated in the bayesian mcmc and resulted in 11 5 27 6 y of mean delay times for groundwater productions table 6 this range is corresponding to the infiltration rate of 0 25 1 84 cm d 1 assuming that the groundwater recharge mainly occurred near production wells which overlaps the ranges calculated from a previous study 0 27 1 17 cm d 1 table 1 in razavipour and farrokh 2014 however samples such as bg 15 bg 29 and bh 05 reached the limit of the t us value table 6 indicating that other processes are responsible for the low level of tritiogenic 3he in this site this is possible for example in the case of degassing loss by contacting with bubbles or by confronting any decompression situation during groundwater transport visser et al 2007 note that most of 3h 3he age was underestimating the groundwater age fig s4 in supplementary material also suggested the significant degassing loss radiogenic 4he is normally assigned to explain the very old groundwater for the samples solomon et al 2000 as already mentioned in the previous section i e 3 1 3 accumulating tracer 4he this tracer however exhibited a large discordance with other age tracers in apparent age estimation this can be attributed to the existence of very old groundwater fraction or an additional radiogenic 4he source exists in the study site bethke et al 1999 castro et al 1998 torgersen and clarke 1985 zhou and ballentine 2006 the possibility of a shallow aquifer to be mixed with the old groundwater however looks very low as the large amount of radiogenic 4he could not be explained with the fssm possessing a wide age distribution range fig 9b the accumulation rate of radiogenic 4he was evaluated in the bayesian inference by incorporating additional parameters the λ 4 he which varied from 1 8 10 11 to 7 9 10 10 cm3 stp g 1 y 1 in this site table 6 this range is relatively large in comparison to the reported values such as 1 10 11 to 2 10 11 cm3 stp g 1 y 1 in visser et al 2013 1 3 10 10 cm3 stp g 1 y 1 in solomon et al 1996 5 3 10 12 cm3 stp g 1 y 1 in sültenfuß et al 2011 and also much overriding the theoretical value of 1 84 10 11 cm3 stp g 1 y 1 calculated using u and th contents see the 3 1 3 accumulating tracer 4he this indicates that the relatively large extra flux of radiogenic 4he exists throughout the study area therefore the radiogenic 4he tracer naturally showed the noticeable improvement after incorporating the λ 4 he in the simulation fig 11c note that the accumulation rate of radiogenic 4he is not related to the production well depth fig s5 in supplementary materials which seems affected by highly heterogeneous and anisotropic weathered unit resulting in a various vertical flow rate through the study site lee et al 2017 in groundwater age dating extra sources and sinks of age tracers need to be considered to identify the age distribution properly a total of eight simulations successfully constrained the influence of various processes on the tracer distribution with optimizing the groundwater mixing structure and mean age based on the dic parameter note that apparent age did not show any relation to the mean age optimized in the repeated bayesian mcmc fig s4 in supplementary materials again nullifying the piston like flow assumption additionally the mean age did not have any relation to the production well depth fig s6 in supplementary material indicating the age distribution of study site was dependent on heterogeneous hydraulic system in addition to in well mixing 4 conclusions this study aimed at inferring the groundwater age distributions at a number of production wells in a heterogenous fractured medium multiple tracers including cfcs 3h tritiogenic 3he and radiogenic 4he provided the information to constrain groundwater age distributions to overcome the lack of preliminary knowledge on hydrogeological system of study site various mixing models including four lpms and two shape free approaches were incorporated into a bayesian framework to estimate age distributions most of the samples were described using the simple lpms better than using the shape free approaches when the model complexity was accounted for with a penalty the exceptions were five wells including bg 02 bg 07 bg 24 bg 28 and bh 01 that were better described using shape free models this probably stemmed from the complex hydrogeological features of the study site i e fractures and wide vadose zone and from the groundwater withdrawal competition between densely located wells also the newly proposed shape free model based on free bin sizes i e fssm was found to better capture the complicated groundwater mixing than the traditional shape free model i e sfhm this is tought to be due to the higher flexibility of the former approach in describing a wide range of age spectrum the major factors effecting the age determination in this site were identified based on the dic criteria from repeated simulations with and without certain features including 1 groundwater mixing 2 contamination 3 non uniform accumulation rate of radiogenic 4he and 4 travel time in the vadose zone specifically the fact that smaller dic was achieved when including the vadose zone travel and non uniform accumulation rate of radiogenic 4he indicates the significant influence of those parameters on age dating in this site the insoluble tritiogenic 3he and radiogenic 4he showed a degassing signature was depicted with the vadose zone delay parameter the heterogeneous fractured medium resulted in the non uniform production rate of radiogenic 4he throughout the study site also small dic was observable after excluding the contaminated samples suggesting the tracer contamination was significant overall results of this study showed that the bayesian mcmc with the dic criterion can provide an opportunity for quantifying the uncertainties associated with groundwater age dating and therefore able to optimize groundwater age distribution even in a complex hydrogeological setting credit authorship contribution statement yeojin ju conceptualization methodology data curation formal analysis investigation writing original draft arash massoudieh methodology software writing review editing dugin kaown data curation investigation writing review editing yoon yeol yoon data curation kang kun lee funding acquisition supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the national research council of science technology nst grant by the korean government msip no cap 17 05 kigam the national research foundation of korea grant no nrf 2019r1a2c1001986 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2020 124885 supplementary data the following are the supplementary data to this article supplementary data 1 
5502,when environmental tracers are used to determine groundwater age distributions various factors including measurement error model structural error and sample contamination can affect the outcome in this study we tried to untangle and explain the uncertainties associated with the inference of age distribution for a set of highly utilized production wells in a fractured rock aquifer system a total of 17 samples were collected at various depths 22 150 m from production wells these samples were analyzed for six age tracers including 3h tritiogenic 3he radiogenic 4he cfc 11 cfc 12 and cfc 113 a bayesian approach was used for evaluating age distribution for the samples based on several presumed lumped parameter models lpm s and shape free models it was found that the measured data in most wells could be explained by traditional lpms reasonably well however for five of the 17 wells it was found that the simple lpms were not adequate and the more complex shape free approaches resulted better based on the deviance information criteria dic measure this looked attributed to 1 competition between densely located wells 2 a thick vadose zone layer possibly causing preferential flows 3 fractures allowing a localized production furthermore it was shown that three other factors including tracer contamination non uniform 4he production and the heterogeneity in the travel time in vadose zone added uncertainties to groundwater age dating overall results showed that the combination of bayesian approach with dic criterion can help to identify uncertainties associated with the age distribution for hydrologically complicated systems keywords fractured aquifer age tracers bayesian inference uncertainty analysis lumped parameter models residence time distribution 1 introduction groundwater age is defined as the travel time of a water volume from the precipitation recharge point to a monitoring location in the aquifer the groundwater obtained from a pumping well however is a mixture of various water streams with different residence times this suggests that the groundwater age is not a scalar value but should be considered as a distribution bethke et al 2008 weissmann and fogg 1999 weissmann et al 2002 małoszewski and zuber 1982 suggested the use of lumped parameter models lpms to constraint the age distribution of a groundwater system in this approach a mathematical age distribution is presumed and its parameters are determined using environmental tracers such as chlorofluorocarbons cfcs busenberg and plummer 1992 plummer et al 2000 thompson and hayes 1979 3h and 3he schlosser et al 1988 schlosser et al 1989 solomon et al 2000 and sf6 tracers busenberg and plummer 2000 gooddy et al 2006 zuber et al 2006 the method is a cost effective approach compared to direct simulation of travel time distributions eberts et al 2012 however it is only applicable for the simple systems in which the groundwater mixing structure can be described in a simple mathematical form leray et al 2016 weissmann et al 2002 weissmann et al 2002 suggested that the groundwater mixing problem could be overcome by constructing a high resolution numerical model based on realizations created according to the geostatistical properties of the hydraulic conductivity field however the numerical models may not be capable of reproducing the highly localized flows such as when there is perturbative capture zone competition between production wells which can be crucial for the age dating of an actively developed groundwater system visser et al 2013 to overcome the irregular hydrological mixings originated from a complex aquifer setting and from production well screen visser et al 2013 proposed the shape free age model in contrast to earlier methods this approach doesn t presume a mathematical form shape or demand high resolution geologic data in describing the groundwater age distribution but rather it allows the water fraction to be variable in a pre determined number of age bins that results in the best reproduction of measured data the age tracers with different historical accumulation or decay rates in a groundwater system could explain the various spectra of groundwater residence time and therefore can collectively help infer the age distribution cook et al 2000 massoudieh et al 2012 applied bayes theorem to lpms for quantifying the uncertainties associated with the estimation of groundwater age distributions this way the uncertainties stemming from measurement error and other factors such as subsurface decay microbial degradation and dilution of tracers after groundwater recharge as well as model structural error due to the idealized forms of lpms can be systematically propagated into the inferred parameters of lpms massoudieh et al 2014a used this approach to quantify the improvement in the reliability of age distribution inferences when measured tracers at multiple times are available the bayesian approach was later applied to the shape free approach by allowing a markov chain monte carlo mcmc algorithm to generate a posterior probability distribution of fractions of water in a set of pre determined age bins massoudieh et al 2014b the groundwater system near private wells at the eumseoung site is very complex because of a relatively wide and non uniform unsaturated zone a heterogeneous and anisotropic field of a non uniform fractured system and a production competition among densely located agricultural wells see section of site description for details these can make a reliable estimation of groundwater age challenging in this study an attempt has been made to infer the groundwater mixing mechanism and groundwater mean age of the private wells based on multiple age tracers chorco alvarado et al 2007 plummer et al 2001 reilly et al 1994 visser et al 2013 including 3h 3he 4he cfc 11 cfc 113 and cfc 12 through bayesian inference to handle the possible irregular shape of groundwater age distributions and the fact that the groundwater may be a mixture of young and old groundwater a new free step size model was introduced in this study the bayesian approach is expected to allow us to quantify the uncertainties associated with estimating the age distributions in this complex aquifer system 2 methods 2 1 site description the study site is located in the upper miho river watershed of eumseong south korea fig 1 samples were mainly collected from the southern part of the watershed which has a gentler slope compared to the more rugged landscape in the north k water and molit 2009 71 of the annual precipitation occurs in the rainy season june september korea meteorological administration website www kma go kr groundwater recharge actively occurs in the northern part of the basin and moves downstream to the southern part following a hydraulic gradient of approximately 0 003 the linear groundwater velocity has been estimated to be around 0 06 0 44 m d 1 lee et al 2017 the vertical profile of the study site was revealed by drilling a series of borehole bh wells fig 1 at the location of most boreholes the stratigraphy consists of a top alluvial layer 0 2 m b g s a weathered layer 2 70 m b g s and bedrock 70 m b g s ju et al 2018 the weathered layer can be further characterized by two distinguished layers including a highly fractured zone weathered soil at 2 30 m b g s and a weathered rock layer situated underneath it between 30 and 70 m b g s depths the aquifer is unconfined without any impermeable layer the local permeability field was examined by an electrical resistivity survey near the bh series wells fig 1 in which the horizontal intrinsic permeability ranged from 6 18 10 14 m2 to 1 76 10 12 m2 while the vertical one ranged from 1 24 10 14 m2 to 3 52 10 13 m2 table 4 in lee et al 2017 in korean showing a very heterogeneous and anisotropic system at this site in addition kim et al 2018 identified a non uniform hydraulic conductivity field from push and pull tests using cl and sf6 tracers near the bh series wells fig 1 ranging from 4 0 10 6 m s 1 to 2 0 10 5 m s 1 on four repeated experiments agricultural fields constitute the majority of the land cover in the basin with approximately 70 2 of the land cover near the production wells being agricultural fields table 1 the agricultural paddy and non paddy fields can be differentiated based on their soil permeability the paddy field consists of muddy soil and are able to maintain a shallow water table for cultivating rice fig 1 ju et al 2018 the industrial and residential areas contain impermeable surfaces however the impervious surfaces are not continuously covering the surface within each private well s radius of influence roi but are widely scattered through the study site table 1 the private wells were densely located in the study site bg 01 to 29 and it seems that in many instances their rois overlap as they compete for groundwater fig 3 in ju et al 2018 in this study we were limited to 12 of the 29 private wells due to the restrictions on the gas sampling procedure fig 1 the information on well depth and hydrostratigraphic characteristics is necessary to understand the age distributions of an aquifer system the information was provided by korean government or by performing direct measurements for privately constructed wells table 1 throughout the sampling locations the depth of the unsaturated zone was relatively thick varying between 3 6 m b g s and 27 8 m b g s and the lower elevation of the production well screens ranged between 22 0 m b g s and 150 5 m b g s table 1 the bg 01 and bg 24 private wells didn t have any reported information regarding screen depth just relying on direct measurement it was also found that the well depths of bg 07 bg 14 bg 19 bg 27 and bg 28 differed from the reported ones probably due to poor record keeping by the private well owner we were not able to measure the depth to the water table for bg 03 bg 04 and bg 29 because the tops of the production wells were tightly closed their water table levels however were expected to be consistent with adjacent production wells as judged from a relatively uniform distribution of them through the production points table 1 2 2 water sampling and data acquisition in march of 2015 17 groundwater samples were collected from 5 monitoring wells and 12 private wells using a peristaltic pump after three borehole volumes of water had been purged fig 1 a detailed description of the sampling procedure can be found in ju et al 2018 groundwater samples for cfcs were collected following iaea 2006 protocol busenberg et al 2006 samples were triplicated and contained in glass bottles sealed by caps with metal liners analysis of cfc 11 cfc 12 and cfc 113 were conducted at the university of utah through gas chromatography in a closed system where the cfcs were stripped out from the water sample and measured against a standard gas which following general procedures suggested by the u s geological survey cfc laboratory in reston va busenberg and plummer 1992 the standard deviation of the measured concentrations was found to be less than 2 for cfc 11 and cfc 12 and about 3 for cfc 113 the analytical precision is about 50 near detection limit and about 3 above 25 pg kg 1 dissolved noble gas lab university of utah website http www noblegaslab utah edu the noble gas components such as he ne ar kr and xe and he isotope ratios 3he 4he were also analyzed at the university of utah aeschbach hertig et al 2013 solomon et al 2015 the measurement error for he tracers are estimated to be less than 1 and less than 5 for other noble gases manning et al 2005 solomon et al 2010 approximately 28 cm3 of groundwater was collected in a copper tube and sealed off using stainless steel clamps to avoid contact with the atmosphere gases were first extracted from the groundwater sample and stored in a stainless steel flask bayer et al 1989 before injecting samples into the mass spectrometer excessive water vapor active gases and other condensable gases were removed through a purification process using cryogenic traps lott 2001 and saes getter pumps he tracers were quantified using a quadrupole mass spectrometer stanford research systems rga300 while he and 3he 4he were analyzed by a sector field mass spectrometer mass analyser products model map 215 50 equipped with an electron multiplier to measure low abundance ions in high precision and a faraday cup to measure more abundant ions then electrical responses of six components were converted into the air quantity by comparing to a standard gas dry atmosphere the 3h samples were analyzed in the korea institute of geoscience and mineral resources kigam using low level tritium analysis samples were collected and stored in high density polyethylene hdpe plastic bottles prior to the analysis the electrolytic enrichment method was utilized to lower the detection limit of 3h by adding 4 g of na2o2 and 1 ml of standard solution to 400 ml of groundwater sample the electrolyzed sample 25 ml was washed with high purity co2 to precipitate naoh into na2co3 and remove it from the solution then samples went through a distillation column to be purified the 10 ml of purified sample was mixed with 10 ml of a scintillation solution the spectrum of tritium was measured by liquid scintillation counter lsc method the detection limit of this method is 0 8 tu and lsc counting efficiency is 28 70 0 27 yoon et al 2007 2 3 preparation of the input record cfc 11 cfc 113 and cfc 12 are anthropogenic compounds that were manufactured from the early 1930s to the 1990s therefore the cfcs can act as an age marker for dating relatively young groundwater ekwurzel et al 1994 plummer et al 2000 the atmospheric cfcs are known to have a small spatial variation below 10 around the globe kazemi et al 2006 therefore the data from north america was used for the study site s cfc input the north american atmospheric station is located at an elevation of 3 013 m in the rocky mountains near boulder colorado elkins et al 1996 the 3h is a radioactive isotope of hydrogen naturally produced by cosmic radiation or a nuclear reaction process solomon et al 2000 the current state of 3h in this study site was reconstructed from 3h input history reported by international atomic energy agency iaea iiaea wmo 2015 with the decay rate of 12 43 y lucas and unterweger 2000 missing data in the 3h input history was calculated by correlation analysis between several observatories such as daejeon korea pohang korea tokyo japan vienna austria portland oregon united states washington united states and hong kong china koh et al 2005 the radiogenic 4he is a stable nuclide produced by the alpha decay of th and or u in crustal materials the production rate of radiogenic 4he in this process is slow enough to conserve the contents of the parent material therefore in groundwater systems radiogenic 4he is linearly accumulated along a flow path at a constant rate kipfer et al 2002 the accumulation rate of radiogenic 4he for the study area was reconstructed to calculate the groundwater residence time following the zhou and ballentine 2006 eq 1 and 2 1 4 he in situ production ρ λ j 4 he 1 φ φ t 2 j 4 he 0 2355 10 12 u 1 0 123 th u 4 where ρ is the density of porous rock g cm 3 λ is the parameter defining the efficiency of transfer from the rock matrix to groundwater φ is the rock porosity j 4 he is the source function of radiogenic 4he in the aquifer matrix cm3stp4he g rock 1 y 1 t is the groundwater residence time y and u and th are the u and th concentrations in rock ppm 2 4 bayesian inference and markov chain monte carlo simulation a bayesian inference was used for identifying the age distribution of groundwater samples the simulation was performed using a markov chain monte carlo mcmc algorithm based on massoudieh et al 2012 in bayes theorem the posterior distribution of parameter values for the age distributions can be defined as 3 π θ γ c π c θ γ π θ γ where θ is the vector of model parameters γ is the variance covariance matrix of errors π c θ γ is the likelihood function or the likelihood of observing the measured tracer concentrations c given model parameters θ and the variance covariance matrix γ and π θ γ is the prior distribution of model parameters and the elements of the variance covariance matrix we here assume that the distribution of errors is independent a priori and that the prior distribution of model parameters are also independent the distributions of priors are reported in table 2 and the ranges of them were roughly decided to cover the plausible ranges in typical shallow aquifer system the independent units allow for expressing the prior distribution of model parameters as the multiplication of prior distributions for each model parameter i e π θ k 1 l π θ k it also allows for expressing the likelihood function as 4 π c θ γ g i j c i j i 1 m j 1 n σ i j e j 1 n i 1 m g c i j g c i j 2 2 ln σ i j 2 where c is the predicted tracer concentration based on parameter values θ m is the total number of age tracers n is the total number of production wells σ i j is the standard deviation of tracer i in well j that is error or uncertainty lying on the tracer concentration due to either measurement error or model structural error g is the mapping function that transforms the errors into a designated distribution and g is its derivative for example if the error structure is assumed to be gaussian g x x and if it is assumed to be log normally distributed g x ln x here we assume a tracer to have the same error structure and error standard deviation in all wells and therefore g i j g i and σ i j σ i the metropolis hastings algorithm was used to perform the mcmc sampling hastings 1970 2 5 groundwater mixing models the lumped parameter models lpm can shed light into the groundwater mixing problem małoszewski and zuber 1982 in this study four lpms including the piston flow model pfm exponential mixing model emm dispersion model dm shifted exponential mixing model semm and two alternative shape free models have been used to interpret the groundwater mixing table 2 a pfm represents a system where a minimum level of mixing takes place and that the production well extracts water effectively from a single groundwater stream the emm represents a groundwater system where a maximum level of mixing occurs between various streams the dm assumes an aquifer has a semi infinite recharge medium the semm represents an idealized system where a no dispersion flow path is followed by a fully mixed zone jurgens et al 2012 note that these traditional lpms are referred to as shape models in the results and discussion section according to the definition of a shape free model see the following paragraph visser et al 2013 the shape free models are especially beneficial when 1 a simple mathematical model i e shape model cannot represent the complexity of the age distribution 2 multiple age tracers are available and 3 the input history and or decay rate of the tracers contains information about a substantially different parts of the age distribution 11 bins for both shape free approaches resulting in ten unknown parameters table 2 so considering the fact that four tracers were available the model is clearly over parameterized however the cumulative age distributions are expected to be constrained as stated by massoudieh et al 2014a the shape free models are based on describing the age distribution as a histogram table 2 the shape free histogram model sfhm is based on presuming the bounds of the histogram bins a priori and then treating the bin contents as parameters to be estimated this approach has been previously used by visser et al 2013 and massoudieh et al 2014b the second shape free approach that is introduced here is based on fixing the contents of the histogram bins a priori and then treating the bounds of the histogram bins as parameters to be estimated by the inverse modeling technique we refer to this second approach as the free step size model fssm the second approach is more suitable in cases where the age distribution is highly skewed or heavy tailed due to the fact that its bins can cover the wider age spectrum for the lpms the prior distributions of the model parameters were assumed to be uniform table 2 specifically the prior distribution of mean age θ 1 in all lpms including pfm emm dm and semm was assumed to be uniform from 15 to 220 y while the prior distribution of the dispersion parameter θ 2 in the dm was assumed to range from 0 01 to 50 the shift parameter θ 2 in the semm was also considered to be uniformly distributed from 0 01 to 50 y table 2 the error structure i e g of the residuals between the modeled and observed values were considered to be log normal eq 4 massoudieh et al 2012 2 6 model selection deviance information criterion dic gamerman and lopes 2006 spiegelhalter et al 2002 was used to compare the ability of the model to explain the observed tracer data dic evaluates the goodness of fit based on the difference between the predicted and observed data while penalizing for model complexity eq 5 thus favoring models that cause a lower level of equifinality 5 dic 2 d θ d θ 6 d θ 2 e ln p c θ 2 ln f c 7 d θ 2 ln p c θ 2 ln f c where d θ is the mean deviance d θ is the deviance of the mean f is a standardizing term that is a function of the observation data θ is the random vector distribution corresponding to the posterior distribution and θ is the expected value of the posterior distribution of parameters the tracer concentrations at a discharge point is a function of recharge concentration c i 0 t a age distribution density ρ i a and the sources and sinks of each tracer in a subsurface system małoszewski and zuber 1982 fig 2 cfcs were assumed to undergo no decay and therefore the following equation was used to calculate the concentrations based on the age distribution 8 c i t 0 c i 0 t a ρ i a da for tracers undergoing first order decay such as 3h the concentration is calculated as 9 c i t 0 c i 0 t a e λ i a ρ i a da the tritiogenic 3he is the decay product of the 3h tracer because it is poorly soluble in water most of it is lost back into the atmosphere during the unsaturated zone travel time fig 2 assuming that all the tritiogenic 3he was lost in the unsaturated zone the concentration of 3he in the groundwater can be calculated via 10 c i t 0 c i 0 t a e λ i t us 1 e λ i a t us h a t us ρ i a da where t us is the travel time in the vadose zone and h is the heaviside function assuming that radiogenic 4he accumulates linearly only in the saturated zone fig 2 as with the theoretical rate described in the section 2 3 preparation of the input record its concentration in groundwater can be calculated as 11 c i t 0 c i 0 t a λ i a t us h a t us ρ i a da 3 results and discussion 3 1 groundwater apparent age the concept of apparent age or piston flow age allows the hydrologist to estimate the groundwater age directly by assuming no significant groundwater mixing for a groundwater system bethke et al 2008 three different tracers including event markers i e cfcs radioactive tracer i e 3h 3he and accumulating tracers i e radiogenic 4he were applied to identify the apparent age of this site cook et al 2000 3 1 1 event markers cfcs the cfcs are the age markers for dating relatively young groundwater up to 70 y ekwurzel et al 1994 plummer et al 2000 the gas tracers are however easily subjected to air intrusion during the groundwater recharge period therefore the excess air correction was made for the cfcs using biochemically inert noble gas tracers prior to age determination aeschbach hertig et al 2008 the bh 02 was the most air contaminated sample of which 29 2 of cfc 11 137 0 of cfc 113 and 54 0 of cfc 12 came from the excess air intrusion respectively table 3 and table s1 in supplementary material one thing that needs to be pointed out is that nine cfc 11 samples and three cfc 12 samples still showed a larger value than the historical maximum concentration indicating that the local contaminant source could affect the cfcs in the study site kazemi et al 2006 the groundwater ages calculated using cfcs showed relatively consistent distributions among produced samples such as 28 3 39 2 y for cfc 11 26 8 37 0 y for cfc 113 and 32 2 41 5 y for cfc 12 table 3 3 1 2 radioactive tracer 3h and 3he the decay of 3h accumulates the tritiogenic 3he in the groundwater system with the half life of 12 43 y lucas and unterweger 2000 in a closed system the tritiogenic 3he accumulates in the groundwater system without being lost into the atmosphere this provides another way for dating relatively young groundwater up to 60 y solomon et al 2000 firstly the current state of 3h was reconstructed for the study site see the 2 3 preparation of the input record for details 3h was up to 58 8 tu during the nuclear test period 1954 1964 followed by a drop to the natural background level below 4 0 tu after 1999 fig 3 according to the reconstructed history the existence of an exceptionally low tritium concentration below 1 tu indicates a notable influence of pre modern groundwater i e prior to 1953 fig 3 the old water 1 tu however only could be observed when more than 66 1 of the water is comprised of old water avg of years 1865 1950 0 02 tu if the reminder of the water was recharged since the year 1999 avg 2 90 tu or more than 95 6 with the remainder is recharged during the peak period of 1958 1967 avg 22 02 tu the produced samples however in none of the wells seem to be significantly affected by old groundwater as 3h was maintained larger than 1 42 tu table 4 the apparent groundwater age was calculated for 17 production wells based on the reconstructed input history and a known decay rate τ 1 2 ln 2 following schlosser et al 1988 schlosser et al 1989 12 τ τ 1 2 ln 2 ln 1 he 3 h 3 where τ is groundwater apparent age τ 1 2 is the half life of 3h of 12 43 y lucas and unterweger 2000 and 3he and 3h are the concentrations of each species in a unit of tu the calculation was preceded by a component separation process using noble 90 i e compiled matlab routine of groundwater recharge models to separate the tritiogenic 3he of the 3h beta decay origin from the other atmospheric and radiogenic origins of the total he aeschbach hertig et al 2008 the calculated apparent ages were ranging from 0 y to 48 6 y table 4 the raw data for the analysis can be found in supplementary table s2 the bg 24 showed an erroneous recharge temperature of 47 4 c that is unrealistic for this shallow groundwater condition indicating this sample had been deteriorated by degassing loss table 4 a detailed discussion on the degassing issue was made in the section on bayesian inference influence of heterogeneous geophysical setting on the age distribution 3 1 3 accumulating tracer 4he the radiogenic 4he does not react or adsorb strongly to soil materials but linearly accumulates in the groundwater system after its production from the radioactive crustal element thus it is widely used for the age dating of groundwater water especially for very old water zhou and ballentine 2006 the bedrock of the study site consists of mesozoic granitic rocks containing u of 0 24 4 56 ppm x 2 21 ppm σ 0 76 and th of 0 41 19 12 ppm x 8 32 ppm σ 3 56 with the porosity of 0 06 and bulk density of 2 2 g cm 3 jurgens et al 2012 ju et al 2018 this resulted in an estimated radiogenic 4he accumulation rate of 18 4 micro cm3 m 3 y 1 for this site eq 1 and 2 the radiogenic 4he of the groundwater samples were separated and quantified using noble 90 with noble gas input data table 4 aeschbach hertig et al 2008 the maximum concentration of radiogenic 4he was 3 08 10 8 cm3 stp g 1 corresponding to the groundwater age of 2067 y which clearly contradicts with the young apparent ages from the 3h 3he and cfcs data this value is also unrealistic for the shallow groundwater system indicating an unknown source of the radiogenic 4he that exists in the study site 3 1 4 groundwater mixing scenarios the apparent ages calculated from the three different methods showed mismatches for 17 samples table 3 and 4 putting the assumption that the simple apparent age or piston flow age represents the mean groundwater age into question this was also proved in the spatial distribution of age tracers fig 4 which was expected to show a particular relation to the groundwater flow direction since water age is expected to increase toward the downstream of the study site reilly et al 1994 for example cfcs would gradually decrease toward the downstream of a flow line according to their linearly accumulating input history within the groundwater system in fig 4 six different tracers were presented along with the piezometric head distribution the residence time of the groundwater in this site is expected to increase from the northwest to southeast directions however the tracer distributions did not show any particular relation to the flow direction this fact implies that the mean age is possibly defined by groundwater mixing processes along the screen of each production well not by a piston like flow system jurgens et al 2012 lpms can provide insight into the groundwater mixing structure and the groundwater mean age for individual production wells małoszewski and zuber 1982 the groundwater mixing scenarios associated with each well is depicted in the tracer tracer graphs with the selected mathematical shape models such as the pfm emm dm and binary mixing model bmm jurgens et al 2012 małoszewski and zuber 1982 fig 5 in fig 5 the 3h and cfcs tracers were plotted with their error ranges based on the assumed lpms in the case of cfc 11 11 of 17 samples showed deviations that were too large according to the mathematical mixing models fig 5a and b furthermore the gas tracers tritiogenic 3he and radiogenic 4he showed large errors and many of the samples could not reduce the discrepancies between the observed data and the modeled ones fig s1 in supplementary material indicating that there are unknown factors affecting the tracers distributions not efficiently reproduced by the simple lpms 3 1 5 bayesian inference although the lpms are known to provide a straightforward characterization of hydrologic conditions in the current system the simple shape models were not capable of explaining the variation of observed data showing large discrepancies with what is expected based on lpms fig 5 and fig s1 in supplementary material this can be attributed to 1 lack of flexibility in the lpms to represent the complex groundwater mixing massoudieh et al 2014b and 2 undefined sources and sinks of age tracers such as local contamination degradation degassing or other unknown factors alikhani et al 2016 therefore it was deemed to be necessary to employ more flexible models to explain the tracer data a total of six different models such as two alternative shape free models in addition to the four traditional shape models as explained in section 2 5 were utilized to explain the groundwater mixing and therefore to constrain the distribution of six age tracers including 3h cfcs tritiogenic 3he and radiogenic 4he models with a larger number of unknown parameters however inevitably result in higher levels of non uniqueness and thus uncertainty about the value of the parameters massoudieh et al 2012 massoudieh et al 2014a therefore to evaluate the uncertainty in model performance bayesian mcmc and dic criteria were applied for the groundwater mixing problem bayesian inference influence of groundwater mixing on the age distribution the suitability of various groundwater mixing models are compared using the dic measure gamerman and lopes 2006 massoudieh et al 2012 spiegelhalter et al 2002 for wells bg 14 bg 19 and bg 27 the pfm resulted in the lowest dic value table 5 suggesting those wells contain a relatively narrow range of groundwater ages this may be attributed to narrow screens or a wide impervious surface near the production wells the dic values for wells bg 03 bg 04 and bh 04 points to an emm table 5 implying that the screens are extended through active groundwater mixing zones preferentially capturing a large portion of young groundwater the wells bg 24 bh 01 bh 02 and bh 05 adopted the dm table 5 suggesting the moderate mixing of groundwater the semm was preferred by wells bg 01 and bh 03 the shift parameter of semm the θ 2 indicates that the partial screen of production wells affected the groundwater mixing or that an impermeable land surface resulted in recharge delay table 5 jurgens et al 2012 the shape free model has a higher level of flexibility as compared to the shape models i e traditional lpms table 2 two shape free models including the shape free histogram model sfhm and the free step size model fssm were evaluated bg 02 bg 07 bg 15 bg 28 and bg 29 preferentially were adopting two shape free models table 5 for these wells a narrow confidence range was obtained for shape free models despite the large number of input parameters fig 6 in this site the production wells are located in the agricultural area in which numerous private wells are competing for the groundwater production ju et al 2018 the competition of the production wells was known to make the local hydrological system heterogeneous visser et al 2013 which seems to demand a high level of flexibility for a model to explain the complex groundwater mixing structure furthermore when shape free models were preferred the dic was mostly better for fssm than sfhm which can be attributed to the higher flexibility of the fssm model in capturing different portions of the groundwater age distribution despite having the same number of parameters table 5 even though the age density of the shape free models show some oscillation as compared to the shape models the cumulative distributions are smoother fig 6 for most wells the modeled distributions of shape free models overlapped with that of the simple shape models suggesting that the traditional lpms are also capable of capturing groundwater mixing at this site in some cases the sfhm showed notable deviation with other models e g fig 6c and d for example the sfhm had the abnormal sharp increase in the old recharge period and this was apparent for wells containing older groundwater such as bg 03 and bg 04 fig 6c and d this problem originated from limiting the bounds of the groundwater age to 110 9 y in the sfhm model table 2 this issue was not observed when the fssm approach was used due to the fact that no limits to the age range are imposed on it wells bg 02 bg 07 bg 15 bg 29 and bh 05 showed relatively large dic values 10 4 table 5 the bh 05 had an unrealistic tritiogenic 3he concentration of 0 tu table 4 the others showed a highly elevated cfc 11 concentration which cannot be explained by north american input history table 3 the latter ones looks affected by contamination to see the influence of contamination on the inference of the model parameters another set of simulations was conducted excluding the contaminated samples from input data sets fig 7 as a result most of samples except bg 28 showing improvement in dic however bg 02 bg 15 bg 29 and bh 05 still resulted in large dic values 20 4 fig 7 indicating the errors did not solely originate from the contamination the age tracer distributions in this site could not be explained just by groundwater mixing model it seemed affected by undefined mechanisms note that two simulations showed the overall consistent estimations for tracer concentrations despite the high level of contamination shown in the data set fig s2 in supplementary material which is attributed to the structure of the bayesian likelihood function not allowing the method to assign larger error standard deviations to the tracers that cannot be reproduced effectively in turn assigning those tracers a lower weight i e 2 ln σ i j in eq 4 bayesian inference influence of heterogeneous geological setting on the age distribution the multiple tracers generated a signal to constrain the age distribution for collected groundwater samples however in this site the observed tracer distribution could not be perfectly explained only by groundwater mixing possibly attributed to the other mechanisms in the groundwater system alikhani et al 2016 the current study site is characterized by a wide and variable depth of vadose zone and heterogeneous weathered medium fig 2 the wide vadose zone possibly affect the distributions of the insoluble age tracers i e tritiogenic 3he and radiogenic 4he visser et al 2007 and non uniform fractured system is known to affect the distribution of radiogenic species i e radiogenic 4he solomon et al 1996 we performed four additional sets of mcmc simulations to identify the major processes responsible for the tracer distribution 1 without considering vadose zone delay t us and the non uniform radiogenic 4he accumulation rate λ 4 h e throughout the study site 2 with non uniform vadose zone delay t us 3 a non uniform radiogenic 4he accumulation rate λ 4 he and 4 with inclusion of both parameters two parameters i e t us and λ 4 he should be thoroughly reviewed when the insoluble and radiogenic substances are adopted for age determination kazemi et al 2006 the t us parameter was firstly incorporated in the simulation to see the influence of heterogeneous vadose zone on the tracer distribution in this site after applying the new parameter on the simulation nine of 17 samples showed an improvement in terms of dic value fig 8 a and b three of them considered this version of the estimation as the best one see the third column in table 6 indicating the t us cannot be ignored in explaining the tracer distribution of this site with the incorporation of t us the estimation was improved for the tritiogenic 3he tracer specifically in samples bg 03 bg 07 bg 29 and bh 05 where the bias of modeled ranges to measured value was reduced notably fig 9 a on the other hand some results were overestimating the tritiogenic 3he tracer for bg 04 bg 14 and bh 03 fig 9a this was affected by large amounts of radiogenic 4he in the samples demanding a long residence time for reproducing the measured data which inevitably resulted in the elevation of the tritiogenic 3he fig 9a and b since current simulation can not explain the large amount of radiogenic 4he another parameter is necessary to explain the tracer distribution properly fig 9b note that for bg 02 bg 15 bg 29 and bh 05 a zero value for the modeled he concentrations were obtained fig 9a and b which resulted from a large vadose travel time table 6 the incorporation of λ 4 he in the simulations improved the dic value for 11 of the 17 samples fig 8a and c and seven of the samples considered this version of the estimation as the best one table 6 suggesting the non uniform distribution of λ 4 he throughout the study site when λ 4 he is treated as an unknown parameter the inferred 4he resulted in a better agreement with the measured values for most of the wells as compared to the case when λ 4 he was a constant fig 9b and d this improvement was however not apparent for the samples having a small radiogenic 4he amount for example the samples bg 15 bg 19 bg 29 bh 01 and bh 05 presented relatively highly overestimated values with wide credible intervals fig 9d it is evident that the current simulation demands the additional parameter to compensate the overestimation of tritiogenic 3he and radiogenic 4he tracers such as degassing loss of insoluble tracers during vadose zone delay i e t us in consideration of the geological setting of study site i e the wide vadose zone in many cases the estimated radiogenic 4he had wide credible intervals showing high uncertainty in their estimation fig 9d in the bayesian mcmc the uncertainty of input parameters can propagate into the output distribution and considering the fact the reproduced radiogenic 4he is relying on the λ 4 he parameter the wide distribution of radiogenic 4he could stem from the prior distribution of λ 4 he another set of simulations was performed in which the distribution range of the λ 4 he prior was repeatedly adjusted fig 10 in fig 10a the uncertainty level was gradually improved with reducing the range of the prior distribution however it was not a proper treatment for samples containing the large amount of radiogenic 4he for example in bg 01 the radiogenic 4he could not be accounted for with the small prior ranges below 0 01 20 10 9 cm3 stp g 1 y 1 fig 10a furthermore the uncertainty level of the reproduced values were rather consistent when the prior range contained the measured value that is the prior distribution of 0 01 30 in fig 10a and all ranges in fig 10b indicating the prior distribution was not the primary reason for the wide uncertainty levels according to massoudieh et al 2014b the wide credible interval is also observable when the estimated parameters are correlated however this was also not the case for this study site as significant correlation was not found between estimated parameters fig s3 in supplementary material one obvious thing we can say for this situation is that λ 4 he is currently constrained only by single tracer the radiogenic 4he tracer which could result in the high level of uncertainty in model estimation that is current model has a possibility to be improved by incorporating new tracers related to the radiogenic production in the groundwater system the simulation with both t us and λ 4 he parameters was effective as 14 of 17 samples showed improvement in terms of dic value fig 8a and d these improvements include several samples which previously showed an improvement by incorporating a single parameter in the simulation just t us or λ 4 he in addition although bg 04 did not show any improvement in the previous simulations it is better constrained by using both t us and λ 4 he parameter on the other hand samples such as bg 24 and bh 01 lost the explanatory power for the observation data when treating both t us and λ 4 he as unknown parameters indicating the new parameters added unnecessary complexity in the model rather than constraining the tracer distribution in this set of simulations more than one third of samples i e seven of 17 however resulted in the best dic when vadose zone travel time was considered and λ 4 he was treated as unknown i e the case 4 table 6 confirming the significant influence of both t us and λ 4 he parameters on tracer distributions in this study site note that the overestimation of tritiogenic 3he and radiogenic 4he was still observable even though wide ranges of t us 30 y and enough low λ 4 he 10 11 cm3 stp g 1 were provided for the simulation to improve the bias in our current situation it would be efficient to incorporate new tracers with smaller error than that of current tracers i e σ i j in eq 4 or to apply a transient data set as massoudieh et al 2014a done for their simulation the model identified as best according to the dic are summarized in the last two columns of table 6 though some samples still provided high uncertainty from the bayesian mcmc the dic values showed clear improvement from 10 6 28 1 to 21 1 11 5 for 17 samples after incorporating new parameters which again highlights the significant influence of vadose zone delay t us and radiogenic 4he accumulation λ 4 he on the distribution of age tracers throughout the study site even after including the additional parameters still did the bg 02 bg 07 bg 24 bg 28 and bh 01 exhibit the complex groundwater mixing structures table 6 it looked attributed to the action of the wide and thick vadose zone and fractures to the groundwater residence times the thick and wide vadose layer noticeably delayed the groundwater flow up to 27 6 y in the site table 6 in addition to the flow delay the vadose layer was well known to generate the lateral and preferential flows depending on a heterogeneous permeability distribution in that layer kung 1990 resulting in the various streams of different residence times furthermore fractured unit of the aquifer allowed a localized production through the vertical conduits in the site as evidenced from the wide distribution of 4he accumulation rate of 0 2 7 9 10 10 cm3 stp g 1 y 1 table 6 and which supports the situation that deeper groundwater was added into the shallow production through the vertical conduits resulting in the complex age distributions bayesian inference uncertainties lying on individual age tracers multiple tracers were incorporated into a bayesian simulation to overcome the lack of preliminary knowledge on hydrogeological system the advantage of 3h tracer in groundwater age dating is that since it is a part of the water molecules it is not lost into the atmosphere once it has entered the subsurface system its decay rate is also known with very high accuracy lucas and unterweger 2000 it is not affected by the vadose zone travel and or the excess air intrusion or degassing problem in subsurface system therefore there was no significant improvement after the incorporation of new parameters i e t us and λ 4 he fig 11 a note that the bg 19 looks attributable to analytical failure which cannot be explained within the model structure the modeled cfcs showed a large overestimation compared to measured values indicating the existence of a local unknown source in this site red symbols in fig 11d and f 11 of cfc 11 samples and three of cfc 12 samples were deteriorated by unknown local sources the cfcs could not be improved upon with any new parameters as their bias was originated from unknown sources which can not be described in the conceptual model fig 11d and f the high level of cfc contamination has been reported in agricultural lands of south korea in which the elevation of cfcs was noticeably more than the historical maximum concentration due to the plastic pe or pvc casing of the wells kaown et al 2009 additionally cfcs can also have negative bias when they are affected by microbial degradation in the groundwater system possibly resulting in the overestimation without proper parameters to explain the lost amount sebol et al 2007 in this site however the groundwater system maintains an oxic condition 5 0 ju et al 2018 therefore the degradation of cfcs is a minor issue this statement also can be verified from fig 11d e and f where the estimated values mostly followed the measured data without overestimation contrary to 3h and cfcs tracers the distribution of tritiogenic 3he tracer was not solely constrained by groundwater mixing but significantly affected by vadose zone delay t us in this site table 6 in the first place we observed discrepancies between the cfcs and 3h 3he in apparent age for 13 of 17 samples table 3 and 4 the cfcs ages were older than the 3h 3he ones up to 32 4 y this situation is normally observable in the thick vadose zone system kaown et al 2009 therefore the t us was incorporated in the bayesian mcmc and resulted in 11 5 27 6 y of mean delay times for groundwater productions table 6 this range is corresponding to the infiltration rate of 0 25 1 84 cm d 1 assuming that the groundwater recharge mainly occurred near production wells which overlaps the ranges calculated from a previous study 0 27 1 17 cm d 1 table 1 in razavipour and farrokh 2014 however samples such as bg 15 bg 29 and bh 05 reached the limit of the t us value table 6 indicating that other processes are responsible for the low level of tritiogenic 3he in this site this is possible for example in the case of degassing loss by contacting with bubbles or by confronting any decompression situation during groundwater transport visser et al 2007 note that most of 3h 3he age was underestimating the groundwater age fig s4 in supplementary material also suggested the significant degassing loss radiogenic 4he is normally assigned to explain the very old groundwater for the samples solomon et al 2000 as already mentioned in the previous section i e 3 1 3 accumulating tracer 4he this tracer however exhibited a large discordance with other age tracers in apparent age estimation this can be attributed to the existence of very old groundwater fraction or an additional radiogenic 4he source exists in the study site bethke et al 1999 castro et al 1998 torgersen and clarke 1985 zhou and ballentine 2006 the possibility of a shallow aquifer to be mixed with the old groundwater however looks very low as the large amount of radiogenic 4he could not be explained with the fssm possessing a wide age distribution range fig 9b the accumulation rate of radiogenic 4he was evaluated in the bayesian inference by incorporating additional parameters the λ 4 he which varied from 1 8 10 11 to 7 9 10 10 cm3 stp g 1 y 1 in this site table 6 this range is relatively large in comparison to the reported values such as 1 10 11 to 2 10 11 cm3 stp g 1 y 1 in visser et al 2013 1 3 10 10 cm3 stp g 1 y 1 in solomon et al 1996 5 3 10 12 cm3 stp g 1 y 1 in sültenfuß et al 2011 and also much overriding the theoretical value of 1 84 10 11 cm3 stp g 1 y 1 calculated using u and th contents see the 3 1 3 accumulating tracer 4he this indicates that the relatively large extra flux of radiogenic 4he exists throughout the study area therefore the radiogenic 4he tracer naturally showed the noticeable improvement after incorporating the λ 4 he in the simulation fig 11c note that the accumulation rate of radiogenic 4he is not related to the production well depth fig s5 in supplementary materials which seems affected by highly heterogeneous and anisotropic weathered unit resulting in a various vertical flow rate through the study site lee et al 2017 in groundwater age dating extra sources and sinks of age tracers need to be considered to identify the age distribution properly a total of eight simulations successfully constrained the influence of various processes on the tracer distribution with optimizing the groundwater mixing structure and mean age based on the dic parameter note that apparent age did not show any relation to the mean age optimized in the repeated bayesian mcmc fig s4 in supplementary materials again nullifying the piston like flow assumption additionally the mean age did not have any relation to the production well depth fig s6 in supplementary material indicating the age distribution of study site was dependent on heterogeneous hydraulic system in addition to in well mixing 4 conclusions this study aimed at inferring the groundwater age distributions at a number of production wells in a heterogenous fractured medium multiple tracers including cfcs 3h tritiogenic 3he and radiogenic 4he provided the information to constrain groundwater age distributions to overcome the lack of preliminary knowledge on hydrogeological system of study site various mixing models including four lpms and two shape free approaches were incorporated into a bayesian framework to estimate age distributions most of the samples were described using the simple lpms better than using the shape free approaches when the model complexity was accounted for with a penalty the exceptions were five wells including bg 02 bg 07 bg 24 bg 28 and bh 01 that were better described using shape free models this probably stemmed from the complex hydrogeological features of the study site i e fractures and wide vadose zone and from the groundwater withdrawal competition between densely located wells also the newly proposed shape free model based on free bin sizes i e fssm was found to better capture the complicated groundwater mixing than the traditional shape free model i e sfhm this is tought to be due to the higher flexibility of the former approach in describing a wide range of age spectrum the major factors effecting the age determination in this site were identified based on the dic criteria from repeated simulations with and without certain features including 1 groundwater mixing 2 contamination 3 non uniform accumulation rate of radiogenic 4he and 4 travel time in the vadose zone specifically the fact that smaller dic was achieved when including the vadose zone travel and non uniform accumulation rate of radiogenic 4he indicates the significant influence of those parameters on age dating in this site the insoluble tritiogenic 3he and radiogenic 4he showed a degassing signature was depicted with the vadose zone delay parameter the heterogeneous fractured medium resulted in the non uniform production rate of radiogenic 4he throughout the study site also small dic was observable after excluding the contaminated samples suggesting the tracer contamination was significant overall results of this study showed that the bayesian mcmc with the dic criterion can provide an opportunity for quantifying the uncertainties associated with groundwater age dating and therefore able to optimize groundwater age distribution even in a complex hydrogeological setting credit authorship contribution statement yeojin ju conceptualization methodology data curation formal analysis investigation writing original draft arash massoudieh methodology software writing review editing dugin kaown data curation investigation writing review editing yoon yeol yoon data curation kang kun lee funding acquisition supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the national research council of science technology nst grant by the korean government msip no cap 17 05 kigam the national research foundation of korea grant no nrf 2019r1a2c1001986 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2020 124885 supplementary data the following are the supplementary data to this article supplementary data 1 
5503,the establishment of an accurate and reliable forecasting model is important for water resource planning and management in this study we developed a hybrid model namely gmm xgboost coupling extreme gradient boosting xgboost with gaussian mixture model gmm for monthly streamflow forecasting the proposed model is based on the principle of modular model where a complex problem is divided into several simple ones gmm was applied to cluster streamflow into several groups using the features selected by a tree based method then each group was used to fit several single xgboosts and the prediction is a weighted average of the single models monthly streamflow data at cuntan and hankou stations on yangtze river basin were used to evaluate the performance of the proposed model to compare the forecasting efficiency support vector machine svm and standalone xgboost were selected as the benchmark models the results indicated that although all three models yielded quite good performance on one month ahead forecasting with high nash sutclitte efficiency coefficient nse and low root mean squared error rmse gmm xgboost provided the best accuracy with significant improvement of forecasting accuracy it can be inferred from the results that 1 xgboost is applicable for streamflow forecasting and in general performs better than svm 2 the cluster analysis based modular model is helpful in improving accuracy and capturing the complicated patterns of hydrological process 3 the proposed gmm xgboost model is a superior alternative which can provide accurate and reliable predictions for optimal water resources management keywords streamflow forecasting extreme gradient boosting gaussian mixture model modular models 1 introduction with the increasing water requirements and weather extremes effective planning and management for water issues has been of great concern over the past decades wang et al 2019a b accurate and reliable streamflow forecasting is a critical step for water resources supply and prevention of natural disasters such as floods and droughts rezaie balf et al 2019 wang et al 2019a b however forecasting is a challenging task due to the non linear and non stationary nature of streamflow especially when it comes to extreme flows high and low flows meng et al 2019 therefore improving the accuracy of streamflow forecasting has received considerable attention in order to obtain the reliable forecasting considerable efforts have been made to develop and apply different methods to improve the accuracy these methods can be classified into two types in the first type a hydrological model is established to calculate the true rainfall runoff system response based on the physical mechanism crochemore et al 2016 roy et al 2017 sharma et al 2019 however these models are based on simplified assumptions and require large data sets mehr et al 2013 the second type is data driven models such as statistical models and machine learning based models aksoy and dahamsheh 2018 kratzert et al 2018 quilty et al 2019 yang et al 2017 they are empirical and easy to implement because they are based on historical observations and do not require information on physical processes liu et al 2015 statistical data driven methods such as multiple linear regression autoregressive moving average arma and its variants have been applied for hydrological forecasting since the 1970s adamowski et al 2012 carlson et al 1970 salas 1980 in recent years machine learning techniques have received considerable attention for their strong learning ability and suitability for modeling complex and nonlinear processes a variety of machine learning models such as artificial neural networks ann wen et al 2019 zhang et al 2018a b support vector regression svr liang et al 2018 meng et al 2019 genetic programming gp ravansalar et al 2017 and adaptive neuro fuzzy inference system anfis dehghani et al 2019 yaseen et al 2017 have been developed and provided satisfactory performance in modeling nonlinear hydrological processes including sediment transport modeling ebtehaj et al 2016c 2016a 2016b rainfall runoff modeling kratzert et al 2018 xiang et al 2020 and drought forecasting rahmati et al 2020 zhang et al 2019 compared with other machine learning models decision tree dt is computationally cheaper moreover in dt no assumptions are needed concerning the predictor s distribution also dt offers distinct advantages such as easy to interpret and to visualize ghiasi and zendehboudi 2019 recently a dt based model extreme gradient boosting xgboost proposed by chen and guestrin 2016 has gained popularity in machine learning competitions because this fast efficient scalable model achieves promising results in many domains different from random forest rf which applies parallel ensemble xgboost model is based on the idea of boosting which combines all the prediction of weak learners for developing a strong learner through additive training strategies fan et al 2019 based on dt and gradient boosting xgboost takes advantage of dt as well as gradient boosting gb a few studies have investigated its performance in earth science fields and achieved state of art results fan et al 2018 compared the svm and the xgboost methods for daily solar radiation prediction in the humid subtropical china they found that xgboost outperformed the studied empirical models and recommended it as a promising model for solar radiation estimation due to better model stability efficiency and comparable prediction accuracy xiao et al 2018 proposed an ensemble machine learning approach they used generalized additive model gam to combine predictions derived from rf xgboost and gam to provide reliable historical pm2 5 concentrations predictions the results showed that the proposed model provided more accurate predictions zhang et al 2019 applied xgboost to predict standardized precipitation evapotranspiration index spei at t time using lagged spei at t i time i 1 2 n meteorological measures and climate signals from 32 stations the results showed that the xgboost predicted more accurately in 1 6 steps than ann did despite being widely used in many other fields chen et al 2018 tuong et al 2019 xia et al 2017 to the best of the authors knowledge its streamflow forecasting abilities are thus far unknown since time series data for streamflow are generally highly nonlinear and seasonal applying the raw data directly to the model may not obtain reliable and accurate results rezaie balf et al 2019 in this context several studies employed the idea of separating streamflow dynamics into sub dynamics using modular models wang et al 2006 applied three methods including threshold values fuzzy c means fcm and periodic autoregressive model to group streamflow data into several clusters then a separate multi layer perceptron mlp was fitted to each cluster wu et al 2009 proposed a crisp distributed support vector regression svr model for monthly streamflow prediction according to the magnitudes of flow data the fcm first split the data into three subsets low medium and high levels then three single svrs were fitted to three subsets the results showed the superior performance of this proposed modular model apart from using cluster methods or threshold to group data some signal processing methods such as wavelet transformation singular spectrum analysis and empirical model decomposition emd and its variants are widely used to decompose the time series into several sub series then fit these sub series to several single models to improve the accuracy of forecasting for example wen et al 2019 used two phase decomposition coupling emd with variational model decomposition vmd to enhance a modular model that was comprised of extreme learning machine elm to forecast runoff they found that the modular model performed better than standalone elm rezaie balf et al 2019 used an ensemble empirical model decomposition eemd to enhance a modular model comprised of m5 model tree m5tree and multivariate adaptive regression spline mars to forecast daily monthly river flow the results indicated that the modular models outperformed the standalone models these studies revealed that signal processing method based modular models can improve model performances however they also suffer from the problem of boundary effects and future information hidden in the decomposition processing the further discussion about the future data issue can be referred to fang et al 2019 quilty and adamowski 2018 and zhang et al 2015 the commonly used clustering approaches such as k means and fuzzy c means are distance based while gaussian mixture model gmm is based on probability model rather than an objective function of distance measures gmm assumes that data set follow a mixture model of probability distributions so that each cluster is represented by a parametric probability density and the entire cluster structure can be modeled by a finite mixture gmm has been shown to be a powerful tool for clustering in many research fields kim et al 2014 niknejad et al 2015 qiu et al 2019 yang et al 2012 however the practical applications have rarely been reported in hydrological studies since gmm is based on probability model cluster results can be largely affected by the dimension of the input dataset in such case selecting the important feature subset is critical to help conducting cluster analysis zeng and cheung 2009 in this study to be consistent with the tree based model xgboost decision tree was chose to select features using variable importance which was computed as the total reduction of the criterion brought by that feature the objectives of this study are as follows 1 investigate the potential of xgboost for forecasting streamflow it is the first time that such models have been applied in streamflow forecasting 2 construct a modular model coupling xgboost with gaussian mixture model 3 test the performance of the gmm xgboost model in terms of evaluation criteria hydrographs and scatter plots the remainder of this paper is organized as follows a general description of the methods and performance measures is provided in section 2 the developed model is illustrated in detail in section 3 section 4 presents applications and relevant discussion of results also includes the advantages limitations and future improvement finally section 5 concludes the paper 2 methodology this part gives a brief introduction to extreme gradient boosting xgboost gaussian mixture model gmm variable importance and performance measures 2 1 extreme gradient boosting xgboost extreme gradient boosting xgboost is a scalable machine learning system for tree boosting that proposed by chen and guestrin 2016 the tree ensemble model used in xgboost is trained in an additive manner until stopping criteria are satisfied and the predicted score in a functional form like this 1 y i k 1 k f k x i f k f where y i is the predicted value fk represents an individual regression tree xi is the input vector k is the number of regression functions and f is the space of all possible fk s to learn the set of functions used in the model the following regularized objective is minimized 2 l ϕ i 1 n l y i y i k 1 k ω f k where ω f γ t 1 2 λ ω 2 where l is a loss function between the observed value yi and predicted value y i the second term ω is the regularization term penalized the model complexity to avoid overfitting γ is the complexity of each leaf t is the number of leaves in a decision tree λ is the trade off parameter to scale the penalty ω is the vector of scores on leaves the model is trained in an additive manner formally let y i t be the prediction of the i th instance at the t th iteration a new function ft is added to minimize the following objective 3 l t i 1 n l y i y i t 1 f t x i ω f t to simplify the optimization of eq 3 the loss function is expanded according to the second order taylor series 4 f x f a f a 1 x a f a 2 x a 2 let x be l t i 1 n l y i y i t 1 f t x i ω f t and a be y i t 1 the objective function can be quickly optimized 5 l t i 1 n l y i y t 1 g i f t x i 1 2 h i f t 2 x i ω f t where g i y t 1 l y i y t 1 and h i 2 y t 1 l y i y t 1 are first and second order gradient statistics on the loss function respectively removing the constant terms in eq 5 to obtain the following simplified objective at step t 6 l t i 1 n g i f t x i 1 2 h i f t 2 x i ω f t define i j i q x i j as the instance set of leaf j rewrite eq 6 by expanding ω as follows 7 l t i 1 n g i f t x i 1 2 h i f t 2 x i γ t 1 2 λ j 1 t ω j 2 j 1 t i i j g i ω j 1 2 i i j h i λ ω j 2 γ t taking the derivatives of eq 7 with respect to ωi and equating them to zero gave the optimal weight ω i of leaf j 8 ω j i i j g i i i j h i λ and calculate the corresponding optimal value by 9 l t 1 2 j 1 t i i j g i 2 i i j h i λ γ t assume that il and ir are the instance sets of left and right nodes after split letting i i l i r then the loss reduction after the split is given by 10 l split 1 2 i i l g i 2 i i l h i λ i i r g i 2 i i r h i λ i i g i 2 i i h i λ γ this formula is the gain in loss reduction equation and used in practice for evaluating the split candidates 2 2 gaussian mixture model gmm a gaussian mixture model gmm is a probabilistic model for data clustering that considers all data points to be derived from a mixture of a finite gaussian distribution with unknown parameters mathematically gmm is defined as a parametric probability density function which can be represented as a weighted sum of k gaussian components each component is characterized by a simple parametric form the gmm can be written as 11 p m x i 1 k α i p x μ i σ i where p x μ i σ i is known as the j th components of the mixture with μi σ i αi is called mixture coefficient and must satisfy 0 α i 1 together with i 1 k α i 1 in gmm the probability density function is gaussian distribution defined as follows 12 p x 1 2 π d 2 σ 1 2 e 1 2 x μ t σ 1 x μ by bayes theorem the posterior probability γji that xj belongs to the ith component in the mixture can be defined as follows 13 γ ji p m j x j α i p x j μ i σ i l 1 k α l p x j μ l σ l and each xj s cluster can be determined 14 λ j arg max i 1 2 k γ ji the main task of gmm clustering analysis is to find estimate parameters from observations a general approach is to search in the parameter space to find parameters that reaches a maximum of the fitness in terms of maximum likelihood 15 ll d ln j 1 n p m x j 1 n ln i 1 k α i p x j μ i σ i the commonly used searching strategy is the expectation maximization e m algorithm which is an iterative procedure consisting of two main steps the expectation and maximization steps 2 3 variable importance in this study classification and regression tree cart is employed for feature selection the cart chooses the split for each node such that maximum reduction in overall node impurity is achieved where impurity is measured as the total sum of squared deviations from node centers in regression problems grömping 2009 in cart the importance of a feature variable is computed as the normalized total reduction of the criterion for regression use mean square error mse brought by that feature taking a well known variable importance metric in cart trees gini importance as example the following briefly introduces the variable importance using impurity reduction ghiasi and zendehboudi 2019 consider that the nk samples fraction from k category out of all samples at the τ node is expressed as follows 16 p k n k n the following equation presents the mathematical expression for gini impurity 17 i τ 1 k p k 2 as the samples are separated and sent to sub nodes τ 1 and τ 2 the gini impurity changes to define the reduction amount of i τ the following equation can be used 18 δ i τ i τ p l i τ 1 p r i τ 2 where pl and pr are the left and right partitions of samples at the τ node and the gini importance can be calculated by summing the reduction in i τ for all the nodes individually for all features θ 19 i g θ τ δ i θ τ replace the gini by mean square error mse the variable importance can be calculated for regression after that perform feature selection by ranking the variable importance from high to low 2 4 performance measures the following four performance measures were used to qualitatively evaluate the performance of the developed models root mean squared error rmse correlation coefficient r nash sutcliffe model efficiency coefficient nse and mean absolute relative error mare which were expressed as follows 20 rmse 1 n i 1 n y pred y obs 2 21 r i 1 n y obs y obs y pred y pred i 1 n y obs y obs 2 i 1 n y pred y pred 2 22 nse 1 i 1 n y obs y pred 2 i 1 n y obs y obs 2 23 mare 1 n i 1 n y pred y obs y obs where n is the number of observations y pred represents the predicted flow y obs is the observed flow and y obs y pred denote the average of observed and predicted flow respectively 3 a hybrid forecasting model before applying this hybrid model to perform streamflow forecasting a decision tree based feature selection is firstly performed to capture the important features which would be fed into the gmm then the streamflow is processed via gmm to separate streamflow into different components with their corresponding probabilities which would be used to fit each xgboost model respectively finally in the testing stage the prediction is the weight sum of values predicted by every xgboost models the procedures of gaussian mixture model coupling with extreme gradient boosting model gmm xgboost for streamflow forecasting are described as follows 1 let y t 1 2 n denotes the time series of target variable and x 1 t x 2 t xnt t 1 2 n denote the time series of explanatory variables 2 divide the time series into training and testing sets y train x train and y test x test respectively 3 use variable importance to select the inputs fed into gmm 4 determine the number of clusters j 5 use explanatory features in the training set to train gmm then the training data will be divided into j groups 6 fit xgboost 1 by clustered data 1 xgboost 2 by clustered data 2 then obtain j xgboosts 7 use trained gmm to cluster testing sets then each data will obtain their probabilities belong to each cluster 8 fed testing set into the all trained xgboosts and the final output is a weight sum of all single xgboost predictions and the weights are the corresponding probabilities fig 1 shows the flowchart of gmm xgboost forecasting model 4 applications 4 1 study area and hydrological data in order to evaluate the performance of gmm xgboost model hydrological series from two representative stations were used monthly streamflow volume data covering the period of january 1959 december 2018 from cuntan and hankou stations on yangtze river basin china were selected for the applications of the gmm xgboost model the yangtze river the third longest river in the world spans a length of 6300 km and drains an area of 1 8 million km2 covering about one fifth of the china s mainland area cuntan station is the inflow gauge point of the upper yangtze river while hankou station is located at the midstream of the yangtze river to improve the performance of the proposed model the meteorological forcing data including precipitation and temperature were used for one month ahead streamflow forecasting fig 2 presents two stations and table 1 enumerates some basic statistics of the streamflow data of the present study sites 4 2 results the antecedent precipitation temperature streamflow at times t 1 t i t 12 where i indicates the lag times were used as the potential predictors the model output is the observed streamflow at time t in both cases the last 20 years of record were used as the testing data to appropriately assess the performance of the proposed model we compared it with two other models standalone xgboost and support vector machine svm unlike traditional machine learning svm simplifies complex problems by mapping the inputs into high dimension space with kernel function to transform the nonlinear problems into linear problems cortes and vapnik 1995 due to the robustness of svm it has been widely applied in streamflow forecasting in recent decades meng et al 2019 therefore in this study svm was employed as a benchmark model applied to compare the performance with standalone xgboost and gmm xgboost standardization was applied to all three models rescaling inputs and output as 24 x scaled x obs μ x σ x where xscaled and xobs indicate the scaled and observed data μx and σx represent the mean and standard deviation of the observed data respectively after rescaling the rescaled data were fed into models grid search and k fold cross validation were applied to optimize three models hyper parameters k was set 5 as commonly used in studies james et al 2013 according to the cross validation results the cluster number was set 3 and 2 for cuntan and hankou forecasting respectively the rmse mare nse r statistics of the gmm xgboost xgboost and svm are given in table 2 the best error measures are highlighted in bold these results indicate that the proposed gmm xgboost exhibits satisfactory predictions and its performance is better than that of other compared models in two case studies in the case of cuntan svm model had poor performance compared with the other models the xgboost showed good performance reducing rmse mare by 4 8 5 5 respectively compared with svm model the gmm xgboost model showed the best accuracy in terms of rmse 84 66 108 m3 mare 18 98 nse 0 82 r 0 91 reducing the rmse mare by 11 1 5 1 respectively compared with svm model also gmm xgboost provided improved forecast accuracy compared with xgboost reducing rmse mare by 6 6 5 6 respectively the svm showed the lowest value of nse and r which was 6 1 and 3 4 less than gmm xgboost in the case of hankou the analyzed results were similar to cuntan the svm had the poor performance compared with other models the gmm xgboost had the best performance amongst all the models and it outperformed xgboost and svm in terms of all the performance measures gaining the best rmse of 129 94 108 m3 nse of 80 57 and mare of 16 88 respectively gmm xgboost reduced the rmse and mare by 6 5 7 8 compared with svm and reduced rmse mare by 5 9 4 7 compared with xgboost in terms of nse and r values gmm xgboost got the highest value 80 57 0 9 while svm had the lowest one with 77 76 0 89 while the statistical metrics presented so far have assessed the performance of the proposed model hydrographs and scatter plots are also helpful in evaluating the correspondence of observed data the forecasts to further illustrate the performance of svm xgboost and gmm xgboost in a more intuitive way hydrographs of the observed versus predicted streamflow in the testing sets were drawn as shown in figs 3 and 4 in the case of cuntan obviously gmm xgboost performed well for forecasting as the predicted data were close to the corresponding observed data and followed the same trend in all plots shown in fig 3 a from the scatterplots of fig 3 it is obvious that all of the model obtained satisfactory results in term of low values less than 300 e 8 m3 while tended to overestimate the medium values 300 700 e 8 m3 and underestimate the high values higher than 700 e 8 m3 also the r value showed that gmm xgboost was superior to other models in hankou station the results obtained from three models were more tightly to the 45 degree straight line than those from cuntan station as shown in fig 4 also gmm xgboost got the highest r value which implied better predictions than others different from predictions from cuntan station predictions from hankou station can better forecast the higher flows to further compare these three models taylor diagram was applied to graphically summarize how closely predictions marches observed pattern in a test data quantified via correlation centred root mean square difference rmsd and amplitude of variation represented by standard deviations fig 5 obviously showed that in both cases the gmm xgboost was closer to the observed reference point with higher correlation and lower centred rmsd in order to test the robustness of the three models the relative error y pred y obs y obs distribution was shown in fig 6 where boxplots were presented to assess the skewness of error fig 6 a showed that in cuntan station for the three models most of relative errors were within the range of 0 3 0 5 while svm tended to make larger errors than xgboost based models in some cases the boxplot showed that the three models got small relative error distributions however svm had larger errors outside the box than the xgboost based models in hankou station the analyzed results were similar to the results from cuntan the boxplot showed that svm tended to produce larger errors than other models in some cases in both cases gmm xgboost generated smaller errors than the xgboost model generally according to the performance measures xgboost based models performed better as their nse all exceeded 75 which indicated a good model and r values were higher than 0 88 which indicated that xgboost is applicable for streamflow forecasting among three models the statistics showed the superiority of the gmm xgboost as in both cases it all got the highest nse and r higher than 0 80 0 90 respectively lowest rmse and mare in generally xgboost were superior to svm in both cuntan and hankou stations as it got less estimation error quantified by rmse and mare moreover it can be observed from the hydrographs and scatterplots that these models had a good performance for forecasting monthly streamflow as the predictions were close to the corresponding observations and followed the same trends in both cases all models performed well in dry seasons but often underestimated flows in wet seasons in the case of cuntan it showed that all models performed well in predicting low flows but tended to underestimate high flows and overestimate medium flows compared with the results from cuntan predictions in hankou were more tightly to the 45 degree lines and compared with low flows high flow prediction seemed to be more scattered indicating the difficulty from capturing the high flow patterns xgboost based models seemed to better forecast the high values compared to other models as the scatterplots showed that the points estimated by gmm xgboost were more tightly to 45 degree straight line to further explore the skill of proposed model in prediction different levels of flows a discussion is given below 4 3 discussion reliable extreme flow low and high flow forecasting is important to disseminate information on water resource management and timely warning such as drought and flood wen et al 2019 tables 3 and 4 showed the statistics of predicted high and low flows in this study high flows are the flows greater one third of mean flow while low flows are those less than one third of mean flow rezaie balf et al 2019 table 3 showed that all models performed satisfactory low flow forecasts with low rmse mare and high nse in cuntan station for the high flow forecasts the value of nse decreased and rmse mare increased as shown in table 3 the gmm xgboost significantly improved the forecasting accuracy in terms of high flows reducing rmse by 11 2 mare by 14 2 compared with svm for hankou station table 4 showed that these models performed well in forecasting low flows while gmm xgboost got best forecasts with reducing rmse mare by 10 0 20 6 improving nse r by 41 2 15 6 respectively compared with svm however they still failed to capture the high flow patterns xgboost outperformed svm not only in forecasting low flows but also in high flows in terms of mare nse and r in respect to high flows gmm xgboost showed its excellent ability to improve the accuracy of high flows with reducing rmse and mare by 10 3 4 3 compared with svm in general svm performed worst in forecasting high flows in wet seasons in both cases also in predicting low flows in hankou station xgboost outperformed svm with lower estimation error in wet seasons also in low flows at hankou station with higher nse and r values similar to xgboost gmm xgboost performed well in estimating high flows the proposed gmm xgboost model outperformed xgboost in predicting low flows in both cases with highest r and lowest mare also it showed significant improvement of forecasting accuracy in high flows at cuntan station but failed to improve accuracy of high flow in hankou station the failure of xgboost may be because it failed to capture the high flow hydrological patterns which will be presented in detail in the following subsection in general it can be conclude from the results that the gmm xgboost improved the accuracy of xgboost in forecasting streamflow of cuntan and hankou stations 4 4 advantages limitations and future improvement in this study based on the principle of modular model a hybrid model coupling xgboost with gmm was proposed to improve monthly streamflow forecasting xgboost was adopted as the base model for its great advantages for example they are simple but still powerful predictive algorithms easy to interpret and require less data preparation feature importance derived from xgboost is useful to interpret the derived approximation of f x to better understand the impact of particular input variables that are most influential in contribution to its variance de clercq et al 2020 also this study has verified the better utility of xgboost over svm based on the principle of modular model cluster analysis was used to improve the forecasting accuracy in this study in the proposed model gmm was applied to group the data into several clusters according to the antecedent precipitation temperature and streamflow the antecedent values of explanatory variables can be considered to represent the catchment characteristics and different hydro meteorological conditions in a data driven model therefore the idea behind this cluster analysis is to identify same hydrological process by grouping the similar temporal information about the physical process into one cluster then the problem of modeling complex hydrological process can be divided into several smaller parts to capture the sub process of hydrology theoretically the idea of modular model can be useful for improving forecasting capabilities of machine learning model as the learning of sub process will be simpler for single model compared to modeling the complicated patterns using one single model the results showed that the cluster analysis based modular model significantly improved the accuracy of standalone xgboost which implied that modular models can better capture the complicated streamflow patterns in spite of the improved accuracy of the proposed models for streamflow forecasting the proposed method has some limitations that create opportunity for further research 1 one should carefully optimize the number of clusters using more clusters we can better model the complicated hydrological process however too many clusters may lead to a poor generalization capability of unseen data i e overfitting on the other hand too few clusters may fail to capture the complicated hydrological patterns therefore the optimal number of clusters is a trade off between accuracy and complexity in this study we chose the cluster number through cross validation in future study a better understanding of physical processes may provide insights into clusters selection 2 more techniques can be applied to tune the hyper parameters in xgboost although the xgboost shows better capability to deal with overfitting problems than other tree based models the hyper parameters in xgboost need to be carefully tuned to attain satisfactory forecasts and better generalization capability in this paper we chose the hyperparameters of xgboost by grid search and cross validation which is time consuming recently some researches have applied several optimization algorithms to improve the forecasting capabilities of data driven models such as particle swarm optimization firefly algorithm and grey wolf optimization dehghani et al 2019 yaseen et al 2017 experimental studies have demonstrated that the proper setting of hyperparameters has substantial influences on the performance of xgboost xia et al 2017 as a future study different optimization algorithms can be carefully explored to provide greater insights into the improvement of forecasting accuracy and other strategies such as early stopping can be adopted to avoid overfitting 3 failure to accurately forecasting streamflow in small catchment in this study we also used streamflow data from huangtaiqiao station on xiaoqing river basin drains an area of 10336 km2 located in jinan city to evaluate the performance of the three models in this case these three models showed poor performance nse is lower than 0 60 the flow is believed to be a result of climate and hydrological processes yang et al 2017 especially the streamflow in small basins is more sensitive to climate variables such as precipitation wang et al 2020 the unsatisfactory results may be due to the poor modeling of the climate process although we used past values to identify the antecedent hydrological conditions the results indicated that to improve the accuracy of data driven models one needs to add some correlated climate variables such as climate index to capture climate patterns 4 provide a deterministic forecast instead of a probabilistic one in hydrological and water resources domains better decision making and risk estimation generally require probabilistic forecasts with quantitative information regarding forecast uncertainty hao et al 2018 ensemble techniques have drawn much attention in probabilistic hydrological forecasting since they can not only provide satisfactory forecasts but also the uncertainty estimation duan et al 2007 therefore there exists further opportunity to couple ensemble techniques such as bayesian model average bma duan et al 2007 and gaussian ensemble dressing ged schölzel and hense 2011 with proposed gmm xgboost to better quantify the forecasting error also to improve the forecasting accuracy 5 conclusions in the context water resources effective planning and management of water issues requires accurate and reliable streamflow forecasting due to nonlinear and non stationary nature of streamflow the forecasting task is proven to be an ongoing scientific challenge most existing researches used machine learning models combined with the idea of separating streamflow dynamics into sub dynamics using modular models to improve the accuracy of forecasting in this study we constructed and evaluated a hybrid model based on extreme gradient boosting and gaussian mixture model namely gmm xgboost this model was developed on the basis of principle of modular models which deals with a complex problems by dividing it into simple ones a tree based feature selection method was applied to determine the input variables fed into gmm then gmm was employed to group the streamflow data into different components based on their hydro meteorological conditions using the selected inputs after that each component was used to fit single xgboost and the final output of the overall gmm xgboost model was a weighted average of the single models the proposed model was applied to predict monthly streamflow at cuntan and hankou stations on yangtze river and to compare the forecasting efficiency svm and standalone xgboost were selected as the benchmark models the results obtained indicated that 1 xgboost based models performed well in two cases as the statistics showed that they all got quite high nse 0 75 and low mare 0 2 and it can be observed from the hydrographs that the predictions followed the same trends with the observed one xgboost is applicable for streamflow forecasting and in general superior to svm 2 among all of the considered models the proposed gmm xgboost model provided the best accuracy and got critical improvement of accuracy compared with the standalone xgboost that s said this cluster analysis based modular model is helpful in improving forecasting accuracy and capturing the dynamic patterns of hydrological process therefore the proposed gmm xgboost is a superior alternative to the other considered models for monthly streamflow forecasting which provides greater insights into the improvement of forecasting accuracy credit authorship contribution statement lingling ni conceptualization methodology software dong wang conceptualization methodology jianfeng wu conceptualization yuankun wang data curation yuwei tao data curation jianyun zhang funding acquisition jiufu liu funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was jointly supported by the national key research and development program of china 2017yfc1502704 2016yfc0401501 and the national natural science foundation of china no 41571017 51679118 91647203 and jiangsu province 333 project bra2018060 the data of meteorological variables including rainfall temperature can be download from national meteorological information center china http data cma cn streamflow data from cuntan and hankou stations to support this study are from the bureau of hydrology ministry of water resource china the 649th order issued in 2000 of ministry of water resource regulations on the national secret and the scope of their secret level in hydraulic engineering work states that hydrological data can not be provided and spread unauthorized but readers can apply for access following by the 601th order issued in 2009 of ministry of water resource china 
5503,the establishment of an accurate and reliable forecasting model is important for water resource planning and management in this study we developed a hybrid model namely gmm xgboost coupling extreme gradient boosting xgboost with gaussian mixture model gmm for monthly streamflow forecasting the proposed model is based on the principle of modular model where a complex problem is divided into several simple ones gmm was applied to cluster streamflow into several groups using the features selected by a tree based method then each group was used to fit several single xgboosts and the prediction is a weighted average of the single models monthly streamflow data at cuntan and hankou stations on yangtze river basin were used to evaluate the performance of the proposed model to compare the forecasting efficiency support vector machine svm and standalone xgboost were selected as the benchmark models the results indicated that although all three models yielded quite good performance on one month ahead forecasting with high nash sutclitte efficiency coefficient nse and low root mean squared error rmse gmm xgboost provided the best accuracy with significant improvement of forecasting accuracy it can be inferred from the results that 1 xgboost is applicable for streamflow forecasting and in general performs better than svm 2 the cluster analysis based modular model is helpful in improving accuracy and capturing the complicated patterns of hydrological process 3 the proposed gmm xgboost model is a superior alternative which can provide accurate and reliable predictions for optimal water resources management keywords streamflow forecasting extreme gradient boosting gaussian mixture model modular models 1 introduction with the increasing water requirements and weather extremes effective planning and management for water issues has been of great concern over the past decades wang et al 2019a b accurate and reliable streamflow forecasting is a critical step for water resources supply and prevention of natural disasters such as floods and droughts rezaie balf et al 2019 wang et al 2019a b however forecasting is a challenging task due to the non linear and non stationary nature of streamflow especially when it comes to extreme flows high and low flows meng et al 2019 therefore improving the accuracy of streamflow forecasting has received considerable attention in order to obtain the reliable forecasting considerable efforts have been made to develop and apply different methods to improve the accuracy these methods can be classified into two types in the first type a hydrological model is established to calculate the true rainfall runoff system response based on the physical mechanism crochemore et al 2016 roy et al 2017 sharma et al 2019 however these models are based on simplified assumptions and require large data sets mehr et al 2013 the second type is data driven models such as statistical models and machine learning based models aksoy and dahamsheh 2018 kratzert et al 2018 quilty et al 2019 yang et al 2017 they are empirical and easy to implement because they are based on historical observations and do not require information on physical processes liu et al 2015 statistical data driven methods such as multiple linear regression autoregressive moving average arma and its variants have been applied for hydrological forecasting since the 1970s adamowski et al 2012 carlson et al 1970 salas 1980 in recent years machine learning techniques have received considerable attention for their strong learning ability and suitability for modeling complex and nonlinear processes a variety of machine learning models such as artificial neural networks ann wen et al 2019 zhang et al 2018a b support vector regression svr liang et al 2018 meng et al 2019 genetic programming gp ravansalar et al 2017 and adaptive neuro fuzzy inference system anfis dehghani et al 2019 yaseen et al 2017 have been developed and provided satisfactory performance in modeling nonlinear hydrological processes including sediment transport modeling ebtehaj et al 2016c 2016a 2016b rainfall runoff modeling kratzert et al 2018 xiang et al 2020 and drought forecasting rahmati et al 2020 zhang et al 2019 compared with other machine learning models decision tree dt is computationally cheaper moreover in dt no assumptions are needed concerning the predictor s distribution also dt offers distinct advantages such as easy to interpret and to visualize ghiasi and zendehboudi 2019 recently a dt based model extreme gradient boosting xgboost proposed by chen and guestrin 2016 has gained popularity in machine learning competitions because this fast efficient scalable model achieves promising results in many domains different from random forest rf which applies parallel ensemble xgboost model is based on the idea of boosting which combines all the prediction of weak learners for developing a strong learner through additive training strategies fan et al 2019 based on dt and gradient boosting xgboost takes advantage of dt as well as gradient boosting gb a few studies have investigated its performance in earth science fields and achieved state of art results fan et al 2018 compared the svm and the xgboost methods for daily solar radiation prediction in the humid subtropical china they found that xgboost outperformed the studied empirical models and recommended it as a promising model for solar radiation estimation due to better model stability efficiency and comparable prediction accuracy xiao et al 2018 proposed an ensemble machine learning approach they used generalized additive model gam to combine predictions derived from rf xgboost and gam to provide reliable historical pm2 5 concentrations predictions the results showed that the proposed model provided more accurate predictions zhang et al 2019 applied xgboost to predict standardized precipitation evapotranspiration index spei at t time using lagged spei at t i time i 1 2 n meteorological measures and climate signals from 32 stations the results showed that the xgboost predicted more accurately in 1 6 steps than ann did despite being widely used in many other fields chen et al 2018 tuong et al 2019 xia et al 2017 to the best of the authors knowledge its streamflow forecasting abilities are thus far unknown since time series data for streamflow are generally highly nonlinear and seasonal applying the raw data directly to the model may not obtain reliable and accurate results rezaie balf et al 2019 in this context several studies employed the idea of separating streamflow dynamics into sub dynamics using modular models wang et al 2006 applied three methods including threshold values fuzzy c means fcm and periodic autoregressive model to group streamflow data into several clusters then a separate multi layer perceptron mlp was fitted to each cluster wu et al 2009 proposed a crisp distributed support vector regression svr model for monthly streamflow prediction according to the magnitudes of flow data the fcm first split the data into three subsets low medium and high levels then three single svrs were fitted to three subsets the results showed the superior performance of this proposed modular model apart from using cluster methods or threshold to group data some signal processing methods such as wavelet transformation singular spectrum analysis and empirical model decomposition emd and its variants are widely used to decompose the time series into several sub series then fit these sub series to several single models to improve the accuracy of forecasting for example wen et al 2019 used two phase decomposition coupling emd with variational model decomposition vmd to enhance a modular model that was comprised of extreme learning machine elm to forecast runoff they found that the modular model performed better than standalone elm rezaie balf et al 2019 used an ensemble empirical model decomposition eemd to enhance a modular model comprised of m5 model tree m5tree and multivariate adaptive regression spline mars to forecast daily monthly river flow the results indicated that the modular models outperformed the standalone models these studies revealed that signal processing method based modular models can improve model performances however they also suffer from the problem of boundary effects and future information hidden in the decomposition processing the further discussion about the future data issue can be referred to fang et al 2019 quilty and adamowski 2018 and zhang et al 2015 the commonly used clustering approaches such as k means and fuzzy c means are distance based while gaussian mixture model gmm is based on probability model rather than an objective function of distance measures gmm assumes that data set follow a mixture model of probability distributions so that each cluster is represented by a parametric probability density and the entire cluster structure can be modeled by a finite mixture gmm has been shown to be a powerful tool for clustering in many research fields kim et al 2014 niknejad et al 2015 qiu et al 2019 yang et al 2012 however the practical applications have rarely been reported in hydrological studies since gmm is based on probability model cluster results can be largely affected by the dimension of the input dataset in such case selecting the important feature subset is critical to help conducting cluster analysis zeng and cheung 2009 in this study to be consistent with the tree based model xgboost decision tree was chose to select features using variable importance which was computed as the total reduction of the criterion brought by that feature the objectives of this study are as follows 1 investigate the potential of xgboost for forecasting streamflow it is the first time that such models have been applied in streamflow forecasting 2 construct a modular model coupling xgboost with gaussian mixture model 3 test the performance of the gmm xgboost model in terms of evaluation criteria hydrographs and scatter plots the remainder of this paper is organized as follows a general description of the methods and performance measures is provided in section 2 the developed model is illustrated in detail in section 3 section 4 presents applications and relevant discussion of results also includes the advantages limitations and future improvement finally section 5 concludes the paper 2 methodology this part gives a brief introduction to extreme gradient boosting xgboost gaussian mixture model gmm variable importance and performance measures 2 1 extreme gradient boosting xgboost extreme gradient boosting xgboost is a scalable machine learning system for tree boosting that proposed by chen and guestrin 2016 the tree ensemble model used in xgboost is trained in an additive manner until stopping criteria are satisfied and the predicted score in a functional form like this 1 y i k 1 k f k x i f k f where y i is the predicted value fk represents an individual regression tree xi is the input vector k is the number of regression functions and f is the space of all possible fk s to learn the set of functions used in the model the following regularized objective is minimized 2 l ϕ i 1 n l y i y i k 1 k ω f k where ω f γ t 1 2 λ ω 2 where l is a loss function between the observed value yi and predicted value y i the second term ω is the regularization term penalized the model complexity to avoid overfitting γ is the complexity of each leaf t is the number of leaves in a decision tree λ is the trade off parameter to scale the penalty ω is the vector of scores on leaves the model is trained in an additive manner formally let y i t be the prediction of the i th instance at the t th iteration a new function ft is added to minimize the following objective 3 l t i 1 n l y i y i t 1 f t x i ω f t to simplify the optimization of eq 3 the loss function is expanded according to the second order taylor series 4 f x f a f a 1 x a f a 2 x a 2 let x be l t i 1 n l y i y i t 1 f t x i ω f t and a be y i t 1 the objective function can be quickly optimized 5 l t i 1 n l y i y t 1 g i f t x i 1 2 h i f t 2 x i ω f t where g i y t 1 l y i y t 1 and h i 2 y t 1 l y i y t 1 are first and second order gradient statistics on the loss function respectively removing the constant terms in eq 5 to obtain the following simplified objective at step t 6 l t i 1 n g i f t x i 1 2 h i f t 2 x i ω f t define i j i q x i j as the instance set of leaf j rewrite eq 6 by expanding ω as follows 7 l t i 1 n g i f t x i 1 2 h i f t 2 x i γ t 1 2 λ j 1 t ω j 2 j 1 t i i j g i ω j 1 2 i i j h i λ ω j 2 γ t taking the derivatives of eq 7 with respect to ωi and equating them to zero gave the optimal weight ω i of leaf j 8 ω j i i j g i i i j h i λ and calculate the corresponding optimal value by 9 l t 1 2 j 1 t i i j g i 2 i i j h i λ γ t assume that il and ir are the instance sets of left and right nodes after split letting i i l i r then the loss reduction after the split is given by 10 l split 1 2 i i l g i 2 i i l h i λ i i r g i 2 i i r h i λ i i g i 2 i i h i λ γ this formula is the gain in loss reduction equation and used in practice for evaluating the split candidates 2 2 gaussian mixture model gmm a gaussian mixture model gmm is a probabilistic model for data clustering that considers all data points to be derived from a mixture of a finite gaussian distribution with unknown parameters mathematically gmm is defined as a parametric probability density function which can be represented as a weighted sum of k gaussian components each component is characterized by a simple parametric form the gmm can be written as 11 p m x i 1 k α i p x μ i σ i where p x μ i σ i is known as the j th components of the mixture with μi σ i αi is called mixture coefficient and must satisfy 0 α i 1 together with i 1 k α i 1 in gmm the probability density function is gaussian distribution defined as follows 12 p x 1 2 π d 2 σ 1 2 e 1 2 x μ t σ 1 x μ by bayes theorem the posterior probability γji that xj belongs to the ith component in the mixture can be defined as follows 13 γ ji p m j x j α i p x j μ i σ i l 1 k α l p x j μ l σ l and each xj s cluster can be determined 14 λ j arg max i 1 2 k γ ji the main task of gmm clustering analysis is to find estimate parameters from observations a general approach is to search in the parameter space to find parameters that reaches a maximum of the fitness in terms of maximum likelihood 15 ll d ln j 1 n p m x j 1 n ln i 1 k α i p x j μ i σ i the commonly used searching strategy is the expectation maximization e m algorithm which is an iterative procedure consisting of two main steps the expectation and maximization steps 2 3 variable importance in this study classification and regression tree cart is employed for feature selection the cart chooses the split for each node such that maximum reduction in overall node impurity is achieved where impurity is measured as the total sum of squared deviations from node centers in regression problems grömping 2009 in cart the importance of a feature variable is computed as the normalized total reduction of the criterion for regression use mean square error mse brought by that feature taking a well known variable importance metric in cart trees gini importance as example the following briefly introduces the variable importance using impurity reduction ghiasi and zendehboudi 2019 consider that the nk samples fraction from k category out of all samples at the τ node is expressed as follows 16 p k n k n the following equation presents the mathematical expression for gini impurity 17 i τ 1 k p k 2 as the samples are separated and sent to sub nodes τ 1 and τ 2 the gini impurity changes to define the reduction amount of i τ the following equation can be used 18 δ i τ i τ p l i τ 1 p r i τ 2 where pl and pr are the left and right partitions of samples at the τ node and the gini importance can be calculated by summing the reduction in i τ for all the nodes individually for all features θ 19 i g θ τ δ i θ τ replace the gini by mean square error mse the variable importance can be calculated for regression after that perform feature selection by ranking the variable importance from high to low 2 4 performance measures the following four performance measures were used to qualitatively evaluate the performance of the developed models root mean squared error rmse correlation coefficient r nash sutcliffe model efficiency coefficient nse and mean absolute relative error mare which were expressed as follows 20 rmse 1 n i 1 n y pred y obs 2 21 r i 1 n y obs y obs y pred y pred i 1 n y obs y obs 2 i 1 n y pred y pred 2 22 nse 1 i 1 n y obs y pred 2 i 1 n y obs y obs 2 23 mare 1 n i 1 n y pred y obs y obs where n is the number of observations y pred represents the predicted flow y obs is the observed flow and y obs y pred denote the average of observed and predicted flow respectively 3 a hybrid forecasting model before applying this hybrid model to perform streamflow forecasting a decision tree based feature selection is firstly performed to capture the important features which would be fed into the gmm then the streamflow is processed via gmm to separate streamflow into different components with their corresponding probabilities which would be used to fit each xgboost model respectively finally in the testing stage the prediction is the weight sum of values predicted by every xgboost models the procedures of gaussian mixture model coupling with extreme gradient boosting model gmm xgboost for streamflow forecasting are described as follows 1 let y t 1 2 n denotes the time series of target variable and x 1 t x 2 t xnt t 1 2 n denote the time series of explanatory variables 2 divide the time series into training and testing sets y train x train and y test x test respectively 3 use variable importance to select the inputs fed into gmm 4 determine the number of clusters j 5 use explanatory features in the training set to train gmm then the training data will be divided into j groups 6 fit xgboost 1 by clustered data 1 xgboost 2 by clustered data 2 then obtain j xgboosts 7 use trained gmm to cluster testing sets then each data will obtain their probabilities belong to each cluster 8 fed testing set into the all trained xgboosts and the final output is a weight sum of all single xgboost predictions and the weights are the corresponding probabilities fig 1 shows the flowchart of gmm xgboost forecasting model 4 applications 4 1 study area and hydrological data in order to evaluate the performance of gmm xgboost model hydrological series from two representative stations were used monthly streamflow volume data covering the period of january 1959 december 2018 from cuntan and hankou stations on yangtze river basin china were selected for the applications of the gmm xgboost model the yangtze river the third longest river in the world spans a length of 6300 km and drains an area of 1 8 million km2 covering about one fifth of the china s mainland area cuntan station is the inflow gauge point of the upper yangtze river while hankou station is located at the midstream of the yangtze river to improve the performance of the proposed model the meteorological forcing data including precipitation and temperature were used for one month ahead streamflow forecasting fig 2 presents two stations and table 1 enumerates some basic statistics of the streamflow data of the present study sites 4 2 results the antecedent precipitation temperature streamflow at times t 1 t i t 12 where i indicates the lag times were used as the potential predictors the model output is the observed streamflow at time t in both cases the last 20 years of record were used as the testing data to appropriately assess the performance of the proposed model we compared it with two other models standalone xgboost and support vector machine svm unlike traditional machine learning svm simplifies complex problems by mapping the inputs into high dimension space with kernel function to transform the nonlinear problems into linear problems cortes and vapnik 1995 due to the robustness of svm it has been widely applied in streamflow forecasting in recent decades meng et al 2019 therefore in this study svm was employed as a benchmark model applied to compare the performance with standalone xgboost and gmm xgboost standardization was applied to all three models rescaling inputs and output as 24 x scaled x obs μ x σ x where xscaled and xobs indicate the scaled and observed data μx and σx represent the mean and standard deviation of the observed data respectively after rescaling the rescaled data were fed into models grid search and k fold cross validation were applied to optimize three models hyper parameters k was set 5 as commonly used in studies james et al 2013 according to the cross validation results the cluster number was set 3 and 2 for cuntan and hankou forecasting respectively the rmse mare nse r statistics of the gmm xgboost xgboost and svm are given in table 2 the best error measures are highlighted in bold these results indicate that the proposed gmm xgboost exhibits satisfactory predictions and its performance is better than that of other compared models in two case studies in the case of cuntan svm model had poor performance compared with the other models the xgboost showed good performance reducing rmse mare by 4 8 5 5 respectively compared with svm model the gmm xgboost model showed the best accuracy in terms of rmse 84 66 108 m3 mare 18 98 nse 0 82 r 0 91 reducing the rmse mare by 11 1 5 1 respectively compared with svm model also gmm xgboost provided improved forecast accuracy compared with xgboost reducing rmse mare by 6 6 5 6 respectively the svm showed the lowest value of nse and r which was 6 1 and 3 4 less than gmm xgboost in the case of hankou the analyzed results were similar to cuntan the svm had the poor performance compared with other models the gmm xgboost had the best performance amongst all the models and it outperformed xgboost and svm in terms of all the performance measures gaining the best rmse of 129 94 108 m3 nse of 80 57 and mare of 16 88 respectively gmm xgboost reduced the rmse and mare by 6 5 7 8 compared with svm and reduced rmse mare by 5 9 4 7 compared with xgboost in terms of nse and r values gmm xgboost got the highest value 80 57 0 9 while svm had the lowest one with 77 76 0 89 while the statistical metrics presented so far have assessed the performance of the proposed model hydrographs and scatter plots are also helpful in evaluating the correspondence of observed data the forecasts to further illustrate the performance of svm xgboost and gmm xgboost in a more intuitive way hydrographs of the observed versus predicted streamflow in the testing sets were drawn as shown in figs 3 and 4 in the case of cuntan obviously gmm xgboost performed well for forecasting as the predicted data were close to the corresponding observed data and followed the same trend in all plots shown in fig 3 a from the scatterplots of fig 3 it is obvious that all of the model obtained satisfactory results in term of low values less than 300 e 8 m3 while tended to overestimate the medium values 300 700 e 8 m3 and underestimate the high values higher than 700 e 8 m3 also the r value showed that gmm xgboost was superior to other models in hankou station the results obtained from three models were more tightly to the 45 degree straight line than those from cuntan station as shown in fig 4 also gmm xgboost got the highest r value which implied better predictions than others different from predictions from cuntan station predictions from hankou station can better forecast the higher flows to further compare these three models taylor diagram was applied to graphically summarize how closely predictions marches observed pattern in a test data quantified via correlation centred root mean square difference rmsd and amplitude of variation represented by standard deviations fig 5 obviously showed that in both cases the gmm xgboost was closer to the observed reference point with higher correlation and lower centred rmsd in order to test the robustness of the three models the relative error y pred y obs y obs distribution was shown in fig 6 where boxplots were presented to assess the skewness of error fig 6 a showed that in cuntan station for the three models most of relative errors were within the range of 0 3 0 5 while svm tended to make larger errors than xgboost based models in some cases the boxplot showed that the three models got small relative error distributions however svm had larger errors outside the box than the xgboost based models in hankou station the analyzed results were similar to the results from cuntan the boxplot showed that svm tended to produce larger errors than other models in some cases in both cases gmm xgboost generated smaller errors than the xgboost model generally according to the performance measures xgboost based models performed better as their nse all exceeded 75 which indicated a good model and r values were higher than 0 88 which indicated that xgboost is applicable for streamflow forecasting among three models the statistics showed the superiority of the gmm xgboost as in both cases it all got the highest nse and r higher than 0 80 0 90 respectively lowest rmse and mare in generally xgboost were superior to svm in both cuntan and hankou stations as it got less estimation error quantified by rmse and mare moreover it can be observed from the hydrographs and scatterplots that these models had a good performance for forecasting monthly streamflow as the predictions were close to the corresponding observations and followed the same trends in both cases all models performed well in dry seasons but often underestimated flows in wet seasons in the case of cuntan it showed that all models performed well in predicting low flows but tended to underestimate high flows and overestimate medium flows compared with the results from cuntan predictions in hankou were more tightly to the 45 degree lines and compared with low flows high flow prediction seemed to be more scattered indicating the difficulty from capturing the high flow patterns xgboost based models seemed to better forecast the high values compared to other models as the scatterplots showed that the points estimated by gmm xgboost were more tightly to 45 degree straight line to further explore the skill of proposed model in prediction different levels of flows a discussion is given below 4 3 discussion reliable extreme flow low and high flow forecasting is important to disseminate information on water resource management and timely warning such as drought and flood wen et al 2019 tables 3 and 4 showed the statistics of predicted high and low flows in this study high flows are the flows greater one third of mean flow while low flows are those less than one third of mean flow rezaie balf et al 2019 table 3 showed that all models performed satisfactory low flow forecasts with low rmse mare and high nse in cuntan station for the high flow forecasts the value of nse decreased and rmse mare increased as shown in table 3 the gmm xgboost significantly improved the forecasting accuracy in terms of high flows reducing rmse by 11 2 mare by 14 2 compared with svm for hankou station table 4 showed that these models performed well in forecasting low flows while gmm xgboost got best forecasts with reducing rmse mare by 10 0 20 6 improving nse r by 41 2 15 6 respectively compared with svm however they still failed to capture the high flow patterns xgboost outperformed svm not only in forecasting low flows but also in high flows in terms of mare nse and r in respect to high flows gmm xgboost showed its excellent ability to improve the accuracy of high flows with reducing rmse and mare by 10 3 4 3 compared with svm in general svm performed worst in forecasting high flows in wet seasons in both cases also in predicting low flows in hankou station xgboost outperformed svm with lower estimation error in wet seasons also in low flows at hankou station with higher nse and r values similar to xgboost gmm xgboost performed well in estimating high flows the proposed gmm xgboost model outperformed xgboost in predicting low flows in both cases with highest r and lowest mare also it showed significant improvement of forecasting accuracy in high flows at cuntan station but failed to improve accuracy of high flow in hankou station the failure of xgboost may be because it failed to capture the high flow hydrological patterns which will be presented in detail in the following subsection in general it can be conclude from the results that the gmm xgboost improved the accuracy of xgboost in forecasting streamflow of cuntan and hankou stations 4 4 advantages limitations and future improvement in this study based on the principle of modular model a hybrid model coupling xgboost with gmm was proposed to improve monthly streamflow forecasting xgboost was adopted as the base model for its great advantages for example they are simple but still powerful predictive algorithms easy to interpret and require less data preparation feature importance derived from xgboost is useful to interpret the derived approximation of f x to better understand the impact of particular input variables that are most influential in contribution to its variance de clercq et al 2020 also this study has verified the better utility of xgboost over svm based on the principle of modular model cluster analysis was used to improve the forecasting accuracy in this study in the proposed model gmm was applied to group the data into several clusters according to the antecedent precipitation temperature and streamflow the antecedent values of explanatory variables can be considered to represent the catchment characteristics and different hydro meteorological conditions in a data driven model therefore the idea behind this cluster analysis is to identify same hydrological process by grouping the similar temporal information about the physical process into one cluster then the problem of modeling complex hydrological process can be divided into several smaller parts to capture the sub process of hydrology theoretically the idea of modular model can be useful for improving forecasting capabilities of machine learning model as the learning of sub process will be simpler for single model compared to modeling the complicated patterns using one single model the results showed that the cluster analysis based modular model significantly improved the accuracy of standalone xgboost which implied that modular models can better capture the complicated streamflow patterns in spite of the improved accuracy of the proposed models for streamflow forecasting the proposed method has some limitations that create opportunity for further research 1 one should carefully optimize the number of clusters using more clusters we can better model the complicated hydrological process however too many clusters may lead to a poor generalization capability of unseen data i e overfitting on the other hand too few clusters may fail to capture the complicated hydrological patterns therefore the optimal number of clusters is a trade off between accuracy and complexity in this study we chose the cluster number through cross validation in future study a better understanding of physical processes may provide insights into clusters selection 2 more techniques can be applied to tune the hyper parameters in xgboost although the xgboost shows better capability to deal with overfitting problems than other tree based models the hyper parameters in xgboost need to be carefully tuned to attain satisfactory forecasts and better generalization capability in this paper we chose the hyperparameters of xgboost by grid search and cross validation which is time consuming recently some researches have applied several optimization algorithms to improve the forecasting capabilities of data driven models such as particle swarm optimization firefly algorithm and grey wolf optimization dehghani et al 2019 yaseen et al 2017 experimental studies have demonstrated that the proper setting of hyperparameters has substantial influences on the performance of xgboost xia et al 2017 as a future study different optimization algorithms can be carefully explored to provide greater insights into the improvement of forecasting accuracy and other strategies such as early stopping can be adopted to avoid overfitting 3 failure to accurately forecasting streamflow in small catchment in this study we also used streamflow data from huangtaiqiao station on xiaoqing river basin drains an area of 10336 km2 located in jinan city to evaluate the performance of the three models in this case these three models showed poor performance nse is lower than 0 60 the flow is believed to be a result of climate and hydrological processes yang et al 2017 especially the streamflow in small basins is more sensitive to climate variables such as precipitation wang et al 2020 the unsatisfactory results may be due to the poor modeling of the climate process although we used past values to identify the antecedent hydrological conditions the results indicated that to improve the accuracy of data driven models one needs to add some correlated climate variables such as climate index to capture climate patterns 4 provide a deterministic forecast instead of a probabilistic one in hydrological and water resources domains better decision making and risk estimation generally require probabilistic forecasts with quantitative information regarding forecast uncertainty hao et al 2018 ensemble techniques have drawn much attention in probabilistic hydrological forecasting since they can not only provide satisfactory forecasts but also the uncertainty estimation duan et al 2007 therefore there exists further opportunity to couple ensemble techniques such as bayesian model average bma duan et al 2007 and gaussian ensemble dressing ged schölzel and hense 2011 with proposed gmm xgboost to better quantify the forecasting error also to improve the forecasting accuracy 5 conclusions in the context water resources effective planning and management of water issues requires accurate and reliable streamflow forecasting due to nonlinear and non stationary nature of streamflow the forecasting task is proven to be an ongoing scientific challenge most existing researches used machine learning models combined with the idea of separating streamflow dynamics into sub dynamics using modular models to improve the accuracy of forecasting in this study we constructed and evaluated a hybrid model based on extreme gradient boosting and gaussian mixture model namely gmm xgboost this model was developed on the basis of principle of modular models which deals with a complex problems by dividing it into simple ones a tree based feature selection method was applied to determine the input variables fed into gmm then gmm was employed to group the streamflow data into different components based on their hydro meteorological conditions using the selected inputs after that each component was used to fit single xgboost and the final output of the overall gmm xgboost model was a weighted average of the single models the proposed model was applied to predict monthly streamflow at cuntan and hankou stations on yangtze river and to compare the forecasting efficiency svm and standalone xgboost were selected as the benchmark models the results obtained indicated that 1 xgboost based models performed well in two cases as the statistics showed that they all got quite high nse 0 75 and low mare 0 2 and it can be observed from the hydrographs that the predictions followed the same trends with the observed one xgboost is applicable for streamflow forecasting and in general superior to svm 2 among all of the considered models the proposed gmm xgboost model provided the best accuracy and got critical improvement of accuracy compared with the standalone xgboost that s said this cluster analysis based modular model is helpful in improving forecasting accuracy and capturing the dynamic patterns of hydrological process therefore the proposed gmm xgboost is a superior alternative to the other considered models for monthly streamflow forecasting which provides greater insights into the improvement of forecasting accuracy credit authorship contribution statement lingling ni conceptualization methodology software dong wang conceptualization methodology jianfeng wu conceptualization yuankun wang data curation yuwei tao data curation jianyun zhang funding acquisition jiufu liu funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was jointly supported by the national key research and development program of china 2017yfc1502704 2016yfc0401501 and the national natural science foundation of china no 41571017 51679118 91647203 and jiangsu province 333 project bra2018060 the data of meteorological variables including rainfall temperature can be download from national meteorological information center china http data cma cn streamflow data from cuntan and hankou stations to support this study are from the bureau of hydrology ministry of water resource china the 649th order issued in 2000 of ministry of water resource regulations on the national secret and the scope of their secret level in hydraulic engineering work states that hydrological data can not be provided and spread unauthorized but readers can apply for access following by the 601th order issued in 2009 of ministry of water resource china 
5504,recently there has been an increased emphasis on employing data driven models to forecast streamflow however in these data driven models used for forecasting monthly streamflow the performances of filter based feature selection ffs methods have not been studied in detail in this study we investigated the effectiveness of eight common ffs methods namely linear pearson correlation partial linear pearson correlation pci mutual information mi conditional mi partial mi maximal relevance minimal redundancy pearson correlation maximal relevance minimal redundancy mi and gamma test methods on three regression models namely multiple linear regression mlr ensemble extreme learning machine enelm and k nearest neighbor knn regression for real world one month ahead streamflow forecasting the study was conducted on three cases from the catchment attributes and meteorology for large sample studies camels data sets furthermore two termination criterion tc methods the hampel test and resampling were comparatively analyzed the results of this study highlight three important findings first there was no dominant ffs method that coupled with enelm or knn second when resampling was applied to select a final model in the candidate combinations of the eight ffs methods and three regression models pci was the most favorable ffs method for the final model finally the hampel test tc was superior to the resampling tc in terms of stability and anti overfitting these findings have significant practical reference value for real world monthly streamflow forecasting keywords feature selection filter method termination criterion streamflow forecasting 1 introduction streamflow forecasting is a crucial part of water resource planning and management yaseen et al 2015 in recent decades there have been an increasing number of publications focusing on improving the accuracy of streamflow forecasting e g fahimi et al 2016 fang et al 2019 however streamflow changes have intricate patterns and are difficult to accurately forecast due to influences from the climate the geographical environment social development and human activities huang et al 2014 shoaib et al 2016 categorized the existing streamflow forecasting models into two main categories theory driven models and data driven models compared with theory driven models data driven models have attracted considerable interest in recent years because they do not involve physical mechanisms and can be accessibly applied liu et al 2014 researchers have developed various data driven models including classic time series e g mehdizadeh et al 2019 valipour 2015 and artificial intelligence based models e g fahimi et al 2016 tan et al 2018 tikhamarine et al 2020 yaseen et al 2015 2016 yu et al 2020 for streamflow forecasting the mechanism of data driven models for streamflow forecasting is the establishment of a mapping relationship between the influential factors historical rainfall historical river flow temperature evaporation etc and the forecasting targets through statistical learning therefore there are two essential factors for data driven models namely the mapping relationship and the selected influential factors i e the model inputs to establish an appropriate robust mapping relationship abundant regression models have been applied for streamflow forecasting e g tongal and booij 2018 yaseen et al 2017 these models include novel regression methods such as the combined continuous wavelet and multigene genetic programming method hadi and tombul 2018 the stepwise model empowered with genetic programming mahmood al juboori and guven 2016 a method based on the hidden markov model and gaussian mixture regression liu et al 2018 and the use of a wavelet based dynamic neural network shoaib et al 2016 in addition popular machine learning models and deep learning models such as support vector regression svr extreme learning machines elm and the long short term memory lstm neural network are frequently employed for streamflow forecasting e g kisi and cimen 2011 yaseen et al 2019 yuan et al 2018 regarding model inputs in addition to the most commonly used input influential factors of precipitation and streamflow e g kagoda et al 2010 li et al 2010 information such as evaporation temperature soil moisture relative humidity and climatic indices have been employed in data driven models and have proven to be beneficial for streamflow forecasting behzad et al 2009 makkeasorn et al 2008 noori et al 2011 rasouli et al 2012 sharma et al 2015 notably increased input variables for data driven models do not necessarily result in better performances guyon and elisseeff 2003 therefore when developing data driven models one should perform input variable selection ivs which is also known as feature selection galelli et al 2014 miao and niu 2016 as a generally accepted rule ivs algorithms can be classified into three categories filter wrapper and embedded methods jović et al 2015 may et al 2011 compared with wrapper based and embedded based feature selection methods the filter based feature selection ffs method has generated considerable recent research interest in hydrological data driven models as the ffs method is independent of a regression model and easy to compute quilty et al 2016 based on whether they consider the dependencies between the features the ffs methods can be divided into bivariate and multivariate methods jović et al 2015 the former uses specific evaluation criteria to evaluate the relation between the feature and the target regardless of other features while the latter considers not only the correlation between the feature and the target but also the correlations between the feature and other features for hydrological research fields multivariate ffs methods including partial mutual information pmi may et al 2008 conditional mutual information cmi quilty et al 2016 partial linear pearson correlation pci galelli et al 2014 gamma test noori et al 2011 sharifi et al 2017 and maximal relevance minimal redundancy mutual information mrmrmi methods peng et al 2005 have been frequently applied to drive more informative data driven models fang et al 2018 utilized pmi to select input variables from local meteorological and global climate data for reference evapotranspiration forecasting noori et al 2011 applied the gamma test to select the appropriate inputs for monthly streamflow forecasting sharifi et al 2017 used the gamma test forward selection and factor analysis to determine the best input combination for daily runoff prediction quilty et al 2016 proposed bootstrap cmi and compared bootstrap cmi with pci cmi and pmi for an urban water demand forecasting experiment in ottawa canada hejazi and cai 2009 presented a modified version of mrmrmi to select inputs for forecasting daily reservoir releases in addition to the above multivariate ffs methods bivariate ffs methods such as linear pearson correlation lc zou et al 2003 and mutual information mi vergara and estévez 2013 have been frequently employed to select input variables for hydrological forecast models li et al 2019 liu et al 2014 however it seems that there is no systemic study comparing different ffs methods for streamflow forecasting furthermore the termination criterion tc which could result in different selections has not been investigated for ffs for monthly streamflow forecasting regarding the tc for ffs may et al 2008 noted that among various tc methods including the bootstrap modified bootstrap tabulated critical value akaike information criterion aic and hampel test methods the aic and the hampel test should be widely applicable regarding this recommendation two points should be noted first the aic is a measure of trade off between the accuracy and complexity of a model therefore the calculation of aic depends on the type of regression model that is used for the linear regression model and ordinary shallow artificial neural network ann the measure of model complexity for the aic can be easily obtained by determining the number of model parameters but for other regression models such as nonparametric regression it is complicated or difficult to calculate complexity through the effective number of parameters or the vapnik chernovenkis dimension may et al 2011 2008 second determining an appropriate feature subset is a model selection problem stone 1977 proved that leave one out loo cross validation cv and the aic method are asymptotically equivalent therefore in addition to loo cv resampling methods for model selection such as k fold cv and bootstrapping hastie et al 2009 kuhn and johnson 2013 could be leveraged off for the tc of ffs which has not been attempted by previous studies of streamflow forecasting the objectives of this study are twofold first we examined the effectiveness of eight ffs methods namely lc pci mi cmi pmi maximal relevance minimal redundancy pearson correlation mrmrp tsanas et al 2013 mrmrmi and the gamma test on three regression models namely multiple linear regression mlr ensemble extreme learning machine enelm and k nearest neighbor knn regression for one month ahead streamflow forecasting second in addition to the hampel test tc resampling methods namely the loo k fold bootstrap and holdout methods were explored as the tc of ffs for one month ahead streamflow forecasting the remainder of this work is organized as follows in section 2 we present the study areas and data used section 3 describes the eight ffs methods two tc for ffs three regression methods four error evaluation criteria and the experimental setup used the experimental results are displayed in section 4 the discussion and conclusion are given in sections 5 and 6 respectively 2 study areas and data in this study three catchments fig 1 that are impacted by a relatively low level of human activities and have different hydroclimatic conditions were selected as the study areas table 1 lists the gauge name gauge id catchment area and climate characteristics of these basins these data were retrieved from the catchment attributes and meteorology for large sample studies camels data set which is a new data set of attributes for 671 catchments in the united states interested readers can obtain more detailed information about the study areas from this public database addor et al 2017 newman et al 2015 the period of the data set used in this study is from january 1980 to december 2014 the time series of the studied monthly streamflow and the corresponding autocorrelograms are shown in fig 2 all of the series show a strong annual periodicity candidate input variables including 12 lags in five types of local monthly meteorological information five global monthly climatic indices and monthly streamflow were used to forecast the monthly streamflow consequently the sample size was 408 and the number of candidate input variables was 132 to maintain a 7 3 ratio of the training set to the testing set the first 285 samples were used as the training set and the remaining 123 samples were used as the testing set for local meteorological information we obtained daily average precipitation mm d solar radiation w m2 minimum and maximum temperature c and vapor pressure pa from daymet thornton et al 2014 in camels and averaged these daily data at the monthly scale referring to rasouli et al 2012 we selected the niño 3 4 pacific north american pna arctic oscillation ao north atlantic oscillation nao and pacific decadal oscillation pdo data sets as candidate global climatic indices and these data sets were downloaded from the earth system research laboratory of the national oceanic and atmospheric administration https www esrl noaa gov psd data climateindices list monthly streamflow m3 s was acquired by averaging the daily streamflow m3 s retrieved from the r package dataretrieval in one month table 2 presents the commonly used descriptive statistical results for the studied streamflow time series the brock dechert scheinkman bds test broock et al 1996 a nonparametric method was used to investigate whether the studied streamflow series was nonlinear detailed information of the bds test for streamflow series is shown in maheswaran and khosa 2012 the results of the bds test for the three studied series are given in table 3 this table indicates that all statistical values of the bds test are significant therefore it can be inferred that all of the studied streamflow series had nonlinear features and the nonlinear data driven model should be suitable for the studied series maheswaran and khosa 2012 before training the data driven models using eq 1 all variables in the full data set were normalized into the range of 0 1 1 x i x i x imin x imax x imin where xi is the ith variable and ximin and ximax are the minimum and maximum values of the ith variable in the training set respectively after the training and forecasting processes had been conducted inverse transformations for eq 1 were performed for the forecasting values finally the error evaluation criteria in section 3 4 were calculated based on these back transformed normalized forecasting data the objective of data normalization is to eliminate the different scales among each data dimension which could increase the accuracy and speed of calculations hadi and tombul 2018 3 methods 3 1 eight filter based feature selection methods the ffs selects features based on the general characteristics of the data sánchez maroño et al 2007 generally ffs executes a statistical measure e g distance dependency consistency or information between the input variables and the target variables to allocate a score to each feature and then the features are ranked by that score by using tc such as the hampel test tc on ranked features one can decide whether the feature should be kept or removed from the candidate input set there have been numerous publications focusing on ffs because of its advantages such as its computational efficiency however ffs also has disadvantages for example the selected subset might not be globally optimal chandrashekar and sahin 2014 ffs can be divided into two categories bivariate ffs and multivariate ffs the former category which includes the lc method and the mi method does not consider the correlations among input variables while the latter category which includes pci and pmi takes these correlations into consideration to choose the representative ffs in this study we selected eight commonly used ffs methods for comparison for bivariate ffs we selected the lc method and the mi method which consider linear correlation and nonlinear correlation respectively for multivariate ffs we chose pci and mrmrp as the linear correlation cases pmi cmi mrmrmi and the gamma test were chosen as the nonlinear correlation cases the detailed calculation methods of these selected ffss are reported in the corresponding references in table 4 3 2 two typical termination criteria because different tc methods can generate various feature selection results selecting an appropriate tc method is important for ffs in the field of water resources diverse tc methods for ffs such as aic bayesian information criterion bic bootstrap tests modified bootstrap tests outlier detection methods and tabulated critical values galelli et al 2014 he et al 2011 may et al 2008 sharma and mehrotra 2014 have been utilized two tc methods have been recommended for ffs in these previous studies may et al 2008 compared eight tc methods for both pmi and pci and recommended the aic and hampel test due to their regardless of the data distribution quilty et al 2016 advocated the hampel test for ffs as it is a robust outlier detection method and is computationally efficient however as mentioned in section 1 the aic may be complicated or difficult to calculate when coupled with nonparametric regression therefore in this study we selected the hampel test and the loo cv which is asymptotically equivalent to the aic stone 1977 as the tc methods for ffs in addition several other representative resampling methods including the k fold cv bootstrap holdout and repeated k fold cv which are more efficient than the loo cv were explored as the tc of ffs in this study the hampel test tc can be calculated only using the values of the ranked features however the resampling tc requires a regression model and preset choice criteria such as the root mean square error rmse and the coefficient of determination r2 referring to lima et al 2015 we selected the rmse as the choice criterion in this study specifically in terms of the incremental forwarding strategy the ranked candidate features were added to the regression model in sequence the rmse which was computed on the out of sample by resampling in the training set was considered as the choice criterion in other words the data driven model that presented the minimum rmse was regarded as the best model and the corresponding input variables were considered to comprise the best input scenario for brevity details on the hampel test method can be obtained from may et al 2008 and kuhn and johnson 2013 describes the five selected resampling methods notably the resampling methods could be used not only to select variables but also to tune hyperparameters which are essentially used to make model selections 3 3 regression methods in this study we selected three regression methods mlr enelm and knn to compare the effects of the eight ffs methods we selected these three regression methods for two reasons first the enelm and knn are typical nonlinear regression methods for streamflow forecasting and the mlr is a typical linear regression method for streamflow forecasting second these three regression methods are computationally efficient and easy to program for applications 3 3 1 multiple linear regression mlr models the linear relationship between explanatory independent variables and response dependent variables andrews 1974 by fitting a linear equation 2 2 y α 0 α 1 x 1 α 2 x 2 α k x k where y is the response variable xt x 1 x 2 x k represents the explanatory variables αt α 0 α 1 α k denotes the regression coefficients and is the error term of the model also known as the residual in this study we utilized commonly used ordinary least squares method to estimate the coefficients αt in eq 2 3 3 2 ensemble extreme learning machine elm which were proposed by huang et al 2006 is a type of single hidden layer feedforward neural network slfn that is fast learning an slfn with l hidden layer nodes can be represented as eq 3 3 y j i 1 l β i g w i x j b i β 0 i 1 2 l j 1 2 n where n is the number of the cases l is the number of hidden layer nodes i denotes the ith hidden layer j is the jth case xj and y j represent the model input and output in the jth case respectively β i and β 0 denote the weight and bias respectively of the output w i and b i represent the input weight and bias respectively in the ith hidden layer and g is the activation function huang et al 2006 proved that if the activation function is infinitely differentiable through randomly assigned w i and b i values only the β parameters need to be optimized when minimizing the mean squared error between the model output and the target data in this way training an slfn can be transformed into solving a linear system as h β y then we can obtain β h y zhu et al 2005 4 h 1 g w 1 x 1 b 1 g w l x 1 b l 1 g w 1 x n b 1 g w l x n b l where h denotes the moore penrose generalized inverse of h eq 4 β is the parameter matrix eq 5 with the dimension l 1 m and y is the target matrix eq 6 with the dimension n m 5 β β 0 β 1 β l 6 y y 1 y 2 y n because of the random assignment of weights and bias parameters in the hidden layer the elm may produce different results when the algorithm is repeated on the same data set to overcome this problem and improve the predictive performance an ensemble elm is proposed nan and han 2010 zhai et al 2012 although there are various ensemble methods in this study we used the simplest method which averages the outputs of individual ensemble members lima et al 2015 3 3 3 k nearest neighbor regression knn regression is a nonparametric method that stores all available cases and forecasts the numerical target according to a similarity measure maltamo and kangas 1998 usually for regression three similarity measures namely the euclidean distance manhattan distance and minkowski distance are used after searching the knns the expected numerical target can be obtained by calculating the numerical target of the knns the simple average and inverse distance weighted average algorithms are frequently used in the calculations nigsch et al 2006 the knn regression method used in this study is described as follows 1 load the data and choose the number of neighbors k 2 for each observation calculate the euclidean distance between the queried observation and the current observation from the data record the calculated distance and the observation index 3 sort the observations in ascending order according to distance 4 pick the first k observations from all sorted observations return the inverse distance weighted average of the streamflow output of the selected k observations 3 4 error evaluation criteria to evaluate the performances of the models referring to the literature chai and draxler 2014 krause et al 2005 mccuen et al 2006 shi et al 2018 yaseen et al 2016 in this study we selected four criteria namely the nash sutcliffe efficiency nse rmse correlation coefficient r and mean absolute error mae the formulas of these evaluation criteria are shown as follows 7 nse 1 i 1 n q i q i 2 i 1 n q i q 2 8 rmse i 1 n q i q i 2 n 9 r i 1 n q i q q i q i 1 n q i q 2 i 1 n q i q 2 10 mae 1 n i 1 n q i q i where n q i q q i and q are the number of observations observed river flow average observed river flow forecasted river flow and average forecasted river flow respectively 3 5 experimental setup fig 3 shows the flow chart of the methodology applied in this study in our experiments we assigned the hyperparameters of the enelm before comparing the different fs methods specifically the numbers of elm and hidden layer neurons were set to 50 and 20 respectively the commonly used sigmoid function was regarded as the activation function therefore no other hyperparameters were tuned for the enelm and mlr in our experiments for the knn method we tuned k the number of nearest neighbors from 1 to 20 and the best k value was determined by minimizing the rmse in the out of sample of the training set the regression results for the knn model were obtained by weighting the selected knns according to the inverse distance with respect to the k fold and repeated k fold resampling methods we set the folds and the repeat times at 5 and 10 respectively regarding the bootstrap and holdout resampling methods the bootstrap value and holdout percentage were set to 30 and 30 respectively when conducting pmi and pci we utilized r scripts downloaded from https github com gbhumphrey1 pmis pcis for mi mrmrmi and cmi we programmed these entropy based methods in the matlab environment using nonparametric multivariate edgeworth expansion van hulle 2005 in the information theoretical estimators ite toolbox szabo 2014 the r package forecast was employed for the dm test section 4 6 and bds test section 2 other experiments were performed in the matlab environment for experimental consistency and repeatability we set the fixed random seed for the enelm model and the resampling method 4 results 4 1 linear pearson s correlation and nonlinear correlation mutual information between the streamflow and candidate input variables in the training set to evaluate the relation between the dependent variable and each of the independent variables we plotted the lc and mi between the streamflow and candidate input variables in the training set in figs 4 and 5 figs 4 and 5 show two obvious characteristics first for station 01013500 and station 07083000 the twelfth streamflow lag had the strongest correlation with streamflow in terms of both lc and mi while for station 11264500 the first streamflow lag had the strongest correlation second some candidate input variables such as the fourth lag of the nao had correlation values close to zero in terms of both lc and mi 4 2 impact of different filter based feature selection methods on the regression models when using the hampel test termination criterion to examine the impacts of the eight ffs hampel combinations ffs by the hampel test tc on particular regression models we determined the input variables selected by the eight methods table 5 illustrates the number of selected features and exhibited the performances of the mlr enelm and knn we tuned the best k of the knn by the 5 fold method in this subsection in the testing set using these input variables figs 6 8 the results in figs 6 8 show that pci hampel pci using the hampel test was the most suitable method for mlr in the testing set based on the nse rmse r and mae values which showed consistency in all study cases however for both enelm and knn there was no evidence showing that one ffs hampel method was superior to the others for all study cases based on not only the nse but also the rmse r and mae metrics in the testing set taking the nse metric as an example it is apparent in fig 6 that at station 01013500 the best ffs hampel combinations for the enelm and knn were cmi hampel and pci hampel respectively for station 07083000 the data in fig 7 indicate that the best ffs hampel combinations for the enelm and knn in terms of the nse were mrmrmi hampel and mrmrp hampel respectively regarding station 11264500 mrmrmi hampel was the most appropriate filter method for both enelm and knn based on the nse 4 3 impact of different filter based feature selection methods on the regression models when using the resampling termination criterion to analyze the impacts of the eight ffs methods by the resampling tc on particular regression models we listed the best ffs for the mlr enelm and knn in the training set using an incremental forwarding selection strategy by resampling and the corresponding forecast performance of the testing set in tables 6 8 additionally because diverse resampling methods could induce varied model selection results we also showed the outstanding models results under the five different resampling methods tables 6 8 show that when using mlr pci was preferable to the other ffs methods in the training set in all study cases regardless of which resampling method was employed nevertheless we could not determine the leading ffs method for enelm and knn for instance mrmrp was selected as the optimum ffs at station 07083000 when utilizing resampling with the bootstrap and knn methods however mrmrp was not the best choice for stations 01013500 and 11264500 in addition the use of different resampling methods in the same enelm or knn model at the same station resulted in different selected ffs methods taking station 11264500 as an example when practicing resampling with the 5 fold and bootstrap methods for the knn model the selected ffs methods were pci and pmi respectively 4 4 impact of different filter based feature selection methods on a determined regression model when using the resampling termination criterion to examine the selected regression models selected in the training set among mlr enelm and knn determined through different ffs with the resampling tc we listed the best selected ffs regression methods combination of eight ffs methods and three regression methods using resampling in the training set and the corresponding forecast performances in the testing set for the three study cases in table 9 a comparison of the results in table 9 highlights three interesting characteristics first regardless of the resampling methods adopted no one ffs regression model was always superior to the other models for the three cases for instance when conducting the resampling method with bootstrapping the pci mlr and pmi enelm models were chosen for station 01013500 and station 11264500 respectively second among the eight ffs methods pci was selected the most times for all study cases specifically for station 01013500 all five resampling methods chose pci as the most beneficial method of ffs while pci was selected three times at stations 07083000 and 11264500 notably when using resampling with the 5 fold method pci was the most favorable ffs method for all stations the last characteristic is related to the resampling method the performances of the models selected by the 5 fold and bootstrap methods were similar to each other the model selected by loo cv produced the most inferior performance at all stations and the models selected by the holdout and 10 repeat 5 fold methods showed the second worst performances at station 01013500 and station 11264500 respectively typically at station 11264500 the poorest rmse nse r and mae values were produced by pci mlr with 49 input variables selected through loo cv pci mlr with 48 input variables selected through the 10 repeat 5 fold method produced close to the poorest results pci mlr with 31 input variables and pmi enelm with 4 input variables which were developed by the 5 fold and bootstrap methods respectively had comparable predictive performances in terms of the rmse and nse values 4 5 impacts of different filter based feature selection methods on a determined regression model when using the hampel test termination criterion corresponding to table 9 table 10 shows the best selected ffs hampel regression regression models with ffs hampel methods using resampling in the training set and the forecasting performances of these models in the testing set for the three case studies the first notable characteristic of table 9 mentioned in subsection 4 4 still exists in table 10 for example when performing resampling with the 5 fold method pci hampel knn was selected for station 07083000 and pci hampel mlr was chosen for station 11264500 similarly the second notable characteristic of table 9 is also evident in table 10 at stations 01013500 and 11264500 pci was selected as the final ffs with all five resampling methods although pci was selected two times at station 07083000 pci hampel knn selected by the 5 fold method generated the same performance as mrmrmi hampel knn selected by the 10 repeat 5 fold method and exhibited the best model performance with regard to the characteristics of the resampling methods the data in table 10 show that model selection using the bootstrap and holdout methods may result in the most inferior performance and the best model performances were generated by model selection using the 5 fold or 10 repeat 5 fold methods 4 6 comparing models using the diebold mariano test tables 9 and 10 show that some models presented close performance values for instance in table 9 at station 07083000 pci enelm using the 5 fold method produced a nse of 0 795 in the testing set while pci knn using the holdout method yielded a nse of 0 810 in the testing set to verify whether the accuracies of these models had statistical significance in this study we utilized the diebold mariano test with absolute error loss dm ae to compare typical models qu et al 2017 first we investigated which resampling method should be employed in practice as indicated by the third characteristics in tables 9 and 10 resampling with the 5 fold method seemed to be the best option among all resampling methods to support this hypothesis if the models selected by the 5 fold method did not show the best performance we compared them with the best performance model selected by other resampling methods table 11 provides the results of these tests it is apparent that the dm ae values of the two compared pairs were higher than the upper limit at the 5 significance level this implies that the models compared in table 11 had different accuracies second we compared the difference between the selected ffs hampel regression using the 5 fold method corresponding to the results in table 10 and the selected ffs regression using the 5 fold method corresponding to the results in table 9 for the three study stations table 12 the data in table 12 indicate that at station 07083000 pci enelm with the 5 fold method and pci hampel knn with the 5 fold method had different accuracies while there was no significant difference between the models of pci mlr with the 5 fold method and pci hampel mlr with the 5 fold method at stations 01013500 and 11264500 5 discussion according to the above described results pci hampel is strongly recommended for one month ahead data driven models of streamflow forecasting in this study the correlation results in figs 4 and 5 suggest that the lags of streamflow provide the most informative guide for one month ahead streamflow forecasting in this study which means that the traditional univariate streamflow time series forecasting model may yield valid forecasting results in addition the figures highlight the need for some general candidate variables to be disregarded due to their near zero correlation values with regard to lc and mi with respect to the choice of a proper ffs method for a particular regression model in practice the results of subsections 4 2 and 4 3 suggest that in practice it is not possible to predict a common ffs for enelm and knn this finding means that when using enelm or knn in practical applications for one month ahead streamflow forecasting the choice of a specific ffs should be analyzed concretely however quilty et al 2016 suggested that the performance of cmi is always superior to that of pmi and pci for several synthetic data sets and real world daily urban water demand forecasts using enelm this inconsistency might be because the driving factors for the studied real world monthly streamflow series were more complex and diverse than those of the synthetic data sets and the real world daily urban water demand series studied by quilty et al 2016 notably no previous research was involved in this finding and we speculate that this situation might apply to other types of nonlinear regression for one month ahead streamflow forecasting in addition the evidence from tables 6 8 and figs 6 8 confirmed that pci was the best choice for the mlr this is in good agreement with previous studies interestingly when we employed the resampling methods to choose a data driven model from the combinations of eight ffs and three regression methods in subsections 4 4 and 4 5 pci was the most popular ffs to be selected in our study areas regardless of whether the selected regression model was linear or nonlinear although a few exceptions in tables 9 and 10 did not support this result it can be inferred that this inconsistency was due to the application of five different resampling methods notably may et al 2008 suggested that for their studied synthetic data sets pci performed relatively poorly in comparison to pmi when using the data produced by a nonlinear model and performed well when using the data produced by a linear model however for the studied real world streamflow series that had nonlinear features table 3 it seems that pci had a superior performance to pmi and other nonlinear ffss this might be the result of complex relations which have both linearity and nonlinearity with more linearity than nonlinearity among the driving factors and the real world monthly streamflow series therefore this study makes an important finding that the pci may be the most promising ffs among the eight studied ffss for real world monthly streamflow forecasting in addition as indicated by the data in tables 6 10 utilizing different resampling methods could cause the selection of dissimilar models these dissimilar models result in various forecasting results which creates a difficult problem with the selection of the resampling method in practice as previously described by a comprehensive analysis of the data in tables 9 and 10 the 5 fold method seems to be the best resampling method for our cases however evidence from table 11 does not agree with this conjecture this discrepancy between table 9 and table 10 might have occurred because the models in table 9 used the resampling tc while the models in table 10 used the hampel test tc thus the results in table 9 were more sensitive to the resampling method than those in table 10 additionally it must be emphasized that except for loo cv the resampling methods used in this study have randomness thus different random seeds or holdout percentages can produce different results therefore future research should be performed to determine which resampling method is most robust to randomness notably loo cv yielded the most unsatisfactory performances in table 9 suggesting that loo cv which is asymptotically equivalent to aic has limitations in the model selection of streamflow forecasting this is consistent with the results of taormina and chau 2015 who found that when applying the aic for elm lower penalties should be employed for the penalties of model complexity regarding the hampel test tc tables 9 and 10 suggest that the hampel test tc was superior to the resampling tc although this result is contradicted by some resampling methods the data for station 07083000 in table 12 confirm that with 5 fold resampling the model using the hampel test tc outperformed the model using the 5 fold tc moreover notably the features selected by the hampel test tc may be a subset of the candidate feature sets of the resampling tc when conducting the incremental forwarding selection strategy this implies that the selected models in table 10 which employed the hampel test tc had a smaller computational cost than the selected models in table 9 this important point also means that if the candidate regression models using features selected by the hampel test tc have the same or a lower rmse than the models using the features selected by the resampling tc in the training set they should be considered as the best models in table 9 however this assumption was not valid for our cases moreover under normal conditions the selected models would have performed better than the unselected models in the testing set however the performances of the models selected by 5 fold resampling at station 0708300 in table 12 are contradictory to the normal conditions therefore it is speculated that under these circumstances there was overfitting in the models with the resampling tc overall all of the above signs lead us to prefer the hampel test tc this result confirms that the hampel test can be successfully used for ivs for water resource modeling as practiced by previous studies e g chen et al 2013 fernando et al 2009 may et al 2008 quilty et al 2016 although the above findings are interesting they should be validated in more watersheds which is the main limitation of this study besides the reliability of these findings might be affected by climate changes and human activities the reason is that all the data driven models in this study are based on the assumption that the underlying relations of the data in the future would be same as that in the past therefore researchers should be cautious when they use the findings of this study future work could also investigate more time scales such as the daily and weekly scales for streamflow forecasting examining ffs for other types of hydrological forecasting such as groundwater table forecasting would be very meaningful work in addition ensemble ffs which is practiced by quilty et al 2016 for urban water demand forecasting is a very promising method to explore 6 conclusion in this study we compared the performances of eight common ffs methods with two tc methods in one month ahead streamflow forecasting using mlr enelm and knn to our knowledge this is the first systematic study in this field after experimenting on three cases of the camels data set we summarized the primary conclusions of this study as follows 1 regardless of whether the hampel tc or resample tc was utilized among the eight ffs methods pci was the most applicable for mlr however for enelm or knn the best choice of ffs could not be preselected and should be analyzed in depth 2 when using the resampling method to choose a determined data driven model among the candidate combinations of ffs and regression methods according to the minimum rmse pci was the most promising ffs for both the selected linear and nonlinear regression models 3 the resampling method that was chosen had a great influence on the forecasting results compared with the resampling tc which could be impacted by the selected resampling method the hampel test tc had increased stability and produced improved forecasting results for one month ahead streamflow forecasting credit authorship contribution statement kun ren conceptualization methodology software writing original draft wei fang investigation writing review editing jihong qu visualization xia zhang investigation xiaoyu shi resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was financially supported by the doctoral research fund of north china university of water resources and electric power china 40464 the authors would also like to thank the anonymous reviewers and the editor for their comments which have substantially improved the quality of this paper 
5504,recently there has been an increased emphasis on employing data driven models to forecast streamflow however in these data driven models used for forecasting monthly streamflow the performances of filter based feature selection ffs methods have not been studied in detail in this study we investigated the effectiveness of eight common ffs methods namely linear pearson correlation partial linear pearson correlation pci mutual information mi conditional mi partial mi maximal relevance minimal redundancy pearson correlation maximal relevance minimal redundancy mi and gamma test methods on three regression models namely multiple linear regression mlr ensemble extreme learning machine enelm and k nearest neighbor knn regression for real world one month ahead streamflow forecasting the study was conducted on three cases from the catchment attributes and meteorology for large sample studies camels data sets furthermore two termination criterion tc methods the hampel test and resampling were comparatively analyzed the results of this study highlight three important findings first there was no dominant ffs method that coupled with enelm or knn second when resampling was applied to select a final model in the candidate combinations of the eight ffs methods and three regression models pci was the most favorable ffs method for the final model finally the hampel test tc was superior to the resampling tc in terms of stability and anti overfitting these findings have significant practical reference value for real world monthly streamflow forecasting keywords feature selection filter method termination criterion streamflow forecasting 1 introduction streamflow forecasting is a crucial part of water resource planning and management yaseen et al 2015 in recent decades there have been an increasing number of publications focusing on improving the accuracy of streamflow forecasting e g fahimi et al 2016 fang et al 2019 however streamflow changes have intricate patterns and are difficult to accurately forecast due to influences from the climate the geographical environment social development and human activities huang et al 2014 shoaib et al 2016 categorized the existing streamflow forecasting models into two main categories theory driven models and data driven models compared with theory driven models data driven models have attracted considerable interest in recent years because they do not involve physical mechanisms and can be accessibly applied liu et al 2014 researchers have developed various data driven models including classic time series e g mehdizadeh et al 2019 valipour 2015 and artificial intelligence based models e g fahimi et al 2016 tan et al 2018 tikhamarine et al 2020 yaseen et al 2015 2016 yu et al 2020 for streamflow forecasting the mechanism of data driven models for streamflow forecasting is the establishment of a mapping relationship between the influential factors historical rainfall historical river flow temperature evaporation etc and the forecasting targets through statistical learning therefore there are two essential factors for data driven models namely the mapping relationship and the selected influential factors i e the model inputs to establish an appropriate robust mapping relationship abundant regression models have been applied for streamflow forecasting e g tongal and booij 2018 yaseen et al 2017 these models include novel regression methods such as the combined continuous wavelet and multigene genetic programming method hadi and tombul 2018 the stepwise model empowered with genetic programming mahmood al juboori and guven 2016 a method based on the hidden markov model and gaussian mixture regression liu et al 2018 and the use of a wavelet based dynamic neural network shoaib et al 2016 in addition popular machine learning models and deep learning models such as support vector regression svr extreme learning machines elm and the long short term memory lstm neural network are frequently employed for streamflow forecasting e g kisi and cimen 2011 yaseen et al 2019 yuan et al 2018 regarding model inputs in addition to the most commonly used input influential factors of precipitation and streamflow e g kagoda et al 2010 li et al 2010 information such as evaporation temperature soil moisture relative humidity and climatic indices have been employed in data driven models and have proven to be beneficial for streamflow forecasting behzad et al 2009 makkeasorn et al 2008 noori et al 2011 rasouli et al 2012 sharma et al 2015 notably increased input variables for data driven models do not necessarily result in better performances guyon and elisseeff 2003 therefore when developing data driven models one should perform input variable selection ivs which is also known as feature selection galelli et al 2014 miao and niu 2016 as a generally accepted rule ivs algorithms can be classified into three categories filter wrapper and embedded methods jović et al 2015 may et al 2011 compared with wrapper based and embedded based feature selection methods the filter based feature selection ffs method has generated considerable recent research interest in hydrological data driven models as the ffs method is independent of a regression model and easy to compute quilty et al 2016 based on whether they consider the dependencies between the features the ffs methods can be divided into bivariate and multivariate methods jović et al 2015 the former uses specific evaluation criteria to evaluate the relation between the feature and the target regardless of other features while the latter considers not only the correlation between the feature and the target but also the correlations between the feature and other features for hydrological research fields multivariate ffs methods including partial mutual information pmi may et al 2008 conditional mutual information cmi quilty et al 2016 partial linear pearson correlation pci galelli et al 2014 gamma test noori et al 2011 sharifi et al 2017 and maximal relevance minimal redundancy mutual information mrmrmi methods peng et al 2005 have been frequently applied to drive more informative data driven models fang et al 2018 utilized pmi to select input variables from local meteorological and global climate data for reference evapotranspiration forecasting noori et al 2011 applied the gamma test to select the appropriate inputs for monthly streamflow forecasting sharifi et al 2017 used the gamma test forward selection and factor analysis to determine the best input combination for daily runoff prediction quilty et al 2016 proposed bootstrap cmi and compared bootstrap cmi with pci cmi and pmi for an urban water demand forecasting experiment in ottawa canada hejazi and cai 2009 presented a modified version of mrmrmi to select inputs for forecasting daily reservoir releases in addition to the above multivariate ffs methods bivariate ffs methods such as linear pearson correlation lc zou et al 2003 and mutual information mi vergara and estévez 2013 have been frequently employed to select input variables for hydrological forecast models li et al 2019 liu et al 2014 however it seems that there is no systemic study comparing different ffs methods for streamflow forecasting furthermore the termination criterion tc which could result in different selections has not been investigated for ffs for monthly streamflow forecasting regarding the tc for ffs may et al 2008 noted that among various tc methods including the bootstrap modified bootstrap tabulated critical value akaike information criterion aic and hampel test methods the aic and the hampel test should be widely applicable regarding this recommendation two points should be noted first the aic is a measure of trade off between the accuracy and complexity of a model therefore the calculation of aic depends on the type of regression model that is used for the linear regression model and ordinary shallow artificial neural network ann the measure of model complexity for the aic can be easily obtained by determining the number of model parameters but for other regression models such as nonparametric regression it is complicated or difficult to calculate complexity through the effective number of parameters or the vapnik chernovenkis dimension may et al 2011 2008 second determining an appropriate feature subset is a model selection problem stone 1977 proved that leave one out loo cross validation cv and the aic method are asymptotically equivalent therefore in addition to loo cv resampling methods for model selection such as k fold cv and bootstrapping hastie et al 2009 kuhn and johnson 2013 could be leveraged off for the tc of ffs which has not been attempted by previous studies of streamflow forecasting the objectives of this study are twofold first we examined the effectiveness of eight ffs methods namely lc pci mi cmi pmi maximal relevance minimal redundancy pearson correlation mrmrp tsanas et al 2013 mrmrmi and the gamma test on three regression models namely multiple linear regression mlr ensemble extreme learning machine enelm and k nearest neighbor knn regression for one month ahead streamflow forecasting second in addition to the hampel test tc resampling methods namely the loo k fold bootstrap and holdout methods were explored as the tc of ffs for one month ahead streamflow forecasting the remainder of this work is organized as follows in section 2 we present the study areas and data used section 3 describes the eight ffs methods two tc for ffs three regression methods four error evaluation criteria and the experimental setup used the experimental results are displayed in section 4 the discussion and conclusion are given in sections 5 and 6 respectively 2 study areas and data in this study three catchments fig 1 that are impacted by a relatively low level of human activities and have different hydroclimatic conditions were selected as the study areas table 1 lists the gauge name gauge id catchment area and climate characteristics of these basins these data were retrieved from the catchment attributes and meteorology for large sample studies camels data set which is a new data set of attributes for 671 catchments in the united states interested readers can obtain more detailed information about the study areas from this public database addor et al 2017 newman et al 2015 the period of the data set used in this study is from january 1980 to december 2014 the time series of the studied monthly streamflow and the corresponding autocorrelograms are shown in fig 2 all of the series show a strong annual periodicity candidate input variables including 12 lags in five types of local monthly meteorological information five global monthly climatic indices and monthly streamflow were used to forecast the monthly streamflow consequently the sample size was 408 and the number of candidate input variables was 132 to maintain a 7 3 ratio of the training set to the testing set the first 285 samples were used as the training set and the remaining 123 samples were used as the testing set for local meteorological information we obtained daily average precipitation mm d solar radiation w m2 minimum and maximum temperature c and vapor pressure pa from daymet thornton et al 2014 in camels and averaged these daily data at the monthly scale referring to rasouli et al 2012 we selected the niño 3 4 pacific north american pna arctic oscillation ao north atlantic oscillation nao and pacific decadal oscillation pdo data sets as candidate global climatic indices and these data sets were downloaded from the earth system research laboratory of the national oceanic and atmospheric administration https www esrl noaa gov psd data climateindices list monthly streamflow m3 s was acquired by averaging the daily streamflow m3 s retrieved from the r package dataretrieval in one month table 2 presents the commonly used descriptive statistical results for the studied streamflow time series the brock dechert scheinkman bds test broock et al 1996 a nonparametric method was used to investigate whether the studied streamflow series was nonlinear detailed information of the bds test for streamflow series is shown in maheswaran and khosa 2012 the results of the bds test for the three studied series are given in table 3 this table indicates that all statistical values of the bds test are significant therefore it can be inferred that all of the studied streamflow series had nonlinear features and the nonlinear data driven model should be suitable for the studied series maheswaran and khosa 2012 before training the data driven models using eq 1 all variables in the full data set were normalized into the range of 0 1 1 x i x i x imin x imax x imin where xi is the ith variable and ximin and ximax are the minimum and maximum values of the ith variable in the training set respectively after the training and forecasting processes had been conducted inverse transformations for eq 1 were performed for the forecasting values finally the error evaluation criteria in section 3 4 were calculated based on these back transformed normalized forecasting data the objective of data normalization is to eliminate the different scales among each data dimension which could increase the accuracy and speed of calculations hadi and tombul 2018 3 methods 3 1 eight filter based feature selection methods the ffs selects features based on the general characteristics of the data sánchez maroño et al 2007 generally ffs executes a statistical measure e g distance dependency consistency or information between the input variables and the target variables to allocate a score to each feature and then the features are ranked by that score by using tc such as the hampel test tc on ranked features one can decide whether the feature should be kept or removed from the candidate input set there have been numerous publications focusing on ffs because of its advantages such as its computational efficiency however ffs also has disadvantages for example the selected subset might not be globally optimal chandrashekar and sahin 2014 ffs can be divided into two categories bivariate ffs and multivariate ffs the former category which includes the lc method and the mi method does not consider the correlations among input variables while the latter category which includes pci and pmi takes these correlations into consideration to choose the representative ffs in this study we selected eight commonly used ffs methods for comparison for bivariate ffs we selected the lc method and the mi method which consider linear correlation and nonlinear correlation respectively for multivariate ffs we chose pci and mrmrp as the linear correlation cases pmi cmi mrmrmi and the gamma test were chosen as the nonlinear correlation cases the detailed calculation methods of these selected ffss are reported in the corresponding references in table 4 3 2 two typical termination criteria because different tc methods can generate various feature selection results selecting an appropriate tc method is important for ffs in the field of water resources diverse tc methods for ffs such as aic bayesian information criterion bic bootstrap tests modified bootstrap tests outlier detection methods and tabulated critical values galelli et al 2014 he et al 2011 may et al 2008 sharma and mehrotra 2014 have been utilized two tc methods have been recommended for ffs in these previous studies may et al 2008 compared eight tc methods for both pmi and pci and recommended the aic and hampel test due to their regardless of the data distribution quilty et al 2016 advocated the hampel test for ffs as it is a robust outlier detection method and is computationally efficient however as mentioned in section 1 the aic may be complicated or difficult to calculate when coupled with nonparametric regression therefore in this study we selected the hampel test and the loo cv which is asymptotically equivalent to the aic stone 1977 as the tc methods for ffs in addition several other representative resampling methods including the k fold cv bootstrap holdout and repeated k fold cv which are more efficient than the loo cv were explored as the tc of ffs in this study the hampel test tc can be calculated only using the values of the ranked features however the resampling tc requires a regression model and preset choice criteria such as the root mean square error rmse and the coefficient of determination r2 referring to lima et al 2015 we selected the rmse as the choice criterion in this study specifically in terms of the incremental forwarding strategy the ranked candidate features were added to the regression model in sequence the rmse which was computed on the out of sample by resampling in the training set was considered as the choice criterion in other words the data driven model that presented the minimum rmse was regarded as the best model and the corresponding input variables were considered to comprise the best input scenario for brevity details on the hampel test method can be obtained from may et al 2008 and kuhn and johnson 2013 describes the five selected resampling methods notably the resampling methods could be used not only to select variables but also to tune hyperparameters which are essentially used to make model selections 3 3 regression methods in this study we selected three regression methods mlr enelm and knn to compare the effects of the eight ffs methods we selected these three regression methods for two reasons first the enelm and knn are typical nonlinear regression methods for streamflow forecasting and the mlr is a typical linear regression method for streamflow forecasting second these three regression methods are computationally efficient and easy to program for applications 3 3 1 multiple linear regression mlr models the linear relationship between explanatory independent variables and response dependent variables andrews 1974 by fitting a linear equation 2 2 y α 0 α 1 x 1 α 2 x 2 α k x k where y is the response variable xt x 1 x 2 x k represents the explanatory variables αt α 0 α 1 α k denotes the regression coefficients and is the error term of the model also known as the residual in this study we utilized commonly used ordinary least squares method to estimate the coefficients αt in eq 2 3 3 2 ensemble extreme learning machine elm which were proposed by huang et al 2006 is a type of single hidden layer feedforward neural network slfn that is fast learning an slfn with l hidden layer nodes can be represented as eq 3 3 y j i 1 l β i g w i x j b i β 0 i 1 2 l j 1 2 n where n is the number of the cases l is the number of hidden layer nodes i denotes the ith hidden layer j is the jth case xj and y j represent the model input and output in the jth case respectively β i and β 0 denote the weight and bias respectively of the output w i and b i represent the input weight and bias respectively in the ith hidden layer and g is the activation function huang et al 2006 proved that if the activation function is infinitely differentiable through randomly assigned w i and b i values only the β parameters need to be optimized when minimizing the mean squared error between the model output and the target data in this way training an slfn can be transformed into solving a linear system as h β y then we can obtain β h y zhu et al 2005 4 h 1 g w 1 x 1 b 1 g w l x 1 b l 1 g w 1 x n b 1 g w l x n b l where h denotes the moore penrose generalized inverse of h eq 4 β is the parameter matrix eq 5 with the dimension l 1 m and y is the target matrix eq 6 with the dimension n m 5 β β 0 β 1 β l 6 y y 1 y 2 y n because of the random assignment of weights and bias parameters in the hidden layer the elm may produce different results when the algorithm is repeated on the same data set to overcome this problem and improve the predictive performance an ensemble elm is proposed nan and han 2010 zhai et al 2012 although there are various ensemble methods in this study we used the simplest method which averages the outputs of individual ensemble members lima et al 2015 3 3 3 k nearest neighbor regression knn regression is a nonparametric method that stores all available cases and forecasts the numerical target according to a similarity measure maltamo and kangas 1998 usually for regression three similarity measures namely the euclidean distance manhattan distance and minkowski distance are used after searching the knns the expected numerical target can be obtained by calculating the numerical target of the knns the simple average and inverse distance weighted average algorithms are frequently used in the calculations nigsch et al 2006 the knn regression method used in this study is described as follows 1 load the data and choose the number of neighbors k 2 for each observation calculate the euclidean distance between the queried observation and the current observation from the data record the calculated distance and the observation index 3 sort the observations in ascending order according to distance 4 pick the first k observations from all sorted observations return the inverse distance weighted average of the streamflow output of the selected k observations 3 4 error evaluation criteria to evaluate the performances of the models referring to the literature chai and draxler 2014 krause et al 2005 mccuen et al 2006 shi et al 2018 yaseen et al 2016 in this study we selected four criteria namely the nash sutcliffe efficiency nse rmse correlation coefficient r and mean absolute error mae the formulas of these evaluation criteria are shown as follows 7 nse 1 i 1 n q i q i 2 i 1 n q i q 2 8 rmse i 1 n q i q i 2 n 9 r i 1 n q i q q i q i 1 n q i q 2 i 1 n q i q 2 10 mae 1 n i 1 n q i q i where n q i q q i and q are the number of observations observed river flow average observed river flow forecasted river flow and average forecasted river flow respectively 3 5 experimental setup fig 3 shows the flow chart of the methodology applied in this study in our experiments we assigned the hyperparameters of the enelm before comparing the different fs methods specifically the numbers of elm and hidden layer neurons were set to 50 and 20 respectively the commonly used sigmoid function was regarded as the activation function therefore no other hyperparameters were tuned for the enelm and mlr in our experiments for the knn method we tuned k the number of nearest neighbors from 1 to 20 and the best k value was determined by minimizing the rmse in the out of sample of the training set the regression results for the knn model were obtained by weighting the selected knns according to the inverse distance with respect to the k fold and repeated k fold resampling methods we set the folds and the repeat times at 5 and 10 respectively regarding the bootstrap and holdout resampling methods the bootstrap value and holdout percentage were set to 30 and 30 respectively when conducting pmi and pci we utilized r scripts downloaded from https github com gbhumphrey1 pmis pcis for mi mrmrmi and cmi we programmed these entropy based methods in the matlab environment using nonparametric multivariate edgeworth expansion van hulle 2005 in the information theoretical estimators ite toolbox szabo 2014 the r package forecast was employed for the dm test section 4 6 and bds test section 2 other experiments were performed in the matlab environment for experimental consistency and repeatability we set the fixed random seed for the enelm model and the resampling method 4 results 4 1 linear pearson s correlation and nonlinear correlation mutual information between the streamflow and candidate input variables in the training set to evaluate the relation between the dependent variable and each of the independent variables we plotted the lc and mi between the streamflow and candidate input variables in the training set in figs 4 and 5 figs 4 and 5 show two obvious characteristics first for station 01013500 and station 07083000 the twelfth streamflow lag had the strongest correlation with streamflow in terms of both lc and mi while for station 11264500 the first streamflow lag had the strongest correlation second some candidate input variables such as the fourth lag of the nao had correlation values close to zero in terms of both lc and mi 4 2 impact of different filter based feature selection methods on the regression models when using the hampel test termination criterion to examine the impacts of the eight ffs hampel combinations ffs by the hampel test tc on particular regression models we determined the input variables selected by the eight methods table 5 illustrates the number of selected features and exhibited the performances of the mlr enelm and knn we tuned the best k of the knn by the 5 fold method in this subsection in the testing set using these input variables figs 6 8 the results in figs 6 8 show that pci hampel pci using the hampel test was the most suitable method for mlr in the testing set based on the nse rmse r and mae values which showed consistency in all study cases however for both enelm and knn there was no evidence showing that one ffs hampel method was superior to the others for all study cases based on not only the nse but also the rmse r and mae metrics in the testing set taking the nse metric as an example it is apparent in fig 6 that at station 01013500 the best ffs hampel combinations for the enelm and knn were cmi hampel and pci hampel respectively for station 07083000 the data in fig 7 indicate that the best ffs hampel combinations for the enelm and knn in terms of the nse were mrmrmi hampel and mrmrp hampel respectively regarding station 11264500 mrmrmi hampel was the most appropriate filter method for both enelm and knn based on the nse 4 3 impact of different filter based feature selection methods on the regression models when using the resampling termination criterion to analyze the impacts of the eight ffs methods by the resampling tc on particular regression models we listed the best ffs for the mlr enelm and knn in the training set using an incremental forwarding selection strategy by resampling and the corresponding forecast performance of the testing set in tables 6 8 additionally because diverse resampling methods could induce varied model selection results we also showed the outstanding models results under the five different resampling methods tables 6 8 show that when using mlr pci was preferable to the other ffs methods in the training set in all study cases regardless of which resampling method was employed nevertheless we could not determine the leading ffs method for enelm and knn for instance mrmrp was selected as the optimum ffs at station 07083000 when utilizing resampling with the bootstrap and knn methods however mrmrp was not the best choice for stations 01013500 and 11264500 in addition the use of different resampling methods in the same enelm or knn model at the same station resulted in different selected ffs methods taking station 11264500 as an example when practicing resampling with the 5 fold and bootstrap methods for the knn model the selected ffs methods were pci and pmi respectively 4 4 impact of different filter based feature selection methods on a determined regression model when using the resampling termination criterion to examine the selected regression models selected in the training set among mlr enelm and knn determined through different ffs with the resampling tc we listed the best selected ffs regression methods combination of eight ffs methods and three regression methods using resampling in the training set and the corresponding forecast performances in the testing set for the three study cases in table 9 a comparison of the results in table 9 highlights three interesting characteristics first regardless of the resampling methods adopted no one ffs regression model was always superior to the other models for the three cases for instance when conducting the resampling method with bootstrapping the pci mlr and pmi enelm models were chosen for station 01013500 and station 11264500 respectively second among the eight ffs methods pci was selected the most times for all study cases specifically for station 01013500 all five resampling methods chose pci as the most beneficial method of ffs while pci was selected three times at stations 07083000 and 11264500 notably when using resampling with the 5 fold method pci was the most favorable ffs method for all stations the last characteristic is related to the resampling method the performances of the models selected by the 5 fold and bootstrap methods were similar to each other the model selected by loo cv produced the most inferior performance at all stations and the models selected by the holdout and 10 repeat 5 fold methods showed the second worst performances at station 01013500 and station 11264500 respectively typically at station 11264500 the poorest rmse nse r and mae values were produced by pci mlr with 49 input variables selected through loo cv pci mlr with 48 input variables selected through the 10 repeat 5 fold method produced close to the poorest results pci mlr with 31 input variables and pmi enelm with 4 input variables which were developed by the 5 fold and bootstrap methods respectively had comparable predictive performances in terms of the rmse and nse values 4 5 impacts of different filter based feature selection methods on a determined regression model when using the hampel test termination criterion corresponding to table 9 table 10 shows the best selected ffs hampel regression regression models with ffs hampel methods using resampling in the training set and the forecasting performances of these models in the testing set for the three case studies the first notable characteristic of table 9 mentioned in subsection 4 4 still exists in table 10 for example when performing resampling with the 5 fold method pci hampel knn was selected for station 07083000 and pci hampel mlr was chosen for station 11264500 similarly the second notable characteristic of table 9 is also evident in table 10 at stations 01013500 and 11264500 pci was selected as the final ffs with all five resampling methods although pci was selected two times at station 07083000 pci hampel knn selected by the 5 fold method generated the same performance as mrmrmi hampel knn selected by the 10 repeat 5 fold method and exhibited the best model performance with regard to the characteristics of the resampling methods the data in table 10 show that model selection using the bootstrap and holdout methods may result in the most inferior performance and the best model performances were generated by model selection using the 5 fold or 10 repeat 5 fold methods 4 6 comparing models using the diebold mariano test tables 9 and 10 show that some models presented close performance values for instance in table 9 at station 07083000 pci enelm using the 5 fold method produced a nse of 0 795 in the testing set while pci knn using the holdout method yielded a nse of 0 810 in the testing set to verify whether the accuracies of these models had statistical significance in this study we utilized the diebold mariano test with absolute error loss dm ae to compare typical models qu et al 2017 first we investigated which resampling method should be employed in practice as indicated by the third characteristics in tables 9 and 10 resampling with the 5 fold method seemed to be the best option among all resampling methods to support this hypothesis if the models selected by the 5 fold method did not show the best performance we compared them with the best performance model selected by other resampling methods table 11 provides the results of these tests it is apparent that the dm ae values of the two compared pairs were higher than the upper limit at the 5 significance level this implies that the models compared in table 11 had different accuracies second we compared the difference between the selected ffs hampel regression using the 5 fold method corresponding to the results in table 10 and the selected ffs regression using the 5 fold method corresponding to the results in table 9 for the three study stations table 12 the data in table 12 indicate that at station 07083000 pci enelm with the 5 fold method and pci hampel knn with the 5 fold method had different accuracies while there was no significant difference between the models of pci mlr with the 5 fold method and pci hampel mlr with the 5 fold method at stations 01013500 and 11264500 5 discussion according to the above described results pci hampel is strongly recommended for one month ahead data driven models of streamflow forecasting in this study the correlation results in figs 4 and 5 suggest that the lags of streamflow provide the most informative guide for one month ahead streamflow forecasting in this study which means that the traditional univariate streamflow time series forecasting model may yield valid forecasting results in addition the figures highlight the need for some general candidate variables to be disregarded due to their near zero correlation values with regard to lc and mi with respect to the choice of a proper ffs method for a particular regression model in practice the results of subsections 4 2 and 4 3 suggest that in practice it is not possible to predict a common ffs for enelm and knn this finding means that when using enelm or knn in practical applications for one month ahead streamflow forecasting the choice of a specific ffs should be analyzed concretely however quilty et al 2016 suggested that the performance of cmi is always superior to that of pmi and pci for several synthetic data sets and real world daily urban water demand forecasts using enelm this inconsistency might be because the driving factors for the studied real world monthly streamflow series were more complex and diverse than those of the synthetic data sets and the real world daily urban water demand series studied by quilty et al 2016 notably no previous research was involved in this finding and we speculate that this situation might apply to other types of nonlinear regression for one month ahead streamflow forecasting in addition the evidence from tables 6 8 and figs 6 8 confirmed that pci was the best choice for the mlr this is in good agreement with previous studies interestingly when we employed the resampling methods to choose a data driven model from the combinations of eight ffs and three regression methods in subsections 4 4 and 4 5 pci was the most popular ffs to be selected in our study areas regardless of whether the selected regression model was linear or nonlinear although a few exceptions in tables 9 and 10 did not support this result it can be inferred that this inconsistency was due to the application of five different resampling methods notably may et al 2008 suggested that for their studied synthetic data sets pci performed relatively poorly in comparison to pmi when using the data produced by a nonlinear model and performed well when using the data produced by a linear model however for the studied real world streamflow series that had nonlinear features table 3 it seems that pci had a superior performance to pmi and other nonlinear ffss this might be the result of complex relations which have both linearity and nonlinearity with more linearity than nonlinearity among the driving factors and the real world monthly streamflow series therefore this study makes an important finding that the pci may be the most promising ffs among the eight studied ffss for real world monthly streamflow forecasting in addition as indicated by the data in tables 6 10 utilizing different resampling methods could cause the selection of dissimilar models these dissimilar models result in various forecasting results which creates a difficult problem with the selection of the resampling method in practice as previously described by a comprehensive analysis of the data in tables 9 and 10 the 5 fold method seems to be the best resampling method for our cases however evidence from table 11 does not agree with this conjecture this discrepancy between table 9 and table 10 might have occurred because the models in table 9 used the resampling tc while the models in table 10 used the hampel test tc thus the results in table 9 were more sensitive to the resampling method than those in table 10 additionally it must be emphasized that except for loo cv the resampling methods used in this study have randomness thus different random seeds or holdout percentages can produce different results therefore future research should be performed to determine which resampling method is most robust to randomness notably loo cv yielded the most unsatisfactory performances in table 9 suggesting that loo cv which is asymptotically equivalent to aic has limitations in the model selection of streamflow forecasting this is consistent with the results of taormina and chau 2015 who found that when applying the aic for elm lower penalties should be employed for the penalties of model complexity regarding the hampel test tc tables 9 and 10 suggest that the hampel test tc was superior to the resampling tc although this result is contradicted by some resampling methods the data for station 07083000 in table 12 confirm that with 5 fold resampling the model using the hampel test tc outperformed the model using the 5 fold tc moreover notably the features selected by the hampel test tc may be a subset of the candidate feature sets of the resampling tc when conducting the incremental forwarding selection strategy this implies that the selected models in table 10 which employed the hampel test tc had a smaller computational cost than the selected models in table 9 this important point also means that if the candidate regression models using features selected by the hampel test tc have the same or a lower rmse than the models using the features selected by the resampling tc in the training set they should be considered as the best models in table 9 however this assumption was not valid for our cases moreover under normal conditions the selected models would have performed better than the unselected models in the testing set however the performances of the models selected by 5 fold resampling at station 0708300 in table 12 are contradictory to the normal conditions therefore it is speculated that under these circumstances there was overfitting in the models with the resampling tc overall all of the above signs lead us to prefer the hampel test tc this result confirms that the hampel test can be successfully used for ivs for water resource modeling as practiced by previous studies e g chen et al 2013 fernando et al 2009 may et al 2008 quilty et al 2016 although the above findings are interesting they should be validated in more watersheds which is the main limitation of this study besides the reliability of these findings might be affected by climate changes and human activities the reason is that all the data driven models in this study are based on the assumption that the underlying relations of the data in the future would be same as that in the past therefore researchers should be cautious when they use the findings of this study future work could also investigate more time scales such as the daily and weekly scales for streamflow forecasting examining ffs for other types of hydrological forecasting such as groundwater table forecasting would be very meaningful work in addition ensemble ffs which is practiced by quilty et al 2016 for urban water demand forecasting is a very promising method to explore 6 conclusion in this study we compared the performances of eight common ffs methods with two tc methods in one month ahead streamflow forecasting using mlr enelm and knn to our knowledge this is the first systematic study in this field after experimenting on three cases of the camels data set we summarized the primary conclusions of this study as follows 1 regardless of whether the hampel tc or resample tc was utilized among the eight ffs methods pci was the most applicable for mlr however for enelm or knn the best choice of ffs could not be preselected and should be analyzed in depth 2 when using the resampling method to choose a determined data driven model among the candidate combinations of ffs and regression methods according to the minimum rmse pci was the most promising ffs for both the selected linear and nonlinear regression models 3 the resampling method that was chosen had a great influence on the forecasting results compared with the resampling tc which could be impacted by the selected resampling method the hampel test tc had increased stability and produced improved forecasting results for one month ahead streamflow forecasting credit authorship contribution statement kun ren conceptualization methodology software writing original draft wei fang investigation writing review editing jihong qu visualization xia zhang investigation xiaoyu shi resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was financially supported by the doctoral research fund of north china university of water resources and electric power china 40464 the authors would also like to thank the anonymous reviewers and the editor for their comments which have substantially improved the quality of this paper 
