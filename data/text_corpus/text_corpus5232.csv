index,text
26160,the current influx of climate related information required scientists to communicate their findings to decision makers in governments disaster preparedness organizations and the general public the soil and water assessment tool swat is a powerful modelling tool that allows scientists to simulate many of the physical processes involved in the water cycle this article presents the design methods and development efforts to overcome some of the limitations of the previously developed swat visualization software programs by creating a set of modular web applications that can be duplicated customized and run moreover this article features a web application development tool for climate data retrieval the nasaaccess fetches extracts and reformats climate data from the national aeronautics and space administration servers and outputs data compatible with hydrological models this work has the potential to increase the swat s model impact on non technically trained stakeholders and decision makers charged with water and climate management keywords tethys swat remote sensing climate water management nasa 1 introduction over the last several years the issue of climate change has come to the forefront of many political and economic issues multiple initiatives of the united nations such as the 2015 united nations climate change conference cop 21 paris agreement https unfccc int the sustainable development goals united nations 2016 and the sendai framework united nations office for disaster risk reduction 2015 are strongly linked to the sustainability of the environment and resilience and risk reduction from climatological disasters in addition to the overly politicized climate change crisis there are also natural disasters occurring on a very frequent basis these crises and disasters are generally unavoidable and have led many to question how these global changes e g deforestation global warming population growth and natural disasters will affect the livelihoods of humans around the world foley 2011 these climate issues have simultaneously emerged into global awareness with the growth of big data or more specifically the increase in the amount of climate data that is now available faghmous and kumar 2014 the emergence of better technologies to access analyze and share climate information can greatly improve the efforts of governments around the world and also people in disaster prone areas to prepare for and respond to changes in climate and the increasing frequencies of disasters earth observations both from space and ground when supplemented with climate models and statistical data assimilation methods have already proven to be powerful tools in forecasting future events analyzing past events and performing various scenario analyses to assist in disaster preparedness and future infrastructure planning efforts are being made within the fields of data science climatology hydrology and hydroinformatics to use these data to better understand water management and to ensure its fair use e g group on earth observations geo https www earthobservations org one commonly used tool for understanding climate and hydrologic information by decision makers is the soil and water assessment tool swat arnold et al 1998 the swat model has being used globally to model physical processes involved in the hydrologic cycle and has proven to be a valuable resource for supporting the decision making responsibilities of water managers muleta and nicklow 2005 through using the swat decision makers and stakeholders can better understand the impacts of both natural and human driven changes on the environment and then make more informed decisions arias et al 2011 one of the objectives of the relatively new field of hydroinformatics is to use information and communication technologies to store manage and analyze water data so that more people can understand the water cycle and its impact on the environment chen and han 2016 however even with new advances in data management techniques and the continuous generation of climate data and model simulations a very small amount these data are actually being used for decision support lehmann et al 2014 in a study done by overpeck et al 2011 the amount of climate data is projected to reach 350 petabytes 1 pb 1 000 tb by the year 2030 however according to selding 2012 only 3 5 of the currently available data is actually being used the findings of dahlhaus et al 2015 suggest that an even smaller amount of that climate data is reaching those that can use it to make decisions within the petabytes of data from earth observations and climate models there are patterns that can help us understand the past and predict future changes in the earth s climate assunção et al 2015 unfortunately the people responsible for making decisions based on the information from these climate data and models generally do not have the infrastructure the time or the technical expertise to sift through and analyze the raw data to make the informed decisions for which the data was produced in the first place dahlhaus et al 2015 for this reason the full potential of the swat model and other climate data sources has yet to be realized the complexity in obtaining and preparing the necessary data running the models and then interpreting the data has been a barrier for those lacking the technical training software licenses and computing resources jayakrishnan et al 2005 lehmann et al 2017 the work presented in this article represents an effort to lower technical barriers for the swat model through using open source web development web services and cloud storage technologies using the tethys platform swain 2015 swain et al 2016 as the web framework and the data and model outputs from the upgraded regional swat model for the lower mekong river basin in southeast asia mohammed et al 2018 an online swat data portal was developed in the form of two separate modular web applications the nasaaccess app mohammed 2019 and the swatonline data viewer while the swat model used here as a case study for the lower mekong river basin the developed application is completely open source and modular this means that the apps provided and presented in this work can be replicated customized and implemented anywhere ames et al 2016 croney et al 2007 for any watershed with the swat model output data 2 background 2 1 the soil and water assessment tool swat the soil and water assessment tool swat is a powerful modelling tool that allows scientists to simulate many of the physical processes involved in the water cycle arnold and fohrer 2005 arnold et al 2012 douglas mankin et al 2010 gassman et al 2007 each swat model simulation produces a large number of output files with a large amount of information each file represents the model outputs for one of the watershed subdivision units outlined above i e full watershed subbasins hrus and stream reaches these files are all written in ascii text format and contain either daily monthly or yearly time steps for a wide range of variables for each modeling unit subbasin hru or stream segment arnold et al 2012 among the many output files produced by swat the primary ones are output sub time series data for each subbasin output hru timeseries data for each hru output rch timeseries data for each stream reach for more information on the swat output files see the swat input output documentation at https swat tamu edu documentation 2012 io these swat output files can often be very large in size which leads to difficulty in extracting and visualizing data to handle these complex files there are a number of robust gis software systems that have been developed in the swat s relatively short history to assist users in preparing input data running the models and then visualizing the model outputs abbaspour et al 2015 babbar sebens et al 2015 baird and associates 2004 dile et al 2016 fant et al 2017 giuliani et al 2013 gorgan et al 2012 jayakrishnan et al 2005 rajib et al 2016 winchell et al 2010 yen et al 2016 yu 2018 zhang et al 2015 currently many of these software systems are time and knowledge intensive to use often are not interoperable with other software and sometimes rely on license restricted software programs like arcgis giuliani et al 2013 that must be updated periodically on the user s desktop computers desktop applications software plugins and standalone software programs that swat users can run from a local computer are currently the most commonly used among swat model developers desktop software will likely continue to play a key role in the swat model development and visualization for scientists and developers familiar with the swat model however there are limitations to how useful these tools can be for stakeholders without technical training in the swat model but for whom data and information from the swat models is a vital part of their decision process operating system compatibility licensing costs and software versioning issues can often inhibit users from having access to the newest or most robust technologies in addition the local nature of these technologies causes issues when sharing data across disciplines or organizations is required the technical expertise needed to create a custom swat model using these desktop applications requires those interested in the swat model to have the computational and storage resources locally to run the model and store all of the outputs this severely limits the potential for data sharing and collaboration between users unless they are all looking at the same computer screen in recent years there have been efforts to bring the swat model functionality to the web these efforts were due in part to the need for more collaboration and data sharing between the swat model developers and stakeholders table 1 is a representation of some of the key features for the most commonly used swat model related desktop programs and web services from a review of the most relevant software systems for the swat model modularity and data sharing emerge as two key features that when combined will help make the swat model to reach a new level of impact in the swat model users community the modularity i e think of the independent mobility of the apps on your smartphone of the desktop applications allows them to meet the unique needs of specific areas as there is not a one size fits all solution for all situations especially in hydrology since desktop applications fall short in their lack of data sharing capabilities and compatibility across operating systems on the other hand the open nature of the web technologies facilitates a much higher level of scientist stakeholder collaboration and data sharing than the technically exclusive desktop applications adding here that these web interfaces for the swat model are tied to servers hosting them which limit their potential global impact the development of new web applications introduced in this work that leverage data sharing capabilities of current web technologies and that can be duplicated installed and hosted anywhere the swat model s ability to meet the unique data and modeling needs of stakeholders in any region will improve significantly 2 2 nasaaccess one of the main obstacles in running the swat model lies in the difficulty of accessing the various input files required without access to in situ observed data from local organizations a user s options are often limited to having to use a global dataset like the global precipitation measurement gpm huffman et al 2018 and the global land data assimilation system gldas rodell et al 2004 datasets while these datasets are available for free their global nature requires for a substantial amount of pre processing before the data can be used in a model like swat rahman et al 2017 nasaaccess is a software tool built in r software program r development core team 2018 that streamlines the retrieval and processing of the global national aeronautics and space administration nasa earth observation data products i e gpm and gldas for use in hydrological models such as the swat mohammed 2019 mohammed et al 2018 the core functionality of the nasaaccess can be summarized as a access the nasa goddard space flight center gsfc servers to download earth observation data b clip needed grids to an input shapefile of a user study watershed c handle temporal and spatial inconsistencies d generate daily climate gridded data files and definition files compatible with the swat and other hydrological models the nasaaccess software package was built as an r library containing four separate data processing functions which are described in table 2 it is a very efficient system for accessing earth observation data however the number of potential users has been limited in part because of the relatively high learning curve involved in using the r language part of the work presented in this article involves an effort to make the nasaaccess software functionality available to a wider audience using a custom web interface developed through the tethys development framework swain 2015 swain et al 2016 2 3 the tethys platform a modular platform for visualizing and sharing swat input and output data the tethys platform swain 2015 swain et al 2016 was created to lower barriers of web application development for engineers and hydrologists so they could better share models and data the tethys combines many of the most commonly used technologies and scripting languages for database management data processing and web design into a relatively easy to use framework for developing web based applications and decision support tools the architecture used by tethys can be divided into three main components tethys sdk software development kit tethys portal and tethys software suite the combination of these three components in tethys provide developers with all the tools needed to create robust modular web based tools for processing and sharing data tethys web apps are developed using the python programming language and a software development kit sdk the sdk provides python module links to each software component of the tethys platform making the functionality of each component more accessible to novice programmers who have a working knowledge of python but not all of the underlying web technologies such as html javascript css postgis geoserver and others used by tethys and necessary to create a robust geospatial web application developers can use any of the python packages that they are accustomed to using in their scientific modeling to control the functionality of their web apps the second component tethys portal is where developed apps are published it acts as an app landing page for the users to access installed apps based on the django framework it includes tools and functionalities to customize features such as user permissions portal design security and content management the final component the tethys software suite contains tools and packages such as geoserver postgresql openlayers and more that are used commonly when developing geospatial web apps each of these tools has been built in to the overall functionality of tethys and accessible through python making it a very powerful tool not only for displaying data but also for any number of geoprocessing and database services a visual representation of the tethys platform software architecture can be reviewed at swain et al 2016 the complete documentation for the tethys platform is available at http docs tethysplatform org en stable index html 3 online swat data portal software organization the application structure for both the nasaaccess and the swatonline data viewer apps follows the model view controller mvc software architecture as shown in fig 1 and fig 2 this allows for simple readable and reusable code the web app model is responsible for initializing the database a postgresql database in this case and managing the database structure the controllers are scripts written in python that handle the logic and functionality of the web application and connect the data in the database and the server to the front end within these controller functions scientists are able to leverage the wealth of already developed python packages e g pandas gdal numpy along with their own customized scripts to control the data retrieval processing and analysis functions of an app the data is then passed from the controller to the views the views represent the html pages that are rendered for the users to see and include necessary web based gis mapping functionalities the data from the controllers is passed in the form of context variables meaning variables that are created every time the app is initiated thus ensuring that the data is dynamic the tethys app folder structure was designed for easy duplication and deployment in the app package each file plays a role in making the app work as illustrated in the file structure diagrams shown in fig 3 and fig 4 the controllers py file contains all of the code directly related to the initial view of the app it also manages all of the user actions within the app in other words it takes user inputs from the app interface passes them into the various data processing python functions and then renders or updates the app interface based on the output data of the functions called the templates directory contains the html pages that are rendered to the front end the public directory contains resources that are responsible for rendering the html content such as javascript cascading style sheets css and images the public directory also contains any external libraries the original django app structure has several moving parts within the mvc architecture and thus is not straightforward for novice developers the tethys project app structure has all the mvc components within the app directory making it easier for first time web developers to leverage the mvc structure and focus on their own code in python through the controllers py file 4 the swatonline design and key capabilities in this section the key functionalities of the nasaaccess and the swatonline data viewer apps will be introduced data and model outputs from the upgraded regional swat model for the lower mekong river basin mohammed et al 2018 will be used for illustration purposes the nasaaccess web app is simply a user interface for accessing the nasaaccess software mohammed 2019 which acts as a data portal for those interested in accessing climate data from nasa with limited time or technical background the swatonline data viewer is a fully customizable interface for visualizing processing and downloading the swat model outputs fig 5 developers are encouraged to visit the related nasaaccess and swatonline web apps source code and documentation available at https github com byu hydroinformatics swatonline git in summary the nasaaccess and swatonline web apps can be used to simplify the swat input and output data querying visualization and sharing processes in addition to providing decision makers and water managers with simple data visualization tools to use while engaging with stakeholders 4 1 accessing swat climate inputs through the nasaaccess app the main purpose of the nasaaccess web application is to give users access to the nasaaccess data processing functions the sole purpose of which is to create swat model compatible climate input files within an easy to use interface thus the key functionality of the app resides in the four input elements in the left pane of the app as shown in fig 6 the user may select the watershed boundary digital elevation model and date range to be used as input arguments in the nasaaccess functions the user is also given the option to select one or multiple nasaaccess functions to run using those arguments the app uses these input elements to pass user requests as input arguments into the nasaaccess functions as shown in the flowchart in fig 7 4 2 the swat model output querying and time series visualization the swatonline application supports time series visualization of variables from the swat model rch and sub output files it also supports the geospatial visualization of the stream network the stream network visualization is done through geoserver map publishing framework and openlayers a javascript mapping library a watershed of interest is uploaded to geoserver using the geoserver rest api the published layer is then available as a wms endpoint the openlayers library can access the wms endpoint and displays it on an interactive map selecting a reach on the map will open a modal window with options to query different swat model output files as seen in fig 8 once the variable and time range are selected the resulting data is shown as a time series plot through the highcharts javascript plotting library 4 3 land use land cover and soil coverage layers statistics the land use land cover and soil layers coverage statistics are represented as pie charts within the swatonline platform when a reach is selected on the map the corresponding sub basin is highlighted the land use land cover and soil layers coverage maps are clipped to that subbasin boundary using gdal and coverage statistics are computed for the selected area the clipped rasters are published as a wms layer to the geoserver the wms layer is then displayed through openlayers for a visual representation of the land use land cover and soil coverage classification a pie chart of the classification is rendered through the highcharts library the chart can be queried for a breakdown of more distinct classification as seen in fig 9 and fig 10 data used in the land use land cover and soil layers examples are obtained from the swat model described by mohammed et al 2018 4 4 data storage and upload the applications presented in this work rely on three types of data 1 the swat model watershed shapefiles 2 the swat model output files and 3 the swat model land use land cover and soil input files these data are stored in a combination of three different storage technologies 1 a geoserver for geospatial datasets 2 a postgresql database and 3 local storage on the server hosting the apps included in the app package is a python script called upload new model py that will take each of the files described earlier and upload or save them to their correct location within the storage architecture of the app fig 11 and fig 12 are comprehensive flow charts of the data upload storage and visualization methods used by the applications the swat watershed files include geospatial files such as stream network subbasin and gage station shapefiles these files are published as wms layers to the geoserver once published they are accessible as wms services the connectivity information i e downstream ids for the stream and subbasin networks is uploaded to a table in the postgresql database using the psycopg2 python package the swat model output files are also uploaded to the postgresql database the swatonline application has its own database to store the output files each output file is stored in a database table specifically created for that file each record in the table for the output files holds the following information 1 watershed id 2 year month day 3 reach id 4 variable name and 5 value the tables are then indexed for improving the efficiency for querying the time series the land use land cover and soil files and their metadata are stored in multiple forms for the swatonline app to process initially the files are published to the geoserver for display in the app s map view as wms services the lookup tables used to translate the raster pixel values to land use land cover and soil classification names are uploaded to a table in the postgresql database so that the app can quickly identify and display coverage information the original land use land cover and soil files are also stored locally on the hosting server to be used in the clipping and raster calculations when requested by a user 4 5 data download while the swatonline apps presented allow for basic data visualization and sharing for a wide range of users they are limited in in depth data analysis functionality for this reason the apps both facilitate data downloading for users who are interested so that further data analysis can be performed the swatonline data viewer app features a data cart capability that functions very similar to an online shopping cart the user can perform any number of data queries from the watershed the swat model output and land use land cover or soil data that the app provides add the data to their cart and then download a zip file containing all of that data to use for advanced data analysis or further modeling processes the data query and download process is shown in fig 13 4 6 the swatonline app modularity and customization the upload new model py script included in the swatonline app package will work for any new swat model and will automatically update the app features based on available data for the given model i e the land use land cover data visualization and data processing features will be disabled if a land use land cover raster file wasn t uploaded with the model the modularity and customizability of the swatonline data viewer is helpful and essential when analysis for different regions or different countries is thought by stakeholders or individuals as demonstrated by the lower mekong river basin multi countries swat model example mohammed et al 2018 5 discussion and conclusions the information that the swat hydrological model uses and simulates has the potential to have a significant impact on the future decisions of water and climate scientists policy makers and communities around the world lehmann et al 2014 2017 however the swat model s impact has been limited because of the complicated nature of the various model outputs while the technical barrier for creating and running the swat hydrological model will likely never be eliminated completely improving the way the model inputs and outputs are visualized and shared can increase the swat model impact substantially for scientists and the swat model developers accessing inputs for the swat model can pose a challenge the global precipitation measurement gpm mission and global land data assimilation system gldas data products produced regularly by nasa on a global scale contain valuable information on the current state of the world s climate and can be used as inputs for any swat model setup however the use of these earth observation datasets available for free from the nasa earth data website https earthdata nasa gov has been limited due to the high technical requirements for accessing processing and understanding it the work done by mohammed 2019 to develop the nasaaccess workflow was an important step in opening these datasets up to those that could benefit from them however similar to the limitations of the datasets themselves the nasaaccess software package has been limited in use because it is available only within the r software environment the nasaaccess web application was developed to lower the technical barrier that was keeping interested parties from accessing the powerful capabilities of the nasaaccess package and ultimately the information available in the gpm and gldas datasets the nasaaccess web interface frees users from needing any technical background in r or earth observation data processing yet still allows them to process large amounts of data into small more manageable data files the nasaaccess app produces data that is then ready to be used in a wide range of climatological and hydrological uses including hydrologic modeling programs like the swat climate modeling statistical analysis and data visualization for decision support for decision makers and stakeholders in an area where the hydrologic process plays a key part in environmental and economic sustainability the swat model can provide crucial information to future planning and analysis of past events however due to high technical requirements in using the swat model its impact on stakeholders and decision makers has been severely limited the swatonline data viewer was designed to overcome the limitations of existing desktop and web technologies for the swat model visualization instead of being tied down with software licensing and versioning issues inherent in the current desktop applications the swatonline data viewer is completely open source and was built to be resilient to changes in swat software it is also completely modular unlike other swat related web interfaces which means that the app can be duplicated installed and run from any machine private or public local or shared with a tethys platform installed making it adaptable to any specific user needs while the applications presented in this work are limited to some extent in their functionality when compared to the currently available programs and services for the swat model the customizability modularity and easy to use interfaces of these two apps have the potential to simplify the swat model data analysis and visualization for those lacking technical training in the swat model development with all the new technical developments in the fields of hydrology earth observations and software and web development complicated science continues to become more accessible to a wider group of people the swatonline data viewer and the nasaaccess applications have the potential to meet the goal of full stakeholder adoption the apps have significantly simplified the process of accessing the climate inputs and model outputs for the swat model they can be implemented anywhere by any interested organization or individual and can be used for any swat model for any watershed this potential for stakeholder adoption can be realized through an increased effort to inform stakeholders of the current developments train them in using the apps and then to involve them in future developments software availability all swatonline and nasaaccess related source code and documentation is available online at https github com byu hydroinformatics swatonline git acknowledgements the work was completed in collaboration with experts at the asian disaster preparedness center adpc the national aeronautics and space administration nasa goddard space flight center gsfc and the servir science coordination office at nasa marshall space flight center msfc we are indebted to the valuable discussions and comments from gsfc msfc and adpc staff members this work was funded by the nasa applied sciences grant nnx16at88g and grant nnx16at86g appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 104499 
26160,the current influx of climate related information required scientists to communicate their findings to decision makers in governments disaster preparedness organizations and the general public the soil and water assessment tool swat is a powerful modelling tool that allows scientists to simulate many of the physical processes involved in the water cycle this article presents the design methods and development efforts to overcome some of the limitations of the previously developed swat visualization software programs by creating a set of modular web applications that can be duplicated customized and run moreover this article features a web application development tool for climate data retrieval the nasaaccess fetches extracts and reformats climate data from the national aeronautics and space administration servers and outputs data compatible with hydrological models this work has the potential to increase the swat s model impact on non technically trained stakeholders and decision makers charged with water and climate management keywords tethys swat remote sensing climate water management nasa 1 introduction over the last several years the issue of climate change has come to the forefront of many political and economic issues multiple initiatives of the united nations such as the 2015 united nations climate change conference cop 21 paris agreement https unfccc int the sustainable development goals united nations 2016 and the sendai framework united nations office for disaster risk reduction 2015 are strongly linked to the sustainability of the environment and resilience and risk reduction from climatological disasters in addition to the overly politicized climate change crisis there are also natural disasters occurring on a very frequent basis these crises and disasters are generally unavoidable and have led many to question how these global changes e g deforestation global warming population growth and natural disasters will affect the livelihoods of humans around the world foley 2011 these climate issues have simultaneously emerged into global awareness with the growth of big data or more specifically the increase in the amount of climate data that is now available faghmous and kumar 2014 the emergence of better technologies to access analyze and share climate information can greatly improve the efforts of governments around the world and also people in disaster prone areas to prepare for and respond to changes in climate and the increasing frequencies of disasters earth observations both from space and ground when supplemented with climate models and statistical data assimilation methods have already proven to be powerful tools in forecasting future events analyzing past events and performing various scenario analyses to assist in disaster preparedness and future infrastructure planning efforts are being made within the fields of data science climatology hydrology and hydroinformatics to use these data to better understand water management and to ensure its fair use e g group on earth observations geo https www earthobservations org one commonly used tool for understanding climate and hydrologic information by decision makers is the soil and water assessment tool swat arnold et al 1998 the swat model has being used globally to model physical processes involved in the hydrologic cycle and has proven to be a valuable resource for supporting the decision making responsibilities of water managers muleta and nicklow 2005 through using the swat decision makers and stakeholders can better understand the impacts of both natural and human driven changes on the environment and then make more informed decisions arias et al 2011 one of the objectives of the relatively new field of hydroinformatics is to use information and communication technologies to store manage and analyze water data so that more people can understand the water cycle and its impact on the environment chen and han 2016 however even with new advances in data management techniques and the continuous generation of climate data and model simulations a very small amount these data are actually being used for decision support lehmann et al 2014 in a study done by overpeck et al 2011 the amount of climate data is projected to reach 350 petabytes 1 pb 1 000 tb by the year 2030 however according to selding 2012 only 3 5 of the currently available data is actually being used the findings of dahlhaus et al 2015 suggest that an even smaller amount of that climate data is reaching those that can use it to make decisions within the petabytes of data from earth observations and climate models there are patterns that can help us understand the past and predict future changes in the earth s climate assunção et al 2015 unfortunately the people responsible for making decisions based on the information from these climate data and models generally do not have the infrastructure the time or the technical expertise to sift through and analyze the raw data to make the informed decisions for which the data was produced in the first place dahlhaus et al 2015 for this reason the full potential of the swat model and other climate data sources has yet to be realized the complexity in obtaining and preparing the necessary data running the models and then interpreting the data has been a barrier for those lacking the technical training software licenses and computing resources jayakrishnan et al 2005 lehmann et al 2017 the work presented in this article represents an effort to lower technical barriers for the swat model through using open source web development web services and cloud storage technologies using the tethys platform swain 2015 swain et al 2016 as the web framework and the data and model outputs from the upgraded regional swat model for the lower mekong river basin in southeast asia mohammed et al 2018 an online swat data portal was developed in the form of two separate modular web applications the nasaaccess app mohammed 2019 and the swatonline data viewer while the swat model used here as a case study for the lower mekong river basin the developed application is completely open source and modular this means that the apps provided and presented in this work can be replicated customized and implemented anywhere ames et al 2016 croney et al 2007 for any watershed with the swat model output data 2 background 2 1 the soil and water assessment tool swat the soil and water assessment tool swat is a powerful modelling tool that allows scientists to simulate many of the physical processes involved in the water cycle arnold and fohrer 2005 arnold et al 2012 douglas mankin et al 2010 gassman et al 2007 each swat model simulation produces a large number of output files with a large amount of information each file represents the model outputs for one of the watershed subdivision units outlined above i e full watershed subbasins hrus and stream reaches these files are all written in ascii text format and contain either daily monthly or yearly time steps for a wide range of variables for each modeling unit subbasin hru or stream segment arnold et al 2012 among the many output files produced by swat the primary ones are output sub time series data for each subbasin output hru timeseries data for each hru output rch timeseries data for each stream reach for more information on the swat output files see the swat input output documentation at https swat tamu edu documentation 2012 io these swat output files can often be very large in size which leads to difficulty in extracting and visualizing data to handle these complex files there are a number of robust gis software systems that have been developed in the swat s relatively short history to assist users in preparing input data running the models and then visualizing the model outputs abbaspour et al 2015 babbar sebens et al 2015 baird and associates 2004 dile et al 2016 fant et al 2017 giuliani et al 2013 gorgan et al 2012 jayakrishnan et al 2005 rajib et al 2016 winchell et al 2010 yen et al 2016 yu 2018 zhang et al 2015 currently many of these software systems are time and knowledge intensive to use often are not interoperable with other software and sometimes rely on license restricted software programs like arcgis giuliani et al 2013 that must be updated periodically on the user s desktop computers desktop applications software plugins and standalone software programs that swat users can run from a local computer are currently the most commonly used among swat model developers desktop software will likely continue to play a key role in the swat model development and visualization for scientists and developers familiar with the swat model however there are limitations to how useful these tools can be for stakeholders without technical training in the swat model but for whom data and information from the swat models is a vital part of their decision process operating system compatibility licensing costs and software versioning issues can often inhibit users from having access to the newest or most robust technologies in addition the local nature of these technologies causes issues when sharing data across disciplines or organizations is required the technical expertise needed to create a custom swat model using these desktop applications requires those interested in the swat model to have the computational and storage resources locally to run the model and store all of the outputs this severely limits the potential for data sharing and collaboration between users unless they are all looking at the same computer screen in recent years there have been efforts to bring the swat model functionality to the web these efforts were due in part to the need for more collaboration and data sharing between the swat model developers and stakeholders table 1 is a representation of some of the key features for the most commonly used swat model related desktop programs and web services from a review of the most relevant software systems for the swat model modularity and data sharing emerge as two key features that when combined will help make the swat model to reach a new level of impact in the swat model users community the modularity i e think of the independent mobility of the apps on your smartphone of the desktop applications allows them to meet the unique needs of specific areas as there is not a one size fits all solution for all situations especially in hydrology since desktop applications fall short in their lack of data sharing capabilities and compatibility across operating systems on the other hand the open nature of the web technologies facilitates a much higher level of scientist stakeholder collaboration and data sharing than the technically exclusive desktop applications adding here that these web interfaces for the swat model are tied to servers hosting them which limit their potential global impact the development of new web applications introduced in this work that leverage data sharing capabilities of current web technologies and that can be duplicated installed and hosted anywhere the swat model s ability to meet the unique data and modeling needs of stakeholders in any region will improve significantly 2 2 nasaaccess one of the main obstacles in running the swat model lies in the difficulty of accessing the various input files required without access to in situ observed data from local organizations a user s options are often limited to having to use a global dataset like the global precipitation measurement gpm huffman et al 2018 and the global land data assimilation system gldas rodell et al 2004 datasets while these datasets are available for free their global nature requires for a substantial amount of pre processing before the data can be used in a model like swat rahman et al 2017 nasaaccess is a software tool built in r software program r development core team 2018 that streamlines the retrieval and processing of the global national aeronautics and space administration nasa earth observation data products i e gpm and gldas for use in hydrological models such as the swat mohammed 2019 mohammed et al 2018 the core functionality of the nasaaccess can be summarized as a access the nasa goddard space flight center gsfc servers to download earth observation data b clip needed grids to an input shapefile of a user study watershed c handle temporal and spatial inconsistencies d generate daily climate gridded data files and definition files compatible with the swat and other hydrological models the nasaaccess software package was built as an r library containing four separate data processing functions which are described in table 2 it is a very efficient system for accessing earth observation data however the number of potential users has been limited in part because of the relatively high learning curve involved in using the r language part of the work presented in this article involves an effort to make the nasaaccess software functionality available to a wider audience using a custom web interface developed through the tethys development framework swain 2015 swain et al 2016 2 3 the tethys platform a modular platform for visualizing and sharing swat input and output data the tethys platform swain 2015 swain et al 2016 was created to lower barriers of web application development for engineers and hydrologists so they could better share models and data the tethys combines many of the most commonly used technologies and scripting languages for database management data processing and web design into a relatively easy to use framework for developing web based applications and decision support tools the architecture used by tethys can be divided into three main components tethys sdk software development kit tethys portal and tethys software suite the combination of these three components in tethys provide developers with all the tools needed to create robust modular web based tools for processing and sharing data tethys web apps are developed using the python programming language and a software development kit sdk the sdk provides python module links to each software component of the tethys platform making the functionality of each component more accessible to novice programmers who have a working knowledge of python but not all of the underlying web technologies such as html javascript css postgis geoserver and others used by tethys and necessary to create a robust geospatial web application developers can use any of the python packages that they are accustomed to using in their scientific modeling to control the functionality of their web apps the second component tethys portal is where developed apps are published it acts as an app landing page for the users to access installed apps based on the django framework it includes tools and functionalities to customize features such as user permissions portal design security and content management the final component the tethys software suite contains tools and packages such as geoserver postgresql openlayers and more that are used commonly when developing geospatial web apps each of these tools has been built in to the overall functionality of tethys and accessible through python making it a very powerful tool not only for displaying data but also for any number of geoprocessing and database services a visual representation of the tethys platform software architecture can be reviewed at swain et al 2016 the complete documentation for the tethys platform is available at http docs tethysplatform org en stable index html 3 online swat data portal software organization the application structure for both the nasaaccess and the swatonline data viewer apps follows the model view controller mvc software architecture as shown in fig 1 and fig 2 this allows for simple readable and reusable code the web app model is responsible for initializing the database a postgresql database in this case and managing the database structure the controllers are scripts written in python that handle the logic and functionality of the web application and connect the data in the database and the server to the front end within these controller functions scientists are able to leverage the wealth of already developed python packages e g pandas gdal numpy along with their own customized scripts to control the data retrieval processing and analysis functions of an app the data is then passed from the controller to the views the views represent the html pages that are rendered for the users to see and include necessary web based gis mapping functionalities the data from the controllers is passed in the form of context variables meaning variables that are created every time the app is initiated thus ensuring that the data is dynamic the tethys app folder structure was designed for easy duplication and deployment in the app package each file plays a role in making the app work as illustrated in the file structure diagrams shown in fig 3 and fig 4 the controllers py file contains all of the code directly related to the initial view of the app it also manages all of the user actions within the app in other words it takes user inputs from the app interface passes them into the various data processing python functions and then renders or updates the app interface based on the output data of the functions called the templates directory contains the html pages that are rendered to the front end the public directory contains resources that are responsible for rendering the html content such as javascript cascading style sheets css and images the public directory also contains any external libraries the original django app structure has several moving parts within the mvc architecture and thus is not straightforward for novice developers the tethys project app structure has all the mvc components within the app directory making it easier for first time web developers to leverage the mvc structure and focus on their own code in python through the controllers py file 4 the swatonline design and key capabilities in this section the key functionalities of the nasaaccess and the swatonline data viewer apps will be introduced data and model outputs from the upgraded regional swat model for the lower mekong river basin mohammed et al 2018 will be used for illustration purposes the nasaaccess web app is simply a user interface for accessing the nasaaccess software mohammed 2019 which acts as a data portal for those interested in accessing climate data from nasa with limited time or technical background the swatonline data viewer is a fully customizable interface for visualizing processing and downloading the swat model outputs fig 5 developers are encouraged to visit the related nasaaccess and swatonline web apps source code and documentation available at https github com byu hydroinformatics swatonline git in summary the nasaaccess and swatonline web apps can be used to simplify the swat input and output data querying visualization and sharing processes in addition to providing decision makers and water managers with simple data visualization tools to use while engaging with stakeholders 4 1 accessing swat climate inputs through the nasaaccess app the main purpose of the nasaaccess web application is to give users access to the nasaaccess data processing functions the sole purpose of which is to create swat model compatible climate input files within an easy to use interface thus the key functionality of the app resides in the four input elements in the left pane of the app as shown in fig 6 the user may select the watershed boundary digital elevation model and date range to be used as input arguments in the nasaaccess functions the user is also given the option to select one or multiple nasaaccess functions to run using those arguments the app uses these input elements to pass user requests as input arguments into the nasaaccess functions as shown in the flowchart in fig 7 4 2 the swat model output querying and time series visualization the swatonline application supports time series visualization of variables from the swat model rch and sub output files it also supports the geospatial visualization of the stream network the stream network visualization is done through geoserver map publishing framework and openlayers a javascript mapping library a watershed of interest is uploaded to geoserver using the geoserver rest api the published layer is then available as a wms endpoint the openlayers library can access the wms endpoint and displays it on an interactive map selecting a reach on the map will open a modal window with options to query different swat model output files as seen in fig 8 once the variable and time range are selected the resulting data is shown as a time series plot through the highcharts javascript plotting library 4 3 land use land cover and soil coverage layers statistics the land use land cover and soil layers coverage statistics are represented as pie charts within the swatonline platform when a reach is selected on the map the corresponding sub basin is highlighted the land use land cover and soil layers coverage maps are clipped to that subbasin boundary using gdal and coverage statistics are computed for the selected area the clipped rasters are published as a wms layer to the geoserver the wms layer is then displayed through openlayers for a visual representation of the land use land cover and soil coverage classification a pie chart of the classification is rendered through the highcharts library the chart can be queried for a breakdown of more distinct classification as seen in fig 9 and fig 10 data used in the land use land cover and soil layers examples are obtained from the swat model described by mohammed et al 2018 4 4 data storage and upload the applications presented in this work rely on three types of data 1 the swat model watershed shapefiles 2 the swat model output files and 3 the swat model land use land cover and soil input files these data are stored in a combination of three different storage technologies 1 a geoserver for geospatial datasets 2 a postgresql database and 3 local storage on the server hosting the apps included in the app package is a python script called upload new model py that will take each of the files described earlier and upload or save them to their correct location within the storage architecture of the app fig 11 and fig 12 are comprehensive flow charts of the data upload storage and visualization methods used by the applications the swat watershed files include geospatial files such as stream network subbasin and gage station shapefiles these files are published as wms layers to the geoserver once published they are accessible as wms services the connectivity information i e downstream ids for the stream and subbasin networks is uploaded to a table in the postgresql database using the psycopg2 python package the swat model output files are also uploaded to the postgresql database the swatonline application has its own database to store the output files each output file is stored in a database table specifically created for that file each record in the table for the output files holds the following information 1 watershed id 2 year month day 3 reach id 4 variable name and 5 value the tables are then indexed for improving the efficiency for querying the time series the land use land cover and soil files and their metadata are stored in multiple forms for the swatonline app to process initially the files are published to the geoserver for display in the app s map view as wms services the lookup tables used to translate the raster pixel values to land use land cover and soil classification names are uploaded to a table in the postgresql database so that the app can quickly identify and display coverage information the original land use land cover and soil files are also stored locally on the hosting server to be used in the clipping and raster calculations when requested by a user 4 5 data download while the swatonline apps presented allow for basic data visualization and sharing for a wide range of users they are limited in in depth data analysis functionality for this reason the apps both facilitate data downloading for users who are interested so that further data analysis can be performed the swatonline data viewer app features a data cart capability that functions very similar to an online shopping cart the user can perform any number of data queries from the watershed the swat model output and land use land cover or soil data that the app provides add the data to their cart and then download a zip file containing all of that data to use for advanced data analysis or further modeling processes the data query and download process is shown in fig 13 4 6 the swatonline app modularity and customization the upload new model py script included in the swatonline app package will work for any new swat model and will automatically update the app features based on available data for the given model i e the land use land cover data visualization and data processing features will be disabled if a land use land cover raster file wasn t uploaded with the model the modularity and customizability of the swatonline data viewer is helpful and essential when analysis for different regions or different countries is thought by stakeholders or individuals as demonstrated by the lower mekong river basin multi countries swat model example mohammed et al 2018 5 discussion and conclusions the information that the swat hydrological model uses and simulates has the potential to have a significant impact on the future decisions of water and climate scientists policy makers and communities around the world lehmann et al 2014 2017 however the swat model s impact has been limited because of the complicated nature of the various model outputs while the technical barrier for creating and running the swat hydrological model will likely never be eliminated completely improving the way the model inputs and outputs are visualized and shared can increase the swat model impact substantially for scientists and the swat model developers accessing inputs for the swat model can pose a challenge the global precipitation measurement gpm mission and global land data assimilation system gldas data products produced regularly by nasa on a global scale contain valuable information on the current state of the world s climate and can be used as inputs for any swat model setup however the use of these earth observation datasets available for free from the nasa earth data website https earthdata nasa gov has been limited due to the high technical requirements for accessing processing and understanding it the work done by mohammed 2019 to develop the nasaaccess workflow was an important step in opening these datasets up to those that could benefit from them however similar to the limitations of the datasets themselves the nasaaccess software package has been limited in use because it is available only within the r software environment the nasaaccess web application was developed to lower the technical barrier that was keeping interested parties from accessing the powerful capabilities of the nasaaccess package and ultimately the information available in the gpm and gldas datasets the nasaaccess web interface frees users from needing any technical background in r or earth observation data processing yet still allows them to process large amounts of data into small more manageable data files the nasaaccess app produces data that is then ready to be used in a wide range of climatological and hydrological uses including hydrologic modeling programs like the swat climate modeling statistical analysis and data visualization for decision support for decision makers and stakeholders in an area where the hydrologic process plays a key part in environmental and economic sustainability the swat model can provide crucial information to future planning and analysis of past events however due to high technical requirements in using the swat model its impact on stakeholders and decision makers has been severely limited the swatonline data viewer was designed to overcome the limitations of existing desktop and web technologies for the swat model visualization instead of being tied down with software licensing and versioning issues inherent in the current desktop applications the swatonline data viewer is completely open source and was built to be resilient to changes in swat software it is also completely modular unlike other swat related web interfaces which means that the app can be duplicated installed and run from any machine private or public local or shared with a tethys platform installed making it adaptable to any specific user needs while the applications presented in this work are limited to some extent in their functionality when compared to the currently available programs and services for the swat model the customizability modularity and easy to use interfaces of these two apps have the potential to simplify the swat model data analysis and visualization for those lacking technical training in the swat model development with all the new technical developments in the fields of hydrology earth observations and software and web development complicated science continues to become more accessible to a wider group of people the swatonline data viewer and the nasaaccess applications have the potential to meet the goal of full stakeholder adoption the apps have significantly simplified the process of accessing the climate inputs and model outputs for the swat model they can be implemented anywhere by any interested organization or individual and can be used for any swat model for any watershed this potential for stakeholder adoption can be realized through an increased effort to inform stakeholders of the current developments train them in using the apps and then to involve them in future developments software availability all swatonline and nasaaccess related source code and documentation is available online at https github com byu hydroinformatics swatonline git acknowledgements the work was completed in collaboration with experts at the asian disaster preparedness center adpc the national aeronautics and space administration nasa goddard space flight center gsfc and the servir science coordination office at nasa marshall space flight center msfc we are indebted to the valuable discussions and comments from gsfc msfc and adpc staff members this work was funded by the nasa applied sciences grant nnx16at88g and grant nnx16at86g appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 104499 
26161,in order to better manage complex situations of natural resource management models are built in a participative way involving the stakeholders of these situations in participatory modelling activities the impact that this activity of participatory modelling has on the stakeholders is at the heart of the companion modelling approach but this impact is hardly possible to evaluate on the field in this paper we propose a general framework to study in vitro the impact of participatory modelling on natural resources management we illustrate our framework by proposing an experimental setting that looks at participatory modelling in the context of water management we realized a pilot experiment and show that this experimental setting can be used to test in the laboratory the hypothesis that participatory modelling of a common pool resource situation has an impact on the way the resource is managed and increases the cooperative behaviour of stakeholders keywords companion modelling experimental economics agent based modelling role playing game integrated water resource management 1 introduction the first version of the charter of the companion modelling commod approach was published more than a decade ago barreteau 2003b it was then signed by numerous researchers from various disciplines related to natural resource management nrm the approach was adopted and developed in several case studies with various stakeholders and was used to tackle different problems étienne 2011 companion modelling is at the same time both an approach and an epistemic and deontological stance that a modeller may adopt when involving stakeholders in the production of a model that represents a nrm situation in which they are taking part it stems from the fact that involving the stakeholders of nrm situations when modelling the situation in which they find themselves may have an impact on that situation for instance if we bring fishermen into a room and ask them to explain their practices in order to build a model of fishery in the region it may have an impact on the way fishery will evolve in that region consequently from a rigorous scientific and civic perspective this impact must be considered when models of nrm situations are built two main cases can be distinguished depending on whether the objective of the model building is to study the nrm system for scientific purposes only or to explicitly use the modelling activity to improve a collective decision making process in the latter case the model is used as a medium by stakeholders to specify their points of view and issues the modelling activity is considered as the building up of a shared representation of the environment this shared representation the model can then be used to design concerted action plans it is difficult to assess the impact of modelling activity in natural resource situations in a falsifiable way sensu popper 1959 several proposals have been made for providing monitoring and evaluation protocols with a view to making comparisons and improving the design of participatory modelling devices and the implementation of commod approaches such protocols are often used and useful jones et al 2009 perez et al 2011 hassenforder et al 2016 and have been adopted in various cases however these evaluations focused on diagnosis assessing for action and were not dedicated to explaining how the modelling activity impacted the situation in this paper we propose an original approach to address this issue the aim was to design reproducible experiments so that the results of the experiments could be refuted or replicated by our peers we identified two main challenges the first challenge was that designing such an experimental setting meant handling concepts and objects used at various levels of abstraction the concepts from the modelling language used to build the model the model used during the commod process the model that we used in the experiment to represent the model used during the commod process etc we thus needed a robust conceptual framework in order to specify rigorously the hypotheses we wanted to test and see how they could be refuted or confirmed in order to take up this first challenge we used a generic framework for meta modelling called the minsky triad conceptual framework bonté et al 2012 which was developed to perform reflexive studies on modelling and simulation activities in general the second challenge was related to the fact that the outcomes of companion modelling approaches may be very difficult to measure being both context and time dependent in order to take up this second challenge we relied on experimental economics falk and heckman 2009 which addressed the issues of reproducibility context dependency etc here we transpose the conditions of a commod process into the laboratory by using the minsky triad conceptual framework and the principles of experimental economics to this end we developed a software device based on the netlogo platform and on the generic watershed modelling kit wat a game wag this device which we called anawag for analyse wat a game is available on the comses platform wag is a paper and pebbles participatory modelling kit that has been used in various water management situations in many countries for more than ten years abrami et al 2012 taking advantage of the experience accumulated with wag we designed the anawag device to be easily adapted to other similar research in order to test and illustrate the relevance of our approach we chose a specific case study in the field of integrated water resource management this case study was a specific project undertaken between 2005 and 2008 in the kat river valley in south africa farolfi et al 2010 the project implemented a commod approach for better management of water resources in a sub catchment hereafter following we refer to it as the kat river commod process in the next section we introduce the rationale of our approach in the third section we extensively describe our framework and illustrate it with our case study in the fourth and fifth sections we provide details of the implementation and results of a pilot experiment in the last section we discuss the limits and perspectives of the approach 2 rationale 2 1 experimentation in the social sciences experimentation is a growing practice in many social sciences several disciplines from psychology boring 1950 to sociology and more recently from social psychology moreno 1954 to political science druckman et al 2011 have introduced controlled experimentation in the laboratory to test hypotheses about the observed behaviour of human agents experimental methods in economics became popular around the end of the 20th century according to levitt and list 2007 economists have increasingly turned to the experimental modelling of the physical sciences as a way of understanding human behaviour peer reviewed articles using the methodology of experimental economics were almost non existent up to the mid 1960s they exceeded 50 per year for the first time in 1982 and by 1998 the number of experimental economics papers published per year topped 200 holt 2006 in experimental economics laboratory experiments enable the investigator to influence economic variables in a fully controlled environment and thus measure the impact of those changes on the agent s behaviour falk and heckman 2009 in other words the causal effects of economic factors are observed ceteris paribus this type of observation is almost impossible to obtain outside a laboratory environment in economics experimentation is characterized by a lack of protocol frame and the neutrality of the experimental framework which ensures that subjects do not reach an interpretation outside the scope of the tested hypothesis and give the greatest control to the experimenter czap et al 2012 that said several authors have pleaded recently for the introduction of elements of context in experiments as a way of improving the external validity of observations namely to improve the fact that generic results observed in the laboratory are also observed in the real world laury and taylor 2008 anderies et al 2013 farolfi et al 2014 according to michel guillou and moser 2006 contextualizing may also enable subjects to make context awareness explicit within their behaviour hence some tests have been performed to assess experimentally how players behave during games about natural resource management desolé 2011 these are preliminary results but it is now admitted that contextualized economic experiments which take part of the system complexity into account are important if we aim to understand stakeholder behaviour better including issues of water resource management janssen et al 2011a 2 2 the minsky triad conceptual framework marvin minsky s definition of the term model is both precise and generic it states as follows to an observer b an object a is a model of an object a to the extent that b can use a to answer questions that interest him about a minsky 1965 starting from that definition bonté et al 2012 proposed calling the three entities a b and a the minsky triad called t the relation between the observer and the object is called ρ o and the relation between the observer and the model is called ρ m the key idea of the framework was to build a model of the whole minsky triad itself in order to address questions related to the use of models in a given context therefore in order to study the interactions between the three entities of the triad the proposal made in bonté et al 2012 was to build a model t of the triad t the minsky triad conceptual framework was originally created to evaluate models of any systems that are ill defined incompletely known and which for whatever reason cannot be tested under real conditions such as economic systems on a country scale epidemics or natural disasters for instance where human lives are the main issue in this paper we explain how this framework can be used to study commod processes commod processes are characterized by a succession of models built iteratively each loop of model building is associated with a collective learning process in the kat river commod process three different versions of a model representing the kat river sub catchment were built two agent based models and one role playing game model farolfi et al 2010 we focused in this study on the first modelling loop during which the first model called kataware was built we refer to it hereafter as the kataware triad that we called t in the kataware triad t the object a was the whole kat river sub catchment the observer b was a group composed by the members of a recently created water users association at the level of the kat river the question that the group of stakeholders b had about the kat river sub catchment was as follows how can a catchment action plan in the kat river valley be collectively designed and more precisely how should water use licences be attributed to water users and at what price in order to answer to these questions the group b built the first version of the agent based kataware model which we called a b the general question that we had about this commod process was as follows does participatory modelling foster cooperation in the real situation in order to answer that question we followed our method to build the corresponding experimental design considering our case study the exercise could be summed up as follows we as researchers in experimental social science had a question about the kataware triad t and in order to answer that question we built and used a model of the kataware triad which we called t itself comprising three entities the first entity was a model of the situation in the katriver the second entity was a model of the group of stakeholders the third entity was a model of the kataware multi agent model built and used in the kat river commod process we chose or built these models according to the question we had about t in the next section we propose a general framework for building models of commod processes based on experimental economics we illustrate our framework by the presentation of our model of the kat river commod process 3 proposal the expecommod triad our general framework was called the expecommod triad it is summarised in fig 1 which can be read as follows in order to address research questions about the use of a model box a b within a commod process considered as the commod triad box t researchers in experimental social science circle c build a model of the commod triad box t in this context the relationship that the researchers in experimental social science have with the commod triad is that they have research questions about it arrow ρ o c from these research questions they can formulate hypotheses and design experimental plans that they will perform with the model of the commod triad arrow ρ m c the question of the observer c does not concern the model a b itself but the use of the model a b by the observer b consequently the model of the commod triad box t contains a model of each entity and relation present in the commod triad t we designated as the abstract nrm situation box a c the model used by researchers in experimental social science to represent the nrm situation a we designated as the meta model the model of box a used by researchers in experimental social science to represent the commod model a b we designated as the group of subjects the group of people in position b on which experiments were be performed and which are a model of the group of stakeholders b the expecommod triad called t is created in the process the observed object is the commod triad t the observer is the group of researchers in experimental social science c and the model is the model of commod triad t we present these three entities in detail in this section 3 1 the commod triad a great deal of literature is available on commod processes see a summary in étienne 2011 for instance and we refer to it for further details the synthetic vision that we propose here merely seeks to explain how we see such a process under the lens of the minsky triad framework 3 1 1 the nrm situation at one moment of the process the nrm situation a is specified by a scope defined more or less strictly by either a research project or a local development project or a combination of both in our case study the kat river commod process the nrm situation was scoped by the research action project called a stakeholder driven process to develop a catchment management plan for the kat founded by the south african water research commission the project established the area as the kat river quaternary sub catchment of 1700 km2 including 19 km2 of irrigated area and home to around 50 000 inhabitants in 2001 irrigation took up by far the majority of the water in the catchment and relied mostly on the kat dam situated in the upstream section of the catchment with a 24 10 3 m 3 storage capacity farolfi and rowntree 2006 fig 2 presents the kat river catchment and the main kat river water users 3 1 2 the group of stakeholders the group of stakeholders b is a heterogeneous group in which we distinguished four main types 1 stakeholders of the nrm situation who have been identified by the commod process for various reasons we will discuss these reasons when we describe their relations with the nrm situation 2 experts who have no stake in the situation but have expertise in the objects involved in the nrm situation 3 researchers or facilitators who lead the commod process 4 possibly the funding organizations of the process which may be external to the process research funding agencies local or national state departments international development agencies etc considering the heterogeneity of the group of stakeholders b we had to acknowledge that they may have different kinds of relations with the nrm situation which we called their involvement in the nrm situation ρ o relation we assumed three non exclusive possibilities for each individual in the group 1 knowledge the individual has information about the nrm situations 2 stake the individual has a stake in the nrm situation and 3 power of action the individual as a decision maker can change the nrm situation through his decisions in the kat river commod process the group of stakeholders was composed of the researchers involved in the research action project including hydrologists economists social scientists computer sciencists etc and the members of the kat river water users association composed of representatives of different categories of farmers in the area and representatives of domestic water users from different parts of the area in this study we focused on the group of farmers all farmers had some stakes knowledge and power of action at their levels of the catchment 3 1 3 the commod model even though the commod community is not restricted to a specific kind of model the commod models a b used and built during commod processes usually share some common characteristics and acknowledge commonly used paradigms indeed since nrm situations involve and are usually determined by the decisions of stakeholders regarding the situation it is interesting for the a b models to explicitly represent the beliefs goals and decision processes of these stakeholders for this reason the most commonly used paradigm is the multi agent system paradigm in which the world is represented as a set of objects situated in an environment and manipulated by autonomous agents who represent social entities and can modify the object of the environment move communicate etc this paradigm can easily be mapped either to computer agent based models abm or to role playing games rpg when rpg models are used stakeholders are invited to play their own roles in order to represent and discuss scenarios that can happen in their nrm situation barreteau 2003a the version 1 of the kataware model which we focused on in this study is an abm it is extensively described in farolfi et al 2010 3 1 4 involvment of the group of stakeholders in the commod process depending on a the kind of model used b the question addressed by the commod process and c the nature of the group of stakeholders the involvement in the commod process of the group of stakeholders relation ρ m can have several dimensions for this relation we assumed four non exclusive possibilities of action and four non exclusive possibilities of intention the actions may be either facilitating the modelling and simulation activity and providing the modelling language the individuals usually the facilitators provide a language to build the model and facilitate the process building the model the individuals take part in the modelling process simulating the model by role playing the individuals take part in a participatory simulation of an rpg model where they are invited to play a role simulating the model by changing parameters and observing simulation results the intentions may be either to learn about the system the individuals want to understand how the nrm situation works learn about the strategies of stakeholders or decision makers the individuals want to understand strategies of specific stakeholders or decision makers use the model to convey a message the individuals want to use the model simulation or model building process to influence other members explicitly or implicitly or hide a strategic behaviour the individuals participate in the process for some specific reason but do not want to expose their strategy in the kat river commod process considering the group of farmers and the building of version 1 of the kataware model which was an abm we considered that these farmers had participated in building the model see fig 3 left and in simulating the model by changing parameters and observing simulation results see fig 3 right we did not measure the intentions that these stakeholders had when participating in the kat river commod processes considering farmers we could assume that all the intentions listed above were potentially present 3 1 5 question addressed by the commod model the last remaining element of the commod triad is the question addressed by the group of stakeholders although the group of stakeholders is heterogeneous and has a complex involvement in both the nrm situation and the commod process and even though the question addressed by the commod process is dynamic it may change during the process the question is usually precisely expressed at any moment of the process since it is part of the contract established between all the participants in the commod process in the kat river commod process as mentioned above the question was to design a new catchment action for the farmers of the wua one of the main issues was access to water rights that might enable the use of water from the kat dam which at the time was only available for scheduled farmers see fig 2 3 2 a question about the commod triad the objective of our approach was to use models sensu minsky to reflect upon commod processes we may wish to raise numerous questions about commod triads but we have very little visibility in terms of defining the limitations of the type of question that can be addressed using models based on social experimentation computer models have been built and used to address questions about some aspects of the commod triad for instance an agent based model was designed by emmanuel dubois to assess how player attitudes can change during a role playing game depending on the game settings dubois et al 2013 however the impact of the participatory modelling activity has never been explicitly addressed by the use of a model in our case study we proposed to address a specific question about this in our case study our question about the t commod triad described above was as follows does participatory modelling foster cooperation to answer this question we proposed the model of the commod triad described below as in any modelling process the question asked already scoped the system to be represented we looked at the effect of participatory modelling activity and not at the effect of an entire commod process where participants inhabit the system they model usually simulate or play with the model they build etc 3 3 a model of the commod triad in order to build a model of the commod triad we needed to identify an object or a set of objects and concepts that could be used to represent the commod triad moreover we wanted to be able to perform reproducible controlled experiments on this object or set of objects which we used as a model and we wanted to be able to identify all the entities and relations presented previously as part of the commod triad 3 3 1 modelling the group of stakeholders we propose to use theories and practices from experimental economics in order to use groups of people to represent the group of observers b of the commod triad in accordance with minsky triad framework we designate this group b and we called it a group of subjects university students randomly chosen with specific methods are commonly used in experimental economics to represent a generic group of people falk and heckman 2009 following the prescriptions of experimental economics the subjects for the experiments are chosen among university students and are paid at the end of the game sessions according to their performance during the session harrison and list 2004 eber and willinger 2005 in our case study we constituted groups of four people from the pool of subjects at the laboratory of experimental economics in montpellier leem 3 3 2 modelling the nrm situation the model of the nrm situation used in the model of the commod triad may be very simplified abstracted compared to the nrm situation of the commod process we propose to build it as a controlled role playing game in which players are put in a similar situation to that of the stakeholders of the commod triad of course the similarity of the situations has to be measured with regard to the research question about the commod triad level of knowledge stakes and power of decision that stakeholders have regarding the nrm situation in our case study we wanted to take into account the fact that the nrm situation of the commod triad was about water management and agriculture and that there was an asymmetry of access to the resource and to the associated infrastructure we also needed to represent the fact that the stakeholders had stakes in the situation and some power of action over it since our research question was very general and the players of the game were mostly students who were not well aware of complex nrm situations we tried to find the simplest rpg that could respect our constraints and in which we could measure whether the players cooperated or not hence the model of the nrm situation that we considered was the textbook case of an irrigated scheme with several farmers dealing with the double problem of provision to a public infrastructure contribution to the operating costs of a borehole providing supplementary water to the scheme in the event of drought and extraction from the common pool resource represented by the water available through the irrigation scheme it referred to the case used by janssen et al 2011a b where the authors combined a public good game with an extraction of common pool resource cpr game in which players must first decide how much to contribute to the cpr and then how much to extract from it for their own payoff in order to put the players in this situation we used elements of the wat a game modelling tool kit widely used in commod processes involving water management abrami et al 2012 2016 using this modelling language modellers can use pebbles of various colours to represent resources such as water or money land plot cards to represent land plots owned by the players activity cards to represent activities consuming and generating resources and river path cards to represent canals during each turn of the role playing game built with these elements a facilitator makes the water pebbles flow through a network composed of river path cards and land plot cards when the pebbles reach a land plot on which an activity card stands the owner of the land plot cards can choose to extract water pebbles from the river in order to perform the activity and gather the resources generated by that activity at the end of the turn players can change the activity cards standing on the land plot cards they own for this study we computerized the wat a game as a network game coded in the netlogo agent base modelling and simulation platform so that we could control the information available to the players fig 4 presents our conceptual model of the nrm situation on the left and the graphic interface of its implementation as a computerized wat a game rpg the details and implementation of the wag rpg are described in section 4 3 3 3 modelling the involvement of the group of stakeholders in the commod process the relation between the model of the nrm situation and the group of subjects may not be exactly the same as that between the group of stakeholders b and the original nrm situation a since we do not want to face the same issues as in the real commod triads where experience is hardly reproducible however some aspects of the relation remain to be studied such as knowledge about the situation or even stakes in the situation most importantly the group of subjects b must be able to build the meta model a as their own representation of the model of the nrm situation built in order to answer a question they have about that situation to do so and in order to have reproducible controlled experiments we need at least a pre defined modelling language limiting the noise that would occur if any kind of model was possible thus the model of the commod triad must include a modelling language that the group of subjects can use to build the meta model a hence the relation of the group of subjects to the meta model ρ m relation must at least include the modelling activity it may also include some of the intentions and actions that the original group of stakeholders b may have with the original model a b presented in the commod triad subsection section 3 1 4 the group of subjects may also somehow have some power of action stakes information etc in the model of the nrm situation in order to represent the relation of the stakeholder of the commod triad to the real nrm situation in our case study the groups of subjects participated in a modelling activity with pens and post its during which the members of a given group did not have the same pieces of information and they were told to engage in a role and build a model of their situation as a drawing see fig 5 this first activity represented the relation that the stakeholders had with the model in the commod triad ρ m the groups of subjects were then asked to play the computerized wag rpg following the precepts of experimental economics this phase took place in a laboratory of experimental economics under controled conditions see fig 6 the players were paid according to their results in the game in the pilot experiment the participants earned from 7 euros to 60 euros for a 2 h experiment this second activity where the players had power of action and stakes in our model of the nrm situation represented the relation of the stakeholders to the nrm situation in the commod triad ρ o 3 3 4 modelling the model as is the case for the models a b used by stakeholders of real commod triads the models that we can use to represent them in models of the commod triad the meta model a may have several forms from conceptual models drawn on paper up to abm in our case study we used drawings used as conceptual models by the groups of subjects such a model can be seen in the table in the middle of the picture fig 5 3 4 the experiment and its analysis ρ m c following the general framework of the minsky triad now that we had specified the t model we needed to specify which experimental plan which set of experiments would be performed on this model in our case study we wanted to test the following hypotheses h1 and h2 h1 if people take part in the participatory building of a model representing a situation in which they have a stake in shared resources and in which they have power of action they will change their behaviour once they are placed in this situation h2 if people take part in the participatory building of a model representing a situation in which they have a stake in shared resources and in which they have power of action they will cooperate more once they are placed in this situation in order to test these hypotheses and following the precepts of experimental economics we propose to submit a population of students to two different treatments t0 and t1 in our case study for each treatment n groups of 4 players called g i j were composed where i t 0 t 1 was the treatment number see below and j 1 n was the index of group j of a given treatment i groups submitted to t0 were asked to have some group activity unrelated to the nrm situation and then to play to the computerized role playing game the model of the nrm situation groups submitted to t1 were asked to build the meta model a and will then were asked to play the computerized rpg the model of the nrm situation the level of cooperation of the groups of subjects was assessed in two dimensions their total contribution in the public infrastructure the more they contributed the more we considered that they cooperated and their choice of activity as described in section 4 1 4 details and implementation of the case study model of the commod triad 4 1 the computerized role playing game the anawag device includes a client server network game module see appendix d such that the experimenter can stand behind a server computer and each player stands behind a separate computer with a client interface displaying only a chosen set of information and allowing only a chosen set of possible actions we calibrated the game in order to be able to measure the cooperation or non cooperation of players and to limit the number of players and the duration of the game as repetition is necessary in order to create the conditions in which players can learn we considered a repeated game with 15 rounds per session the irrigation scheme was fed by two sources of water the surface water source supposed to come from a reservoir regularly filled with rain the amount of surface water was known by the players and always equal to 1 unit of water the ground water source whose delivery depended on the players investment representing their contribution to the public infrastructure see fig 7 and section 4 1 below each player possessed one plot of land where he could place an activity card each activity needed resources wags the money and clean water produced wags and eventually rejected clean water reusable in the irrigated scheme the activities available are presented in table 1 an activity was entirely defined by the type and quantity of resources it needed and the type and quantity of resources it produced for instance activity a3 consumed 2 units of water and 1 wag and produced 1 unit of water and 3 wags in order to set up on a field a player had to invest the monetary resource needed wag in in table 1 if the water available was not sufficient there were fewer water units in the river at the level of the field than the water in units requested by the card the investment was lost and no resource was produced otherwise the player received the produced income wag out and the produced amount of water water out flowed back to the river at each turn of the game all the players made two individual decisions they chose how much to invest in public infrastructure the total investment of the group would determine the water available from the public infrastructure as shown in fig 7 the activity to put in their fields which implied the water extraction level according to the figures presented in table 1 a report on the status of their own savings and on the quantity of the remaining water downstream of the irrigated scheme was shown to players after each round investment in public infrastructure the production function for public infrastructure depended on the sum y i 1 4 y i where y i was the contribution of player i in order to capture some aspects of the nature of irrigation systems namely increasing returns to scale for lower levels of investment and decreasing returns for higher levels we employed a linear production function presented in fig 7 referring to anderies et al 2013 and thinking about the kat river dam of our case study we chose a scaling that produced a range making it impossible for one person to create a public infrastructure without the help of the others investments in activities after having made the water resource available the second investment of players took the form of the activities they chose to set up on their lands as described in table 1 this choice was related to the profit that the card can provide and the risk they take of losing their investments if there is not enough water this decision involved two uncertainties 1 the uncertainty of the investments that would be made in the public infrastructure responsible for the amount of ground water supplied by the public infrastructure 2 the uncertainty of the activities to be played by upstream players final payoff of players the payoff of a player i for each round r resulted from the payoff derived from the production of their activities minus the amount of wag invested in the public infrastructure the final payoff given by equation 1 was computed as the sum of the payoffs of all repetitions 1 p i r 1 r e y i r c i r o k c i r o u t c i r i n where r 1 15 is the index of the repetition p i is the total payoff of player i e is the initial number of wags given to each player at each repetition y i r 0 3 is the number of wags invested in the public infrastructure by player i at repetition r c i r a 1 a 2 a 5 is the activity card played by player i at repetition r c i n is the number of wags needed for the installation of activity c wag in in table 1 c o u t is the number of wags produced when activity c was performed wag out in table 1 c o k 0 1 specifies whether the activity was performed enough water in the river or not not enough water in the river if a player did not get the water he needed through one of his activities he was not paid for that activity and lost the wag invested in that one measuring cooperation we had two indicators to measure player cooperation the first was the total contribution to the public infrastructure and the second was the activity cards that players play in order to qualitatively estimate whether groups had a cooperative or selfish behaviour we compared their actions to economics equilibrium cooperative players would coordinate in a stable and durable way to reach a cooperative equilibrium where all players would have the same payoff players would all contribute the same amount 1 3 wags each and would play all the same card a3 if the group contribution is 4 or a5 if the group contribution is 8 12 the corresponding group payoffs would be 4 if group contribution is 4 all play a3 8 if group contribution is 8 all play a5 4 if group contribution is 12 all play a5 the optimal equilibrium is when all contribute 2 wags each and play a5 then they would reach a group payoff of 8 highest group payoff corresponding to equal individual payoffs on the other hand perfectly selfish and informed players would reach a nash equilibrium where player 1 the only one that can take advantage of surface rainwater would contribute 3 wags and plays card a5 for a net payoff of 1 all other players expecting that player 1 contributes 3 would contribute the minimum 1 necessary to play the card that would give them the highest possible payoff a4 with the minimum effort this would produce a group investment of 6 for a group payoff of 7 hence we created a model of the nrm situation representing the kat river case study in which we had individual stakes a public infrastructure asymmetric access to the resource and to the infrastructure and a benefit from cooperating one of the issues of the cooperation was a management issue since upstream players needed to understand that downstream players would be interested in contributing only if they derived some benefit from their contribution 4 2 the pilot experiment preliminary analyses were conducted over 300 observations produced by an experimental pilot session undertaken over 15 repeated periods on 5 groups of 4 subjects each two groups were assigned to the treatment t0 that is the puzzle treatment noted treatment p below andthree groups were assigned to the treatment t1 that is the model treatment noted treatment m below instructions for the two treatments are available in the appendix 5 results of the pilot experiment a summary of the descriptive statistics concerning the main variables analyzed is included in table 2 5 1 individual choices by treatment the results show that there was no treatment effect in terms of individual contribution which was close to 1 43 wags in both treatments wilcoxon mann whitney test p value 0 936 in terms of the choice of activity cards and therefore the strategy of resource extraction after conversion of the labels of cards a0 a5 to numbers 0 5 the average card played by individuals was 4 34 for m and 4 12 for p a treatment effect was detected wilcoxon mann whitney test p value 0 015 on the categories and 0 0495 on the labels of the cards converted in numeric values the resulting average individual payoff per period was 0 72 wag in the m treatment and 0 60 wag in the p treatment running a chi2 test on the distribution of average individual payoff per period a treatment effect was shown with a p value 0 013 the distribution of the individual payoff per period showed that extreme values positive and negative were more frequent in the m treatment globally individual payoffs of 1 3 amounted together to 60 of occurrences and 1 was largely more frequent in the p treatment while 3 dominated in the m treatment fig 8 shows the dynamics of the individual cumulated payoffs in the two treatments the plot of the m treatment was consistently above that for the p despite a decrease in the last 3 periods and the average individual cumulated payoff was 6 9 wag in the m treatment and 4 09 in the p treatment a t test p value 0 024 showed that there was a significant treatment effect over the whole session 5 2 comparison of results with expected equilibria in the experiment players in both treatments contributed an average amount per round of 1 43 wag close to 6 wag group while the average card chosen was between a4 and a5 4 34 in model and 4 18 in puzzle these average choices were very close to a nash equilibrium but due to free riding of upstream players they led to much lower group payoffs than what would be expected in a nash equilibrium 2 8 wag and 2 4 wag respectively for the m and the p treatments instead of 7 if players had played the nash equilibrium as explained in section 4 1 this distance from equilibrium might be explained by the fact that players within each group had different behaviours depending on their position players upstream 1 and 2 played higher activity cards than players downstream 3 and 4 players downstream conversely tended to invest more in the public infrastructure certainly hoping that the upstream players would not free ride on the common resource produced this different behaviour between players with asymmetric access to the resource in a group provoked gaps in terms of individual cumulated payoffs far from cooperative equilibrium fig 9 shows the average individual cumulated payoff per player 1 4 in the groups of treatment m and in the groups of treatment p in the groups of treatment m more extreme behaviour was observed bringing higher payoff to player 1 and leaving player 4 with negative payoffs while in the groups of treatment p player 1 extracted less common resource especially during the first ten periods this allowed the three other players to finish the game with non negative payoffs 5 3 learning and individual decision making in order to better understand the process of individual decision making a multi level mixed effect linear regression analysis was run on the individual level data of investment contribution to ground water extraction and choice of activity card corresponding to the water extraction level the impact of three variables representing the information available to the subjects about their choices or their situation at the time of decision making t or in the previous round t 1 was estimated the regression estimated the player s investment at time t according to the activity played at time t the round t the profit at time t 1 and the value of the dummy variable not played at time t 1 indicating whether or not the player received enough water to play his activity card at time t 1 the regresssion was estimated separately for the two treatments m and p whatever the treatment the decision to invest was significantly and negatively affected by the individual profit at t 1 as if a good level of payoff reached previously would push the subjects to reduce the level of contribution to the common resource free riding on the group to have an even higher payoff in round t we observed a significant and negative impact on individual contributions of the not played variable at t 1 clearly the occurrence of such an event impossibility of playing a card in the previous round pushed the players to reduce their investments at time t as we observed in the data that this occurrence was more frequent for downstream players we considered that such a behaviour corresponded to the social sanction that downstream players could impose on upstream players seen as stationary bandits janssen et al 2011b playing a higher activity card in round t had a positive impact on the player s investment at the same period in the m treatment but it was not significant in the p treatment is and lastly there only seemed to be a learning effect negative and significant correlation with the variable round in the m treatment in fact trends for investment were steadier and decreasing in m than in p 5 4 answsers to our research questions and hypothesis although this was only a pilot experiment so the sample was not large enough to be statistically significant some preliminary thoughts can be expressed on our hypotheses h1 was partially confirmed there seemed to be a treatment effect in terms of the choice of activity cards and in the distribution of individual payoffs but not in terms of contributions the groups in m treatment earned more but there was more of a gap between players h2 was not confirmed on the contrary compared to another collaborative activity in a group participatory modelling seemed to favour free riding and aggressive behaviour by upstream players especially p1 while p3 and p4 remained prone to invest even when loosing and allowing p1 to free ride despite a certain social sanction behaviour observed in both treatments 6 discussion 6 1 using experiments as simulations in their paper in science janssen et al 2010 explain that they used methods of dynamic decision making in order to perform controlled experiments that examine the relevant complexity of social ecological systems themselves refering to dörner 1996 for the use of computerized microworld in experiments about organisation management our questioning was on an higher level of abstraction we reflected on the use of a model to think about the social ecological system but we used experimentations in the same way i e to represent the relevent complexity of social ecological systems in the exercise to clarify the position of these experiments in our questionning we referred to guala 2012 who studied the epistemic relations between models simulations and experiments in his view of social experiments we used hybrid entites between simulations and experiments we brought some material from the real world the human subjects into the laboratory but we do not claim that our experiment exactly reproduced a phenomenon of the real world the minsky triad makes it explicit that we simulated a model using guala s words we decided to speak about simulating experiments using models of this nature we are able to imagine an experimental platform in the sense of muniesa and callon 2007 which for instance by substituting the current cards by value cards where agents could express their views on water management could serve as a basis for experimental sociology richard ferroudji 2008 or for experiments in other social sciences these models could constitute frontier objects to facilitate dialogue among various specialists of these disciplines in a community of practice at the interface between science action and policy making 6 2 a new kind of meta models the concept of the meta model a model of a model may differ from one community to another and is directly related to the definition given of the concept of model in the community of theory of modelling and simulation led by bernard zeigler zeigler et al 2000 modellers consider models of dynamic systems in this community a model is evaluated according to the way it reproduces or not the behaviour of the system it represents within a specific experimental frame therefore a meta model is considered as another object that has statistically the same behaviour as the model zeigler et al 2000 for a given experimental frame and at a given level of specification in agent based modelling in ecology or environmental science modellers have a more conceptual understanding of a model whereby a meta model is a set of concepts that constitute a generic model general enough to be specialized in less abstract more specific representations of the system under study treuil et al 2008 in this paper and following the general framework of the minsky triad an object was considered as a meta model as long as it was used in our reasoning to represent another model used for a specific purpose by a specific observer with this definition we considered an object as a meta model only if we also modelled the observer the object modelled and their interactions this definition was particularly suited to the study of commod processes where we assumed that the object modelled the nrm situation was modified by the use or creation of the model by the observers for that reason the outcomes of a commod process are extremely difficult to observe in the real world with the model of the commod triad it was possible to repeat experiments and measure outcomes in the laboratory 6 3 using our approach to learn about commod processes 6 3 1 when should this approach be used we could not imagine a specific type of questions about the commod process ρ o c in the t framework presented fig 1 that would require the use of this approach referring to the study on the kat river commod process presented in this paper we saw that it implied questions about power asymmetries finding new cooperative arrangements and assessing the impact of the participatory modelling process there are several ways of studying these questions without building a model of the commod process some studies have been conducted for instance by interviewing several researchers who implemented different commod processes see for instance barnaud et al 2014 for a study about power asymmetries in commod processes some others analysed several commod processes with the same observation protocol see for instance perez et al 2011 for a study on monitoring and assessing of the impact of commod processes some others compared commod approaches with other participatory methods based on case studies and a shared analysis grid see for instance berthet et al 2016 about fostering agroecological innovation on the other hand we believe that many questions that social scientists have about commod processes can be addressed with this approach however we know that we will be restricted by the nature of our model for instance in order to answer our question we can imagine an experimental setting where subjects would follow a complete commod loop a first phase where players play a second where they build a model and a third where they play again however the different possible situations in the first phase would have distilled the results and such an experimental setting would require many more observations in fact the minsky triad conceptual framework should be used when a model of a commod process is built thus the motivations that we can imagine are the same motivations as those that researchers can have to build a model varenne 2018 organises the different functions that a simulation model can have in 5 categories i to ease experimentation ii to ease comprehensible formulation iii to ease theory building iv to ease communication and cooperative building of knowledge v to ease decision making and action we believe that regardless the research question about the commod process a model of this process can be built for many reasons included in any of these five categeories 6 3 2 what is the validity and generality of our model as in any modelling process the validity of the model of the commod triad depends on the question that we have about the commod triad and on the function we give to our model in our questioning in the introduction we stated that our aim was to ease experimentation as for many reasons explained above we cannot reproduce the same commod process as many time as needed we reproduce it in the laboratory and study it in vitro however the question we had about the commod processes was very generic consequently the model of the nrm situation that we used to represent the kat river nrm situation was very simple and very different from the kat river situation we actually used the kat river situation to induce a generic model of commod processes that helped us to reflect upon a generic question we had about commod processes in general thus the results of our experiment will not teach us many things about the kat river situation but more about a general theoretical hypothesis about the effect of commod processes on natural resources management issues in other words our model of the nrm situation represented a common and generic problem in water management and could certainly be used to reflect upon many specific commod processes in a rather abstract way we believe that this approach is well suited to addressing generic and theoretical questions about the impact of a modelling activity in a commod process firstly because we can generalize situations and secondly we can repeat experiments at will however the knowledge built with these models the results and demonstrations made will remain theoretical and will need to be confirmed by studies in the field on real commod processes we consider our model of the commod triad as a crutch for thinking about commod processes in a theory building perspective the more detailed our models of the commod triad are the richer will be the discussions that we can have about them for instance a salient question about commod processes is the way they interfere with existing institutions formal or informal that frame the actions and perceptions of stakeholders we plan to continue developing the anawag platform in order to use t models to represent these institutions we are confident that this task is possible because the wag modelling kit proposes a way of representing such institutions abrami et al 2012 and extensive literature is available to describe these institutions based on a common analytical framework proposed by ostrom 1990 a framework already exists for modelling these institutions in agent based models using the framework proposed by e ostrom ghorbani et al 2013 7 conclusion the work presented in this paper presents a proof of concept showing that the general framework of the minsky triad is both necessary and well suited to exploring theoretical questions about companion modelling processes we did not perform the full simulating experiment that we designed and only have the results from a pilot experiment however we were already able to see in our model that companion modelling could have an effect on resource management it was our first hypothesis in the way we modelled companion modelling we observed that it increased the efficiency of resource management we also observed that in the way that we modelled commod processes the participatory modelling activity increased the inequality among stakeholders compared to another collaborative activity we found several possible explanations for this observation and we need to perform the full experiment to discriminate between them it is interesting to see that this observation gives rise to new hypothesis on the effects of companion modelling processes for instance we believe that this increased inequality is maybe due to the fact that participants are more cooperative and that this decreases the social sanction effect assumed to regulate inequality according to the economic theory 8 software and data availability the model code and data used is published on the comses platform bonté et al 2019 with the documentation presented in appendix d below all the sotfware packages used are free of charge and open source platform netlogo 5 3 1 programming language netlogo operating system platform independent model code licensed under gnu gpl version 3 netlogo software is authored by uri wilensky email uri northwestern edu phone 847 467 3818 fax 847 491 8999 offices annenberg hall 337 ccl lab phone 847 467 7593 ford lab phone 847 467 2838 the anawag platform has been programmed under the netlogo software by bruno bonté and mamadou ciss diallo who are authors of this paper see contact information in the authors section appendix a modelling activity instructions for modelers instructions were distributed to each subject then they were asked to read them and an experimenter read them aloud instructions changed only in the position asigned to the player upstream in the middle or downstream we translated the instructions in the paragraph below instructions for modelers you are part of a group of 4 subjects you are a farmer who is a member of a user association that manages an irrigated system upstream farmers have priority in terms of access to water over those in the middle or downstream you are a farmer located in the middle upstream downstream of the irrigated system your objective is to build with other farmers a model that represents your irrigated system and will help you discuss system management strategies you have a kit that allows you to represent an irrigated system with four irrigators and a water source drilling positioned upstream of the system the system is gravity based so surface water from the nearest dam enters the upstream irrigated system each farmer has an irrigated plot the following elements are at your disposal to model your system a sheet of flipchart felt pens colored post it notes you have 15 min to build your model example of model fig a1 presents an example of model built by the subjects fig a1 example of model fig a1 appendix b puzzle activity instructions for puzzle players instructions were distributed to each subject then they were asked to read them and an experimenter read them aloud we translated the instructions in the paragraph below instructions for puzzle players you are part of a group of 4 subjects your goal is to solve a 28 piece puzzle together in 15 min you have an illustration containing the solution of the puzzle divided into 4 quadrants each subject has a quadrant and cannot share it with the other three subjects one piece of the puzzle at a time can be moved exchange with another piece only one player at a time can work on the puzzle each in turn clockwise puzzle the image ask to rebuild is presented in fig b1 it was printed on a a3 page and then cutted in 28 pieces 7x4 that were placed on the grid in random positions fig b1 puzzle image fig b1 appendix c role playing game instructions instructions the experience you are about to participate in is intended for the study of decision making we ask you to read the instructions carefully they should allow you to fully understand the experience when all participants have read these instructions an experimenter will read them aloud all your decisions will be treated anonymously you will indicate your choices to the computer you are sitting in front of from now on we ask you to stop talking if you have a question raise your hand and an experimenter will come and answer you in private during the experiment you will accumulate earnings expressed in experimental currency units the wag at the end of the experiment your accumulated earnings will be converted into euros at the conversion rate 1 wag 1 euro general framework you are one of four members of a group of farmers in an irrigated system who share a borehole to irrigate their fields the amount of water produced by the borehole depends on the maintenance provided by the group the more the group contributes to the maintenance the more water the borehole will produce the fields of the four farmers are aligned along an irrigation channel water arrives first in the fields of the first then in the second etc your position 1 2 3 or 4 will be indicated at the beginning of the game and will remain unchanged until the end of the game you will be able to use the water from the canal to carry out your activities these activities are represented by activity cards that you can install on your field the activities have a cost 1 2 wags depending on the activities and generate revenue 1 6 wags as explained in the glossary the game is repeated 15 times you will have 5 training rounds beforehand which will not count in your remuneration water availability there are two sources of water surface water rain and groundwater from drilling by default one unit of surface water comes from the rain every turn the amount of water produced by drilling each tower depends on the amount of money invested by the group each tower in its maintenance fig c1 shows the number of units of produced water on the ordinate as a function of the total contribution invested by the group on the abscissa outline of a turn a turn lasts 30 s you will have a countdown at the top right of the screen each turn you can invest up to 5 wags 0 to 3 wags in drilling maintenance action 1 and 0 to 2 wags in an activity card action 2 action 1 to invest in drilling maintenance you must position the cursor under the corresponding number see image 1 action 2 your field is highlighted and you can choose the activity you want to perform by clicking on one of the cards in the left column see image 1 at the end of the tour the water rain drilling possibly water produced by the activities flows from the upstream top left to the downstream bottom right and is gradually distributed in the fields gain for each turn your gain is determined by the income generated by the chosen activity minus the investment in drilling maintenance and the cost of the activity card example you contribute up to 1 wag to the maintenance of the borehole and choose map 4 this requires two water units and an investment of 1 wag and in return it generates an income of 4 wags if at least two units of water reach the field your gain is 4 income 1 activity cost 1 drilling investment 2 wags if on the other hand less than two units of water reach the field your gain is 0 income 1 activity cost 1 drilling investment 2 wags fig c1 drilling water production based on the group s contribution fig c1 image 1 interface actions4 image 1 image 2 interface informations5 image 2 glossaire image 6 field the position of your land in the irrigated system is represented by an exaggeration of your color image 7 water water is represented by drops each representing one or more units of water here a unit of water in the activity maps the water needs and the water discharged is symbolized by blue dots image 8 image 9 wag wags are represented in the activity cards by yellow squares they represent your economic resource your actions in the game will cause you to win or lose wags each game turn image 10 drilling produces water from the borehole image 11 rain produces natural srface water image 12 the activity cards there are 5 different activity cards that you can make on your field the activity requires a number of wags image 13 and water units image 14 to be realized upper part of the map it rejects a certain amount in return and if it receives all the water it needs it is successful and produces money lower part of the map once the activity is placed the number of wags necessary for its realization will be deducted from your profit of the corresponding round if the activity is successful the money it produces will be less expensive and your contribution to the drilling will be less of a benefit to you example if a player wants to play the a3 card above he must invest 1 wags if it receives two units of water the activity is successful and the player who installed it will receive 3 wags in addition a unit of water received by the field will be returned to the irrigated system imagine that the player has invested 1 wag in the maintenance of the borehole and the activity is successful his profit for this round will be 1 wag 2 wags invested and 3 wags won appendix d the anawag device the anawag device code and documentation can be downloaded from the comses model library at the following link https doi org 10 25937 5j66 e528 below is the user guide do not hesitate to contact authors for any help for use or design of new features anawag user guide table of content purpose structure of the anawag device setting experimental parameters experimenter modelling experimenter design a watershed model play experimenter organise and run a network game play player participate to a network game simulate experimenter run simulations with computerized players download and installation of anawag details and implementation in netlogo purpose the anawag device for analyse wat a game wag is a computer version of the wat a game paper and pebbles modelling and simulation tool for water management see abrami et al 2012 1 1 abrami g ferrand n morardet s murgue c popova a de fooij h farolfi s du toit d aquae gaudi w 2012 wat a game a toolkit for building role playing games about integrated water management in r seppelt a a voinov s lange d bankamp eds 2012 international environmental modelling and software society iemss 2012 international congress on environmental modelling and software managing resources of a limited planet pathways and visions under uncertainty sixth biennial meeting leipzig germany it enables to perform the three activities below 1 build up a wat a game model representing a watershed that may also be seen as an irrigated scheme 2 simulate the model by playing it as a network game in an experimental design 3 simulate the model with computer agents instead of players the aim is to make possible to perform experiments in the understanding of contextualized experimental economics in which subjects can build role playing game models as the one built during participatory processes and then play to the model they built in this actual version anawag is designed to realize the specific experiment presented in a scientific paper 2 2 bruno bonté stefano farolfi nils ferrand géraldine abrami mamadou ciss diallo dimitri dubois anne johannet wanda aquae gaudi building new kinds of meta models to analyse experimentally companion modelling processes in the field of natural resource management environmental modelling software 2019 issn 1364 8152 https doi org 10 1016 j envsoft 2019 07 011 however it can be easily reused to design other experiments structure of the anawag device we distinguish two kinds of users of the anawag device the experimenter who can set experimental parameters build a watershed model run a simulation with computerized agents run a game session with human players the players who can play a game session entities state variables and scales of the wag model entities of anawag device model correspond to the entities that exist in the wag role playing game and in a watershed system in general players that represent water users waterpaths that represent the river fields that represent elementary spatial units activities that represent uses of resources water resource and eventually other resources to produce other resources and that must be installed on a field entity pumps that enable to withdraw water from the river to bring it to the fields outlets that represent the out flow from fields entities to the river sources of water that brings water to the waterpaths water resource that can flow along river path and wag resources that represent money the conceptual model of entities and their state variables is presented in an uml class diagram in figure below anawag main entities and state variables image 15 there are three main levels of spatial scale in the wag modelling language the level of the field that is the same level of the activity in the spatial scale it represents the elementary unit spatially and temporally indeed the transformation of resource described by all activities are processes that occur at the same level of spatial and temporal scale this level however is not specified at this point it depends on each wag model in the model used in bonte et al under rewiew which is theoretical we can consider that the spatial level is a plot of an watershed the level of the farm or set of fields owned by a player is the spatial scale of strategic decision making since it determines the stakes of each players in the model used in bonte et al under rewiew each player own one or several plots the level of the watershed is the greater level that contains all entities in the model used in bonte et al under rewiew it represents a watershed managed by four farmers and supplied by one natural source of water rain from upstream and one artificial source of water pumped from an aquifer the temporal resolution is the year or the time to execute an activity it corresponds to a round of the game the temporal extent is the number of rounds setting experimental parameters experimenter the first feature enables the experimenter to set up the parameters of a session group numbers duration water supply parameters and to choose the activity to perform modelling simulation or network game the corresponding interface is the general interface displayed below opened when the file is open anawag main inferface set parameters and choose activity image 16 to change parameters values replace the value by the value of your choice and press enter to start an activity click on the button parameters to set are the following define the context i and j indexes used to save data and relate it to a simulation or a group of players nb players number of players agents in the watershed initial w number of units of money at the initialisation of each round rounds maximal number of rounds during a simulation or a game max investment maximal possible investment in the water harvesting public infrastructure define the natural water parameters min natural water minimum natural water in random natural sources max natural water maximum natural water in random natural sources forcast error error factor in natural water forcasting choose activity choose one of the following activity described in the next sections of the guide modelling experimenter design a watershed model play experimenter organise and run a network game play player participate to a network game simulate modelling experimenter design a model of watershed the modelling feature enables to realise the model of an watershed model as presented in bonté et al 2019 2 figure below presents the interface in which an experimenter already started to draw a water shed with 4 players agents a field a river reach and a water source visible in the drawing area the user may load or save his watershed and modify existing watersheds anawag modelling inferface draw your watershed image 17 click on run button to start the activity draw your watershed by drog and droping elements from the tool area to the drawing area eventual options will be proposed when you install elements owner of the fields kind of the water sources save or load your wartershed with corresponding buttons play experimenter organise and run a network game the play activity enables to realise the network game model activity organised as a client server architecture based on hubnet in which when clicking on the play button a windows open and the experimenter must first start a network session to which players will connect he or she must just enter a session name and click on the start button see figure below starting a network session window image 18 enter session name choose to broadcast session so that players can see the session when they open clients click on start once the session is started the experimenter can monitor and manage the clients connexions see interface below managing client connexions with hubnet control center interface image 19 you can see connected clients here one client bruno and disconnect them eventually kick button you can see server address and port you can open local client connexions local button you can send messages to clients the experimenter manages the server interface see figure below with which he can monitor players actions and decide to start pause or resume the game a game session is by default initialized with the default example watershed but you may load another existing watershed the anawag play inferface experimenter manage a game session image 20 the example watershed model is loaded by default if you want to use another one you need to click on load button and choose the watershed model you want to play when you click on run button each connected client is associated to a player of the watershed by order of connexion supernumerar clients are not associated here there is only one client connected bruno and he is associated to the red player player 1 before starting the game you may set the speed of drops they run through the watershed at the end of each round and the round duration 3 possibilities there may be some issues with client messages sent during pauses if this happens clik on clean server buffer and set back the start pause switch on there may be some issues in visualizing the space all or part in gray if it happens click on refresh view the players are presented in next section see next section play player participate to a network game the players manage their client interface with which a player can at each round monitor his own activities and status choose his participation to the public infrastructure and change the activities to implement on his plots by clicking on a plot and choosing an activity card in the legend client must first run the hubnet client software executable file in the root ot netlogo installation folder that you just need to copy and paste on your computer and connect to the server using the hubnet client connexion interface displayed below connexion with hubnet client connexion interface image 21 choose the session you want to connect to or enter manualy the server address and port enter a user name click on the enter button once connected the player waits for the game to start and then he can start playing by playing an activity card on each of his field and choosing how much he wants to contribute to the water harvesting public infrastructure for instance the interface of player 1 bruno client in figure below where player 4 just changed the activity card standing on his first plot client game interface image 22 select your investment in public water source here player 1 chooses 2 for each one of your fields fields of your color set the activity by clicking on the field it becomes highlited with a white halo and then clicking on the activity you want to settle you can see how much time is remaining for the current round here 1 s you can see your income for previous rounds here only one previous round t1 where your income was 1 you can see your actual wealth under the figure representing you in the top of the screen here the red player owns 5 wags simulate experimenter run simulations with computerized players the experimenter can test his watersheds models by running simulations where human players are replaced by computer agents an inference engine has been built to model agents behaviours but at the moment given rules are very simple so agent behaviour is erratic however it enables to watch a simulation when you do not want to play all the players see figure below simulation interface just click on run button and the simulation starts at beginning the game is on pause if you want to start it you need to click set the start pause switch on rounds are passed automaticaly and activities and investments are choosen automaticaly by each agents you can see on the image that drops of water are flowing in the watershed download and installation of anawag all software used are free of charge and open source platform netlogo 5 3 1 programming language netlogo operating system platform independent model code licensed under gnu gpl version 3 in order to use anawag you must first firstly download and install netlogo 5 3 1 netlogo download page and then secondly download the extra widget extension v1 1 0 extrawidget extension page and install it as an extension in your netlogo installation as explained in the extension guide of netlogo just put the downloaded file in the rigth folder of your netlogo install details and implementation in netlogo mapping of the wag model in the netlogo world the conceptual model of anawag presented above as the conceptual class diagram has been mapped to the netlogo meta model in order to implement the model in the netlogo platform see figure below mapping of the wag conceptual model used in anawag into the netlogo meta model process overview and scheduling of the wag model in the anawag device the simulation corresponds to the network game feature or to a simulation with computer agents when it is a network game it is managed by a specific user of the device called the experimenter that starts each round when all players are ready once the round is started the players or agents choose the activities they want to install on each of their fields as well as the investment they want to put in the artificial source of water then the waterpath entities distribute water through each field and the activities entities determine if they succeed get enough resources or not an uml sequence diagram presents the scheduling in the wag model used in anawag in figure below sequence diagram of the wag model used in anawag development and results analysis analysis of simulation or game session can be automatized with r software a script is provided in the analysis folder of the source code computer code is split in a main source file called main nlogo in the root of the ana wag folder and a specific file for each class of the model class mame nls situated in the src folder watershed folder is used to store watershed models raw results files are saged in the results folder sets of rules describing agents behaviors are saved in agentrulesdatabase folder database folder is not used yet appendix e supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix e supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 07 011 
26161,in order to better manage complex situations of natural resource management models are built in a participative way involving the stakeholders of these situations in participatory modelling activities the impact that this activity of participatory modelling has on the stakeholders is at the heart of the companion modelling approach but this impact is hardly possible to evaluate on the field in this paper we propose a general framework to study in vitro the impact of participatory modelling on natural resources management we illustrate our framework by proposing an experimental setting that looks at participatory modelling in the context of water management we realized a pilot experiment and show that this experimental setting can be used to test in the laboratory the hypothesis that participatory modelling of a common pool resource situation has an impact on the way the resource is managed and increases the cooperative behaviour of stakeholders keywords companion modelling experimental economics agent based modelling role playing game integrated water resource management 1 introduction the first version of the charter of the companion modelling commod approach was published more than a decade ago barreteau 2003b it was then signed by numerous researchers from various disciplines related to natural resource management nrm the approach was adopted and developed in several case studies with various stakeholders and was used to tackle different problems étienne 2011 companion modelling is at the same time both an approach and an epistemic and deontological stance that a modeller may adopt when involving stakeholders in the production of a model that represents a nrm situation in which they are taking part it stems from the fact that involving the stakeholders of nrm situations when modelling the situation in which they find themselves may have an impact on that situation for instance if we bring fishermen into a room and ask them to explain their practices in order to build a model of fishery in the region it may have an impact on the way fishery will evolve in that region consequently from a rigorous scientific and civic perspective this impact must be considered when models of nrm situations are built two main cases can be distinguished depending on whether the objective of the model building is to study the nrm system for scientific purposes only or to explicitly use the modelling activity to improve a collective decision making process in the latter case the model is used as a medium by stakeholders to specify their points of view and issues the modelling activity is considered as the building up of a shared representation of the environment this shared representation the model can then be used to design concerted action plans it is difficult to assess the impact of modelling activity in natural resource situations in a falsifiable way sensu popper 1959 several proposals have been made for providing monitoring and evaluation protocols with a view to making comparisons and improving the design of participatory modelling devices and the implementation of commod approaches such protocols are often used and useful jones et al 2009 perez et al 2011 hassenforder et al 2016 and have been adopted in various cases however these evaluations focused on diagnosis assessing for action and were not dedicated to explaining how the modelling activity impacted the situation in this paper we propose an original approach to address this issue the aim was to design reproducible experiments so that the results of the experiments could be refuted or replicated by our peers we identified two main challenges the first challenge was that designing such an experimental setting meant handling concepts and objects used at various levels of abstraction the concepts from the modelling language used to build the model the model used during the commod process the model that we used in the experiment to represent the model used during the commod process etc we thus needed a robust conceptual framework in order to specify rigorously the hypotheses we wanted to test and see how they could be refuted or confirmed in order to take up this first challenge we used a generic framework for meta modelling called the minsky triad conceptual framework bonté et al 2012 which was developed to perform reflexive studies on modelling and simulation activities in general the second challenge was related to the fact that the outcomes of companion modelling approaches may be very difficult to measure being both context and time dependent in order to take up this second challenge we relied on experimental economics falk and heckman 2009 which addressed the issues of reproducibility context dependency etc here we transpose the conditions of a commod process into the laboratory by using the minsky triad conceptual framework and the principles of experimental economics to this end we developed a software device based on the netlogo platform and on the generic watershed modelling kit wat a game wag this device which we called anawag for analyse wat a game is available on the comses platform wag is a paper and pebbles participatory modelling kit that has been used in various water management situations in many countries for more than ten years abrami et al 2012 taking advantage of the experience accumulated with wag we designed the anawag device to be easily adapted to other similar research in order to test and illustrate the relevance of our approach we chose a specific case study in the field of integrated water resource management this case study was a specific project undertaken between 2005 and 2008 in the kat river valley in south africa farolfi et al 2010 the project implemented a commod approach for better management of water resources in a sub catchment hereafter following we refer to it as the kat river commod process in the next section we introduce the rationale of our approach in the third section we extensively describe our framework and illustrate it with our case study in the fourth and fifth sections we provide details of the implementation and results of a pilot experiment in the last section we discuss the limits and perspectives of the approach 2 rationale 2 1 experimentation in the social sciences experimentation is a growing practice in many social sciences several disciplines from psychology boring 1950 to sociology and more recently from social psychology moreno 1954 to political science druckman et al 2011 have introduced controlled experimentation in the laboratory to test hypotheses about the observed behaviour of human agents experimental methods in economics became popular around the end of the 20th century according to levitt and list 2007 economists have increasingly turned to the experimental modelling of the physical sciences as a way of understanding human behaviour peer reviewed articles using the methodology of experimental economics were almost non existent up to the mid 1960s they exceeded 50 per year for the first time in 1982 and by 1998 the number of experimental economics papers published per year topped 200 holt 2006 in experimental economics laboratory experiments enable the investigator to influence economic variables in a fully controlled environment and thus measure the impact of those changes on the agent s behaviour falk and heckman 2009 in other words the causal effects of economic factors are observed ceteris paribus this type of observation is almost impossible to obtain outside a laboratory environment in economics experimentation is characterized by a lack of protocol frame and the neutrality of the experimental framework which ensures that subjects do not reach an interpretation outside the scope of the tested hypothesis and give the greatest control to the experimenter czap et al 2012 that said several authors have pleaded recently for the introduction of elements of context in experiments as a way of improving the external validity of observations namely to improve the fact that generic results observed in the laboratory are also observed in the real world laury and taylor 2008 anderies et al 2013 farolfi et al 2014 according to michel guillou and moser 2006 contextualizing may also enable subjects to make context awareness explicit within their behaviour hence some tests have been performed to assess experimentally how players behave during games about natural resource management desolé 2011 these are preliminary results but it is now admitted that contextualized economic experiments which take part of the system complexity into account are important if we aim to understand stakeholder behaviour better including issues of water resource management janssen et al 2011a 2 2 the minsky triad conceptual framework marvin minsky s definition of the term model is both precise and generic it states as follows to an observer b an object a is a model of an object a to the extent that b can use a to answer questions that interest him about a minsky 1965 starting from that definition bonté et al 2012 proposed calling the three entities a b and a the minsky triad called t the relation between the observer and the object is called ρ o and the relation between the observer and the model is called ρ m the key idea of the framework was to build a model of the whole minsky triad itself in order to address questions related to the use of models in a given context therefore in order to study the interactions between the three entities of the triad the proposal made in bonté et al 2012 was to build a model t of the triad t the minsky triad conceptual framework was originally created to evaluate models of any systems that are ill defined incompletely known and which for whatever reason cannot be tested under real conditions such as economic systems on a country scale epidemics or natural disasters for instance where human lives are the main issue in this paper we explain how this framework can be used to study commod processes commod processes are characterized by a succession of models built iteratively each loop of model building is associated with a collective learning process in the kat river commod process three different versions of a model representing the kat river sub catchment were built two agent based models and one role playing game model farolfi et al 2010 we focused in this study on the first modelling loop during which the first model called kataware was built we refer to it hereafter as the kataware triad that we called t in the kataware triad t the object a was the whole kat river sub catchment the observer b was a group composed by the members of a recently created water users association at the level of the kat river the question that the group of stakeholders b had about the kat river sub catchment was as follows how can a catchment action plan in the kat river valley be collectively designed and more precisely how should water use licences be attributed to water users and at what price in order to answer to these questions the group b built the first version of the agent based kataware model which we called a b the general question that we had about this commod process was as follows does participatory modelling foster cooperation in the real situation in order to answer that question we followed our method to build the corresponding experimental design considering our case study the exercise could be summed up as follows we as researchers in experimental social science had a question about the kataware triad t and in order to answer that question we built and used a model of the kataware triad which we called t itself comprising three entities the first entity was a model of the situation in the katriver the second entity was a model of the group of stakeholders the third entity was a model of the kataware multi agent model built and used in the kat river commod process we chose or built these models according to the question we had about t in the next section we propose a general framework for building models of commod processes based on experimental economics we illustrate our framework by the presentation of our model of the kat river commod process 3 proposal the expecommod triad our general framework was called the expecommod triad it is summarised in fig 1 which can be read as follows in order to address research questions about the use of a model box a b within a commod process considered as the commod triad box t researchers in experimental social science circle c build a model of the commod triad box t in this context the relationship that the researchers in experimental social science have with the commod triad is that they have research questions about it arrow ρ o c from these research questions they can formulate hypotheses and design experimental plans that they will perform with the model of the commod triad arrow ρ m c the question of the observer c does not concern the model a b itself but the use of the model a b by the observer b consequently the model of the commod triad box t contains a model of each entity and relation present in the commod triad t we designated as the abstract nrm situation box a c the model used by researchers in experimental social science to represent the nrm situation a we designated as the meta model the model of box a used by researchers in experimental social science to represent the commod model a b we designated as the group of subjects the group of people in position b on which experiments were be performed and which are a model of the group of stakeholders b the expecommod triad called t is created in the process the observed object is the commod triad t the observer is the group of researchers in experimental social science c and the model is the model of commod triad t we present these three entities in detail in this section 3 1 the commod triad a great deal of literature is available on commod processes see a summary in étienne 2011 for instance and we refer to it for further details the synthetic vision that we propose here merely seeks to explain how we see such a process under the lens of the minsky triad framework 3 1 1 the nrm situation at one moment of the process the nrm situation a is specified by a scope defined more or less strictly by either a research project or a local development project or a combination of both in our case study the kat river commod process the nrm situation was scoped by the research action project called a stakeholder driven process to develop a catchment management plan for the kat founded by the south african water research commission the project established the area as the kat river quaternary sub catchment of 1700 km2 including 19 km2 of irrigated area and home to around 50 000 inhabitants in 2001 irrigation took up by far the majority of the water in the catchment and relied mostly on the kat dam situated in the upstream section of the catchment with a 24 10 3 m 3 storage capacity farolfi and rowntree 2006 fig 2 presents the kat river catchment and the main kat river water users 3 1 2 the group of stakeholders the group of stakeholders b is a heterogeneous group in which we distinguished four main types 1 stakeholders of the nrm situation who have been identified by the commod process for various reasons we will discuss these reasons when we describe their relations with the nrm situation 2 experts who have no stake in the situation but have expertise in the objects involved in the nrm situation 3 researchers or facilitators who lead the commod process 4 possibly the funding organizations of the process which may be external to the process research funding agencies local or national state departments international development agencies etc considering the heterogeneity of the group of stakeholders b we had to acknowledge that they may have different kinds of relations with the nrm situation which we called their involvement in the nrm situation ρ o relation we assumed three non exclusive possibilities for each individual in the group 1 knowledge the individual has information about the nrm situations 2 stake the individual has a stake in the nrm situation and 3 power of action the individual as a decision maker can change the nrm situation through his decisions in the kat river commod process the group of stakeholders was composed of the researchers involved in the research action project including hydrologists economists social scientists computer sciencists etc and the members of the kat river water users association composed of representatives of different categories of farmers in the area and representatives of domestic water users from different parts of the area in this study we focused on the group of farmers all farmers had some stakes knowledge and power of action at their levels of the catchment 3 1 3 the commod model even though the commod community is not restricted to a specific kind of model the commod models a b used and built during commod processes usually share some common characteristics and acknowledge commonly used paradigms indeed since nrm situations involve and are usually determined by the decisions of stakeholders regarding the situation it is interesting for the a b models to explicitly represent the beliefs goals and decision processes of these stakeholders for this reason the most commonly used paradigm is the multi agent system paradigm in which the world is represented as a set of objects situated in an environment and manipulated by autonomous agents who represent social entities and can modify the object of the environment move communicate etc this paradigm can easily be mapped either to computer agent based models abm or to role playing games rpg when rpg models are used stakeholders are invited to play their own roles in order to represent and discuss scenarios that can happen in their nrm situation barreteau 2003a the version 1 of the kataware model which we focused on in this study is an abm it is extensively described in farolfi et al 2010 3 1 4 involvment of the group of stakeholders in the commod process depending on a the kind of model used b the question addressed by the commod process and c the nature of the group of stakeholders the involvement in the commod process of the group of stakeholders relation ρ m can have several dimensions for this relation we assumed four non exclusive possibilities of action and four non exclusive possibilities of intention the actions may be either facilitating the modelling and simulation activity and providing the modelling language the individuals usually the facilitators provide a language to build the model and facilitate the process building the model the individuals take part in the modelling process simulating the model by role playing the individuals take part in a participatory simulation of an rpg model where they are invited to play a role simulating the model by changing parameters and observing simulation results the intentions may be either to learn about the system the individuals want to understand how the nrm situation works learn about the strategies of stakeholders or decision makers the individuals want to understand strategies of specific stakeholders or decision makers use the model to convey a message the individuals want to use the model simulation or model building process to influence other members explicitly or implicitly or hide a strategic behaviour the individuals participate in the process for some specific reason but do not want to expose their strategy in the kat river commod process considering the group of farmers and the building of version 1 of the kataware model which was an abm we considered that these farmers had participated in building the model see fig 3 left and in simulating the model by changing parameters and observing simulation results see fig 3 right we did not measure the intentions that these stakeholders had when participating in the kat river commod processes considering farmers we could assume that all the intentions listed above were potentially present 3 1 5 question addressed by the commod model the last remaining element of the commod triad is the question addressed by the group of stakeholders although the group of stakeholders is heterogeneous and has a complex involvement in both the nrm situation and the commod process and even though the question addressed by the commod process is dynamic it may change during the process the question is usually precisely expressed at any moment of the process since it is part of the contract established between all the participants in the commod process in the kat river commod process as mentioned above the question was to design a new catchment action for the farmers of the wua one of the main issues was access to water rights that might enable the use of water from the kat dam which at the time was only available for scheduled farmers see fig 2 3 2 a question about the commod triad the objective of our approach was to use models sensu minsky to reflect upon commod processes we may wish to raise numerous questions about commod triads but we have very little visibility in terms of defining the limitations of the type of question that can be addressed using models based on social experimentation computer models have been built and used to address questions about some aspects of the commod triad for instance an agent based model was designed by emmanuel dubois to assess how player attitudes can change during a role playing game depending on the game settings dubois et al 2013 however the impact of the participatory modelling activity has never been explicitly addressed by the use of a model in our case study we proposed to address a specific question about this in our case study our question about the t commod triad described above was as follows does participatory modelling foster cooperation to answer this question we proposed the model of the commod triad described below as in any modelling process the question asked already scoped the system to be represented we looked at the effect of participatory modelling activity and not at the effect of an entire commod process where participants inhabit the system they model usually simulate or play with the model they build etc 3 3 a model of the commod triad in order to build a model of the commod triad we needed to identify an object or a set of objects and concepts that could be used to represent the commod triad moreover we wanted to be able to perform reproducible controlled experiments on this object or set of objects which we used as a model and we wanted to be able to identify all the entities and relations presented previously as part of the commod triad 3 3 1 modelling the group of stakeholders we propose to use theories and practices from experimental economics in order to use groups of people to represent the group of observers b of the commod triad in accordance with minsky triad framework we designate this group b and we called it a group of subjects university students randomly chosen with specific methods are commonly used in experimental economics to represent a generic group of people falk and heckman 2009 following the prescriptions of experimental economics the subjects for the experiments are chosen among university students and are paid at the end of the game sessions according to their performance during the session harrison and list 2004 eber and willinger 2005 in our case study we constituted groups of four people from the pool of subjects at the laboratory of experimental economics in montpellier leem 3 3 2 modelling the nrm situation the model of the nrm situation used in the model of the commod triad may be very simplified abstracted compared to the nrm situation of the commod process we propose to build it as a controlled role playing game in which players are put in a similar situation to that of the stakeholders of the commod triad of course the similarity of the situations has to be measured with regard to the research question about the commod triad level of knowledge stakes and power of decision that stakeholders have regarding the nrm situation in our case study we wanted to take into account the fact that the nrm situation of the commod triad was about water management and agriculture and that there was an asymmetry of access to the resource and to the associated infrastructure we also needed to represent the fact that the stakeholders had stakes in the situation and some power of action over it since our research question was very general and the players of the game were mostly students who were not well aware of complex nrm situations we tried to find the simplest rpg that could respect our constraints and in which we could measure whether the players cooperated or not hence the model of the nrm situation that we considered was the textbook case of an irrigated scheme with several farmers dealing with the double problem of provision to a public infrastructure contribution to the operating costs of a borehole providing supplementary water to the scheme in the event of drought and extraction from the common pool resource represented by the water available through the irrigation scheme it referred to the case used by janssen et al 2011a b where the authors combined a public good game with an extraction of common pool resource cpr game in which players must first decide how much to contribute to the cpr and then how much to extract from it for their own payoff in order to put the players in this situation we used elements of the wat a game modelling tool kit widely used in commod processes involving water management abrami et al 2012 2016 using this modelling language modellers can use pebbles of various colours to represent resources such as water or money land plot cards to represent land plots owned by the players activity cards to represent activities consuming and generating resources and river path cards to represent canals during each turn of the role playing game built with these elements a facilitator makes the water pebbles flow through a network composed of river path cards and land plot cards when the pebbles reach a land plot on which an activity card stands the owner of the land plot cards can choose to extract water pebbles from the river in order to perform the activity and gather the resources generated by that activity at the end of the turn players can change the activity cards standing on the land plot cards they own for this study we computerized the wat a game as a network game coded in the netlogo agent base modelling and simulation platform so that we could control the information available to the players fig 4 presents our conceptual model of the nrm situation on the left and the graphic interface of its implementation as a computerized wat a game rpg the details and implementation of the wag rpg are described in section 4 3 3 3 modelling the involvement of the group of stakeholders in the commod process the relation between the model of the nrm situation and the group of subjects may not be exactly the same as that between the group of stakeholders b and the original nrm situation a since we do not want to face the same issues as in the real commod triads where experience is hardly reproducible however some aspects of the relation remain to be studied such as knowledge about the situation or even stakes in the situation most importantly the group of subjects b must be able to build the meta model a as their own representation of the model of the nrm situation built in order to answer a question they have about that situation to do so and in order to have reproducible controlled experiments we need at least a pre defined modelling language limiting the noise that would occur if any kind of model was possible thus the model of the commod triad must include a modelling language that the group of subjects can use to build the meta model a hence the relation of the group of subjects to the meta model ρ m relation must at least include the modelling activity it may also include some of the intentions and actions that the original group of stakeholders b may have with the original model a b presented in the commod triad subsection section 3 1 4 the group of subjects may also somehow have some power of action stakes information etc in the model of the nrm situation in order to represent the relation of the stakeholder of the commod triad to the real nrm situation in our case study the groups of subjects participated in a modelling activity with pens and post its during which the members of a given group did not have the same pieces of information and they were told to engage in a role and build a model of their situation as a drawing see fig 5 this first activity represented the relation that the stakeholders had with the model in the commod triad ρ m the groups of subjects were then asked to play the computerized wag rpg following the precepts of experimental economics this phase took place in a laboratory of experimental economics under controled conditions see fig 6 the players were paid according to their results in the game in the pilot experiment the participants earned from 7 euros to 60 euros for a 2 h experiment this second activity where the players had power of action and stakes in our model of the nrm situation represented the relation of the stakeholders to the nrm situation in the commod triad ρ o 3 3 4 modelling the model as is the case for the models a b used by stakeholders of real commod triads the models that we can use to represent them in models of the commod triad the meta model a may have several forms from conceptual models drawn on paper up to abm in our case study we used drawings used as conceptual models by the groups of subjects such a model can be seen in the table in the middle of the picture fig 5 3 4 the experiment and its analysis ρ m c following the general framework of the minsky triad now that we had specified the t model we needed to specify which experimental plan which set of experiments would be performed on this model in our case study we wanted to test the following hypotheses h1 and h2 h1 if people take part in the participatory building of a model representing a situation in which they have a stake in shared resources and in which they have power of action they will change their behaviour once they are placed in this situation h2 if people take part in the participatory building of a model representing a situation in which they have a stake in shared resources and in which they have power of action they will cooperate more once they are placed in this situation in order to test these hypotheses and following the precepts of experimental economics we propose to submit a population of students to two different treatments t0 and t1 in our case study for each treatment n groups of 4 players called g i j were composed where i t 0 t 1 was the treatment number see below and j 1 n was the index of group j of a given treatment i groups submitted to t0 were asked to have some group activity unrelated to the nrm situation and then to play to the computerized role playing game the model of the nrm situation groups submitted to t1 were asked to build the meta model a and will then were asked to play the computerized rpg the model of the nrm situation the level of cooperation of the groups of subjects was assessed in two dimensions their total contribution in the public infrastructure the more they contributed the more we considered that they cooperated and their choice of activity as described in section 4 1 4 details and implementation of the case study model of the commod triad 4 1 the computerized role playing game the anawag device includes a client server network game module see appendix d such that the experimenter can stand behind a server computer and each player stands behind a separate computer with a client interface displaying only a chosen set of information and allowing only a chosen set of possible actions we calibrated the game in order to be able to measure the cooperation or non cooperation of players and to limit the number of players and the duration of the game as repetition is necessary in order to create the conditions in which players can learn we considered a repeated game with 15 rounds per session the irrigation scheme was fed by two sources of water the surface water source supposed to come from a reservoir regularly filled with rain the amount of surface water was known by the players and always equal to 1 unit of water the ground water source whose delivery depended on the players investment representing their contribution to the public infrastructure see fig 7 and section 4 1 below each player possessed one plot of land where he could place an activity card each activity needed resources wags the money and clean water produced wags and eventually rejected clean water reusable in the irrigated scheme the activities available are presented in table 1 an activity was entirely defined by the type and quantity of resources it needed and the type and quantity of resources it produced for instance activity a3 consumed 2 units of water and 1 wag and produced 1 unit of water and 3 wags in order to set up on a field a player had to invest the monetary resource needed wag in in table 1 if the water available was not sufficient there were fewer water units in the river at the level of the field than the water in units requested by the card the investment was lost and no resource was produced otherwise the player received the produced income wag out and the produced amount of water water out flowed back to the river at each turn of the game all the players made two individual decisions they chose how much to invest in public infrastructure the total investment of the group would determine the water available from the public infrastructure as shown in fig 7 the activity to put in their fields which implied the water extraction level according to the figures presented in table 1 a report on the status of their own savings and on the quantity of the remaining water downstream of the irrigated scheme was shown to players after each round investment in public infrastructure the production function for public infrastructure depended on the sum y i 1 4 y i where y i was the contribution of player i in order to capture some aspects of the nature of irrigation systems namely increasing returns to scale for lower levels of investment and decreasing returns for higher levels we employed a linear production function presented in fig 7 referring to anderies et al 2013 and thinking about the kat river dam of our case study we chose a scaling that produced a range making it impossible for one person to create a public infrastructure without the help of the others investments in activities after having made the water resource available the second investment of players took the form of the activities they chose to set up on their lands as described in table 1 this choice was related to the profit that the card can provide and the risk they take of losing their investments if there is not enough water this decision involved two uncertainties 1 the uncertainty of the investments that would be made in the public infrastructure responsible for the amount of ground water supplied by the public infrastructure 2 the uncertainty of the activities to be played by upstream players final payoff of players the payoff of a player i for each round r resulted from the payoff derived from the production of their activities minus the amount of wag invested in the public infrastructure the final payoff given by equation 1 was computed as the sum of the payoffs of all repetitions 1 p i r 1 r e y i r c i r o k c i r o u t c i r i n where r 1 15 is the index of the repetition p i is the total payoff of player i e is the initial number of wags given to each player at each repetition y i r 0 3 is the number of wags invested in the public infrastructure by player i at repetition r c i r a 1 a 2 a 5 is the activity card played by player i at repetition r c i n is the number of wags needed for the installation of activity c wag in in table 1 c o u t is the number of wags produced when activity c was performed wag out in table 1 c o k 0 1 specifies whether the activity was performed enough water in the river or not not enough water in the river if a player did not get the water he needed through one of his activities he was not paid for that activity and lost the wag invested in that one measuring cooperation we had two indicators to measure player cooperation the first was the total contribution to the public infrastructure and the second was the activity cards that players play in order to qualitatively estimate whether groups had a cooperative or selfish behaviour we compared their actions to economics equilibrium cooperative players would coordinate in a stable and durable way to reach a cooperative equilibrium where all players would have the same payoff players would all contribute the same amount 1 3 wags each and would play all the same card a3 if the group contribution is 4 or a5 if the group contribution is 8 12 the corresponding group payoffs would be 4 if group contribution is 4 all play a3 8 if group contribution is 8 all play a5 4 if group contribution is 12 all play a5 the optimal equilibrium is when all contribute 2 wags each and play a5 then they would reach a group payoff of 8 highest group payoff corresponding to equal individual payoffs on the other hand perfectly selfish and informed players would reach a nash equilibrium where player 1 the only one that can take advantage of surface rainwater would contribute 3 wags and plays card a5 for a net payoff of 1 all other players expecting that player 1 contributes 3 would contribute the minimum 1 necessary to play the card that would give them the highest possible payoff a4 with the minimum effort this would produce a group investment of 6 for a group payoff of 7 hence we created a model of the nrm situation representing the kat river case study in which we had individual stakes a public infrastructure asymmetric access to the resource and to the infrastructure and a benefit from cooperating one of the issues of the cooperation was a management issue since upstream players needed to understand that downstream players would be interested in contributing only if they derived some benefit from their contribution 4 2 the pilot experiment preliminary analyses were conducted over 300 observations produced by an experimental pilot session undertaken over 15 repeated periods on 5 groups of 4 subjects each two groups were assigned to the treatment t0 that is the puzzle treatment noted treatment p below andthree groups were assigned to the treatment t1 that is the model treatment noted treatment m below instructions for the two treatments are available in the appendix 5 results of the pilot experiment a summary of the descriptive statistics concerning the main variables analyzed is included in table 2 5 1 individual choices by treatment the results show that there was no treatment effect in terms of individual contribution which was close to 1 43 wags in both treatments wilcoxon mann whitney test p value 0 936 in terms of the choice of activity cards and therefore the strategy of resource extraction after conversion of the labels of cards a0 a5 to numbers 0 5 the average card played by individuals was 4 34 for m and 4 12 for p a treatment effect was detected wilcoxon mann whitney test p value 0 015 on the categories and 0 0495 on the labels of the cards converted in numeric values the resulting average individual payoff per period was 0 72 wag in the m treatment and 0 60 wag in the p treatment running a chi2 test on the distribution of average individual payoff per period a treatment effect was shown with a p value 0 013 the distribution of the individual payoff per period showed that extreme values positive and negative were more frequent in the m treatment globally individual payoffs of 1 3 amounted together to 60 of occurrences and 1 was largely more frequent in the p treatment while 3 dominated in the m treatment fig 8 shows the dynamics of the individual cumulated payoffs in the two treatments the plot of the m treatment was consistently above that for the p despite a decrease in the last 3 periods and the average individual cumulated payoff was 6 9 wag in the m treatment and 4 09 in the p treatment a t test p value 0 024 showed that there was a significant treatment effect over the whole session 5 2 comparison of results with expected equilibria in the experiment players in both treatments contributed an average amount per round of 1 43 wag close to 6 wag group while the average card chosen was between a4 and a5 4 34 in model and 4 18 in puzzle these average choices were very close to a nash equilibrium but due to free riding of upstream players they led to much lower group payoffs than what would be expected in a nash equilibrium 2 8 wag and 2 4 wag respectively for the m and the p treatments instead of 7 if players had played the nash equilibrium as explained in section 4 1 this distance from equilibrium might be explained by the fact that players within each group had different behaviours depending on their position players upstream 1 and 2 played higher activity cards than players downstream 3 and 4 players downstream conversely tended to invest more in the public infrastructure certainly hoping that the upstream players would not free ride on the common resource produced this different behaviour between players with asymmetric access to the resource in a group provoked gaps in terms of individual cumulated payoffs far from cooperative equilibrium fig 9 shows the average individual cumulated payoff per player 1 4 in the groups of treatment m and in the groups of treatment p in the groups of treatment m more extreme behaviour was observed bringing higher payoff to player 1 and leaving player 4 with negative payoffs while in the groups of treatment p player 1 extracted less common resource especially during the first ten periods this allowed the three other players to finish the game with non negative payoffs 5 3 learning and individual decision making in order to better understand the process of individual decision making a multi level mixed effect linear regression analysis was run on the individual level data of investment contribution to ground water extraction and choice of activity card corresponding to the water extraction level the impact of three variables representing the information available to the subjects about their choices or their situation at the time of decision making t or in the previous round t 1 was estimated the regression estimated the player s investment at time t according to the activity played at time t the round t the profit at time t 1 and the value of the dummy variable not played at time t 1 indicating whether or not the player received enough water to play his activity card at time t 1 the regresssion was estimated separately for the two treatments m and p whatever the treatment the decision to invest was significantly and negatively affected by the individual profit at t 1 as if a good level of payoff reached previously would push the subjects to reduce the level of contribution to the common resource free riding on the group to have an even higher payoff in round t we observed a significant and negative impact on individual contributions of the not played variable at t 1 clearly the occurrence of such an event impossibility of playing a card in the previous round pushed the players to reduce their investments at time t as we observed in the data that this occurrence was more frequent for downstream players we considered that such a behaviour corresponded to the social sanction that downstream players could impose on upstream players seen as stationary bandits janssen et al 2011b playing a higher activity card in round t had a positive impact on the player s investment at the same period in the m treatment but it was not significant in the p treatment is and lastly there only seemed to be a learning effect negative and significant correlation with the variable round in the m treatment in fact trends for investment were steadier and decreasing in m than in p 5 4 answsers to our research questions and hypothesis although this was only a pilot experiment so the sample was not large enough to be statistically significant some preliminary thoughts can be expressed on our hypotheses h1 was partially confirmed there seemed to be a treatment effect in terms of the choice of activity cards and in the distribution of individual payoffs but not in terms of contributions the groups in m treatment earned more but there was more of a gap between players h2 was not confirmed on the contrary compared to another collaborative activity in a group participatory modelling seemed to favour free riding and aggressive behaviour by upstream players especially p1 while p3 and p4 remained prone to invest even when loosing and allowing p1 to free ride despite a certain social sanction behaviour observed in both treatments 6 discussion 6 1 using experiments as simulations in their paper in science janssen et al 2010 explain that they used methods of dynamic decision making in order to perform controlled experiments that examine the relevant complexity of social ecological systems themselves refering to dörner 1996 for the use of computerized microworld in experiments about organisation management our questioning was on an higher level of abstraction we reflected on the use of a model to think about the social ecological system but we used experimentations in the same way i e to represent the relevent complexity of social ecological systems in the exercise to clarify the position of these experiments in our questionning we referred to guala 2012 who studied the epistemic relations between models simulations and experiments in his view of social experiments we used hybrid entites between simulations and experiments we brought some material from the real world the human subjects into the laboratory but we do not claim that our experiment exactly reproduced a phenomenon of the real world the minsky triad makes it explicit that we simulated a model using guala s words we decided to speak about simulating experiments using models of this nature we are able to imagine an experimental platform in the sense of muniesa and callon 2007 which for instance by substituting the current cards by value cards where agents could express their views on water management could serve as a basis for experimental sociology richard ferroudji 2008 or for experiments in other social sciences these models could constitute frontier objects to facilitate dialogue among various specialists of these disciplines in a community of practice at the interface between science action and policy making 6 2 a new kind of meta models the concept of the meta model a model of a model may differ from one community to another and is directly related to the definition given of the concept of model in the community of theory of modelling and simulation led by bernard zeigler zeigler et al 2000 modellers consider models of dynamic systems in this community a model is evaluated according to the way it reproduces or not the behaviour of the system it represents within a specific experimental frame therefore a meta model is considered as another object that has statistically the same behaviour as the model zeigler et al 2000 for a given experimental frame and at a given level of specification in agent based modelling in ecology or environmental science modellers have a more conceptual understanding of a model whereby a meta model is a set of concepts that constitute a generic model general enough to be specialized in less abstract more specific representations of the system under study treuil et al 2008 in this paper and following the general framework of the minsky triad an object was considered as a meta model as long as it was used in our reasoning to represent another model used for a specific purpose by a specific observer with this definition we considered an object as a meta model only if we also modelled the observer the object modelled and their interactions this definition was particularly suited to the study of commod processes where we assumed that the object modelled the nrm situation was modified by the use or creation of the model by the observers for that reason the outcomes of a commod process are extremely difficult to observe in the real world with the model of the commod triad it was possible to repeat experiments and measure outcomes in the laboratory 6 3 using our approach to learn about commod processes 6 3 1 when should this approach be used we could not imagine a specific type of questions about the commod process ρ o c in the t framework presented fig 1 that would require the use of this approach referring to the study on the kat river commod process presented in this paper we saw that it implied questions about power asymmetries finding new cooperative arrangements and assessing the impact of the participatory modelling process there are several ways of studying these questions without building a model of the commod process some studies have been conducted for instance by interviewing several researchers who implemented different commod processes see for instance barnaud et al 2014 for a study about power asymmetries in commod processes some others analysed several commod processes with the same observation protocol see for instance perez et al 2011 for a study on monitoring and assessing of the impact of commod processes some others compared commod approaches with other participatory methods based on case studies and a shared analysis grid see for instance berthet et al 2016 about fostering agroecological innovation on the other hand we believe that many questions that social scientists have about commod processes can be addressed with this approach however we know that we will be restricted by the nature of our model for instance in order to answer our question we can imagine an experimental setting where subjects would follow a complete commod loop a first phase where players play a second where they build a model and a third where they play again however the different possible situations in the first phase would have distilled the results and such an experimental setting would require many more observations in fact the minsky triad conceptual framework should be used when a model of a commod process is built thus the motivations that we can imagine are the same motivations as those that researchers can have to build a model varenne 2018 organises the different functions that a simulation model can have in 5 categories i to ease experimentation ii to ease comprehensible formulation iii to ease theory building iv to ease communication and cooperative building of knowledge v to ease decision making and action we believe that regardless the research question about the commod process a model of this process can be built for many reasons included in any of these five categeories 6 3 2 what is the validity and generality of our model as in any modelling process the validity of the model of the commod triad depends on the question that we have about the commod triad and on the function we give to our model in our questioning in the introduction we stated that our aim was to ease experimentation as for many reasons explained above we cannot reproduce the same commod process as many time as needed we reproduce it in the laboratory and study it in vitro however the question we had about the commod processes was very generic consequently the model of the nrm situation that we used to represent the kat river nrm situation was very simple and very different from the kat river situation we actually used the kat river situation to induce a generic model of commod processes that helped us to reflect upon a generic question we had about commod processes in general thus the results of our experiment will not teach us many things about the kat river situation but more about a general theoretical hypothesis about the effect of commod processes on natural resources management issues in other words our model of the nrm situation represented a common and generic problem in water management and could certainly be used to reflect upon many specific commod processes in a rather abstract way we believe that this approach is well suited to addressing generic and theoretical questions about the impact of a modelling activity in a commod process firstly because we can generalize situations and secondly we can repeat experiments at will however the knowledge built with these models the results and demonstrations made will remain theoretical and will need to be confirmed by studies in the field on real commod processes we consider our model of the commod triad as a crutch for thinking about commod processes in a theory building perspective the more detailed our models of the commod triad are the richer will be the discussions that we can have about them for instance a salient question about commod processes is the way they interfere with existing institutions formal or informal that frame the actions and perceptions of stakeholders we plan to continue developing the anawag platform in order to use t models to represent these institutions we are confident that this task is possible because the wag modelling kit proposes a way of representing such institutions abrami et al 2012 and extensive literature is available to describe these institutions based on a common analytical framework proposed by ostrom 1990 a framework already exists for modelling these institutions in agent based models using the framework proposed by e ostrom ghorbani et al 2013 7 conclusion the work presented in this paper presents a proof of concept showing that the general framework of the minsky triad is both necessary and well suited to exploring theoretical questions about companion modelling processes we did not perform the full simulating experiment that we designed and only have the results from a pilot experiment however we were already able to see in our model that companion modelling could have an effect on resource management it was our first hypothesis in the way we modelled companion modelling we observed that it increased the efficiency of resource management we also observed that in the way that we modelled commod processes the participatory modelling activity increased the inequality among stakeholders compared to another collaborative activity we found several possible explanations for this observation and we need to perform the full experiment to discriminate between them it is interesting to see that this observation gives rise to new hypothesis on the effects of companion modelling processes for instance we believe that this increased inequality is maybe due to the fact that participants are more cooperative and that this decreases the social sanction effect assumed to regulate inequality according to the economic theory 8 software and data availability the model code and data used is published on the comses platform bonté et al 2019 with the documentation presented in appendix d below all the sotfware packages used are free of charge and open source platform netlogo 5 3 1 programming language netlogo operating system platform independent model code licensed under gnu gpl version 3 netlogo software is authored by uri wilensky email uri northwestern edu phone 847 467 3818 fax 847 491 8999 offices annenberg hall 337 ccl lab phone 847 467 7593 ford lab phone 847 467 2838 the anawag platform has been programmed under the netlogo software by bruno bonté and mamadou ciss diallo who are authors of this paper see contact information in the authors section appendix a modelling activity instructions for modelers instructions were distributed to each subject then they were asked to read them and an experimenter read them aloud instructions changed only in the position asigned to the player upstream in the middle or downstream we translated the instructions in the paragraph below instructions for modelers you are part of a group of 4 subjects you are a farmer who is a member of a user association that manages an irrigated system upstream farmers have priority in terms of access to water over those in the middle or downstream you are a farmer located in the middle upstream downstream of the irrigated system your objective is to build with other farmers a model that represents your irrigated system and will help you discuss system management strategies you have a kit that allows you to represent an irrigated system with four irrigators and a water source drilling positioned upstream of the system the system is gravity based so surface water from the nearest dam enters the upstream irrigated system each farmer has an irrigated plot the following elements are at your disposal to model your system a sheet of flipchart felt pens colored post it notes you have 15 min to build your model example of model fig a1 presents an example of model built by the subjects fig a1 example of model fig a1 appendix b puzzle activity instructions for puzzle players instructions were distributed to each subject then they were asked to read them and an experimenter read them aloud we translated the instructions in the paragraph below instructions for puzzle players you are part of a group of 4 subjects your goal is to solve a 28 piece puzzle together in 15 min you have an illustration containing the solution of the puzzle divided into 4 quadrants each subject has a quadrant and cannot share it with the other three subjects one piece of the puzzle at a time can be moved exchange with another piece only one player at a time can work on the puzzle each in turn clockwise puzzle the image ask to rebuild is presented in fig b1 it was printed on a a3 page and then cutted in 28 pieces 7x4 that were placed on the grid in random positions fig b1 puzzle image fig b1 appendix c role playing game instructions instructions the experience you are about to participate in is intended for the study of decision making we ask you to read the instructions carefully they should allow you to fully understand the experience when all participants have read these instructions an experimenter will read them aloud all your decisions will be treated anonymously you will indicate your choices to the computer you are sitting in front of from now on we ask you to stop talking if you have a question raise your hand and an experimenter will come and answer you in private during the experiment you will accumulate earnings expressed in experimental currency units the wag at the end of the experiment your accumulated earnings will be converted into euros at the conversion rate 1 wag 1 euro general framework you are one of four members of a group of farmers in an irrigated system who share a borehole to irrigate their fields the amount of water produced by the borehole depends on the maintenance provided by the group the more the group contributes to the maintenance the more water the borehole will produce the fields of the four farmers are aligned along an irrigation channel water arrives first in the fields of the first then in the second etc your position 1 2 3 or 4 will be indicated at the beginning of the game and will remain unchanged until the end of the game you will be able to use the water from the canal to carry out your activities these activities are represented by activity cards that you can install on your field the activities have a cost 1 2 wags depending on the activities and generate revenue 1 6 wags as explained in the glossary the game is repeated 15 times you will have 5 training rounds beforehand which will not count in your remuneration water availability there are two sources of water surface water rain and groundwater from drilling by default one unit of surface water comes from the rain every turn the amount of water produced by drilling each tower depends on the amount of money invested by the group each tower in its maintenance fig c1 shows the number of units of produced water on the ordinate as a function of the total contribution invested by the group on the abscissa outline of a turn a turn lasts 30 s you will have a countdown at the top right of the screen each turn you can invest up to 5 wags 0 to 3 wags in drilling maintenance action 1 and 0 to 2 wags in an activity card action 2 action 1 to invest in drilling maintenance you must position the cursor under the corresponding number see image 1 action 2 your field is highlighted and you can choose the activity you want to perform by clicking on one of the cards in the left column see image 1 at the end of the tour the water rain drilling possibly water produced by the activities flows from the upstream top left to the downstream bottom right and is gradually distributed in the fields gain for each turn your gain is determined by the income generated by the chosen activity minus the investment in drilling maintenance and the cost of the activity card example you contribute up to 1 wag to the maintenance of the borehole and choose map 4 this requires two water units and an investment of 1 wag and in return it generates an income of 4 wags if at least two units of water reach the field your gain is 4 income 1 activity cost 1 drilling investment 2 wags if on the other hand less than two units of water reach the field your gain is 0 income 1 activity cost 1 drilling investment 2 wags fig c1 drilling water production based on the group s contribution fig c1 image 1 interface actions4 image 1 image 2 interface informations5 image 2 glossaire image 6 field the position of your land in the irrigated system is represented by an exaggeration of your color image 7 water water is represented by drops each representing one or more units of water here a unit of water in the activity maps the water needs and the water discharged is symbolized by blue dots image 8 image 9 wag wags are represented in the activity cards by yellow squares they represent your economic resource your actions in the game will cause you to win or lose wags each game turn image 10 drilling produces water from the borehole image 11 rain produces natural srface water image 12 the activity cards there are 5 different activity cards that you can make on your field the activity requires a number of wags image 13 and water units image 14 to be realized upper part of the map it rejects a certain amount in return and if it receives all the water it needs it is successful and produces money lower part of the map once the activity is placed the number of wags necessary for its realization will be deducted from your profit of the corresponding round if the activity is successful the money it produces will be less expensive and your contribution to the drilling will be less of a benefit to you example if a player wants to play the a3 card above he must invest 1 wags if it receives two units of water the activity is successful and the player who installed it will receive 3 wags in addition a unit of water received by the field will be returned to the irrigated system imagine that the player has invested 1 wag in the maintenance of the borehole and the activity is successful his profit for this round will be 1 wag 2 wags invested and 3 wags won appendix d the anawag device the anawag device code and documentation can be downloaded from the comses model library at the following link https doi org 10 25937 5j66 e528 below is the user guide do not hesitate to contact authors for any help for use or design of new features anawag user guide table of content purpose structure of the anawag device setting experimental parameters experimenter modelling experimenter design a watershed model play experimenter organise and run a network game play player participate to a network game simulate experimenter run simulations with computerized players download and installation of anawag details and implementation in netlogo purpose the anawag device for analyse wat a game wag is a computer version of the wat a game paper and pebbles modelling and simulation tool for water management see abrami et al 2012 1 1 abrami g ferrand n morardet s murgue c popova a de fooij h farolfi s du toit d aquae gaudi w 2012 wat a game a toolkit for building role playing games about integrated water management in r seppelt a a voinov s lange d bankamp eds 2012 international environmental modelling and software society iemss 2012 international congress on environmental modelling and software managing resources of a limited planet pathways and visions under uncertainty sixth biennial meeting leipzig germany it enables to perform the three activities below 1 build up a wat a game model representing a watershed that may also be seen as an irrigated scheme 2 simulate the model by playing it as a network game in an experimental design 3 simulate the model with computer agents instead of players the aim is to make possible to perform experiments in the understanding of contextualized experimental economics in which subjects can build role playing game models as the one built during participatory processes and then play to the model they built in this actual version anawag is designed to realize the specific experiment presented in a scientific paper 2 2 bruno bonté stefano farolfi nils ferrand géraldine abrami mamadou ciss diallo dimitri dubois anne johannet wanda aquae gaudi building new kinds of meta models to analyse experimentally companion modelling processes in the field of natural resource management environmental modelling software 2019 issn 1364 8152 https doi org 10 1016 j envsoft 2019 07 011 however it can be easily reused to design other experiments structure of the anawag device we distinguish two kinds of users of the anawag device the experimenter who can set experimental parameters build a watershed model run a simulation with computerized agents run a game session with human players the players who can play a game session entities state variables and scales of the wag model entities of anawag device model correspond to the entities that exist in the wag role playing game and in a watershed system in general players that represent water users waterpaths that represent the river fields that represent elementary spatial units activities that represent uses of resources water resource and eventually other resources to produce other resources and that must be installed on a field entity pumps that enable to withdraw water from the river to bring it to the fields outlets that represent the out flow from fields entities to the river sources of water that brings water to the waterpaths water resource that can flow along river path and wag resources that represent money the conceptual model of entities and their state variables is presented in an uml class diagram in figure below anawag main entities and state variables image 15 there are three main levels of spatial scale in the wag modelling language the level of the field that is the same level of the activity in the spatial scale it represents the elementary unit spatially and temporally indeed the transformation of resource described by all activities are processes that occur at the same level of spatial and temporal scale this level however is not specified at this point it depends on each wag model in the model used in bonte et al under rewiew which is theoretical we can consider that the spatial level is a plot of an watershed the level of the farm or set of fields owned by a player is the spatial scale of strategic decision making since it determines the stakes of each players in the model used in bonte et al under rewiew each player own one or several plots the level of the watershed is the greater level that contains all entities in the model used in bonte et al under rewiew it represents a watershed managed by four farmers and supplied by one natural source of water rain from upstream and one artificial source of water pumped from an aquifer the temporal resolution is the year or the time to execute an activity it corresponds to a round of the game the temporal extent is the number of rounds setting experimental parameters experimenter the first feature enables the experimenter to set up the parameters of a session group numbers duration water supply parameters and to choose the activity to perform modelling simulation or network game the corresponding interface is the general interface displayed below opened when the file is open anawag main inferface set parameters and choose activity image 16 to change parameters values replace the value by the value of your choice and press enter to start an activity click on the button parameters to set are the following define the context i and j indexes used to save data and relate it to a simulation or a group of players nb players number of players agents in the watershed initial w number of units of money at the initialisation of each round rounds maximal number of rounds during a simulation or a game max investment maximal possible investment in the water harvesting public infrastructure define the natural water parameters min natural water minimum natural water in random natural sources max natural water maximum natural water in random natural sources forcast error error factor in natural water forcasting choose activity choose one of the following activity described in the next sections of the guide modelling experimenter design a watershed model play experimenter organise and run a network game play player participate to a network game simulate modelling experimenter design a model of watershed the modelling feature enables to realise the model of an watershed model as presented in bonté et al 2019 2 figure below presents the interface in which an experimenter already started to draw a water shed with 4 players agents a field a river reach and a water source visible in the drawing area the user may load or save his watershed and modify existing watersheds anawag modelling inferface draw your watershed image 17 click on run button to start the activity draw your watershed by drog and droping elements from the tool area to the drawing area eventual options will be proposed when you install elements owner of the fields kind of the water sources save or load your wartershed with corresponding buttons play experimenter organise and run a network game the play activity enables to realise the network game model activity organised as a client server architecture based on hubnet in which when clicking on the play button a windows open and the experimenter must first start a network session to which players will connect he or she must just enter a session name and click on the start button see figure below starting a network session window image 18 enter session name choose to broadcast session so that players can see the session when they open clients click on start once the session is started the experimenter can monitor and manage the clients connexions see interface below managing client connexions with hubnet control center interface image 19 you can see connected clients here one client bruno and disconnect them eventually kick button you can see server address and port you can open local client connexions local button you can send messages to clients the experimenter manages the server interface see figure below with which he can monitor players actions and decide to start pause or resume the game a game session is by default initialized with the default example watershed but you may load another existing watershed the anawag play inferface experimenter manage a game session image 20 the example watershed model is loaded by default if you want to use another one you need to click on load button and choose the watershed model you want to play when you click on run button each connected client is associated to a player of the watershed by order of connexion supernumerar clients are not associated here there is only one client connected bruno and he is associated to the red player player 1 before starting the game you may set the speed of drops they run through the watershed at the end of each round and the round duration 3 possibilities there may be some issues with client messages sent during pauses if this happens clik on clean server buffer and set back the start pause switch on there may be some issues in visualizing the space all or part in gray if it happens click on refresh view the players are presented in next section see next section play player participate to a network game the players manage their client interface with which a player can at each round monitor his own activities and status choose his participation to the public infrastructure and change the activities to implement on his plots by clicking on a plot and choosing an activity card in the legend client must first run the hubnet client software executable file in the root ot netlogo installation folder that you just need to copy and paste on your computer and connect to the server using the hubnet client connexion interface displayed below connexion with hubnet client connexion interface image 21 choose the session you want to connect to or enter manualy the server address and port enter a user name click on the enter button once connected the player waits for the game to start and then he can start playing by playing an activity card on each of his field and choosing how much he wants to contribute to the water harvesting public infrastructure for instance the interface of player 1 bruno client in figure below where player 4 just changed the activity card standing on his first plot client game interface image 22 select your investment in public water source here player 1 chooses 2 for each one of your fields fields of your color set the activity by clicking on the field it becomes highlited with a white halo and then clicking on the activity you want to settle you can see how much time is remaining for the current round here 1 s you can see your income for previous rounds here only one previous round t1 where your income was 1 you can see your actual wealth under the figure representing you in the top of the screen here the red player owns 5 wags simulate experimenter run simulations with computerized players the experimenter can test his watersheds models by running simulations where human players are replaced by computer agents an inference engine has been built to model agents behaviours but at the moment given rules are very simple so agent behaviour is erratic however it enables to watch a simulation when you do not want to play all the players see figure below simulation interface just click on run button and the simulation starts at beginning the game is on pause if you want to start it you need to click set the start pause switch on rounds are passed automaticaly and activities and investments are choosen automaticaly by each agents you can see on the image that drops of water are flowing in the watershed download and installation of anawag all software used are free of charge and open source platform netlogo 5 3 1 programming language netlogo operating system platform independent model code licensed under gnu gpl version 3 in order to use anawag you must first firstly download and install netlogo 5 3 1 netlogo download page and then secondly download the extra widget extension v1 1 0 extrawidget extension page and install it as an extension in your netlogo installation as explained in the extension guide of netlogo just put the downloaded file in the rigth folder of your netlogo install details and implementation in netlogo mapping of the wag model in the netlogo world the conceptual model of anawag presented above as the conceptual class diagram has been mapped to the netlogo meta model in order to implement the model in the netlogo platform see figure below mapping of the wag conceptual model used in anawag into the netlogo meta model process overview and scheduling of the wag model in the anawag device the simulation corresponds to the network game feature or to a simulation with computer agents when it is a network game it is managed by a specific user of the device called the experimenter that starts each round when all players are ready once the round is started the players or agents choose the activities they want to install on each of their fields as well as the investment they want to put in the artificial source of water then the waterpath entities distribute water through each field and the activities entities determine if they succeed get enough resources or not an uml sequence diagram presents the scheduling in the wag model used in anawag in figure below sequence diagram of the wag model used in anawag development and results analysis analysis of simulation or game session can be automatized with r software a script is provided in the analysis folder of the source code computer code is split in a main source file called main nlogo in the root of the ana wag folder and a specific file for each class of the model class mame nls situated in the src folder watershed folder is used to store watershed models raw results files are saged in the results folder sets of rules describing agents behaviors are saved in agentrulesdatabase folder database folder is not used yet appendix e supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix e supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 07 011 
26162,knowledge infrastructure design 2 2 community supported collaborative web platform hydroshare 2 3 1 distributed data storage 2 3 2 resource exploration discovery and management 2 3 3 actions on resources through web apps 2 4 software environment cuahsi jupyterhub 2 4 1 community supported development and operation 2 4 2 tools and models 2 4 3 landlab community 2 5 advanced cyberinfrastructure and cybergis jupyter 2 6 modeling framework landlab and its application on hydroshare 2 7 user experience design for multiple learning pathways 2 8 data and models for three computational narratives 3 results 3 1 notebook 1 exploring runoff hydrographs with landlab 3 1 1 notebook 1 overview 3 1 2 notebook 1 interactive steps 3 1 3 impacts on numerical modeling education 3 1 4 notebook 1 access 3 2 notebook 2 replicate a landslide model to explore fire impacts on slope instability in a watershed within a regional study 3 2 1 notebook 2 overview 3 2 2 notebook 2 interactive steps 3 2 3 impacts on replicating scientific findings 3 2 4 notebook 2 access 3 3 notebook 3 reuse an ecohydrology model with gridded hydrometeorology forcing 3 3 1 notebook 3 overview 3 3 2 notebook 3 interactive steps and model results 3 3 3 impacts on use and reuse of research models 3 3 4 notebook 3 access 4 discussion 4 1 defining five common barriers 4 2 development based on user input 4 3 development to advance science 4 3 1 inductive learning approach 4 3 2 deductive learning approach 5 conclusions software and or data availability acknowledgments abbreviations appendix a supplementary data adams 2014 b dakotaamultilevelparallelobjectorientedframeworkfordesignoptimizationparameterestimationuncertaintyquantificationsensitivityanalysisversion60usersmanual adams 2017 1645 1663 j dealmeida 2012 g anders 2008 479 a apachesolr atkins 2003 d atkinsreportrevolutionizingscienceengineeringthroughcyberinfrastructurereportblueribbonadvisorypanelcyberinfrastructure baker 2012 127 136 i baldwin 2013 h techhotshotsriseuxexpert bandaragoda 2006 2 6 c bandaragoda 2019 c borgman 2015 207 227 c brooks 1996 317 328 k proceedingsfourthacminternationalconferencemultimedia storyagentsuserockingchairstheoryimplementationonemodelforcomputationalnarrative castronova 2018 a dockerfileforhydrosharejupyterhubbaseimage clark 2008 m clark 2011 m clark 2015 2515 2542 m clark 2015 2498 2514 m devi 2014 2250 3153 aworkingframeworkforusercentereddesignapproachasurveyavailablemethods dilling 2017 2628 2648 l ding 2014 357 360 t django 2018 webframeworkforperfectionistsdeadlinesdjango edwards 2013 p essawy 2018 217 229 b flanagan 2007 1603 1612 d forlizzi 2000 j symposiumdesigninginteractivesystems buildingblocksexperienceearlyframeworkforinteractiondesigners freeman 2005 682 691 p freire 2016 j reproducibilitydataorientedexperimentsinesciencedagstuhlseminar16041 gross 2014 939 943 a han 2015 1334 1350 j hanney 2013 r hobley 2017 21 46 d horsburgh 2016 55 74 j horsburgh 2016 873 889 j horsburgh 2017 83 94 j hughes 2014 s presentedcarolinasclimateresilienceconferencecharlottenc ametaanalysislocalclimatechangeadaptationactionsscienceinventoryepa hutton 2016 7548 7555 c idaszak 2017 219 233 r softwareengineeringforscience hydroshareacasestudyapplicationmodernsoftwareengineeringalargedistributedfederallyfundedscientificsoftwaredevelopmentproject irods istanbulluoglu 2004 e jones 2017 1095 1120 a kadlec 2015 19 28 j kluyver 2016 t positioningpowerinacademicpublishingplayersagentsagendasproceedings20thinternationalconferenceelectronicpublishing jupyternotebooksapublishingformatforreproduciblecomputationalworkflows kokotsaki 2016 267 277 d laflen 1997 96 102 j laflen 1991 34 38 j lagoze 2008 c objectreuseexchangearesourcecentricapproach lemos 2012 789 794 m livneh 2015 150042 b aspatiallycomprehensive luo 2004 215 220 w luo 2016 60 73 w mani 2013 i computationalnarratology mees 2017 374 390 h merkel 2014 d mezzanineprojectthebestdjangocms mihalevich 2017 593 b moore 2008 r moore d morsy 2017 13 28 m nalau 2015 89 98 j nash 1999 d netzeva 2005 155 173 t newman 2003 167 256 m nosek 2015 1422 1425 b pande 2017 e1193 s perez 2015 f projectjupytercomputationalnarrativesenginecollaborativedatascience perkel 2019 17 18 j pfister 2017 1792 1798 l phuong 2019 j rajib 2016 498 512 m ragankelley 2013 461 464 b shen 2014 151 h sidle 1992 1897 1910 r stagge 2019 j stocker 2018 21 m strauch 2018 49 75 r tarboton d tarbotondthehydroshareteam 2018 collaborativeresearchsi2ssicyberinfrastructureforadvancinghydrologicknowledgethroughcollaborativeintegrationdatasciencemodelinganalysis tarboton 2014 d internationalconferencehydroinformatics aresourcecentricapproachforadvancingcollaborationthroughhydrologicdatamodelsharing tarboton 2014 d presented7thinternationalcongressenvironmentalmodellingsoftwareiemss2014 hydroshareadvancingcollaborationthroughhydrologicdatamodelsharing tarboton d tesfa 2011 1696 1709 t tucker 2010 28 50 g vanwesten 2006 65 c wang 2010 535 557 s wang 2016 965 968 s 2019 cybergisforgeospatialdiscoveryinnovation yetemen 2015 1127 1157 o yi 2018 233 240 h yin 2017 18 1 18 8 d proceedingspracticeexperienceinadvancedresearchcomputing2017sustainabilitysuccessimpact acybergisjupyterframeworkforgeospatialanalyticsscale yuan 2018 167 z zhou 2013 x bandaragodax2019x104424 bandaragodax2019x104424xc 2020 09 10t00 00 00z https vtw elsevier com content oragreement 10144 chu nsf publishacceptedmanuscriptindexable http www elsevier com open access userlicense 1 0 2020 09 10t00 00 00z http creativecommons org licenses by nc nd 4 0 2019 published by elsevier ltd 2022 06 10t21 38 34 628z http vtw elsevier com data voc addontypes 50 7 aggregated refined brigham young university byu brigham young university http data elsevier com vocabulary scivalfunders 100006756 http sws geonames org 6252001 university of washington uw university of washington http data elsevier com vocabulary scivalfunders 100007812 http sws geonames org 6252001 tufts university tufts university http data elsevier com vocabulary scivalfunders 100008090 http sws geonames org 6252001 community surface dynamics modeling system ear 1831623 national center for atmospheric research ncar national center for atmospheric research http data elsevier com vocabulary scivalfunders 100005323 http sws geonames org 6252001 utah state university usu utah state university http data elsevier com vocabulary scivalfunders 100006630 http sws geonames org 6252001 oliver fund of tulane university cbet 1336725 cuahsi ear 1338606 cuahsi consortium of universities for the advancement of hydrologic science http data elsevier com vocabulary scivalfunders 100018070 http sws geonames org 6252001 purdue university university of texas at austin cybergis aci 1047916 ear 1349375 oac 1047916 oac 1147454 oac 1429699 oac 1443080 oac 1450338 oac 1450409 oac 1450412 european union apos s horizon 2020 research and innovation programme horizon 2020 http data elsevier com vocabulary scivalfunders 501100007601 http sws geonames org 6695072 nsf aci 1148090 aci 1148453 oac 1664018 oac 1664061 oac 1664119 nsf national science foundation http data elsevier com vocabulary scivalfunders 100000001 http sws geonames org 6252001 university of virginia uv university of virginia http data elsevier com vocabulary scivalfunders 100008457 http sws geonames org 6252001 landlab group european union s horizon 2020 research and innovation programme h2020 horizon 2020 framework programme http data elsevier com vocabulary scivalfunders 100010661 http sws geonames org 6695072 nsf ear ear 1725774 marie skłodowska curie 663830 msca h2020 marie skłodowska curie actions http data elsevier com vocabulary scivalfunders 100010665 http sws geonames org 6695072 we acknowledge funding from nsf for hydroshare aci 1148453 tarboton bandaragoda aci 1148090 idaszak oac 1664018 idaszak oac 1664061 bandaragoda idaszak tarboton and oac 1664119 wang cuahsi ear 1338606 castronova and the community surface dynamics modeling system csdms ear 1831623 these development grants supported a team including the consortium of universities for the advancement of hydrologic science inc cuahsi utah state university brigham young university tufts university university of virginia university of washington national center for atmospheric research ncar purdue university university of texas at austin and san diego supercomputing center for the development of the hydroshare platform http www hydroshare org from 2012 to 2018 for roger supercomputing oac 1429699 wang and advanced cyberinfrastructure oac 1443080 oac 1429699 and oac 1047916 wang and cybergis aci 1047916 wang idaszak for landlab oac 1450412 istanbulluoglu oac 1147454 oac 1450409 tucker hobley oac 1450338 ear 1349375 the oliver fund of tulane university gasparini lyons and for landslide research cbet 1336725 istanbulluoglu barnhart acknowledges an nsf ear postdoctoral fellowship ear 1725774 this project received partial funding from the european union s horizon 2020 research and innovation programme under the marie skłodowska curie grant agreement no 663830 hobley the authors are grateful for this diversity of contributions any opinions findings conclusions or recommendations expressed in this material are those of the authors and developers and do not necessarily reflect the views of the nsf or other funding organizations all data and code used in this research are available on github landlab and hydroshare organizations as well as hydroshare www hydroshare org where readers can collaborate join the public landlab group and view shared public data described in this paper we acknowledge funding from nsf for hydroshare aci 1148453 tarboton bandaragoda aci 1148090 idaszak oac 1664018 idaszak oac 1664061 bandaragoda idaszak tarboton and oac 1664119 wang cuahsi ear 1338606 castronova and the community surface dynamics modeling system csdms ear 1831623 these development grants supported a team including the consortium of universities for the advancement of hydrologic science inc cuahsi utah state university brigham young university tufts university university of virginia university of washington national center for atmospheric research ncar purdue university university of texas at austin and san diego supercomputing center for the development of the hydroshare platform http www hydroshare org from 2012 to 2018 for roger supercomputing oac 1429699 wang and advanced cyberinfrastructure oac 1443080 oac 1429699 and oac 1047916 wang and cybergis aci 1047916 wang idaszak for landlab oac 1450412 istanbulluoglu oac 1147454 oac 1450409 tucker hobley oac 1450338 ear 1349375 the oliver fund of tulane university gasparini lyons and for landslide research cbet 1336725 istanbulluoglu barnhart acknowledges an nsf ear postdoctoral fellowship ear 1725774 this project received partial funding from the european union apos s horizon 2020 research and innovation programme under the marie skłodowska curie grant agreement no 663830 hobley the authors are grateful for this diversity of contributions any opinions findings conclusions or recommendations expressed in this material are those of the authors and developers and do not necessarily reflect the views of the nsf or other funding organizations all data and code used in this research are available on github landlab and hydroshare organizations as well as hydroshare www hydroshare org where readers can collaborate join the public landlab group and view shared public data described in this paper item s1364 8152 19 30156 2 s1364815219301562 1 s2 0 s1364815219301562 10 1016 j envsoft 2019 03 020 271872 2020 10 12t02 27 59 672677z 2019 10 01 2019 10 31 1 s2 0 s1364815219301562 main pdf https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 main application pdf f6f2698e4ea1c136d4ef2298cd2dab1c main pdf main pdf pdf true 3188158 main 18 1 s2 0 s1364815219301562 main 1 png https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 preview image png 86417c35d32cb687f6132698945432f7 main 1 png main 1 png png 50037 849 656 image web pdf 1 1 s2 0 s1364815219301562 gr1 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr1 thumbnail image gif d8ed2038120a61fa2305870b401f6523 gr1 sml gr1 gr1 sml sml 18357 136 219 image thumbnail 1 s2 0 s1364815219301562 gr2 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr2 thumbnail image gif 738610bca6f952dbb9774a6d2460d983 gr2 sml gr2 gr2 sml sml 18126 164 137 image thumbnail 1 s2 0 s1364815219301562 gr3 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr3 thumbnail image gif 0af114deeaa4d230e4f58a029a6345b4 gr3 sml gr3 gr3 sml sml 27599 125 219 image thumbnail 1 s2 0 s1364815219301562 gr4 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr4 thumbnail image gif b80cf2bdf378f876d4c384add218a59d gr4 sml gr4 gr4 sml sml 33849 154 219 image thumbnail 1 s2 0 s1364815219301562 gr5 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr5 thumbnail image gif 3fef4c80a1d95a7e5f182f899a5d3928 gr5 sml gr5 gr5 sml sml 39277 164 216 image thumbnail 1 s2 0 s1364815219301562 gr6 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr6 thumbnail image gif 30d49b70dfd28d924f7b17acab40ad07 gr6 sml gr6 gr6 sml sml 30394 106 219 image thumbnail 1 s2 0 s1364815219301562 gr7 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr7 thumbnail image gif aa24243b49ac25621ab103befd37c03f gr7 sml gr7 gr7 sml sml 24726 148 219 image thumbnail 1 s2 0 s1364815219301562 gr8 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr8 thumbnail image gif 589ec56640a83562d594375d1ce9b5a7 gr8 sml gr8 gr8 sml sml 29701 163 131 image thumbnail 1 s2 0 s1364815219301562 gr9 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr9 thumbnail image gif b2ebd248731285f9d55c792fbe6060b9 gr9 sml gr9 gr9 sml sml 13525 164 193 image thumbnail 1 s2 0 s1364815219301562 gr1 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr1 downsampled image jpeg 76cf7a0e3192b1219567734f9805bdf8 gr1 jpg gr1 gr1 jpg jpg 83021 375 602 image downsampled 1 s2 0 s1364815219301562 gr2 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr2 downsampled image jpeg b7af9bfac7a4fd376efa67fa1d58aab1 gr2 jpg gr2 gr2 jpg jpg 91281 613 513 image downsampled 1 s2 0 s1364815219301562 gr3 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr3 downsampled image jpeg 3bed0491ff755f130fe6589aaf83e486 gr3 jpg gr3 gr3 jpg jpg 116338 380 669 image downsampled 1 s2 0 s1364815219301562 gr4 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr4 downsampled image jpeg adaa30b94b040c2616e733ef9fff728b gr4 jpg gr4 gr4 jpg jpg 128606 361 513 image downsampled 1 s2 0 s1364815219301562 gr5 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr5 downsampled image jpeg e794f1b8012e134544588823bcb3ed76 gr5 jpg gr5 gr5 jpg jpg 83421 287 379 image downsampled 1 s2 0 s1364815219301562 gr6 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr6 downsampled image jpeg 1836923b8731481fe44c4bd2b48dac4d gr6 jpg gr6 gr6 jpg jpg 87230 270 557 image downsampled 1 s2 0 s1364815219301562 gr7 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr7 downsampled image jpeg 1c2e006332b92d222d6fb1bc5b1f9696 gr7 jpg gr7 gr7 jpg jpg 112746 423 624 image downsampled 1 s2 0 s1364815219301562 gr8 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr8 downsampled image jpeg e57614ee25e95fb3801510f226f6c07b gr8 jpg gr8 gr8 jpg jpg 204204 639 513 image downsampled 1 s2 0 s1364815219301562 gr9 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr9 downsampled image jpeg 003bff5726dd1b371473be882bcf0987 gr9 jpg gr9 gr9 jpg jpg 62342 436 513 image downsampled 1 s2 0 s1364815219301562 gr1 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr1 highres image jpeg 32ed3afd05b69abc3d886996fd929ca0 gr1 lrg jpg gr1 gr1 lrg jpg jpg 558802 1658 2665 image high res 1 s2 0 s1364815219301562 gr2 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr2 highres image jpeg b06461b665f4ddd5656545aec49b8535 gr2 lrg jpg gr2 gr2 lrg jpg jpg 578375 2713 2272 image high res 1 s2 0 s1364815219301562 gr3 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr3 highres image jpeg 38e4b1a289f0252d06a44da60e930074 gr3 lrg jpg gr3 gr3 lrg jpg jpg 888899 1684 2961 image high res 1 s2 0 s1364815219301562 gr4 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr4 highres image jpeg e78f64b98ea2d32640d6f22ae038b63e gr4 lrg jpg gr4 gr4 lrg jpg jpg 1072097 1601 2272 image high res 1 s2 0 s1364815219301562 gr5 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr5 highres image jpeg d53a7277e96ef937462ce854633898e3 gr5 lrg jpg gr5 gr5 lrg jpg jpg 593999 1273 1681 image high res 1 s2 0 s1364815219301562 gr6 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr6 highres image jpeg 220611ee57c4103f915b3c119871a8d7 gr6 lrg jpg gr6 gr6 lrg jpg jpg 628007 1198 2469 image high res 1 s2 0 s1364815219301562 gr7 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr7 highres image jpeg ab50f7873d8830881f38702eaf5277e7 gr7 lrg jpg gr7 gr7 lrg jpg jpg 751414 1872 2764 image high res 1 s2 0 s1364815219301562 gr8 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr8 highres image jpeg 1335f8e4d9c9570b40b4bf9ee858e1c8 gr8 lrg jpg gr8 gr8 lrg jpg jpg 1501100 2831 2272 image high res 1 s2 0 s1364815219301562 gr9 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr9 highres image jpeg fc6168875b04ebe9fe138d43b02f1aa6 gr9 lrg jpg gr9 gr9 lrg jpg jpg 352900 1930 2272 image high res 1 s2 0 s1364815219301562 mmc1 xml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 mmc1 main application xml 751b38495eb2d743bec6c8d8934f8a62 mmc1 xml mmc1 mmc1 xml xml 405 application 1 s2 0 s1364815219301562 mmc2 docx https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 mmc2 main application vnd openxmlformats officedocument wordprocessingml document df0ee447e64d21c48ab97db7a9263330 mmc2 docx mmc2 mmc2 docx docx 541071 application 1 s2 0 s1364815219301562 am pdf am am pdf pdf 2529308 aam pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content egi 10splkm0jc1 main application pdf fe9f63515fb34b6a1a0bb9248b9dd5e3 am pdf enso 4424 104424 s1364 8152 19 30156 2 10 1016 j envsoft 2019 03 020 fig 1 illustration of six basic elements for a knowledge infrastructure for interactive community modeling and exploration research software communities maintain support of operations between docker containers and software environment domain science communities maintain support for version control and user communications specific to modeling frameworks fig 1 fig 2 illustration of flow routing outputs a elevation map of spring creek central co with locations outlet midstream upstream where hydrographs are plotted b d hydrographs plotted at three locations shown in a driven by the high intensity rainfall option using kinwaveimplicitoverlandflow and overlandflow components respectively c e flow depth maps during peak flow for kinwaveimplicitoverlandflow and overlandflow components respectively results were produced on hydroshare using the landlab modeling framework fig 2 fig 3 a example debris avalanches cyan mapped in three areas within noca contours are in 100 m intervals aerial image source from world imagery esri inc b elevation distribution of the relative frequency of mapped debris avalanche source areas and c high elevation rock and glacier surrounding spiral glacier in north cascades showing a bedrock glacier cirque with thin barren soils and moraine deposits photo by john scurlock with permission d elevation ft for noca model extent from strauch et al 2018 and e for the subset for the thunder creek extent figures a c adapted in entirety from strauch et al 2018 under cc by 4 0 for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 3 fig 4 maps show modeled landslide return periods using landlab for noca overlain with mapped debris avalanches including zoomed in areas at top for greater detail the uncertainty of soil depth was characterized from a long term soil evolution model m sd lt cumulative distribution of landslide return periods for ssurgo soil depth ssurgo sd modeled soil depth m sd and modeled soil depth considering long term dynamics m sd lt scenarios plotted on a log log scale using the weibull plotting position figure adapted in entirety from strauch et al 2018 under cc by 4 0 fig 4 fig 5 landslide probability estimates in the thunder creek watershed photo increase given post fire root cohesion assumptions 70 less as compared to the original cohesion assumptions in strauch et al 2018 as an example of knowledge infrastructure functionality the notebook replicates published findings as well as tests the parameter function described in the peer reviewed publication inset maps and cumulative distribution plots of the spatial probability of landsliding for pre fire and post fire conditions photo is looking north down the broad glacial carved valley of thunder creek courtesy of michael kirshenbaum and national park service fig 5 fig 6 map of elevation bands in new mexico state a used to extract gridded hydrometeorological forcing data elevation bins are referred to as low elevation 1200 1700 m mid elevation 1700 2000 m and high elevation 2000 2500 m the vegetation patterns from aerial imagery of new mexico are distinct within these bands b fig 6 fig 7 climate data downloaded and processed from livneh et al 2015 a annual precipitation plotted with respect to time for each elevation band b mean monthly daily minimum and maximum temperatures for each elevation band fig 7 fig 8 spatial organization of pfts at year 1503 left column and annual areal cover fraction of each pft plotted with respect to time right column for a low elevation landscapes 1200 m 1700 m b mid elevation landscapes 1700 m 2000 m and c high elevation landscapes 2000 m 2500 m fig 8 fig 9 illustration of community learning and discovery process by code access and utilization among scientists key triangle synthesis merge circle connector square process quadrilateral manual or machine operation cylinder database inductive processes are supported when for example a landlab user has a new idea for a component develops the landlab application and publishes it on hydroshare formally with doi or get a publicly accessible url and reviewers can test the experiment with cloud resources deductive processes are supported when new earth observations are published on hydroshare used to test hypotheses or principals using published models and results shown to lead to scientific advancements or the development of new ideas fig 9 table 1 three study problems were designed with a focus to 1 explore 2 replication and 3 reuse research computational narratives demonstrate how to use knowledge infrastructure for computation and visualization of earth surface models where the user interacts with the infrastructure to develop their own story table 1 purpose tasks highlight science topic workflow notebook title 1 educate training and curriculum development flexible components hydrology inductive explore flood routing ipynb 2 replicate execute a published model to replicate reported findings controlled software environment landslides and fire deductive replicate landslide model ipynb 3 reuse execute and enhance a published model in a new location multiple components wrapped for efficiency ecohydrology inductive deductive reuse ecohydrology gridhydromet ipynb table 2 parameters used to obtain spring creek high intensity model comparisons between kinematic wave and overland flow model table 2 variable parameter description value dimension hours hours of model run time 6 hours number frames number of frames to plot 6 n manning s roughness coefficient 0 03 s m 1 3 base runoff rate base runoff rate 10 mm hr higherintensity runoff rate high intensity runoff rate 20 mm hr storm duration storm duration 2 hours dt time step for kinwaveimplicitoverlandflow 600 seconds enabling collaborative numerical modeling in earth sciences using knowledge infrastructure c bandaragoda a a castronova b e istanbulluoglu a r strauch c s s nudurupati a j phuong d j m adams e n m gasparini g k barnhart h m e w h hutton f d e j hobley i n j lyons g g e tucker f h m d g tarboton j r idaszak k s wang l a department of civil and environmental engineering university of washington seattle usa department of civil and environmental engineering university of washington seattle usa b consortium of universities for the advancement of hydrologic science inc cuahsi usa consortium of universities for the advancement of hydrologic science inc cuahsi usa c seattle city light seattle usa seattle city light seattle usa d department of biomedical informatics and medical education university of washington seattle usa department of biomedical informatics and medical education university of washington seattle usa e institute of arctic and alpine research university of colorado boulder co usa institute of arctic and alpine research university of colorado boulder co usa f community surface dynamics modeling system csdms university of colorado boulder usa community surface dynamics modeling system csdms university of colorado boulder usa g department of earth and environmental sciences tulane university new orleans la usa department of earth and environmental sciences tulane university new orleans la usa h department of geological sciences university of colorado at boulder boulder co usa department of geological sciences university of colorado at boulder boulder co usa i cardiff university cardiff uk cardiff university cardiff uk j department of civil environmental engineering utah state university logan usa department of civil environmental engineering utah state university logan usa k renci university of north carolina chapel hill usa renci university of north carolina chapel hill usa l department of geography and geographic information science university of illinois at urbana champaign urbana usa department of geography and geographic information science university of illinois at urbana champaign urbana usa m cooperative institute for research in environmental sciences cires university of colorado at boulder boulder co usa cooperative institute for research in environmental sciences cires university of colorado at boulder boulder co usa corresponding author department of civil environmental engineering university of washington 201 more hall box 352700 seattle wa 98195 2700 usa department of civil environmental engineering university of washington 201 more hall box 352700 seattle wa 98195 2700 usa knowledge infrastructure is an intellectual framework for creating sharing and distributing knowledge in this paper we use knowledge infrastructure to address common barriers to entry into numerical modeling in earth sciences as demonstrated in three computational narratives physical process modeling education replicating published model results and reusing published models to extend research we outline six critical functional requirements 1 workflows designed for new users 2 community supported collaborative web platform 3 distributed data storage 4 software environment 5 personalized cloud based high performance computing platform and 6 a standardized open source modeling framework our methods meet these functional requirements by providing three interactive computational narratives for hands on problem based research using landlab on hydroshare landlab is an open source toolkit for building coupling and exploring two dimensional numerical models hydroshare is an online collaborative environment for the sharing of data and models we describe the methods we are using to accelerate knowledge development by providing a suite of modular and interoperable process components that allows students domain experts collaborators researchers and sponsors to learn by exploring shared data and modeling resources the system is designed to support uses on the continuum from fully developed modeling applications to prototyping research software tools landlab notebooks are available for interactive computing on hydroshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 and for further development on github at https zenodo org badge latestdoi 187289993 keywords cyberinfrastructure knowledge infrastructure reproducible modeling landlab hydroshare earth science education 1 introduction modeling in earth sciences began with the use of hand written mathematical formulas that were developed from observational evidence conjecture or hypothesis and shared through conversation and correspondence as richness and complexity of our available earth observations have grown in parallel with technological advances in computational resources supercomputing high performance computing and cloud computing our models now focus on couplings among atmospheric hydrologic ecologic geomorphic and human impacted processes e g tucker and hancock 2010 yetemen et al 2015a b han et al 2015 anders et al 2008 pande and sivapalan 2017 advances in internet based cyberinfrastructure includes computational systems data and information management advanced instruments visualization environments and people all linked together by software and advanced networks to improve scholarly productivity and enable knowledge breakthroughs and discoveries not otherwise possible this digital infrastructure expands our capacity for structured collaborations in research edwards et al 2013 however these technological advances often come at the expense of raising the technological bar for entry into numerical modeling here with examples from earth science we discuss how to lower this bar with that include three key features 1 a community platform that allows dynamic interactions among developers researchers and new users 2 clear documentation of theoretical and mathematical details that are often lost for new users of complex model programs and 3 model reproducibility for example sharing the code and data within a community portal with computational capacity allows new users to easily find and test training materials developers to easily distribute open workshop materials and communities to build new research networks further as technology is integrated in the research with greater sophistication it is increasingly a challenge to keep the fundamental equations that define the driving assumptions in the model structure accessible to software users using methods such as inclusion of equations and references in online documents can avoid the black box syndrome and improve ease of learning transparency and usability of the modeling code communicating what can be expected to be known by using the research tool provides the domain of applicability netzeva et al 2005 or builds into the system edwards et al 2013 to be clear on the purpose and limits of the model what can be expected to be known by using the research tool experimental design is addressed by illustrating three different areas where model reproducibility can have an impact on advancing science classroom and peer to peer education replicating published results and reusing models to build new research products knowledge infrastructure is an emerging intellectual framework to understand and improve how people create share interpret observations and modeled results and distribute knowledge which has dramatically changed and is continually transformed by internet technologies and advanced cyberinfrastructure knowledge infrastructure is most simply defined as robust networks of people artifacts and institutions that generate share and maintain specific knowledge about the human and natural worlds borgman et al 2015 in earth and hydrologic sciences interpreting observational and model simulated data is a fundamental task but systematic acquisition of data for interpretations and machine readability is not common practice among environmental research infrastructures stocker et al 2018 knowledge infrastructure advances us beyond cyberinfrastructure which is generally limited to distributed computer information and communication technologies by including networks of groups and institutions and the cultural practices of developing and sharing computational narratives brooks 1996 perez and granger 2015 computational narratives are the algorithmic processes involved in creating and interpreting computed representations mani 2013 in our case the algorithmic processes are earth surface models and the computed representation is the results of the analytical research and how those results are summarized recent developments in the use of advanced cyber infrastructure in earth science include tools used to support hydroinformatics such as hydroshare tarboton et al 2014a tarboton et al 2014b 2018 and the cuahsi jupyterhub service castronova 2018 perez and granger 2015 development efforts concentrate on the application of information and communication technologies icts targeted for geospatial analytics yin et al 2017 and hydrologic data types and models horsburgh et al 2016a morsy et al 2017 strauch et al 2018 by providing resources for open source practices including sharing of data and models and providing online computational resources i e cloud computing with expert knowledge or user experience designed to support non experts these platforms can be effectively used for expanding and broadening our capacity to investigate hydrologic and earth system processes in model based investigations reproducibility increases confidence in results and improves interpretation about what results do and do not mean lack of reproducibility limits the expansion and growth of knowledge hutton et al 2016 nosek et al 2015 the term reproducibility has many aspects which can be explored further in other work essawy et al 2018 yuan et al 2018 stagge et al 2019 but we broadly use the term to ecompass multiple aspects including availability computational reproducibility portability experimental replicacability and accessibility the advancement of knowledge and lowering the barriers to reproducibility can be enabled by knowledge infrastructure that supports collaborative research education and curriculum development and improves standards for technology practices for publication of research web based interactive computing environments such as jupyter notebooks perez and granger 2015 are designed to execute models and perform data analytics and have become increasingly prevalent to improve reproducibility of research in the past few years shen 2014 especially with early adopters in the biological sciences perkel 2019 gross et al 2014 ragan kelley et al 2013 ding and schloss 2014 francis 2018 created a reference of jupyter notebooks currently available on the web with limited examples of experiments in the earth sciences community one of the first interactive notebooks that we know of was published by shen 2014 which provided computational resources for executing code snippets exploring astronomy data this was available online as an interactive notebook for three years 2014 2017 and it was replaced with a static view of an example execution of the notebook in november 2017 luo et al 2016 have shown that interacting with web based models through a graphical user interface in classroom environments improves higher level thinking and attitudes about complex landscape evolution models we do not know of any collections of notebooks published with the supporting infrastructure available for authors to maintain accessible interactive notebooks for their readers in hydrologic sciences and earth surface modeling communities or studies on how interacting with model code improves educational or research outcomes efforts to provide online computing capacity for earth science research and education includes landscape evolution modeling such as the wilsim model luo et al 2004 2016 watershed hydrology and erosion modeling using wepp laflen et al 1991 laflen 1997 flanagan et al 2007 and river basin environmental modeling using swat rajib et al 2016 while these web based modeling approaches lower the bar for model execution model options and the level of interaction of the users with models are constrained by the limited set of options envisioned by the developers these tools rely on graphical user interfaces gui with limited user inputs parameter values or scenario choices and they do not provide an interactive software environment for user collaboration and co creation of knowledge to develop a persistent collaborative environment that will have a profound transformational effect on our society newman 2003 we need to identify and overcome the barriers that are currently preventing rapid adoption of knowledge infrastructure for earth surface modelers this paper is motivated by the following questions can current software infrastructure and research communities 1 facilitate rapid adoption and scientific advancement of complex earth surface models 2 lower the bar for entry into modeling 3 improve collaborations among scientists and science partners and 4 advance useable science with sustainable open source software in addressing these questions our aim is to explore knowledge infrastructure using advanced data access and computational resources beyond what an individual scientist would normally have available bandaragoda et al 2006 we first describe three emerging open source modeling practices to lower the bar into modeling methods section 2 in our methods we review basic elements of knowledge infrastructure and substantiate it with specific technical details as implemented in hydroshare the ci platform we use in this study in the results section 3 we focus on the use of the landlab earth surface modeling toolkit hobley et al 2017 deployed on hydroshare in three use cases that employ emerging open source modeling practices to lower barriers in modeling we provide workflows designed with interactive notebooks aimed at earth science education as well as reuse and replication of research models our discussion section 4 explores the barriers we have identified followed by conclusions section 5 on our approach to address the motivating questions and current limitations 2 methods 2 1 emerging practices for modeling the ability to reproduce experiments and share data is expanding open source cyberinfrastructure platforms for research publication are designed to facilitate the use of existing models by making input data and model code publicly available online and providing software tools for pre and post processing data running models sharing data and formally publishing with a digital object identifier freeman et al 2005 atkins et al 2003 using recent examples in water monitoring horsburgh et al 2017 jones et al 2017 mihalevich et al 2017 landslide modeling strauch et al 2018 and data science freire et al 2016 we identified three critical open source technology practices supported by knowledge infrastructure expected to lead to scientific discoveries sections 2 1 1 2 1 2 and 2 1 3 2 1 1 code development in an open source environment evolving software versions hardware requirements numerical methods and code quality limit the ability to replicate and reuse model applications developing models from a personal computer pc requires installing a suite of specialized software tools and access to computational hardware to visualize store and prepare model inputs and outputs thus reproducing a study by others often depends on the ability to reproduce the software environment 2 1 2 cyber training in numerical modeling education the use of numerical models for science education should not diminish the instruction time for basic science costs that sometimes arise from using models in the classroom include time needed for extensive technological instruction and technical troubleshooting these costs can be avoided by developing software infrastructure that accesses computational and data intensive models from a web browser avoiding the need for any software installations enables classroom experiences for students that focuses time on improved understanding of existing theory and is designed to generate curiosity to propose hypotheses and design further modeling field and laboratory experiments 2 1 3 cyber interactions in collaboration in most academic research projects skills for code development diagnostics and model execution are limited to a few individuals graduate students postdocs etc however most modelers would agree that coding errors can be more effectively identified more user friendly codes can be designed and new research ideas can be developed when other experts have access to models for evaluation experimentation and testing when scientists and stakeholders can interact with execute and visualize various components of coupled models used in collaborative projects the research process leads to rapid development of ideas and research products and more useable science lemos et al 2012 2 2 knowledge infrastructure design our approach includes the following six methodological software and hardware components fig 1 labels 1 6 that can address the barriers to computational modeling 1 user experience design is the conceptual and evolving software design that includes all the practices developed to efficiently accomplish collaborative online tasks based on personal collaborator and institutional cultural preferences e g workflow practices for using software to run models perform data analysis and publish research products the user experience design guides the development of the framework and in research software includes contributions from both developers and new users section 2 7 2 community supported collaborative web platform that interacts with high performance computing hpc and data storage nodes allows for computationally intensive computing and supports publishing and privacy section 2 2 3 data storage that may be distributed to different locations section 2 3 4 software environment that provides a library of software and programming languages supporting model applications version control data analytics and facilitates the execution of numerical models section 2 4 5 cloud based high performance computing chpc platform that hosts the software environment models and personal user space section 2 5 and 6 a standardized modeling framework section 2 6 the adoption ongoing adaptation and growth of an infrastructure system is fundamentally dependent on personal research choices collaborative dependencies and institutional policies section 2 7 in section 2 8 we provide examples that generated design input to component 1 user experience design in order to evolve the the knowledge infrastructure system 2 2 community supported collaborative web platform hydroshare hydroshare http www hydroshare org is an online collaborative platform developed to address the growing computer modeling data storage and sharing needs of the community it supports the sharing of both data and models using hydroshare resources and facilitates the execution of numerical models using web apps associated with or linked to hydroshare hydroshare is operated by the consortium of universities for the advancement of hydrologic science inc cuahsi www cuahsi org as a community supported collaborative web platform fig 1 box 2 a web browser is the interface to hydroshare and provides access to hydrologic and earth surface models and data that are saved as resources in hydroshare the architecture of hydroshare is designed to support 1 resource storage 2 resource exploration and 3 actions on resources these are implemented using system components that are relatively loosely coupled and interact through application programming interfaces apis the loose coupling takes advantage of services oriented architecture soa that enhances robustness as components can be upgraded and advanced relatively independently 2 3 1 distributed data storage content that can be shared within hydroshare is diverse including digital objects that represent multiple hydrologic data types models and model instances documents and other content types commonly used in hydrologic research horsburgh et al 2016b a resource is the discrete unit of digital content within hydroshare resources are cast as social objects that can be published collaborated around annotated discovered and accessed horsburgh et al 2016b in this resource centric approach a resource is the granular unit used for management and access control hydroshare resources include hydrologic time series geographic feature vector data geographic raster gridded data multidimensional space time data sets e g netcdf and composite resources that represent combinations of these data types as well as collections that group together different resources model programs and model instances are additional types of content that can be shared and manipulated within hydroshare metadata is maintained that tracks system level attributes of the resource including timestamps of creation and modification ownership access control rules etc persistent identifiers access control versioning sharing and discovery are all managed at the resource level in hydroshare hydroshare s overarching resource data model is an implementation of the open archives initiative object reuse and exchange oai ore standard lagoze et al 2008 that holds metadata in a standardized and machine readable way to promote interoperability with other systems oai ore is a standard for the description and exchange of web resources hydroshare uses the integrated rule oriented data system irods moore 2008 irods consortium 2016 yi et al 2018 as its distributed network storage back end irods provides a virtual file system for physical storage distributed across multiple locations and enables data federation across geographically dispersed institutions yi et al 2018 2 3 2 resource exploration discovery and management the primary user interface for hydroshare is the website hosted at www hydroshare org developed using the django web framework django 2018 and mezzanine content management system mezzanine project 2018 together these technologies are used to build a system for archiving data and metadata for each resource and provides a landing page where metadata can be entered and edited or content files added or removed in the sharing settings panel users can specify sharing status e g private or public and manage who has access to edit or view the content a resource may be permanently published in which case it is precluded from further editing and assigned a citable digital object identifier doi the django website also provides a my resources page for listing data that belong to or have been shared with each user a discover page that supports keyword and map based search for content based on their spatial coverage information using the apache solr search platform solr project 2018 and a collaborate page for users to create or join groups aligned around specific research topics collectively these web pages provide a system where users can discover and manage the content to which they have access including changing access control settings and creating new content the business logic of resource and content types and access control is all managed using standard python django software packages 2 3 3 actions on resources through web apps the hydroshare repository broadly consisting of irods middleware for managing data storage and a django website for content discovery and management is extended by independent web applications that allow users to perform actions on hydroshare data using a services oriented software pattern hydroshare has been designed to support this interaction with 3rd party applications using a representative state transfer rest application programming interface api the industry standard oauth protocol is used to manage authentication and interface with hydroshare s access and control model which is necessary to support interaction with remotely hosted web applications via the api flexible web app launching functionality has been established through a hydroshare resource type that defines the url and parameters for invoking the web application these web app resources can be created by any hydroshare user to interact with 3rd party web applications that are designed to act on hydroshare content hydroshare web applications can be hosted anywhere and have the potential to provide users with a gateway to high performance computing 2 4 software environment cuahsi jupyterhub this paper makes use of a jupyterhub web application developed and maintained by cuahsi https jupyter cuahsi org that leverages jupyter notebook technology jupyter notebooks are an effective way to document research analysis workflows and modeling procedures in a reproducible manner kluyver et al 2016 the cuahsi jupyterhub service is under active development to support 1 computationally intensive research 2 data intensive research 3 education and the dissemination of knowledge and 4 reproducible science these goals are made possible through the development of data transfer mechanisms to move data between hydroshare and the jupyterhub environment as seamlessly as possible moreover hydroshare provides a mechanism for users to launch notebook workflows and their associated datasets into a pre configured isolated remote compute environment each compute environment is created on the fly and contains a persistent data store for performing hydrologic analysis in a manner that is insulated from all other users this is possible by leveraging operating system level virtualization software such as docker merkel 2014 each user instance runs the ubuntu linux operating system and is pre configured with scientific python and r libraries software for interacting with the hydroshare rest api and various physical models including landlab a typical workflow is to launch the cuahsi jupyterhub web application from a hydroshare resource programmatically collect any necessary data using the hydroshare rest api perform modeling and analysis and finally save results back to hydroshare after these data i e jupyter notebook and data files are saved back to the hydroshare repository they can be shared with other users and groups who can further analyze them in a similar way this back and forth sharing enables collaboration in the development and analysis of landlab models using the hydroshare repository and linked jupyterhub web app 2 4 1 community supported development and operation cuahsi supports the development and operation of cuahsi jupyterhub as part of the hydroshare project idaszak et al 2017 as well as through their cooperative agreement with nsf see acknowledgements development and operation efforts are divided into two categories 1 system maintenance and user support and 2 hydrologic research and modeling the first category focuses primarily on maintaining existing capabilities updating libraries and performing system level maintenance and upgrades this includes overseeing the installation and compiling of python versions 2 7 and 3 6 r version 3 4 scientific libraries such as pandas dakota adams et al 2014 spotpy numpy etc and modeling applications e g modflow 6 landlab taudem the latter category consists of collaborative research to lower the barrier of entry to modern modeling applications such as the structure for unifying multiple modeling alternatives summa and the national water model nwm configuration of wrf hydro these efforts are coordinated using an open source codebase in which code contributions undergo a review process and formal release schedule users provide feedback and requests via github issues with bug and enhancement tickets 2 4 2 tools and models one of the goals of cuahsi jupyterhub is to make it simple for users to access the software they need without some of the challenges associated with library dependencies computer operating system or platform compatibility and installation challenges as such cuahsi jupyterhub has installed and supports a range of software and tools commonly used for hydrologic analyses to help users get going quickly in their work and make their work more reproducible it is intended for this set of software and models to grow as the platform is further developed currently cuahsi jupyterhub includes the following landlab an earth surface modeling toolkit that this paper focuses on as an example of the approach hobley et al 2017 taudem a set of gis tools for terrain analysis and watershed delineation tarboton 2018 tesfa et al 2011 modflow groundwater model the structure for unifying multiple modeling alternatives summa clark et al 2008 2011 2015a 2015b model framework that allows for formal evaluation of multiple working hypotheses on model representations of physical processes irods icommands component for accessing large files efficiently from the hydroshare repository using irods python tools for working with hydroshare observation data model 2 odm2 time series content types horsburgh et al 2016a the waterml r package kadlec et al 2015 2 4 3 landlab community landlab has four main releases per year february may august november which accompany landlab s quarterly newsletter the landlab lookout the newsletter alerts users that a new version is available describes what s new in the release and gives a summary of landlab related news such as landlab themed clinics publications using landlab etc occasionally intermediate releases will happen in conjunction with annual community meetings that include presentations or workshops that feature landlab for instance american geophysical union annual meeting december recurring geological society of america july recurring community surface dynamics modeling system may recurring this ensures that participants of these meetings can use the latest version of landlab in addition to announcing new releases via the newsletter landlab developers also contact directly other researchers that use landlab for hydroshare this means either submitting issues on the hydroshare jupyterhub github repository or sending email directly to cuahsi jupyterhub developers this ensures that these projects provide their users with the most up to date landlab versions the role of version control is highlighted in fig 1 as domain science community support of research 2 5 advanced cyberinfrastructure and cybergis jupyter hydroshare has recently been developed to exploit cybergis that is geospatial information science and systems based on advanced computing and cyberinfrastructure and high performance computing hpc wang 2010 wang and goodchild 2019 cybergis jupyter allows hydroshare jupyter notebooks to harness hpc resources such as those provided by the nsf extreme science and engineering discovery environment xsede and resourcing open geospatial education and research roger supercomputer wang 2016 specifically cybergis jupyter encompasses the following three major functional components yin et al 2017 jupyterhub is used to handle authentication and schedule standalone jupyter servers after authentication dedicated containers are sent to the docker swarm docker swarm is responsible for spawning and managing all docker containers across a specific group of virtual machines the swarm the containerization provides fine grain on demand provisioning of cloud infrastructure as a service when a user launches a notebook batch hpc is adapted to harness distributed parallel computing resources high performance storage systems and cybergis software to greatly expand the capabilities of a typical jupyter notebook environment 2 6 modeling framework landlab and its application on hydroshare a new paradigm in hydrologic and earth system modeling is emerging where software once developed for individual research are being reconfigured in community open source research software systems in this context components represent a set of scientific and software methods used to represent a physical process e g flow routing and not the entire system of processes e g a distributed hydrologic model simulating multiple physical processes in the water cycle landlab is one such system based on a python language programming library that supports efficient creation and or coupling of 2d numerical models hobley et al 2017 it is a framework geared towards but not limited to earth surface dynamics landlab is composed of three main divisions of code grid components and supporting utilities the spatial template for modeling is created by the landlab modelgrid class modelgrid provides common structured and unstructured e g voronoi polygons data structures where data fields can be attached to grid elements and grid elements can be built as a structured or unstructured grid in a single line of code each physical process is coded into individual landlab class and added to the landlab library as a component providing an ecosystem of hypothesized behavior of earth system processes supporting utilities and driver scripts were developed to pre process post process and improve workflow efficiencies for coupling multiple components most components operate on interact with and update grid fields components can be coupled via data exchange over the grid a model driver is a python script developed to import instantiate and run a single or multiple coupled landlab components landlab utilities provide tools for input output management and visualization in this paper we use models for coupled ecohydrology and spatial vegetation dynamics flow routing adams et al 2017 and landslide probability strauch et al 2018 along with a recently developed climate data handling utility phuong et al 2019 as with the open source nature of landlab a growing community of developers contribute numerical functions process based components and utilities 2 7 user experience design for multiple learning pathways in this section we describe how the knowledge infrastructure can be viewed from the lens of a research workflow presented in appendix a upon publication of a resource and its deployment to users by sharing the location of the resource on hydroshare the users begin learning and exploring the code users may be collaborators in a research project stakeholders of watershed resources and or students the user may explore landlab on hydroshare using the deployed model driver by changing parameter values of the process components and perhaps explores other components by adding them to the driver or in the process of exploring the model the user may develop their own new ideas to develop new process representations presented as new components in landlab or develop new ways of data visualization these new developments on landlab components will continue when users who contribute their work to the landlab repository track and manage landlab version updates and its further deployment on to hydroshare these model developments can continue offline by installing and using landlab on a personal computer or other jupyterhub servers 2 8 data and models for three computational narratives to illustrate our methods for lowering the barriers to computational modeling we have developed three computational narratives for user experience ux table 1 a computational narrative can be considered a story that can be told about the data by executing scripts that generate data analysis and visualization in the provided workflow recognizing that every experience is made of many parts that contribute to the adoption and evolution of tool development and the narrative see section 4 inductive and or deductive can provide a framework for a user to generate their own story by exploring the science topic with interactive tools a ux can be described as a computer human interaction the importance of ux design is becoming more widely recognized in science and technology development to achieve the desired outcome of the ux such as improving the knowledge base and cognitive capabilities of users baldwin 2013 glassdoor 2017 given that an experience may be generated by any interaction we designed three example computational narratives to generate individual experiences share understanding on existing theory and to open doors for future developments forlizzi and ford 2000 in the first case we give an example of how to use this infrastructure fig 1 to develop training and educational materials for classroom curriculum this example focuses on the use of flexible components in a modeling framework to demonstrate two approaches for flow routing from simple to more complex solution of the same shallow water equation with inductive narrative workflows designed to orient new users to a focused set of theoretical concepts that can be explored with minimum background in the computational infrastructure or coding in the second case we illustrate how a researcher may execute a model to replicate reported findings in a published study on annual landslide probability we particularly focus on how the use of a controlled software environment provides easy access to new users of the tool and facilitates the exploration of other questions associated with the processes investigated using the same tool and data this is an example of a deductive workflow where new hypotheses are tested using a published set of tools and data in the third computational narrative we present a more sophisticated example for executing a published ecohydrology model enhanced and applied in a new location it uses a component bundling idea for efficient scenario building to explore eco hydrologic response to a climatic gradient mediated by elevation this example illustrates a research cycle that includes both inductive and deductive workflows to generate new understanding computational narratives demonstrate how to use knowledge infrastructure to educate replicate and reuse earth surface models where the user interacts with the infrastructure to develop their own story notebooks are designed with up to 10 sections for example for the example see 4 1 notebook section 1 introduces the theory and the conceptual design of the models for example in the first notebook we begin with the theory of the 1 d saint venant equation for transient shallow water flow which is at the core of many hydrodynamic models data science and cyberinfrastructure methods are provided in notebook section 2 0 followed by landlab methods notebook section 3 0 notebook sections 1 to 3 are designed to function as an interactive textbook or reference in the section labeled make model decisions notebook section 4 0 our aim is to clearly distinguish the component based options for designing a model experiment for example in the first notebook we provide options for designing a storm hydrograph based on the choice of basin storm intensity and routing method model computations notebook section 5 0 and results notebook section 6 0 provide code to execute the model visualize results and export data discussion 7 0 conclusions 8 0 and saving results to hydroshare notebook section 9 0 are designed to support graduate level coursework in hydrologic processes and modeling finally users are provided shell script prompts that can be executed in the jupyter notebook to remove data from the jupyterhub server after completing their work notebook section 10 3 results in our results we describe three computational narratives we designed to lower barriers to computational modeling using the ci described in section 2 we relied on juptyer notebooks for sharing the following computational narratives and designed the sequence of commentary text and code blocks to be generally useful to earth surface modeling research communities hanney and savin badem 2013 suggest that combining project and problem based learning may be the best practice for generating engagement critical thinking and creativity with the use of problem based learning as an important tool for providing authentic experiences highly valued by all learners kokotsaki et al 2016 the interactive landlab notebooks described in sections 3 1 3 2 and 3 3 are available on hydrosshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 3 1 notebook 1 exploring runoff hydrographs with landlab 3 1 1 notebook 1 overview this notebook provides resources to compare two different flow routing schemes kinematic wave and overland flow 2d de almeida 2012 solution of the saint venant equation as explained on the notebook in detail in two different landscapes for a given rate of rainfall excess rainfall in excess of infiltration the notebook can be used to investigate process based questions on the generation of overland flow hydrographs across the landscape in relation to the role of runoff rate watershed topography network structure and surface roughness and it allows to compare and contrast the properties of streamflow hydrographs generated by the two different flow routing algorithms to provide a contrast between different landscape shapes this notebook uses two domains a watershed from central colorado spring creek and a modeled rectangular landscape obtained by running an existing fluvial landscape evolution model driver in landlab adams et al 2017 both landscapes have a drainage area of 36 km2 and a cell size of 30 m rain falls on the landscape and flows downhill driving overland flow and a hydrograph at every location on the landscape in this notebook we track the hydrograph at three points in the watershed we recommend that the users review introductory concepts of overland flow and hydrographs before using this notebook and develop familiarity with the term s rainfall intensity and duration as well as peak discharge hydrograph time to peak rising limb and falling limb our aim is to clearly distinguish the component based options for designing a storm hydrograph based on the choice of basin storm intensity and routing method 3 1 2 notebook 1 interactive steps the notebook is designed to run the model several times each time changing the rainfall characteristics routing methods or watershed on which flow is routed different combinations of model components or model instance will generate different hydrographs through which the user can explore how different parameters affect hydrograph characteristics we have provided code to import spatial data linked to the original source of the use of this notebook adams et al 2017 published on hydroshare so that code can be reproducibly executed with the original ascii text files on a personal computer in initial runs the user does not need to change any code but different scenarios can be developed by switching between test watersheds by changing model parameters such as basin flag to equal spring creek or to square table 2 lists the parameters used to obtain the results shown in fig 2 to generate a storm hydrograph over a modeled time period approximately 50 000 model timesteps seconds could take up to ten minutes of computational run time section 5 0 on existing computer infrastructure in development for xsede also possible on commercial cloud platforms we illustrated outputs from the flow routing notebook in fig 2 the user selects which landlab component to run kinwaveimplicitoverlandflow or overlandflow components 3 1 3 impacts on numerical modeling education using an interactive notebook as a component of the science and engineering curriculum is expected to increase student and faculty access to modeling tools rather than relying on software in a computer laboratory or asking students to install new software on their computers the code can be used in any classroom by every student with access to any computer with a web browser the example illustrates how model methods and output options can be developed to enhance multifaceted learning experience of the process of interest in the first notebook there are three main components and various scenarios to explore two different watersheds two routing methods and three different storms students can simultaneously run scenarios by systematically changing the flags e g routing method basin flag and storm flag re running all code blocks sequentially and saving the resulting hydrograph plots for each scenario to use in project reporting or homework the two different flow routing methods show the outcome of including the gradients of fluid pressure and bed elevation and friction terms of the shallow water equation with different assumptions on hydrographs multiple locations for plotting hydrographs in two watersheds will show the role of catchment size and properties different excess rainfall intensities are for exploring how increased runoff depth change the hydrograph properties advanced students may use the code to build their own visualization landlab components or model optimizations because all students can gain hands on experience with the model and code during the classroom instruction it increases the opportunity and depth of discussions between classmates by providing peer to peer learning environment 3 1 4 notebook 1 access to run this notebook go to this hydroshare resource appendix a supplementary data https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 click on the blue open with button select jupyterhub conceptually this will bring you to block 4 in fig 1 the system will certify you are a hydroshare user if not you will be asked to sign up at https www hydroshare org download the data and notebooks from this hydroshare resource to a personal user space in the hydroshare cloud click on the file explore routing tutorial ipynb alternatively advanced users edits are required to remove hydroshare dependencies can download the notebook to run on a personal computer with an installed version of landlab with instruction available in the hydroshare readme md further the notebook can be directly downloaded no requirement to become a hydroshare user at this link explore routing tutorial ipynb or viewed on github in the landlab organization https github com christinab pub bandaragoda etal ems repository see the explore flow routing folder for example view at this link https github com christinab pub bandaragoda etal ems blob master explore routing tutorial ipynb 3 2 notebook 2 replicate a landslide model to explore fire impacts on slope instability in a watershed within a regional study 3 2 1 notebook 2 overview landslides are notoriously challenging to predict van westen et al 2006 a new model developed as a component in landlab landslideprobability offers the ability to predict the probability of shallow landslide initiation at regional scales probability of landsliding is calculated by the infinite slope stability equation using a monte carlo approach by introducing uncertainty to soil vegetation and recharge variables this model was first implemented in a 2700 km2 area in the north cascades national park complex noca of washington state fig 3 where annual probability and return period for shallow landslide initiation was mapped for different soil depth products fig 4 strauch et al 2018 considering the uncertainty of soil depth root cohesion and mechanical soil properties the model predicts 20 40 of the area with a landslide return period of 1 in 100 years or less fig 4 in comparison to notebook 1 designed for classroom use this notebook is designed to replicate model results from strauch et al 2018 in thunder creek watershed located within noca it calculates the probability of shallow landslide initiation at a 30 m rectangular grid resolution across the watershed using gridded datasets of landscape characteristics for topography slope and upslope catchment area land use and land cover vegetation type root cohesion soil internal friction angle and transmissivity and annual maximum daily subsurface flow recharge rate derived from a previously run hydrologic model all the resources needed for model application are obtained from the existing hydroshare resource from strauch et al 2018 code is provided to import data from the regional noca area and create a subset of this data covering thunder creek watershed through import of a watershed boundary shapefile the mean relative wetness and probability of saturated conditions at each grid cell are also calculated in the process of calculating the probability of landsliding the notebook is designed for exploring the sensitivity of landsliding to environmental conditions that lead to loss of root cohesion such as a wildfire or timber harvest 3 2 2 notebook 2 interactive steps for detailed instructions for notebook access see section 3 1 4 and use the jupyter notebook replicate landslide model for fire ipynb for this example the notebook is organized with an introduction notebook section 1 0 to the infinite slope factor of safety equation which predicts the ratio of stabilizing to destabilizing forces on a hillslope plane and the monte carlo solution developed to compute probability of landslide initiation data science and cyberinfrastructure methods are provided in notebook section 2 0 that describe specifics of accessing existing spatial data extracting information for the watershed of interest followed by landlab methods for setting model parameters in the notebook subsection labeled specify recharge our aim is to clearly distinguish the component based options for studying the impact of assumptions related to recharge and hydrologic forcing on landslide probability at the end of this notebook section the number of monte carlo iterations is assigned in notebook section 3 0 results the model is executed for thunder creek and the results are visualized steps for saving results back to hydroshare are listed in notebook section 4 0 to support graduate level coursework in hydrologic processes and modeling we include code blocks that print more explanatory variables and numerical values to verify results are as reported in strauch et al 2018 in this demonstration notebook the user imports necessary python utilities and libraries and reviews the data needed to execute the landslide model code is provided to import data from the regional noca area and create a subset of this data covering thunder creek watershed through import of a watershed boundary shapefile one of four recharge options is specified and the user loads existing mapped landslides to overlay on the landscape to compare with the probabilistic landslide hazard map the user specifies the number of iterations to use in a monte carlo simulation then runs the landslideprobability component with two cohesion assumptions the first cohesion assumption is based on existing conditions as described in strauch et al 2018 the second cohesion assumption generating a second model instance approximates post fire conditions where root cohesion is reduced by 70 this represents the reduced root cohesion following a wildfire as existing roots decay following wildfire while new roots begin to regenerate sidle 1992 istanbulluoglu et al 2004 finally maps are generated to compare the results of the stability analyses and results can be saved back to hydroshare fig 5 replication of the strauch et al 2018 model in thunder creek for potential postfire conditions clearly show an increase in annual probability of failure pf when the root cohesion is reduced following wildfire in the pre fire simulation 25 of the landslide is unconditionally unstable pf 1 0 meaning that the soil cannot stand on these slopes this high annual probability is a conservative estimate and it is largely due to the use of the ssurgo soil depth product in this application strauch et al 2018 discussed how more processed based modeling of soil depth reduce pf to more realistic ranges with wildfire impact unconditionally unstable regions grew to 40 of the watershed before fires 40 of the watershed is unconditionally stable pf 0 0 these regions are located in the lower portions of u shaped pro glacial valleys fig 5 with a vegetation disturbance such as wildfire this fraction is reduced to 5 which could lead increased sediment input from the sides of u shaped valley directly to the valley floor and result in decline of aquatic habitat quality 3 2 3 impacts on replicating scientific findings this notebook is designed for earth scientists and stakeholders who are interested in understanding the landslide hazard risk as a probability in space and time running this notebook using landlab leverages the software infrastructure of the landlab python toolkit which standardizes the handling of spatial temporal data executing the notebook on hydroshare allows the ability to store necessary data deploy the model via a super computer and see the results which can be evaluated and shared thus the notebook becomes a one stop online platform for demonstrating the landslide model and facilitating ease of model augmentation current barriers to conducting landslide hazard analysis includes the ability to consider landscape variability data uncertainty and hydrological triggering mechanisms over a large spatial scale this narrative helps reduce the barrier of significant time investment to implementing a complex model by providing the necessary data and code for implementing the landlab landslideprobability component as a result the researcher can see what the model requires and how it runs to produce the results presented in a publication the notebook can provide an example that can be modified to use in a new study effectively across the nation additionally the barrier to accessing compiled observations and research products is overcome with this notebook including compiled spatial temporal visualizations that can be used to communicate results 3 2 4 notebook 2 access a published regional landlab shallow landslide model has been developed to explore changes in forest cover at a subcatchment scale within the noca study area using the jupyter notebook replicate landslide model for fire ipynb this notebook is available on hydroshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 for detailed instructructions on notebook access see section 3 1 4 or the readme found at the hydroshare link 3 3 notebook 3 reuse an ecohydrology model with gridded hydrometeorology forcing 3 3 1 notebook 3 overview in semiarid regions climate change and human impact can lead to dramatic changes in the composition and organization of plant functional types pfts such as trees and shrubs and thus the biomass production of the ecosystem ecohydrologic vegetation dynamics models are tools that can be used to explore the role of climatology on the spatial organization of pfts fatichi et al 2016 in this notebook we adapt landlab s ecohydrologic vegetation dynamics model to illustrate how an existing model can be reused by enhancing and developing a workflow at a new location in our case for studying the role of elevation dependent precipitation and temperature gradients on pfts using historical gridded daily weather data from livneh et al 2015 broad elevation bands low 1200 1700 m medium 1700 2000 m and high 2000 2500 m are developed and the ecohydrology model in landlab is implemented to simulate the resultant organization of pfts at each elevation band in the state of new mexico on hypothetical flat surfaces with a spatially homogenous soil textural properties fig 6 the landlab ecohydrology model we used is based on catgrass cellular automaton tree grass shrub simulator a discrete time cellular automaton ca model for spatial evolution of pfts zhou et al 2013 in catgrass each cell in the domain can be occupied by a single pft tree shrub grass or left unoccupied as bare soil the model couples local ecohydrologic vegetation dynamics which simulate biomass production based on local soil moisture and actual evapotranspiration with spatial processes for plant establishment and mortality controlled by seed dispersal rules water stress tolerance and space availability trees and shrubs disperse seeds to their neighbors grass seeds are assumed to be available everywhere establishment of plants in bare cells is determined probabilistically based on water stress of pfts neighboring the bare cells plants with lower water stress have higher probability of establishment plant mortality is simulated probabilistically as a result of aging and drought stress the model is driven by rainfall pulses observed or generated solar radiation and temperature the latter two variables can also be used to prescribe a seasonal potential evapotranspiration input in landlab the model is implemented as a set of interacting components each describing a different element of the coupled system precipitationdistribution radiation potentialevapotranspiration soilmoisture vegetation component for local growth and vegca component for cellular automaton rules 3 3 2 notebook 3 interactive steps and model results for detailed instructructions for notebook access see section 3 1 4 in this example we constructed a reproducible ecohydrology model using landlab and hydroshare for a new mexico example for details on methods designed to reuse the model in another location in the continental united states please see the jupyter notebook reuse ecohydrology gridhydromet ipynb in this notebook we define the geographic subset new mexico within north america and download gridded hydrometeorologic data from livneh et al 2015 for this region then we bin this data into three elevation ranges by considering elevation of centroids of the cells in the gridded dataset and calculate the spatial means of daily precipitation maximum and minimum temperature for each bin these data are used to force the ecohydrology model at each elevation bin the hydrometeorological data handling steps are executed in a separate notebook named observatory gridmet newmexico ipynb located in the folder ogh newmexico which runs a recently developed python package for automated retrieval preprocessing and visualization of gridded hydrometeorology data products phuong et al 2019 as we described in the jupyter notebook for this example we found that the livneh et al 2015 data had a wet bias in precipitation this bias is corrected by gathering weather station data moore 2016 that span the range of the elevation bins we used from the livneh et al 2015 data time series of bias corrected annual precipitation and mean monthly temperature show wetter and cooler conditions as elevation grows fig 7 there is a positive trend in annual precipitation from 1950 to 1990 followed by a slight negative trend in the application of this notebook we suggest the users to explore the model outputs to see if this precipitation trend had any impact on the spatial cover fractions of pfts following the bias correction the three elevation bins resulted in climatology s from arid in the low elevation bin to semiarid conditions in the high elevation bin according to the aridity index classification nash et al 1999 discussed in relation to model results below since the historical data extends only for 64 years fig 7 we extended the record to by tiling the daily historical data to facilitate longer vegetation development simulations the limitation of this approach is that the same climate repeats itself in every 64 years the notebook presents three model runs to explore the role of elevation dependent changes in the regional climatology on modeled spatial patterns of pfts shrub grass tree and plots the time series of annual areal cover fraction of each pft that emerge in the domain for a model run time of 1500 years the notebook begins with an introduction notebook section 1 0 to the landlab ecohydrology model and the landlab components used to build this model data science and cyberinfrastructure methods are provided notebook section 2 0 followed by climate methods notebook section 3 0 and ecohydrology modeling using landlab methods notebook section 4 0 finally instructions to save the results back into hydroshare notebook section 5 0 are given starting with a randomly distributed equal fractions of tree grass shrub vegetation and bare soil the model organizes the spatial distribution of pfts through time in the low elevation band map 217 mm pet 1601 mm y aridity index ai 7 34 the local climate can be considered arid ai 5 nash et al 1999 drought tolerant shrub vegetation outcompetes trees leaving a few trees behind while grass gradually retreats leading to an ecosystem where shrubs dominate but co exist with grass as a secondary pft the modeled pft map fig 8 a left shows pockets of grass clusters within the shrub domain a few small clusters of trees still exist in very low fraction of the domain it would be interesting to explore how the grass shrub interplay shape over longer time using this model note that the bell shaped response of grass and to an extent shrubs in this simulation can be attributed to the trends in the precipitation data in the historical period giving 5 10 boost to the areal grass coverage and 5 for shrubs the repetition of the bell shaped response is due to the tiling of the historical precipitation and temperature data in the mid elevations map 285 mm pet 1427 mm y ai 5 in the arid to semiarid climate transition nash et al 1999 the conditions are cooler and wetter compared to low elevation band in this example these conditions provide moisture to sustain enough healthy trees allowing them to outcompete shrubs as trees can spread seeds to longer distances than shrubs for establishment to become the primary pft grass grows in empty spaces that are not surrounded by healthy trees or shrubs due to two reasons 1 the availability of seeds everywhere 2 lack of pfts that outcompete them for establishment as trees and shrubs are competing this leads to an ecosystem dominated by trees but co existing with grass as secondary pft and shrubs as the tertiary pft fig 8 b right it will be worthwhile to check whether this ecosystem can sustain the co existence of the three pfts for longer periods of time at high elevations map 353 mm pet 1293 mm y ai 3 66 climate is the coolest and wettest among the three elevation bands and fall in the semi arid category nash et al 1999 trees dominate shrubs gradually leading to an ecosystem dominated by trees while grass retreats gradually and stabilize only few small shrub clusters remain after 1500 year users can run this model longer to see if shrubs will completely disappear from the ecosystem in addition to running the notebooks for a longer period of time as discussed above one can also edit the model inputs by modifying the file ecohyd inputs yaml located in the folder supporting files and explore various hypotheses for example by changing the soil texture or modifying vegetation parameters to explore how local vegetation dynamics can impact the spatial organization of plants 3 3 3 impacts on use and reuse of research models this notebook is designed for earth scientists who are interested in understanding the influence of climate on long term climate driven changes the spatial vegetation patterns in semi arid landscapes the ecohydrologic vegetation dynamics model built in landlab leverages the framework s flexibility for building numerical models from components and utilities available in its library in this example we have demonstrated how to use a landlab model multiple times on hydroshare using downloaded gridded meteorological datasets with the ogh library phuong et al 2019 3 3 4 notebook 3 access in this example we use a ecohydrology model with landlab and hydroshare in a new mexico example or to reuse in another location in the continental united states please see the jupyter notebook reuse ecohydrology gridhydromet ipynb this notebook is available on hydroshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 for detailed instructructions on notebook access see section 3 1 4 or the readme found at the hydroshare link 4 discussion broadly speaking knowledge infrastructure can be considered a social construct components of hardware and software are built by a community of developers based on a perceived need or by employing user experience research to guide design decisions when the advanced cyberinfrastructure has evolved to knowledge infrastructure the design of the software system is a creative and problem solving endeavor developed with a community committed to using it for their research and education with feedback and investments of resources we discussed knowledge infrastructure as a web based system of tools that can be adapted and co opted to develop technological and sociological solutions to emerging problems of complex systems by efficiently connecting researchers their data and models private and public users and funders committed to long term maintenance and operations of distributed computing resources through the work of developing a description of how others can interact with our earth surface model results we learned that the system outlined in fig 1 is just one realization of how to synthesize components to run landlab models on hydroshare we expect that this model will evolve with each research application model and user especially as technology advances and user input improves usability all users benefit when systematic processes support training for learning new tools and incorporating emerging technology into scientific methods there are two main challenges to conducting sophisticated earth surface model applications 1 they are computationally and data intensive and 2 communication of methods and results through traditional peer reviewed journal publications conference presentations as well as student mentor and peer peer relationships may not be efficient at ensuring reproducible results here we consider reproducible to include both the ability to replicate published results e g testable by editors reviewers or readers and to reuse the research products as a baseline for future studies e g accessible code and data reproducibility in earth surface modeling is time and resources expensive and addressing the challenges above is common across most of computationally intensive sciences requiring research software development for example a spatially distributed numerical model application for landslide risk should be reproducible both at the site where model is calibrated and applied in a paper and the cyberinfrastructure should provide the flexibility for the same model to be applied at another site just by changing several spatial inputs on the same platform for another example an individual researcher may choose a personal cyberinfrastructure system horsburgh et al 2016a b that they design develop and or inherit from colleagues whereas a research collaboration such as a study by multiple domain scientists and institutions may require co design of a community knowledge infrastructure to address a broad range of formal and informal processes that support the ongoing development of research products we submit for consideration by the earth surface research community that more attention on system design for both personal cyberinfrastructure and shared knowledge infrastructure will accelerate our research productivity the aim is to deploy the latest technologies in such a way as to minimize the researchers effort to acquire expertise in technologies outside their domain and to better enable domain scientists to focus their attention on the theoretical underpinnings and development of new process based understanding of the earth system in the current rapidly evolving environment of computer technologies the community of researchers often needs to keep pace with technological advancements such as new computational platforms high performance and cloud computing open source modeling frameworks and software paradigms libraries and tools we identified barriers that can be addressed with knowledge infrastructure design in research section 4 1 we found that these barriers can be lowered by including user input in the system development process section 4 2 which we expect to advance science through simultaneously supporting both inductive and deductive learning processes section 4 3 4 1 defining five common barriers using two user centered design methods devi et al 2012 expert review with landlab researchers and guided walkthrough with tutorials in workshops and classrooms we outline the following five common barriers and sought to lower these for more students and researchers by utilizing community resources for numerical modeling 1 unclear processes in conducting open research vocabulary workflow and metrics for success are not well understood and standards of practice are at the early stages of development 2 technological requirements for hands on learning training and workforce development using large datasets and high performance computing requires expertise beyond the experience of most domain scientists 3 hardware and software requirements for using online infrastructure in workshops and classrooms software installations and model run time on local computers limits the time available to introduce new concepts and tools 4 compiled observations and research products e g model results are difficult to access data driven introduction to science concepts is time intensive and there are no best practices for classroom interaction with large datasets and coupled spatial temporal visualizations of published model results 5 time investment and expertise required to begin using a complex model is too high in many collaborations only one model expert can execute interact and manipulate the model which limits building deeper understanding and communicating about implementing new ideas 4 2 development based on user input knowledge infrastructure can be effective at lowering common barriers if it is designed based on input of users user information may include cultural formal and informal preferences for conducting research and sharing data for example design of knowledge infrastructure to to improve communications among users is generally perceived to have the potential to lead to rapid advancements in process and system level understanding through data analysis and modeling scientists and users from multiple research and decision making communities have shared needs to expand their understanding of processes at specific locations on the earth surface for research communities the focus is always on advancing scientific understanding for other user communities such as those applying the latest research to improve data collection or operating resources based on observational and modeled data the focus may be on incrementally developing systems to use the gained knowledge to adapt to changing conditions mees 2017 dilling et al 2017 hughes s a 2014 nalau et al 2015 baker et al 2012 regardless of the structure of the system users and developers want a simple work experience where they launch a web browser and quickly get to work regardless of what the purposes of modeling and the background of users might be functional knowledge infrastructure should give enough confidence to users to run models reproduce and reuse model applications analyze results and communicate their findings and unique perspectives on the complex system behavior they are investigating 4 3 development to advance science to encourage continuous scientific advancement in the earth science domain we advocate that researchers develop their data and models using knowledge infrastructure that enables replication and reuse and consider leveraging open source data and research software wherever possible this approach is ideal for graduate education where data and models published using shared standards in an open source system can be replicated reused and advanced by other investigators additionally code reproducibility may shorten the learning curve for modeling allowing more time to progress research in a domain of science that is supported by using the model and not distracting from work on a primary research questions with data and modeling technical issues if a user follows an inductive learning narrative they may use a workflow fig 9 top to bottom workflow that starts with a new idea and ends with testing a hypothesis or an inductive learning approach section4 3 1 if a user follows a deductive learning narrative section 4 3 2 they may begin with a pre existing experiment or toolset test a hypothesis and then develop new ideas from what they learn during the tests fig 10 bottom to top workflow next we describe how both inductive and deductive narratives are supported 4 3 1 inductive learning approach an inductive learning approach develops evidence and inference by selecting a hypothesized process representation within a system e g landscape testing that hypothesis and depending on the outcome develop a refined hypothesis of the process and further design testable numerical and field experiments pfister and kirchner 2017 this approach is crucial for advancing theoretical concepts for each process and identifying process couplings most earth science models require laborious work to make them suitable for inductive learning recent component based frameworks like landlab hobley et al 2017 and summa clark et al 2015a 2015 are developed with the perspective that they can be used for inductive learning and research centered on developing a new idea and making use of other published and tested components in the complex system to test one new idea at a time 4 3 2 deductive learning approach a deductive approach is useful when given a precompiled set of model inputs outputs and coupled system of process models the user or cooperative research group can develop new hypotheses to test given emerging research and new observations this is a common workflow in science and engineering after a model in published the code and data are shared such that when new observations or tools are added during continuing research these addenda are added to an existing library and new ideas for tools experiments and data collection emerge and advance the next steps of research the preliminary development of landlab focused on workflow designs where users would begin code development by testing new ideas using published python scripts to develop process representations of individual earth system processes the result is a landlab environment fig 9 with an ecosystem of process components where users can test new ideas resulting in the development of new components that contribute to a shared and expanding library while it is common in earth surface numerical modeling communities to build on and contribute to existing models the landlab approach provides a way for new users to begin learning and contributing by developing simple python scripts that could be executed from a terminal command line landlab provides a means for new users to use an inductive learning approach to study one earth surface process at a time without having to first master the use of pre existing complex model and to contribute code to expand processes represented in the model running landlab on hydroshare fig 1 provides new users the opportunity to quickly begin exploring landlab models with minimal software requirements a web browser and internet connection landlab and hydroshare development and research community can continuously improve and evolve for example by implementing an automated updating system that would maintain landlab version on hydroshare with automated tests the ensure new versions of landlab continue working with all hydroshare resources that use landlab 5 conclusions to illustrate how common barriers to earth surface modeling can be lowered using knowledge infrastructure we have developed three interactive computational narratives using landlab on hydroshare landlab is a recently developed python based earth surface modeling toolkit hobley et al 2017 hydroshare is a web based system that can be used to store share and publish hydrologic data and models idaszak et al 2017 www hydroshare org the infrastructure design and methods are illustrated as an interchangeable set of hardware and software components for our case study we combine an online community repository hydroshare modeling framework landlab software environment dockerized jupyterhub server and storage irods with a community approach to advancing scientific progress using earth surface models we demonstrate how to use this system in a classroom setting to explore spatio temporal data network processes e g hydrologic routing replicate published results from a complex model in a controlled software environment e g landslide model sensitivity to fire related parameters and how to use the same system to reuse flexible components to design a model experiment e g ecohydrology model sensitivity to elevation and climate that can be used generate new results in any location in the continental united states the use cases we present have been designed to illustrate a range of functions and show the benefits of using knowledge infrastructure to transform how researchers share publish and distribute knowledge given a range of science topics to address common challenges to using online systems for collaborative numerical modeling in the past running distributed hydrology landslide and ecohydrologic vegetation dynamics landlab model components required access to a powerful computer an installation of python and an installation of landlab now any user can log into hydroshare through an internet browser from any computer or handheld device and run this model without having to install any software the user can explore the models further by changing the model parameters climate forcings or building their own model with community support the demonstrated knowledge infrastructure enabled by advanced cyberinfrastructure is designed to support researchers in more efficiently advancing earth system knowledge software and or data availability models described in this manuscript are available on hydroshare citation bandaragoda c a m castronova j phuong e istanbulluoglu s s nudurupati r strauch n lyons k barnhart 2019 enabling collaborative numerical modeling in earth sciences using knowledge infrastructure landlab notebooks https zenodo org badge latestdoi 187289993 accessed 5 30 2019 replicated in hydroshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 landlab can be installed from conda forge with windows 7 mac os 10 6 or ubuntu linuxogh v 1 5 4 is released on github https github com landlab landlab releases and is freely available under an mit license this github repository is maintained by the landlab development team the landlab python library is also vailable within a jupyterhub unix docker environment hosted on the cuahsi hydroshare server tutorial use case notebooks for developers can be found at the github repository https github com christinab pub bandaragoda etal ems and the hydroshare resource https www hydroshare org resource fdc3a06e6ad842abacfa5b896df73a76 acknowledgments we acknowledge funding from nsf for hydroshare aci 1148453 tarboton bandaragoda aci 1148090 idaszak oac 1664018 idaszak oac 1664061 bandaragoda idaszak tarboton and oac 1664119 wang cuahsi ear 1338606 castronova and the community surface dynamics modeling system csdms ear 1831623 these development grants supported a team including the consortium of universities for the advancement of hydrologic science inc cuahsi utah state university brigham young university tufts university university of virginia university of washington national center for atmospheric research ncar purdue university university of texas at austin and san diego supercomputing center for the development of the hydroshare platform http www hydroshare org from 2012 to 2018 for roger supercomputing oac 1429699 wang and advanced cyberinfrastructure oac 1443080 oac 1429699 and oac 1047916 wang and cybergis aci 1047916 wang idaszak for landlab oac 1450412 istanbulluoglu oac 1147454 oac 1450409 tucker hobley oac 1450338 ear 1349375 the oliver fund of tulane university gasparini lyons and for landslide research cbet 1336725 istanbulluoglu barnhart acknowledges an nsf ear postdoctoral fellowship ear 1725774 this project received partial funding from the european union s horizon 2020 research and innovation programme under the marie skłodowska curie grant agreement no 663830 hobley the authors are grateful for this diversity of contributions any opinions findings conclusions or recommendations expressed in this material are those of the authors and developers and do not necessarily reflect the views of the nsf or other funding organizations all data and code used in this research are available on github landlab and hydroshare organizations as well as hydroshare www hydroshare org where readers can collaborate join the public landlab group and view shared public data described in this paper abbreviations ki knowledge infrastructure ci cyberinfrastructure cuahsi consortium of universities for the advancement of hydrologic science inc csdms community surface dynamics modeling system icts information and communication technologies gui graphical user interfaces pc personal computer hpc high performance computing chpc cloud based high performance computing soa services oriented architecture oai ore open archives initiative object reuse and exchange standard doi digital object identifier rest representative state transfer api application programming interface summa structure for unifying multiple modeling alternatives nwm national water model odm2 observation data model 2 xsede extreme science and engineering discovery environment roger resourcing open geospatial education and research supercomputer ux user experience modflow the usgs modular three dimensional finite difference ground water flow model taudem terrain analysis using digital elevation models swat soil and water assessment tool wepp water erosion prediction project wilsim web based interactive landform simulation model noca north cascades national park complex ssurgo soil survey geographic database catgrass cellular automata tree grass shrub simulator pft plant functional types map mean annual precipitation pet potential evapotranspiration appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online athttps doi org 10 1016 j envsoft 2019 03 020 
26162,knowledge infrastructure design 2 2 community supported collaborative web platform hydroshare 2 3 1 distributed data storage 2 3 2 resource exploration discovery and management 2 3 3 actions on resources through web apps 2 4 software environment cuahsi jupyterhub 2 4 1 community supported development and operation 2 4 2 tools and models 2 4 3 landlab community 2 5 advanced cyberinfrastructure and cybergis jupyter 2 6 modeling framework landlab and its application on hydroshare 2 7 user experience design for multiple learning pathways 2 8 data and models for three computational narratives 3 results 3 1 notebook 1 exploring runoff hydrographs with landlab 3 1 1 notebook 1 overview 3 1 2 notebook 1 interactive steps 3 1 3 impacts on numerical modeling education 3 1 4 notebook 1 access 3 2 notebook 2 replicate a landslide model to explore fire impacts on slope instability in a watershed within a regional study 3 2 1 notebook 2 overview 3 2 2 notebook 2 interactive steps 3 2 3 impacts on replicating scientific findings 3 2 4 notebook 2 access 3 3 notebook 3 reuse an ecohydrology model with gridded hydrometeorology forcing 3 3 1 notebook 3 overview 3 3 2 notebook 3 interactive steps and model results 3 3 3 impacts on use and reuse of research models 3 3 4 notebook 3 access 4 discussion 4 1 defining five common barriers 4 2 development based on user input 4 3 development to advance science 4 3 1 inductive learning approach 4 3 2 deductive learning approach 5 conclusions software and or data availability acknowledgments abbreviations appendix a supplementary data adams 2014 b dakotaamultilevelparallelobjectorientedframeworkfordesignoptimizationparameterestimationuncertaintyquantificationsensitivityanalysisversion60usersmanual adams 2017 1645 1663 j dealmeida 2012 g anders 2008 479 a apachesolr atkins 2003 d atkinsreportrevolutionizingscienceengineeringthroughcyberinfrastructurereportblueribbonadvisorypanelcyberinfrastructure baker 2012 127 136 i baldwin 2013 h techhotshotsriseuxexpert bandaragoda 2006 2 6 c bandaragoda 2019 c borgman 2015 207 227 c brooks 1996 317 328 k proceedingsfourthacminternationalconferencemultimedia storyagentsuserockingchairstheoryimplementationonemodelforcomputationalnarrative castronova 2018 a dockerfileforhydrosharejupyterhubbaseimage clark 2008 m clark 2011 m clark 2015 2515 2542 m clark 2015 2498 2514 m devi 2014 2250 3153 aworkingframeworkforusercentereddesignapproachasurveyavailablemethods dilling 2017 2628 2648 l ding 2014 357 360 t django 2018 webframeworkforperfectionistsdeadlinesdjango edwards 2013 p essawy 2018 217 229 b flanagan 2007 1603 1612 d forlizzi 2000 j symposiumdesigninginteractivesystems buildingblocksexperienceearlyframeworkforinteractiondesigners freeman 2005 682 691 p freire 2016 j reproducibilitydataorientedexperimentsinesciencedagstuhlseminar16041 gross 2014 939 943 a han 2015 1334 1350 j hanney 2013 r hobley 2017 21 46 d horsburgh 2016 55 74 j horsburgh 2016 873 889 j horsburgh 2017 83 94 j hughes 2014 s presentedcarolinasclimateresilienceconferencecharlottenc ametaanalysislocalclimatechangeadaptationactionsscienceinventoryepa hutton 2016 7548 7555 c idaszak 2017 219 233 r softwareengineeringforscience hydroshareacasestudyapplicationmodernsoftwareengineeringalargedistributedfederallyfundedscientificsoftwaredevelopmentproject irods istanbulluoglu 2004 e jones 2017 1095 1120 a kadlec 2015 19 28 j kluyver 2016 t positioningpowerinacademicpublishingplayersagentsagendasproceedings20thinternationalconferenceelectronicpublishing jupyternotebooksapublishingformatforreproduciblecomputationalworkflows kokotsaki 2016 267 277 d laflen 1997 96 102 j laflen 1991 34 38 j lagoze 2008 c objectreuseexchangearesourcecentricapproach lemos 2012 789 794 m livneh 2015 150042 b aspatiallycomprehensive luo 2004 215 220 w luo 2016 60 73 w mani 2013 i computationalnarratology mees 2017 374 390 h merkel 2014 d mezzanineprojectthebestdjangocms mihalevich 2017 593 b moore 2008 r moore d morsy 2017 13 28 m nalau 2015 89 98 j nash 1999 d netzeva 2005 155 173 t newman 2003 167 256 m nosek 2015 1422 1425 b pande 2017 e1193 s perez 2015 f projectjupytercomputationalnarrativesenginecollaborativedatascience perkel 2019 17 18 j pfister 2017 1792 1798 l phuong 2019 j rajib 2016 498 512 m ragankelley 2013 461 464 b shen 2014 151 h sidle 1992 1897 1910 r stagge 2019 j stocker 2018 21 m strauch 2018 49 75 r tarboton d tarbotondthehydroshareteam 2018 collaborativeresearchsi2ssicyberinfrastructureforadvancinghydrologicknowledgethroughcollaborativeintegrationdatasciencemodelinganalysis tarboton 2014 d internationalconferencehydroinformatics aresourcecentricapproachforadvancingcollaborationthroughhydrologicdatamodelsharing tarboton 2014 d presented7thinternationalcongressenvironmentalmodellingsoftwareiemss2014 hydroshareadvancingcollaborationthroughhydrologicdatamodelsharing tarboton d tesfa 2011 1696 1709 t tucker 2010 28 50 g vanwesten 2006 65 c wang 2010 535 557 s wang 2016 965 968 s 2019 cybergisforgeospatialdiscoveryinnovation yetemen 2015 1127 1157 o yi 2018 233 240 h yin 2017 18 1 18 8 d proceedingspracticeexperienceinadvancedresearchcomputing2017sustainabilitysuccessimpact acybergisjupyterframeworkforgeospatialanalyticsscale yuan 2018 167 z zhou 2013 x bandaragodax2019x104424 bandaragodax2019x104424xc 2020 09 10t00 00 00z https vtw elsevier com content oragreement 10144 chu nsf publishacceptedmanuscriptindexable http www elsevier com open access userlicense 1 0 2020 09 10t00 00 00z http creativecommons org licenses by nc nd 4 0 2019 published by elsevier ltd 2022 06 10t21 38 34 628z http vtw elsevier com data voc addontypes 50 7 aggregated refined brigham young university byu brigham young university http data elsevier com vocabulary scivalfunders 100006756 http sws geonames org 6252001 university of washington uw university of washington http data elsevier com vocabulary scivalfunders 100007812 http sws geonames org 6252001 tufts university tufts university http data elsevier com vocabulary scivalfunders 100008090 http sws geonames org 6252001 community surface dynamics modeling system ear 1831623 national center for atmospheric research ncar national center for atmospheric research http data elsevier com vocabulary scivalfunders 100005323 http sws geonames org 6252001 utah state university usu utah state university http data elsevier com vocabulary scivalfunders 100006630 http sws geonames org 6252001 oliver fund of tulane university cbet 1336725 cuahsi ear 1338606 cuahsi consortium of universities for the advancement of hydrologic science http data elsevier com vocabulary scivalfunders 100018070 http sws geonames org 6252001 purdue university university of texas at austin cybergis aci 1047916 ear 1349375 oac 1047916 oac 1147454 oac 1429699 oac 1443080 oac 1450338 oac 1450409 oac 1450412 european union apos s horizon 2020 research and innovation programme horizon 2020 http data elsevier com vocabulary scivalfunders 501100007601 http sws geonames org 6695072 nsf aci 1148090 aci 1148453 oac 1664018 oac 1664061 oac 1664119 nsf national science foundation http data elsevier com vocabulary scivalfunders 100000001 http sws geonames org 6252001 university of virginia uv university of virginia http data elsevier com vocabulary scivalfunders 100008457 http sws geonames org 6252001 landlab group european union s horizon 2020 research and innovation programme h2020 horizon 2020 framework programme http data elsevier com vocabulary scivalfunders 100010661 http sws geonames org 6695072 nsf ear ear 1725774 marie skłodowska curie 663830 msca h2020 marie skłodowska curie actions http data elsevier com vocabulary scivalfunders 100010665 http sws geonames org 6695072 we acknowledge funding from nsf for hydroshare aci 1148453 tarboton bandaragoda aci 1148090 idaszak oac 1664018 idaszak oac 1664061 bandaragoda idaszak tarboton and oac 1664119 wang cuahsi ear 1338606 castronova and the community surface dynamics modeling system csdms ear 1831623 these development grants supported a team including the consortium of universities for the advancement of hydrologic science inc cuahsi utah state university brigham young university tufts university university of virginia university of washington national center for atmospheric research ncar purdue university university of texas at austin and san diego supercomputing center for the development of the hydroshare platform http www hydroshare org from 2012 to 2018 for roger supercomputing oac 1429699 wang and advanced cyberinfrastructure oac 1443080 oac 1429699 and oac 1047916 wang and cybergis aci 1047916 wang idaszak for landlab oac 1450412 istanbulluoglu oac 1147454 oac 1450409 tucker hobley oac 1450338 ear 1349375 the oliver fund of tulane university gasparini lyons and for landslide research cbet 1336725 istanbulluoglu barnhart acknowledges an nsf ear postdoctoral fellowship ear 1725774 this project received partial funding from the european union s horizon 2020 research and innovation programme under the marie skłodowska curie grant agreement no 663830 hobley the authors are grateful for this diversity of contributions any opinions findings conclusions or recommendations expressed in this material are those of the authors and developers and do not necessarily reflect the views of the nsf or other funding organizations all data and code used in this research are available on github landlab and hydroshare organizations as well as hydroshare www hydroshare org where readers can collaborate join the public landlab group and view shared public data described in this paper we acknowledge funding from nsf for hydroshare aci 1148453 tarboton bandaragoda aci 1148090 idaszak oac 1664018 idaszak oac 1664061 bandaragoda idaszak tarboton and oac 1664119 wang cuahsi ear 1338606 castronova and the community surface dynamics modeling system csdms ear 1831623 these development grants supported a team including the consortium of universities for the advancement of hydrologic science inc cuahsi utah state university brigham young university tufts university university of virginia university of washington national center for atmospheric research ncar purdue university university of texas at austin and san diego supercomputing center for the development of the hydroshare platform http www hydroshare org from 2012 to 2018 for roger supercomputing oac 1429699 wang and advanced cyberinfrastructure oac 1443080 oac 1429699 and oac 1047916 wang and cybergis aci 1047916 wang idaszak for landlab oac 1450412 istanbulluoglu oac 1147454 oac 1450409 tucker hobley oac 1450338 ear 1349375 the oliver fund of tulane university gasparini lyons and for landslide research cbet 1336725 istanbulluoglu barnhart acknowledges an nsf ear postdoctoral fellowship ear 1725774 this project received partial funding from the european union apos s horizon 2020 research and innovation programme under the marie skłodowska curie grant agreement no 663830 hobley the authors are grateful for this diversity of contributions any opinions findings conclusions or recommendations expressed in this material are those of the authors and developers and do not necessarily reflect the views of the nsf or other funding organizations all data and code used in this research are available on github landlab and hydroshare organizations as well as hydroshare www hydroshare org where readers can collaborate join the public landlab group and view shared public data described in this paper item s1364 8152 19 30156 2 s1364815219301562 1 s2 0 s1364815219301562 10 1016 j envsoft 2019 03 020 271872 2020 10 12t02 27 59 672677z 2019 10 01 2019 10 31 1 s2 0 s1364815219301562 main pdf https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 main application pdf f6f2698e4ea1c136d4ef2298cd2dab1c main pdf main pdf pdf true 3188158 main 18 1 s2 0 s1364815219301562 main 1 png https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 preview image png 86417c35d32cb687f6132698945432f7 main 1 png main 1 png png 50037 849 656 image web pdf 1 1 s2 0 s1364815219301562 gr1 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr1 thumbnail image gif d8ed2038120a61fa2305870b401f6523 gr1 sml gr1 gr1 sml sml 18357 136 219 image thumbnail 1 s2 0 s1364815219301562 gr2 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr2 thumbnail image gif 738610bca6f952dbb9774a6d2460d983 gr2 sml gr2 gr2 sml sml 18126 164 137 image thumbnail 1 s2 0 s1364815219301562 gr3 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr3 thumbnail image gif 0af114deeaa4d230e4f58a029a6345b4 gr3 sml gr3 gr3 sml sml 27599 125 219 image thumbnail 1 s2 0 s1364815219301562 gr4 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr4 thumbnail image gif b80cf2bdf378f876d4c384add218a59d gr4 sml gr4 gr4 sml sml 33849 154 219 image thumbnail 1 s2 0 s1364815219301562 gr5 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr5 thumbnail image gif 3fef4c80a1d95a7e5f182f899a5d3928 gr5 sml gr5 gr5 sml sml 39277 164 216 image thumbnail 1 s2 0 s1364815219301562 gr6 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr6 thumbnail image gif 30d49b70dfd28d924f7b17acab40ad07 gr6 sml gr6 gr6 sml sml 30394 106 219 image thumbnail 1 s2 0 s1364815219301562 gr7 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr7 thumbnail image gif aa24243b49ac25621ab103befd37c03f gr7 sml gr7 gr7 sml sml 24726 148 219 image thumbnail 1 s2 0 s1364815219301562 gr8 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr8 thumbnail image gif 589ec56640a83562d594375d1ce9b5a7 gr8 sml gr8 gr8 sml sml 29701 163 131 image thumbnail 1 s2 0 s1364815219301562 gr9 sml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr9 thumbnail image gif b2ebd248731285f9d55c792fbe6060b9 gr9 sml gr9 gr9 sml sml 13525 164 193 image thumbnail 1 s2 0 s1364815219301562 gr1 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr1 downsampled image jpeg 76cf7a0e3192b1219567734f9805bdf8 gr1 jpg gr1 gr1 jpg jpg 83021 375 602 image downsampled 1 s2 0 s1364815219301562 gr2 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr2 downsampled image jpeg b7af9bfac7a4fd376efa67fa1d58aab1 gr2 jpg gr2 gr2 jpg jpg 91281 613 513 image downsampled 1 s2 0 s1364815219301562 gr3 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr3 downsampled image jpeg 3bed0491ff755f130fe6589aaf83e486 gr3 jpg gr3 gr3 jpg jpg 116338 380 669 image downsampled 1 s2 0 s1364815219301562 gr4 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr4 downsampled image jpeg adaa30b94b040c2616e733ef9fff728b gr4 jpg gr4 gr4 jpg jpg 128606 361 513 image downsampled 1 s2 0 s1364815219301562 gr5 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr5 downsampled image jpeg e794f1b8012e134544588823bcb3ed76 gr5 jpg gr5 gr5 jpg jpg 83421 287 379 image downsampled 1 s2 0 s1364815219301562 gr6 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr6 downsampled image jpeg 1836923b8731481fe44c4bd2b48dac4d gr6 jpg gr6 gr6 jpg jpg 87230 270 557 image downsampled 1 s2 0 s1364815219301562 gr7 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr7 downsampled image jpeg 1c2e006332b92d222d6fb1bc5b1f9696 gr7 jpg gr7 gr7 jpg jpg 112746 423 624 image downsampled 1 s2 0 s1364815219301562 gr8 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr8 downsampled image jpeg e57614ee25e95fb3801510f226f6c07b gr8 jpg gr8 gr8 jpg jpg 204204 639 513 image downsampled 1 s2 0 s1364815219301562 gr9 jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr9 downsampled image jpeg 003bff5726dd1b371473be882bcf0987 gr9 jpg gr9 gr9 jpg jpg 62342 436 513 image downsampled 1 s2 0 s1364815219301562 gr1 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr1 highres image jpeg 32ed3afd05b69abc3d886996fd929ca0 gr1 lrg jpg gr1 gr1 lrg jpg jpg 558802 1658 2665 image high res 1 s2 0 s1364815219301562 gr2 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr2 highres image jpeg b06461b665f4ddd5656545aec49b8535 gr2 lrg jpg gr2 gr2 lrg jpg jpg 578375 2713 2272 image high res 1 s2 0 s1364815219301562 gr3 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr3 highres image jpeg 38e4b1a289f0252d06a44da60e930074 gr3 lrg jpg gr3 gr3 lrg jpg jpg 888899 1684 2961 image high res 1 s2 0 s1364815219301562 gr4 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr4 highres image jpeg e78f64b98ea2d32640d6f22ae038b63e gr4 lrg jpg gr4 gr4 lrg jpg jpg 1072097 1601 2272 image high res 1 s2 0 s1364815219301562 gr5 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr5 highres image jpeg d53a7277e96ef937462ce854633898e3 gr5 lrg jpg gr5 gr5 lrg jpg jpg 593999 1273 1681 image high res 1 s2 0 s1364815219301562 gr6 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr6 highres image jpeg 220611ee57c4103f915b3c119871a8d7 gr6 lrg jpg gr6 gr6 lrg jpg jpg 628007 1198 2469 image high res 1 s2 0 s1364815219301562 gr7 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr7 highres image jpeg ab50f7873d8830881f38702eaf5277e7 gr7 lrg jpg gr7 gr7 lrg jpg jpg 751414 1872 2764 image high res 1 s2 0 s1364815219301562 gr8 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr8 highres image jpeg 1335f8e4d9c9570b40b4bf9ee858e1c8 gr8 lrg jpg gr8 gr8 lrg jpg jpg 1501100 2831 2272 image high res 1 s2 0 s1364815219301562 gr9 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 gr9 highres image jpeg fc6168875b04ebe9fe138d43b02f1aa6 gr9 lrg jpg gr9 gr9 lrg jpg jpg 352900 1930 2272 image high res 1 s2 0 s1364815219301562 mmc1 xml https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 mmc1 main application xml 751b38495eb2d743bec6c8d8934f8a62 mmc1 xml mmc1 mmc1 xml xml 405 application 1 s2 0 s1364815219301562 mmc2 docx https s3 amazonaws com prod ucs content store us east content pii s1364815219301562 mmc2 main application vnd openxmlformats officedocument wordprocessingml document df0ee447e64d21c48ab97db7a9263330 mmc2 docx mmc2 mmc2 docx docx 541071 application 1 s2 0 s1364815219301562 am pdf am am pdf pdf 2529308 aam pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content egi 10splkm0jc1 main application pdf fe9f63515fb34b6a1a0bb9248b9dd5e3 am pdf enso 4424 104424 s1364 8152 19 30156 2 10 1016 j envsoft 2019 03 020 fig 1 illustration of six basic elements for a knowledge infrastructure for interactive community modeling and exploration research software communities maintain support of operations between docker containers and software environment domain science communities maintain support for version control and user communications specific to modeling frameworks fig 1 fig 2 illustration of flow routing outputs a elevation map of spring creek central co with locations outlet midstream upstream where hydrographs are plotted b d hydrographs plotted at three locations shown in a driven by the high intensity rainfall option using kinwaveimplicitoverlandflow and overlandflow components respectively c e flow depth maps during peak flow for kinwaveimplicitoverlandflow and overlandflow components respectively results were produced on hydroshare using the landlab modeling framework fig 2 fig 3 a example debris avalanches cyan mapped in three areas within noca contours are in 100 m intervals aerial image source from world imagery esri inc b elevation distribution of the relative frequency of mapped debris avalanche source areas and c high elevation rock and glacier surrounding spiral glacier in north cascades showing a bedrock glacier cirque with thin barren soils and moraine deposits photo by john scurlock with permission d elevation ft for noca model extent from strauch et al 2018 and e for the subset for the thunder creek extent figures a c adapted in entirety from strauch et al 2018 under cc by 4 0 for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 3 fig 4 maps show modeled landslide return periods using landlab for noca overlain with mapped debris avalanches including zoomed in areas at top for greater detail the uncertainty of soil depth was characterized from a long term soil evolution model m sd lt cumulative distribution of landslide return periods for ssurgo soil depth ssurgo sd modeled soil depth m sd and modeled soil depth considering long term dynamics m sd lt scenarios plotted on a log log scale using the weibull plotting position figure adapted in entirety from strauch et al 2018 under cc by 4 0 fig 4 fig 5 landslide probability estimates in the thunder creek watershed photo increase given post fire root cohesion assumptions 70 less as compared to the original cohesion assumptions in strauch et al 2018 as an example of knowledge infrastructure functionality the notebook replicates published findings as well as tests the parameter function described in the peer reviewed publication inset maps and cumulative distribution plots of the spatial probability of landsliding for pre fire and post fire conditions photo is looking north down the broad glacial carved valley of thunder creek courtesy of michael kirshenbaum and national park service fig 5 fig 6 map of elevation bands in new mexico state a used to extract gridded hydrometeorological forcing data elevation bins are referred to as low elevation 1200 1700 m mid elevation 1700 2000 m and high elevation 2000 2500 m the vegetation patterns from aerial imagery of new mexico are distinct within these bands b fig 6 fig 7 climate data downloaded and processed from livneh et al 2015 a annual precipitation plotted with respect to time for each elevation band b mean monthly daily minimum and maximum temperatures for each elevation band fig 7 fig 8 spatial organization of pfts at year 1503 left column and annual areal cover fraction of each pft plotted with respect to time right column for a low elevation landscapes 1200 m 1700 m b mid elevation landscapes 1700 m 2000 m and c high elevation landscapes 2000 m 2500 m fig 8 fig 9 illustration of community learning and discovery process by code access and utilization among scientists key triangle synthesis merge circle connector square process quadrilateral manual or machine operation cylinder database inductive processes are supported when for example a landlab user has a new idea for a component develops the landlab application and publishes it on hydroshare formally with doi or get a publicly accessible url and reviewers can test the experiment with cloud resources deductive processes are supported when new earth observations are published on hydroshare used to test hypotheses or principals using published models and results shown to lead to scientific advancements or the development of new ideas fig 9 table 1 three study problems were designed with a focus to 1 explore 2 replication and 3 reuse research computational narratives demonstrate how to use knowledge infrastructure for computation and visualization of earth surface models where the user interacts with the infrastructure to develop their own story table 1 purpose tasks highlight science topic workflow notebook title 1 educate training and curriculum development flexible components hydrology inductive explore flood routing ipynb 2 replicate execute a published model to replicate reported findings controlled software environment landslides and fire deductive replicate landslide model ipynb 3 reuse execute and enhance a published model in a new location multiple components wrapped for efficiency ecohydrology inductive deductive reuse ecohydrology gridhydromet ipynb table 2 parameters used to obtain spring creek high intensity model comparisons between kinematic wave and overland flow model table 2 variable parameter description value dimension hours hours of model run time 6 hours number frames number of frames to plot 6 n manning s roughness coefficient 0 03 s m 1 3 base runoff rate base runoff rate 10 mm hr higherintensity runoff rate high intensity runoff rate 20 mm hr storm duration storm duration 2 hours dt time step for kinwaveimplicitoverlandflow 600 seconds enabling collaborative numerical modeling in earth sciences using knowledge infrastructure c bandaragoda a a castronova b e istanbulluoglu a r strauch c s s nudurupati a j phuong d j m adams e n m gasparini g k barnhart h m e w h hutton f d e j hobley i n j lyons g g e tucker f h m d g tarboton j r idaszak k s wang l a department of civil and environmental engineering university of washington seattle usa department of civil and environmental engineering university of washington seattle usa b consortium of universities for the advancement of hydrologic science inc cuahsi usa consortium of universities for the advancement of hydrologic science inc cuahsi usa c seattle city light seattle usa seattle city light seattle usa d department of biomedical informatics and medical education university of washington seattle usa department of biomedical informatics and medical education university of washington seattle usa e institute of arctic and alpine research university of colorado boulder co usa institute of arctic and alpine research university of colorado boulder co usa f community surface dynamics modeling system csdms university of colorado boulder usa community surface dynamics modeling system csdms university of colorado boulder usa g department of earth and environmental sciences tulane university new orleans la usa department of earth and environmental sciences tulane university new orleans la usa h department of geological sciences university of colorado at boulder boulder co usa department of geological sciences university of colorado at boulder boulder co usa i cardiff university cardiff uk cardiff university cardiff uk j department of civil environmental engineering utah state university logan usa department of civil environmental engineering utah state university logan usa k renci university of north carolina chapel hill usa renci university of north carolina chapel hill usa l department of geography and geographic information science university of illinois at urbana champaign urbana usa department of geography and geographic information science university of illinois at urbana champaign urbana usa m cooperative institute for research in environmental sciences cires university of colorado at boulder boulder co usa cooperative institute for research in environmental sciences cires university of colorado at boulder boulder co usa corresponding author department of civil environmental engineering university of washington 201 more hall box 352700 seattle wa 98195 2700 usa department of civil environmental engineering university of washington 201 more hall box 352700 seattle wa 98195 2700 usa knowledge infrastructure is an intellectual framework for creating sharing and distributing knowledge in this paper we use knowledge infrastructure to address common barriers to entry into numerical modeling in earth sciences as demonstrated in three computational narratives physical process modeling education replicating published model results and reusing published models to extend research we outline six critical functional requirements 1 workflows designed for new users 2 community supported collaborative web platform 3 distributed data storage 4 software environment 5 personalized cloud based high performance computing platform and 6 a standardized open source modeling framework our methods meet these functional requirements by providing three interactive computational narratives for hands on problem based research using landlab on hydroshare landlab is an open source toolkit for building coupling and exploring two dimensional numerical models hydroshare is an online collaborative environment for the sharing of data and models we describe the methods we are using to accelerate knowledge development by providing a suite of modular and interoperable process components that allows students domain experts collaborators researchers and sponsors to learn by exploring shared data and modeling resources the system is designed to support uses on the continuum from fully developed modeling applications to prototyping research software tools landlab notebooks are available for interactive computing on hydroshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 and for further development on github at https zenodo org badge latestdoi 187289993 keywords cyberinfrastructure knowledge infrastructure reproducible modeling landlab hydroshare earth science education 1 introduction modeling in earth sciences began with the use of hand written mathematical formulas that were developed from observational evidence conjecture or hypothesis and shared through conversation and correspondence as richness and complexity of our available earth observations have grown in parallel with technological advances in computational resources supercomputing high performance computing and cloud computing our models now focus on couplings among atmospheric hydrologic ecologic geomorphic and human impacted processes e g tucker and hancock 2010 yetemen et al 2015a b han et al 2015 anders et al 2008 pande and sivapalan 2017 advances in internet based cyberinfrastructure includes computational systems data and information management advanced instruments visualization environments and people all linked together by software and advanced networks to improve scholarly productivity and enable knowledge breakthroughs and discoveries not otherwise possible this digital infrastructure expands our capacity for structured collaborations in research edwards et al 2013 however these technological advances often come at the expense of raising the technological bar for entry into numerical modeling here with examples from earth science we discuss how to lower this bar with that include three key features 1 a community platform that allows dynamic interactions among developers researchers and new users 2 clear documentation of theoretical and mathematical details that are often lost for new users of complex model programs and 3 model reproducibility for example sharing the code and data within a community portal with computational capacity allows new users to easily find and test training materials developers to easily distribute open workshop materials and communities to build new research networks further as technology is integrated in the research with greater sophistication it is increasingly a challenge to keep the fundamental equations that define the driving assumptions in the model structure accessible to software users using methods such as inclusion of equations and references in online documents can avoid the black box syndrome and improve ease of learning transparency and usability of the modeling code communicating what can be expected to be known by using the research tool provides the domain of applicability netzeva et al 2005 or builds into the system edwards et al 2013 to be clear on the purpose and limits of the model what can be expected to be known by using the research tool experimental design is addressed by illustrating three different areas where model reproducibility can have an impact on advancing science classroom and peer to peer education replicating published results and reusing models to build new research products knowledge infrastructure is an emerging intellectual framework to understand and improve how people create share interpret observations and modeled results and distribute knowledge which has dramatically changed and is continually transformed by internet technologies and advanced cyberinfrastructure knowledge infrastructure is most simply defined as robust networks of people artifacts and institutions that generate share and maintain specific knowledge about the human and natural worlds borgman et al 2015 in earth and hydrologic sciences interpreting observational and model simulated data is a fundamental task but systematic acquisition of data for interpretations and machine readability is not common practice among environmental research infrastructures stocker et al 2018 knowledge infrastructure advances us beyond cyberinfrastructure which is generally limited to distributed computer information and communication technologies by including networks of groups and institutions and the cultural practices of developing and sharing computational narratives brooks 1996 perez and granger 2015 computational narratives are the algorithmic processes involved in creating and interpreting computed representations mani 2013 in our case the algorithmic processes are earth surface models and the computed representation is the results of the analytical research and how those results are summarized recent developments in the use of advanced cyber infrastructure in earth science include tools used to support hydroinformatics such as hydroshare tarboton et al 2014a tarboton et al 2014b 2018 and the cuahsi jupyterhub service castronova 2018 perez and granger 2015 development efforts concentrate on the application of information and communication technologies icts targeted for geospatial analytics yin et al 2017 and hydrologic data types and models horsburgh et al 2016a morsy et al 2017 strauch et al 2018 by providing resources for open source practices including sharing of data and models and providing online computational resources i e cloud computing with expert knowledge or user experience designed to support non experts these platforms can be effectively used for expanding and broadening our capacity to investigate hydrologic and earth system processes in model based investigations reproducibility increases confidence in results and improves interpretation about what results do and do not mean lack of reproducibility limits the expansion and growth of knowledge hutton et al 2016 nosek et al 2015 the term reproducibility has many aspects which can be explored further in other work essawy et al 2018 yuan et al 2018 stagge et al 2019 but we broadly use the term to ecompass multiple aspects including availability computational reproducibility portability experimental replicacability and accessibility the advancement of knowledge and lowering the barriers to reproducibility can be enabled by knowledge infrastructure that supports collaborative research education and curriculum development and improves standards for technology practices for publication of research web based interactive computing environments such as jupyter notebooks perez and granger 2015 are designed to execute models and perform data analytics and have become increasingly prevalent to improve reproducibility of research in the past few years shen 2014 especially with early adopters in the biological sciences perkel 2019 gross et al 2014 ragan kelley et al 2013 ding and schloss 2014 francis 2018 created a reference of jupyter notebooks currently available on the web with limited examples of experiments in the earth sciences community one of the first interactive notebooks that we know of was published by shen 2014 which provided computational resources for executing code snippets exploring astronomy data this was available online as an interactive notebook for three years 2014 2017 and it was replaced with a static view of an example execution of the notebook in november 2017 luo et al 2016 have shown that interacting with web based models through a graphical user interface in classroom environments improves higher level thinking and attitudes about complex landscape evolution models we do not know of any collections of notebooks published with the supporting infrastructure available for authors to maintain accessible interactive notebooks for their readers in hydrologic sciences and earth surface modeling communities or studies on how interacting with model code improves educational or research outcomes efforts to provide online computing capacity for earth science research and education includes landscape evolution modeling such as the wilsim model luo et al 2004 2016 watershed hydrology and erosion modeling using wepp laflen et al 1991 laflen 1997 flanagan et al 2007 and river basin environmental modeling using swat rajib et al 2016 while these web based modeling approaches lower the bar for model execution model options and the level of interaction of the users with models are constrained by the limited set of options envisioned by the developers these tools rely on graphical user interfaces gui with limited user inputs parameter values or scenario choices and they do not provide an interactive software environment for user collaboration and co creation of knowledge to develop a persistent collaborative environment that will have a profound transformational effect on our society newman 2003 we need to identify and overcome the barriers that are currently preventing rapid adoption of knowledge infrastructure for earth surface modelers this paper is motivated by the following questions can current software infrastructure and research communities 1 facilitate rapid adoption and scientific advancement of complex earth surface models 2 lower the bar for entry into modeling 3 improve collaborations among scientists and science partners and 4 advance useable science with sustainable open source software in addressing these questions our aim is to explore knowledge infrastructure using advanced data access and computational resources beyond what an individual scientist would normally have available bandaragoda et al 2006 we first describe three emerging open source modeling practices to lower the bar into modeling methods section 2 in our methods we review basic elements of knowledge infrastructure and substantiate it with specific technical details as implemented in hydroshare the ci platform we use in this study in the results section 3 we focus on the use of the landlab earth surface modeling toolkit hobley et al 2017 deployed on hydroshare in three use cases that employ emerging open source modeling practices to lower barriers in modeling we provide workflows designed with interactive notebooks aimed at earth science education as well as reuse and replication of research models our discussion section 4 explores the barriers we have identified followed by conclusions section 5 on our approach to address the motivating questions and current limitations 2 methods 2 1 emerging practices for modeling the ability to reproduce experiments and share data is expanding open source cyberinfrastructure platforms for research publication are designed to facilitate the use of existing models by making input data and model code publicly available online and providing software tools for pre and post processing data running models sharing data and formally publishing with a digital object identifier freeman et al 2005 atkins et al 2003 using recent examples in water monitoring horsburgh et al 2017 jones et al 2017 mihalevich et al 2017 landslide modeling strauch et al 2018 and data science freire et al 2016 we identified three critical open source technology practices supported by knowledge infrastructure expected to lead to scientific discoveries sections 2 1 1 2 1 2 and 2 1 3 2 1 1 code development in an open source environment evolving software versions hardware requirements numerical methods and code quality limit the ability to replicate and reuse model applications developing models from a personal computer pc requires installing a suite of specialized software tools and access to computational hardware to visualize store and prepare model inputs and outputs thus reproducing a study by others often depends on the ability to reproduce the software environment 2 1 2 cyber training in numerical modeling education the use of numerical models for science education should not diminish the instruction time for basic science costs that sometimes arise from using models in the classroom include time needed for extensive technological instruction and technical troubleshooting these costs can be avoided by developing software infrastructure that accesses computational and data intensive models from a web browser avoiding the need for any software installations enables classroom experiences for students that focuses time on improved understanding of existing theory and is designed to generate curiosity to propose hypotheses and design further modeling field and laboratory experiments 2 1 3 cyber interactions in collaboration in most academic research projects skills for code development diagnostics and model execution are limited to a few individuals graduate students postdocs etc however most modelers would agree that coding errors can be more effectively identified more user friendly codes can be designed and new research ideas can be developed when other experts have access to models for evaluation experimentation and testing when scientists and stakeholders can interact with execute and visualize various components of coupled models used in collaborative projects the research process leads to rapid development of ideas and research products and more useable science lemos et al 2012 2 2 knowledge infrastructure design our approach includes the following six methodological software and hardware components fig 1 labels 1 6 that can address the barriers to computational modeling 1 user experience design is the conceptual and evolving software design that includes all the practices developed to efficiently accomplish collaborative online tasks based on personal collaborator and institutional cultural preferences e g workflow practices for using software to run models perform data analysis and publish research products the user experience design guides the development of the framework and in research software includes contributions from both developers and new users section 2 7 2 community supported collaborative web platform that interacts with high performance computing hpc and data storage nodes allows for computationally intensive computing and supports publishing and privacy section 2 2 3 data storage that may be distributed to different locations section 2 3 4 software environment that provides a library of software and programming languages supporting model applications version control data analytics and facilitates the execution of numerical models section 2 4 5 cloud based high performance computing chpc platform that hosts the software environment models and personal user space section 2 5 and 6 a standardized modeling framework section 2 6 the adoption ongoing adaptation and growth of an infrastructure system is fundamentally dependent on personal research choices collaborative dependencies and institutional policies section 2 7 in section 2 8 we provide examples that generated design input to component 1 user experience design in order to evolve the the knowledge infrastructure system 2 2 community supported collaborative web platform hydroshare hydroshare http www hydroshare org is an online collaborative platform developed to address the growing computer modeling data storage and sharing needs of the community it supports the sharing of both data and models using hydroshare resources and facilitates the execution of numerical models using web apps associated with or linked to hydroshare hydroshare is operated by the consortium of universities for the advancement of hydrologic science inc cuahsi www cuahsi org as a community supported collaborative web platform fig 1 box 2 a web browser is the interface to hydroshare and provides access to hydrologic and earth surface models and data that are saved as resources in hydroshare the architecture of hydroshare is designed to support 1 resource storage 2 resource exploration and 3 actions on resources these are implemented using system components that are relatively loosely coupled and interact through application programming interfaces apis the loose coupling takes advantage of services oriented architecture soa that enhances robustness as components can be upgraded and advanced relatively independently 2 3 1 distributed data storage content that can be shared within hydroshare is diverse including digital objects that represent multiple hydrologic data types models and model instances documents and other content types commonly used in hydrologic research horsburgh et al 2016b a resource is the discrete unit of digital content within hydroshare resources are cast as social objects that can be published collaborated around annotated discovered and accessed horsburgh et al 2016b in this resource centric approach a resource is the granular unit used for management and access control hydroshare resources include hydrologic time series geographic feature vector data geographic raster gridded data multidimensional space time data sets e g netcdf and composite resources that represent combinations of these data types as well as collections that group together different resources model programs and model instances are additional types of content that can be shared and manipulated within hydroshare metadata is maintained that tracks system level attributes of the resource including timestamps of creation and modification ownership access control rules etc persistent identifiers access control versioning sharing and discovery are all managed at the resource level in hydroshare hydroshare s overarching resource data model is an implementation of the open archives initiative object reuse and exchange oai ore standard lagoze et al 2008 that holds metadata in a standardized and machine readable way to promote interoperability with other systems oai ore is a standard for the description and exchange of web resources hydroshare uses the integrated rule oriented data system irods moore 2008 irods consortium 2016 yi et al 2018 as its distributed network storage back end irods provides a virtual file system for physical storage distributed across multiple locations and enables data federation across geographically dispersed institutions yi et al 2018 2 3 2 resource exploration discovery and management the primary user interface for hydroshare is the website hosted at www hydroshare org developed using the django web framework django 2018 and mezzanine content management system mezzanine project 2018 together these technologies are used to build a system for archiving data and metadata for each resource and provides a landing page where metadata can be entered and edited or content files added or removed in the sharing settings panel users can specify sharing status e g private or public and manage who has access to edit or view the content a resource may be permanently published in which case it is precluded from further editing and assigned a citable digital object identifier doi the django website also provides a my resources page for listing data that belong to or have been shared with each user a discover page that supports keyword and map based search for content based on their spatial coverage information using the apache solr search platform solr project 2018 and a collaborate page for users to create or join groups aligned around specific research topics collectively these web pages provide a system where users can discover and manage the content to which they have access including changing access control settings and creating new content the business logic of resource and content types and access control is all managed using standard python django software packages 2 3 3 actions on resources through web apps the hydroshare repository broadly consisting of irods middleware for managing data storage and a django website for content discovery and management is extended by independent web applications that allow users to perform actions on hydroshare data using a services oriented software pattern hydroshare has been designed to support this interaction with 3rd party applications using a representative state transfer rest application programming interface api the industry standard oauth protocol is used to manage authentication and interface with hydroshare s access and control model which is necessary to support interaction with remotely hosted web applications via the api flexible web app launching functionality has been established through a hydroshare resource type that defines the url and parameters for invoking the web application these web app resources can be created by any hydroshare user to interact with 3rd party web applications that are designed to act on hydroshare content hydroshare web applications can be hosted anywhere and have the potential to provide users with a gateway to high performance computing 2 4 software environment cuahsi jupyterhub this paper makes use of a jupyterhub web application developed and maintained by cuahsi https jupyter cuahsi org that leverages jupyter notebook technology jupyter notebooks are an effective way to document research analysis workflows and modeling procedures in a reproducible manner kluyver et al 2016 the cuahsi jupyterhub service is under active development to support 1 computationally intensive research 2 data intensive research 3 education and the dissemination of knowledge and 4 reproducible science these goals are made possible through the development of data transfer mechanisms to move data between hydroshare and the jupyterhub environment as seamlessly as possible moreover hydroshare provides a mechanism for users to launch notebook workflows and their associated datasets into a pre configured isolated remote compute environment each compute environment is created on the fly and contains a persistent data store for performing hydrologic analysis in a manner that is insulated from all other users this is possible by leveraging operating system level virtualization software such as docker merkel 2014 each user instance runs the ubuntu linux operating system and is pre configured with scientific python and r libraries software for interacting with the hydroshare rest api and various physical models including landlab a typical workflow is to launch the cuahsi jupyterhub web application from a hydroshare resource programmatically collect any necessary data using the hydroshare rest api perform modeling and analysis and finally save results back to hydroshare after these data i e jupyter notebook and data files are saved back to the hydroshare repository they can be shared with other users and groups who can further analyze them in a similar way this back and forth sharing enables collaboration in the development and analysis of landlab models using the hydroshare repository and linked jupyterhub web app 2 4 1 community supported development and operation cuahsi supports the development and operation of cuahsi jupyterhub as part of the hydroshare project idaszak et al 2017 as well as through their cooperative agreement with nsf see acknowledgements development and operation efforts are divided into two categories 1 system maintenance and user support and 2 hydrologic research and modeling the first category focuses primarily on maintaining existing capabilities updating libraries and performing system level maintenance and upgrades this includes overseeing the installation and compiling of python versions 2 7 and 3 6 r version 3 4 scientific libraries such as pandas dakota adams et al 2014 spotpy numpy etc and modeling applications e g modflow 6 landlab taudem the latter category consists of collaborative research to lower the barrier of entry to modern modeling applications such as the structure for unifying multiple modeling alternatives summa and the national water model nwm configuration of wrf hydro these efforts are coordinated using an open source codebase in which code contributions undergo a review process and formal release schedule users provide feedback and requests via github issues with bug and enhancement tickets 2 4 2 tools and models one of the goals of cuahsi jupyterhub is to make it simple for users to access the software they need without some of the challenges associated with library dependencies computer operating system or platform compatibility and installation challenges as such cuahsi jupyterhub has installed and supports a range of software and tools commonly used for hydrologic analyses to help users get going quickly in their work and make their work more reproducible it is intended for this set of software and models to grow as the platform is further developed currently cuahsi jupyterhub includes the following landlab an earth surface modeling toolkit that this paper focuses on as an example of the approach hobley et al 2017 taudem a set of gis tools for terrain analysis and watershed delineation tarboton 2018 tesfa et al 2011 modflow groundwater model the structure for unifying multiple modeling alternatives summa clark et al 2008 2011 2015a 2015b model framework that allows for formal evaluation of multiple working hypotheses on model representations of physical processes irods icommands component for accessing large files efficiently from the hydroshare repository using irods python tools for working with hydroshare observation data model 2 odm2 time series content types horsburgh et al 2016a the waterml r package kadlec et al 2015 2 4 3 landlab community landlab has four main releases per year february may august november which accompany landlab s quarterly newsletter the landlab lookout the newsletter alerts users that a new version is available describes what s new in the release and gives a summary of landlab related news such as landlab themed clinics publications using landlab etc occasionally intermediate releases will happen in conjunction with annual community meetings that include presentations or workshops that feature landlab for instance american geophysical union annual meeting december recurring geological society of america july recurring community surface dynamics modeling system may recurring this ensures that participants of these meetings can use the latest version of landlab in addition to announcing new releases via the newsletter landlab developers also contact directly other researchers that use landlab for hydroshare this means either submitting issues on the hydroshare jupyterhub github repository or sending email directly to cuahsi jupyterhub developers this ensures that these projects provide their users with the most up to date landlab versions the role of version control is highlighted in fig 1 as domain science community support of research 2 5 advanced cyberinfrastructure and cybergis jupyter hydroshare has recently been developed to exploit cybergis that is geospatial information science and systems based on advanced computing and cyberinfrastructure and high performance computing hpc wang 2010 wang and goodchild 2019 cybergis jupyter allows hydroshare jupyter notebooks to harness hpc resources such as those provided by the nsf extreme science and engineering discovery environment xsede and resourcing open geospatial education and research roger supercomputer wang 2016 specifically cybergis jupyter encompasses the following three major functional components yin et al 2017 jupyterhub is used to handle authentication and schedule standalone jupyter servers after authentication dedicated containers are sent to the docker swarm docker swarm is responsible for spawning and managing all docker containers across a specific group of virtual machines the swarm the containerization provides fine grain on demand provisioning of cloud infrastructure as a service when a user launches a notebook batch hpc is adapted to harness distributed parallel computing resources high performance storage systems and cybergis software to greatly expand the capabilities of a typical jupyter notebook environment 2 6 modeling framework landlab and its application on hydroshare a new paradigm in hydrologic and earth system modeling is emerging where software once developed for individual research are being reconfigured in community open source research software systems in this context components represent a set of scientific and software methods used to represent a physical process e g flow routing and not the entire system of processes e g a distributed hydrologic model simulating multiple physical processes in the water cycle landlab is one such system based on a python language programming library that supports efficient creation and or coupling of 2d numerical models hobley et al 2017 it is a framework geared towards but not limited to earth surface dynamics landlab is composed of three main divisions of code grid components and supporting utilities the spatial template for modeling is created by the landlab modelgrid class modelgrid provides common structured and unstructured e g voronoi polygons data structures where data fields can be attached to grid elements and grid elements can be built as a structured or unstructured grid in a single line of code each physical process is coded into individual landlab class and added to the landlab library as a component providing an ecosystem of hypothesized behavior of earth system processes supporting utilities and driver scripts were developed to pre process post process and improve workflow efficiencies for coupling multiple components most components operate on interact with and update grid fields components can be coupled via data exchange over the grid a model driver is a python script developed to import instantiate and run a single or multiple coupled landlab components landlab utilities provide tools for input output management and visualization in this paper we use models for coupled ecohydrology and spatial vegetation dynamics flow routing adams et al 2017 and landslide probability strauch et al 2018 along with a recently developed climate data handling utility phuong et al 2019 as with the open source nature of landlab a growing community of developers contribute numerical functions process based components and utilities 2 7 user experience design for multiple learning pathways in this section we describe how the knowledge infrastructure can be viewed from the lens of a research workflow presented in appendix a upon publication of a resource and its deployment to users by sharing the location of the resource on hydroshare the users begin learning and exploring the code users may be collaborators in a research project stakeholders of watershed resources and or students the user may explore landlab on hydroshare using the deployed model driver by changing parameter values of the process components and perhaps explores other components by adding them to the driver or in the process of exploring the model the user may develop their own new ideas to develop new process representations presented as new components in landlab or develop new ways of data visualization these new developments on landlab components will continue when users who contribute their work to the landlab repository track and manage landlab version updates and its further deployment on to hydroshare these model developments can continue offline by installing and using landlab on a personal computer or other jupyterhub servers 2 8 data and models for three computational narratives to illustrate our methods for lowering the barriers to computational modeling we have developed three computational narratives for user experience ux table 1 a computational narrative can be considered a story that can be told about the data by executing scripts that generate data analysis and visualization in the provided workflow recognizing that every experience is made of many parts that contribute to the adoption and evolution of tool development and the narrative see section 4 inductive and or deductive can provide a framework for a user to generate their own story by exploring the science topic with interactive tools a ux can be described as a computer human interaction the importance of ux design is becoming more widely recognized in science and technology development to achieve the desired outcome of the ux such as improving the knowledge base and cognitive capabilities of users baldwin 2013 glassdoor 2017 given that an experience may be generated by any interaction we designed three example computational narratives to generate individual experiences share understanding on existing theory and to open doors for future developments forlizzi and ford 2000 in the first case we give an example of how to use this infrastructure fig 1 to develop training and educational materials for classroom curriculum this example focuses on the use of flexible components in a modeling framework to demonstrate two approaches for flow routing from simple to more complex solution of the same shallow water equation with inductive narrative workflows designed to orient new users to a focused set of theoretical concepts that can be explored with minimum background in the computational infrastructure or coding in the second case we illustrate how a researcher may execute a model to replicate reported findings in a published study on annual landslide probability we particularly focus on how the use of a controlled software environment provides easy access to new users of the tool and facilitates the exploration of other questions associated with the processes investigated using the same tool and data this is an example of a deductive workflow where new hypotheses are tested using a published set of tools and data in the third computational narrative we present a more sophisticated example for executing a published ecohydrology model enhanced and applied in a new location it uses a component bundling idea for efficient scenario building to explore eco hydrologic response to a climatic gradient mediated by elevation this example illustrates a research cycle that includes both inductive and deductive workflows to generate new understanding computational narratives demonstrate how to use knowledge infrastructure to educate replicate and reuse earth surface models where the user interacts with the infrastructure to develop their own story notebooks are designed with up to 10 sections for example for the example see 4 1 notebook section 1 introduces the theory and the conceptual design of the models for example in the first notebook we begin with the theory of the 1 d saint venant equation for transient shallow water flow which is at the core of many hydrodynamic models data science and cyberinfrastructure methods are provided in notebook section 2 0 followed by landlab methods notebook section 3 0 notebook sections 1 to 3 are designed to function as an interactive textbook or reference in the section labeled make model decisions notebook section 4 0 our aim is to clearly distinguish the component based options for designing a model experiment for example in the first notebook we provide options for designing a storm hydrograph based on the choice of basin storm intensity and routing method model computations notebook section 5 0 and results notebook section 6 0 provide code to execute the model visualize results and export data discussion 7 0 conclusions 8 0 and saving results to hydroshare notebook section 9 0 are designed to support graduate level coursework in hydrologic processes and modeling finally users are provided shell script prompts that can be executed in the jupyter notebook to remove data from the jupyterhub server after completing their work notebook section 10 3 results in our results we describe three computational narratives we designed to lower barriers to computational modeling using the ci described in section 2 we relied on juptyer notebooks for sharing the following computational narratives and designed the sequence of commentary text and code blocks to be generally useful to earth surface modeling research communities hanney and savin badem 2013 suggest that combining project and problem based learning may be the best practice for generating engagement critical thinking and creativity with the use of problem based learning as an important tool for providing authentic experiences highly valued by all learners kokotsaki et al 2016 the interactive landlab notebooks described in sections 3 1 3 2 and 3 3 are available on hydrosshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 3 1 notebook 1 exploring runoff hydrographs with landlab 3 1 1 notebook 1 overview this notebook provides resources to compare two different flow routing schemes kinematic wave and overland flow 2d de almeida 2012 solution of the saint venant equation as explained on the notebook in detail in two different landscapes for a given rate of rainfall excess rainfall in excess of infiltration the notebook can be used to investigate process based questions on the generation of overland flow hydrographs across the landscape in relation to the role of runoff rate watershed topography network structure and surface roughness and it allows to compare and contrast the properties of streamflow hydrographs generated by the two different flow routing algorithms to provide a contrast between different landscape shapes this notebook uses two domains a watershed from central colorado spring creek and a modeled rectangular landscape obtained by running an existing fluvial landscape evolution model driver in landlab adams et al 2017 both landscapes have a drainage area of 36 km2 and a cell size of 30 m rain falls on the landscape and flows downhill driving overland flow and a hydrograph at every location on the landscape in this notebook we track the hydrograph at three points in the watershed we recommend that the users review introductory concepts of overland flow and hydrographs before using this notebook and develop familiarity with the term s rainfall intensity and duration as well as peak discharge hydrograph time to peak rising limb and falling limb our aim is to clearly distinguish the component based options for designing a storm hydrograph based on the choice of basin storm intensity and routing method 3 1 2 notebook 1 interactive steps the notebook is designed to run the model several times each time changing the rainfall characteristics routing methods or watershed on which flow is routed different combinations of model components or model instance will generate different hydrographs through which the user can explore how different parameters affect hydrograph characteristics we have provided code to import spatial data linked to the original source of the use of this notebook adams et al 2017 published on hydroshare so that code can be reproducibly executed with the original ascii text files on a personal computer in initial runs the user does not need to change any code but different scenarios can be developed by switching between test watersheds by changing model parameters such as basin flag to equal spring creek or to square table 2 lists the parameters used to obtain the results shown in fig 2 to generate a storm hydrograph over a modeled time period approximately 50 000 model timesteps seconds could take up to ten minutes of computational run time section 5 0 on existing computer infrastructure in development for xsede also possible on commercial cloud platforms we illustrated outputs from the flow routing notebook in fig 2 the user selects which landlab component to run kinwaveimplicitoverlandflow or overlandflow components 3 1 3 impacts on numerical modeling education using an interactive notebook as a component of the science and engineering curriculum is expected to increase student and faculty access to modeling tools rather than relying on software in a computer laboratory or asking students to install new software on their computers the code can be used in any classroom by every student with access to any computer with a web browser the example illustrates how model methods and output options can be developed to enhance multifaceted learning experience of the process of interest in the first notebook there are three main components and various scenarios to explore two different watersheds two routing methods and three different storms students can simultaneously run scenarios by systematically changing the flags e g routing method basin flag and storm flag re running all code blocks sequentially and saving the resulting hydrograph plots for each scenario to use in project reporting or homework the two different flow routing methods show the outcome of including the gradients of fluid pressure and bed elevation and friction terms of the shallow water equation with different assumptions on hydrographs multiple locations for plotting hydrographs in two watersheds will show the role of catchment size and properties different excess rainfall intensities are for exploring how increased runoff depth change the hydrograph properties advanced students may use the code to build their own visualization landlab components or model optimizations because all students can gain hands on experience with the model and code during the classroom instruction it increases the opportunity and depth of discussions between classmates by providing peer to peer learning environment 3 1 4 notebook 1 access to run this notebook go to this hydroshare resource appendix a supplementary data https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 click on the blue open with button select jupyterhub conceptually this will bring you to block 4 in fig 1 the system will certify you are a hydroshare user if not you will be asked to sign up at https www hydroshare org download the data and notebooks from this hydroshare resource to a personal user space in the hydroshare cloud click on the file explore routing tutorial ipynb alternatively advanced users edits are required to remove hydroshare dependencies can download the notebook to run on a personal computer with an installed version of landlab with instruction available in the hydroshare readme md further the notebook can be directly downloaded no requirement to become a hydroshare user at this link explore routing tutorial ipynb or viewed on github in the landlab organization https github com christinab pub bandaragoda etal ems repository see the explore flow routing folder for example view at this link https github com christinab pub bandaragoda etal ems blob master explore routing tutorial ipynb 3 2 notebook 2 replicate a landslide model to explore fire impacts on slope instability in a watershed within a regional study 3 2 1 notebook 2 overview landslides are notoriously challenging to predict van westen et al 2006 a new model developed as a component in landlab landslideprobability offers the ability to predict the probability of shallow landslide initiation at regional scales probability of landsliding is calculated by the infinite slope stability equation using a monte carlo approach by introducing uncertainty to soil vegetation and recharge variables this model was first implemented in a 2700 km2 area in the north cascades national park complex noca of washington state fig 3 where annual probability and return period for shallow landslide initiation was mapped for different soil depth products fig 4 strauch et al 2018 considering the uncertainty of soil depth root cohesion and mechanical soil properties the model predicts 20 40 of the area with a landslide return period of 1 in 100 years or less fig 4 in comparison to notebook 1 designed for classroom use this notebook is designed to replicate model results from strauch et al 2018 in thunder creek watershed located within noca it calculates the probability of shallow landslide initiation at a 30 m rectangular grid resolution across the watershed using gridded datasets of landscape characteristics for topography slope and upslope catchment area land use and land cover vegetation type root cohesion soil internal friction angle and transmissivity and annual maximum daily subsurface flow recharge rate derived from a previously run hydrologic model all the resources needed for model application are obtained from the existing hydroshare resource from strauch et al 2018 code is provided to import data from the regional noca area and create a subset of this data covering thunder creek watershed through import of a watershed boundary shapefile the mean relative wetness and probability of saturated conditions at each grid cell are also calculated in the process of calculating the probability of landsliding the notebook is designed for exploring the sensitivity of landsliding to environmental conditions that lead to loss of root cohesion such as a wildfire or timber harvest 3 2 2 notebook 2 interactive steps for detailed instructions for notebook access see section 3 1 4 and use the jupyter notebook replicate landslide model for fire ipynb for this example the notebook is organized with an introduction notebook section 1 0 to the infinite slope factor of safety equation which predicts the ratio of stabilizing to destabilizing forces on a hillslope plane and the monte carlo solution developed to compute probability of landslide initiation data science and cyberinfrastructure methods are provided in notebook section 2 0 that describe specifics of accessing existing spatial data extracting information for the watershed of interest followed by landlab methods for setting model parameters in the notebook subsection labeled specify recharge our aim is to clearly distinguish the component based options for studying the impact of assumptions related to recharge and hydrologic forcing on landslide probability at the end of this notebook section the number of monte carlo iterations is assigned in notebook section 3 0 results the model is executed for thunder creek and the results are visualized steps for saving results back to hydroshare are listed in notebook section 4 0 to support graduate level coursework in hydrologic processes and modeling we include code blocks that print more explanatory variables and numerical values to verify results are as reported in strauch et al 2018 in this demonstration notebook the user imports necessary python utilities and libraries and reviews the data needed to execute the landslide model code is provided to import data from the regional noca area and create a subset of this data covering thunder creek watershed through import of a watershed boundary shapefile one of four recharge options is specified and the user loads existing mapped landslides to overlay on the landscape to compare with the probabilistic landslide hazard map the user specifies the number of iterations to use in a monte carlo simulation then runs the landslideprobability component with two cohesion assumptions the first cohesion assumption is based on existing conditions as described in strauch et al 2018 the second cohesion assumption generating a second model instance approximates post fire conditions where root cohesion is reduced by 70 this represents the reduced root cohesion following a wildfire as existing roots decay following wildfire while new roots begin to regenerate sidle 1992 istanbulluoglu et al 2004 finally maps are generated to compare the results of the stability analyses and results can be saved back to hydroshare fig 5 replication of the strauch et al 2018 model in thunder creek for potential postfire conditions clearly show an increase in annual probability of failure pf when the root cohesion is reduced following wildfire in the pre fire simulation 25 of the landslide is unconditionally unstable pf 1 0 meaning that the soil cannot stand on these slopes this high annual probability is a conservative estimate and it is largely due to the use of the ssurgo soil depth product in this application strauch et al 2018 discussed how more processed based modeling of soil depth reduce pf to more realistic ranges with wildfire impact unconditionally unstable regions grew to 40 of the watershed before fires 40 of the watershed is unconditionally stable pf 0 0 these regions are located in the lower portions of u shaped pro glacial valleys fig 5 with a vegetation disturbance such as wildfire this fraction is reduced to 5 which could lead increased sediment input from the sides of u shaped valley directly to the valley floor and result in decline of aquatic habitat quality 3 2 3 impacts on replicating scientific findings this notebook is designed for earth scientists and stakeholders who are interested in understanding the landslide hazard risk as a probability in space and time running this notebook using landlab leverages the software infrastructure of the landlab python toolkit which standardizes the handling of spatial temporal data executing the notebook on hydroshare allows the ability to store necessary data deploy the model via a super computer and see the results which can be evaluated and shared thus the notebook becomes a one stop online platform for demonstrating the landslide model and facilitating ease of model augmentation current barriers to conducting landslide hazard analysis includes the ability to consider landscape variability data uncertainty and hydrological triggering mechanisms over a large spatial scale this narrative helps reduce the barrier of significant time investment to implementing a complex model by providing the necessary data and code for implementing the landlab landslideprobability component as a result the researcher can see what the model requires and how it runs to produce the results presented in a publication the notebook can provide an example that can be modified to use in a new study effectively across the nation additionally the barrier to accessing compiled observations and research products is overcome with this notebook including compiled spatial temporal visualizations that can be used to communicate results 3 2 4 notebook 2 access a published regional landlab shallow landslide model has been developed to explore changes in forest cover at a subcatchment scale within the noca study area using the jupyter notebook replicate landslide model for fire ipynb this notebook is available on hydroshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 for detailed instructructions on notebook access see section 3 1 4 or the readme found at the hydroshare link 3 3 notebook 3 reuse an ecohydrology model with gridded hydrometeorology forcing 3 3 1 notebook 3 overview in semiarid regions climate change and human impact can lead to dramatic changes in the composition and organization of plant functional types pfts such as trees and shrubs and thus the biomass production of the ecosystem ecohydrologic vegetation dynamics models are tools that can be used to explore the role of climatology on the spatial organization of pfts fatichi et al 2016 in this notebook we adapt landlab s ecohydrologic vegetation dynamics model to illustrate how an existing model can be reused by enhancing and developing a workflow at a new location in our case for studying the role of elevation dependent precipitation and temperature gradients on pfts using historical gridded daily weather data from livneh et al 2015 broad elevation bands low 1200 1700 m medium 1700 2000 m and high 2000 2500 m are developed and the ecohydrology model in landlab is implemented to simulate the resultant organization of pfts at each elevation band in the state of new mexico on hypothetical flat surfaces with a spatially homogenous soil textural properties fig 6 the landlab ecohydrology model we used is based on catgrass cellular automaton tree grass shrub simulator a discrete time cellular automaton ca model for spatial evolution of pfts zhou et al 2013 in catgrass each cell in the domain can be occupied by a single pft tree shrub grass or left unoccupied as bare soil the model couples local ecohydrologic vegetation dynamics which simulate biomass production based on local soil moisture and actual evapotranspiration with spatial processes for plant establishment and mortality controlled by seed dispersal rules water stress tolerance and space availability trees and shrubs disperse seeds to their neighbors grass seeds are assumed to be available everywhere establishment of plants in bare cells is determined probabilistically based on water stress of pfts neighboring the bare cells plants with lower water stress have higher probability of establishment plant mortality is simulated probabilistically as a result of aging and drought stress the model is driven by rainfall pulses observed or generated solar radiation and temperature the latter two variables can also be used to prescribe a seasonal potential evapotranspiration input in landlab the model is implemented as a set of interacting components each describing a different element of the coupled system precipitationdistribution radiation potentialevapotranspiration soilmoisture vegetation component for local growth and vegca component for cellular automaton rules 3 3 2 notebook 3 interactive steps and model results for detailed instructructions for notebook access see section 3 1 4 in this example we constructed a reproducible ecohydrology model using landlab and hydroshare for a new mexico example for details on methods designed to reuse the model in another location in the continental united states please see the jupyter notebook reuse ecohydrology gridhydromet ipynb in this notebook we define the geographic subset new mexico within north america and download gridded hydrometeorologic data from livneh et al 2015 for this region then we bin this data into three elevation ranges by considering elevation of centroids of the cells in the gridded dataset and calculate the spatial means of daily precipitation maximum and minimum temperature for each bin these data are used to force the ecohydrology model at each elevation bin the hydrometeorological data handling steps are executed in a separate notebook named observatory gridmet newmexico ipynb located in the folder ogh newmexico which runs a recently developed python package for automated retrieval preprocessing and visualization of gridded hydrometeorology data products phuong et al 2019 as we described in the jupyter notebook for this example we found that the livneh et al 2015 data had a wet bias in precipitation this bias is corrected by gathering weather station data moore 2016 that span the range of the elevation bins we used from the livneh et al 2015 data time series of bias corrected annual precipitation and mean monthly temperature show wetter and cooler conditions as elevation grows fig 7 there is a positive trend in annual precipitation from 1950 to 1990 followed by a slight negative trend in the application of this notebook we suggest the users to explore the model outputs to see if this precipitation trend had any impact on the spatial cover fractions of pfts following the bias correction the three elevation bins resulted in climatology s from arid in the low elevation bin to semiarid conditions in the high elevation bin according to the aridity index classification nash et al 1999 discussed in relation to model results below since the historical data extends only for 64 years fig 7 we extended the record to by tiling the daily historical data to facilitate longer vegetation development simulations the limitation of this approach is that the same climate repeats itself in every 64 years the notebook presents three model runs to explore the role of elevation dependent changes in the regional climatology on modeled spatial patterns of pfts shrub grass tree and plots the time series of annual areal cover fraction of each pft that emerge in the domain for a model run time of 1500 years the notebook begins with an introduction notebook section 1 0 to the landlab ecohydrology model and the landlab components used to build this model data science and cyberinfrastructure methods are provided notebook section 2 0 followed by climate methods notebook section 3 0 and ecohydrology modeling using landlab methods notebook section 4 0 finally instructions to save the results back into hydroshare notebook section 5 0 are given starting with a randomly distributed equal fractions of tree grass shrub vegetation and bare soil the model organizes the spatial distribution of pfts through time in the low elevation band map 217 mm pet 1601 mm y aridity index ai 7 34 the local climate can be considered arid ai 5 nash et al 1999 drought tolerant shrub vegetation outcompetes trees leaving a few trees behind while grass gradually retreats leading to an ecosystem where shrubs dominate but co exist with grass as a secondary pft the modeled pft map fig 8 a left shows pockets of grass clusters within the shrub domain a few small clusters of trees still exist in very low fraction of the domain it would be interesting to explore how the grass shrub interplay shape over longer time using this model note that the bell shaped response of grass and to an extent shrubs in this simulation can be attributed to the trends in the precipitation data in the historical period giving 5 10 boost to the areal grass coverage and 5 for shrubs the repetition of the bell shaped response is due to the tiling of the historical precipitation and temperature data in the mid elevations map 285 mm pet 1427 mm y ai 5 in the arid to semiarid climate transition nash et al 1999 the conditions are cooler and wetter compared to low elevation band in this example these conditions provide moisture to sustain enough healthy trees allowing them to outcompete shrubs as trees can spread seeds to longer distances than shrubs for establishment to become the primary pft grass grows in empty spaces that are not surrounded by healthy trees or shrubs due to two reasons 1 the availability of seeds everywhere 2 lack of pfts that outcompete them for establishment as trees and shrubs are competing this leads to an ecosystem dominated by trees but co existing with grass as secondary pft and shrubs as the tertiary pft fig 8 b right it will be worthwhile to check whether this ecosystem can sustain the co existence of the three pfts for longer periods of time at high elevations map 353 mm pet 1293 mm y ai 3 66 climate is the coolest and wettest among the three elevation bands and fall in the semi arid category nash et al 1999 trees dominate shrubs gradually leading to an ecosystem dominated by trees while grass retreats gradually and stabilize only few small shrub clusters remain after 1500 year users can run this model longer to see if shrubs will completely disappear from the ecosystem in addition to running the notebooks for a longer period of time as discussed above one can also edit the model inputs by modifying the file ecohyd inputs yaml located in the folder supporting files and explore various hypotheses for example by changing the soil texture or modifying vegetation parameters to explore how local vegetation dynamics can impact the spatial organization of plants 3 3 3 impacts on use and reuse of research models this notebook is designed for earth scientists who are interested in understanding the influence of climate on long term climate driven changes the spatial vegetation patterns in semi arid landscapes the ecohydrologic vegetation dynamics model built in landlab leverages the framework s flexibility for building numerical models from components and utilities available in its library in this example we have demonstrated how to use a landlab model multiple times on hydroshare using downloaded gridded meteorological datasets with the ogh library phuong et al 2019 3 3 4 notebook 3 access in this example we use a ecohydrology model with landlab and hydroshare in a new mexico example or to reuse in another location in the continental united states please see the jupyter notebook reuse ecohydrology gridhydromet ipynb this notebook is available on hydroshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 for detailed instructructions on notebook access see section 3 1 4 or the readme found at the hydroshare link 4 discussion broadly speaking knowledge infrastructure can be considered a social construct components of hardware and software are built by a community of developers based on a perceived need or by employing user experience research to guide design decisions when the advanced cyberinfrastructure has evolved to knowledge infrastructure the design of the software system is a creative and problem solving endeavor developed with a community committed to using it for their research and education with feedback and investments of resources we discussed knowledge infrastructure as a web based system of tools that can be adapted and co opted to develop technological and sociological solutions to emerging problems of complex systems by efficiently connecting researchers their data and models private and public users and funders committed to long term maintenance and operations of distributed computing resources through the work of developing a description of how others can interact with our earth surface model results we learned that the system outlined in fig 1 is just one realization of how to synthesize components to run landlab models on hydroshare we expect that this model will evolve with each research application model and user especially as technology advances and user input improves usability all users benefit when systematic processes support training for learning new tools and incorporating emerging technology into scientific methods there are two main challenges to conducting sophisticated earth surface model applications 1 they are computationally and data intensive and 2 communication of methods and results through traditional peer reviewed journal publications conference presentations as well as student mentor and peer peer relationships may not be efficient at ensuring reproducible results here we consider reproducible to include both the ability to replicate published results e g testable by editors reviewers or readers and to reuse the research products as a baseline for future studies e g accessible code and data reproducibility in earth surface modeling is time and resources expensive and addressing the challenges above is common across most of computationally intensive sciences requiring research software development for example a spatially distributed numerical model application for landslide risk should be reproducible both at the site where model is calibrated and applied in a paper and the cyberinfrastructure should provide the flexibility for the same model to be applied at another site just by changing several spatial inputs on the same platform for another example an individual researcher may choose a personal cyberinfrastructure system horsburgh et al 2016a b that they design develop and or inherit from colleagues whereas a research collaboration such as a study by multiple domain scientists and institutions may require co design of a community knowledge infrastructure to address a broad range of formal and informal processes that support the ongoing development of research products we submit for consideration by the earth surface research community that more attention on system design for both personal cyberinfrastructure and shared knowledge infrastructure will accelerate our research productivity the aim is to deploy the latest technologies in such a way as to minimize the researchers effort to acquire expertise in technologies outside their domain and to better enable domain scientists to focus their attention on the theoretical underpinnings and development of new process based understanding of the earth system in the current rapidly evolving environment of computer technologies the community of researchers often needs to keep pace with technological advancements such as new computational platforms high performance and cloud computing open source modeling frameworks and software paradigms libraries and tools we identified barriers that can be addressed with knowledge infrastructure design in research section 4 1 we found that these barriers can be lowered by including user input in the system development process section 4 2 which we expect to advance science through simultaneously supporting both inductive and deductive learning processes section 4 3 4 1 defining five common barriers using two user centered design methods devi et al 2012 expert review with landlab researchers and guided walkthrough with tutorials in workshops and classrooms we outline the following five common barriers and sought to lower these for more students and researchers by utilizing community resources for numerical modeling 1 unclear processes in conducting open research vocabulary workflow and metrics for success are not well understood and standards of practice are at the early stages of development 2 technological requirements for hands on learning training and workforce development using large datasets and high performance computing requires expertise beyond the experience of most domain scientists 3 hardware and software requirements for using online infrastructure in workshops and classrooms software installations and model run time on local computers limits the time available to introduce new concepts and tools 4 compiled observations and research products e g model results are difficult to access data driven introduction to science concepts is time intensive and there are no best practices for classroom interaction with large datasets and coupled spatial temporal visualizations of published model results 5 time investment and expertise required to begin using a complex model is too high in many collaborations only one model expert can execute interact and manipulate the model which limits building deeper understanding and communicating about implementing new ideas 4 2 development based on user input knowledge infrastructure can be effective at lowering common barriers if it is designed based on input of users user information may include cultural formal and informal preferences for conducting research and sharing data for example design of knowledge infrastructure to to improve communications among users is generally perceived to have the potential to lead to rapid advancements in process and system level understanding through data analysis and modeling scientists and users from multiple research and decision making communities have shared needs to expand their understanding of processes at specific locations on the earth surface for research communities the focus is always on advancing scientific understanding for other user communities such as those applying the latest research to improve data collection or operating resources based on observational and modeled data the focus may be on incrementally developing systems to use the gained knowledge to adapt to changing conditions mees 2017 dilling et al 2017 hughes s a 2014 nalau et al 2015 baker et al 2012 regardless of the structure of the system users and developers want a simple work experience where they launch a web browser and quickly get to work regardless of what the purposes of modeling and the background of users might be functional knowledge infrastructure should give enough confidence to users to run models reproduce and reuse model applications analyze results and communicate their findings and unique perspectives on the complex system behavior they are investigating 4 3 development to advance science to encourage continuous scientific advancement in the earth science domain we advocate that researchers develop their data and models using knowledge infrastructure that enables replication and reuse and consider leveraging open source data and research software wherever possible this approach is ideal for graduate education where data and models published using shared standards in an open source system can be replicated reused and advanced by other investigators additionally code reproducibility may shorten the learning curve for modeling allowing more time to progress research in a domain of science that is supported by using the model and not distracting from work on a primary research questions with data and modeling technical issues if a user follows an inductive learning narrative they may use a workflow fig 9 top to bottom workflow that starts with a new idea and ends with testing a hypothesis or an inductive learning approach section4 3 1 if a user follows a deductive learning narrative section 4 3 2 they may begin with a pre existing experiment or toolset test a hypothesis and then develop new ideas from what they learn during the tests fig 10 bottom to top workflow next we describe how both inductive and deductive narratives are supported 4 3 1 inductive learning approach an inductive learning approach develops evidence and inference by selecting a hypothesized process representation within a system e g landscape testing that hypothesis and depending on the outcome develop a refined hypothesis of the process and further design testable numerical and field experiments pfister and kirchner 2017 this approach is crucial for advancing theoretical concepts for each process and identifying process couplings most earth science models require laborious work to make them suitable for inductive learning recent component based frameworks like landlab hobley et al 2017 and summa clark et al 2015a 2015 are developed with the perspective that they can be used for inductive learning and research centered on developing a new idea and making use of other published and tested components in the complex system to test one new idea at a time 4 3 2 deductive learning approach a deductive approach is useful when given a precompiled set of model inputs outputs and coupled system of process models the user or cooperative research group can develop new hypotheses to test given emerging research and new observations this is a common workflow in science and engineering after a model in published the code and data are shared such that when new observations or tools are added during continuing research these addenda are added to an existing library and new ideas for tools experiments and data collection emerge and advance the next steps of research the preliminary development of landlab focused on workflow designs where users would begin code development by testing new ideas using published python scripts to develop process representations of individual earth system processes the result is a landlab environment fig 9 with an ecosystem of process components where users can test new ideas resulting in the development of new components that contribute to a shared and expanding library while it is common in earth surface numerical modeling communities to build on and contribute to existing models the landlab approach provides a way for new users to begin learning and contributing by developing simple python scripts that could be executed from a terminal command line landlab provides a means for new users to use an inductive learning approach to study one earth surface process at a time without having to first master the use of pre existing complex model and to contribute code to expand processes represented in the model running landlab on hydroshare fig 1 provides new users the opportunity to quickly begin exploring landlab models with minimal software requirements a web browser and internet connection landlab and hydroshare development and research community can continuously improve and evolve for example by implementing an automated updating system that would maintain landlab version on hydroshare with automated tests the ensure new versions of landlab continue working with all hydroshare resources that use landlab 5 conclusions to illustrate how common barriers to earth surface modeling can be lowered using knowledge infrastructure we have developed three interactive computational narratives using landlab on hydroshare landlab is a recently developed python based earth surface modeling toolkit hobley et al 2017 hydroshare is a web based system that can be used to store share and publish hydrologic data and models idaszak et al 2017 www hydroshare org the infrastructure design and methods are illustrated as an interchangeable set of hardware and software components for our case study we combine an online community repository hydroshare modeling framework landlab software environment dockerized jupyterhub server and storage irods with a community approach to advancing scientific progress using earth surface models we demonstrate how to use this system in a classroom setting to explore spatio temporal data network processes e g hydrologic routing replicate published results from a complex model in a controlled software environment e g landslide model sensitivity to fire related parameters and how to use the same system to reuse flexible components to design a model experiment e g ecohydrology model sensitivity to elevation and climate that can be used generate new results in any location in the continental united states the use cases we present have been designed to illustrate a range of functions and show the benefits of using knowledge infrastructure to transform how researchers share publish and distribute knowledge given a range of science topics to address common challenges to using online systems for collaborative numerical modeling in the past running distributed hydrology landslide and ecohydrologic vegetation dynamics landlab model components required access to a powerful computer an installation of python and an installation of landlab now any user can log into hydroshare through an internet browser from any computer or handheld device and run this model without having to install any software the user can explore the models further by changing the model parameters climate forcings or building their own model with community support the demonstrated knowledge infrastructure enabled by advanced cyberinfrastructure is designed to support researchers in more efficiently advancing earth system knowledge software and or data availability models described in this manuscript are available on hydroshare citation bandaragoda c a m castronova j phuong e istanbulluoglu s s nudurupati r strauch n lyons k barnhart 2019 enabling collaborative numerical modeling in earth sciences using knowledge infrastructure landlab notebooks https zenodo org badge latestdoi 187289993 accessed 5 30 2019 replicated in hydroshare at https doi org 10 4211 hs fdc3a06e6ad842abacfa5b896df73a76 landlab can be installed from conda forge with windows 7 mac os 10 6 or ubuntu linuxogh v 1 5 4 is released on github https github com landlab landlab releases and is freely available under an mit license this github repository is maintained by the landlab development team the landlab python library is also vailable within a jupyterhub unix docker environment hosted on the cuahsi hydroshare server tutorial use case notebooks for developers can be found at the github repository https github com christinab pub bandaragoda etal ems and the hydroshare resource https www hydroshare org resource fdc3a06e6ad842abacfa5b896df73a76 acknowledgments we acknowledge funding from nsf for hydroshare aci 1148453 tarboton bandaragoda aci 1148090 idaszak oac 1664018 idaszak oac 1664061 bandaragoda idaszak tarboton and oac 1664119 wang cuahsi ear 1338606 castronova and the community surface dynamics modeling system csdms ear 1831623 these development grants supported a team including the consortium of universities for the advancement of hydrologic science inc cuahsi utah state university brigham young university tufts university university of virginia university of washington national center for atmospheric research ncar purdue university university of texas at austin and san diego supercomputing center for the development of the hydroshare platform http www hydroshare org from 2012 to 2018 for roger supercomputing oac 1429699 wang and advanced cyberinfrastructure oac 1443080 oac 1429699 and oac 1047916 wang and cybergis aci 1047916 wang idaszak for landlab oac 1450412 istanbulluoglu oac 1147454 oac 1450409 tucker hobley oac 1450338 ear 1349375 the oliver fund of tulane university gasparini lyons and for landslide research cbet 1336725 istanbulluoglu barnhart acknowledges an nsf ear postdoctoral fellowship ear 1725774 this project received partial funding from the european union s horizon 2020 research and innovation programme under the marie skłodowska curie grant agreement no 663830 hobley the authors are grateful for this diversity of contributions any opinions findings conclusions or recommendations expressed in this material are those of the authors and developers and do not necessarily reflect the views of the nsf or other funding organizations all data and code used in this research are available on github landlab and hydroshare organizations as well as hydroshare www hydroshare org where readers can collaborate join the public landlab group and view shared public data described in this paper abbreviations ki knowledge infrastructure ci cyberinfrastructure cuahsi consortium of universities for the advancement of hydrologic science inc csdms community surface dynamics modeling system icts information and communication technologies gui graphical user interfaces pc personal computer hpc high performance computing chpc cloud based high performance computing soa services oriented architecture oai ore open archives initiative object reuse and exchange standard doi digital object identifier rest representative state transfer api application programming interface summa structure for unifying multiple modeling alternatives nwm national water model odm2 observation data model 2 xsede extreme science and engineering discovery environment roger resourcing open geospatial education and research supercomputer ux user experience modflow the usgs modular three dimensional finite difference ground water flow model taudem terrain analysis using digital elevation models swat soil and water assessment tool wepp water erosion prediction project wilsim web based interactive landform simulation model noca north cascades national park complex ssurgo soil survey geographic database catgrass cellular automata tree grass shrub simulator pft plant functional types map mean annual precipitation pet potential evapotranspiration appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online athttps doi org 10 1016 j envsoft 2019 03 020 
26163,error metrics quantify predicted flow accuracy and compare different predictions hydrologists commonly use and report metrics with little justification or discussion of the selected metric or metric strengths and weaknesses metric selection requires clear objectives as different metrics are sensitive to different bias or error types we review over 60 different error metrics along with various common modifications we provide a brief metric description of these metrics and a more in depth discussion of metrics often reported in hydrological literature we recommend that multiple metrics be used to evaluate model accuracy we present the open source hydroerr library implemented in python and matlab which contains the error metric functions reported here to facilitate greater use of these metrics and encourage metric exploration related to relative metric strengths and weaknesses we demonstrate the library with short case studies and provide a supplement with additional detail graphical abstract image 1 keywords hydrology model error model evaluation model accuracy predicted versus observed 1 introduction 1 1 error metrics a brief overview scientists use error metrics to quantify the goodness of fit or accuracy of predictions or model results to measured data the need for error metrics and error quantification is generally understood but the methods used in practice vary widely reich et al 2016 error metrics to compare time series models and data are common in many fields using earth observations or environmental modeling krause et al 2005 hydrologic models are a special case as they generate time series predictions rather than single values time series comparisons add some complexity to accuracy evaluations reich et al 2016 this discussion on which metrics are most appropriate is a long standing issue as early as 1920 a paper mathematically compared the mean error me and the mean squared error mse metrics for evaluating the accuracy of time series predictions and concluded the mse was preferable as the me provided no additional information fisher 1920 however this recommendation was not without caveats as fisher 1920 notes that the me while not preferred is less affected by outliers in 1969 empirical studies used a limited number of methods to compare the accuracy of large numbers of time series newbold 1983 reid 1969 1975 starting in 1979 makridakis et al 1979 published the results of a series of three competitions to evaluate new and novel error metrics of time series accuracy measures makridakis et al 1979 1982 makridakis and hibon 2000 these articles present an extensive overview of time series error metrics and their use and provide a good review of the associated issues we recommend these articles as a primer on the topic one of the first papers comparing time series error metrics fisher 1920 highlights a major challenge involved in selecting appropriate error metrics namely what is meant by goodness of fit and what deviations from observations are important krause et al 2005 mccuen et al 2006 reich et al 2016 willmott 1981 willmott et al 2012 this topic what is goodness of fit and what should be quantified by an error metric has generated voluminous discussions the literature presents debates on various approaches to error metrics and justifications for using specific approaches for example tornquist et al 1985 argue for using relative change rather than absolute change they argue that relative change metrics are unitless and thus directly comparable across locations or measurement types while others have argued for absolute change error metrics which have the same units as the data providing insights to accuracy reich et al 2016 notes a trend for using l1 norms or relative absolute error metrics e g relative mean absolute error or mean absolute scaled error as just two examples rather than l2 norms or squared error metrics e g mean squared error to reduce impacts from outliers armstrong and collopy 1992 hyndman and koehler 2006 associated research has resulted in a number of proposed metrics such as the naive2 method makridakis and hibon 2000 and others that have not been widely adopted reich et al 2016 in some fields such as weather and climate forecasting a relative mean squared metric called forecast skill has been widely used since the 1980s murphy 1988 in hydrology this metric has not been broadly adopted though the nash sutcliffe efficiency nse index nash and sutcliffe 1970 a squared error metric is gaining dominance in recent literature kling et al 2012 in section 4 2 we provide additional discussions about the nse index reported issues and metrics developed to address these issues a large volume of literature exists comparing error metrics and many of the references we provide for the specific metrics listed in section 2 are detailed comparisons of a specific metric with other metrics there are also more general discussions for example krause et al 2005 provides a detailed examination using hydrographs of a number of commonly used metrics in hydrology r2 various forms of the nash sutcliffe efficiency coefficient nash and sutcliffe 1970 and various forms of the index of agreement willmott 1981 in this paper we do not attempt to compare metrics we systematically review common metrics used in hydrology and provide an open source software library for community testing using and further developing these metrics 1 2 metric or performance measure requirements in hydrology error metrics are used to measure the goodness of fit or to quantify the difference between predicted and observed values in a time series the metric can quantify different deviations such as a difference in the time series values a difference in the shape or sequence of the time series a difference in the distribution of the values in a time series accuracy of the prediction compared to a naïve prediction or other pertinent measures hydrologists select error metrics to quantify the accuracy of a prediction or to guide model calibration or development depending on the application different measures are applicable and in many cases it is likely preferable to use multiple metrics since different metrics quantify different aspects of fit and model accuracy though the use of multiple metrics is not common in the literature one barrier to using multiple metrics is that many metrics even commonly used ones have implementation details that seem to be often ignored or not noted in the hydrology literature for example tornquist et al 1985 note that most error metrics are asymmetric and or non additive which means the error metric value depends on the order of comparison between the predicted and observed series and even more importantly that successive changes if measured individually do not give the same result as the same change measured in one step both issues complicate interpretation in asymmetric measures the order of comparison matters for example if the predicted and observed values are 2 and 4 respectively the error is 50 but if the predicted and observed values are reversed the error is 100 in either case the absolute error is 2 while the actual error is either 2 or 2 depending on the order non additive error metrics give different results depending on the number of steps in the comparison for example if we have two prediction steps starting at 2 then stepping to values of 4 and 6 the stepwise errors are 100 2 4 and 50 4 6 summing to 150 while the single step error from 2 to 6 is 300 these are not incorrect but most model accuracy discussions reported in the literature do not discuss or acknowledge these issues there is a debate on whether to use metrics that present actual error i e in the same units as the data or relative error i e as a percentage of the data tornquist et al 1985 in hydrology relative change metrics such as percentages highlight errors in low flows more than high flows for example if the absolute error is 2 units during a period with a base flow of 4 units this would be a 50 error while the same error occurring during high flows at 40 units would only be a 10 error in either case the absolute error is 2 depending on the prediction requirements this may be helpful or misleading in another example if the model objective is peak flow prediction an error metric that is dominated by low flow regimes may not result in the best calibration for a model for other applications a prediction that minimizes relative error in both low and high flow regimes e g models used to manage water use might produce the most useful model in the latter case absolute error metrics log error metrics and squared error metrics all weight errors in the high and low flow regimes differently and also weight outliers differently in the final value relative change metrics using log difference or log percent difference as the error measures are symmetric and also additive which address many of these issues optimally hydrologists would explore these various error metric options with their strengths and weaknesses and use several metrics when evaluating model predictions or performing model calibration model bias is also interesting to consider in terms of error metrics most metrics purposely eliminate bias effects by using absolute or squared error values to avoid negative and positive errors canceling each other for most objectives this is the preferred behavior as over and under predicted values can cancel out resulting in an error metric value that appears to indicate good fit when none exists however for model calibration and model characterization quantifying bias is important modeled time series data often have a systematic bias such as over prediction under prediction or a time shift most commonly used error metrics do not indicate a systematic under or over prediction as the metric is always positive for model calibration it is useful to know if the prediction has an over or under prediction bias any metric either relative or absolute that involves the square or absolute value of the error cannot identify the direction of that bias in the prediction this is an example where using multiple error metrics that assess different aspects of model fit including bias can be more effective for improving model calibration than using a single metric 1 3 definitions metric types and notation for discussion we will refer to the following where h represents the error metric function y is the predicted data and x is the observed data so y x represents the error term a metric is symmetric if 1 1 h y x h x y o r h y x h x y a metric is additive if when we consider a two stage change x y z and the corresponding single stage change x z the metric value is the same 1 2 h z x h y x h z y measures that report bias usually have negative values for an under prediction bias i e if the measure of y is less than the measure of x and positive values for over prediction i e if the measure of y is greater than the measure of x though other values can represent bias generally if a metric reports a bias it can be stated as 1 3 h y x 0 i f f y x 1 h y x 0 i f f y x 1 where f y x is the function used to sum or quantify the differences these error metric properties symmetric additive and bias reporting are not all present in most single error metrics and a metric with all these properties may not be useful alone however hydrologist should be aware of the properties of a metric and what it does and does not measure there are a number of types of error metrics used in hydrology some measure the spread in the data e g standard deviation or other data set parameters but most measure the distance between the predicted and observed time series these types of distance measurements in multi dimensional space are called norms in linear algebra essentially we treat the two time series as a set of multi dimensional vectors identifying a single location in multi dimensional space and measure the distance between those locations as a norm norms use a number of different error term representations most error metrics used in hydrology are standard linear algebra norms using different error terms these norms are often normalized by selected features of the data set to generate a relative metric that is dimensionless the general form of the norm often called the p norm with notations of or lp norm defined as 1 4 ε p i 1 n ε i p 1 p where ε i is the error measure for the ith predicted measured pair of points n is the number of points in the time series and p is the order of the norm if for example the error term is the difference between the predicted and observed values ε y i x i then we can write the ℓ 1 n o r m or l1 norm as 1 5 ε 1 i 1 n y i x i and the l2 norm is 1 6 ε 2 i 1 n y i x i 2 1 2 when p the ℓ or infinity norm is equal to the maximum value of the error term ℓ m a x y i x i when p 0 the ℓ 0 or zero norm is the number of non zero members in the vector often referred to as sparsity metrics in the forms of the ℓ 1 ℓ 2 and ℓ norms are those most commonly used in hydrology other forms are common in other fields for example the l0 norm is used in compressive sensing where the goal is to maximize sparsity minimize the zero norm and the l2 norm is used in least squares fits common in hydrology recently error metrics in the form of the l1 norm are more often recommended in hydrology and other fields as they reduce the impact of outliers in a data set on the computed value the metrics based on the l2 norm are often used because the mathematics results in a simple deterministic equation for the fit however as noted recently there are arguments that using metrics based on the l1 norm provides significant benefits though its use in computing a model fit is more complex in hydrology we are generally not using norms to develop a statistical model between the predicted and observed time series but rather just measuring correlations between two data series so these computational concerns are not important in either case with modern computers and software computational complexity is less of a concern these general norms can use different error measures and are commonly normalized by various aspects of the data set error metrics are often normalized so the norms are less dependent on the number of samples and norms from data sets of different sizes are more easily compared the most common normalization is to divide by n the number of samples as norms are a distance measure normalizing by the number of samples n is the same as converting the norm to a unit vector for example the square of the 2 norm is 1 7 ε 2 2 i 1 n y i x i 2 the normalized square of the 2 norm normalized by the number of samples n is the mean squared error mse 1 8 m s e 1 n ε 2 2 and the normalized ℓ 1 norm is the mean absolute error mae 1 9 m a e 1 n ε 1 norms are also commonly normalized by other functions such as the mean of the observed data or the spread of the observed data to generate relative measures the commonly used nash sutcliff efficiency index is of this form this can be considered a normalized index e g normalized by the difference from the mean or as a skill score where the error is compared to a naïve forecast in this case using the mean value as the naïve forecast we included this general discussion on notation and general terms to guide readers as they study the literature for example the use of norm notation is much more common outside hydrology especially in the growing fields of machine learning and big data both the script ℓ p n o r m regular lp norm and the italic p norm notations are found in the literature in the remainder of this paper we will most often write norms using the summation notation i e the right side of equations 1 4 with explicit definitions of the error terms this notation while somewhat unwieldy clearly presents the error metrics in an easily understandable form and in a way that can be directly implemented in addition most of the error metrics are standardized and normalized by various terms this is more clearly presented by a summation notation we will use y to represent the predicted values and x to represent the observed values while y x is the most used error term the norm of any other selected error terms can be computed and many of the metrics presented in this paper use other definitions 1 4 considering negative values for the purposes of this paper we are focused on error metrics that quantify the difference between predicted and observed time series data which we assume to be streamflow data this means that the data are strictly positive many of the metrics presented in this following sections are not defined for negative data and could not be used for data with negative values such as air temperature they can however be used if the data are transposed to a positive domain the error metrics we present differ in how the error is measured if the error term is transformed e g log transform how the error is standardized or weighted and how the error metric is normalized the different metrics highlight different aspects of the error between the predicted and observed time series some metrics indicate bias some minimize the impact of outliers some evaluate shape some are insensitive to linear offsets or transform and some have different ranges and responses to the magnitude of the differences 1 5 objectives the primary objective of this paper is to provide a review of error metrics reported in the hydrologic literature along with brief descriptions of each metric and implementations of these metrics our secondary objective is to introduce a new open source software library called hydroerr to encourage hydrologists to explore and use multiple metrics in their work this manuscript is an extension of an earlier paper roberts et al 2018 that presented the python hydrostats package this package includes the hydroerr library reported in this paper but also includes tools for dealing with time series data visualizations and plots the earlier paper did not provide details on the error metrics which are the heart of the python package this paper provides that detail and discussion in the electronic supplement to this article we apply a large number of these metrics to 13 different common discrepancies between predicted and observed flows using synthetic data the supplement also provides more in depth application of 7 selected metrics these presentations include graphical depictions of the errors and color coded tables that indicate the sensitivity of the metric to the various error types the objective of the hydroerr library is to provide a coded implementation of metrics used to compare time series especially for flow so that hydrologists can quickly and efficiently compute different error metrics on their data with confidence that it has been coded correctly implemented as both a python and matlab these tools will hopefully encourage researchers to use multiple metrics and to explore issues such as lag correlation or timing offsets in their data we also hope that as hydrologists develop or apply metrics that are not in hydroerr that they will extend the library for community use 2 error metrics review 2 1 relative error metrics ratios or percent tornquist et al 1985 presented an argument for using relative error metrics or rations they strongly argues for using log relative metrics we summarize his discussion here as it is informative they provide various forms of relative error metrics terms with nine specific and one general functional form in the following discussion the numbering and presentation follow tornquist et al 1985 the metric is first presented first equation to the right of the sign with the error measure presented as a difference between the predicted y and the observed x time series then the ratio or relative form presented as the terms right of the second sign this is to show how differences translate into ratios of log terms we do not present the algebra required to create the relative term in these equations the subscripts and summation notation over point pairs are omitted for simplicity in each of these metrics equation 2 1 through 2 11 the summation over the predicted measured pairs is implied this notation is also omitted because these equations 2 1 2 11 are only notional forms actual metrics would need to clearly define the error term y x and other aspects such as normalization by the number of pairs in the series or other measure any of these error representations could be used to calculate an error metric and while we do not do so many of the presented metrics could be categorized by this list relative difference 2 1 h 1 y x y x x y x 1 2 2 h 2 y x y x y 1 x y standardized forms 2 3 h 3 y x y x 1 2 x y y x 1 1 2 1 y x 2 4 h 4 y x y x x y y x 1 y x 2 5 h 5 y x y x 1 2 x 1 y 1 1 y x 1 1 x y 2 2 6 h 6 y x y x 1 2 x k y k 1 k y x 1 1 x y 1 2 1 y x k 1 k 2 7 h 7 y x y x min x y y x 1 min 1 y x 2 8 h 8 y x y x max x y y x 1 max 1 y x general form 2 9 h 9 y x y x k x y y x 1 k 1 y x log of ratios 2 10 h 10 y x l o g e y x metrics h 1 and h 2 equations 2 1 and 2 2 are standardized by the average x and average y values respectively where the metrics h 3 through h 8 equation 2 3 2 4 are standardized by various functions of both x and y which are respectively the arithmetic geometric and the harmonic means the moment mean of order k and the minimum and maximum error the h 9 metric equation 2 9 is a general form where the error measure is standardized by a function k x y that satisfies a number of mathematical properties tornquist et al 1985 then show that the log difference metric h 10 equation 2 10 can be reformatted as 2 11 l o g e y x y x l x y where l x y is the logarithmic mean thus h 10 equation 2 10 is also a specific form of h 9 metric equation 2 9 error metrics can be also be combinations of two or more other metrics this is often done to combine relevant qualities from several metrics into a single value for example h 3 4 1 3 h 3 2 3 h 4 approximates h10 for small changes tornquist et al 1985 tornquist et al 1985 recommend the h10 log ratio metric formulation as this metric is symmetric and non additive he notes that a new indicator can be obtained by multiplying any of the indicators by a positive constant h1 h10 are all normed but their positive multiples are not multiples of h10 have common scientific usage for example decibels acoustics and electronics din film sensitivity in photographs and the richter scale power in earthquakes are all just multiples of h10 difference measures in signal processing error measurements of this form are often reported in dbs decibels going back to its use in acoustics while tornquist et al 1985 argues strongly for using relative difference measures i e ratios many if not most commonly used metrics in hydrology use some form of the absolute difference between the observed and measured values y x where y x represent some function of the difference between the predicted and observed times series either relative error terms or quantitative error terms can be used to compute the various p norm measures of distance between the predicted and observed time series these error measures can be standardized by various terms for example the nash sutcliffe efficiency score is standardized by the spread of the observed data this results in a value that compares the predicted values to a value that would result if the prediction were just the average of the observed data nash and sutcliffe 1970 2 2 other measures some metrics measure the distance or difference between various statistical or other properties of the predicted and observed time series rather than the distance between the values for example we can calculate the norm of a series rather than a difference and compare these norms 2 12 d i f f e r e n c e o f m e a n s p n o r m y p n o r m x where if we use normalized p norm values divide by n then the l1 and l2 norms would give a difference in the arithmetic and geometric means of the two time series respectively other measures can be and are also used such as the variance of the differences vod 2 13 v o d σ 2 y x or the difference in the variances dov 2 14 d o v σ 2 y σ 2 x where the variance of x σ 2 x is defined as 2 15 σ 2 x 1 n i 1 n x i x where x is the mean of the time series vod gives a measure of the spread of the differences in the predicted observed pairs while the dov gives a measure of how the spread in the two data sets compares to each other both can result in small values which indicate good matches even if the two time series are offset by a large constant amount these highlight different aspects of the goodness of fit useful but not commonly reported in the hydrologic literature 2 3 lag correlation in hydrology one issue is the timing of an event between the predicted and observed data set these timing errors can be characterized using lag correlation metrics lag correlation metrics show timing or offset errors and are calculated by computing a selected error metric off setting or lagging one of the time series then recomputing the metric this approach results in a graph showing at what lag or time offset the two data sets are best matched this has several uses for example hyndman and khandakar 2008 used lag correlation measures to better understand how their dataset captured specific events even though the timing was slightly off 2 4 hydrologic error metrics tables 1 4 present common error metrics used in hydrologic science we selected references given in the tables for manuscripts where the error metric is compared and contrasted with other common metrics these tables are not an exhaustive list of error metrics though we attempted to include all commonly used metrics we did not attempt to find the first reference to a given error metric in the literature rather we referenced manuscripts that provided discussions of metric comparisons using that metric metrics are often known by different names and acronyms across and even within disciplines we have attempted to use the name more commonly used in hydrologic literature while these lists of error metrics are extensive they are not exhaustive and the literature is replete with additional metrics some metrics presented in the literature are new and unique and some existing metrics are presented in papers with new names new applications or in a different mathematical forms as discussed in sections 1 3 2 1 2 3 and by hyndman and koehler 2006 new error metrics can easily be derived by selecting an appropriate error term and means of normalization error metrics can be modified by scaling or transforming the error term e g logs or z scale transforms or using different p norms with the same error term e g absolute value square or cube error metrics can be normalized using different mean values e g geometric mean arithmetic mean etc maximum values minimum values the error of naïve forecasts or other terms the following organization of categories and the associated discussions generally follows hyndman and koehler 2006 which we recommend to those interested in error metric application and issues as we do not provide the same level of detail error metrics can be categorized into general categories though this categorization may not be unique depending on the form of the written metric or how different term are interpreted it may appear to belong to different categories even though the metric has not changed we used the following categorizes for discussion scaled error percentage error scaled forecasts and an other category hyndman and koehler 2006 these categories can provide guidelines for when to use the different types of error metrics and the information they provide about the predicted observed fit we provide some limited discussion on these general categories some specific common example metrics in each category and when metrics from the category are applicable or conversely when they are not applicable for hydrologic model analysis 3 common error metrics 3 1 scaled errorss table 1 presents scaled errors scaled errors such as mse rmse mae or mdae can be based on either an absolute or squared error term mse and rmse are commonly used metrics from this category but they are sensitive to outliers which can limit their usefulness armstrong and collopy 1992 the rmse is useful because it presents errors in the same units as the measurement and most hydrologists are familiar with the metric and its application however as stated above these metrics are insensitive to linear transforms or offsets that means that the predication can be significantly different from the observation and still have a low rmse most literature recommends using the log of the predicted and observed in the error metric to reduce the impact or weight of outliers in the data all of these metrics can use log transformed data with the exception of those which already do a log transform as with 1 above values need to be positive i e before the log transform the data need to be 1 3 2 percentage errors percentage errors scale the error term by the observed data in some form resulting in metrics that are scalable and can be compared across different data sets commonly used metrics in this category include mape mdape and rmspe though there are others that are also used in the hydrologic literature values for these metrics are undefined for observed values of 0 and results in skewed distributions when values are near zero because of the resulting large values of the metric hyndman and koehler 2006 makridakis and hibon 2000 these measures require a meaningful zero i e the absence of quantity and cannot be used for data such as temperature in this category mape and mdape weight positive errors more than negative errors this issue is addressed with symmetric measures in this category such as smape and smdape makridakis 1993 though these metrics are actually not symmetric and weight errors for low and high forecasts differently goodwin and lawton 1999 koehler 2001 authors have also recommended modifications to these approaches such as using absolute values in the denominator to avoid negative values or using logarithm transforms of the flow data such as mle male msle to make them more stable and address the fact that they are highly skewed if the data cover a large range coleman and swanson 2007 3 3 scaled forecasts these metrics compare the ratio of the forecast error to an error obtained using a naïve forecast method such as a random walk model or even just the average flow value e g nash sutcliffe efficiency nse if the observed data have little variation then the naïve forecast error can be small resulting in large error values for scaled forecast metrics essentially metrics in this category indicate if the model forecast is better than a naïve forecast for example an nse value 0 indicates that the forecast is better than just choosing the average observed value while the random walk model xi 1 xi is commonly used as the naïve forecast method in these metrics the nse metric widely used in hydrologic model analysis uses the mean observed value as the naïve forecast method this can cause difficulties comparing across scenarios or time scales for example the nse value of a forecast during a period of flat flows will indicate a fit significantly worse that a forecast during rising flows even if the mse is the same the reason is that the variance or spread of the data is larger for rising flows than for flat flows making the denominator of the nse larger scaled forecast measures are often adjusted for seasonal forecasts where the naïve prediction is only used over a season examples of metrics in this category include nse mase mdase and gmase most often gmase is recommended in the forecasting literature armstrong and collopy 1992 in hydrology nse is the most commonly reported in the hydrologic literature kling et al 2012 there are a number of studies that evaluate the strengths and weaknesses of the nse for use in hydrologic model characterization a series of papers present methods that address short comings and issues with nse and over the course of the papers present a number of improved methods legates and mccabe 1999 willmott 1981 willmott and matsuura 2005 willmott et al 2012 this series of papers ultimately present the d r refined index of agreement metric and recommend it as the best forecast metric for hydrological data willmott et al 2012 we concur with this recommendation the d r is a relatively complex metric to compute and we submit that is one reason it has not been more widely used in hydrologic model studies we refer the readers to willmott et al 2012 for a discussion of issues with nse and applications 3 4 other error metrics and measures there are numerous other disciplines that also compare data vectors whether time series or data from other processes for example spectral measurements result in data vectors and when a spectroscopist compares modeled to measured values they are most interested in the shape of the vector rather than matching magnitudes this is also true in hydrology we are often concerned with the shape of the data for example is the hydrograph narrow or broad is it symmetric etc and while magnitude is important the shape of the data is often more important measures such as the spectral angle sa spectral correlation sc spectral information divergence sid or the spectral gradient angle sga all provide indications not only on the magnitude of the error but how well the general shape of the data in the two vectors match for example the sa treats the data as a vector in n dimensional space to compare two data sets these n dimensional vectors are normalized to unit vectors again in n dimensions then the spectral angle or direction in space between the two vectors are compared sa of 0 means the two series have the same direction i e same shape though they may be of different magnitude an sa of 0 means that one vector of data is a linear multiple of the other many of these other methods compare the shape of two series rather than the magnitude and can be useful in hydrology for specific applications others such as the euclidean distance ed and normalized euclidean distance ned measure the distance in hyperspace between two vectors the ed is the 2 norm of the error and is used in many fields we have also included a number of difference metrics based on the norms of the h metrics tornquist et al 1985 4 hydroerr open source library 4 1 software introduction hydroerr is a new open source library of error metrics for hydrologic data implemented in both python and matlab the genesis of this effort was for comparing simulated and observed streamflow data but these metrics can be used to compare any two time series except for some metrics that do not accept negative values i e log metrics the library implements over 60 individual error metrics including those provided in tables 1 4 above the python implementation of hydroerr is available on the python package index repository pypi hydroerr is a module in the hydrostats package which was partially developed to provide error metric functions for the tethys platform swain et al 2015 2016 and use with a tethys application for national and global streamflow forecasting bales 2016 snow et al 2016 the tethys platform provides tools to lower the barrier of entry for water resources web app development the matlab implementation is provided as a stand alone library a goal in creating this library was to make it easy and efficient to use several different metrics to explore different information they provide about model accuracy and to make it easier for hydrologists to access the metric s that are most appropriate for the given application for example the root mean square error rmse a commonly used metric in many fields is completely insensitive to linear transforms of the data i e the magnitude of the predicted flow could be an order of magnitude larger or smaller than the observed flow and the rmse could indicate perfect correlation for some cases this is not an issue for other cases e g flood predictions this could be a significant issue 4 2 software availability hydroerr is provided in both python and matlab implementations the python library is available on pypi and is installable by pip source code and working implementations in both languages are available from the hydroerr page on github https github com byu hydroinformatics hydroerr for the python library and https github com byu hydroinformatics hydroerr toolbox for the matlab toolbox the matlab code is implemented as individual function files if placed in a single directory they can be used as a matlab library the documentation page for both repositories provides installation instructions and examples the readthedocs documentation pages have links to updated and detailed information on the included metrics https hydroerr readthedocs io en stable 4 3 software design all hydroerr functions are designed with a relatively simple application programmer interface api in each case the function for a specific metric is called with two data vectors representing the simulated and observed flows for example the mean error function could be called as me pred obs where pred and obs are vectors of predicted and observed values respectively the functions assume the data are evenly spaced i e the same time step with missing values or unknown values represented by nan or inf placeholders many of the metrics require strictly positive values for the python implementation the vectors should be 1d numpy arrays oliphant 2006 for the matlab implementation the vectors should be 1 d vectors both in the same orientation i e horizontal or vertical vectors the metrics perform some minimal pre processing which includes checks to determine if data provided are vectors of the correct type one dimensional and if the two vectors are the same length if either check fails the function returns an error message the hydroerr metric functions can check for 0 or negative values and they check for missing values by default the behavior of the matlab and python functions vary slightly the matlab functions can be called with two optional boolean variables remove neg and remove zero which default to false if these are set to true then negative and zero values are removed the python functions have four flags replace nan replace inf remove neg and remove zero the default behavior for both matlab and python i e flags not set is to remove any data with nan and inf values the data are removed from both vectors and a warning is given to users for example if the observed data has missing values indicated by nan s in the vector these nan values along with the corresponding data from the simulated vector are deleted this shortens the vectors matlab functions and default python behavior retains zero or negative values in the python implementation the replace neg and replace inf flags provide values used to replace any instances these entries while the remove neg and remove zero flags instruct the functions to remove any instances of these values if an entry is removed in one vector the corresponding entry is removed from the other vector if the value is changed to a specified value using the replace nan or replace neg flags the corresponding value in the other vector is unchanged in the matlab implementation there is no option to replace these values they are always removed all of the metrics return a single value the calculated metric value unless otherwise specified in some of the metrics i e kge fig 1 provides simple example code showing metric use with examples in both python and matlab in these examples two datasets representing predicted and observed data respectively are compared using the mean squared error metric using both the default option and the option to remove zero valued data 4 4 implementation of hydroerr in 3rd party software the python library implementation of hydroerr lends itself to embedding in 3rd party software where error metrics are needed this software can be graphical user interfaces for specific models web based data analysis tools or research software implemented in testing suites such as jupyter notebooks to test the ability of the library to be embedded in a 3rd party software application we used it as a core component of a web based global streamflow forecast system constructed in python using django and tethys platform the matlab implementation provides efficient access for these routines in interactive sessions or for matlab scripts fig 2 shows three general use cases for the hydroerr library hydroerr can be included as a library in python or matlab installation and used interactively for data exploration or script writing the api requiring just two data vectors as input supports ease of use and integration into various other routines the second case is implementation of hydoerr as a web service which could be integrated into larger web applications for example a web application might host a predictive model and gather observation results from distributed measurements hydroerr web service could be used to create accuracy measures as part of automated tasks in the third use case the hydroerr library could be used to develop stand alone models providing an extensive library of error metrics for a developer hydroerr functions can be used as reference code for implementations in other languages most machine learning approaches involve optimization of some error measure the hydroerr library provides researchers with an efficient method of exploring the effectiveness of various different metrics with these routines 4 5 example software testing results in this section we demonstrate the library using three metrics me mae and nse we selected me and mae since because they are the simplest metrics in the library measuring the average error and the absolute error respectively it is easy to understand their application and results we selected nse because it is the most commonly used metric in the hydrologic literature kling et al 2012 the nse is simple in concept compares the prediction error to the error that would result if the average of the observed flow were used as the prediction but difficult to interpret this is discussed in additional detail in section 4 we generated synthetic data to demonstrate and test the error functions these data consisted of observed flow in the form of a sine wave with user defined minimum and maximum flows to maintain positive flow values and to allow us to change the amplitude we generated predicted flows that included gaussian noise ranging from infinity with a zero mean and unit e g 1 standard deviation and variance percent noise which adds gaussian noise weighted by the flow with weights from 0 to 1 for minimum to maximum flow respectively shifted data which shifts the sine wave in time outliers which adds outlier values at locations generated using a random vector with a selected threshold standard deviation value then multiplying the value by a constant over and under predicted flows and flows with different shapes notations for these variations are n noise p percent weighted flow s shifted flow x outliers u under predicted and o over predicted the normal flow was designated y and ys indicates flows with different shapes for example normal flow with noise is designated yn a flow that has noise is shifted and under predicted would be ynsu matlab code to generate these synthetic flows is provided in the electronic supplement fig 3 presents examples of synthetic flow records that show various combinations of errors the first three records yps ypu and yspo show shifted under predicted and over predicted flows respectively with added percent weighted gaussian noise examination shows that these flow scenarios exhibit little to no noise in the lower flow regimes and higher error in the upper regimes the magnitude of the noise changes linearly with the flow magnitude the yxnsu record shows outliers at randomly selected locations these locations were selected by generating a random vector the same length as the flow period then choosing locations outside of 3 standard deviations or at about 0 3 of the sites locations greater than 3 standard deviations were set to 1 and 1 for positive and negative values respectively locations with standard deviations less than 3 were set to zero this vector was then multiplied by the outlier factor and added to the flow data to create outliers fig 3 shows that when an outlier location is in the lower flow regime the outlier is as not evident in the plot because the outlier magnitude is a multiple of the flow the yspo record shows a flow record with a different shape ys with weighted noise and an over prediction fig 4 shows how the me mae and nse metrics behave as the flow predictions range 10 under to over prediction the upper panel only shows one year of data but the metrics were computed using three years of data this is true for the remainder of this section in fig 4 the values for each metric are normalized to a range of 0 1 for comparison the actual values of the me mae and nse metrics range from approximately 5 5 to 5 5 0 to 5 5 and 0 9630 to 1 for the me mae and nse respectively for this scenario in the bottom panel of fig 4 the me trace shows the bias in the prediction error and changes linearly from 4 5 to 4 5 as the error changes from under to over prediction the mae also changes linearly but is always positive changing from 5 5 to 0 to 5 5 as the prediction error changes from 10 to 0 to 10 respectively fig 4 seems to show the nse as sensitive to these changes but the actual nse value exhibits very little change going from 0 9752 to 1 to 0 9630 in a non linear non symmetric manner as the prediction error goes from 10 to 0 to 10 respectively this is an absolute change of less than 0 025 for under prediction and less than 0 04 for over prediction nse is not sensitive to these under and over prediction errors as they are significantly better predictions than the average flow value which is the naïve prediction used by the nse for comparison the naïve prediction for nse is just a constant value i e straight line equal to the average flow for the sine wave in the y or normal flows this is the average of the minimum and maximum flows for the ys or different shape flows it is slightly below the mid point the nse appears sensitive in fig 4 because it is normalized this normalization shows one interesting aspect of the nse it is not symmetric and is more sensitive to over prediction than to under prediction the non normalized values for me and mae are identical in the over prediction region of the plot they are offset here because of normalization to different ranges approximately 5 to 5 and 0 to 5 for the me and mae respectively fig 5 shows the behavior of the three metrics i e me mae and nse for the same series of flows as fig 4 with gaussian noise added to the predicted flows the top panel of fig 5 only shows the minimum and maximum flows with gaussian noise the added noise has a zero mean and unit standard deviation and variance the bottom panel of fig 5 shows how these three metrics change as the flows range from under to over predicted the bottom panel of fig 5 presents metric values normalized by the range of the metric for the data without noise e g the values from the bottom panel of fig 4 we did this to show how noise effects the different metrics the me metric does not show any change as the average of the added noise is 0 the noise cancels out in the metric computation the mae clearly indicates that noise is present and the difference indicates the magnitude of the noise the nse is essentially insensitive to the noise with a maximum difference of 0 001 as above the error from the noise is small compared to the error of the average flow value the insert in the bottom right corner of fig 5 shows the non normalized values the insert in the bottom right corner shows the non normalized metric values where the nse plots as a straight line i e insensitive to these changes and as expected the me and mae overlay each other in the over prediction region fig 6 presents two different observed base flow scenarios with maximum flows of 100 and 20 for the high flow and low flow scenarios respectively also shown are single realizations of predicted flows which are the base flows with gaussian noise added zero mean unit standard deviation and variance the me for the high flow and low flow scenarios are 0 005 and 0 02 respectively approximately the same and close to zero the me is close to zero because the positive and negative errors cancel if a longer simulation were used the value would tend toward 0 the me does not distinguish between the low and high flow scenarios as the errors are statistically the same the mae for the high flow and low flow data are 0 80 and 0 79 respectively these values are approximately the same because like the me the mae provides an index into the error the mae values are not zero as they report on the absolute value and represent the average distance between the observed and predicted flows the nse for the high flow and low flow data are 0 9990 and 0 9265 respectively which are significantly different even though the error in both scenarios is statistically the same this is because the nse normalizes the error term by a naïve prediction which is the average of the flow data the average flow is a better prediction of the low flow scenario than for the high flow scenario this results in a poorer nse value for the high flow case 4 6 electronic supplement the electronic supplement provided with this manuscript gives more in depth information on selected metrics example uses and an in depth analysis of a large number of the metrics it also includes example matlab code to generate a number of different synthetic flow records with various types of errors the electronic supplement includes instructions on accessing and downloading both the python and matlab versions of the library and provides some short examples of calling and using the metrics we direct readers to the readthedocs documentation for up to date instructions as we anticipate hydroerr development to continue the electronic supplement includes color coded tables that show performance of a large number of the more common metrics in the library against a number of different types of expected errors including magnitude shifts o and u timing shifts s noise n and p outlier values x and different shapes ys the supplement analyzes error metrics on 13 different error combinations which were selected to represent common biases or errors between modeled and observed data we encourage readers to use the electronic supplement as a resource to understand usage of the various metrics and as a case study on the methods to evaluate metrics for different types of errors 5 recommendations 5 1 general recommendations there are a large number of error metrics because each different metrics has specific strengths and weaknesses most new metrics are presented to address deficiencies in specific applications that are not filled by existing metrics we suspect that in a most hydrologic modelling studies error metrics are chosen based on familiarity without consideration of the relative strengths and weaknesses hyndman and koehler 2006 state despite two decades of papers on measures of forecast error we believe that some fundamental problems have been overlooked in particular the measures used and the measures recommended by other authors all have problems they recommend that the absolute forecast error scaled by the in sample mean absolute error from the naïve forecasting method is more generally applicable and more easily interpreted for hydrological applications the nse nash and sutcliffe 1970 kge12 kling et al 2012 and other extensions to the nse metric legates and mccabe 1999 willmott et al 2012 are examples of this type of metric they also note that in many cases other error metrics can and should be used to augment understanding of the forecast hyndman and koehler 2006 recommend mase as it is less sensitive to outliers though they note circumstances where other measures are useful they also recommend that mae and mape be used in conjunction it is also useful to compute one of the simple metrics that indicate bias such as me to understand model performance we recommend the following general approach this is not meant to be a detailed guide but rather a guide on how to start to characterize and understand model skill and performance 1 plot observed and predicted flow values and visually analyze the general fit try to identify any trend such as better fits in various flow ranges or times if predicted flows seem smoother than observed data if the error is mostly due to apparent noise in the observed data or any other characteristics presented by the plots we recommend using a number of different plots to start to understand the nature and character of the error we recommend starting with a simple visual analysis then move on to other more specialized plots as required this could include 1 1 flow time plots with predicted and observed flows as separate lines some items to consider visually examine the general fit identify times or flow regimes with good or bad fits and note if any timing issues are present 1 2 predicted observed pair plots scatter plot do the data fall on the 1 1 line are there flow regions where there are large apparent spreads e g low flow or high flow and are patterns present 1 3 q q plots quantile quantile plots these plots help determine if the predicted and observed data come from similar statistical distribution they can also help identify if the distribution in the predicted and observed flows are comparable and how well flow in different regimes e g high or low flow regions follow similar distributions 1 4 histograms of the observed and predicted flow values use histograms to visually compare data distributions you may want to plot histograms of the log flow values also this will give you an indication of the data distribution do you have long tails is the majority of the data in certain flow regimes are the distributions skewed are there obvious outliners and other information this analysis can help select the appropriate error metrics to use 1 5 histogram of the error y x and note the distribution if the distribution is significantly skewed you may want to plot the error of the logs log y log x which can be written as log y log x this can direct error metric choice and whether to use error metrics based on log data 2 calculate a small subset of error metrics presented for the predicted and observed flows we recommend simple metrics such as me and mle to explore bias mae to evaluate overall fit mape to evaluate fit in percentage terms and some of the scaled forecast metrics such a as mase mdase gmase we also recommend nse since it is a current standard but you should also compute the d r as studies have shown it outperforms nse willmott et al 2012 and or kge12 to better understand what is causing the error gupta et al 2009 kling et al 2012 2 1 it may be useful to calculate more targeted metrics for example sa sc or sid sa is recommended can tell you if the shape of the computed hydrograph matches the shape of the observed hydrograph even if the magnitude of the predicted flows is off significantly 2 2 it often useful to compute metrics on the log of the flow values which reduces the impact of outliers and limits the influence of high flow regimes on the metric 3 compute and plot time lag values of a small set of the metrics me mae mdmase for example to determine if there is a timing error in the prediction the plots of these values will indicate the offset between the data sets as the lag with the best value of the metric for these plots you lag one of the vectors by a given amount compute the metric change the lag and continue typically ranges of 4 to 6 lags are generally sufficient however your knowledge of the magnitude of potential timing error should guide this choice in our research group we routinely use acc nrmse mae kge12 and h10 as a subset of metrics to initially explore we use me as a useful metric to check for bias i e under or over prediction many of the literature discussions recommend using log values when computing metrics there are a number of metrics that by definition use log flow values but any of the metrics in this library can be used with log flow values working with the logs reduces the influence of outliers and reduces the impact of high flow regimes on some metrics this is important as flow data often span several orders of magnitude in these cases absolute errors in the high flow regimes hide errors in the low flow regime even if the percentage error in the low flow regions are large using log flow data addresses this to a great extent by more evenly weighting errors in low and high flow regimes whether this is important depends on your application for flood predictions for example errors in the low flow regime may not be as important and a metric that emphasizes fit in the high flow regions might be more appropriate 5 2 discussion of the nash sutcliffe efficiency index kling et al 2012 note that the nse or ef nash and sutcliffe 1970 is the most commonly used error metric in hydrologic modeling the nse compares the error of the predicted flows to the error to that of a naïve forecast a scaled forecast metric the nse uses the average of the observed flows as the naïve prediction and the mae as the error term both the prediction error and the naïve error terms are squared in the ratio with i 1 n y i x i 2 and i 1 n x i x 2 for the prediction error term and naïve error term respectively an efficiency of zero which occurs at a ratio of 1 or when these two terms are equal indicates that the predicted data have the same error as using the average of the observed data as a forecast a negative efficiency means that the observed average is a better predictor i e has a smaller error term than the model prediction a number of researchers have noted issues with this metric for example the metric changes depending on the nature of the observed flow even if the error is constant consider a simple case where modeled flow can be defined as f e where f is the observed flow and e is a random error nse will give a different value depending on f if f is constant it will give a lower value worse fit than if f is not constant e g annual variation rising limb of a hydrograph this leads to overestimations of model skill for highly seasonal flows and difficulty comparing model skill across basins with flows of differing variability gupta et al 2009 this nse works best when the coefficient of variation is large and model bias produced by calibration is low mccuen et al 2006 it is possible to calculate a high efficiency value when the variance in the data is very high even when the fit of the model is relatively poor jain and sudheer 2007 the efficiency coefficient is sensitive to outliers so nse works best when data are transformed to a normal distribution before testing for similar reasons hyndman and koehler 2006 recommended mase as a useful metric for seasonal data the literature reports a number of revised or refined nse type indexes that were specifically designed to address issues associated with nse a number of which are listed in table 3 of these we recommend using d r the refined index of agreement willmott et al 2012 as a replacement for nse d r is the last reported index in a series of refinements designed to address the issues associated with nse willmott 1981 willmott and matsuura 2005 willmott et al 2012 we recommend reading willmott et al 2012 and gupta et al 2009 for in depth discussions on issues related to the use of nse for model calibration and skill measurement and on other metrics that address these issues gupta et al 2009 provides a brief literature review of a number of papers discussing the suitability of the nse along with recommended replacements and application methods such as using seasonal averages rather than the average of the entire data set for model calibration we recommend kge12 kling et al 2012 instead of nse gupta et al 2009 provides a detailed discussion on how to use kge09 and by extension kge12 for model calibration both these metrics provide multiple criteria to better understand model behavior and to optimize model calibration kge12 is a decomposition and extension of the nse into three parameters that combine to provide the index value these three parts of kge12 are r the correlation coefficient which represents correlation between predicted and observed flows β the bias ratio between predicted and observed flows and γ which is the variability ratio between the predicted and observed flows these three parts of the kge12 metric help better understand model performance models need to match temporal dynamics measured by r and also match the flow distribution or flow duration curve described by the first and second moments measured here by β and γ which are indexes into the variability and skew of the data respectively gupta et al 2009 these three components are actually ratios which show how the predicted and observed flows compare in these three areas we recommend reading gupta and kling 2011 and gupta et al 2009 for discussions of issues associated with the mse and nse and how these are addressed using kge09 we recommend gupta et al 2009 and kling et al 2012 for in depth discussions of the theory and use of kge12 for model analysis and calibration 6 summary many error metrics are used in research and industry simply because they have been commonly used or they are easily calculated however there are a large number and variety of additional error metrics reported in the hydrologic and modeling literature each developed and applied to characterize specific issues associated with comparing predicted and observed data no single metric can fully characterize the skill of a model or the fit between the predicted and observed data which issues are important and which metrics better characterize a model depends on the specific use of the model the flow regime the model is applied to and the behavior and distribution of the data however some metrics are better suited than others depending on the nature of the time series being compared in addition to a single error metric graphical analysis is an important tool for understanding model behavior for hydrology timing errors are common and need to be evaluated by calculated a lagged error metric to determine if the best fit occurs at some lag between the two flows if the hydrographs do show timing errors magnitude errors or combinations of the two different metrics perform better than others the commonly used r 2 and r correlation coefficient do not change with respect to magnitude scale change while sa is important for evaluating the shape of the two flows the sa value is relatively insensitive to timing changes or lags other commonly used metrics such as rmse change significantly with magnitude changes while it remains essentially constant with respect to timing changes more detailed discussions of these types of behaviors are presented in the electronic supplement to this article in conclusion it is difficult to understand model behavior using a single error metric we recommend using a more inclusive characterization including multiple metrics and graphical analysis for tasks such as optimized model calibration or other machine learning type uses where the objective is to maximize or minimize a selected metric we recommend that the metric be carefully chosen to represent the appropriate model behaviors the software library is intended to facilitate use of multiple metrics the library calling routines are simple only requiring vectors of observed and predicted flows since all the functions have the same minimal interface this library allows multiple metrics to be incorporated into the analysis in addition to providing tools for model comparisons we also provide this library as a community resource where as researchers develop new metrics they can add them to and extend this library providing a common repository for error metrics used in hydrology author contributions ms jackson dr nelson dr ames and dr williams methodology ms jackson and dr williams software mr nelsen mr roberts and dr williams validation ms jackson mr nelsen mr roberts and dr williams writing ms jackson dr williams and mr roberts original draft preparation ms jackson writing review and editing dr ames and dr nelson mr roberts supervision dr ames and dr nelson project administration dr ames and dr nelson funding acquisition dr ames and dr nelson funding this research was funded by servir nasa applied sciences program grant number nnx16an45g conflicts of interest the authors declare no conflict of interest appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 05 001 
26163,error metrics quantify predicted flow accuracy and compare different predictions hydrologists commonly use and report metrics with little justification or discussion of the selected metric or metric strengths and weaknesses metric selection requires clear objectives as different metrics are sensitive to different bias or error types we review over 60 different error metrics along with various common modifications we provide a brief metric description of these metrics and a more in depth discussion of metrics often reported in hydrological literature we recommend that multiple metrics be used to evaluate model accuracy we present the open source hydroerr library implemented in python and matlab which contains the error metric functions reported here to facilitate greater use of these metrics and encourage metric exploration related to relative metric strengths and weaknesses we demonstrate the library with short case studies and provide a supplement with additional detail graphical abstract image 1 keywords hydrology model error model evaluation model accuracy predicted versus observed 1 introduction 1 1 error metrics a brief overview scientists use error metrics to quantify the goodness of fit or accuracy of predictions or model results to measured data the need for error metrics and error quantification is generally understood but the methods used in practice vary widely reich et al 2016 error metrics to compare time series models and data are common in many fields using earth observations or environmental modeling krause et al 2005 hydrologic models are a special case as they generate time series predictions rather than single values time series comparisons add some complexity to accuracy evaluations reich et al 2016 this discussion on which metrics are most appropriate is a long standing issue as early as 1920 a paper mathematically compared the mean error me and the mean squared error mse metrics for evaluating the accuracy of time series predictions and concluded the mse was preferable as the me provided no additional information fisher 1920 however this recommendation was not without caveats as fisher 1920 notes that the me while not preferred is less affected by outliers in 1969 empirical studies used a limited number of methods to compare the accuracy of large numbers of time series newbold 1983 reid 1969 1975 starting in 1979 makridakis et al 1979 published the results of a series of three competitions to evaluate new and novel error metrics of time series accuracy measures makridakis et al 1979 1982 makridakis and hibon 2000 these articles present an extensive overview of time series error metrics and their use and provide a good review of the associated issues we recommend these articles as a primer on the topic one of the first papers comparing time series error metrics fisher 1920 highlights a major challenge involved in selecting appropriate error metrics namely what is meant by goodness of fit and what deviations from observations are important krause et al 2005 mccuen et al 2006 reich et al 2016 willmott 1981 willmott et al 2012 this topic what is goodness of fit and what should be quantified by an error metric has generated voluminous discussions the literature presents debates on various approaches to error metrics and justifications for using specific approaches for example tornquist et al 1985 argue for using relative change rather than absolute change they argue that relative change metrics are unitless and thus directly comparable across locations or measurement types while others have argued for absolute change error metrics which have the same units as the data providing insights to accuracy reich et al 2016 notes a trend for using l1 norms or relative absolute error metrics e g relative mean absolute error or mean absolute scaled error as just two examples rather than l2 norms or squared error metrics e g mean squared error to reduce impacts from outliers armstrong and collopy 1992 hyndman and koehler 2006 associated research has resulted in a number of proposed metrics such as the naive2 method makridakis and hibon 2000 and others that have not been widely adopted reich et al 2016 in some fields such as weather and climate forecasting a relative mean squared metric called forecast skill has been widely used since the 1980s murphy 1988 in hydrology this metric has not been broadly adopted though the nash sutcliffe efficiency nse index nash and sutcliffe 1970 a squared error metric is gaining dominance in recent literature kling et al 2012 in section 4 2 we provide additional discussions about the nse index reported issues and metrics developed to address these issues a large volume of literature exists comparing error metrics and many of the references we provide for the specific metrics listed in section 2 are detailed comparisons of a specific metric with other metrics there are also more general discussions for example krause et al 2005 provides a detailed examination using hydrographs of a number of commonly used metrics in hydrology r2 various forms of the nash sutcliffe efficiency coefficient nash and sutcliffe 1970 and various forms of the index of agreement willmott 1981 in this paper we do not attempt to compare metrics we systematically review common metrics used in hydrology and provide an open source software library for community testing using and further developing these metrics 1 2 metric or performance measure requirements in hydrology error metrics are used to measure the goodness of fit or to quantify the difference between predicted and observed values in a time series the metric can quantify different deviations such as a difference in the time series values a difference in the shape or sequence of the time series a difference in the distribution of the values in a time series accuracy of the prediction compared to a naïve prediction or other pertinent measures hydrologists select error metrics to quantify the accuracy of a prediction or to guide model calibration or development depending on the application different measures are applicable and in many cases it is likely preferable to use multiple metrics since different metrics quantify different aspects of fit and model accuracy though the use of multiple metrics is not common in the literature one barrier to using multiple metrics is that many metrics even commonly used ones have implementation details that seem to be often ignored or not noted in the hydrology literature for example tornquist et al 1985 note that most error metrics are asymmetric and or non additive which means the error metric value depends on the order of comparison between the predicted and observed series and even more importantly that successive changes if measured individually do not give the same result as the same change measured in one step both issues complicate interpretation in asymmetric measures the order of comparison matters for example if the predicted and observed values are 2 and 4 respectively the error is 50 but if the predicted and observed values are reversed the error is 100 in either case the absolute error is 2 while the actual error is either 2 or 2 depending on the order non additive error metrics give different results depending on the number of steps in the comparison for example if we have two prediction steps starting at 2 then stepping to values of 4 and 6 the stepwise errors are 100 2 4 and 50 4 6 summing to 150 while the single step error from 2 to 6 is 300 these are not incorrect but most model accuracy discussions reported in the literature do not discuss or acknowledge these issues there is a debate on whether to use metrics that present actual error i e in the same units as the data or relative error i e as a percentage of the data tornquist et al 1985 in hydrology relative change metrics such as percentages highlight errors in low flows more than high flows for example if the absolute error is 2 units during a period with a base flow of 4 units this would be a 50 error while the same error occurring during high flows at 40 units would only be a 10 error in either case the absolute error is 2 depending on the prediction requirements this may be helpful or misleading in another example if the model objective is peak flow prediction an error metric that is dominated by low flow regimes may not result in the best calibration for a model for other applications a prediction that minimizes relative error in both low and high flow regimes e g models used to manage water use might produce the most useful model in the latter case absolute error metrics log error metrics and squared error metrics all weight errors in the high and low flow regimes differently and also weight outliers differently in the final value relative change metrics using log difference or log percent difference as the error measures are symmetric and also additive which address many of these issues optimally hydrologists would explore these various error metric options with their strengths and weaknesses and use several metrics when evaluating model predictions or performing model calibration model bias is also interesting to consider in terms of error metrics most metrics purposely eliminate bias effects by using absolute or squared error values to avoid negative and positive errors canceling each other for most objectives this is the preferred behavior as over and under predicted values can cancel out resulting in an error metric value that appears to indicate good fit when none exists however for model calibration and model characterization quantifying bias is important modeled time series data often have a systematic bias such as over prediction under prediction or a time shift most commonly used error metrics do not indicate a systematic under or over prediction as the metric is always positive for model calibration it is useful to know if the prediction has an over or under prediction bias any metric either relative or absolute that involves the square or absolute value of the error cannot identify the direction of that bias in the prediction this is an example where using multiple error metrics that assess different aspects of model fit including bias can be more effective for improving model calibration than using a single metric 1 3 definitions metric types and notation for discussion we will refer to the following where h represents the error metric function y is the predicted data and x is the observed data so y x represents the error term a metric is symmetric if 1 1 h y x h x y o r h y x h x y a metric is additive if when we consider a two stage change x y z and the corresponding single stage change x z the metric value is the same 1 2 h z x h y x h z y measures that report bias usually have negative values for an under prediction bias i e if the measure of y is less than the measure of x and positive values for over prediction i e if the measure of y is greater than the measure of x though other values can represent bias generally if a metric reports a bias it can be stated as 1 3 h y x 0 i f f y x 1 h y x 0 i f f y x 1 where f y x is the function used to sum or quantify the differences these error metric properties symmetric additive and bias reporting are not all present in most single error metrics and a metric with all these properties may not be useful alone however hydrologist should be aware of the properties of a metric and what it does and does not measure there are a number of types of error metrics used in hydrology some measure the spread in the data e g standard deviation or other data set parameters but most measure the distance between the predicted and observed time series these types of distance measurements in multi dimensional space are called norms in linear algebra essentially we treat the two time series as a set of multi dimensional vectors identifying a single location in multi dimensional space and measure the distance between those locations as a norm norms use a number of different error term representations most error metrics used in hydrology are standard linear algebra norms using different error terms these norms are often normalized by selected features of the data set to generate a relative metric that is dimensionless the general form of the norm often called the p norm with notations of or lp norm defined as 1 4 ε p i 1 n ε i p 1 p where ε i is the error measure for the ith predicted measured pair of points n is the number of points in the time series and p is the order of the norm if for example the error term is the difference between the predicted and observed values ε y i x i then we can write the ℓ 1 n o r m or l1 norm as 1 5 ε 1 i 1 n y i x i and the l2 norm is 1 6 ε 2 i 1 n y i x i 2 1 2 when p the ℓ or infinity norm is equal to the maximum value of the error term ℓ m a x y i x i when p 0 the ℓ 0 or zero norm is the number of non zero members in the vector often referred to as sparsity metrics in the forms of the ℓ 1 ℓ 2 and ℓ norms are those most commonly used in hydrology other forms are common in other fields for example the l0 norm is used in compressive sensing where the goal is to maximize sparsity minimize the zero norm and the l2 norm is used in least squares fits common in hydrology recently error metrics in the form of the l1 norm are more often recommended in hydrology and other fields as they reduce the impact of outliers in a data set on the computed value the metrics based on the l2 norm are often used because the mathematics results in a simple deterministic equation for the fit however as noted recently there are arguments that using metrics based on the l1 norm provides significant benefits though its use in computing a model fit is more complex in hydrology we are generally not using norms to develop a statistical model between the predicted and observed time series but rather just measuring correlations between two data series so these computational concerns are not important in either case with modern computers and software computational complexity is less of a concern these general norms can use different error measures and are commonly normalized by various aspects of the data set error metrics are often normalized so the norms are less dependent on the number of samples and norms from data sets of different sizes are more easily compared the most common normalization is to divide by n the number of samples as norms are a distance measure normalizing by the number of samples n is the same as converting the norm to a unit vector for example the square of the 2 norm is 1 7 ε 2 2 i 1 n y i x i 2 the normalized square of the 2 norm normalized by the number of samples n is the mean squared error mse 1 8 m s e 1 n ε 2 2 and the normalized ℓ 1 norm is the mean absolute error mae 1 9 m a e 1 n ε 1 norms are also commonly normalized by other functions such as the mean of the observed data or the spread of the observed data to generate relative measures the commonly used nash sutcliff efficiency index is of this form this can be considered a normalized index e g normalized by the difference from the mean or as a skill score where the error is compared to a naïve forecast in this case using the mean value as the naïve forecast we included this general discussion on notation and general terms to guide readers as they study the literature for example the use of norm notation is much more common outside hydrology especially in the growing fields of machine learning and big data both the script ℓ p n o r m regular lp norm and the italic p norm notations are found in the literature in the remainder of this paper we will most often write norms using the summation notation i e the right side of equations 1 4 with explicit definitions of the error terms this notation while somewhat unwieldy clearly presents the error metrics in an easily understandable form and in a way that can be directly implemented in addition most of the error metrics are standardized and normalized by various terms this is more clearly presented by a summation notation we will use y to represent the predicted values and x to represent the observed values while y x is the most used error term the norm of any other selected error terms can be computed and many of the metrics presented in this paper use other definitions 1 4 considering negative values for the purposes of this paper we are focused on error metrics that quantify the difference between predicted and observed time series data which we assume to be streamflow data this means that the data are strictly positive many of the metrics presented in this following sections are not defined for negative data and could not be used for data with negative values such as air temperature they can however be used if the data are transposed to a positive domain the error metrics we present differ in how the error is measured if the error term is transformed e g log transform how the error is standardized or weighted and how the error metric is normalized the different metrics highlight different aspects of the error between the predicted and observed time series some metrics indicate bias some minimize the impact of outliers some evaluate shape some are insensitive to linear offsets or transform and some have different ranges and responses to the magnitude of the differences 1 5 objectives the primary objective of this paper is to provide a review of error metrics reported in the hydrologic literature along with brief descriptions of each metric and implementations of these metrics our secondary objective is to introduce a new open source software library called hydroerr to encourage hydrologists to explore and use multiple metrics in their work this manuscript is an extension of an earlier paper roberts et al 2018 that presented the python hydrostats package this package includes the hydroerr library reported in this paper but also includes tools for dealing with time series data visualizations and plots the earlier paper did not provide details on the error metrics which are the heart of the python package this paper provides that detail and discussion in the electronic supplement to this article we apply a large number of these metrics to 13 different common discrepancies between predicted and observed flows using synthetic data the supplement also provides more in depth application of 7 selected metrics these presentations include graphical depictions of the errors and color coded tables that indicate the sensitivity of the metric to the various error types the objective of the hydroerr library is to provide a coded implementation of metrics used to compare time series especially for flow so that hydrologists can quickly and efficiently compute different error metrics on their data with confidence that it has been coded correctly implemented as both a python and matlab these tools will hopefully encourage researchers to use multiple metrics and to explore issues such as lag correlation or timing offsets in their data we also hope that as hydrologists develop or apply metrics that are not in hydroerr that they will extend the library for community use 2 error metrics review 2 1 relative error metrics ratios or percent tornquist et al 1985 presented an argument for using relative error metrics or rations they strongly argues for using log relative metrics we summarize his discussion here as it is informative they provide various forms of relative error metrics terms with nine specific and one general functional form in the following discussion the numbering and presentation follow tornquist et al 1985 the metric is first presented first equation to the right of the sign with the error measure presented as a difference between the predicted y and the observed x time series then the ratio or relative form presented as the terms right of the second sign this is to show how differences translate into ratios of log terms we do not present the algebra required to create the relative term in these equations the subscripts and summation notation over point pairs are omitted for simplicity in each of these metrics equation 2 1 through 2 11 the summation over the predicted measured pairs is implied this notation is also omitted because these equations 2 1 2 11 are only notional forms actual metrics would need to clearly define the error term y x and other aspects such as normalization by the number of pairs in the series or other measure any of these error representations could be used to calculate an error metric and while we do not do so many of the presented metrics could be categorized by this list relative difference 2 1 h 1 y x y x x y x 1 2 2 h 2 y x y x y 1 x y standardized forms 2 3 h 3 y x y x 1 2 x y y x 1 1 2 1 y x 2 4 h 4 y x y x x y y x 1 y x 2 5 h 5 y x y x 1 2 x 1 y 1 1 y x 1 1 x y 2 2 6 h 6 y x y x 1 2 x k y k 1 k y x 1 1 x y 1 2 1 y x k 1 k 2 7 h 7 y x y x min x y y x 1 min 1 y x 2 8 h 8 y x y x max x y y x 1 max 1 y x general form 2 9 h 9 y x y x k x y y x 1 k 1 y x log of ratios 2 10 h 10 y x l o g e y x metrics h 1 and h 2 equations 2 1 and 2 2 are standardized by the average x and average y values respectively where the metrics h 3 through h 8 equation 2 3 2 4 are standardized by various functions of both x and y which are respectively the arithmetic geometric and the harmonic means the moment mean of order k and the minimum and maximum error the h 9 metric equation 2 9 is a general form where the error measure is standardized by a function k x y that satisfies a number of mathematical properties tornquist et al 1985 then show that the log difference metric h 10 equation 2 10 can be reformatted as 2 11 l o g e y x y x l x y where l x y is the logarithmic mean thus h 10 equation 2 10 is also a specific form of h 9 metric equation 2 9 error metrics can be also be combinations of two or more other metrics this is often done to combine relevant qualities from several metrics into a single value for example h 3 4 1 3 h 3 2 3 h 4 approximates h10 for small changes tornquist et al 1985 tornquist et al 1985 recommend the h10 log ratio metric formulation as this metric is symmetric and non additive he notes that a new indicator can be obtained by multiplying any of the indicators by a positive constant h1 h10 are all normed but their positive multiples are not multiples of h10 have common scientific usage for example decibels acoustics and electronics din film sensitivity in photographs and the richter scale power in earthquakes are all just multiples of h10 difference measures in signal processing error measurements of this form are often reported in dbs decibels going back to its use in acoustics while tornquist et al 1985 argues strongly for using relative difference measures i e ratios many if not most commonly used metrics in hydrology use some form of the absolute difference between the observed and measured values y x where y x represent some function of the difference between the predicted and observed times series either relative error terms or quantitative error terms can be used to compute the various p norm measures of distance between the predicted and observed time series these error measures can be standardized by various terms for example the nash sutcliffe efficiency score is standardized by the spread of the observed data this results in a value that compares the predicted values to a value that would result if the prediction were just the average of the observed data nash and sutcliffe 1970 2 2 other measures some metrics measure the distance or difference between various statistical or other properties of the predicted and observed time series rather than the distance between the values for example we can calculate the norm of a series rather than a difference and compare these norms 2 12 d i f f e r e n c e o f m e a n s p n o r m y p n o r m x where if we use normalized p norm values divide by n then the l1 and l2 norms would give a difference in the arithmetic and geometric means of the two time series respectively other measures can be and are also used such as the variance of the differences vod 2 13 v o d σ 2 y x or the difference in the variances dov 2 14 d o v σ 2 y σ 2 x where the variance of x σ 2 x is defined as 2 15 σ 2 x 1 n i 1 n x i x where x is the mean of the time series vod gives a measure of the spread of the differences in the predicted observed pairs while the dov gives a measure of how the spread in the two data sets compares to each other both can result in small values which indicate good matches even if the two time series are offset by a large constant amount these highlight different aspects of the goodness of fit useful but not commonly reported in the hydrologic literature 2 3 lag correlation in hydrology one issue is the timing of an event between the predicted and observed data set these timing errors can be characterized using lag correlation metrics lag correlation metrics show timing or offset errors and are calculated by computing a selected error metric off setting or lagging one of the time series then recomputing the metric this approach results in a graph showing at what lag or time offset the two data sets are best matched this has several uses for example hyndman and khandakar 2008 used lag correlation measures to better understand how their dataset captured specific events even though the timing was slightly off 2 4 hydrologic error metrics tables 1 4 present common error metrics used in hydrologic science we selected references given in the tables for manuscripts where the error metric is compared and contrasted with other common metrics these tables are not an exhaustive list of error metrics though we attempted to include all commonly used metrics we did not attempt to find the first reference to a given error metric in the literature rather we referenced manuscripts that provided discussions of metric comparisons using that metric metrics are often known by different names and acronyms across and even within disciplines we have attempted to use the name more commonly used in hydrologic literature while these lists of error metrics are extensive they are not exhaustive and the literature is replete with additional metrics some metrics presented in the literature are new and unique and some existing metrics are presented in papers with new names new applications or in a different mathematical forms as discussed in sections 1 3 2 1 2 3 and by hyndman and koehler 2006 new error metrics can easily be derived by selecting an appropriate error term and means of normalization error metrics can be modified by scaling or transforming the error term e g logs or z scale transforms or using different p norms with the same error term e g absolute value square or cube error metrics can be normalized using different mean values e g geometric mean arithmetic mean etc maximum values minimum values the error of naïve forecasts or other terms the following organization of categories and the associated discussions generally follows hyndman and koehler 2006 which we recommend to those interested in error metric application and issues as we do not provide the same level of detail error metrics can be categorized into general categories though this categorization may not be unique depending on the form of the written metric or how different term are interpreted it may appear to belong to different categories even though the metric has not changed we used the following categorizes for discussion scaled error percentage error scaled forecasts and an other category hyndman and koehler 2006 these categories can provide guidelines for when to use the different types of error metrics and the information they provide about the predicted observed fit we provide some limited discussion on these general categories some specific common example metrics in each category and when metrics from the category are applicable or conversely when they are not applicable for hydrologic model analysis 3 common error metrics 3 1 scaled errorss table 1 presents scaled errors scaled errors such as mse rmse mae or mdae can be based on either an absolute or squared error term mse and rmse are commonly used metrics from this category but they are sensitive to outliers which can limit their usefulness armstrong and collopy 1992 the rmse is useful because it presents errors in the same units as the measurement and most hydrologists are familiar with the metric and its application however as stated above these metrics are insensitive to linear transforms or offsets that means that the predication can be significantly different from the observation and still have a low rmse most literature recommends using the log of the predicted and observed in the error metric to reduce the impact or weight of outliers in the data all of these metrics can use log transformed data with the exception of those which already do a log transform as with 1 above values need to be positive i e before the log transform the data need to be 1 3 2 percentage errors percentage errors scale the error term by the observed data in some form resulting in metrics that are scalable and can be compared across different data sets commonly used metrics in this category include mape mdape and rmspe though there are others that are also used in the hydrologic literature values for these metrics are undefined for observed values of 0 and results in skewed distributions when values are near zero because of the resulting large values of the metric hyndman and koehler 2006 makridakis and hibon 2000 these measures require a meaningful zero i e the absence of quantity and cannot be used for data such as temperature in this category mape and mdape weight positive errors more than negative errors this issue is addressed with symmetric measures in this category such as smape and smdape makridakis 1993 though these metrics are actually not symmetric and weight errors for low and high forecasts differently goodwin and lawton 1999 koehler 2001 authors have also recommended modifications to these approaches such as using absolute values in the denominator to avoid negative values or using logarithm transforms of the flow data such as mle male msle to make them more stable and address the fact that they are highly skewed if the data cover a large range coleman and swanson 2007 3 3 scaled forecasts these metrics compare the ratio of the forecast error to an error obtained using a naïve forecast method such as a random walk model or even just the average flow value e g nash sutcliffe efficiency nse if the observed data have little variation then the naïve forecast error can be small resulting in large error values for scaled forecast metrics essentially metrics in this category indicate if the model forecast is better than a naïve forecast for example an nse value 0 indicates that the forecast is better than just choosing the average observed value while the random walk model xi 1 xi is commonly used as the naïve forecast method in these metrics the nse metric widely used in hydrologic model analysis uses the mean observed value as the naïve forecast method this can cause difficulties comparing across scenarios or time scales for example the nse value of a forecast during a period of flat flows will indicate a fit significantly worse that a forecast during rising flows even if the mse is the same the reason is that the variance or spread of the data is larger for rising flows than for flat flows making the denominator of the nse larger scaled forecast measures are often adjusted for seasonal forecasts where the naïve prediction is only used over a season examples of metrics in this category include nse mase mdase and gmase most often gmase is recommended in the forecasting literature armstrong and collopy 1992 in hydrology nse is the most commonly reported in the hydrologic literature kling et al 2012 there are a number of studies that evaluate the strengths and weaknesses of the nse for use in hydrologic model characterization a series of papers present methods that address short comings and issues with nse and over the course of the papers present a number of improved methods legates and mccabe 1999 willmott 1981 willmott and matsuura 2005 willmott et al 2012 this series of papers ultimately present the d r refined index of agreement metric and recommend it as the best forecast metric for hydrological data willmott et al 2012 we concur with this recommendation the d r is a relatively complex metric to compute and we submit that is one reason it has not been more widely used in hydrologic model studies we refer the readers to willmott et al 2012 for a discussion of issues with nse and applications 3 4 other error metrics and measures there are numerous other disciplines that also compare data vectors whether time series or data from other processes for example spectral measurements result in data vectors and when a spectroscopist compares modeled to measured values they are most interested in the shape of the vector rather than matching magnitudes this is also true in hydrology we are often concerned with the shape of the data for example is the hydrograph narrow or broad is it symmetric etc and while magnitude is important the shape of the data is often more important measures such as the spectral angle sa spectral correlation sc spectral information divergence sid or the spectral gradient angle sga all provide indications not only on the magnitude of the error but how well the general shape of the data in the two vectors match for example the sa treats the data as a vector in n dimensional space to compare two data sets these n dimensional vectors are normalized to unit vectors again in n dimensions then the spectral angle or direction in space between the two vectors are compared sa of 0 means the two series have the same direction i e same shape though they may be of different magnitude an sa of 0 means that one vector of data is a linear multiple of the other many of these other methods compare the shape of two series rather than the magnitude and can be useful in hydrology for specific applications others such as the euclidean distance ed and normalized euclidean distance ned measure the distance in hyperspace between two vectors the ed is the 2 norm of the error and is used in many fields we have also included a number of difference metrics based on the norms of the h metrics tornquist et al 1985 4 hydroerr open source library 4 1 software introduction hydroerr is a new open source library of error metrics for hydrologic data implemented in both python and matlab the genesis of this effort was for comparing simulated and observed streamflow data but these metrics can be used to compare any two time series except for some metrics that do not accept negative values i e log metrics the library implements over 60 individual error metrics including those provided in tables 1 4 above the python implementation of hydroerr is available on the python package index repository pypi hydroerr is a module in the hydrostats package which was partially developed to provide error metric functions for the tethys platform swain et al 2015 2016 and use with a tethys application for national and global streamflow forecasting bales 2016 snow et al 2016 the tethys platform provides tools to lower the barrier of entry for water resources web app development the matlab implementation is provided as a stand alone library a goal in creating this library was to make it easy and efficient to use several different metrics to explore different information they provide about model accuracy and to make it easier for hydrologists to access the metric s that are most appropriate for the given application for example the root mean square error rmse a commonly used metric in many fields is completely insensitive to linear transforms of the data i e the magnitude of the predicted flow could be an order of magnitude larger or smaller than the observed flow and the rmse could indicate perfect correlation for some cases this is not an issue for other cases e g flood predictions this could be a significant issue 4 2 software availability hydroerr is provided in both python and matlab implementations the python library is available on pypi and is installable by pip source code and working implementations in both languages are available from the hydroerr page on github https github com byu hydroinformatics hydroerr for the python library and https github com byu hydroinformatics hydroerr toolbox for the matlab toolbox the matlab code is implemented as individual function files if placed in a single directory they can be used as a matlab library the documentation page for both repositories provides installation instructions and examples the readthedocs documentation pages have links to updated and detailed information on the included metrics https hydroerr readthedocs io en stable 4 3 software design all hydroerr functions are designed with a relatively simple application programmer interface api in each case the function for a specific metric is called with two data vectors representing the simulated and observed flows for example the mean error function could be called as me pred obs where pred and obs are vectors of predicted and observed values respectively the functions assume the data are evenly spaced i e the same time step with missing values or unknown values represented by nan or inf placeholders many of the metrics require strictly positive values for the python implementation the vectors should be 1d numpy arrays oliphant 2006 for the matlab implementation the vectors should be 1 d vectors both in the same orientation i e horizontal or vertical vectors the metrics perform some minimal pre processing which includes checks to determine if data provided are vectors of the correct type one dimensional and if the two vectors are the same length if either check fails the function returns an error message the hydroerr metric functions can check for 0 or negative values and they check for missing values by default the behavior of the matlab and python functions vary slightly the matlab functions can be called with two optional boolean variables remove neg and remove zero which default to false if these are set to true then negative and zero values are removed the python functions have four flags replace nan replace inf remove neg and remove zero the default behavior for both matlab and python i e flags not set is to remove any data with nan and inf values the data are removed from both vectors and a warning is given to users for example if the observed data has missing values indicated by nan s in the vector these nan values along with the corresponding data from the simulated vector are deleted this shortens the vectors matlab functions and default python behavior retains zero or negative values in the python implementation the replace neg and replace inf flags provide values used to replace any instances these entries while the remove neg and remove zero flags instruct the functions to remove any instances of these values if an entry is removed in one vector the corresponding entry is removed from the other vector if the value is changed to a specified value using the replace nan or replace neg flags the corresponding value in the other vector is unchanged in the matlab implementation there is no option to replace these values they are always removed all of the metrics return a single value the calculated metric value unless otherwise specified in some of the metrics i e kge fig 1 provides simple example code showing metric use with examples in both python and matlab in these examples two datasets representing predicted and observed data respectively are compared using the mean squared error metric using both the default option and the option to remove zero valued data 4 4 implementation of hydroerr in 3rd party software the python library implementation of hydroerr lends itself to embedding in 3rd party software where error metrics are needed this software can be graphical user interfaces for specific models web based data analysis tools or research software implemented in testing suites such as jupyter notebooks to test the ability of the library to be embedded in a 3rd party software application we used it as a core component of a web based global streamflow forecast system constructed in python using django and tethys platform the matlab implementation provides efficient access for these routines in interactive sessions or for matlab scripts fig 2 shows three general use cases for the hydroerr library hydroerr can be included as a library in python or matlab installation and used interactively for data exploration or script writing the api requiring just two data vectors as input supports ease of use and integration into various other routines the second case is implementation of hydoerr as a web service which could be integrated into larger web applications for example a web application might host a predictive model and gather observation results from distributed measurements hydroerr web service could be used to create accuracy measures as part of automated tasks in the third use case the hydroerr library could be used to develop stand alone models providing an extensive library of error metrics for a developer hydroerr functions can be used as reference code for implementations in other languages most machine learning approaches involve optimization of some error measure the hydroerr library provides researchers with an efficient method of exploring the effectiveness of various different metrics with these routines 4 5 example software testing results in this section we demonstrate the library using three metrics me mae and nse we selected me and mae since because they are the simplest metrics in the library measuring the average error and the absolute error respectively it is easy to understand their application and results we selected nse because it is the most commonly used metric in the hydrologic literature kling et al 2012 the nse is simple in concept compares the prediction error to the error that would result if the average of the observed flow were used as the prediction but difficult to interpret this is discussed in additional detail in section 4 we generated synthetic data to demonstrate and test the error functions these data consisted of observed flow in the form of a sine wave with user defined minimum and maximum flows to maintain positive flow values and to allow us to change the amplitude we generated predicted flows that included gaussian noise ranging from infinity with a zero mean and unit e g 1 standard deviation and variance percent noise which adds gaussian noise weighted by the flow with weights from 0 to 1 for minimum to maximum flow respectively shifted data which shifts the sine wave in time outliers which adds outlier values at locations generated using a random vector with a selected threshold standard deviation value then multiplying the value by a constant over and under predicted flows and flows with different shapes notations for these variations are n noise p percent weighted flow s shifted flow x outliers u under predicted and o over predicted the normal flow was designated y and ys indicates flows with different shapes for example normal flow with noise is designated yn a flow that has noise is shifted and under predicted would be ynsu matlab code to generate these synthetic flows is provided in the electronic supplement fig 3 presents examples of synthetic flow records that show various combinations of errors the first three records yps ypu and yspo show shifted under predicted and over predicted flows respectively with added percent weighted gaussian noise examination shows that these flow scenarios exhibit little to no noise in the lower flow regimes and higher error in the upper regimes the magnitude of the noise changes linearly with the flow magnitude the yxnsu record shows outliers at randomly selected locations these locations were selected by generating a random vector the same length as the flow period then choosing locations outside of 3 standard deviations or at about 0 3 of the sites locations greater than 3 standard deviations were set to 1 and 1 for positive and negative values respectively locations with standard deviations less than 3 were set to zero this vector was then multiplied by the outlier factor and added to the flow data to create outliers fig 3 shows that when an outlier location is in the lower flow regime the outlier is as not evident in the plot because the outlier magnitude is a multiple of the flow the yspo record shows a flow record with a different shape ys with weighted noise and an over prediction fig 4 shows how the me mae and nse metrics behave as the flow predictions range 10 under to over prediction the upper panel only shows one year of data but the metrics were computed using three years of data this is true for the remainder of this section in fig 4 the values for each metric are normalized to a range of 0 1 for comparison the actual values of the me mae and nse metrics range from approximately 5 5 to 5 5 0 to 5 5 and 0 9630 to 1 for the me mae and nse respectively for this scenario in the bottom panel of fig 4 the me trace shows the bias in the prediction error and changes linearly from 4 5 to 4 5 as the error changes from under to over prediction the mae also changes linearly but is always positive changing from 5 5 to 0 to 5 5 as the prediction error changes from 10 to 0 to 10 respectively fig 4 seems to show the nse as sensitive to these changes but the actual nse value exhibits very little change going from 0 9752 to 1 to 0 9630 in a non linear non symmetric manner as the prediction error goes from 10 to 0 to 10 respectively this is an absolute change of less than 0 025 for under prediction and less than 0 04 for over prediction nse is not sensitive to these under and over prediction errors as they are significantly better predictions than the average flow value which is the naïve prediction used by the nse for comparison the naïve prediction for nse is just a constant value i e straight line equal to the average flow for the sine wave in the y or normal flows this is the average of the minimum and maximum flows for the ys or different shape flows it is slightly below the mid point the nse appears sensitive in fig 4 because it is normalized this normalization shows one interesting aspect of the nse it is not symmetric and is more sensitive to over prediction than to under prediction the non normalized values for me and mae are identical in the over prediction region of the plot they are offset here because of normalization to different ranges approximately 5 to 5 and 0 to 5 for the me and mae respectively fig 5 shows the behavior of the three metrics i e me mae and nse for the same series of flows as fig 4 with gaussian noise added to the predicted flows the top panel of fig 5 only shows the minimum and maximum flows with gaussian noise the added noise has a zero mean and unit standard deviation and variance the bottom panel of fig 5 shows how these three metrics change as the flows range from under to over predicted the bottom panel of fig 5 presents metric values normalized by the range of the metric for the data without noise e g the values from the bottom panel of fig 4 we did this to show how noise effects the different metrics the me metric does not show any change as the average of the added noise is 0 the noise cancels out in the metric computation the mae clearly indicates that noise is present and the difference indicates the magnitude of the noise the nse is essentially insensitive to the noise with a maximum difference of 0 001 as above the error from the noise is small compared to the error of the average flow value the insert in the bottom right corner of fig 5 shows the non normalized values the insert in the bottom right corner shows the non normalized metric values where the nse plots as a straight line i e insensitive to these changes and as expected the me and mae overlay each other in the over prediction region fig 6 presents two different observed base flow scenarios with maximum flows of 100 and 20 for the high flow and low flow scenarios respectively also shown are single realizations of predicted flows which are the base flows with gaussian noise added zero mean unit standard deviation and variance the me for the high flow and low flow scenarios are 0 005 and 0 02 respectively approximately the same and close to zero the me is close to zero because the positive and negative errors cancel if a longer simulation were used the value would tend toward 0 the me does not distinguish between the low and high flow scenarios as the errors are statistically the same the mae for the high flow and low flow data are 0 80 and 0 79 respectively these values are approximately the same because like the me the mae provides an index into the error the mae values are not zero as they report on the absolute value and represent the average distance between the observed and predicted flows the nse for the high flow and low flow data are 0 9990 and 0 9265 respectively which are significantly different even though the error in both scenarios is statistically the same this is because the nse normalizes the error term by a naïve prediction which is the average of the flow data the average flow is a better prediction of the low flow scenario than for the high flow scenario this results in a poorer nse value for the high flow case 4 6 electronic supplement the electronic supplement provided with this manuscript gives more in depth information on selected metrics example uses and an in depth analysis of a large number of the metrics it also includes example matlab code to generate a number of different synthetic flow records with various types of errors the electronic supplement includes instructions on accessing and downloading both the python and matlab versions of the library and provides some short examples of calling and using the metrics we direct readers to the readthedocs documentation for up to date instructions as we anticipate hydroerr development to continue the electronic supplement includes color coded tables that show performance of a large number of the more common metrics in the library against a number of different types of expected errors including magnitude shifts o and u timing shifts s noise n and p outlier values x and different shapes ys the supplement analyzes error metrics on 13 different error combinations which were selected to represent common biases or errors between modeled and observed data we encourage readers to use the electronic supplement as a resource to understand usage of the various metrics and as a case study on the methods to evaluate metrics for different types of errors 5 recommendations 5 1 general recommendations there are a large number of error metrics because each different metrics has specific strengths and weaknesses most new metrics are presented to address deficiencies in specific applications that are not filled by existing metrics we suspect that in a most hydrologic modelling studies error metrics are chosen based on familiarity without consideration of the relative strengths and weaknesses hyndman and koehler 2006 state despite two decades of papers on measures of forecast error we believe that some fundamental problems have been overlooked in particular the measures used and the measures recommended by other authors all have problems they recommend that the absolute forecast error scaled by the in sample mean absolute error from the naïve forecasting method is more generally applicable and more easily interpreted for hydrological applications the nse nash and sutcliffe 1970 kge12 kling et al 2012 and other extensions to the nse metric legates and mccabe 1999 willmott et al 2012 are examples of this type of metric they also note that in many cases other error metrics can and should be used to augment understanding of the forecast hyndman and koehler 2006 recommend mase as it is less sensitive to outliers though they note circumstances where other measures are useful they also recommend that mae and mape be used in conjunction it is also useful to compute one of the simple metrics that indicate bias such as me to understand model performance we recommend the following general approach this is not meant to be a detailed guide but rather a guide on how to start to characterize and understand model skill and performance 1 plot observed and predicted flow values and visually analyze the general fit try to identify any trend such as better fits in various flow ranges or times if predicted flows seem smoother than observed data if the error is mostly due to apparent noise in the observed data or any other characteristics presented by the plots we recommend using a number of different plots to start to understand the nature and character of the error we recommend starting with a simple visual analysis then move on to other more specialized plots as required this could include 1 1 flow time plots with predicted and observed flows as separate lines some items to consider visually examine the general fit identify times or flow regimes with good or bad fits and note if any timing issues are present 1 2 predicted observed pair plots scatter plot do the data fall on the 1 1 line are there flow regions where there are large apparent spreads e g low flow or high flow and are patterns present 1 3 q q plots quantile quantile plots these plots help determine if the predicted and observed data come from similar statistical distribution they can also help identify if the distribution in the predicted and observed flows are comparable and how well flow in different regimes e g high or low flow regions follow similar distributions 1 4 histograms of the observed and predicted flow values use histograms to visually compare data distributions you may want to plot histograms of the log flow values also this will give you an indication of the data distribution do you have long tails is the majority of the data in certain flow regimes are the distributions skewed are there obvious outliners and other information this analysis can help select the appropriate error metrics to use 1 5 histogram of the error y x and note the distribution if the distribution is significantly skewed you may want to plot the error of the logs log y log x which can be written as log y log x this can direct error metric choice and whether to use error metrics based on log data 2 calculate a small subset of error metrics presented for the predicted and observed flows we recommend simple metrics such as me and mle to explore bias mae to evaluate overall fit mape to evaluate fit in percentage terms and some of the scaled forecast metrics such a as mase mdase gmase we also recommend nse since it is a current standard but you should also compute the d r as studies have shown it outperforms nse willmott et al 2012 and or kge12 to better understand what is causing the error gupta et al 2009 kling et al 2012 2 1 it may be useful to calculate more targeted metrics for example sa sc or sid sa is recommended can tell you if the shape of the computed hydrograph matches the shape of the observed hydrograph even if the magnitude of the predicted flows is off significantly 2 2 it often useful to compute metrics on the log of the flow values which reduces the impact of outliers and limits the influence of high flow regimes on the metric 3 compute and plot time lag values of a small set of the metrics me mae mdmase for example to determine if there is a timing error in the prediction the plots of these values will indicate the offset between the data sets as the lag with the best value of the metric for these plots you lag one of the vectors by a given amount compute the metric change the lag and continue typically ranges of 4 to 6 lags are generally sufficient however your knowledge of the magnitude of potential timing error should guide this choice in our research group we routinely use acc nrmse mae kge12 and h10 as a subset of metrics to initially explore we use me as a useful metric to check for bias i e under or over prediction many of the literature discussions recommend using log values when computing metrics there are a number of metrics that by definition use log flow values but any of the metrics in this library can be used with log flow values working with the logs reduces the influence of outliers and reduces the impact of high flow regimes on some metrics this is important as flow data often span several orders of magnitude in these cases absolute errors in the high flow regimes hide errors in the low flow regime even if the percentage error in the low flow regions are large using log flow data addresses this to a great extent by more evenly weighting errors in low and high flow regimes whether this is important depends on your application for flood predictions for example errors in the low flow regime may not be as important and a metric that emphasizes fit in the high flow regions might be more appropriate 5 2 discussion of the nash sutcliffe efficiency index kling et al 2012 note that the nse or ef nash and sutcliffe 1970 is the most commonly used error metric in hydrologic modeling the nse compares the error of the predicted flows to the error to that of a naïve forecast a scaled forecast metric the nse uses the average of the observed flows as the naïve prediction and the mae as the error term both the prediction error and the naïve error terms are squared in the ratio with i 1 n y i x i 2 and i 1 n x i x 2 for the prediction error term and naïve error term respectively an efficiency of zero which occurs at a ratio of 1 or when these two terms are equal indicates that the predicted data have the same error as using the average of the observed data as a forecast a negative efficiency means that the observed average is a better predictor i e has a smaller error term than the model prediction a number of researchers have noted issues with this metric for example the metric changes depending on the nature of the observed flow even if the error is constant consider a simple case where modeled flow can be defined as f e where f is the observed flow and e is a random error nse will give a different value depending on f if f is constant it will give a lower value worse fit than if f is not constant e g annual variation rising limb of a hydrograph this leads to overestimations of model skill for highly seasonal flows and difficulty comparing model skill across basins with flows of differing variability gupta et al 2009 this nse works best when the coefficient of variation is large and model bias produced by calibration is low mccuen et al 2006 it is possible to calculate a high efficiency value when the variance in the data is very high even when the fit of the model is relatively poor jain and sudheer 2007 the efficiency coefficient is sensitive to outliers so nse works best when data are transformed to a normal distribution before testing for similar reasons hyndman and koehler 2006 recommended mase as a useful metric for seasonal data the literature reports a number of revised or refined nse type indexes that were specifically designed to address issues associated with nse a number of which are listed in table 3 of these we recommend using d r the refined index of agreement willmott et al 2012 as a replacement for nse d r is the last reported index in a series of refinements designed to address the issues associated with nse willmott 1981 willmott and matsuura 2005 willmott et al 2012 we recommend reading willmott et al 2012 and gupta et al 2009 for in depth discussions on issues related to the use of nse for model calibration and skill measurement and on other metrics that address these issues gupta et al 2009 provides a brief literature review of a number of papers discussing the suitability of the nse along with recommended replacements and application methods such as using seasonal averages rather than the average of the entire data set for model calibration we recommend kge12 kling et al 2012 instead of nse gupta et al 2009 provides a detailed discussion on how to use kge09 and by extension kge12 for model calibration both these metrics provide multiple criteria to better understand model behavior and to optimize model calibration kge12 is a decomposition and extension of the nse into three parameters that combine to provide the index value these three parts of kge12 are r the correlation coefficient which represents correlation between predicted and observed flows β the bias ratio between predicted and observed flows and γ which is the variability ratio between the predicted and observed flows these three parts of the kge12 metric help better understand model performance models need to match temporal dynamics measured by r and also match the flow distribution or flow duration curve described by the first and second moments measured here by β and γ which are indexes into the variability and skew of the data respectively gupta et al 2009 these three components are actually ratios which show how the predicted and observed flows compare in these three areas we recommend reading gupta and kling 2011 and gupta et al 2009 for discussions of issues associated with the mse and nse and how these are addressed using kge09 we recommend gupta et al 2009 and kling et al 2012 for in depth discussions of the theory and use of kge12 for model analysis and calibration 6 summary many error metrics are used in research and industry simply because they have been commonly used or they are easily calculated however there are a large number and variety of additional error metrics reported in the hydrologic and modeling literature each developed and applied to characterize specific issues associated with comparing predicted and observed data no single metric can fully characterize the skill of a model or the fit between the predicted and observed data which issues are important and which metrics better characterize a model depends on the specific use of the model the flow regime the model is applied to and the behavior and distribution of the data however some metrics are better suited than others depending on the nature of the time series being compared in addition to a single error metric graphical analysis is an important tool for understanding model behavior for hydrology timing errors are common and need to be evaluated by calculated a lagged error metric to determine if the best fit occurs at some lag between the two flows if the hydrographs do show timing errors magnitude errors or combinations of the two different metrics perform better than others the commonly used r 2 and r correlation coefficient do not change with respect to magnitude scale change while sa is important for evaluating the shape of the two flows the sa value is relatively insensitive to timing changes or lags other commonly used metrics such as rmse change significantly with magnitude changes while it remains essentially constant with respect to timing changes more detailed discussions of these types of behaviors are presented in the electronic supplement to this article in conclusion it is difficult to understand model behavior using a single error metric we recommend using a more inclusive characterization including multiple metrics and graphical analysis for tasks such as optimized model calibration or other machine learning type uses where the objective is to maximize or minimize a selected metric we recommend that the metric be carefully chosen to represent the appropriate model behaviors the software library is intended to facilitate use of multiple metrics the library calling routines are simple only requiring vectors of observed and predicted flows since all the functions have the same minimal interface this library allows multiple metrics to be incorporated into the analysis in addition to providing tools for model comparisons we also provide this library as a community resource where as researchers develop new metrics they can add them to and extend this library providing a common repository for error metrics used in hydrology author contributions ms jackson dr nelson dr ames and dr williams methodology ms jackson and dr williams software mr nelsen mr roberts and dr williams validation ms jackson mr nelsen mr roberts and dr williams writing ms jackson dr williams and mr roberts original draft preparation ms jackson writing review and editing dr ames and dr nelson mr roberts supervision dr ames and dr nelson project administration dr ames and dr nelson funding acquisition dr ames and dr nelson funding this research was funded by servir nasa applied sciences program grant number nnx16an45g conflicts of interest the authors declare no conflict of interest appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 05 001 
26164,extreme coastal flooding poses a major threat to human life and infrastructure low gradient coastal watersheds can be vulnerable to flooding from both intense rainfall and storm surge here we present a comprehensive review of the most recent studies that quantify extreme flooding using variations of a compound inundation model a compound inundation model may consist of different numerical models observed data and or a combination of these the definitions advantages and limitations of each joining technique are discussed with the goal of enabling and focusing subsequent research future investigation should focus on the development of a tight coupling procedure that can accurately represent the complex physical interactions between storm surge and rainfall runoff a more accurate compound flood forecast tool can help decision makers stakeholders and authorities converge on better coastal resiliency measures that can potentially save human lives aid in the design of structures and communities and decrease property damage keywords storm surge rainfall runoff compound flood flood transition zone tropical cyclone inundation model 1 introduction coastal regions are vital for the advancement of society by supporting capital flows for tourism industrialization transportation and urban development current projections for the united states us population that resides in low gradient coastal zones indicates an increase of 145 by 2030 with respect to 2000 neumann et al 2015 in addition the us has 17 port cities with a population greater than 1 million wahl et al 2015 extreme coastal flooding is one of the hazardous elements that pose a major threat to human life and infrastructure bates et al 2005 bhaskaran et al 2014 moussa and bocquillon 2009 padgett et al 2008 low gradient coastal watersheds are vulnerable to flooding hazards from both intense rainfall and coastal storm surge penetration which are produced from extreme meteorological events e g tropical cyclones low pressure systems bilskie and hagen 2018 comer et al 2017 mcinnes et al 2002 moftakhari et al 2017 ray et al 2011 silva araya et al 2018 hurricanes were responsible for 40 of the global total deaths for all weather related disasters from 1995 to 2015 unisdr and cred 2015 also three of the five costliest hurricanes that have impacted the us mainland and its territories occurred in the 2017 hurricane season noaa 2018 hurricanes harvey irma and maria affected the texas and louisiana coasts the florida peninsula and puerto rico and the u s virgin islands respectively in less than a month these three hurricanes produced a total damage of 265 000 million 2017 usd and were directly responsible for the loss of 183 human lives blake and zelinsky 2018 cangialosi et al 2018 noaa 2018 pasch et al 2018 ward et al 2018 zscheischler et al 2018 these natural hazards can be devastating with wide ranging social comer et al 2017 karamouz et al 2017a olbert et al 2017 economic chen and liu 2014 karamouz et al 2015 lian et al 2013 wang et al 2015 and environmental costabile et al 2013 park et al 2011 stamey et al 2007 consequences in low gradient coastal watersheds around the world floods can emerge from several mechanisms or driving forces bacopoulos et al 2017 serafin et al 2019 here we limit focus on the flooding mechanisms produced by a tropical cyclone and extreme precipitation events in which subsurface flow and storm water systems are typically negligible these flooding mechanisms can occur due to a single meteorological event e g tropical cyclone that includes extreme precipitation or by a combination of separate events that occur in close succession or simultaneously such as when an intense and prolongated precipitation event occurs before any extreme wind event e g tropical cyclone prevalent strong onshore winds low pressure system fig 1 illustrates the flooding mechanisms typically considered during a cyclonic event in a coastal watershed these mechanisms can produce flooding via i precipitation rainfall intense or prolonged precipitation can induce surface runoff runoff moves from overland areas to a stream increasing the streamflow rate to a point that exceeds the channel capacity and producing an out of bank flow i e overbank flow that inundates the floodplain fig 2 ii storm surge storm surge is produced by high winds and low atmospheric pressure that drives oceanic waters to interact with the local coastal geometry the total water level is temporarily raised and can penetrate inland to inundate the floodplain iii compound flood a combination of both mechanisms i e rainfall runoff and storm surge that can occur simultaneously or in close succession commonly referred as compound flooding bilskie and hagen 2018 ikeuchi et al 2017 kumbier et al 2018a paprotny et al 2018 saleh et al 2017 wahl et al 2015 ward et al 2018 zscheischler et al 2018 also a compound flood can be produced by other flooding mechanisms that are not considered here such as waves and tides blanton et al 2018 buschman et al 2009 comer et al 2017 olbert et al 2017 orton et al 2018 for example when both mechanisms i e rainfall runoff and storm surge occur simultaneously there is an increase in the flood hazard due to the combined effects of high river flow rates and elevated sea levels at the river outlet e g estuarine or tidal river erikson et al 2018 hubbert and mcinnes 1999 ikeuchi et al 2017 maskell et al 2014 svensson and jones 2004 tromble et al 2010 wahl et al 2015 therefore storm surge and rainfall runoff in coastal watersheds are not necessarily mutually exclusive hazards christian et al 2015 karamouz et al 2017b torres et al 2015 since the early 2000s studies have investigated the probability of storm surge and rainfall runoff occurring simultaneously or in close succession these studies highlight that these flooding mechanisms are present over different length scales such as local scale kew et al 2013 klerk et al 2015 svensson and jones 2004 thompson and frazier 2014 zheng et al 2014 continental scale moftakhari et al 2017 paprotny et al 2018 wahl et al 2015 zheng et al 2013 and global scale ward et al 2018 they depend on watershed properties such as location and size for example hurricane florence 2018 produced a catastrophic flood in north carolina us which was induced by intense and prolonged precipitation and high levels of storm surge that blocked the streamflow towards the estuaries almasy et al 2018 elliott 2018 therefore it is critical to quantify the dependence between the flooding mechanisms bilskie and hagen 2018 zheng et al 2014 as the effects of carbon emissions shape the earth s climate it is possible that extreme weather events and their compound effects will become more severe and frequent through increased sea levels bhaskaran et al 2014 bilskie et al 2019 ge et al 2014 karamouz et al 2017a passeri et al 2015b smith et al 2012 sweet and park 2014 river discharges paprotny et al 2018 zscheischler et al 2018 and extreme precipitation chen et al 2013 feng and brubaker 2016 karamouz et al 2015 wang et al 2013 observations indicate that hurricanes are expected to become stronger and more frequent with the number of major storms e g categories iv and v based on the saffir simpson scale increasing over the past 35 years along with ocean temperature anthes et al 2006 bender et al 2010 elsner 2008 emanuel 2005 1987 holland and bruyère 2014 lal 2001 lynn et al 2009 tang et al 2013 van aalst 2006 in addition projections of future climate indicate potential shifts in rainfall patterns toward stronger and more intense storms feng and brubaker 2016 karamouz et al 2015 risser and wehner 2017 trenberth et al 2018 wang et al 2013 understanding the hazard posed by the combination of extreme events under present and future sea levels is crucial for the successful management of coastal communities by means of effective coastal resilient measures these measures may include a comprehensive understanding and the capability of modeling effectively both mechanisms i e storm surge and rainfall runoff that produce these extreme flooding bacopoulos et al 2017 bhaskaran et al 2014 bilskie and hagen 2018 dresback et al 2013 passeri et al 2015b flood inundation maps useful for planning and management of riverine and coastal floodplains are another important consideration regarding compound flooding these maps are used to delineate no build zones flood insurance rates identify evacuation routes for communities issue early warning advisories and as aid in the development of safe and cost effective design criteria for hydraulic structures e g bridges culverts levees seawalls flood gates etc christian et al 2015 moftakhari et al 2017 silva araya et al 2018 torres et al 2015 common flood hazard assessment practices typically account for one mechanism at a time e g rainfall runoff or storm surge and not their combination whereas coastal cities are exposed to multiple flooding mechanisms bilskie and hagen 2018 erikson et al 2018 klerk et al 2015 moftakhari et al 2017 orton et al 2015 serafin et al 2019 torres et al 2015 ward et al 2018 zscheischler et al 2018 for example the standard assumption with the federal emergency management agency fema flood zone mapping with flood hazard assessment studies and with operational systems is that rainfall runoff flooding can be neglected when modeling a storm surge event since the impact of the cyclone is relatively short in comparison to the time it takes for any rainfall runoff flooding to reach the coast blanton et al 2018 orton et al 2018 ray et al 2011 silva araya et al 2018 tang et al 2013 torres et al 2015 this assumption has been shown to not always be correct since the time of arrival of both flooding mechanisms i e storm surge and rainfall runoff depends on several factors such as watershed properties antecedent conditions and storm characteristics kumbier et al 2018b orton et al 2018 2015 santiago collazo et al 2017 silva araya et al 2018 there is an urgent need to simulate the potential compound effects of rainfall runoff and storm surge flooding a direct capability to define flood transition zones bilskie and hagen 2018 can lead to transdisciplinary research outcomes that will prove beneficial to society numerical models provide information about complex physical processes e g compound flooding and have shown to aid in disaster and evacuation planning which is a critical tool for decision makers blanton et al 2018 chen and liu 2014 georgas et al 2016 kew et al 2013 olbert et al 2017 serafin et al 2019 one of the flooding mechanisms that is often neglected in coastal inundation modeling i e storm surge modeling is rainfall runoff when it is considered some physical processes are missing or simplified such as momentum exchange of fluxes which is important in delineating the spatial extent of the inundation maskell et al 2014 orton et al 2018 recently compound inundation models have been focused on quantifying streamflow and storm surge interaction while neglecting the out of bank flow surface runoff and storm surge interaction in addition the direct effect of the precipitation over a study area i e model domain has also been neglected the majority of these models have been implemented with loosely coupled or linked techniques which simplifies the interaction between both inundation models and may be misrepresenting the actual physical processes in fact bilskie and hagen 2018 demonstrate how the superposition of runoff with surge can overestimate total water levels modeling approaches that integrate multiple flooding mechanisms e g storm surge surface runoff and streamflow and simulate their compound influences would be more effective in supporting a wide range of decision making orton et al 2018 saleh et al 2017 the current techniques for joining two or more numerical models can be summarized into four classifications linking technique loose coupling tight coupling and full coupling table 1 these classifications vary on the technique employed to transfer or exchange information between each numerical model which represents the individual physical processes flowcharts for each joining technique is shown in fig 3 a linking technique is defined as a method that transfers the results from one model i e courier model to be used as an input for a second model i e recipient model as shown in fig 3i silva araya et al 2018 sulis et al 2010 this technique is also known as one way coupling since the transfer of information only occurs in one direction cheng et al 2010 hühne et al 2016 usually the courier model is run first and independently from the recipient model then the results are transferred by means of boundary conditions to the recipient model which is run with all the required input information and boundary conditions finally the results from the recipient model are analyzed and if further changes are necessary to the courier model the process will repeat again an example of an application of this technique is the resulting wind field from an atmospheric model that is transferred as an input to an ocean circulation model alternatively a loosely coupled technique is defined as a method that couples models which are run separately using information exchange in an iterative manner fig 3ii blanton et al 2018 goodall et al 2011 hühne et al 2016 sulis et al 2010 this technique is also known as two way coupling since the transfer of information occurs in two directions cheng et al 2010 hühne et al 2016 the process of a loosely coupled technique between two models e g model a and model b can be described by the following i the results from model a are transferred to model b via boundary conditions ii model b uses this information to compute new results and transfer the new information to model a iii model a uses the information received to compute updated new results and transfers it to model b iv the process is repeated until it reaches the end of the simulation period on the other hand a tightly coupled technique is defined as a method that joins the independent models into a single modeling framework by combining their source code as shown in fig 3iii blanton et al 2018 goodall et al 2011 in other words portions of the source code that describes the physical processes of model a are incorporated into the source code of model b or vice versa this means that the information exchange between both portions of the code is performed internally within the same source code i e computer memory and does not involve the exchange of external input and output files one example of this technique is the swan adcirc simulating waves nearshore model advanced circulation model modeling framework in this example swan transfers wave radiation stresses to adcirc and adcirc transfers back to swan the updated wind velocities water levels and currents dietrich et al 2012 2011b lastly a fully coupled technique is defined as a technique in which the governing equations of all the physical processes considered e g storm surge and rainfall runoff are solved simultaneously within the same modeling framework as shown in fig 3iv hühne et al 2016 sulis et al 2010 for example wash123d watershed systems of 1 d stream river network 2 d overland regime and 3 d subsurface media model shih et al 2012 shih and yeh 2011 yeh et al 2011 2005 1998 in which many physical processes e g streamflow surface runoff flow subsurface flow are represented using a common set of governing equations such as the navier stokes equations for describing motion of a viscous fluid unfortunately wash123d does not model storm surge conditions the remainder of this paper consists of a review of the widely used inundation models to simulate rainfall runoff and storm surge in low gradient coastal landscapes three categories of inundation models are discussed rainfall runoff driven storm surge driven and compound inundation models the most recent and relevant studies using these models are described including their advantages and limitations furthermore the four classifications of compound inundation models depending on the coupling approach will be explained in additional detail finally conclusions are drawn and future research is discussed 2 inundation models in the context of this paper we focus on inundation models that are typically developed to quantify and delineate the flood zone due to a certain atmospheric event e g tropical cyclone low pressure system prolonged and intense precipitation event such models can be categorized by the mechanism that drives the flooding we do not consider inundation models that account for subsurface flow i e groundwater flow and or storm water drainage systems or flooding from tsunamis due to the challenging numerical representation of the physical processes of a compound flood event both types of models i e rainfall runoff driven and storm surge driven have been developed and used independently with the advancement of computer technology and numerical modeling both models have been recently one way loosely coupled to produce a better estimate of total water levels the remainder of the section will discuss the inundation models driven by rainfall runoff and storm surge as well as the compound inundation model 2 1 rainfall runoff driven inundation models a rainfall runoff driven inundation model commonly known as a hydrologic model can be defined as the characterization of real hydrologic features and systems such as rainfall runoff evapotranspiration interception infiltration etc in general two types of hydrologic models have been developed and applied in recent years conceptual based lumped parameter hydrologic models and physically based distributed parameter hydrologic models these models differ in the mathematical representation of the hydrologic processes spatial representation of the watershed properties and data requirements el hassan et al 2013 the conceptual based lumped parameter hydrologic model assumes the watershed properties e g soil type land use cover initial soil moisture surface roughness etc are uniform over the entire domain and may be used to simulate total watershed runoff using basin average input data and empirical parameters andréassian et al 2004 el hassan et al 2013 fatichi et al 2016 kalyanapu et al 2009 sharif et al 2013 torres et al 2015 such models produce reasonable estimates of runoff but due to the distributed nature of hydrological properties the models cannot accurately represent the spatial variation of the watershed conditions el hassan et al 2013 however a common workaround is to divide basins into hydrologically similar sub basins to take advantage of the spatial resolution of rainfall and watershed properties sharif et al 2013 alternatively physically based distributed parameter hydrologic models are capable of having a spatial distribution of precipitation and watershed properties through a computational grid thus hydrologic processes e g conservation of mass momentum and energy for overland runoff are mathematically represented in each grid cell el hassan et al 2013 torres et al 2015 some advantages of these models include the capability to produce simulation data at any point within the model domain initialization with minimal historical data and greater flexibility in the calibration process for the watershed properties hunter et al 2003 sharif et al 2013 2010a torres et al 2015 contrarily this type of hydrologic model may require more time to develop and greater computer power than the conceptual based lumped parameter hydrologic models usually all types of hydrologic models are comprised of two primary components rainfall runoff estimation and a routing scheme to transport the rainfall runoff the routing scheme used in a hydrologic model can be a limitation for flood modeling since the real physical characteristics of the rivers are not considered nguyen et al 2016 therefore hydraulic models have been used to simulate floods together with hydrologic models in which the rainfall runoff estimated from the hydrologic model is used as an input in the hydraulic model some of the most popular hydraulic models used are the hydrologic engineering center river analysis system hec ras model brunner 2001 the mike hydro river i e mike 11 model danish hydraulic institute 1997 the lisflood fp model bates and de roo 2000 the flo 2d model o brien et al 1993 and the msn flood model falconer 1984 the hec ras model developed by the u s army corp of engineers usace computes the water depth in a river cross section given a flow rate this model is widely used due to its freely available software anees et al 2016 ray et al 2011 also the lisflood fp model was designed by the university of bristol to simulate floodplain inundation over complex topography bates et al 2005 bates and de roo 2000 lewis et al 2013 smith et al 2012 one of the main advantages of hydraulic models is that the modeling is based on the topography of the channel and floodplain which is in accordance with the continuity and momentum principles and minimal parameters nguyen et al 2016 the selection of an appropriate hydrologic modeling methodology is a key step of any flood modeling system sharif et al 2010b this research only focuses on the to date application of hydrologic models at the coast and are not necessarily including all rainfall runoff driven inundation model advancements e g curtu et al 2014 demir and krajewski 2013 elsaadani and krajewski 2017 quintero et al 2016 the usace has developed two of the most popular conceptual based lumped parameter hydrologic models hydrologic engineering center 1 hec 1 model and the hydrologic engineering center hydrologic modeling system hec hms model the hec 1 model hydrologic engineering center 1998 was developed in the 1990s and was replaced by the hec hms model scharffenberg 2016 in the early 2000s hec hms was originally designed to simulate the rainfall runoff processes of drainage basins in a wide range of geographic areas and has been extensively used in the us el hassan et al 2013 the u s environmental protection agency epa has developed a conceptual based lumped parameter hydrologic model named storm water management model swmm it is used throughout the world for planning analysis and design related to storm water runoff combined and sanitary sewers and other drainage systems in urban areas rossman 2015 for long term modeling the agricultural research service from the u s department of agriculture usda developed the soil and water assessment tool swat model to predict the impact of land management practices on water sediment and agricultural chemicals in large complex watersheds on a daily basis neitsch et al 2002 in addition this model has been used for quantifying rainfall runoff flooding events when linked to other hydraulic models such as hec ras duvvuri and narasimhan 2013 international river interface cooperative iric model jamrussri and toda 2017 and lisflood fp rajib et al 2016 and also for determining river discharges if used independently singh et al 2005 wu and xu 2006 within the category of physically based distributed parameter hydrologic models two of the most prominent models are the gridded surface subsurface hydrologic analysis gssha model downer et al 2002 and the vflo hydrologic model vieux and vieux 2002 gssha was developed by the usace as an enhancement to the hydrologic model casc2d downer et al 2003 gssha has been implemented on a wide variety of watersheds around the us to determine rainfall runoff inundation for forecasting and evaluating extreme precipitation events chintalapudi et al 2012 el hassan et al 2013 hunter et al 2003 sharif et al 2013 2010b 2010a 2006 yang et al 2016 in a similar manner the vflo model has been applied under various watershed characteristics and conditions to estimate the real time urban rainfall runoff evaluate flood control systems and forecast flash floods fang et al 2010 kim et al 2008 looper et al 2012 looper and vieux 2012 teague et al 2013 vieux et al 2005 other models such as the mike she mike 2017 and the hydrology laboratory research distributed hydrologic model hl rdhm colorado basin river forecast center 2008 have been also used for quantifying the rainfall runoff inundation on different watersheds fares et al 2014 geoghegan et al 2018 kitzmiller et al 2011 nguyen et al 2016 sahoo et al 2006 wang et al 2012 xevi et al 1997 zhang et al 2008b 2 2 storm surge driven inundation models coastal inundation is one of the most hazardous events that can occur on a low lying coastal watershed and can result from a wide variety of environmental impacts bhaskaran et al 2014 storm surge is a temporary rise of the total water level at the coast generated by extreme wind and low atmospheric pressure krestenitis et al 2011 lewis et al 2013 mcinnes et al 2002 to assess coastal flood hazards an ocean circulation model is an essential component to predict water levels and inundation extent bates et al 2005 bhaskaran et al 2014 lewis et al 2013 an ocean circulation model simulates the surges in water level due to wind driven and pressure induced events i e storm surge events and by astronomic tides in addition a wave induced surge can be simulated by including the effects of wind waves on storm surge by coupling between an ocean circulation model and a wave model wave models that have been coupled include the simulating waves nearshore swan model booij et al 1999 the steady state spectral wave stwave model resio 1987 and the wavewatch iii ww3 model sheng et al 2010 tolman 2009 some of the most popular ocean circulation models are sea lake and overland surges from hurricanes slosh jelesnianski et al 1992 the advanced circulation adcirc luettich et al 1992 the princeton ocean model pom blumberg and mellor 1987 delft3d deltares 2009 and the finite volume coastal ocean model fvcom chen et al 2003 adcirc is a robust model that has been successfully validated with numerous historical hurricanes over varying coastal regions such as the us atlantic coast bacopoulos et al 2012 colle et al 2008 garzon and ferreira 2016 hagen et al 2012 yin et al 2016 the north indian ocean bhaskaran et al 2014 gayathri et al 2016 and the gulf of mexico bilskie et al 2016b bunya et al 2010 dietrich et al 2011a hagen et al 2012 hope et al 2013 with a high accuracy adcirc has been used to produce real time storm surge and wave forecast for the northern gulf of mexico dietrich et al 2013 the us atlantic coast blanton et al 2012 dresback et al 2013 garzon et al 2018 and the north western pacific ocean suh et al 2015 adcirc has also been used to simulate numerous synthetic storms based on historical tracks and storm intensity to explore the effects of these storms making landfall in another location and or with greater storm intensity kennedy et al 2012 rao et al 2013 sebastian et al 2014 others have implemented adcirc for simulating coastal inundation for the past present and future conditions of the coastal landscape with or without projected sea level rise bilskie et al 2019 2016a 2014 passeri et al 2015a siverd et al 2018 similar to the adcirc model the fvcom model has been implemented on the wide variety of hurricane conditions either in forecast or analysis mode for several coastlines within the us mainland and the korea peninsula rego and li 2009a 2009b rego and li 2010 weisberg and zheng 2006 2008 yang et al 2014 yoon and shim 2013 2016 similarly the pom peng et al 2006 2004 xia et al 2008 xie et al 2008 2004 slosh mercado 1994 murdukhayeva et al 2013 zhang et al 2008a and delft3d brown et al 2007 cranston and tavendale 2012 models have been implemented under complex environments for historical hurricanes 2 3 compound inundation models simulation of storm surge propagation in rivers and estuaries including the backwater effects of river flow is important for coastal inundation modeling in low gradient coastal watersheds lewis et al 2013 a compound inundation model consists of one or more numerical models that are combined with the aim of obtaining an accurate total water level the numerical models that comprise a compound inundation model may be a combination of hydrologic ocean circulation or hydraulic models commonly these numerical models have been combined with each other using a one way loose or a tight coupling approach the definition of each joining technique has been defined previously in section 1 and are summarized in table 1 implementation of full and tight coupling for these types of numerical models e g hydrologic ocean circulation and hydraulic model is more complicated than loose or one way coupling this difficulty is attributed to the complex mathematical representation of their physical processes the computational power required and the temporal and spatial resolution varying time and length scales of the numerical models for example the fully coupled wash123d model has been used successfully in idealistic cases but has not been able to simulate real world scenarios accurately however due to the continuous advances in computer technology tight coupling these numerical models is more feasible today than in the past several efforts to couple both storm surge and rainfall runoff have been developed in the last decade the joining technique used for combining different models depends greatly on the physical processes to be simulated for example when coupling an ocean circulation model with a wave model funakoshi et al 2008 found that numerical problems increased when the tight coupling technique was used and that a loose coupling technique may be sufficient to capture this interaction also the physical interactions between the flooding mechanisms e g atmospheric hydrological and coastal oceanic are typically handled via loose coupling blanton et al 2018 conversely the tight coupling technique is necessary to accurately account for watershed nearshore interactions during storm events cheng et al 2010 from the available literature only one study used a loosely coupled technique to produce the compound inundation model cheng et al 2010 which is described in section 2 3 4 also only one study used a tightly coupled technique to produce the compound inundation model tang et al 2013 which is described in section 2 3 5 the remaining publications found used a linking technique and are summarized in table 2 through table 4 which lists the year it was published the location of the study area the numerical models used and the joining technique these linked models are characterized based on the type of base model i e recipient model used when joining both the hydrologic and ocean circulation model therefore they are categorized as i linked hydrological model ii linked ocean circulation model or iii linked hydraulic model unfortunately studies that used a fully coupled technique to produce a compound inundation model were not found in the available literature the remainder of this section will focus on discussing published studies that employed a one way loosely and tightly coupled technique 2 3 1 linked hydrologic model thirteen percent of the publications found used a linked hydrologic model for the compound model see table 2 this linking technique is based on independently running the ocean circulation model first which requires wind speed and atmospheric pressure data as input the results from the ocean circulation model e g total seawater level are used as an input for the hydrologic model in addition to the precipitation data by means of boundary conditions the results from the linked hydrologic model can be considered as compound water level inundation this procedure is summarized in fig 4 for example silva araya et al 2018 first employed an ocean circulation model i e adcirc to produce time series of total seawater level and used it as an input to a hydrologic model i e gssha by means of time varying boundary condition points at the downstream end of the watershed the studies within this category applied the models in coastal watersheds in the us mainland and its territories the vast majority of these studies used the gssha hydrologic model while adcirc was the most common ocean circulation model also the majority of these studies used observed data from a tide gauge to force the hydrologic model instead of results from an ocean circulation model some studies considered future climate change conditions including varying sea level rise slr precipitation and storm characteristics while others considered flooding scenarios from different return periods in a compound model that uses a linked hydrologic model information is transferred at the boundary condition points located at the downstream end of the hydrologic model the location of the boundary points limits the influence of the storm surge which is typically greater at the river outlet i e bay or estuary margin these methods neglect any interaction between the rainfall runoff and the storm surge in the coastal floodplain or in the flood transition zone bilskie and hagen 2018 for example the interaction between the surface runoff storm surge and the out of bank flow storm surge is not considered see fig 1 this can result in underestimating the total water level on the other hand the low computational power needed for this technique makes it suitable for simulating multiple flooding scenarios within a short period this technique requires less effort since only the hydrologic model has to be developed if observed data for storm surge is used instead of an ocean circulation model also accurate flooding maps can be produced using this technique since karamouz et al 2017b reproduce the flooding map from hurricane sandy 2012 at lower manhattan new york city ny with a 3 overestimate of the floodplain area nevertheless the conclusion from these studies supports the need for developing a more holistic model that can account for potential interactions between storm surge and rainfall runoff 2 3 2 linked ocean circulation model forty five percent of the publications found used a linked ocean circulation model for the compound model see table 3 this linking technique is based on independently running the hydrologic model first which requires precipitation data as input the freshwater discharge results from the hydrologic model are used as an input for the ocean circulation model in addition to the wind speed and atmospheric pressure data by means of boundary conditions the results from the linked ocean circulation model can be considered as a compound water level inundation this procedure is summarized in fig 5 for example dresback et al 2013 first employed a hydrologic model i e hl rdhm to produce freshwater discharge hydrographs and used them as input to their ocean circulation model i e adcirc by means of time varying boundary condition points the boundary condition points were located at four areas in the watershed well upstream the coast where any tidal or storm surge effects would be experienced the studies within this category applied this method to coastal watersheds in the us mainland taiwan australia germany england and the korean peninsula the vast majority of these studies used the adcirc model while hl rdhm was the most used hydrologic model in addition the majority used observed streamflow data from a river gauge to force the ocean circulation model instead of using a hydrologic model some of these studies linked both numerical models through the use of time variant boundary conditions of riverine discharge i e freshwater flow while others used river stage level to set boundary conditions and some used time invariant riverine flow drive radiation boundary conditions only one study used rating curves i e discharge versus water level plot in a compound model that uses a linked ocean circulation model the boundary condition that transfers information from the hydrologic model is specified at the upstream end of the ocean circulation model usually the location of these boundary condition points is upstream in the river system where the influence of the estuary conditions i e storm surge tide seawater level can be neglected a limitation of this approach is that the out of bank flow which exits from the stream to the floodplain see figs 1 and 2 is not considered in the total compound inundation model since when the freshwater discharge is transferred to the ocean circulation model as a boundary condition point it only transfers data from a single point and the recorded or simulated discharge data may not include the out of bank flow chen and liu 2014 2016 reported a mean absolute error ten times higher and a root mean square rms error nine times higher in the river than on the coast this can be attributed to the lack of the out of bank flow processes within the linked model also the precipitation that falls directly into the ocean circulation model domain is neglected these precipitation amounts may be negligible but it can be significant for slow moving storms that dump an excessive amount of precipitation over a long period of time such as hurricane harvey 2017 and hurricane florence 2018 therefore the surface runoff produced by this precipitation i e rainfall runoff and the direct volume contribution over the seawater domain is not accounted for the total compound inundation despite these limitations most studies demonstrated the importance of including the hydrology component in numerical simulation of compound inundation in low lying coastal watershed during extreme atmospheric events bacopoulos et al 2017 bilskie and hagen 2018 chen and liu 2016 2014 herdman et al 2018 kumbier et al 2018b maskell et al 2014 orton et al 2012 2018 2015 similar to the linked hydrologic model the low computational power needed for this technique makes it suitable for simulating multiple flooding scenarios within a short period of time this can be useful as a first approximation of the flood levels when forecasting the impact of a tropical cyclone to a low gradient coastal watershed some researchers had simulated water levels with rms errors within 10 5 cm 34 cm using this technique which may be considered accurate when modeling surge events on the order of tens of meters bacopoulos et al 2017 georgas et al 2016 kumbier et al 2018a orton et al 2018 also this technique requires less effort since only the ocean circulation model has to be developed if observed data for riverine flow is used instead of a hydrologic model 2 3 3 linked hydraulic model thirty eight percent of the publications found used a linked hydraulic model for the compound model see table 4 this linking technique is based on independently running the hydrologic model and the ocean circulation model first with their required data inputs e g precipitation wind speed and atmospheric pressure the results from the hydrologic model e g freshwater discharge and the ocean circulation model e g total seawater level are both used as inputs for the hydraulic model by means of boundary conditions the results from the linked hydraulic model can be considered as compound water level inundation this procedure is summarized in fig 6 for example torres et al 2015 first employed a hydrologic model i e vflo and ocean circulation model i e adcirc to produce freshwater discharge hydrographs and total seawater levels to be used as inputs to a hydraulic model i e hec ras by means of time variant boundary condition points at upstream and downstream portions of the watershed respectively the studies within this category applied this method to coastal watersheds in the us mainland china united kingdom ireland bangladesh and taiwan the vast majority used the hec ras hydraulic model in addition the majority of these studies used in a combination or separately observed data from a river gauge and or a tide gauge to force the hydraulic model instead of using a hydrologic model or an ocean circulation model respectively all of these studies employed a linking technique with the use of time variant boundary conditions points of freshwater discharge time variant boundary conditions points of seawater level elevation or a combination of both in a compound model that uses a linked hydraulic model the boundary condition that transfers information from each model e g hydrologic and ocean circulation model are specified at two different locations within the hydraulic model the hydrologic model passes information at the upstream end of the hydraulic model while the ocean circulation model passes information at the downstream end of the hydraulic model one of the limitations of this approach is the additional effort of developing a third model i e hydraulic model to estimate the compound inundation the development of a model may require the collection and processing of data as well as the calibration and validation of the model also most of the ocean circulation models e g fvcom adcirc have the capability of computing the flow hydrodynamics as the hydraulic model and therefore at some instance it may substitute the hydraulic model from their compound model configuration similar to the approach of using an ocean circulation model to link both models the direct effects of the precipitation over the model domain is neglected since the hydraulic model does not have the capacity to transform rainfall into surface runoff the total compound inundation may be underestimated however for most of these studies the implementation of a hydraulic model i e 1d models with boundary conditions derived from hydrologic and ocean circulation models i e 2d 3d models can be a viable approach to reduce numerical modeling gaps that exist for coastal rivers christian et al 2015 ikeuchi et al 2017 mashriqui et al 2010 2014 ray et al 2011 skinner et al 2015 torres et al 2015 this technique requires less effort since only the hydraulic model has to be developed if observed data for storm surge and riverine flow are used instead of an ocean circulation model and a hydrologic model respectively also this technique may be useful to estimate the flood levels in the transition zone bilskie and hagen 2018 since this technique extends well enough upstream to isolate the effects of the storm surge in the riverine flow at the upstream boundary and extends well enough downstream to isolate the effects of the riverine flow in the storm surge this linking technique can estimate accurate water levels since some researchers had simulated water levels with rms errors within 15 cm 27 cm comer et al 2017 feng and brubaker 2016 mashriqui et al 2014 olbert et al 2017 wang et al 2014 2 3 4 loosely coupled models as mentioned before only one publication that used a loosely coupled technique for developing a compound model was found cheng et al 2010 when both numerical models are loosely coupled the zone where both flooding mechanisms i e storm surge and rainfall runoff interact must be specified using boundary condition points this technique will require transferring the results from one model to another at a certain time interval specified by the user a third party software typically carries out the exchange of information this tight coupling technique is based on running the hydrologic model and the ocean circulation model with their required data inputs e g precipitation wind speed and atmospheric pressure simultaneously the results from each model e g freshwater discharge and total seawater levels are used as inputs to the other model e g freshwater discharge used as an input to the ocean circulation model by means of boundary conditions and the models are run again with their new inputs the results from the loosely coupled hydrologic ocean circulation model can be considered as compound water level inundation this procedure is summarized in fig 7 for example cheng et al 2010 loosely coupled an ocean circulation model i e adcirc with a hydrologic model i e pwash123d using this boundary condition points they simulated hurricane katrina 2005 impact over the mississippi us coast using synthetic rainfall instead of the actual hurricane rainfall a limitation of this approach is that the interaction between the two models occurs at the coastline only where it could naturally occur upstream in the river outlet or in the coastal floodplain nonetheless this technique is capable of improving the interaction between both flooding mechanisms i e rainfall runoff and storm surge since their results supported the use of a loose coupling technique over the linking technique for watershed nearshore interaction for example the comparison of results between different coupling techniques e g one way vs two way shows a difference in river stage and in overland water depth of 60 cm and 1 0 m during the storm peak respectively therefore the linking technique may be insufficient for intense storms since the greatest watershed nearshore interaction is during the storm peak 2 3 5 tightly coupled models only one publication that used a tightly coupled technique for developing a compound model was found tang et al 2013 tight coupling two numerical models at code level require that the mathematical representation of one of the physical processes e g storm surge or rainfall runoff be included in the numerical code of the other model this approach is more complicated than the boundary condition method since it involves programming and modifying the numerical model algorithm tang et al 2013 used this approach to couple a hydrologic model i e flood potential model to an existing loosely coupled hydraulic ocean circulation model i e fvcom and shallow water model they simulated varying storm conditions with different sea level rise scenarios over the new jersey us coastline a limitation of their study is that the hydrologic model used does not consider any infiltration precipitation losses surface routing scheme or runoff volume computations some physical processes such as infiltration are often neglected for a simplified case but in some cases contributes to improving the results for example when loftis et al 2016 considered infiltration their mean difference between modeled and observed water levels reduced from 10 to 2 5 also the equations that represent their hydrologic model are implemented within the other model on a per pixel basis which may not capture the full physics behind each physical process on the other hand this technique requires less effort since only one numerical model has to be developed also this technique requires the running of only one numerical model which might be computationally more expensive and may require less user interaction versus when multiple numerical models need to be run sequentially or simultaneously 3 conclusion and future research extreme weather events may bring intense rainfall and high storm surges along their trajectory surface runoff is produced when an excess of water cannot infiltrate to the soil and this excess is transported across the landscape by means of the gravity force until it reaches a channel or a river storm surge is produced by a combination of strong winds blowing towards the shore and the uplift of the water surface due to a decrease in barometric pressure these two flooding mechanisms can affect low gradient coastal watersheds and their frequency is increasing due to effects of climate change chen et al 2013 feng and brubaker 2016 karamouz et al 2017a passeri et al 2015b also these flooding mechanisms can occur simultaneously or in close succession i e compound flooding which can exacerbate flooding for coastal communities some recent examples are hurricane florence 2018 that brought record breaking rainfall 912 mm to north carolina while a 3 0 m maximum storm surge was recorded at the neuse pamlico estuary erdman 2018 the weather channel 2018 also hurricane harvey 2017 was the most significant tropical cyclone rainfall event in us history producing a storm total rainfall of 1539 mm and a 3 2 m maximum storm surge within the texas region blake and zelinsky 2018 therefore there is an urgent need to develop new technologies that are capable to comprehensively study and simulate compound flood events many numerical models or algorithms have been developed to determine the flooding caused by rainfall runoff in the past few decades similarly numerical models for computing coastal inundation caused by tropical cyclones have been developed researchers have coupled both numerical models i e hydrologic and ocean circulation model successfully using various approaches e g one way loosely tightly coupled technique to quantify compound inundation brought by a cyclonic event the linking technique may be useful as a first attempt to quantify the compound inundation since it requires less effort and computational resources than loosely or tightly coupling techniques however it neglects many of the natural interactions between both flooding mechanisms such as storm surge surface runoff storm surge out of bank flow and storm surge streamflow interactions also the direct effects of the precipitation over the model domain are neglected while the additional effort of developing a third model e g hydraulic model may be time consuming however despite the use of the coupling technique e g loosely or tightly some limitations are still encountered such as limiting the exchange of information to a single boundary e g coastline only and not including essential components of the hydrologic model e g infiltration precipitation losses surface routing scheme or runoff volume computations to address the current limitations for compound inundation estimates future research should focus on the following i assessments of compound flood events in low gradient coastal regions must move beyond the current one way and loosely coupled techniques to tightly and fully coupled approaches fortunately computational resources can now favor tight coupling techniques ii the direct effect of the precipitation falling over the entire model domain must be assessed this domain includes the ocean circulation model domain the hydrologic model domain and the transition zone bilskie and hagen 2018 between both flooding mechanisms the contribution can be included by means of an increase in the volume of water at the ocean domain and as a surface rainfall runoff computation at the land surface where both flooding mechanisms interact also these contributions can be included by using a tightly coupled technique to introduce the corresponding equations within the hydrodynamic model iii the complete interaction between storm surge and rainfall runoff at the coastal floodplain must be quantified these interactions include storm surge surface runoff storm surge out of bank flow and storm surge streamflow they may be accounted for by means of tight coupling techniques to the authors knowledge no numerical model that considers all possible interactions e g storm surge surface runoff storm surge out of bank flow and storm surge streamflow between both storm surge and rainfall runoff in a single framework has been developed published or employed in practice despite that many researchers have stated that there is an urgent need for such a modeling framework cheng et al 2010 herdman et al 2018 mashriqui et al 2010 2014 orton et al 2012 serafin et al 2019 skinner et al 2015 thompson and frazier 2014 wang et al 2015 a comprehensive compound inundation model that considers all physical processes can describe a more complete interaction between the flooding mechanisms that commonly occur during an extreme event e g hurricanes or typhoons the improvement in describing this interaction can translate into a more realistic simulated total flood hazards in coastal watersheds which affects millions of people around the world this comprehensive compound inundation model can serve as a more accurate complete flood forecast tool that can help decision makers and authorities create better coastal resiliency measurements e g delineation of no build zones and flood insurance map and emergency plans e g identifying evacuation routes for communities and issuing early warning advisories that can save lives and reduce damages to property acknowledgments the authors greatly appreciated the feedback provided by dr madeline foster martinez during the preparation of this article this material is based upon work supported in part by the national science foundation graduate research fellowship program grant no 1452778 the national oceanic and atmospheric administration ecological effects of sea level rise program award no na16nos4780208 the u s department of homeland security award no 2015 st 061 nd0001 01 the gulf research program grp of the national academies of sciences engineering and medicine award no 200000829 the robert wood johnson foundation rwjf award no 200000829 and the louisiana sea grant laborde chair any opinions findings and conclusions or recommendations expressed in this material are those of the author s and do not necessarily reflect the views of the nsf noaa grp rwjf or the louisiana sea grant college program the views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies either expressed or implied of the u s department of homeland security 
26164,extreme coastal flooding poses a major threat to human life and infrastructure low gradient coastal watersheds can be vulnerable to flooding from both intense rainfall and storm surge here we present a comprehensive review of the most recent studies that quantify extreme flooding using variations of a compound inundation model a compound inundation model may consist of different numerical models observed data and or a combination of these the definitions advantages and limitations of each joining technique are discussed with the goal of enabling and focusing subsequent research future investigation should focus on the development of a tight coupling procedure that can accurately represent the complex physical interactions between storm surge and rainfall runoff a more accurate compound flood forecast tool can help decision makers stakeholders and authorities converge on better coastal resiliency measures that can potentially save human lives aid in the design of structures and communities and decrease property damage keywords storm surge rainfall runoff compound flood flood transition zone tropical cyclone inundation model 1 introduction coastal regions are vital for the advancement of society by supporting capital flows for tourism industrialization transportation and urban development current projections for the united states us population that resides in low gradient coastal zones indicates an increase of 145 by 2030 with respect to 2000 neumann et al 2015 in addition the us has 17 port cities with a population greater than 1 million wahl et al 2015 extreme coastal flooding is one of the hazardous elements that pose a major threat to human life and infrastructure bates et al 2005 bhaskaran et al 2014 moussa and bocquillon 2009 padgett et al 2008 low gradient coastal watersheds are vulnerable to flooding hazards from both intense rainfall and coastal storm surge penetration which are produced from extreme meteorological events e g tropical cyclones low pressure systems bilskie and hagen 2018 comer et al 2017 mcinnes et al 2002 moftakhari et al 2017 ray et al 2011 silva araya et al 2018 hurricanes were responsible for 40 of the global total deaths for all weather related disasters from 1995 to 2015 unisdr and cred 2015 also three of the five costliest hurricanes that have impacted the us mainland and its territories occurred in the 2017 hurricane season noaa 2018 hurricanes harvey irma and maria affected the texas and louisiana coasts the florida peninsula and puerto rico and the u s virgin islands respectively in less than a month these three hurricanes produced a total damage of 265 000 million 2017 usd and were directly responsible for the loss of 183 human lives blake and zelinsky 2018 cangialosi et al 2018 noaa 2018 pasch et al 2018 ward et al 2018 zscheischler et al 2018 these natural hazards can be devastating with wide ranging social comer et al 2017 karamouz et al 2017a olbert et al 2017 economic chen and liu 2014 karamouz et al 2015 lian et al 2013 wang et al 2015 and environmental costabile et al 2013 park et al 2011 stamey et al 2007 consequences in low gradient coastal watersheds around the world floods can emerge from several mechanisms or driving forces bacopoulos et al 2017 serafin et al 2019 here we limit focus on the flooding mechanisms produced by a tropical cyclone and extreme precipitation events in which subsurface flow and storm water systems are typically negligible these flooding mechanisms can occur due to a single meteorological event e g tropical cyclone that includes extreme precipitation or by a combination of separate events that occur in close succession or simultaneously such as when an intense and prolongated precipitation event occurs before any extreme wind event e g tropical cyclone prevalent strong onshore winds low pressure system fig 1 illustrates the flooding mechanisms typically considered during a cyclonic event in a coastal watershed these mechanisms can produce flooding via i precipitation rainfall intense or prolonged precipitation can induce surface runoff runoff moves from overland areas to a stream increasing the streamflow rate to a point that exceeds the channel capacity and producing an out of bank flow i e overbank flow that inundates the floodplain fig 2 ii storm surge storm surge is produced by high winds and low atmospheric pressure that drives oceanic waters to interact with the local coastal geometry the total water level is temporarily raised and can penetrate inland to inundate the floodplain iii compound flood a combination of both mechanisms i e rainfall runoff and storm surge that can occur simultaneously or in close succession commonly referred as compound flooding bilskie and hagen 2018 ikeuchi et al 2017 kumbier et al 2018a paprotny et al 2018 saleh et al 2017 wahl et al 2015 ward et al 2018 zscheischler et al 2018 also a compound flood can be produced by other flooding mechanisms that are not considered here such as waves and tides blanton et al 2018 buschman et al 2009 comer et al 2017 olbert et al 2017 orton et al 2018 for example when both mechanisms i e rainfall runoff and storm surge occur simultaneously there is an increase in the flood hazard due to the combined effects of high river flow rates and elevated sea levels at the river outlet e g estuarine or tidal river erikson et al 2018 hubbert and mcinnes 1999 ikeuchi et al 2017 maskell et al 2014 svensson and jones 2004 tromble et al 2010 wahl et al 2015 therefore storm surge and rainfall runoff in coastal watersheds are not necessarily mutually exclusive hazards christian et al 2015 karamouz et al 2017b torres et al 2015 since the early 2000s studies have investigated the probability of storm surge and rainfall runoff occurring simultaneously or in close succession these studies highlight that these flooding mechanisms are present over different length scales such as local scale kew et al 2013 klerk et al 2015 svensson and jones 2004 thompson and frazier 2014 zheng et al 2014 continental scale moftakhari et al 2017 paprotny et al 2018 wahl et al 2015 zheng et al 2013 and global scale ward et al 2018 they depend on watershed properties such as location and size for example hurricane florence 2018 produced a catastrophic flood in north carolina us which was induced by intense and prolonged precipitation and high levels of storm surge that blocked the streamflow towards the estuaries almasy et al 2018 elliott 2018 therefore it is critical to quantify the dependence between the flooding mechanisms bilskie and hagen 2018 zheng et al 2014 as the effects of carbon emissions shape the earth s climate it is possible that extreme weather events and their compound effects will become more severe and frequent through increased sea levels bhaskaran et al 2014 bilskie et al 2019 ge et al 2014 karamouz et al 2017a passeri et al 2015b smith et al 2012 sweet and park 2014 river discharges paprotny et al 2018 zscheischler et al 2018 and extreme precipitation chen et al 2013 feng and brubaker 2016 karamouz et al 2015 wang et al 2013 observations indicate that hurricanes are expected to become stronger and more frequent with the number of major storms e g categories iv and v based on the saffir simpson scale increasing over the past 35 years along with ocean temperature anthes et al 2006 bender et al 2010 elsner 2008 emanuel 2005 1987 holland and bruyère 2014 lal 2001 lynn et al 2009 tang et al 2013 van aalst 2006 in addition projections of future climate indicate potential shifts in rainfall patterns toward stronger and more intense storms feng and brubaker 2016 karamouz et al 2015 risser and wehner 2017 trenberth et al 2018 wang et al 2013 understanding the hazard posed by the combination of extreme events under present and future sea levels is crucial for the successful management of coastal communities by means of effective coastal resilient measures these measures may include a comprehensive understanding and the capability of modeling effectively both mechanisms i e storm surge and rainfall runoff that produce these extreme flooding bacopoulos et al 2017 bhaskaran et al 2014 bilskie and hagen 2018 dresback et al 2013 passeri et al 2015b flood inundation maps useful for planning and management of riverine and coastal floodplains are another important consideration regarding compound flooding these maps are used to delineate no build zones flood insurance rates identify evacuation routes for communities issue early warning advisories and as aid in the development of safe and cost effective design criteria for hydraulic structures e g bridges culverts levees seawalls flood gates etc christian et al 2015 moftakhari et al 2017 silva araya et al 2018 torres et al 2015 common flood hazard assessment practices typically account for one mechanism at a time e g rainfall runoff or storm surge and not their combination whereas coastal cities are exposed to multiple flooding mechanisms bilskie and hagen 2018 erikson et al 2018 klerk et al 2015 moftakhari et al 2017 orton et al 2015 serafin et al 2019 torres et al 2015 ward et al 2018 zscheischler et al 2018 for example the standard assumption with the federal emergency management agency fema flood zone mapping with flood hazard assessment studies and with operational systems is that rainfall runoff flooding can be neglected when modeling a storm surge event since the impact of the cyclone is relatively short in comparison to the time it takes for any rainfall runoff flooding to reach the coast blanton et al 2018 orton et al 2018 ray et al 2011 silva araya et al 2018 tang et al 2013 torres et al 2015 this assumption has been shown to not always be correct since the time of arrival of both flooding mechanisms i e storm surge and rainfall runoff depends on several factors such as watershed properties antecedent conditions and storm characteristics kumbier et al 2018b orton et al 2018 2015 santiago collazo et al 2017 silva araya et al 2018 there is an urgent need to simulate the potential compound effects of rainfall runoff and storm surge flooding a direct capability to define flood transition zones bilskie and hagen 2018 can lead to transdisciplinary research outcomes that will prove beneficial to society numerical models provide information about complex physical processes e g compound flooding and have shown to aid in disaster and evacuation planning which is a critical tool for decision makers blanton et al 2018 chen and liu 2014 georgas et al 2016 kew et al 2013 olbert et al 2017 serafin et al 2019 one of the flooding mechanisms that is often neglected in coastal inundation modeling i e storm surge modeling is rainfall runoff when it is considered some physical processes are missing or simplified such as momentum exchange of fluxes which is important in delineating the spatial extent of the inundation maskell et al 2014 orton et al 2018 recently compound inundation models have been focused on quantifying streamflow and storm surge interaction while neglecting the out of bank flow surface runoff and storm surge interaction in addition the direct effect of the precipitation over a study area i e model domain has also been neglected the majority of these models have been implemented with loosely coupled or linked techniques which simplifies the interaction between both inundation models and may be misrepresenting the actual physical processes in fact bilskie and hagen 2018 demonstrate how the superposition of runoff with surge can overestimate total water levels modeling approaches that integrate multiple flooding mechanisms e g storm surge surface runoff and streamflow and simulate their compound influences would be more effective in supporting a wide range of decision making orton et al 2018 saleh et al 2017 the current techniques for joining two or more numerical models can be summarized into four classifications linking technique loose coupling tight coupling and full coupling table 1 these classifications vary on the technique employed to transfer or exchange information between each numerical model which represents the individual physical processes flowcharts for each joining technique is shown in fig 3 a linking technique is defined as a method that transfers the results from one model i e courier model to be used as an input for a second model i e recipient model as shown in fig 3i silva araya et al 2018 sulis et al 2010 this technique is also known as one way coupling since the transfer of information only occurs in one direction cheng et al 2010 hühne et al 2016 usually the courier model is run first and independently from the recipient model then the results are transferred by means of boundary conditions to the recipient model which is run with all the required input information and boundary conditions finally the results from the recipient model are analyzed and if further changes are necessary to the courier model the process will repeat again an example of an application of this technique is the resulting wind field from an atmospheric model that is transferred as an input to an ocean circulation model alternatively a loosely coupled technique is defined as a method that couples models which are run separately using information exchange in an iterative manner fig 3ii blanton et al 2018 goodall et al 2011 hühne et al 2016 sulis et al 2010 this technique is also known as two way coupling since the transfer of information occurs in two directions cheng et al 2010 hühne et al 2016 the process of a loosely coupled technique between two models e g model a and model b can be described by the following i the results from model a are transferred to model b via boundary conditions ii model b uses this information to compute new results and transfer the new information to model a iii model a uses the information received to compute updated new results and transfers it to model b iv the process is repeated until it reaches the end of the simulation period on the other hand a tightly coupled technique is defined as a method that joins the independent models into a single modeling framework by combining their source code as shown in fig 3iii blanton et al 2018 goodall et al 2011 in other words portions of the source code that describes the physical processes of model a are incorporated into the source code of model b or vice versa this means that the information exchange between both portions of the code is performed internally within the same source code i e computer memory and does not involve the exchange of external input and output files one example of this technique is the swan adcirc simulating waves nearshore model advanced circulation model modeling framework in this example swan transfers wave radiation stresses to adcirc and adcirc transfers back to swan the updated wind velocities water levels and currents dietrich et al 2012 2011b lastly a fully coupled technique is defined as a technique in which the governing equations of all the physical processes considered e g storm surge and rainfall runoff are solved simultaneously within the same modeling framework as shown in fig 3iv hühne et al 2016 sulis et al 2010 for example wash123d watershed systems of 1 d stream river network 2 d overland regime and 3 d subsurface media model shih et al 2012 shih and yeh 2011 yeh et al 2011 2005 1998 in which many physical processes e g streamflow surface runoff flow subsurface flow are represented using a common set of governing equations such as the navier stokes equations for describing motion of a viscous fluid unfortunately wash123d does not model storm surge conditions the remainder of this paper consists of a review of the widely used inundation models to simulate rainfall runoff and storm surge in low gradient coastal landscapes three categories of inundation models are discussed rainfall runoff driven storm surge driven and compound inundation models the most recent and relevant studies using these models are described including their advantages and limitations furthermore the four classifications of compound inundation models depending on the coupling approach will be explained in additional detail finally conclusions are drawn and future research is discussed 2 inundation models in the context of this paper we focus on inundation models that are typically developed to quantify and delineate the flood zone due to a certain atmospheric event e g tropical cyclone low pressure system prolonged and intense precipitation event such models can be categorized by the mechanism that drives the flooding we do not consider inundation models that account for subsurface flow i e groundwater flow and or storm water drainage systems or flooding from tsunamis due to the challenging numerical representation of the physical processes of a compound flood event both types of models i e rainfall runoff driven and storm surge driven have been developed and used independently with the advancement of computer technology and numerical modeling both models have been recently one way loosely coupled to produce a better estimate of total water levels the remainder of the section will discuss the inundation models driven by rainfall runoff and storm surge as well as the compound inundation model 2 1 rainfall runoff driven inundation models a rainfall runoff driven inundation model commonly known as a hydrologic model can be defined as the characterization of real hydrologic features and systems such as rainfall runoff evapotranspiration interception infiltration etc in general two types of hydrologic models have been developed and applied in recent years conceptual based lumped parameter hydrologic models and physically based distributed parameter hydrologic models these models differ in the mathematical representation of the hydrologic processes spatial representation of the watershed properties and data requirements el hassan et al 2013 the conceptual based lumped parameter hydrologic model assumes the watershed properties e g soil type land use cover initial soil moisture surface roughness etc are uniform over the entire domain and may be used to simulate total watershed runoff using basin average input data and empirical parameters andréassian et al 2004 el hassan et al 2013 fatichi et al 2016 kalyanapu et al 2009 sharif et al 2013 torres et al 2015 such models produce reasonable estimates of runoff but due to the distributed nature of hydrological properties the models cannot accurately represent the spatial variation of the watershed conditions el hassan et al 2013 however a common workaround is to divide basins into hydrologically similar sub basins to take advantage of the spatial resolution of rainfall and watershed properties sharif et al 2013 alternatively physically based distributed parameter hydrologic models are capable of having a spatial distribution of precipitation and watershed properties through a computational grid thus hydrologic processes e g conservation of mass momentum and energy for overland runoff are mathematically represented in each grid cell el hassan et al 2013 torres et al 2015 some advantages of these models include the capability to produce simulation data at any point within the model domain initialization with minimal historical data and greater flexibility in the calibration process for the watershed properties hunter et al 2003 sharif et al 2013 2010a torres et al 2015 contrarily this type of hydrologic model may require more time to develop and greater computer power than the conceptual based lumped parameter hydrologic models usually all types of hydrologic models are comprised of two primary components rainfall runoff estimation and a routing scheme to transport the rainfall runoff the routing scheme used in a hydrologic model can be a limitation for flood modeling since the real physical characteristics of the rivers are not considered nguyen et al 2016 therefore hydraulic models have been used to simulate floods together with hydrologic models in which the rainfall runoff estimated from the hydrologic model is used as an input in the hydraulic model some of the most popular hydraulic models used are the hydrologic engineering center river analysis system hec ras model brunner 2001 the mike hydro river i e mike 11 model danish hydraulic institute 1997 the lisflood fp model bates and de roo 2000 the flo 2d model o brien et al 1993 and the msn flood model falconer 1984 the hec ras model developed by the u s army corp of engineers usace computes the water depth in a river cross section given a flow rate this model is widely used due to its freely available software anees et al 2016 ray et al 2011 also the lisflood fp model was designed by the university of bristol to simulate floodplain inundation over complex topography bates et al 2005 bates and de roo 2000 lewis et al 2013 smith et al 2012 one of the main advantages of hydraulic models is that the modeling is based on the topography of the channel and floodplain which is in accordance with the continuity and momentum principles and minimal parameters nguyen et al 2016 the selection of an appropriate hydrologic modeling methodology is a key step of any flood modeling system sharif et al 2010b this research only focuses on the to date application of hydrologic models at the coast and are not necessarily including all rainfall runoff driven inundation model advancements e g curtu et al 2014 demir and krajewski 2013 elsaadani and krajewski 2017 quintero et al 2016 the usace has developed two of the most popular conceptual based lumped parameter hydrologic models hydrologic engineering center 1 hec 1 model and the hydrologic engineering center hydrologic modeling system hec hms model the hec 1 model hydrologic engineering center 1998 was developed in the 1990s and was replaced by the hec hms model scharffenberg 2016 in the early 2000s hec hms was originally designed to simulate the rainfall runoff processes of drainage basins in a wide range of geographic areas and has been extensively used in the us el hassan et al 2013 the u s environmental protection agency epa has developed a conceptual based lumped parameter hydrologic model named storm water management model swmm it is used throughout the world for planning analysis and design related to storm water runoff combined and sanitary sewers and other drainage systems in urban areas rossman 2015 for long term modeling the agricultural research service from the u s department of agriculture usda developed the soil and water assessment tool swat model to predict the impact of land management practices on water sediment and agricultural chemicals in large complex watersheds on a daily basis neitsch et al 2002 in addition this model has been used for quantifying rainfall runoff flooding events when linked to other hydraulic models such as hec ras duvvuri and narasimhan 2013 international river interface cooperative iric model jamrussri and toda 2017 and lisflood fp rajib et al 2016 and also for determining river discharges if used independently singh et al 2005 wu and xu 2006 within the category of physically based distributed parameter hydrologic models two of the most prominent models are the gridded surface subsurface hydrologic analysis gssha model downer et al 2002 and the vflo hydrologic model vieux and vieux 2002 gssha was developed by the usace as an enhancement to the hydrologic model casc2d downer et al 2003 gssha has been implemented on a wide variety of watersheds around the us to determine rainfall runoff inundation for forecasting and evaluating extreme precipitation events chintalapudi et al 2012 el hassan et al 2013 hunter et al 2003 sharif et al 2013 2010b 2010a 2006 yang et al 2016 in a similar manner the vflo model has been applied under various watershed characteristics and conditions to estimate the real time urban rainfall runoff evaluate flood control systems and forecast flash floods fang et al 2010 kim et al 2008 looper et al 2012 looper and vieux 2012 teague et al 2013 vieux et al 2005 other models such as the mike she mike 2017 and the hydrology laboratory research distributed hydrologic model hl rdhm colorado basin river forecast center 2008 have been also used for quantifying the rainfall runoff inundation on different watersheds fares et al 2014 geoghegan et al 2018 kitzmiller et al 2011 nguyen et al 2016 sahoo et al 2006 wang et al 2012 xevi et al 1997 zhang et al 2008b 2 2 storm surge driven inundation models coastal inundation is one of the most hazardous events that can occur on a low lying coastal watershed and can result from a wide variety of environmental impacts bhaskaran et al 2014 storm surge is a temporary rise of the total water level at the coast generated by extreme wind and low atmospheric pressure krestenitis et al 2011 lewis et al 2013 mcinnes et al 2002 to assess coastal flood hazards an ocean circulation model is an essential component to predict water levels and inundation extent bates et al 2005 bhaskaran et al 2014 lewis et al 2013 an ocean circulation model simulates the surges in water level due to wind driven and pressure induced events i e storm surge events and by astronomic tides in addition a wave induced surge can be simulated by including the effects of wind waves on storm surge by coupling between an ocean circulation model and a wave model wave models that have been coupled include the simulating waves nearshore swan model booij et al 1999 the steady state spectral wave stwave model resio 1987 and the wavewatch iii ww3 model sheng et al 2010 tolman 2009 some of the most popular ocean circulation models are sea lake and overland surges from hurricanes slosh jelesnianski et al 1992 the advanced circulation adcirc luettich et al 1992 the princeton ocean model pom blumberg and mellor 1987 delft3d deltares 2009 and the finite volume coastal ocean model fvcom chen et al 2003 adcirc is a robust model that has been successfully validated with numerous historical hurricanes over varying coastal regions such as the us atlantic coast bacopoulos et al 2012 colle et al 2008 garzon and ferreira 2016 hagen et al 2012 yin et al 2016 the north indian ocean bhaskaran et al 2014 gayathri et al 2016 and the gulf of mexico bilskie et al 2016b bunya et al 2010 dietrich et al 2011a hagen et al 2012 hope et al 2013 with a high accuracy adcirc has been used to produce real time storm surge and wave forecast for the northern gulf of mexico dietrich et al 2013 the us atlantic coast blanton et al 2012 dresback et al 2013 garzon et al 2018 and the north western pacific ocean suh et al 2015 adcirc has also been used to simulate numerous synthetic storms based on historical tracks and storm intensity to explore the effects of these storms making landfall in another location and or with greater storm intensity kennedy et al 2012 rao et al 2013 sebastian et al 2014 others have implemented adcirc for simulating coastal inundation for the past present and future conditions of the coastal landscape with or without projected sea level rise bilskie et al 2019 2016a 2014 passeri et al 2015a siverd et al 2018 similar to the adcirc model the fvcom model has been implemented on the wide variety of hurricane conditions either in forecast or analysis mode for several coastlines within the us mainland and the korea peninsula rego and li 2009a 2009b rego and li 2010 weisberg and zheng 2006 2008 yang et al 2014 yoon and shim 2013 2016 similarly the pom peng et al 2006 2004 xia et al 2008 xie et al 2008 2004 slosh mercado 1994 murdukhayeva et al 2013 zhang et al 2008a and delft3d brown et al 2007 cranston and tavendale 2012 models have been implemented under complex environments for historical hurricanes 2 3 compound inundation models simulation of storm surge propagation in rivers and estuaries including the backwater effects of river flow is important for coastal inundation modeling in low gradient coastal watersheds lewis et al 2013 a compound inundation model consists of one or more numerical models that are combined with the aim of obtaining an accurate total water level the numerical models that comprise a compound inundation model may be a combination of hydrologic ocean circulation or hydraulic models commonly these numerical models have been combined with each other using a one way loose or a tight coupling approach the definition of each joining technique has been defined previously in section 1 and are summarized in table 1 implementation of full and tight coupling for these types of numerical models e g hydrologic ocean circulation and hydraulic model is more complicated than loose or one way coupling this difficulty is attributed to the complex mathematical representation of their physical processes the computational power required and the temporal and spatial resolution varying time and length scales of the numerical models for example the fully coupled wash123d model has been used successfully in idealistic cases but has not been able to simulate real world scenarios accurately however due to the continuous advances in computer technology tight coupling these numerical models is more feasible today than in the past several efforts to couple both storm surge and rainfall runoff have been developed in the last decade the joining technique used for combining different models depends greatly on the physical processes to be simulated for example when coupling an ocean circulation model with a wave model funakoshi et al 2008 found that numerical problems increased when the tight coupling technique was used and that a loose coupling technique may be sufficient to capture this interaction also the physical interactions between the flooding mechanisms e g atmospheric hydrological and coastal oceanic are typically handled via loose coupling blanton et al 2018 conversely the tight coupling technique is necessary to accurately account for watershed nearshore interactions during storm events cheng et al 2010 from the available literature only one study used a loosely coupled technique to produce the compound inundation model cheng et al 2010 which is described in section 2 3 4 also only one study used a tightly coupled technique to produce the compound inundation model tang et al 2013 which is described in section 2 3 5 the remaining publications found used a linking technique and are summarized in table 2 through table 4 which lists the year it was published the location of the study area the numerical models used and the joining technique these linked models are characterized based on the type of base model i e recipient model used when joining both the hydrologic and ocean circulation model therefore they are categorized as i linked hydrological model ii linked ocean circulation model or iii linked hydraulic model unfortunately studies that used a fully coupled technique to produce a compound inundation model were not found in the available literature the remainder of this section will focus on discussing published studies that employed a one way loosely and tightly coupled technique 2 3 1 linked hydrologic model thirteen percent of the publications found used a linked hydrologic model for the compound model see table 2 this linking technique is based on independently running the ocean circulation model first which requires wind speed and atmospheric pressure data as input the results from the ocean circulation model e g total seawater level are used as an input for the hydrologic model in addition to the precipitation data by means of boundary conditions the results from the linked hydrologic model can be considered as compound water level inundation this procedure is summarized in fig 4 for example silva araya et al 2018 first employed an ocean circulation model i e adcirc to produce time series of total seawater level and used it as an input to a hydrologic model i e gssha by means of time varying boundary condition points at the downstream end of the watershed the studies within this category applied the models in coastal watersheds in the us mainland and its territories the vast majority of these studies used the gssha hydrologic model while adcirc was the most common ocean circulation model also the majority of these studies used observed data from a tide gauge to force the hydrologic model instead of results from an ocean circulation model some studies considered future climate change conditions including varying sea level rise slr precipitation and storm characteristics while others considered flooding scenarios from different return periods in a compound model that uses a linked hydrologic model information is transferred at the boundary condition points located at the downstream end of the hydrologic model the location of the boundary points limits the influence of the storm surge which is typically greater at the river outlet i e bay or estuary margin these methods neglect any interaction between the rainfall runoff and the storm surge in the coastal floodplain or in the flood transition zone bilskie and hagen 2018 for example the interaction between the surface runoff storm surge and the out of bank flow storm surge is not considered see fig 1 this can result in underestimating the total water level on the other hand the low computational power needed for this technique makes it suitable for simulating multiple flooding scenarios within a short period this technique requires less effort since only the hydrologic model has to be developed if observed data for storm surge is used instead of an ocean circulation model also accurate flooding maps can be produced using this technique since karamouz et al 2017b reproduce the flooding map from hurricane sandy 2012 at lower manhattan new york city ny with a 3 overestimate of the floodplain area nevertheless the conclusion from these studies supports the need for developing a more holistic model that can account for potential interactions between storm surge and rainfall runoff 2 3 2 linked ocean circulation model forty five percent of the publications found used a linked ocean circulation model for the compound model see table 3 this linking technique is based on independently running the hydrologic model first which requires precipitation data as input the freshwater discharge results from the hydrologic model are used as an input for the ocean circulation model in addition to the wind speed and atmospheric pressure data by means of boundary conditions the results from the linked ocean circulation model can be considered as a compound water level inundation this procedure is summarized in fig 5 for example dresback et al 2013 first employed a hydrologic model i e hl rdhm to produce freshwater discharge hydrographs and used them as input to their ocean circulation model i e adcirc by means of time varying boundary condition points the boundary condition points were located at four areas in the watershed well upstream the coast where any tidal or storm surge effects would be experienced the studies within this category applied this method to coastal watersheds in the us mainland taiwan australia germany england and the korean peninsula the vast majority of these studies used the adcirc model while hl rdhm was the most used hydrologic model in addition the majority used observed streamflow data from a river gauge to force the ocean circulation model instead of using a hydrologic model some of these studies linked both numerical models through the use of time variant boundary conditions of riverine discharge i e freshwater flow while others used river stage level to set boundary conditions and some used time invariant riverine flow drive radiation boundary conditions only one study used rating curves i e discharge versus water level plot in a compound model that uses a linked ocean circulation model the boundary condition that transfers information from the hydrologic model is specified at the upstream end of the ocean circulation model usually the location of these boundary condition points is upstream in the river system where the influence of the estuary conditions i e storm surge tide seawater level can be neglected a limitation of this approach is that the out of bank flow which exits from the stream to the floodplain see figs 1 and 2 is not considered in the total compound inundation model since when the freshwater discharge is transferred to the ocean circulation model as a boundary condition point it only transfers data from a single point and the recorded or simulated discharge data may not include the out of bank flow chen and liu 2014 2016 reported a mean absolute error ten times higher and a root mean square rms error nine times higher in the river than on the coast this can be attributed to the lack of the out of bank flow processes within the linked model also the precipitation that falls directly into the ocean circulation model domain is neglected these precipitation amounts may be negligible but it can be significant for slow moving storms that dump an excessive amount of precipitation over a long period of time such as hurricane harvey 2017 and hurricane florence 2018 therefore the surface runoff produced by this precipitation i e rainfall runoff and the direct volume contribution over the seawater domain is not accounted for the total compound inundation despite these limitations most studies demonstrated the importance of including the hydrology component in numerical simulation of compound inundation in low lying coastal watershed during extreme atmospheric events bacopoulos et al 2017 bilskie and hagen 2018 chen and liu 2016 2014 herdman et al 2018 kumbier et al 2018b maskell et al 2014 orton et al 2012 2018 2015 similar to the linked hydrologic model the low computational power needed for this technique makes it suitable for simulating multiple flooding scenarios within a short period of time this can be useful as a first approximation of the flood levels when forecasting the impact of a tropical cyclone to a low gradient coastal watershed some researchers had simulated water levels with rms errors within 10 5 cm 34 cm using this technique which may be considered accurate when modeling surge events on the order of tens of meters bacopoulos et al 2017 georgas et al 2016 kumbier et al 2018a orton et al 2018 also this technique requires less effort since only the ocean circulation model has to be developed if observed data for riverine flow is used instead of a hydrologic model 2 3 3 linked hydraulic model thirty eight percent of the publications found used a linked hydraulic model for the compound model see table 4 this linking technique is based on independently running the hydrologic model and the ocean circulation model first with their required data inputs e g precipitation wind speed and atmospheric pressure the results from the hydrologic model e g freshwater discharge and the ocean circulation model e g total seawater level are both used as inputs for the hydraulic model by means of boundary conditions the results from the linked hydraulic model can be considered as compound water level inundation this procedure is summarized in fig 6 for example torres et al 2015 first employed a hydrologic model i e vflo and ocean circulation model i e adcirc to produce freshwater discharge hydrographs and total seawater levels to be used as inputs to a hydraulic model i e hec ras by means of time variant boundary condition points at upstream and downstream portions of the watershed respectively the studies within this category applied this method to coastal watersheds in the us mainland china united kingdom ireland bangladesh and taiwan the vast majority used the hec ras hydraulic model in addition the majority of these studies used in a combination or separately observed data from a river gauge and or a tide gauge to force the hydraulic model instead of using a hydrologic model or an ocean circulation model respectively all of these studies employed a linking technique with the use of time variant boundary conditions points of freshwater discharge time variant boundary conditions points of seawater level elevation or a combination of both in a compound model that uses a linked hydraulic model the boundary condition that transfers information from each model e g hydrologic and ocean circulation model are specified at two different locations within the hydraulic model the hydrologic model passes information at the upstream end of the hydraulic model while the ocean circulation model passes information at the downstream end of the hydraulic model one of the limitations of this approach is the additional effort of developing a third model i e hydraulic model to estimate the compound inundation the development of a model may require the collection and processing of data as well as the calibration and validation of the model also most of the ocean circulation models e g fvcom adcirc have the capability of computing the flow hydrodynamics as the hydraulic model and therefore at some instance it may substitute the hydraulic model from their compound model configuration similar to the approach of using an ocean circulation model to link both models the direct effects of the precipitation over the model domain is neglected since the hydraulic model does not have the capacity to transform rainfall into surface runoff the total compound inundation may be underestimated however for most of these studies the implementation of a hydraulic model i e 1d models with boundary conditions derived from hydrologic and ocean circulation models i e 2d 3d models can be a viable approach to reduce numerical modeling gaps that exist for coastal rivers christian et al 2015 ikeuchi et al 2017 mashriqui et al 2010 2014 ray et al 2011 skinner et al 2015 torres et al 2015 this technique requires less effort since only the hydraulic model has to be developed if observed data for storm surge and riverine flow are used instead of an ocean circulation model and a hydrologic model respectively also this technique may be useful to estimate the flood levels in the transition zone bilskie and hagen 2018 since this technique extends well enough upstream to isolate the effects of the storm surge in the riverine flow at the upstream boundary and extends well enough downstream to isolate the effects of the riverine flow in the storm surge this linking technique can estimate accurate water levels since some researchers had simulated water levels with rms errors within 15 cm 27 cm comer et al 2017 feng and brubaker 2016 mashriqui et al 2014 olbert et al 2017 wang et al 2014 2 3 4 loosely coupled models as mentioned before only one publication that used a loosely coupled technique for developing a compound model was found cheng et al 2010 when both numerical models are loosely coupled the zone where both flooding mechanisms i e storm surge and rainfall runoff interact must be specified using boundary condition points this technique will require transferring the results from one model to another at a certain time interval specified by the user a third party software typically carries out the exchange of information this tight coupling technique is based on running the hydrologic model and the ocean circulation model with their required data inputs e g precipitation wind speed and atmospheric pressure simultaneously the results from each model e g freshwater discharge and total seawater levels are used as inputs to the other model e g freshwater discharge used as an input to the ocean circulation model by means of boundary conditions and the models are run again with their new inputs the results from the loosely coupled hydrologic ocean circulation model can be considered as compound water level inundation this procedure is summarized in fig 7 for example cheng et al 2010 loosely coupled an ocean circulation model i e adcirc with a hydrologic model i e pwash123d using this boundary condition points they simulated hurricane katrina 2005 impact over the mississippi us coast using synthetic rainfall instead of the actual hurricane rainfall a limitation of this approach is that the interaction between the two models occurs at the coastline only where it could naturally occur upstream in the river outlet or in the coastal floodplain nonetheless this technique is capable of improving the interaction between both flooding mechanisms i e rainfall runoff and storm surge since their results supported the use of a loose coupling technique over the linking technique for watershed nearshore interaction for example the comparison of results between different coupling techniques e g one way vs two way shows a difference in river stage and in overland water depth of 60 cm and 1 0 m during the storm peak respectively therefore the linking technique may be insufficient for intense storms since the greatest watershed nearshore interaction is during the storm peak 2 3 5 tightly coupled models only one publication that used a tightly coupled technique for developing a compound model was found tang et al 2013 tight coupling two numerical models at code level require that the mathematical representation of one of the physical processes e g storm surge or rainfall runoff be included in the numerical code of the other model this approach is more complicated than the boundary condition method since it involves programming and modifying the numerical model algorithm tang et al 2013 used this approach to couple a hydrologic model i e flood potential model to an existing loosely coupled hydraulic ocean circulation model i e fvcom and shallow water model they simulated varying storm conditions with different sea level rise scenarios over the new jersey us coastline a limitation of their study is that the hydrologic model used does not consider any infiltration precipitation losses surface routing scheme or runoff volume computations some physical processes such as infiltration are often neglected for a simplified case but in some cases contributes to improving the results for example when loftis et al 2016 considered infiltration their mean difference between modeled and observed water levels reduced from 10 to 2 5 also the equations that represent their hydrologic model are implemented within the other model on a per pixel basis which may not capture the full physics behind each physical process on the other hand this technique requires less effort since only one numerical model has to be developed also this technique requires the running of only one numerical model which might be computationally more expensive and may require less user interaction versus when multiple numerical models need to be run sequentially or simultaneously 3 conclusion and future research extreme weather events may bring intense rainfall and high storm surges along their trajectory surface runoff is produced when an excess of water cannot infiltrate to the soil and this excess is transported across the landscape by means of the gravity force until it reaches a channel or a river storm surge is produced by a combination of strong winds blowing towards the shore and the uplift of the water surface due to a decrease in barometric pressure these two flooding mechanisms can affect low gradient coastal watersheds and their frequency is increasing due to effects of climate change chen et al 2013 feng and brubaker 2016 karamouz et al 2017a passeri et al 2015b also these flooding mechanisms can occur simultaneously or in close succession i e compound flooding which can exacerbate flooding for coastal communities some recent examples are hurricane florence 2018 that brought record breaking rainfall 912 mm to north carolina while a 3 0 m maximum storm surge was recorded at the neuse pamlico estuary erdman 2018 the weather channel 2018 also hurricane harvey 2017 was the most significant tropical cyclone rainfall event in us history producing a storm total rainfall of 1539 mm and a 3 2 m maximum storm surge within the texas region blake and zelinsky 2018 therefore there is an urgent need to develop new technologies that are capable to comprehensively study and simulate compound flood events many numerical models or algorithms have been developed to determine the flooding caused by rainfall runoff in the past few decades similarly numerical models for computing coastal inundation caused by tropical cyclones have been developed researchers have coupled both numerical models i e hydrologic and ocean circulation model successfully using various approaches e g one way loosely tightly coupled technique to quantify compound inundation brought by a cyclonic event the linking technique may be useful as a first attempt to quantify the compound inundation since it requires less effort and computational resources than loosely or tightly coupling techniques however it neglects many of the natural interactions between both flooding mechanisms such as storm surge surface runoff storm surge out of bank flow and storm surge streamflow interactions also the direct effects of the precipitation over the model domain are neglected while the additional effort of developing a third model e g hydraulic model may be time consuming however despite the use of the coupling technique e g loosely or tightly some limitations are still encountered such as limiting the exchange of information to a single boundary e g coastline only and not including essential components of the hydrologic model e g infiltration precipitation losses surface routing scheme or runoff volume computations to address the current limitations for compound inundation estimates future research should focus on the following i assessments of compound flood events in low gradient coastal regions must move beyond the current one way and loosely coupled techniques to tightly and fully coupled approaches fortunately computational resources can now favor tight coupling techniques ii the direct effect of the precipitation falling over the entire model domain must be assessed this domain includes the ocean circulation model domain the hydrologic model domain and the transition zone bilskie and hagen 2018 between both flooding mechanisms the contribution can be included by means of an increase in the volume of water at the ocean domain and as a surface rainfall runoff computation at the land surface where both flooding mechanisms interact also these contributions can be included by using a tightly coupled technique to introduce the corresponding equations within the hydrodynamic model iii the complete interaction between storm surge and rainfall runoff at the coastal floodplain must be quantified these interactions include storm surge surface runoff storm surge out of bank flow and storm surge streamflow they may be accounted for by means of tight coupling techniques to the authors knowledge no numerical model that considers all possible interactions e g storm surge surface runoff storm surge out of bank flow and storm surge streamflow between both storm surge and rainfall runoff in a single framework has been developed published or employed in practice despite that many researchers have stated that there is an urgent need for such a modeling framework cheng et al 2010 herdman et al 2018 mashriqui et al 2010 2014 orton et al 2012 serafin et al 2019 skinner et al 2015 thompson and frazier 2014 wang et al 2015 a comprehensive compound inundation model that considers all physical processes can describe a more complete interaction between the flooding mechanisms that commonly occur during an extreme event e g hurricanes or typhoons the improvement in describing this interaction can translate into a more realistic simulated total flood hazards in coastal watersheds which affects millions of people around the world this comprehensive compound inundation model can serve as a more accurate complete flood forecast tool that can help decision makers and authorities create better coastal resiliency measurements e g delineation of no build zones and flood insurance map and emergency plans e g identifying evacuation routes for communities and issuing early warning advisories that can save lives and reduce damages to property acknowledgments the authors greatly appreciated the feedback provided by dr madeline foster martinez during the preparation of this article this material is based upon work supported in part by the national science foundation graduate research fellowship program grant no 1452778 the national oceanic and atmospheric administration ecological effects of sea level rise program award no na16nos4780208 the u s department of homeland security award no 2015 st 061 nd0001 01 the gulf research program grp of the national academies of sciences engineering and medicine award no 200000829 the robert wood johnson foundation rwjf award no 200000829 and the louisiana sea grant laborde chair any opinions findings and conclusions or recommendations expressed in this material are those of the author s and do not necessarily reflect the views of the nsf noaa grp rwjf or the louisiana sea grant college program the views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies either expressed or implied of the u s department of homeland security 
