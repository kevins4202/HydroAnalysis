index,text
5520,simulation optimization framework is a widely used approach for numerical model calibrations though its primary difficulty is its high demand of computational efforts in this study bagging mars bmars adapted from multivariate adaptive regression splines mars algorithm is used to construct the surrogate of a three dimensional co2 reservoir model which is developed to simulate co2 injection and migration in a fault compartmentalized underground reservoir the bmars surrogate model is then used in model calibration to estimate specified reservoir model input parameters efficiently the results demonstrate that the bmars model can improve fitting stability and predictive accuracy against the ordinary mars model parameter sensitivity analysis which is efficiently conducted using the bmars model suggest that permeability of fault 10 and caprock dominate the pressure buildup in this fault compartmentalized reservoir hence priority should be given to investment in estimating these two reservoir properties overpressure propagation and co2 migration in the reservoir responding to three years of co2 injection are also analyzed using the calibrated model the calibrated water co2 flow model could be a useful tool to evaluate the future operation and risk assessment of the reservoir the results comparison and sensitivity analysis demonstrated the proposed bmars based simulation optimization framework is an efficient and accurate model calibration approach keywords reservoir model calibration bmars surrogate model co2 sequestration 1 introduction numerical model calibrations usually require execution of the model hundreds of times to reach convergence wang and zeng 1997 johnson and rogers 2001 as the high resolution numerical reservoir models nowadays are computationally demanding in order to track multiple hydrogeological processes in complex subsurface formations with large scale dimensions calibrations could become computationally prohibitive wagner 1995 pulido velazquez et al 2007 dhar and datta 2009 it has been discovered that predicting the outcomes of subsurface models does not necessarily require calling these expensive physical models scheidt et al 2018 alternatively statistical models can be developed as a surrogate to the physical simulator in calibrating process that requires numerous model iterations the surrogate model is trained to learn a statistical relationship between input variables and output variable using a specified approximating algorithm and the training dataset are generated from a suite of physical model simulations jin et al 2001 queipo et al 2005 blatman and sudret 2010 there are many statistical methods such as krigging polynomial regression artificial neural networks radial basis functions support vector machines and sparse grid that have been used to approximate hydrological system models in the last decade fen et al 2009 zhang et al 2009 razavi et al 2012a zeng et al 2012 kourakos and mantoglou 2013 zhang and sahinidis 2013 boyle et al 2015 parametric algorithms such as polynomial and gaussian process assume a uniform global function linking input and output variables on the contrary multivariate adaptive regression spline method mars is a non parametric algorithm and use different types of local models adaptively in different regions of data space jin et al 2001 chen et al 2013 conducted a comparative study and demonstrated that mars is superior than parametric methods in approximating extremely non linear model system recently chen et al 2015 applied mars model to approximate a hydro thermal model for optimization of a geothermal reservoir operation dai et al 2014 introduced mars to approximation of a water oil co2 flow reservoir model for an efficient optimization of co2 geological storage and enhanced oil recovery further jordan et al 2015 and keating et al 2016 used mars to develop surrogate models to quantitatively evaluate leakage risk of co2 sequestrations following the above pioneering studies mars approach has been extensively applied in co2 modeling in the past three years to investigate optimal design geological uncertainty and risk assessment during combined co2 underground storage and utilizations e g ampomah et al 2017 dai et al 2016 2018 bagging is a smoothing operation to reduce variance and is usually used to enhance the stability of prediction during regression bühlmann and yu 2002 bagging mars bmars model is the expectation of an ensemble of mars models which can reduce instability of mars regression breiman 1996 bühlmann 2003 chen et al 2017 2018 made the first successful attempts to use bmars to approximate modflow models harbaugh 2005 niswonger et al 2011 in numerical model calibration and bayesian inference both of which require hundreds or thousands of model runs bmars has shown slightly better performance than mars in terms of discrepancy against the modflow model during both fitting and validation processes prediction of reservoir pressure buildup and associated co2 distribution are crucial for developing and implementing co2 geological storage inappropriate injection scheme and overpressure buildup may trigger fault reactivation hydraulic fracturing and induced seismicity especially for fault bounded reservoirs bauer et al 2016 fault reactivation and caprock failure may lead to leakage of co2 and associated environmental risks rutqvist et al 2016 most studies on co2 migration driven by pressure gradients focused on horizontal directions e g person et al 2010 three dimensional numerical model built upon a real geological structure is important for evaluating pressure propagation and fluid migration for reservoir assessment and risk management during co2 sequestration benisch and bauer 2013 sensitivity analysis of the boundary conditions and hydrogeological parameters can necessary to provide insightful evaluations of their impacts on pressure buildup and co2 migration schäfer et al 2011 following these studies in regression techniques and co2 sequestrations one of main objectives of this study is to develop bmars models to surrogate a multiphase flow model for efficient calibration of a realistic 3 d compartmentalized co2 reservoir model the reservoir model is developed using nuft nonisothermal unsaturated saturated flow and transport a software code developed and maintained by lawrence livermore national laboratory usa nitao 1998 hao et al 2012 in this bmars based calibration framework the expensive reservoir flow model is only used to generate training dataset for development of the bmars model which is instead used in iterative model runs during calibration the performance of bmars versus mars model are both developed compared and quantitatively analyzed using various indices for the co2 reservoir model the other objective of this study is to use the calibrated 3d realistic model to predict the dynamic pressure propagation in the fault compartmentalized reservoir and co2 plume migration under the specified injection scheme both horizontal and vertical co2 distribution are analyzed driven by the pressure gradients sensitivities are quantified efficiently using the bmars based method and six most important parameters are identified and evaluated for their impacts on the pressure and fluid distribution 2 materials and methods in this section the proposed methodology framework is firstly introduced and each component is briefly described according to the flowchart then the main components including physical co2 sequestration model development training data generation surrogate model construction and objective function are detailed in the sub sections 2 1 methodology framework in the proposed calibration methodology fig 1 bmars models are trained by using the dataset acquired from a suite of nuft reservoir model simulations using the same dataset the surrogate models are cross validated to demonstrate the accuracy of predicting the response of the multiphase fluid reservoir system the bmars models are then integrated with an effective optimization algorithm namely bound optimization by quadratic approximation bobyqa powell 2009 to calibrate the reservoir model and access sensitivities of various reservoir properties bobyqa is a derivative free optimizing algorithm particularly efficient for bound constrained problem in this study first of all a co2 flow and transport model is developed using nuft code nitao 1998 to simulate co2 injection and migration in the reservoir the m key hydrogeological properties are identified to be optimized second a suite of representative reservoir simulations is designed as shown in fig 1 n parameter vectors are sampled from the m dimensional space defined by their ranges using latin hypercube lh sampling approach mckay et al 1979 the m parameters ranges considered an indicator of the parameter uncertainties are determined according to various sources including available field data literature reports and expert knowledge each m vector sample value is used to generate a nuft model input file and these n samples results in n reservoir model simulations representing all possible reservoir scenarios within the parameter ranges in this study six input variables m 6 are included in calibration and 600 reservoir models n 600 are simulated to generate dataset for training surrogate models third the objective function the error between simulated and measured reservoir pressure history is evaluated from the outputs of these representative simulations the objective function is used as the output of the surrogate model fourth the n pairs input vector vs the objective function are used as the train dataset to develop bmars surrogate model as illustrated by the shaded part of fig 1 using the same training dataset leave one out cross validation method is applied to validate the fitted surrogate model picard cook 1984 the errors between output of representative simulations of nuft and bmars model are used to assess the quality of the bmars model last the developed surrogate model is integrated with bobyqa optimizer to search minimum of the objective function the described framework is programed in a python code to integrate the nuft reservoir model latin hypercube sampling bmars algorithm and bobyqa optimizer 2 2 co2 reservoir model 2 2 1 reservoir description a reservoir model simulating co2 injection and migration is used to demonstrate the proposed calibration methodology framework the study field is an offshore natural gas reservoir about 150 km off the coast and about 300 m below water surface the produced gas which contains about 6 co2 is delivered to the onshore the separated co2 is transported back to the field through pipeline and re injected into the storage reservoir which is situated below the gas reservoir located at 2560 2670 m below sea level the storage formation is about 110 m thick at location of the injector and sealed by an east west elongated fault block system fig 2 as shown in fig 2b three perforated intervals are located in the lower three high permeable hydrogeological units of the five unit reservoir most co2 81 was injected into lowermost perforation and 9 and 10 co2 in the middle and uppermost perforation respectively the up two perforation storages will be referred as the upper perforation as they are adjacent and the lowermost one will be denoted as the lower perforation hereinafter 2 2 2 geological model and mesh the reservoir model mesh is generated upon the earthvision geologic model built with stratigraphic data earthvision is a software containing a suite of modules for the analysis modeling and visualization of spatial data dynamic graphics inc 2008 as shown in fig 3 the 26 km 8 km 110 m model domain is discretized into 160 80 10 128 000 cells with variable volume and irregular shape using evcell the gridline is defined to conform to two approximately parallel fault 9 and 12 fig 2a as well as horizons of top and bottom layers while such treatments of grid lead to irregularly shaped cells and connections the benefit is that simulated fluid flow through these cell connections can closely approximate realistic flow conditions in addition the size of cells around the injector is specified as small as 50 and 20 m and increases gradually to 500 and 400 m near the boundaries in x and y directions respectively higher vertical resolution is assigned to the layers where the injection well was perforated since these areas are expected to experience high pressure gradient during co2 injection as the caprock and bedrock of reservoir the top layer 1 and bottom layer 10 are both as thin as 2 m as shown in fig 3b blue blocks indicate three perforated intervals of the injector and the corresponding layer 5 6 and 9 are less than 10 m thick the vertical size of cells of other layers varies from 10 to 25 m table 1 2 2 3 numerical flow model nuft code which is equipped with span and wagner 1996 equation of state for co2 is utilized to develop the co2 sequestration model according to their coordinates the faults are overlapped to the corresponding model cells which are assigned with hydrogeological properties of faults fig 4 c shows the various hydrogeological features overlapped on the cells of layer 9 mesh the black filled cells are fault blocks while the yellow and blue cells represent high permeable inner channel noted as layer 9a and moderate permeable outer channel noted as layer 9b of layer 9 which are determined by their delineation shown in fig 4b the idea of delineation of inner and outer channels in layer 9 is inspired by the 4d seismic amplitude changes which are mainly contributed by co2 saturation and pore pressure increase over 6 years of injection of 500 ktons co2 as shown in fig 4a the 4d seismic anomaly indicates that the lower perforation layer is very heterogeneous spatially whereas the inner and outer channel boundaries are very apparent accordingly each of the inner and outer channel areas in lower perforation layer is treated as a homogeneous porous media and assigned a uniform set of effective hydrogeological properties in the reservoir model as a result the lower perforation layer consists of three hydrogeological units i e inner channel outer channel and the remaining part of the layer each of the other nine model layers layer 1 8 10 is treated as a homogeneous unit 2 3 representative simulations lower perforation layer layer 9 is the primary storage reservoir 81 injectivity and is targeted as the core domain of the model simulations the representative nuft models which are executed to generate the training data set for bmars model are supposed to cover reservoir scenarios as complete as possible as shown in table 2 six parameters m 6 in fig 1 are considered sensitive for reservoir pressure buildup and hence included in model calibration that is permeability of fault 10 inner and outer channels and porosity of inner and outer channels the ranges of the six parameters are determined from borehole logs fault 10 is believed partially permeable according to 4d seismic amplitude changes fig 4a which clearly shows that co2 and pressure propagated northward across the fault its permeability could vary from 10 17 to 10 14 m2 for lh sampling layer 7 and 8 between upper and lower perforation layers are low permeable and serve as the caprock for the reservoir the caprock s permeability can significantly affect the reservoir pressure buildup and hence is treated as an uncertain parameter ranging from 10 20 to 10 17 m2 the horizontal mobility of injected co2 depends heavily on the permeability of inner and outer channels which are bounded between 10 12 and 10 10 m2 10 14 and 10 12 m2 respectively the porosity of inner and outer channels could also be sensitive for reservoir pressure buildup due to its limited pore space of this fault compartmentalized reservoir which is sealed by impermeable fault zones as side boundaries low permeable caprock and bedrock layer 10 figs 2 4 the ranges of the porosity are estimated from 0 1 to 0 2 and 0 15 to 0 25 for inner and outer channels respectively besides the six uncertain parameters other deterministic input parameters are estimated from the field measurements the model system is considered to be fully saturated aquifer initially and become a two phase flow system with the co2 injection the temperature remains constant at 95 c throughout the entire reservoir the initial pressures are linearly distributed with the depth p z 0 1046 z 15 054 105 where z p are the depth meter and the pressure pa respectively rock compressibility is estimated as 3 72 10 10 pa 1 permeability of each layer is assumed isotropic and listed with porosity in table 1 in this study 600 samples n 600 in fig 1 are drawn from the 6 dimensional parameter space constrained by their ranges table 2 and used to generate 600 representative models along with the other deterministic input parameters the models simulate daily averaged co2 injection for 3 years fig 5 a these 600 models were distributed to and run on a computing cluster with each cost about 10 h 2 4 bmars model a bagging mars bmars model is developed upon an ensemble of multivariate adaptive regression spline mars models mars models calculate the values of basis functions as well as adaptive effect and interaction between input variables it can be expressed as the following equation friedman 1991 1 f x a 0 i 1 k a i j 1 j i s ji x w j i t ji where m a x 0 a0 and k is the constant coefficient and number of basis function respectively ji stands for the number of base function variables s ji 1 or 1 according to the relative side of the data to the point knots w j i is the index tji is the knots where x split bagging estimator breiman 1996 is the expectation of an ensemble of models that is f bagging e f x for a suite of mars models f b x b 1 2 b bmars model can be approximated using monte carlo method 2 f bagging 1 b b 1 b f b x the accuracy of monte carlos approximation is largely dependent on the constant b the value of which is specified according to the sample size and available computational cost 2 5 objective function in this study normalized root mean square error nrmse between simulated and observed pressures is used as the objective function 3 nrmse t 1 n p t p t 2 n m a x p t where n is the number of observations p t and p t are the tth simulated and measured pressures respectively the observations p t are daily pressure records in 3 years of simulation one year of pressure data after the initial injection wasn t used because large amount of the data in the first year of injection are considered outliers for calibration due to reduced injectivity from precipitated salt fig 5b the modeled p t are output of representative simulations 3 results and discussions 3 1 bmars versus mars model to demonstrate the superiority of the bmars model over the ordinary mars model both surrogate models are constructed and validated using 600 observation pairs input parameters versus objective function nrmse both bmars and mars models consists of six degree of interactions and 50 basis functions the number of instantiations are set as 100 b 100 in eq 2 for bmars model the quality of a surrogate model can be measured by comparison of outputs with the corresponding physical model to compare the quality between bmars and mars scatterplots of 600 objective values nrmse calculated from surrogate versus nuft models are compared between bmars and mars models as shown in fig 6 apparently the 600 markers are clustered more closely along the diagonal line from bmars training and validation than those from mars correspondingly r squares of 600 scatters from bmars training 0 9890 and validation 0 9709 are closer to 1 0 than those from mars training 0 9806 and validation 0 9639 moreover rmses between the bmars and nuft model are smaller than those between mars and the same physical model which are 6 119 10 3 and 8 187 10 3 versus 8 108 10 3 and 1 040 10 2 during training and validation respectively the comparison analysis indicates that bmars model is better than mars regarding accuracy and predictive performance the nash sutcliffe ns coefficient is determined for both surrogate models to ensure that the overfitting is not occurred nikoo et al 2018 which is 0 989 and 0 981 for bmars model and 0 980 and 0 968 for mars model in training and validation stages respectively the bmars model with larger nash sutcliffe value in both training and validation stages suggests that bmars model is slightly superior to mars model 3 2 water co2 flow model calibration the bmars based calibration is implemented by integrating surrogate model to bobyqa optimizer fig 1 as shown in table 2 the log transformed permeability of caprock fault 10 inner and outer channel is optimized as 18 15 89 10 45 and 12 61 respectively the porosity of inner and outer channel is estimated as 0 189 and 0 15 respectively the sensitivity indexes si of the objective to the 6 parameters are also conveniently computed using bmars model table 2 the permeability of fault 10 and caprock are ranked top 2 most sensitive parameters si 100 and 88 followed by permeability of outer and inner channel si 43 and 14 the sensitivity analysis suggests that uncertainties of permeability of caprock fault 10 and outer channel contribute to most of the uncertainty of the reservoir status during co2 injection in contrast porosity of both inner and outer channel have little influence on the objective values si 9 and 12 it makes sense since the objective nrmse is derived from the reservoir pressure which is more sensitive to formation permeability than to porosity the optimal values are found after 321 times of bmars model runs corresponding to the minimal objective function shown in the search curve fig 7 a table 2 lists the optimal values for parameters included in calibrations using both bmars and mars surrogate models which costs only several minutes the minimized objective function value is 1 189 10 3 and 2 069 10 3 and the required model runs are 321 and 483 times for bmars and mars respectively furtherly suggesting bmars has better performance for optimization procedure note the single nuft model simulation needs 10 h using the same computer additional surrogate models can be constructed using the same training dataset suggesting super flexibility of the method for instance overpressure or co2 saturation in the reservoir could be used as the response of bmars model for fast prediction fig 7b visualizes the trend of the objective function values with the log permeability of caprock and fault 10 the two most sensitive input parameters on a 2 d response surface it is shown that the local minimal objective values are distributed along a curved strip the global minimum is successfully found at 18 0 15 89 using the proposed calibration methodology 3 3 maximum reservoir overpressure one of the critical issues for a fault compartmentalized reservoir is the overpressure buildup with the continuous co2 injection faults might be activated if the maximum overpressure is beyond the fracture pressure threshold one of the advantages of the surrogate based method is the high flexibility and efficiency to develop various surrogate models once the representative physical model simulations are done in addition to nrmse maximum reservoir overpressure is defined as the response variable for a new bmars model which is used to conduct its sensitivity analysis to the 6 uncertain input parameters the sensitivity index of the 6 parameters for maximum overpressure dp follows the same ranking sequence as that for nrmse as shown in table 2 the permeability of fault 10 and caprock dominate the uncertainty contribution to the overpressure uncertainty the permeability of outer channel is moderate sensitive while the other three parameters are insensitive this result is expected as both mrmse and maximum overpressure are calculated from reservoir pressures whereas the standard deviations of the sensitivities of maximum overpressure are significantly smaller than those of nrmse note that bmars method in our study uses the bootstrap expectation of 100 mars approximations which is implemented by monte carlo method so each sensitivity value comes with a mean and standard deviation to investigate how maximum overpressure could vary with the three most sensitive input parameters 3 d response surface of maximum overpressure corresponding to the permeability of fault 10 caprock and outer channel is generated using bmars model five horizontal and vertical slices of the 3d plot are presented in fig 8 it is seen that the lower the permeability of the three units the higher the maximum overpressure buildup the maximum overpressure would reach as high as 50 mpa if the three units permeability were all at their low bounds 3 4 overpressure propagation and co2 migration analysis using the calibrated nuft model overpressure buildup and co2 migration in response to the 3 years of co2 injection fig 5a in the reservoir is simulated the propagation of overpressure on the lower perforation layer is illustrated by the contour snapshots at 0 200 400 600 and 1095 days of co2 injection as shown in fig 9 the overpressure propagates in this fault compartmentalized reservoir along the elongated east west fault system with fault 9 as the north bound and fault 13 to 15 as the south bound fault identification number can be found in fig 2a after 200 days of injection the overpressure penetrates the permeable fault 10 westwards and propagates out of the outer channel compared to the snapshot on day 400 it is notable that on day 600 overpressure within the inner and outer channels is fading due to 100 days of non injection before the 600th day however overpressure keeps propagating and hits both the east and west ends of the central compartment the east end is a dead end sealed by impermeable faults so the overpressure propagation is stopped here and begins buildup in contrast the west end is open in both south and north bounds as expected both northbound and southbound overpressure propagation at the west end are observed as shown in fig 9d on the 1095th day 3 years at the west end of central compartment the northbound overpressure reaches the north boundary of the model and propagates mainly eastward along north side of fault 9 in the north compartment on the other hand the south bound overpressure bounces from the south boundary of the model and fault 23 this part of overpressure escapes through the narrow mouth between fault 13 and 19 and find its way eastward along the south side of fault 13 in the south compartment note the model is a closed system and all the boundaries are impermeable unlike overpressure propagation co2 migration is mostly restricted within the inner channel as indicated by co2 saturation contour maps of the lower perforation layer on day 300 and 1095 by fig 10 the saturation contour maps look very similar to 4d seismic difference amplitude map fig 4a demonstrating the adequacy of the proposed inner outer channel concept model and accuracy of the corresponding calibrated numerical model although the study is focused on lower perforation layer which is the major co2 storage 81 injectivity the calibrated model also simulates the co2 injection into the upper perforation layer 19 injectivity fig 11 shows the co2 saturation distribution on the yz vertical slice across the injector since the caprock layer 4 overlaying the upper perforation layer 5 6 is moderately permeable 5 1 10 14 m2 co2 migrates horizontally as well as upward under the buoyance force 4 summary and conclusions in this study a 3d realistic co2 sequestration numerical model capable of simulating complicated multiphase flow and transport in a fault compartmentalized reservoir is developed using nuft code for the first time a bmars based optimization framework is developed and successfully applied to calibrate the developed co2 sequestration model in a fault compartmentalized reservoir the developed bmars based calibration method provides an efficient way for complex model calibration and a flexible tool for realistic underground reservoir pressure analysis and fluid migration analysis the main conclusions are as follows the proposed calibration approach is demonstrated efficient the optimizing process calls the surrogate model 321 times and are completed in a minute while a single nuft simulation costs about 10 h using the same computer besides stability and accuracy of bmars over the ordinary mars is demonstrated by comparison analysis bmars model using maximum overpressure as the response variable in addition to nrmse as the response variable for model calibration is conveniently developed for efficient sensitive analysis and response surface analysis by using the same dataset generated from the nuft model the permeability of fault 10 caprock and outer channel are ranked the top 3 sensitive parameters for reservoir overpressure buildup and the maximum overpressure could reach 50 mpa if all the three parameters are on their low bounds the simulation using the calibrated nuft model shows that the pressure continues to propagate in east west directions within the central compartment the pressure begins buildup at the dead east end but bounces back from the west end which is open in both south and north and propagates into the south and north compartments and moves eastward in contrast co2 migration is mainly limited within inner channel of the central compartment the saturation pattern is similar to seismic difference amplitude justifying the inner outer channel concept in developing the nuft model it should be noted that the definition of sampling parameter space is very critical to the performance of the proposed methodology the ranges of each input parameter significantly influence the sensitivity and even optimized results every possible data source as well as experts knowledge should be carefully incorporated in determining the parameter ranges the developed surrogate model is only working in the defined ranges and cannot be used in extrapolated ranges as bmars is a data driven surrogate model by capturing the input output map the bmars based calibration framework is model independent and can be conveniently coupled with any hydrogeological system model as a black box in contrast projection based surrogates or multi fidelity surrogates are intrusive methods dealing with governing equations of the physical models asher et al 2015 although these two lower fidelity surrogates might be more efficient than data driven surrogates their applications to hydrogeological problems are very limited due to this model dependent feature razavi et al 2012b credit authorship contribution statement mingjie chen conceptualization methodology formal analysis writing original draft osman a abdalla resources project administration azizallah izady data curation mohammad reza nikoo visualization ali al maktoumi writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded by bp oman under contract bp dvc wrc 18 01 we acknowledge the support on management and computing facility from water research center at sultan qaboos university appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124798 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5520,simulation optimization framework is a widely used approach for numerical model calibrations though its primary difficulty is its high demand of computational efforts in this study bagging mars bmars adapted from multivariate adaptive regression splines mars algorithm is used to construct the surrogate of a three dimensional co2 reservoir model which is developed to simulate co2 injection and migration in a fault compartmentalized underground reservoir the bmars surrogate model is then used in model calibration to estimate specified reservoir model input parameters efficiently the results demonstrate that the bmars model can improve fitting stability and predictive accuracy against the ordinary mars model parameter sensitivity analysis which is efficiently conducted using the bmars model suggest that permeability of fault 10 and caprock dominate the pressure buildup in this fault compartmentalized reservoir hence priority should be given to investment in estimating these two reservoir properties overpressure propagation and co2 migration in the reservoir responding to three years of co2 injection are also analyzed using the calibrated model the calibrated water co2 flow model could be a useful tool to evaluate the future operation and risk assessment of the reservoir the results comparison and sensitivity analysis demonstrated the proposed bmars based simulation optimization framework is an efficient and accurate model calibration approach keywords reservoir model calibration bmars surrogate model co2 sequestration 1 introduction numerical model calibrations usually require execution of the model hundreds of times to reach convergence wang and zeng 1997 johnson and rogers 2001 as the high resolution numerical reservoir models nowadays are computationally demanding in order to track multiple hydrogeological processes in complex subsurface formations with large scale dimensions calibrations could become computationally prohibitive wagner 1995 pulido velazquez et al 2007 dhar and datta 2009 it has been discovered that predicting the outcomes of subsurface models does not necessarily require calling these expensive physical models scheidt et al 2018 alternatively statistical models can be developed as a surrogate to the physical simulator in calibrating process that requires numerous model iterations the surrogate model is trained to learn a statistical relationship between input variables and output variable using a specified approximating algorithm and the training dataset are generated from a suite of physical model simulations jin et al 2001 queipo et al 2005 blatman and sudret 2010 there are many statistical methods such as krigging polynomial regression artificial neural networks radial basis functions support vector machines and sparse grid that have been used to approximate hydrological system models in the last decade fen et al 2009 zhang et al 2009 razavi et al 2012a zeng et al 2012 kourakos and mantoglou 2013 zhang and sahinidis 2013 boyle et al 2015 parametric algorithms such as polynomial and gaussian process assume a uniform global function linking input and output variables on the contrary multivariate adaptive regression spline method mars is a non parametric algorithm and use different types of local models adaptively in different regions of data space jin et al 2001 chen et al 2013 conducted a comparative study and demonstrated that mars is superior than parametric methods in approximating extremely non linear model system recently chen et al 2015 applied mars model to approximate a hydro thermal model for optimization of a geothermal reservoir operation dai et al 2014 introduced mars to approximation of a water oil co2 flow reservoir model for an efficient optimization of co2 geological storage and enhanced oil recovery further jordan et al 2015 and keating et al 2016 used mars to develop surrogate models to quantitatively evaluate leakage risk of co2 sequestrations following the above pioneering studies mars approach has been extensively applied in co2 modeling in the past three years to investigate optimal design geological uncertainty and risk assessment during combined co2 underground storage and utilizations e g ampomah et al 2017 dai et al 2016 2018 bagging is a smoothing operation to reduce variance and is usually used to enhance the stability of prediction during regression bühlmann and yu 2002 bagging mars bmars model is the expectation of an ensemble of mars models which can reduce instability of mars regression breiman 1996 bühlmann 2003 chen et al 2017 2018 made the first successful attempts to use bmars to approximate modflow models harbaugh 2005 niswonger et al 2011 in numerical model calibration and bayesian inference both of which require hundreds or thousands of model runs bmars has shown slightly better performance than mars in terms of discrepancy against the modflow model during both fitting and validation processes prediction of reservoir pressure buildup and associated co2 distribution are crucial for developing and implementing co2 geological storage inappropriate injection scheme and overpressure buildup may trigger fault reactivation hydraulic fracturing and induced seismicity especially for fault bounded reservoirs bauer et al 2016 fault reactivation and caprock failure may lead to leakage of co2 and associated environmental risks rutqvist et al 2016 most studies on co2 migration driven by pressure gradients focused on horizontal directions e g person et al 2010 three dimensional numerical model built upon a real geological structure is important for evaluating pressure propagation and fluid migration for reservoir assessment and risk management during co2 sequestration benisch and bauer 2013 sensitivity analysis of the boundary conditions and hydrogeological parameters can necessary to provide insightful evaluations of their impacts on pressure buildup and co2 migration schäfer et al 2011 following these studies in regression techniques and co2 sequestrations one of main objectives of this study is to develop bmars models to surrogate a multiphase flow model for efficient calibration of a realistic 3 d compartmentalized co2 reservoir model the reservoir model is developed using nuft nonisothermal unsaturated saturated flow and transport a software code developed and maintained by lawrence livermore national laboratory usa nitao 1998 hao et al 2012 in this bmars based calibration framework the expensive reservoir flow model is only used to generate training dataset for development of the bmars model which is instead used in iterative model runs during calibration the performance of bmars versus mars model are both developed compared and quantitatively analyzed using various indices for the co2 reservoir model the other objective of this study is to use the calibrated 3d realistic model to predict the dynamic pressure propagation in the fault compartmentalized reservoir and co2 plume migration under the specified injection scheme both horizontal and vertical co2 distribution are analyzed driven by the pressure gradients sensitivities are quantified efficiently using the bmars based method and six most important parameters are identified and evaluated for their impacts on the pressure and fluid distribution 2 materials and methods in this section the proposed methodology framework is firstly introduced and each component is briefly described according to the flowchart then the main components including physical co2 sequestration model development training data generation surrogate model construction and objective function are detailed in the sub sections 2 1 methodology framework in the proposed calibration methodology fig 1 bmars models are trained by using the dataset acquired from a suite of nuft reservoir model simulations using the same dataset the surrogate models are cross validated to demonstrate the accuracy of predicting the response of the multiphase fluid reservoir system the bmars models are then integrated with an effective optimization algorithm namely bound optimization by quadratic approximation bobyqa powell 2009 to calibrate the reservoir model and access sensitivities of various reservoir properties bobyqa is a derivative free optimizing algorithm particularly efficient for bound constrained problem in this study first of all a co2 flow and transport model is developed using nuft code nitao 1998 to simulate co2 injection and migration in the reservoir the m key hydrogeological properties are identified to be optimized second a suite of representative reservoir simulations is designed as shown in fig 1 n parameter vectors are sampled from the m dimensional space defined by their ranges using latin hypercube lh sampling approach mckay et al 1979 the m parameters ranges considered an indicator of the parameter uncertainties are determined according to various sources including available field data literature reports and expert knowledge each m vector sample value is used to generate a nuft model input file and these n samples results in n reservoir model simulations representing all possible reservoir scenarios within the parameter ranges in this study six input variables m 6 are included in calibration and 600 reservoir models n 600 are simulated to generate dataset for training surrogate models third the objective function the error between simulated and measured reservoir pressure history is evaluated from the outputs of these representative simulations the objective function is used as the output of the surrogate model fourth the n pairs input vector vs the objective function are used as the train dataset to develop bmars surrogate model as illustrated by the shaded part of fig 1 using the same training dataset leave one out cross validation method is applied to validate the fitted surrogate model picard cook 1984 the errors between output of representative simulations of nuft and bmars model are used to assess the quality of the bmars model last the developed surrogate model is integrated with bobyqa optimizer to search minimum of the objective function the described framework is programed in a python code to integrate the nuft reservoir model latin hypercube sampling bmars algorithm and bobyqa optimizer 2 2 co2 reservoir model 2 2 1 reservoir description a reservoir model simulating co2 injection and migration is used to demonstrate the proposed calibration methodology framework the study field is an offshore natural gas reservoir about 150 km off the coast and about 300 m below water surface the produced gas which contains about 6 co2 is delivered to the onshore the separated co2 is transported back to the field through pipeline and re injected into the storage reservoir which is situated below the gas reservoir located at 2560 2670 m below sea level the storage formation is about 110 m thick at location of the injector and sealed by an east west elongated fault block system fig 2 as shown in fig 2b three perforated intervals are located in the lower three high permeable hydrogeological units of the five unit reservoir most co2 81 was injected into lowermost perforation and 9 and 10 co2 in the middle and uppermost perforation respectively the up two perforation storages will be referred as the upper perforation as they are adjacent and the lowermost one will be denoted as the lower perforation hereinafter 2 2 2 geological model and mesh the reservoir model mesh is generated upon the earthvision geologic model built with stratigraphic data earthvision is a software containing a suite of modules for the analysis modeling and visualization of spatial data dynamic graphics inc 2008 as shown in fig 3 the 26 km 8 km 110 m model domain is discretized into 160 80 10 128 000 cells with variable volume and irregular shape using evcell the gridline is defined to conform to two approximately parallel fault 9 and 12 fig 2a as well as horizons of top and bottom layers while such treatments of grid lead to irregularly shaped cells and connections the benefit is that simulated fluid flow through these cell connections can closely approximate realistic flow conditions in addition the size of cells around the injector is specified as small as 50 and 20 m and increases gradually to 500 and 400 m near the boundaries in x and y directions respectively higher vertical resolution is assigned to the layers where the injection well was perforated since these areas are expected to experience high pressure gradient during co2 injection as the caprock and bedrock of reservoir the top layer 1 and bottom layer 10 are both as thin as 2 m as shown in fig 3b blue blocks indicate three perforated intervals of the injector and the corresponding layer 5 6 and 9 are less than 10 m thick the vertical size of cells of other layers varies from 10 to 25 m table 1 2 2 3 numerical flow model nuft code which is equipped with span and wagner 1996 equation of state for co2 is utilized to develop the co2 sequestration model according to their coordinates the faults are overlapped to the corresponding model cells which are assigned with hydrogeological properties of faults fig 4 c shows the various hydrogeological features overlapped on the cells of layer 9 mesh the black filled cells are fault blocks while the yellow and blue cells represent high permeable inner channel noted as layer 9a and moderate permeable outer channel noted as layer 9b of layer 9 which are determined by their delineation shown in fig 4b the idea of delineation of inner and outer channels in layer 9 is inspired by the 4d seismic amplitude changes which are mainly contributed by co2 saturation and pore pressure increase over 6 years of injection of 500 ktons co2 as shown in fig 4a the 4d seismic anomaly indicates that the lower perforation layer is very heterogeneous spatially whereas the inner and outer channel boundaries are very apparent accordingly each of the inner and outer channel areas in lower perforation layer is treated as a homogeneous porous media and assigned a uniform set of effective hydrogeological properties in the reservoir model as a result the lower perforation layer consists of three hydrogeological units i e inner channel outer channel and the remaining part of the layer each of the other nine model layers layer 1 8 10 is treated as a homogeneous unit 2 3 representative simulations lower perforation layer layer 9 is the primary storage reservoir 81 injectivity and is targeted as the core domain of the model simulations the representative nuft models which are executed to generate the training data set for bmars model are supposed to cover reservoir scenarios as complete as possible as shown in table 2 six parameters m 6 in fig 1 are considered sensitive for reservoir pressure buildup and hence included in model calibration that is permeability of fault 10 inner and outer channels and porosity of inner and outer channels the ranges of the six parameters are determined from borehole logs fault 10 is believed partially permeable according to 4d seismic amplitude changes fig 4a which clearly shows that co2 and pressure propagated northward across the fault its permeability could vary from 10 17 to 10 14 m2 for lh sampling layer 7 and 8 between upper and lower perforation layers are low permeable and serve as the caprock for the reservoir the caprock s permeability can significantly affect the reservoir pressure buildup and hence is treated as an uncertain parameter ranging from 10 20 to 10 17 m2 the horizontal mobility of injected co2 depends heavily on the permeability of inner and outer channels which are bounded between 10 12 and 10 10 m2 10 14 and 10 12 m2 respectively the porosity of inner and outer channels could also be sensitive for reservoir pressure buildup due to its limited pore space of this fault compartmentalized reservoir which is sealed by impermeable fault zones as side boundaries low permeable caprock and bedrock layer 10 figs 2 4 the ranges of the porosity are estimated from 0 1 to 0 2 and 0 15 to 0 25 for inner and outer channels respectively besides the six uncertain parameters other deterministic input parameters are estimated from the field measurements the model system is considered to be fully saturated aquifer initially and become a two phase flow system with the co2 injection the temperature remains constant at 95 c throughout the entire reservoir the initial pressures are linearly distributed with the depth p z 0 1046 z 15 054 105 where z p are the depth meter and the pressure pa respectively rock compressibility is estimated as 3 72 10 10 pa 1 permeability of each layer is assumed isotropic and listed with porosity in table 1 in this study 600 samples n 600 in fig 1 are drawn from the 6 dimensional parameter space constrained by their ranges table 2 and used to generate 600 representative models along with the other deterministic input parameters the models simulate daily averaged co2 injection for 3 years fig 5 a these 600 models were distributed to and run on a computing cluster with each cost about 10 h 2 4 bmars model a bagging mars bmars model is developed upon an ensemble of multivariate adaptive regression spline mars models mars models calculate the values of basis functions as well as adaptive effect and interaction between input variables it can be expressed as the following equation friedman 1991 1 f x a 0 i 1 k a i j 1 j i s ji x w j i t ji where m a x 0 a0 and k is the constant coefficient and number of basis function respectively ji stands for the number of base function variables s ji 1 or 1 according to the relative side of the data to the point knots w j i is the index tji is the knots where x split bagging estimator breiman 1996 is the expectation of an ensemble of models that is f bagging e f x for a suite of mars models f b x b 1 2 b bmars model can be approximated using monte carlo method 2 f bagging 1 b b 1 b f b x the accuracy of monte carlos approximation is largely dependent on the constant b the value of which is specified according to the sample size and available computational cost 2 5 objective function in this study normalized root mean square error nrmse between simulated and observed pressures is used as the objective function 3 nrmse t 1 n p t p t 2 n m a x p t where n is the number of observations p t and p t are the tth simulated and measured pressures respectively the observations p t are daily pressure records in 3 years of simulation one year of pressure data after the initial injection wasn t used because large amount of the data in the first year of injection are considered outliers for calibration due to reduced injectivity from precipitated salt fig 5b the modeled p t are output of representative simulations 3 results and discussions 3 1 bmars versus mars model to demonstrate the superiority of the bmars model over the ordinary mars model both surrogate models are constructed and validated using 600 observation pairs input parameters versus objective function nrmse both bmars and mars models consists of six degree of interactions and 50 basis functions the number of instantiations are set as 100 b 100 in eq 2 for bmars model the quality of a surrogate model can be measured by comparison of outputs with the corresponding physical model to compare the quality between bmars and mars scatterplots of 600 objective values nrmse calculated from surrogate versus nuft models are compared between bmars and mars models as shown in fig 6 apparently the 600 markers are clustered more closely along the diagonal line from bmars training and validation than those from mars correspondingly r squares of 600 scatters from bmars training 0 9890 and validation 0 9709 are closer to 1 0 than those from mars training 0 9806 and validation 0 9639 moreover rmses between the bmars and nuft model are smaller than those between mars and the same physical model which are 6 119 10 3 and 8 187 10 3 versus 8 108 10 3 and 1 040 10 2 during training and validation respectively the comparison analysis indicates that bmars model is better than mars regarding accuracy and predictive performance the nash sutcliffe ns coefficient is determined for both surrogate models to ensure that the overfitting is not occurred nikoo et al 2018 which is 0 989 and 0 981 for bmars model and 0 980 and 0 968 for mars model in training and validation stages respectively the bmars model with larger nash sutcliffe value in both training and validation stages suggests that bmars model is slightly superior to mars model 3 2 water co2 flow model calibration the bmars based calibration is implemented by integrating surrogate model to bobyqa optimizer fig 1 as shown in table 2 the log transformed permeability of caprock fault 10 inner and outer channel is optimized as 18 15 89 10 45 and 12 61 respectively the porosity of inner and outer channel is estimated as 0 189 and 0 15 respectively the sensitivity indexes si of the objective to the 6 parameters are also conveniently computed using bmars model table 2 the permeability of fault 10 and caprock are ranked top 2 most sensitive parameters si 100 and 88 followed by permeability of outer and inner channel si 43 and 14 the sensitivity analysis suggests that uncertainties of permeability of caprock fault 10 and outer channel contribute to most of the uncertainty of the reservoir status during co2 injection in contrast porosity of both inner and outer channel have little influence on the objective values si 9 and 12 it makes sense since the objective nrmse is derived from the reservoir pressure which is more sensitive to formation permeability than to porosity the optimal values are found after 321 times of bmars model runs corresponding to the minimal objective function shown in the search curve fig 7 a table 2 lists the optimal values for parameters included in calibrations using both bmars and mars surrogate models which costs only several minutes the minimized objective function value is 1 189 10 3 and 2 069 10 3 and the required model runs are 321 and 483 times for bmars and mars respectively furtherly suggesting bmars has better performance for optimization procedure note the single nuft model simulation needs 10 h using the same computer additional surrogate models can be constructed using the same training dataset suggesting super flexibility of the method for instance overpressure or co2 saturation in the reservoir could be used as the response of bmars model for fast prediction fig 7b visualizes the trend of the objective function values with the log permeability of caprock and fault 10 the two most sensitive input parameters on a 2 d response surface it is shown that the local minimal objective values are distributed along a curved strip the global minimum is successfully found at 18 0 15 89 using the proposed calibration methodology 3 3 maximum reservoir overpressure one of the critical issues for a fault compartmentalized reservoir is the overpressure buildup with the continuous co2 injection faults might be activated if the maximum overpressure is beyond the fracture pressure threshold one of the advantages of the surrogate based method is the high flexibility and efficiency to develop various surrogate models once the representative physical model simulations are done in addition to nrmse maximum reservoir overpressure is defined as the response variable for a new bmars model which is used to conduct its sensitivity analysis to the 6 uncertain input parameters the sensitivity index of the 6 parameters for maximum overpressure dp follows the same ranking sequence as that for nrmse as shown in table 2 the permeability of fault 10 and caprock dominate the uncertainty contribution to the overpressure uncertainty the permeability of outer channel is moderate sensitive while the other three parameters are insensitive this result is expected as both mrmse and maximum overpressure are calculated from reservoir pressures whereas the standard deviations of the sensitivities of maximum overpressure are significantly smaller than those of nrmse note that bmars method in our study uses the bootstrap expectation of 100 mars approximations which is implemented by monte carlo method so each sensitivity value comes with a mean and standard deviation to investigate how maximum overpressure could vary with the three most sensitive input parameters 3 d response surface of maximum overpressure corresponding to the permeability of fault 10 caprock and outer channel is generated using bmars model five horizontal and vertical slices of the 3d plot are presented in fig 8 it is seen that the lower the permeability of the three units the higher the maximum overpressure buildup the maximum overpressure would reach as high as 50 mpa if the three units permeability were all at their low bounds 3 4 overpressure propagation and co2 migration analysis using the calibrated nuft model overpressure buildup and co2 migration in response to the 3 years of co2 injection fig 5a in the reservoir is simulated the propagation of overpressure on the lower perforation layer is illustrated by the contour snapshots at 0 200 400 600 and 1095 days of co2 injection as shown in fig 9 the overpressure propagates in this fault compartmentalized reservoir along the elongated east west fault system with fault 9 as the north bound and fault 13 to 15 as the south bound fault identification number can be found in fig 2a after 200 days of injection the overpressure penetrates the permeable fault 10 westwards and propagates out of the outer channel compared to the snapshot on day 400 it is notable that on day 600 overpressure within the inner and outer channels is fading due to 100 days of non injection before the 600th day however overpressure keeps propagating and hits both the east and west ends of the central compartment the east end is a dead end sealed by impermeable faults so the overpressure propagation is stopped here and begins buildup in contrast the west end is open in both south and north bounds as expected both northbound and southbound overpressure propagation at the west end are observed as shown in fig 9d on the 1095th day 3 years at the west end of central compartment the northbound overpressure reaches the north boundary of the model and propagates mainly eastward along north side of fault 9 in the north compartment on the other hand the south bound overpressure bounces from the south boundary of the model and fault 23 this part of overpressure escapes through the narrow mouth between fault 13 and 19 and find its way eastward along the south side of fault 13 in the south compartment note the model is a closed system and all the boundaries are impermeable unlike overpressure propagation co2 migration is mostly restricted within the inner channel as indicated by co2 saturation contour maps of the lower perforation layer on day 300 and 1095 by fig 10 the saturation contour maps look very similar to 4d seismic difference amplitude map fig 4a demonstrating the adequacy of the proposed inner outer channel concept model and accuracy of the corresponding calibrated numerical model although the study is focused on lower perforation layer which is the major co2 storage 81 injectivity the calibrated model also simulates the co2 injection into the upper perforation layer 19 injectivity fig 11 shows the co2 saturation distribution on the yz vertical slice across the injector since the caprock layer 4 overlaying the upper perforation layer 5 6 is moderately permeable 5 1 10 14 m2 co2 migrates horizontally as well as upward under the buoyance force 4 summary and conclusions in this study a 3d realistic co2 sequestration numerical model capable of simulating complicated multiphase flow and transport in a fault compartmentalized reservoir is developed using nuft code for the first time a bmars based optimization framework is developed and successfully applied to calibrate the developed co2 sequestration model in a fault compartmentalized reservoir the developed bmars based calibration method provides an efficient way for complex model calibration and a flexible tool for realistic underground reservoir pressure analysis and fluid migration analysis the main conclusions are as follows the proposed calibration approach is demonstrated efficient the optimizing process calls the surrogate model 321 times and are completed in a minute while a single nuft simulation costs about 10 h using the same computer besides stability and accuracy of bmars over the ordinary mars is demonstrated by comparison analysis bmars model using maximum overpressure as the response variable in addition to nrmse as the response variable for model calibration is conveniently developed for efficient sensitive analysis and response surface analysis by using the same dataset generated from the nuft model the permeability of fault 10 caprock and outer channel are ranked the top 3 sensitive parameters for reservoir overpressure buildup and the maximum overpressure could reach 50 mpa if all the three parameters are on their low bounds the simulation using the calibrated nuft model shows that the pressure continues to propagate in east west directions within the central compartment the pressure begins buildup at the dead east end but bounces back from the west end which is open in both south and north and propagates into the south and north compartments and moves eastward in contrast co2 migration is mainly limited within inner channel of the central compartment the saturation pattern is similar to seismic difference amplitude justifying the inner outer channel concept in developing the nuft model it should be noted that the definition of sampling parameter space is very critical to the performance of the proposed methodology the ranges of each input parameter significantly influence the sensitivity and even optimized results every possible data source as well as experts knowledge should be carefully incorporated in determining the parameter ranges the developed surrogate model is only working in the defined ranges and cannot be used in extrapolated ranges as bmars is a data driven surrogate model by capturing the input output map the bmars based calibration framework is model independent and can be conveniently coupled with any hydrogeological system model as a black box in contrast projection based surrogates or multi fidelity surrogates are intrusive methods dealing with governing equations of the physical models asher et al 2015 although these two lower fidelity surrogates might be more efficient than data driven surrogates their applications to hydrogeological problems are very limited due to this model dependent feature razavi et al 2012b credit authorship contribution statement mingjie chen conceptualization methodology formal analysis writing original draft osman a abdalla resources project administration azizallah izady data curation mohammad reza nikoo visualization ali al maktoumi writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded by bp oman under contract bp dvc wrc 18 01 we acknowledge the support on management and computing facility from water research center at sultan qaboos university appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124798 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5521,soil moisture is one of the restricting factors in a fragile karst ecological environment however its spatiotemporal evolution characteristics in the karst areas of china remain poorly understood thus based on soil moisture from reanalysis era interim product and ground stations this study used the mann kendall test the theil sen slope estimator sensitivity analysis and stepwise regression and obtained the following results 1 era interim soil moisture well reflected the interannual change of observational soil moisture at 0 7 7 28 and 28 100 cm 2 the reanalysis and station data showed that soil at various depths in the karst areas was dominated by a drying trend in 1982 2015 3 soil moisture in karst areas of southern china was high but decreased fastest in the karst areas of northern china soil moisture was low and declined quickly nevertheless soil wetting was observed in the central karst areas of qinghai tibet plateau 4 changes of soil moisture throughout the karst region of china and its subareas were mainly affected by precipitation followed by temperature 5 in qinghai tibet plateau and southern china soil moisture in karst areas is overall higher than that in non karst areas when under low vegetation coverage levels ndvi 0 3 of some climate zones possibly caused by the centralized allocation of precipitation in karst areas due to exposed rocks in conclusion climate vegetation and geological background make the spatiotemporal distributions of soil moisture differ within the karst region while the soil drying trend in recent decades and global climate change are not conducive to the ecological restoration of vulnerable karst areas keywords karst soil moisture china climate ndvi sensitivity analysis 1 introduction soil moisture sm is one of the important components of soil that affects crop growth vegetation distribution pattern and soil microbial activities dunn et al 1985 moyano et al 2013 xia and shao 2008 the migration of soil matter stielstra et al 2015 and the absorption and decomposition of terrestrial carbon are inseparable from the role of sm green et al 2019 besides sm functions as the link between surface water and groundwater the dynamics of sm influence surface energy allocation evapotranspiration processes and are important for research on hydrological processes and climate prediction deng 2020 wang 2018 to date international research on the spatiotemporal dynamics of sm has focused on surface soil at a global scale mccoll et al 2017a b sheffield and wood 2008 particularly under the condition of global warming dai 2013 knowledge gaps exist in china s karst region where sm is a limiting factor in the ecological restoration of soil and plant the shortage of soil water resources seriously impacts the local ecological environment and agricultural production qin et al 2015 karst is a unique combination of aboveground and underground geomorphology produced by the water chemical dissolution of soluble rocks such as carbonate rocks and is generally characterized by barren and rocky grounds caves and sinkholes li 2018 parise et al 2015 under the special geological background karst possesses surface and underground water systems which are connected by hydraulic connection as a whole and with considerable surface water seepage its hydrological characteristics are different from these of non karst areas bailly comte et al 2009 ecosystem in a typical karst region is weakly resistant to external disturbances bai et al 2013 particularly in the karst areas of southwestern china tian et al 2016 in these areas soil erosion is severe soil thin and vegetation coverage low febles et al 2009 thereby resulting in a fragile soil environment and frequent temporary droughts deng 2018 ge and wang 2008 previous studies have suggested that sm is a major constraint factor in karst ecosystems and the role of sm in facilitating the ecological restoration and agricultural industrialization in the karst area has been investigated hartmann et al 2014 current research focuses on the spatial characteristics of sm in karst areas chen et al 2010 studied the distribution differences of sm under different land use in a karst slope li et al 2014 revealed the influence of rock exposure on the spatial distribution of sm liu et al 2017 analyzed the spatial movement characteristics of sm on the grass slope of a karst peak cluster area however without comparing with results from non karst areas it is unclear whether sm in karst areas has unique characteristics furthermore a few studies about the trend of sm change in karst areas are primarily carried out on the scales of slope and small watershed chen et al 2010 fu et al 2016 the geological hydrological background of karst such as slow soil formation rate and space mismatch between water and soil leads to the strong spatial heterogeneity of sm li et al 2014 mccole and stern 2007 consequently the conclusions of these previous studies are uncertain in large scale karst areas in addition the interannual variation of sm is affected by various factors including temperature precipitation and vegetation the effects of these factors on sm vary under different spatiotemporal circumstances many scholars found that recent rising in global temperature was the dominant factor causing global soil drying dai 2013 feng and fu 2013 that precipitation controlled the drying trend of sm from 1979 to 2010 in china jia et al 2018 and that vegetation restoration brought about the decline of sm in the loess plateau of china su and shangguan 2019 therefore it s necessary to study the effects of climate and vegetation on sm change in karst areas promoting water and soil conservation and ecological restoration here this paper aims to explore the spatial and temporal characteristics of sm in the karst areas of china in 1982 2015 the concrete objectives are as follows 1 evaluate the reliability of sm from reanalysis product era interim at different depths 2 reveal the spatial distributions and change trends of sm in the karst region of china by using reanalysis and observations data 3 analyze the effects of the normalized difference vegetation index ndvi precipitation and temperature on sm based on sensitivity analysis and stepwise regression and 4 discover sm differences between karst and non karst areas in china 2 data and methods 2 1 data and preprocessing sm product from era interim reanalysis was provided by the european center for medium range weather forecasts ecmwf with spatial and temporal resolutions of 0 125 and monthly respectively https www ecmwf int which has four sm layers 0 7 7 28 28 100 and 100 289 cm the product was previously applied to the analysis of spatiotemporal changes in sm hydrometeorology and numerical simulation deng 2020 materia 2014 xia 2014 also era interim reanalysis data included precipitation and temperature data with the same spatial and temporal resolutions as the sm product the observational sm data were obtained from the international soil moisture network ismn which collects free and high quality in situ sm data worldwide http www ipf tuwien ac at dorigo et al 2011 however the temporal resolution and time length of observation stations vary deng et al 2019 gimms ndvi3g 1982 2015 https ecocast arc nasa gov data pub gimms with spatial and temporal resolutions of 8 km and 15 days respectively was also used in this study yang et al 2019 the actual soil thickness in typical karst areas is usually less than 1 m therefore sm product and site measured data at 0 7 7 28 and 28 100 cm were used in this study temporal resolutions of sm precipitation temperature and ndvi data were converted to the annual scale and among them spatial resolutions of gridded data were interpolated to 0 125 the time coverage for observational sm in china from ismn was mostly 1981 1999 2010 2016 and 2008 2010 with the monitoring times typically on the 8th 18th and 28th of each month thus stations with observation duration less than 5 years were deleted to maintain a sufficient sample the spatial distributions of all stations applied to evaluate era interim sm on the annual scale are shown in fig 1 among them 37 stations fig s1 including four stations baise zhumadia xuzhou jianpin located in karst region were selected to analyze the temporal and spatial evolution of sm in view of their longer observation duration 1981 1999 and more observational data in vertical profile with 11 layers 1 0 0 05 m 2 0 05 0 1 m 3 0 1 0 2 m 4 0 2 0 3 m 5 0 3 0 4 m 6 0 4 0 5 m 7 0 5 0 6 m 8 0 6 0 7 m 9 0 7 0 8 m 10 0 8 0 9 m 11 0 9 1 m the nearest neighbor interpolation method was used to spatially match the era interim sm with the station data deng et al 2019 2 2 study area the distribution area of karst in china is 3 44 million km2 including the karst buried under nonsoluble rocks which exceeds 1 3 of china s total land area the exposed carbonate area of china s total land area is approximately 907 000 km2 which accounts for approximately 1 7 of china s total land area eight provinces with guizhou at the center comprise one of the largest concentrated karst districts in the world song et al 2016 the thin soil layer and poor soil water retention capacity in karst areas result in a vulnerable soil ecosystem and low land productivity wang et al 2004 the karst can be divided into exposed covered and buried types in terms of rocks distribution the exposed type of china was used in this study fig 1 in the exposed karst areas the average annual precipitation and temperature are 24 7 2362 2 mm and 25 2 c 24 8 c respectively and the average elevation is 2887 m the exposed karst areas of china k can be further classified into three subareas the karst of southern china sk the karst of northern china nk and the karst of qinghai tibet plateau qk jiang et al 2011 sk primarily covers the tropical monsoon climate and the subtropical monsoon climate which are wet hot and rainy annual average temperature 15 c average annual precipitation 1000 mm with typical karst developing the climate in nk is dry and cool average annual precipitation 800 mm with considerable water and heat differences within the area nk mostly covers temperate and western dry karst qk has an average elevation of over 4000 m in an alpine cold region the geographic environment of the qinghai tibet plateau plays an important role in weather and climate change in the asian continent and the plateau is a hotspot for research on global change boos and kuang 2010 dong et al 2016 li et al 2017 2 3 methods statistical indicators correlation coefficient and bias were used to evaluate era interim sm data kuriqi 2016 muceku et al 2016 to reduce the effects of outliers on trend analysis the mann kendall mk nonparametric trend test and the theil sen nonparametric linear trend estimator were combined to calculate the variation trends of sm precipitation temperature and ndvi at the pixel and station scales tian et al 2017 unary linear regression was used for the trends of the aforementioned factors at the average regional scale as well as sensitivity analysis of sm to climate and vegetation albano et al 2019 furthermore stepwise regression was adopted to determine the action intensity of precipitation temperature and ndvi on sm changes the critical probability values of the introduced and culling variables were 0 05 and 0 1 respectively to eliminate dimensional influence the input data of stepwise regression at the pixel and regional average scales were standardized using standard deviation then the standardized regression coefficients were obtained the magnitude of which reflected the effect intensity of the corresponding variable on sm zhang et al 2015 specific research objectives and methods can be seen in the technical roadmap fig s2 3 results 3 1 evaluation of the era interim sm product the in situ sm from over 75 of stations with the correlation significance level of 0 05 correlated well with the era interim product at each soil layer fig 2 a from the surface to the deep layer the average correlation coefficients were 0 77 0 71 and 0 56 indicating that the era interim sm product can display the interannual change of actual sm however the correlation of the sm product weakened as depth increased notably sm of a few stations significantly and negatively correlated with the era interim sm at 28 100 cm fig 2a in fig 2b the deviation values of the era interim product from the in situ observed data decreased as soil depth increased with average biases of 0 037 0 009 and 0 006 m3 m3 thereby suggesting that in terms of magnitude the era interim sm overestimated the measured values at 0 7 cm and 7 28 cm and slightly underestimated at 28 100 cm the aforementioned findings prove that the era interim sm product can well reflect the true state of sm from stations at the annual scale 3 2 spatiotemporal dynamics of sm in karst areas 3 2 1 spatial distribution characteristics at the multi year average state sm in china s karst areas decreases from southeast to northwest in space fig 3 a c concerning the regional average fig 3d sm in sk is the highest followed by that in qk sm in nk is the lowest and less than the average sm in the entire karst region of china from 0 7 to 28 100 cm the spatial distribution patterns of sm are similar but the average sm of the entire karst region and its subareas slightly rises as soil depth increases the in situ observational sm shows more detailed characteristics on the vertical soil profile the multi year average sm of most stations including stations in the karst area grows with the increase of soil depth fig 4 indicating that the vertical characteristics of sm from era interim are consistent with that of the measured data 3 2 2 characteristics of change trend the average sm time series in the karst region and its subareas decreased in 1982 2015 with some fluctuations except for sm at deep depth in qk fig s3 in particular table 1 shows that the reduction trends of the entire karst area sk and nk are significant approximately 0 327 to 0 157 10 3 m3 m3 yr 1 however r 2 values the goodness of fit were below 0 5 sm in qk decreased insignificantly at 0 7 and 7 28 cm and increased insignificantly at 28 100 cm simultaneously as soil depth increased the drying rates of sm in the entire karst region nk and qk slowed down this phenomenon is probably because shallow sm is most directly affected by external factors such as temperature and precipitation conversely the drying trend of sm in sk accelerated in deeper soil depth the pixel by pixel sm change rate demonstrates that over 64 of soil drying areas exist in the entire karst region at all depths fig 5 with significant drying z value 1 96 of approximately 35 fig s4 the soil drying areas shrink from the surface to the deep soil remarkably the spatial distribution of sm changes exhibited regional differences soil in over 58 of qk got wetting mostly located at the center of qk and in deeper soil layers the soil wetting areas and the average wetting rate increased slightly which may be induced by the melting of deep frozen soil in the plateau due to the temperature rising the regional mean values of sm change rates in fig 5d are consistent with the results presented in table 1 most of observational data primarily in 1981 1999 showed decreasing trends fig 6 also sm at different soil depths from stations in karst areas decreased except xuzhou station 3 3 sensitivity of sm to climate and vegetation the regression coefficient of sm and single influencing factor was regarded as the sensitivity coefficient table s1 the average sm in the karst region of china significantly showed negative sensitivity to the average ndvi and positive sensitivity to the average annual precipitation in 1982 2015 sensitivity of sm to vegetation or precipitation varied in karst subareas concretely the average sm in nk exhibited the strongest negative sensitivity to vegetation and the sm at 0 7 cm decreased by 0 03 m3 m3 every 0 01 increase of ndvi the average sm in qk had a weak positive sensitivity to ndvi and the average sm in sk performed the weakest sensitivity to precipitation during the study period the average sm in the karst region and its subareas showed extremely similar negative sensitivity to temperature 0 005 m3 m3 c 1 with soil depth increasing the sensitivities of the average sm to climate and vegetation in the karst region and its subareas weakened except for the sensitivity of average sm to vegetation in qk spatial distribution for sensitivities of surface sm to climate and vegetation in fig 7 demonstrated that sm in the whole karst region was negatively sensitive to vegetation mainly located in sk however varying from results in table s1 the stronger positive or negative sensitivity was largely distributed in qk the alpine karst area the sensitivity of sm to precipitation was mainly positive with it in qk the strongest and sk the weakest the sensitivity of sm to temperature was mostly negative and differ slightly in space additionally with the growth of soil depth the sensitivity diminished it may result from the fact that in deeper soil the sm is less disturbed by the external climate activities mccoll et al 2017a 4 discussion 4 1 spatiotemporal characteristics of sm in karst areas the reanalysis and observational data demonstrated that the multi year average sm of karst areas and non karst areas had the same characteristics in the vertical profile figs 5 and 6 that is with the increase of depth the sm generally increased differently the average values of sm in the karst region and its subareas were higher than those in non karst region and its corresponding subareas table s3 possibly caused by excessive coverage of arid areas in non karst areas however compared with non karst areas typical karst areas are characterized by large ratio of rock to soil discontinuous soil distribution and strong spatial heterogeneity due to slow soil formation rate and severe soil erosion then influencing the allocation of precipitation the process of runoff generation and confluence in karst areas and the movement and distribution of sm chan 2012 zhang et al 2008 wang et al 2016 proposed that in the karst areas after the confluence of precipitation rock outcrops distributed almost 50 of the runoff to the adjacent soil which resulted in high sm between the rock outcrops climate is an important factor affecting sm deng et al 2020 and ndvi can approximately indicate the land surface coverage and rocky desertification chen et al 2019 hence to reduce the large divergence of climate between karst and non karst regions in china this study preliminarily compared sm under different vegetation coverage levels of each climate zone for the karst and non karst areas in southern china and qinghai tibet plateau according to unep 1997 the climate zones were obtained by dividing aridity index http www cgiar csi org into five zones fig s1 including ha hyper arid a arid sa semi arid dsh dry sub humid and h humid fig 8 shows that in the southern of china sm in the karst areas under some ndvi levels of the dsh and h climate zones is overall higher than that in the non karst areas although the results are opposite in the sa meanwhile with the increase of vegetation coverage the divergence of sm between karst and non karst areas decreases in the qinghai tibet plateau the sm in karst areas with low vegetation coverage levels ndvi 0 3 is higher than that in non karst areas with vegetation cover improving to over 0 3 the sm in non karst areas exceeds that in karst areas moreover similar findings were also found in deeper sm 7 28 and 28 100 cm table s4 the above results may result from the redistribution of rainfall by exposed rocks in karst areas on a macro scale but despite the more detailed division the areas of the karst and non karst under some vegetation classes of the same climate zone in southern china remain quite different table s5 and the relevant results from reanalysis data require further validation more importantly it is critical to compare sm between karst and non karst areas by using sufficient sm stations with long observation time and even distributions in terms of change trend the reanalysis and observational data show that the average sm of different depths in both the karst and non karst regions of china declined figs 5 and 6 which is consistent with the background that the global and china s sm has been decreasing in recent years dai 2013 feng and fu 2013 jia et al 2018 however remarkable differences in sm among karst subareas in china are also observed sm of sk is large but the average sm has reduced fastest in the past 34 years with the drying rate slightly increasing in deep soil the sm in nk is low but the soil drying trend is dominant in the area during the study period sm in half of qk raised and the soil wetting areas expanded with the increase of soil depth the above findings can be supported by the conclusions that sm in the eastern part of china decreased significantly from 1979 to 2010 chen et al 2016 and that the remote sensing observation showed the wetting trend in the central part of the qinghai tibet plateau van der velde et al 2014 overall as an ecologically fragile li et al 2014 parise et al 2009 and sensitive region karst presents the barren soil with poor water holding capacity and is easy to form a geological drought ni et al 2009 besides the karst area with abundant precipitation is prone to soil erosion chen et al 2019 which exacerbates the uneven distributions of local soil and water resources 4 2 causes of sm change under global warming 4 2 1 changes of climate and vegetation in karst areas in 1982 2015 the average temperature and ndvi of the karst region and its subareas exhibited increasing trends fig s3 particularly in sk precipitation in the karst region sk and nk decreased whereas that in qk experienced an increasing trend spatially figs 9 and s4 vegetation in the karst region was dominated by greening with the increasing areas accounting for 80 3 55 53 z value 1 96 the greening area in each subarea exceeded 70 but their greening rates differed the average rate of ndvi trends in sk 1 41 10 3 yr 1 was two times that in the entire karst region 0 66 10 3 yr 1 for precipitation the area ratio of increase to decrease over the karst areas was approximately 1 1 and the area proportions of significant increase and decrease were 19 97 and 7 73 respectively the areas with precipitation reduction were mostly distributed in nk as well as the northwestern and northern parts of sk precipitation in nk decreased the fastest precipitation in qk was dominated by increasing which mostly occurred in the areas where sm increased the temperature in 78 19 of the entire karst region significantly raised with an average temperature change rate of 0 29 10 3 c yr 1 and the discrepancy between the average temperature change rates in the subareas was indistinctive 4 2 2 effects of ndvi precipitation and temperature on sm sensitivity analysis revealed that sm in karst areas related to vegetation and climate but the relative importance of precipitation temperature and vegetation to sm changes has not been reflected in this regard combined with the changing trend of each factor the stepwise regression results table 2 showed that over 70 of the average sm change in the entire karst region and sk was affected by precipitation increasing and temperature rising sm change in all soil layers of nk was mostly affected by precipitation declining with the interpretation degree ranging from 76 to 82 in qk 66 of sm change at 0 7 cm was affected by precipitation and temperature however 68 was mostly affected by precipitation temperature and ndvi at 7 28 cm with the influence of temperature increasing and sm change was primarily affected by precipitation at 28 100 cm all the standardized regression coefficients indicate that the average sm in karst and its subareas is principally influenced by precipitation in fig 10 the absolute values and the covered space of the stepwise regression coefficients indicate that at the pixel scale the surface sm in karst region and its subareas was dominantly affected by precipitation followed by temperature the area proportions of temperature and precipitation that affected surface sm were the largest in sk and the greatest effect of ndvi on sm was distributed in nk the mean interpretation power r 2 of the stepwise regression for sm at 0 7 cm was 0 71 with the interpretation power below 50 primarily distributed in qk indicating that sm in qk was also affected by other factors such as altitude cao et al 2017 and human activities chaturvedi et al 2017 in deeper soil figs s5 and 6 the interpretation power of sm change in the karst region and its subareas diminished particularly in qk previous studies have found that temperature is a major contributor to global soil drying cheng and huang 2016 feng and fu 2013 nonetheless in this study the influence of precipitation on sm change at 0 7 7 28 28 100 cm is stronger than that of temperature specifically the decrease of precipitation is the major cause of soil drying in the karst region of china also true in sk in qk considerable differences are observed in the causes of sm change fig 10 shows that the soil wetting areas at 0 7 cm in qk are primarily affected by the increase in precipitation and temperature warming does not have a positive effect on sm the results conform to the finding that soil wetting in the early summer in the qinghai tibet plateau is driven by precipitation growth zhang et al 2017 by contrast the soil drying areas in qk are mostly influenced by the decline in precipitation and the rising temperature it may be attributed to global warming resulting in permafrost melting and soil water infiltration thereby making the upper soil dry in the qinghai tibet plateau xue et al 2009 in nk the influence of vegetation on sm has elicited extensive concern particularly in the loess plateau where afforestation caused local sm declining and forming dry soil layers jia et al 2017 although compared with other karst subareas sm of various soil depths in nk showed the most significant negative sensitivity to ndvi the soil drying trend was mainly controlled by precipitation in summary sm in the karst region of china went down under global climate change in 1982 2015 which is primarily endangered by reduced precipitation the reduction in sm can hinder the natural growth of crops boost the demand for agricultural irrigation and increase the risk of drought therefore effective sm management measures are necessary to avoid the risks and harm caused by soil drying in accordance with the actual situations in the karst areas of china 5 conclusion sm plays an important role in ecological restoration and agricultural water resource management in karst areas combined the sm from reanalysis and station data with precipitation temperature and ndvi this study found that climate vegetation and geological background made the spatiotemporal distributions of sm differ within the karst region as follows 1 era interim sm product reflected changes of in situ observed sm well however the correlation weakened as depth increased and in situ sm was overestimated at 0 7 and 7 28 cm and slightly underestimated at 28 100 cm 2 the trend analysis showed that sm in the entire karst region significantly decreased in 1982 2015 with over 64 areas drying at all soil layers 3 sm in sk was the highest but its drying speed was the fastest sm in nk was lower than the average level in entire karst region and its decrease rate was higher than the average rate of the karst region indicating that the risk of drought is possibly enhanced in sk and nk in qk the significant decrease of average sm was observed in the surface soil from 1982 to 2015 although over 58 soil wetting area was observed 4 under the global change the trends of sm in the entire karst region and its subareas were dominated by precipitation followed by temperature the average sm changes in the karst region and sk at all depths were mainly affected by precipitation increasing and temperature warming sm changes in nk were mostly influenced by precipitation factors that affected sm change in qk varied at different depths 5 in southern china the sm under some vegetation levels of dsh and h climate zones in karst areas is higher than that in non karst areas in the qinghai tibet plateau within a climate zone the sm at the lower vegetation coverage levels ndvi less than 0 3 in karst areas generally exceeds that in non karst areas with the results opposite as the ndvi increases to over 0 3 the findings may be the result that the rock outcrops in karst areas with low vegetation coverage lead to the redistribution of precipitation credit authorship contribution statement yuanhong deng data curation formal analysis writing original draft shijie wang conceptualization supervision xiaoyong bai conceptualization supervision guangjie luo visualization luhua wu visualization fei chen visualization jinfeng wang visualization qin li visualization chaojun li writing review editing yujie yang writing review editing zeyin hu writing review editing shiqi tian writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank ecmwf https www ecmwf int for sharing sm products freely the research was supported by the national key research program of china grant numbers 2016yfc0502300 2016yfc0502102 strategic priority research program of the chinese academy of sciences grant number xda23060100 western light talent program category a grant number 2018 99 united fund of karst science research center grant number u1612441 science and technology plan of guizhou province of china grant number 2017 2966 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124744 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5521,soil moisture is one of the restricting factors in a fragile karst ecological environment however its spatiotemporal evolution characteristics in the karst areas of china remain poorly understood thus based on soil moisture from reanalysis era interim product and ground stations this study used the mann kendall test the theil sen slope estimator sensitivity analysis and stepwise regression and obtained the following results 1 era interim soil moisture well reflected the interannual change of observational soil moisture at 0 7 7 28 and 28 100 cm 2 the reanalysis and station data showed that soil at various depths in the karst areas was dominated by a drying trend in 1982 2015 3 soil moisture in karst areas of southern china was high but decreased fastest in the karst areas of northern china soil moisture was low and declined quickly nevertheless soil wetting was observed in the central karst areas of qinghai tibet plateau 4 changes of soil moisture throughout the karst region of china and its subareas were mainly affected by precipitation followed by temperature 5 in qinghai tibet plateau and southern china soil moisture in karst areas is overall higher than that in non karst areas when under low vegetation coverage levels ndvi 0 3 of some climate zones possibly caused by the centralized allocation of precipitation in karst areas due to exposed rocks in conclusion climate vegetation and geological background make the spatiotemporal distributions of soil moisture differ within the karst region while the soil drying trend in recent decades and global climate change are not conducive to the ecological restoration of vulnerable karst areas keywords karst soil moisture china climate ndvi sensitivity analysis 1 introduction soil moisture sm is one of the important components of soil that affects crop growth vegetation distribution pattern and soil microbial activities dunn et al 1985 moyano et al 2013 xia and shao 2008 the migration of soil matter stielstra et al 2015 and the absorption and decomposition of terrestrial carbon are inseparable from the role of sm green et al 2019 besides sm functions as the link between surface water and groundwater the dynamics of sm influence surface energy allocation evapotranspiration processes and are important for research on hydrological processes and climate prediction deng 2020 wang 2018 to date international research on the spatiotemporal dynamics of sm has focused on surface soil at a global scale mccoll et al 2017a b sheffield and wood 2008 particularly under the condition of global warming dai 2013 knowledge gaps exist in china s karst region where sm is a limiting factor in the ecological restoration of soil and plant the shortage of soil water resources seriously impacts the local ecological environment and agricultural production qin et al 2015 karst is a unique combination of aboveground and underground geomorphology produced by the water chemical dissolution of soluble rocks such as carbonate rocks and is generally characterized by barren and rocky grounds caves and sinkholes li 2018 parise et al 2015 under the special geological background karst possesses surface and underground water systems which are connected by hydraulic connection as a whole and with considerable surface water seepage its hydrological characteristics are different from these of non karst areas bailly comte et al 2009 ecosystem in a typical karst region is weakly resistant to external disturbances bai et al 2013 particularly in the karst areas of southwestern china tian et al 2016 in these areas soil erosion is severe soil thin and vegetation coverage low febles et al 2009 thereby resulting in a fragile soil environment and frequent temporary droughts deng 2018 ge and wang 2008 previous studies have suggested that sm is a major constraint factor in karst ecosystems and the role of sm in facilitating the ecological restoration and agricultural industrialization in the karst area has been investigated hartmann et al 2014 current research focuses on the spatial characteristics of sm in karst areas chen et al 2010 studied the distribution differences of sm under different land use in a karst slope li et al 2014 revealed the influence of rock exposure on the spatial distribution of sm liu et al 2017 analyzed the spatial movement characteristics of sm on the grass slope of a karst peak cluster area however without comparing with results from non karst areas it is unclear whether sm in karst areas has unique characteristics furthermore a few studies about the trend of sm change in karst areas are primarily carried out on the scales of slope and small watershed chen et al 2010 fu et al 2016 the geological hydrological background of karst such as slow soil formation rate and space mismatch between water and soil leads to the strong spatial heterogeneity of sm li et al 2014 mccole and stern 2007 consequently the conclusions of these previous studies are uncertain in large scale karst areas in addition the interannual variation of sm is affected by various factors including temperature precipitation and vegetation the effects of these factors on sm vary under different spatiotemporal circumstances many scholars found that recent rising in global temperature was the dominant factor causing global soil drying dai 2013 feng and fu 2013 that precipitation controlled the drying trend of sm from 1979 to 2010 in china jia et al 2018 and that vegetation restoration brought about the decline of sm in the loess plateau of china su and shangguan 2019 therefore it s necessary to study the effects of climate and vegetation on sm change in karst areas promoting water and soil conservation and ecological restoration here this paper aims to explore the spatial and temporal characteristics of sm in the karst areas of china in 1982 2015 the concrete objectives are as follows 1 evaluate the reliability of sm from reanalysis product era interim at different depths 2 reveal the spatial distributions and change trends of sm in the karst region of china by using reanalysis and observations data 3 analyze the effects of the normalized difference vegetation index ndvi precipitation and temperature on sm based on sensitivity analysis and stepwise regression and 4 discover sm differences between karst and non karst areas in china 2 data and methods 2 1 data and preprocessing sm product from era interim reanalysis was provided by the european center for medium range weather forecasts ecmwf with spatial and temporal resolutions of 0 125 and monthly respectively https www ecmwf int which has four sm layers 0 7 7 28 28 100 and 100 289 cm the product was previously applied to the analysis of spatiotemporal changes in sm hydrometeorology and numerical simulation deng 2020 materia 2014 xia 2014 also era interim reanalysis data included precipitation and temperature data with the same spatial and temporal resolutions as the sm product the observational sm data were obtained from the international soil moisture network ismn which collects free and high quality in situ sm data worldwide http www ipf tuwien ac at dorigo et al 2011 however the temporal resolution and time length of observation stations vary deng et al 2019 gimms ndvi3g 1982 2015 https ecocast arc nasa gov data pub gimms with spatial and temporal resolutions of 8 km and 15 days respectively was also used in this study yang et al 2019 the actual soil thickness in typical karst areas is usually less than 1 m therefore sm product and site measured data at 0 7 7 28 and 28 100 cm were used in this study temporal resolutions of sm precipitation temperature and ndvi data were converted to the annual scale and among them spatial resolutions of gridded data were interpolated to 0 125 the time coverage for observational sm in china from ismn was mostly 1981 1999 2010 2016 and 2008 2010 with the monitoring times typically on the 8th 18th and 28th of each month thus stations with observation duration less than 5 years were deleted to maintain a sufficient sample the spatial distributions of all stations applied to evaluate era interim sm on the annual scale are shown in fig 1 among them 37 stations fig s1 including four stations baise zhumadia xuzhou jianpin located in karst region were selected to analyze the temporal and spatial evolution of sm in view of their longer observation duration 1981 1999 and more observational data in vertical profile with 11 layers 1 0 0 05 m 2 0 05 0 1 m 3 0 1 0 2 m 4 0 2 0 3 m 5 0 3 0 4 m 6 0 4 0 5 m 7 0 5 0 6 m 8 0 6 0 7 m 9 0 7 0 8 m 10 0 8 0 9 m 11 0 9 1 m the nearest neighbor interpolation method was used to spatially match the era interim sm with the station data deng et al 2019 2 2 study area the distribution area of karst in china is 3 44 million km2 including the karst buried under nonsoluble rocks which exceeds 1 3 of china s total land area the exposed carbonate area of china s total land area is approximately 907 000 km2 which accounts for approximately 1 7 of china s total land area eight provinces with guizhou at the center comprise one of the largest concentrated karst districts in the world song et al 2016 the thin soil layer and poor soil water retention capacity in karst areas result in a vulnerable soil ecosystem and low land productivity wang et al 2004 the karst can be divided into exposed covered and buried types in terms of rocks distribution the exposed type of china was used in this study fig 1 in the exposed karst areas the average annual precipitation and temperature are 24 7 2362 2 mm and 25 2 c 24 8 c respectively and the average elevation is 2887 m the exposed karst areas of china k can be further classified into three subareas the karst of southern china sk the karst of northern china nk and the karst of qinghai tibet plateau qk jiang et al 2011 sk primarily covers the tropical monsoon climate and the subtropical monsoon climate which are wet hot and rainy annual average temperature 15 c average annual precipitation 1000 mm with typical karst developing the climate in nk is dry and cool average annual precipitation 800 mm with considerable water and heat differences within the area nk mostly covers temperate and western dry karst qk has an average elevation of over 4000 m in an alpine cold region the geographic environment of the qinghai tibet plateau plays an important role in weather and climate change in the asian continent and the plateau is a hotspot for research on global change boos and kuang 2010 dong et al 2016 li et al 2017 2 3 methods statistical indicators correlation coefficient and bias were used to evaluate era interim sm data kuriqi 2016 muceku et al 2016 to reduce the effects of outliers on trend analysis the mann kendall mk nonparametric trend test and the theil sen nonparametric linear trend estimator were combined to calculate the variation trends of sm precipitation temperature and ndvi at the pixel and station scales tian et al 2017 unary linear regression was used for the trends of the aforementioned factors at the average regional scale as well as sensitivity analysis of sm to climate and vegetation albano et al 2019 furthermore stepwise regression was adopted to determine the action intensity of precipitation temperature and ndvi on sm changes the critical probability values of the introduced and culling variables were 0 05 and 0 1 respectively to eliminate dimensional influence the input data of stepwise regression at the pixel and regional average scales were standardized using standard deviation then the standardized regression coefficients were obtained the magnitude of which reflected the effect intensity of the corresponding variable on sm zhang et al 2015 specific research objectives and methods can be seen in the technical roadmap fig s2 3 results 3 1 evaluation of the era interim sm product the in situ sm from over 75 of stations with the correlation significance level of 0 05 correlated well with the era interim product at each soil layer fig 2 a from the surface to the deep layer the average correlation coefficients were 0 77 0 71 and 0 56 indicating that the era interim sm product can display the interannual change of actual sm however the correlation of the sm product weakened as depth increased notably sm of a few stations significantly and negatively correlated with the era interim sm at 28 100 cm fig 2a in fig 2b the deviation values of the era interim product from the in situ observed data decreased as soil depth increased with average biases of 0 037 0 009 and 0 006 m3 m3 thereby suggesting that in terms of magnitude the era interim sm overestimated the measured values at 0 7 cm and 7 28 cm and slightly underestimated at 28 100 cm the aforementioned findings prove that the era interim sm product can well reflect the true state of sm from stations at the annual scale 3 2 spatiotemporal dynamics of sm in karst areas 3 2 1 spatial distribution characteristics at the multi year average state sm in china s karst areas decreases from southeast to northwest in space fig 3 a c concerning the regional average fig 3d sm in sk is the highest followed by that in qk sm in nk is the lowest and less than the average sm in the entire karst region of china from 0 7 to 28 100 cm the spatial distribution patterns of sm are similar but the average sm of the entire karst region and its subareas slightly rises as soil depth increases the in situ observational sm shows more detailed characteristics on the vertical soil profile the multi year average sm of most stations including stations in the karst area grows with the increase of soil depth fig 4 indicating that the vertical characteristics of sm from era interim are consistent with that of the measured data 3 2 2 characteristics of change trend the average sm time series in the karst region and its subareas decreased in 1982 2015 with some fluctuations except for sm at deep depth in qk fig s3 in particular table 1 shows that the reduction trends of the entire karst area sk and nk are significant approximately 0 327 to 0 157 10 3 m3 m3 yr 1 however r 2 values the goodness of fit were below 0 5 sm in qk decreased insignificantly at 0 7 and 7 28 cm and increased insignificantly at 28 100 cm simultaneously as soil depth increased the drying rates of sm in the entire karst region nk and qk slowed down this phenomenon is probably because shallow sm is most directly affected by external factors such as temperature and precipitation conversely the drying trend of sm in sk accelerated in deeper soil depth the pixel by pixel sm change rate demonstrates that over 64 of soil drying areas exist in the entire karst region at all depths fig 5 with significant drying z value 1 96 of approximately 35 fig s4 the soil drying areas shrink from the surface to the deep soil remarkably the spatial distribution of sm changes exhibited regional differences soil in over 58 of qk got wetting mostly located at the center of qk and in deeper soil layers the soil wetting areas and the average wetting rate increased slightly which may be induced by the melting of deep frozen soil in the plateau due to the temperature rising the regional mean values of sm change rates in fig 5d are consistent with the results presented in table 1 most of observational data primarily in 1981 1999 showed decreasing trends fig 6 also sm at different soil depths from stations in karst areas decreased except xuzhou station 3 3 sensitivity of sm to climate and vegetation the regression coefficient of sm and single influencing factor was regarded as the sensitivity coefficient table s1 the average sm in the karst region of china significantly showed negative sensitivity to the average ndvi and positive sensitivity to the average annual precipitation in 1982 2015 sensitivity of sm to vegetation or precipitation varied in karst subareas concretely the average sm in nk exhibited the strongest negative sensitivity to vegetation and the sm at 0 7 cm decreased by 0 03 m3 m3 every 0 01 increase of ndvi the average sm in qk had a weak positive sensitivity to ndvi and the average sm in sk performed the weakest sensitivity to precipitation during the study period the average sm in the karst region and its subareas showed extremely similar negative sensitivity to temperature 0 005 m3 m3 c 1 with soil depth increasing the sensitivities of the average sm to climate and vegetation in the karst region and its subareas weakened except for the sensitivity of average sm to vegetation in qk spatial distribution for sensitivities of surface sm to climate and vegetation in fig 7 demonstrated that sm in the whole karst region was negatively sensitive to vegetation mainly located in sk however varying from results in table s1 the stronger positive or negative sensitivity was largely distributed in qk the alpine karst area the sensitivity of sm to precipitation was mainly positive with it in qk the strongest and sk the weakest the sensitivity of sm to temperature was mostly negative and differ slightly in space additionally with the growth of soil depth the sensitivity diminished it may result from the fact that in deeper soil the sm is less disturbed by the external climate activities mccoll et al 2017a 4 discussion 4 1 spatiotemporal characteristics of sm in karst areas the reanalysis and observational data demonstrated that the multi year average sm of karst areas and non karst areas had the same characteristics in the vertical profile figs 5 and 6 that is with the increase of depth the sm generally increased differently the average values of sm in the karst region and its subareas were higher than those in non karst region and its corresponding subareas table s3 possibly caused by excessive coverage of arid areas in non karst areas however compared with non karst areas typical karst areas are characterized by large ratio of rock to soil discontinuous soil distribution and strong spatial heterogeneity due to slow soil formation rate and severe soil erosion then influencing the allocation of precipitation the process of runoff generation and confluence in karst areas and the movement and distribution of sm chan 2012 zhang et al 2008 wang et al 2016 proposed that in the karst areas after the confluence of precipitation rock outcrops distributed almost 50 of the runoff to the adjacent soil which resulted in high sm between the rock outcrops climate is an important factor affecting sm deng et al 2020 and ndvi can approximately indicate the land surface coverage and rocky desertification chen et al 2019 hence to reduce the large divergence of climate between karst and non karst regions in china this study preliminarily compared sm under different vegetation coverage levels of each climate zone for the karst and non karst areas in southern china and qinghai tibet plateau according to unep 1997 the climate zones were obtained by dividing aridity index http www cgiar csi org into five zones fig s1 including ha hyper arid a arid sa semi arid dsh dry sub humid and h humid fig 8 shows that in the southern of china sm in the karst areas under some ndvi levels of the dsh and h climate zones is overall higher than that in the non karst areas although the results are opposite in the sa meanwhile with the increase of vegetation coverage the divergence of sm between karst and non karst areas decreases in the qinghai tibet plateau the sm in karst areas with low vegetation coverage levels ndvi 0 3 is higher than that in non karst areas with vegetation cover improving to over 0 3 the sm in non karst areas exceeds that in karst areas moreover similar findings were also found in deeper sm 7 28 and 28 100 cm table s4 the above results may result from the redistribution of rainfall by exposed rocks in karst areas on a macro scale but despite the more detailed division the areas of the karst and non karst under some vegetation classes of the same climate zone in southern china remain quite different table s5 and the relevant results from reanalysis data require further validation more importantly it is critical to compare sm between karst and non karst areas by using sufficient sm stations with long observation time and even distributions in terms of change trend the reanalysis and observational data show that the average sm of different depths in both the karst and non karst regions of china declined figs 5 and 6 which is consistent with the background that the global and china s sm has been decreasing in recent years dai 2013 feng and fu 2013 jia et al 2018 however remarkable differences in sm among karst subareas in china are also observed sm of sk is large but the average sm has reduced fastest in the past 34 years with the drying rate slightly increasing in deep soil the sm in nk is low but the soil drying trend is dominant in the area during the study period sm in half of qk raised and the soil wetting areas expanded with the increase of soil depth the above findings can be supported by the conclusions that sm in the eastern part of china decreased significantly from 1979 to 2010 chen et al 2016 and that the remote sensing observation showed the wetting trend in the central part of the qinghai tibet plateau van der velde et al 2014 overall as an ecologically fragile li et al 2014 parise et al 2009 and sensitive region karst presents the barren soil with poor water holding capacity and is easy to form a geological drought ni et al 2009 besides the karst area with abundant precipitation is prone to soil erosion chen et al 2019 which exacerbates the uneven distributions of local soil and water resources 4 2 causes of sm change under global warming 4 2 1 changes of climate and vegetation in karst areas in 1982 2015 the average temperature and ndvi of the karst region and its subareas exhibited increasing trends fig s3 particularly in sk precipitation in the karst region sk and nk decreased whereas that in qk experienced an increasing trend spatially figs 9 and s4 vegetation in the karst region was dominated by greening with the increasing areas accounting for 80 3 55 53 z value 1 96 the greening area in each subarea exceeded 70 but their greening rates differed the average rate of ndvi trends in sk 1 41 10 3 yr 1 was two times that in the entire karst region 0 66 10 3 yr 1 for precipitation the area ratio of increase to decrease over the karst areas was approximately 1 1 and the area proportions of significant increase and decrease were 19 97 and 7 73 respectively the areas with precipitation reduction were mostly distributed in nk as well as the northwestern and northern parts of sk precipitation in nk decreased the fastest precipitation in qk was dominated by increasing which mostly occurred in the areas where sm increased the temperature in 78 19 of the entire karst region significantly raised with an average temperature change rate of 0 29 10 3 c yr 1 and the discrepancy between the average temperature change rates in the subareas was indistinctive 4 2 2 effects of ndvi precipitation and temperature on sm sensitivity analysis revealed that sm in karst areas related to vegetation and climate but the relative importance of precipitation temperature and vegetation to sm changes has not been reflected in this regard combined with the changing trend of each factor the stepwise regression results table 2 showed that over 70 of the average sm change in the entire karst region and sk was affected by precipitation increasing and temperature rising sm change in all soil layers of nk was mostly affected by precipitation declining with the interpretation degree ranging from 76 to 82 in qk 66 of sm change at 0 7 cm was affected by precipitation and temperature however 68 was mostly affected by precipitation temperature and ndvi at 7 28 cm with the influence of temperature increasing and sm change was primarily affected by precipitation at 28 100 cm all the standardized regression coefficients indicate that the average sm in karst and its subareas is principally influenced by precipitation in fig 10 the absolute values and the covered space of the stepwise regression coefficients indicate that at the pixel scale the surface sm in karst region and its subareas was dominantly affected by precipitation followed by temperature the area proportions of temperature and precipitation that affected surface sm were the largest in sk and the greatest effect of ndvi on sm was distributed in nk the mean interpretation power r 2 of the stepwise regression for sm at 0 7 cm was 0 71 with the interpretation power below 50 primarily distributed in qk indicating that sm in qk was also affected by other factors such as altitude cao et al 2017 and human activities chaturvedi et al 2017 in deeper soil figs s5 and 6 the interpretation power of sm change in the karst region and its subareas diminished particularly in qk previous studies have found that temperature is a major contributor to global soil drying cheng and huang 2016 feng and fu 2013 nonetheless in this study the influence of precipitation on sm change at 0 7 7 28 28 100 cm is stronger than that of temperature specifically the decrease of precipitation is the major cause of soil drying in the karst region of china also true in sk in qk considerable differences are observed in the causes of sm change fig 10 shows that the soil wetting areas at 0 7 cm in qk are primarily affected by the increase in precipitation and temperature warming does not have a positive effect on sm the results conform to the finding that soil wetting in the early summer in the qinghai tibet plateau is driven by precipitation growth zhang et al 2017 by contrast the soil drying areas in qk are mostly influenced by the decline in precipitation and the rising temperature it may be attributed to global warming resulting in permafrost melting and soil water infiltration thereby making the upper soil dry in the qinghai tibet plateau xue et al 2009 in nk the influence of vegetation on sm has elicited extensive concern particularly in the loess plateau where afforestation caused local sm declining and forming dry soil layers jia et al 2017 although compared with other karst subareas sm of various soil depths in nk showed the most significant negative sensitivity to ndvi the soil drying trend was mainly controlled by precipitation in summary sm in the karst region of china went down under global climate change in 1982 2015 which is primarily endangered by reduced precipitation the reduction in sm can hinder the natural growth of crops boost the demand for agricultural irrigation and increase the risk of drought therefore effective sm management measures are necessary to avoid the risks and harm caused by soil drying in accordance with the actual situations in the karst areas of china 5 conclusion sm plays an important role in ecological restoration and agricultural water resource management in karst areas combined the sm from reanalysis and station data with precipitation temperature and ndvi this study found that climate vegetation and geological background made the spatiotemporal distributions of sm differ within the karst region as follows 1 era interim sm product reflected changes of in situ observed sm well however the correlation weakened as depth increased and in situ sm was overestimated at 0 7 and 7 28 cm and slightly underestimated at 28 100 cm 2 the trend analysis showed that sm in the entire karst region significantly decreased in 1982 2015 with over 64 areas drying at all soil layers 3 sm in sk was the highest but its drying speed was the fastest sm in nk was lower than the average level in entire karst region and its decrease rate was higher than the average rate of the karst region indicating that the risk of drought is possibly enhanced in sk and nk in qk the significant decrease of average sm was observed in the surface soil from 1982 to 2015 although over 58 soil wetting area was observed 4 under the global change the trends of sm in the entire karst region and its subareas were dominated by precipitation followed by temperature the average sm changes in the karst region and sk at all depths were mainly affected by precipitation increasing and temperature warming sm changes in nk were mostly influenced by precipitation factors that affected sm change in qk varied at different depths 5 in southern china the sm under some vegetation levels of dsh and h climate zones in karst areas is higher than that in non karst areas in the qinghai tibet plateau within a climate zone the sm at the lower vegetation coverage levels ndvi less than 0 3 in karst areas generally exceeds that in non karst areas with the results opposite as the ndvi increases to over 0 3 the findings may be the result that the rock outcrops in karst areas with low vegetation coverage lead to the redistribution of precipitation credit authorship contribution statement yuanhong deng data curation formal analysis writing original draft shijie wang conceptualization supervision xiaoyong bai conceptualization supervision guangjie luo visualization luhua wu visualization fei chen visualization jinfeng wang visualization qin li visualization chaojun li writing review editing yujie yang writing review editing zeyin hu writing review editing shiqi tian writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank ecmwf https www ecmwf int for sharing sm products freely the research was supported by the national key research program of china grant numbers 2016yfc0502300 2016yfc0502102 strategic priority research program of the chinese academy of sciences grant number xda23060100 western light talent program category a grant number 2018 99 united fund of karst science research center grant number u1612441 science and technology plan of guizhou province of china grant number 2017 2966 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124744 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5522,sediment transportation in water bodies may cause many problems for the water resources projects and damage the environment hence modeling sediment load components including suspended sediment load ssl and bedload bl in rivers is of prime importance effective modeling of ssl and bl remains a challenging task due to their complex hydrological process on this account this study aims to appraise the potential of conventional machine learning ml models including adaptive neuro fuzzy inference system anfis support vector regression svr and their integrative version with nature optimization algorithm called genetic algorithm ga anfis and ga svr for ssl and bl prediction two traditional models are developed for modeling verification including the sediment rating curve src and multiple linear regression mlr the modeling results are assessed using four statistical measures e g root mean square error rmse mean absolute error mae nash sutcliffe efficiency nse and coefficient of determination r2 diagnostic analysis scatter plots and taylor diagram and evaluation of the dependence of the state of the river flow sediment system hysteresis analysis based on the attained predictability performance the integrative ml models reveal a superior prediction capacity in comparison with the standalone anfis svr and the traditional models in quantitative evaluation the proposed integrative ml models indicate a remarkable prediction enhancement approximately 44 mean magnitude based on the mae metric against the src traditional model for both the ssl and bl predicted values overall the current investigation evidences the potential of the nature inspired algorithm as a hyper parameter optimizer for ml models that produce a reliable and robust predictive model for sediment concentration quantification keywords heuristic algorithms soft computing hydrology bed load river engineering 1 introduction 1 1 background and motivation in river engineering sediment load is defined as the total amount of sediment output transported by rivers and streams from a watershed accurate estimation of sediment load is crucial to river engineering and management including stable channel design river restoration as well as issues related to the water quality of the river the changes in sediment load and transportation in rivers which may get influenced by spatial and temporal factors can follow an extreme nonlinear process fan and yao 2008 kuai and tsai 2012 sadeghi and mostafazadeh 2016 at the larger time scales the climatic and anthropogenic factors and all the events within the season will be influencing the sediment load patterns the spatial and temporal changes in the watershed characteristics like vegetation cover and soil moisture condition can influence the transport processes of sediment load lyn 1987 henceforth given the complex and nonlinear behavior of the sediment transport process which is influenced by different watershed hydrographic and hydraulic flow factors it is not easy to construct an accurate sediment estimation tool kisi and yaseen 2019a kiyoumars roushangar and shahnazi 2019 the sediment loads of a watershed can be divided into three groups including bedload bl suspended sediment load ssl and wash load fine sediments fall within ssl and may be carried long distances before deposition even under the base and low flow conditions salih et al 2019a on the other hand bl is generally composed of coarse grained sediments that comprise a significant volume of sediment at higher discharges and floods given the varying sedimentation behaviors in ssl and bl states as well as the complexity of the transitional sedimentation phenomena in rivers it is necessary to use models capable of capturing complex processes haddadchi et al 2013b zounemat kermani et al 2016 the wash load consists of very fine and cohesive sediments haddadchi et al 2013a since there was no available measured data for the wash load in this study we have excluded this type of sediment transportation and have focused on bl and ssl for the sediment load prediction tao et al 2019 the accuracy of the sediment prediction models depends on several temporal and spatial factors including the measurement scale of data such as daily weekly or monthly data length input variables selected etc in addition the sediment load in rivers results from weathering land sliding and glacial and fluvial erosion baniya et al 2019 the highly diverse composition of sediment load and bedload make the sediment transport modeling a complex problem and the input selection procedure is a crucial step in this exercise the area of the catchment land cover slope and topography of the catchment rainfall intensity and volume temperature soil characteristics etc are some of the key factors influencing ssl and bl from the basin traditional flow based methods such as the sediment rating curve src do not have a great ability to estimate sediment transportation due to reliance on sediment loads versus discharge rajaee et al 2011 1 2 literature review machine learning and sediment modeling many studies reported that the use of lagged values of river discharge suspended sediment and precipitation is sufficient for the prediction of ssl kakaei lafdani et al 2013 adnan et al 2019 salih et al 2019b the accurate prediction of bl is more difficult than ssl and predictor set for modeling bl researchers in the past considered different combinations of input parameters for improving the accuracy of bl predictions the input data for bl predictions can be prepared considering hydraulic characteristics alone or using hydraulic and sediment properties but often constrained by the availability of datasets to cope with this setback different researches included hydraulic properties like discharge velocity channel properties like manning s roughness particle size channel dimensions etc for the prediction of bedload azamathulla et al 2009 chang et al 2012 haddadchi et al 2012 investigated the suitability of different bedload transport formulae considering the field datasets node river from north eastern iran accounting several universal bedload predictors haddadchi et al 2013b made a comprehensive investigation on the suitability of twelve popular predictive bedload transport equations against bedload and bed material grain size as inputs they found that the sediment transport equations are sensitive to these input parameters bedload transport has a dynamic nature in gravel bed rivers and the complexity of the phenomenon induces uncertainties in predictions riahi madvar and seifi 2018 kitsikoudis et al 2014 reported that the combination of hydraulic parameters involving unit stream power stream power and shear stress depicts the prediction of bl transport in the best way pektas and dogan 2015 attempted to include suspended sediment load data along with the hydraulic parameters for the prediction of bl and reported an improvement in the performance of bl prediction models they reported that the presence of a high value of sediment load leads to poor performance and its exclusion improved the performance roushangar and shahnazi 2019 considered two scenarios for the model inputs of sediment transport based on 1 only hydraulic characteristics and 2 both hydraulic and sediment factors they reported an improvement in sediment load prediction on considering the second scenario given the emergence of machine learning ml models in recent decades and their superiority in simulating many hydrological issues compared to experimental methods these models have been used increasingly for the estimation of sediment transport sharghi et al 2019b yilmaz et al 2018 zounemat kermani 2017 in recent years several successful applications of machine learning ml in simulating sediment transport have been reported given the hydraulic data such as river flow discharge adnan et al 2019 afan et al 2015 baniya et al 2019 parallel to the usage of standard ml models some researchers tried to get the advantages of integrative machine learning models in simulating sediment load in rivers memarian et al 2013 employed an integrative ml model based on the combination of multi layer perceptron mlp neural network and genetic algorithm ga for sediment load simulation in a tropical watershed it was reported that the integrative ga mlp model presented a reliable performance for sediment load modeling sahraei et al 2017 coupled particle swarm optimization pso algorithm to calibrate the regularization and kernel parameters of least square support vector regression lssvr as an alternative integrative method for estimating ssl in channels the findings of the study proved the superiority of the integrative ml model in ssl estimation in comparison to traditional ml models yadav et al 2018 applied a genetic algorithm ga for developing two types of integrative models such as artificial neural networks ann and support vector machines svm for sediment load prediction in comparison to the standard version of the applied ml models the results showed that integrative ml models are better candidates for simulation of the ssl prediction roushangar and shahnazi 2019 challenged the potential of an integrative pso wkelm model a wavelet kernel extreme learning machine coupled with the particle swarm optimization algorithm versus standard ml model in predicting bl in rivers the findings of the study confirmed the higher predictive potential of the pso wkelm integrative ml model in comparison with svm as a standard ml model studying published works in the use of ml methods in sediment modeling implies that the majority of researches focused on using ml models in simulating suspended sediment load ssl compared to bedload bl choubin et al 2018 khosravi et al 2018 khan et al 2019 kumar et al 2019 due to a large number of published pertinent studies using ml models in ssl and bl modeling reporting and covering them requires an ample space which is beyond the aim of this paper however to gain a general concept a concise summary of the most updated research published is presented in table 1 as shown in table 1 the majority of studies on sediment transport modeling in rivers have focused on ssl simulation also no comprehensive study similar to the present research was found to investigate the simultaneous deposition of sediment transport in ssl and bl based on the flow data 1 3 objectives and contribution of the study despite the contributions of various traditional ml studies in sediment load modeling many researchers have emphasized the necessity of integrating meta heuristic algorithms with standard ml models to obtain better results in modeling complex phenomena rajaee et al 2011 zounemat kermani 2017 kisi et al 2019 zounemat kermani et al 2019 therefore this study aims to evaluate the performance of traditional methods src mlr standard ml methods anfis svr and integrative ml and nature inspired methods ga anfis ga svr in predicting sediment load including ssl and bl for this purpose daily long term sediment transport data along the flow discharge of the grande de loíza river in puerto rico are used comparing and appraising the performance of different traditional statistical methods as well as standard and integrative ml models in simulating both ssl and bl is the main novelty of this paper besides exploring previous hydrological studies also shows that evaluating anfis and svr methods as integrative models is only limited to scour prediction around bridge piers sreedhara et al 2018 therefore the performance assessment of the genetic algorithm integrated with machine learning models i e svr and anfis in hydrological processes in sediment transport modeling can be mention as the contribution of the study 2 methods and methodology the models applied in this study are divided into three groups 1 traditional models including src and mlr 2 standard ml models including anifs and svr and 3 integrated ga svr and ga anfis models see fig 1 the following sections describe the overall operation of each model 2 1 traditional models src mlr a sediment rating curve src establishes a relationship between sediment discharge and stream discharge using a graph or equation and can be utilized for estimation of sediment loads using streamflow values asselman 2000 the general form of the sediment rating curve can be written as 1 s a q b where q and s indicate stream discharge and sediment load respectively also a and b are the rating curve parameters that the a coefficient denotes the index of erosion severity and the coefficient indicates the erosive power of the river asselman 2000 it can be mentioned that they can be obtained from the observed data using the regression process by considering a linear regression employing the correction factor is essential to avoid underestimation ssl values however in this study a non linear least squares regression is applied that the sediment load can be estimated at a specific value for stream discharge aytek and kişi 2008 in addition to the traditional src mode this study employs the statistical multiple linear regression mlr model to predict the dependent ssl bl values by using input variables x 1 x 2 x n in general the mlr can be defined as rajaee et al 2011 2 y i β 0 β 1 x i 1 β 2 x i 2 β p x ip ε i where i and yi denote the number of observations and output variables ssl bl respectively βi and εi indicate the coefficient of input variables and residual error respectively note that for applying predictive mlr models the input variables should be independent and values of residual errors should be normally distributed šiljić tomić et al 2018 in the mlr modeling process β values can be tuned by using observation values to find output values with a minimum error during training and testing phases for this purpose in this study the least square approach lsa was used to calibrate the mlr model to minimize the difference between the predicted and observed values 2 2 adaptive neuro fuzzy inference system anfis jang 1993 introduces the adaptive neuro fuzzy inference system as a universal approximation approach from the three common types of fuzzy inference systems tsukamoto s system sugeno s system and mamdani s system the sugeno first order fuzzy method is more reliable than the others jang et al 1997 takagi and sugeno 1985 in this scheme by applying two fuzzy if then statements the following rules can be defined talei et al 2010 3 rule 1 if x is a 1 and y is b 1 then f 1 p 1 x q 1 y r 1 4 rule 2 if x is a 2 and y is b 2 then f 2 p 2 x q 2 y r 2 in which x and y are predictor variables and a1 a2 b1 and b2 values indicate membership indexes for x and y and p1 q1 r1 and p2 q2 r2 denote output function f1 and f2 parameters for establishing rules in the anfis model grid partitioning and subtractive fuzzy clustering have been developed nayak et al 2004 in this study the fuzzy c means fcm clustering approach is applied for constructing a relationship based on rules between predictor and predicted variables also a combination of the least squares and backpropagation gradient descent methods optimization is utilized for obtaining parameters of the membership functions mfs sanikhani et al 2018 the general structure of an anfis is based on a multilayer network and consists of such connected nodes that the last layer computes the final output of the anfis model using the single node salih et al 2019b the equivalent anfis architecture is shown in fig 2 a 2 3 support vector regression svr support vector machines svms as robust classification approaches have gained popularity in water resource management applications raghavendra and deka 2014 the svm method has been suggested by cortes and vapnik 1995 and implemented based on statistical learning concepts svms are applicable for solving both regression and classification problems in this study support vector regression svr is used to find a relationship between an independent variable and dependent variable sets the svr is characterized by a two layer network using nonlinear weights in the first and linear ones in the second layer the estimator function of regression can be written as vapnik 1998 5 f x ω φ x b where ω and b are a coefficient that should be obtained from the data and weight matrix respectively and ϕ indicates inputs feature function the values for ω and b can be calculated by minimizing the risk function 6 r c 1 2 ω 2 c 1 n i 1 n l ε d i y i where 7 l ε d y d y ε i f d y ε 0 otherwise in which lε d y and c denote the ε insensitive loss function and the regularized index respectively and ε represents the tube size for solving eq 7 it should be transformed into a constrained optimization expression as 8 minimize 1 2 ω 2 c i 1 n ξ i ξ i 9 s u b j e c t to ω i φ x i b i d i ε ξ i i 1 2 n d i ω i φ x i b i ε ξ i i 1 2 n where ξ and ξ are slack parameters constrained optimization can be solved using the lagrangian mathematical technique and karush kuhn tucker conditions also it can be mentioned that in this study the gaussian kernel function is used fig 2 b shows the svr model schematic representation 2 4 integration procedure of the integrative models one of the main problem of the traditional optimization techniques is that they may drop in local optimum kisi et al 2017 in this study to overcome this drawback a reliable well known evolutionary optimization approach genetic algorithm ga which has been extensively used in water resource problems is applied to find the parameters of the anfis and svr models due to the remarkable capabilities of ga it can acquire a global optimal result to minimize error in the next step the optimized anfis and svr models are utilized for both the ssl and bl simulation the ga is one of the heuristic search methods based on natural evolution process for solving nonlinear optimization problems that was developed by holland 1975 and has been extensively applied in hydrological studies for enhancing the performance of soft computing models by minimizing the difference between predicted and observed values danandeh mehr et al 2018 yaseen et al 2019 the ga produces a set of a population string at the first stage and then evaluates the fitness index for each string by calculating the difference between observed and computed values using a fitness function in the next stage the new generation should be produced using a selection operation in this study the roulette wheel selection strategy is applied to find the fittest individuals have more chance individual fitness to participate in the mating pool for establishing the next generation in the crossover operation the produced generation from the selection operator is used to create two child individuals by considering a degree of probability finally the mutation operator ensures to avoid being trapped in local optima using the polynomial mutation method more details about the ga can be found in ahmed and sarma 2005 in this study membership functions mf parameters of the integrative anfis model and the kernel s constant parameters the regularization parameter c and the insensitive loss coefficient ε of the integrative svr approach are determined by ga in general the process of applying ga to determine anfis and svr parameters includes 1 creating the structure of svr and anfis 2 initializing the ga parameters see table 2 3 creating a cost function to evaluate the fitness of the agents of population in each iteration and 4 executing the ga to determine optimization parameters in the integrative models the employed procedure is shown in fig 3 3 case study and dataset in this study daily measured values of three hydrologic parameters including mean flow suspended sediment and bedload data of a gauged station belonging to the caguas municipio basin on the rio grande de loíza drainage area 232 6 km2 and gagedatum 50 0 m above ngvd29 in puerto rico are used fig 4 the grande de loíza is the largest river in puerto rico island in volume and flows into the atlantic ocean the data was downloaded from the web site of the united states geological survey usgs hydrologicunitcode 21010005 the data length covers a five years long duration 1 january 1984 31 december 1988 the first four years of the daily datasets 80 of the data from 1 1 1984 to 31 12 1987 are assigned to the training data and the data corresponds to the last year of the period 20 of datasets from 1 1 1988 to 31 12 1988 are used for evaluating the models capabilities in terms of testing data fig 5 shows the historical variation of the flow ssl and bl over the training and testing periods furthermore descriptive statistical information for the applied datasets is presented in table 3 the descriptive statistics of data including range mean and standard deviation std is given in table 3 table 3 clearly shows the magnitude of the difference between the flow suspended sediment and bedload values it can be seen that the ranges of testing datasets fall into the ranges of training datasets this fact confirms the validity of choosing the proper periods for the training and testing set so that the models will not encounter any unseen data the data that does not fall into the training set domain for the testing phase in other words the evaluation of the models will reflect their potential leaving no room for doubt about problems related to the existence of unseen data considering the coefficient of variation values cv it can also be observed that the data distribution of ssl cv 8 5 and bl cv 6 7 values are much more dispersed than the flow data cv 2 7 which defines them as more sporadic phenomena than the flow rate series itself comparing the calculated correlation values between the flow rate and bl as well as the flow rate and ssl shows that flow data has less influence on bl rather than ssl besides the zero p values of the run test for testing the randomness of a distribution implies that the flow ssl and bl data series do not follow a particular predictable trend 4 performance measures and evaluation criteria the present study evaluates the prediction capability of the applied models by using two deviance measures including the root mean square error rmse and the mean absolute error mae a similarity statistical measure the coefficient of determination r2 and an efficiency measure the nash sutcliffe efficiency nse rmse and mae are among the best overall deviance statistical measures of model evaluation according to willmott and willmott and matsuura 2005 in comparison to the mae the rmse is not a good criterion of average model performance however mae is less sensitive to extreme data than rmse r2 reflects the correlation between the observed and modeled values and a value of unity implies that the dispersion of the modeled values is equal to that of the observed data it is worth noting that an under or over predict model might still result in good values for r2 close to 1 0 even if all predictions are inaccurate thus it is recommended to take into account an additional measure which can cope with this drawback hence in this study the nse coefficient is considered as the fourth criterion for having a comprehensive appraisal of the models performance elzwayie et al 2016 krause and boyle 2005 mathematical formulations of the mentioned measures are written as below 10 rmse i 1 n s m s o 2 n range 0 ideal value 0 11 mae 1 n i 1 n s m s o range 0 ideal value 0 12 r 2 i 1 n s m s m s o s o 2 i 1 n s m s m 2 i 1 n s o s o 2 range 0 1 ideal value 1 13 nse 1 i 1 n s m s o 2 i 1 n s o s o 2 range 1 ideal value 1 where so is the observed value of ssl and bl kg s sm stands for the modeled simulated predicted value of ssl and bl kg s in the training testing set n is the number of the data samples and bar denotes the mean value of the observed modeled data 5 application analysis and results the main objective of the current research is to investigate the capacity of integrative classical ml models including anfis and svr with a nature inspired optimization algorithm called genetic algorithm for modeling riverbed sediment load bl and suspended sediment load ssl the premier goal of developing such an integrative model is to overcome the hyperparameter associated problem based on the reported literature within the field of hydrology the feasibility of the ga for tuning ai models demonstrated promising progress bozorg haddad et al 2017 ghorbani et al 2018 roushangar and koosheh 2015 the proposed integrative ai models were validated against the traditional sediment rating curve src multiple linear regression mlr and standalone anfis and svr models conceptually in modeling river sediment the river flow discharge q is one of the essential hydrological processes that influences the sediment amount transport kisi and yaseen 2019 hence in this study the prediction matrix of the applied predictive models is constructed based on the lead times of the correlated magnitudes of q and the bl and ssl themselves note that the correlated lead values are determined using the statistical correlation following several studies conducted over the literature afan et al 2014 kisi 2012 fig 6 the constructed input combinations are tabulated in table 4 it can be noticed from table 4 that there are two types of scenarios input i incorporated only the river discharge information whereas input ii incorporated the river discharge and sediment information for the bl and ssl it is worth noting that in real world modeling the first input scenario is more practical than the second scenario 5 1 suspended sediment load modeling results table 5 reports the statistical results of the applied proposed integrative ml models ga anfis and ga svr as well as traditional and conventional ml models for both modeling scenarios over the training phase for the evaluation purpose the minimal absolute error measures i e rmse and mae the model efficiency i e nse and best fit goodness measure i e r2 are considered in general the determination coefficient r2 revealed good performance for all models as per the reported research moriasi et al 2007 the training prediction exhibits a variance predictability capacity and this is observable over the proposed modeling scenarios table 5 this can be justified due to the sufficiency of the data span used for the learning process however the integrative ai models ga models demonstrate the superior potential for training the predictive models 26 to 54 improvement in mae values see table 5 apparently this is due to the efficiency of nature inspired optimization algorithms where the appropriate tuning internal parameters were allocated for the anfis and svr models it is worth highlighting that the lowest prediction performance was attained using the traditional approaches which is a normal outcome following several established pieces of research over the literature rajaee et al 2011 the potential of the applied predictive models for modeling ssl over the testing phase and for both modeling scenarios is reported in table 6 and fig 7 the statistical performances demonstrate a variance between all models and over both the modeling scenarios of the input variables in other words the evidence reveals the superiority of the integrative ml models i e ga anfis and ga svr over the traditional and conventional ml models for instance combining the ga algorithm with the svr i model rmse of ga svr i 18 670 improves the rmse values of svr i rmse of ga svr 19 896 up to 1 123 kg s overall the ga anfis ii model with minimal rmse 16 82 kg s and maximal nse 0 918 and ga svr ii with the best equilibrium values for nse 0 905 mae 2 809 kg s and rmse 18 02 kg s acted better than the other applied models it is worth to mention that the determination coefficient indicator is not efficient here to demonstrate the predictability performance presentation hence a combination of evaluation indicators e g rmse mae nse and r2 provides a meaningful opportunity to evaluate the developed predictive models 5 2 bedload modeling results the statistical performance of the bl modeling over the training and testing phases using all of the applied predictive models is tabulated in tables 7 and 8 respectively one major observation in the reported statistical performances is the considerable difference between the r2 values for the first input combinations scenario i and second input combinations scenario ii for instance the mlr i has an r2 0 212 whereas the mlr ii has an improved r2 0 530 see table 7 the same trend can be observed more or less for the other models however one should note that r2 sometimes fails to give an informative evaluation for the prediction accuracy yaseen et al 2016 hence a combination of indicators should be established for the modeling evaluation on the other hand it can clearly be seen that the src and mlr i models perform poorly according to the rmse r2 mae and nse criteria see tables 7 and 8 over the training phases the integrative ga svr ii model using the second modeling scenario input variability was accomplished the minimal absolute error measures value rmse 0 53 kg s and mae 0 074 kg s over the testing phase the integrative ga anfis ii using the second modeling scenario demonstrates the best accuracy in terms of rmse 0 53 kg s r2 0 72 nse 0 714 and 42 6 mae improvement while ga svr ii provides the lowest value for mae 0 061 kg s and 72 7 mae improvement it can be also concluded that taking into account the sediment information in the second input scenario models ii noticeably improves the prediction capabilities of the applied models tables 6 and 8 and fig 8 5 3 incorporative diagnostic analysis for having a better and comprehensive visualization the proposed traditional and conventional predictive models are evaluated graphically using scatterplots over the testing phase as reported in figs 9 and 10 for ssl and bl respectively in these figures the best predictive models were displayed for better understanding based on the reported graphical presentation for ssl prediction the highest correlation and best match between the measured and predicted values are attained using the integrative ga anfis and the standalone anfis models using the second modeling scenario input variability this can be best explained due to the high stochasticity pattern of the ssl which requires informative hydrological variables for capturing the complexity of the ssl system e g river discharge hence the incorporation of the antecedent values of ssl improves the accuracy of predicted sll values the attained correlation coefficient values for the ga anfis ii and anfis ii models are slightly similar r 0 96 it should be noted although the highest correlation obtained for the ga anfis ii and anfis ii models however these two models demonstrate a noticeable overestimation trend for the minimal sediment magnitudes on the contrary a more coherent prediction agreement for the integrative ga svr and standalone svr can be observed over both modeling scenarios fig 10 illustrates the scatterplots trend for the bl sediment prediction a consistent predictability performance can be observed for the integrative anfis ga ii model for predicting bl sediment with the highest correlation coefficient r 0 85 however a remarkable diversion from the best fit line for all models toward the over estimation manners can be distinguished except for the attained results using the integrative ga svr ii model r 0 79 it is worth to mention the applied predictive models failed to predict the high magnitudes of the sediments for both ssl and bl this is apparently owing to the sudden changes in the river discharge amount this is due to high rainfall intensity events that generate land sliding phenomena hence the applied models apparently demonstrated an observable limitation toward those high magnitudes of sediment loads another explanation for this limitation the developed predictive models did not experience those high magnitudes of sediment for both ssl and bl during the training modeling phase and thus failed to mimic the actual mechanism between the predictors and predictand variables note that this is a time series sequential hydrological process where random periodic modeling development cannot be established here this can be better understood through the incorporation of the casual hydrological variables such as climatological hydraulic characteristics or other related essential hydrological variables as external predictors for better prediction matrix fig 11 displays the 2 dimensional graphical presentation called the taylor diagram for the developed predictive models for the ssl and bl respectively taylor diagram is one of the best graphical visualizations to evaluate the prediction accuracy based on several statistical indicators taylor 2001 it presents the summary statistical indicators of the measured and predicted sediment including correlation coefficients standard deviations and root mean square error in other words the taylor diagram provides an excellent graphical representation of the similarity between the predicted and observed values fig 11 reveals the slightly similar performance of the applied predictive models for both modeling input scenarios however the proposed integrative ga anfis ii and ga svr ii indicate the closest coordinates to the measured ssl on the other hand fig 11 indicates that ga anfis ii is the best predictive model toward the measured bl benchmark 6 deliberation and discussion from the results of this study it was found that irrespective of the method used the prediction of ssl was reasonably accurate by all the methods with an r2 ranging from 0 857 to 0 934 and nse ranging from 0 814 to 0 918 for the testing data for all of the applied models despite the use of ml techniques or their variants the predictability of bl is less accurate than the ssl which is a major concern for the modelers along with the inclusion of appropriate parameter sets a considerable amount of effort is required in the model development phase further examination and deliberation for the attained results of the models can be achieved by the use of hysteresis analysis hysteresis analysis is a promising graphical tool for studying the non linear relationship between sediment concentration and fluvial discharge lloyd et al 2016 it is basically plotted between sediment load and fluvial discharge in this study a flood hydrograph in the testing phase from 22 08 1988 to 30 08 1988 is considered for the hysteresis analysis of both ssl and bl the flood hydrograph hysteresis loop of observed ssl and hysteresis loops of ssl predicted by the best integrative model and the basic src models are presented in fig 12 the corresponding plots for bl are also provided in fig 13 the properties of the loop can be quantified by its primary characteristic property mean hysteresis index himid which effectively shows the dynamic response of suspended sediment concentrations to flow changes during storm events the himid index estimates the fatness of the hysteresis loop corresponds to the mid point discharge of the flood hydrograph eqs 14 and 15 lawler et al 2006 14 h i mid s r s f 1 clockwise 15 h i mid 1 s r s f 1 anti clockwise in the above formulae s stands for sediment load which can be either bedload or suspended load r stands for rising limb and f stands for falling limb him 0 indicates a weak hysteresis loop a positive value indicates a clockwise loop and a negative value indicates an anticlockwise loop the computed himid values are given in figs 12 and 13 figs 12 and 13 show that for the ssl the hysteresis loop is clockwise while for bl it is anti clockwise in nature the clockwise hysteresis loop is formed due to an increasing concentration of sediment that forms more rapidly during rising limb which suggests a source of sediment close to the monitoring point and sediment depletion in the channel system baniya et al 2019 on the contrary an anticlockwise hysteresis loop shows a long gap between the discharge and concentration peak which suggests that the source is located far from the monitoring point or bank collapse lloyd et al 2016 as for the ssl modeling it is clear from fig 12 that the ga anfis ii model displays excellent predictability and the hysteresis loop of anfis ga based predictions shows striking similarity with that of observed values himid 0 81 vs 0 97 the hysteresis loop of src based predictions shows a significant deviation from that of the observed data which indicates poor predictability power of the src model himid 0 38 hysteresis analysis for the bl model can be seen in fig 13 fig 13 implies that the ga anfis ii model shows fair performance in the prediction of the bl correctly while the src method could not simulate the bl of the river system well although there is a considerable difference between the calculated himid values for the observed loop and predicted ga anfis ii s loop 2 22 vs 6 12 this illustration clearly depicts that the ml model ga anfis was successful in regenerating the hysteresis loop in contrast the src failed in capturing the loop fig 13 that is the corresponding himid value for the src model is 0 03 which is close to zero and indicates no loop at all it is noteworthy that the data length in the present work covers five consecutive years from 1984 to 1989 thus the results obtained here are confined to a moderate time series dataset so more future works are needed for reaching holistic feedback on the merits of the usage of integrative ml models in bl and ssl prediction 7 conclusions this study performed a systematic evaluation of complexities in suspended sediment load ssl and bedload bl prediction in river flow through a multitude of statistical and machine learning ml methods the predictive methods included traditional models src mlr conventional ml models svr anfis and integrative ml models ga svr ga anfis the applied models were constructed based on the flow rate discharge data and by considering two different input scenarios with and without past records of sediment data from the major findings of this study the following general observations can be pointed out i the predictability of ssl was better than the prediction of bl irrespective of the model applied ii src and conventional models showed poor performance in prediction of both ssl and bl iii the inclusion of lagged inputs of sediment was more effective in improving the predictability of the ssl than bl iv regardless of the input scenarios the machine learning models were superior to the traditional methods in prediction of ssl and bl and v a blatant improvement in predicting ability of integrative ml models could be observed in comparison to the standard ml models an average improvement of 7 of rmse and 10 of r2 indeed the current study showed that ml models could be successfully employed to simulate and predict the nonlinear river ssl process in situations where both temporal river flow and sediment data are available however considering the complex nature of the bedload bl time series the utilization of the ml methods can be more beneficial by having access to extra physiographical information such as landslide susceptibility maps of the watershed credit authorship contribution statement mohammad zounemat kermani writing original draft writing review editing formal analysis amin mahdavi meymand data curation software formal analysis meysam alizamir writing original draft writing review editing methodology s adarsh writing original draft writing review editing zaher mundher yaseen writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
5522,sediment transportation in water bodies may cause many problems for the water resources projects and damage the environment hence modeling sediment load components including suspended sediment load ssl and bedload bl in rivers is of prime importance effective modeling of ssl and bl remains a challenging task due to their complex hydrological process on this account this study aims to appraise the potential of conventional machine learning ml models including adaptive neuro fuzzy inference system anfis support vector regression svr and their integrative version with nature optimization algorithm called genetic algorithm ga anfis and ga svr for ssl and bl prediction two traditional models are developed for modeling verification including the sediment rating curve src and multiple linear regression mlr the modeling results are assessed using four statistical measures e g root mean square error rmse mean absolute error mae nash sutcliffe efficiency nse and coefficient of determination r2 diagnostic analysis scatter plots and taylor diagram and evaluation of the dependence of the state of the river flow sediment system hysteresis analysis based on the attained predictability performance the integrative ml models reveal a superior prediction capacity in comparison with the standalone anfis svr and the traditional models in quantitative evaluation the proposed integrative ml models indicate a remarkable prediction enhancement approximately 44 mean magnitude based on the mae metric against the src traditional model for both the ssl and bl predicted values overall the current investigation evidences the potential of the nature inspired algorithm as a hyper parameter optimizer for ml models that produce a reliable and robust predictive model for sediment concentration quantification keywords heuristic algorithms soft computing hydrology bed load river engineering 1 introduction 1 1 background and motivation in river engineering sediment load is defined as the total amount of sediment output transported by rivers and streams from a watershed accurate estimation of sediment load is crucial to river engineering and management including stable channel design river restoration as well as issues related to the water quality of the river the changes in sediment load and transportation in rivers which may get influenced by spatial and temporal factors can follow an extreme nonlinear process fan and yao 2008 kuai and tsai 2012 sadeghi and mostafazadeh 2016 at the larger time scales the climatic and anthropogenic factors and all the events within the season will be influencing the sediment load patterns the spatial and temporal changes in the watershed characteristics like vegetation cover and soil moisture condition can influence the transport processes of sediment load lyn 1987 henceforth given the complex and nonlinear behavior of the sediment transport process which is influenced by different watershed hydrographic and hydraulic flow factors it is not easy to construct an accurate sediment estimation tool kisi and yaseen 2019a kiyoumars roushangar and shahnazi 2019 the sediment loads of a watershed can be divided into three groups including bedload bl suspended sediment load ssl and wash load fine sediments fall within ssl and may be carried long distances before deposition even under the base and low flow conditions salih et al 2019a on the other hand bl is generally composed of coarse grained sediments that comprise a significant volume of sediment at higher discharges and floods given the varying sedimentation behaviors in ssl and bl states as well as the complexity of the transitional sedimentation phenomena in rivers it is necessary to use models capable of capturing complex processes haddadchi et al 2013b zounemat kermani et al 2016 the wash load consists of very fine and cohesive sediments haddadchi et al 2013a since there was no available measured data for the wash load in this study we have excluded this type of sediment transportation and have focused on bl and ssl for the sediment load prediction tao et al 2019 the accuracy of the sediment prediction models depends on several temporal and spatial factors including the measurement scale of data such as daily weekly or monthly data length input variables selected etc in addition the sediment load in rivers results from weathering land sliding and glacial and fluvial erosion baniya et al 2019 the highly diverse composition of sediment load and bedload make the sediment transport modeling a complex problem and the input selection procedure is a crucial step in this exercise the area of the catchment land cover slope and topography of the catchment rainfall intensity and volume temperature soil characteristics etc are some of the key factors influencing ssl and bl from the basin traditional flow based methods such as the sediment rating curve src do not have a great ability to estimate sediment transportation due to reliance on sediment loads versus discharge rajaee et al 2011 1 2 literature review machine learning and sediment modeling many studies reported that the use of lagged values of river discharge suspended sediment and precipitation is sufficient for the prediction of ssl kakaei lafdani et al 2013 adnan et al 2019 salih et al 2019b the accurate prediction of bl is more difficult than ssl and predictor set for modeling bl researchers in the past considered different combinations of input parameters for improving the accuracy of bl predictions the input data for bl predictions can be prepared considering hydraulic characteristics alone or using hydraulic and sediment properties but often constrained by the availability of datasets to cope with this setback different researches included hydraulic properties like discharge velocity channel properties like manning s roughness particle size channel dimensions etc for the prediction of bedload azamathulla et al 2009 chang et al 2012 haddadchi et al 2012 investigated the suitability of different bedload transport formulae considering the field datasets node river from north eastern iran accounting several universal bedload predictors haddadchi et al 2013b made a comprehensive investigation on the suitability of twelve popular predictive bedload transport equations against bedload and bed material grain size as inputs they found that the sediment transport equations are sensitive to these input parameters bedload transport has a dynamic nature in gravel bed rivers and the complexity of the phenomenon induces uncertainties in predictions riahi madvar and seifi 2018 kitsikoudis et al 2014 reported that the combination of hydraulic parameters involving unit stream power stream power and shear stress depicts the prediction of bl transport in the best way pektas and dogan 2015 attempted to include suspended sediment load data along with the hydraulic parameters for the prediction of bl and reported an improvement in the performance of bl prediction models they reported that the presence of a high value of sediment load leads to poor performance and its exclusion improved the performance roushangar and shahnazi 2019 considered two scenarios for the model inputs of sediment transport based on 1 only hydraulic characteristics and 2 both hydraulic and sediment factors they reported an improvement in sediment load prediction on considering the second scenario given the emergence of machine learning ml models in recent decades and their superiority in simulating many hydrological issues compared to experimental methods these models have been used increasingly for the estimation of sediment transport sharghi et al 2019b yilmaz et al 2018 zounemat kermani 2017 in recent years several successful applications of machine learning ml in simulating sediment transport have been reported given the hydraulic data such as river flow discharge adnan et al 2019 afan et al 2015 baniya et al 2019 parallel to the usage of standard ml models some researchers tried to get the advantages of integrative machine learning models in simulating sediment load in rivers memarian et al 2013 employed an integrative ml model based on the combination of multi layer perceptron mlp neural network and genetic algorithm ga for sediment load simulation in a tropical watershed it was reported that the integrative ga mlp model presented a reliable performance for sediment load modeling sahraei et al 2017 coupled particle swarm optimization pso algorithm to calibrate the regularization and kernel parameters of least square support vector regression lssvr as an alternative integrative method for estimating ssl in channels the findings of the study proved the superiority of the integrative ml model in ssl estimation in comparison to traditional ml models yadav et al 2018 applied a genetic algorithm ga for developing two types of integrative models such as artificial neural networks ann and support vector machines svm for sediment load prediction in comparison to the standard version of the applied ml models the results showed that integrative ml models are better candidates for simulation of the ssl prediction roushangar and shahnazi 2019 challenged the potential of an integrative pso wkelm model a wavelet kernel extreme learning machine coupled with the particle swarm optimization algorithm versus standard ml model in predicting bl in rivers the findings of the study confirmed the higher predictive potential of the pso wkelm integrative ml model in comparison with svm as a standard ml model studying published works in the use of ml methods in sediment modeling implies that the majority of researches focused on using ml models in simulating suspended sediment load ssl compared to bedload bl choubin et al 2018 khosravi et al 2018 khan et al 2019 kumar et al 2019 due to a large number of published pertinent studies using ml models in ssl and bl modeling reporting and covering them requires an ample space which is beyond the aim of this paper however to gain a general concept a concise summary of the most updated research published is presented in table 1 as shown in table 1 the majority of studies on sediment transport modeling in rivers have focused on ssl simulation also no comprehensive study similar to the present research was found to investigate the simultaneous deposition of sediment transport in ssl and bl based on the flow data 1 3 objectives and contribution of the study despite the contributions of various traditional ml studies in sediment load modeling many researchers have emphasized the necessity of integrating meta heuristic algorithms with standard ml models to obtain better results in modeling complex phenomena rajaee et al 2011 zounemat kermani 2017 kisi et al 2019 zounemat kermani et al 2019 therefore this study aims to evaluate the performance of traditional methods src mlr standard ml methods anfis svr and integrative ml and nature inspired methods ga anfis ga svr in predicting sediment load including ssl and bl for this purpose daily long term sediment transport data along the flow discharge of the grande de loíza river in puerto rico are used comparing and appraising the performance of different traditional statistical methods as well as standard and integrative ml models in simulating both ssl and bl is the main novelty of this paper besides exploring previous hydrological studies also shows that evaluating anfis and svr methods as integrative models is only limited to scour prediction around bridge piers sreedhara et al 2018 therefore the performance assessment of the genetic algorithm integrated with machine learning models i e svr and anfis in hydrological processes in sediment transport modeling can be mention as the contribution of the study 2 methods and methodology the models applied in this study are divided into three groups 1 traditional models including src and mlr 2 standard ml models including anifs and svr and 3 integrated ga svr and ga anfis models see fig 1 the following sections describe the overall operation of each model 2 1 traditional models src mlr a sediment rating curve src establishes a relationship between sediment discharge and stream discharge using a graph or equation and can be utilized for estimation of sediment loads using streamflow values asselman 2000 the general form of the sediment rating curve can be written as 1 s a q b where q and s indicate stream discharge and sediment load respectively also a and b are the rating curve parameters that the a coefficient denotes the index of erosion severity and the coefficient indicates the erosive power of the river asselman 2000 it can be mentioned that they can be obtained from the observed data using the regression process by considering a linear regression employing the correction factor is essential to avoid underestimation ssl values however in this study a non linear least squares regression is applied that the sediment load can be estimated at a specific value for stream discharge aytek and kişi 2008 in addition to the traditional src mode this study employs the statistical multiple linear regression mlr model to predict the dependent ssl bl values by using input variables x 1 x 2 x n in general the mlr can be defined as rajaee et al 2011 2 y i β 0 β 1 x i 1 β 2 x i 2 β p x ip ε i where i and yi denote the number of observations and output variables ssl bl respectively βi and εi indicate the coefficient of input variables and residual error respectively note that for applying predictive mlr models the input variables should be independent and values of residual errors should be normally distributed šiljić tomić et al 2018 in the mlr modeling process β values can be tuned by using observation values to find output values with a minimum error during training and testing phases for this purpose in this study the least square approach lsa was used to calibrate the mlr model to minimize the difference between the predicted and observed values 2 2 adaptive neuro fuzzy inference system anfis jang 1993 introduces the adaptive neuro fuzzy inference system as a universal approximation approach from the three common types of fuzzy inference systems tsukamoto s system sugeno s system and mamdani s system the sugeno first order fuzzy method is more reliable than the others jang et al 1997 takagi and sugeno 1985 in this scheme by applying two fuzzy if then statements the following rules can be defined talei et al 2010 3 rule 1 if x is a 1 and y is b 1 then f 1 p 1 x q 1 y r 1 4 rule 2 if x is a 2 and y is b 2 then f 2 p 2 x q 2 y r 2 in which x and y are predictor variables and a1 a2 b1 and b2 values indicate membership indexes for x and y and p1 q1 r1 and p2 q2 r2 denote output function f1 and f2 parameters for establishing rules in the anfis model grid partitioning and subtractive fuzzy clustering have been developed nayak et al 2004 in this study the fuzzy c means fcm clustering approach is applied for constructing a relationship based on rules between predictor and predicted variables also a combination of the least squares and backpropagation gradient descent methods optimization is utilized for obtaining parameters of the membership functions mfs sanikhani et al 2018 the general structure of an anfis is based on a multilayer network and consists of such connected nodes that the last layer computes the final output of the anfis model using the single node salih et al 2019b the equivalent anfis architecture is shown in fig 2 a 2 3 support vector regression svr support vector machines svms as robust classification approaches have gained popularity in water resource management applications raghavendra and deka 2014 the svm method has been suggested by cortes and vapnik 1995 and implemented based on statistical learning concepts svms are applicable for solving both regression and classification problems in this study support vector regression svr is used to find a relationship between an independent variable and dependent variable sets the svr is characterized by a two layer network using nonlinear weights in the first and linear ones in the second layer the estimator function of regression can be written as vapnik 1998 5 f x ω φ x b where ω and b are a coefficient that should be obtained from the data and weight matrix respectively and ϕ indicates inputs feature function the values for ω and b can be calculated by minimizing the risk function 6 r c 1 2 ω 2 c 1 n i 1 n l ε d i y i where 7 l ε d y d y ε i f d y ε 0 otherwise in which lε d y and c denote the ε insensitive loss function and the regularized index respectively and ε represents the tube size for solving eq 7 it should be transformed into a constrained optimization expression as 8 minimize 1 2 ω 2 c i 1 n ξ i ξ i 9 s u b j e c t to ω i φ x i b i d i ε ξ i i 1 2 n d i ω i φ x i b i ε ξ i i 1 2 n where ξ and ξ are slack parameters constrained optimization can be solved using the lagrangian mathematical technique and karush kuhn tucker conditions also it can be mentioned that in this study the gaussian kernel function is used fig 2 b shows the svr model schematic representation 2 4 integration procedure of the integrative models one of the main problem of the traditional optimization techniques is that they may drop in local optimum kisi et al 2017 in this study to overcome this drawback a reliable well known evolutionary optimization approach genetic algorithm ga which has been extensively used in water resource problems is applied to find the parameters of the anfis and svr models due to the remarkable capabilities of ga it can acquire a global optimal result to minimize error in the next step the optimized anfis and svr models are utilized for both the ssl and bl simulation the ga is one of the heuristic search methods based on natural evolution process for solving nonlinear optimization problems that was developed by holland 1975 and has been extensively applied in hydrological studies for enhancing the performance of soft computing models by minimizing the difference between predicted and observed values danandeh mehr et al 2018 yaseen et al 2019 the ga produces a set of a population string at the first stage and then evaluates the fitness index for each string by calculating the difference between observed and computed values using a fitness function in the next stage the new generation should be produced using a selection operation in this study the roulette wheel selection strategy is applied to find the fittest individuals have more chance individual fitness to participate in the mating pool for establishing the next generation in the crossover operation the produced generation from the selection operator is used to create two child individuals by considering a degree of probability finally the mutation operator ensures to avoid being trapped in local optima using the polynomial mutation method more details about the ga can be found in ahmed and sarma 2005 in this study membership functions mf parameters of the integrative anfis model and the kernel s constant parameters the regularization parameter c and the insensitive loss coefficient ε of the integrative svr approach are determined by ga in general the process of applying ga to determine anfis and svr parameters includes 1 creating the structure of svr and anfis 2 initializing the ga parameters see table 2 3 creating a cost function to evaluate the fitness of the agents of population in each iteration and 4 executing the ga to determine optimization parameters in the integrative models the employed procedure is shown in fig 3 3 case study and dataset in this study daily measured values of three hydrologic parameters including mean flow suspended sediment and bedload data of a gauged station belonging to the caguas municipio basin on the rio grande de loíza drainage area 232 6 km2 and gagedatum 50 0 m above ngvd29 in puerto rico are used fig 4 the grande de loíza is the largest river in puerto rico island in volume and flows into the atlantic ocean the data was downloaded from the web site of the united states geological survey usgs hydrologicunitcode 21010005 the data length covers a five years long duration 1 january 1984 31 december 1988 the first four years of the daily datasets 80 of the data from 1 1 1984 to 31 12 1987 are assigned to the training data and the data corresponds to the last year of the period 20 of datasets from 1 1 1988 to 31 12 1988 are used for evaluating the models capabilities in terms of testing data fig 5 shows the historical variation of the flow ssl and bl over the training and testing periods furthermore descriptive statistical information for the applied datasets is presented in table 3 the descriptive statistics of data including range mean and standard deviation std is given in table 3 table 3 clearly shows the magnitude of the difference between the flow suspended sediment and bedload values it can be seen that the ranges of testing datasets fall into the ranges of training datasets this fact confirms the validity of choosing the proper periods for the training and testing set so that the models will not encounter any unseen data the data that does not fall into the training set domain for the testing phase in other words the evaluation of the models will reflect their potential leaving no room for doubt about problems related to the existence of unseen data considering the coefficient of variation values cv it can also be observed that the data distribution of ssl cv 8 5 and bl cv 6 7 values are much more dispersed than the flow data cv 2 7 which defines them as more sporadic phenomena than the flow rate series itself comparing the calculated correlation values between the flow rate and bl as well as the flow rate and ssl shows that flow data has less influence on bl rather than ssl besides the zero p values of the run test for testing the randomness of a distribution implies that the flow ssl and bl data series do not follow a particular predictable trend 4 performance measures and evaluation criteria the present study evaluates the prediction capability of the applied models by using two deviance measures including the root mean square error rmse and the mean absolute error mae a similarity statistical measure the coefficient of determination r2 and an efficiency measure the nash sutcliffe efficiency nse rmse and mae are among the best overall deviance statistical measures of model evaluation according to willmott and willmott and matsuura 2005 in comparison to the mae the rmse is not a good criterion of average model performance however mae is less sensitive to extreme data than rmse r2 reflects the correlation between the observed and modeled values and a value of unity implies that the dispersion of the modeled values is equal to that of the observed data it is worth noting that an under or over predict model might still result in good values for r2 close to 1 0 even if all predictions are inaccurate thus it is recommended to take into account an additional measure which can cope with this drawback hence in this study the nse coefficient is considered as the fourth criterion for having a comprehensive appraisal of the models performance elzwayie et al 2016 krause and boyle 2005 mathematical formulations of the mentioned measures are written as below 10 rmse i 1 n s m s o 2 n range 0 ideal value 0 11 mae 1 n i 1 n s m s o range 0 ideal value 0 12 r 2 i 1 n s m s m s o s o 2 i 1 n s m s m 2 i 1 n s o s o 2 range 0 1 ideal value 1 13 nse 1 i 1 n s m s o 2 i 1 n s o s o 2 range 1 ideal value 1 where so is the observed value of ssl and bl kg s sm stands for the modeled simulated predicted value of ssl and bl kg s in the training testing set n is the number of the data samples and bar denotes the mean value of the observed modeled data 5 application analysis and results the main objective of the current research is to investigate the capacity of integrative classical ml models including anfis and svr with a nature inspired optimization algorithm called genetic algorithm for modeling riverbed sediment load bl and suspended sediment load ssl the premier goal of developing such an integrative model is to overcome the hyperparameter associated problem based on the reported literature within the field of hydrology the feasibility of the ga for tuning ai models demonstrated promising progress bozorg haddad et al 2017 ghorbani et al 2018 roushangar and koosheh 2015 the proposed integrative ai models were validated against the traditional sediment rating curve src multiple linear regression mlr and standalone anfis and svr models conceptually in modeling river sediment the river flow discharge q is one of the essential hydrological processes that influences the sediment amount transport kisi and yaseen 2019 hence in this study the prediction matrix of the applied predictive models is constructed based on the lead times of the correlated magnitudes of q and the bl and ssl themselves note that the correlated lead values are determined using the statistical correlation following several studies conducted over the literature afan et al 2014 kisi 2012 fig 6 the constructed input combinations are tabulated in table 4 it can be noticed from table 4 that there are two types of scenarios input i incorporated only the river discharge information whereas input ii incorporated the river discharge and sediment information for the bl and ssl it is worth noting that in real world modeling the first input scenario is more practical than the second scenario 5 1 suspended sediment load modeling results table 5 reports the statistical results of the applied proposed integrative ml models ga anfis and ga svr as well as traditional and conventional ml models for both modeling scenarios over the training phase for the evaluation purpose the minimal absolute error measures i e rmse and mae the model efficiency i e nse and best fit goodness measure i e r2 are considered in general the determination coefficient r2 revealed good performance for all models as per the reported research moriasi et al 2007 the training prediction exhibits a variance predictability capacity and this is observable over the proposed modeling scenarios table 5 this can be justified due to the sufficiency of the data span used for the learning process however the integrative ai models ga models demonstrate the superior potential for training the predictive models 26 to 54 improvement in mae values see table 5 apparently this is due to the efficiency of nature inspired optimization algorithms where the appropriate tuning internal parameters were allocated for the anfis and svr models it is worth highlighting that the lowest prediction performance was attained using the traditional approaches which is a normal outcome following several established pieces of research over the literature rajaee et al 2011 the potential of the applied predictive models for modeling ssl over the testing phase and for both modeling scenarios is reported in table 6 and fig 7 the statistical performances demonstrate a variance between all models and over both the modeling scenarios of the input variables in other words the evidence reveals the superiority of the integrative ml models i e ga anfis and ga svr over the traditional and conventional ml models for instance combining the ga algorithm with the svr i model rmse of ga svr i 18 670 improves the rmse values of svr i rmse of ga svr 19 896 up to 1 123 kg s overall the ga anfis ii model with minimal rmse 16 82 kg s and maximal nse 0 918 and ga svr ii with the best equilibrium values for nse 0 905 mae 2 809 kg s and rmse 18 02 kg s acted better than the other applied models it is worth to mention that the determination coefficient indicator is not efficient here to demonstrate the predictability performance presentation hence a combination of evaluation indicators e g rmse mae nse and r2 provides a meaningful opportunity to evaluate the developed predictive models 5 2 bedload modeling results the statistical performance of the bl modeling over the training and testing phases using all of the applied predictive models is tabulated in tables 7 and 8 respectively one major observation in the reported statistical performances is the considerable difference between the r2 values for the first input combinations scenario i and second input combinations scenario ii for instance the mlr i has an r2 0 212 whereas the mlr ii has an improved r2 0 530 see table 7 the same trend can be observed more or less for the other models however one should note that r2 sometimes fails to give an informative evaluation for the prediction accuracy yaseen et al 2016 hence a combination of indicators should be established for the modeling evaluation on the other hand it can clearly be seen that the src and mlr i models perform poorly according to the rmse r2 mae and nse criteria see tables 7 and 8 over the training phases the integrative ga svr ii model using the second modeling scenario input variability was accomplished the minimal absolute error measures value rmse 0 53 kg s and mae 0 074 kg s over the testing phase the integrative ga anfis ii using the second modeling scenario demonstrates the best accuracy in terms of rmse 0 53 kg s r2 0 72 nse 0 714 and 42 6 mae improvement while ga svr ii provides the lowest value for mae 0 061 kg s and 72 7 mae improvement it can be also concluded that taking into account the sediment information in the second input scenario models ii noticeably improves the prediction capabilities of the applied models tables 6 and 8 and fig 8 5 3 incorporative diagnostic analysis for having a better and comprehensive visualization the proposed traditional and conventional predictive models are evaluated graphically using scatterplots over the testing phase as reported in figs 9 and 10 for ssl and bl respectively in these figures the best predictive models were displayed for better understanding based on the reported graphical presentation for ssl prediction the highest correlation and best match between the measured and predicted values are attained using the integrative ga anfis and the standalone anfis models using the second modeling scenario input variability this can be best explained due to the high stochasticity pattern of the ssl which requires informative hydrological variables for capturing the complexity of the ssl system e g river discharge hence the incorporation of the antecedent values of ssl improves the accuracy of predicted sll values the attained correlation coefficient values for the ga anfis ii and anfis ii models are slightly similar r 0 96 it should be noted although the highest correlation obtained for the ga anfis ii and anfis ii models however these two models demonstrate a noticeable overestimation trend for the minimal sediment magnitudes on the contrary a more coherent prediction agreement for the integrative ga svr and standalone svr can be observed over both modeling scenarios fig 10 illustrates the scatterplots trend for the bl sediment prediction a consistent predictability performance can be observed for the integrative anfis ga ii model for predicting bl sediment with the highest correlation coefficient r 0 85 however a remarkable diversion from the best fit line for all models toward the over estimation manners can be distinguished except for the attained results using the integrative ga svr ii model r 0 79 it is worth to mention the applied predictive models failed to predict the high magnitudes of the sediments for both ssl and bl this is apparently owing to the sudden changes in the river discharge amount this is due to high rainfall intensity events that generate land sliding phenomena hence the applied models apparently demonstrated an observable limitation toward those high magnitudes of sediment loads another explanation for this limitation the developed predictive models did not experience those high magnitudes of sediment for both ssl and bl during the training modeling phase and thus failed to mimic the actual mechanism between the predictors and predictand variables note that this is a time series sequential hydrological process where random periodic modeling development cannot be established here this can be better understood through the incorporation of the casual hydrological variables such as climatological hydraulic characteristics or other related essential hydrological variables as external predictors for better prediction matrix fig 11 displays the 2 dimensional graphical presentation called the taylor diagram for the developed predictive models for the ssl and bl respectively taylor diagram is one of the best graphical visualizations to evaluate the prediction accuracy based on several statistical indicators taylor 2001 it presents the summary statistical indicators of the measured and predicted sediment including correlation coefficients standard deviations and root mean square error in other words the taylor diagram provides an excellent graphical representation of the similarity between the predicted and observed values fig 11 reveals the slightly similar performance of the applied predictive models for both modeling input scenarios however the proposed integrative ga anfis ii and ga svr ii indicate the closest coordinates to the measured ssl on the other hand fig 11 indicates that ga anfis ii is the best predictive model toward the measured bl benchmark 6 deliberation and discussion from the results of this study it was found that irrespective of the method used the prediction of ssl was reasonably accurate by all the methods with an r2 ranging from 0 857 to 0 934 and nse ranging from 0 814 to 0 918 for the testing data for all of the applied models despite the use of ml techniques or their variants the predictability of bl is less accurate than the ssl which is a major concern for the modelers along with the inclusion of appropriate parameter sets a considerable amount of effort is required in the model development phase further examination and deliberation for the attained results of the models can be achieved by the use of hysteresis analysis hysteresis analysis is a promising graphical tool for studying the non linear relationship between sediment concentration and fluvial discharge lloyd et al 2016 it is basically plotted between sediment load and fluvial discharge in this study a flood hydrograph in the testing phase from 22 08 1988 to 30 08 1988 is considered for the hysteresis analysis of both ssl and bl the flood hydrograph hysteresis loop of observed ssl and hysteresis loops of ssl predicted by the best integrative model and the basic src models are presented in fig 12 the corresponding plots for bl are also provided in fig 13 the properties of the loop can be quantified by its primary characteristic property mean hysteresis index himid which effectively shows the dynamic response of suspended sediment concentrations to flow changes during storm events the himid index estimates the fatness of the hysteresis loop corresponds to the mid point discharge of the flood hydrograph eqs 14 and 15 lawler et al 2006 14 h i mid s r s f 1 clockwise 15 h i mid 1 s r s f 1 anti clockwise in the above formulae s stands for sediment load which can be either bedload or suspended load r stands for rising limb and f stands for falling limb him 0 indicates a weak hysteresis loop a positive value indicates a clockwise loop and a negative value indicates an anticlockwise loop the computed himid values are given in figs 12 and 13 figs 12 and 13 show that for the ssl the hysteresis loop is clockwise while for bl it is anti clockwise in nature the clockwise hysteresis loop is formed due to an increasing concentration of sediment that forms more rapidly during rising limb which suggests a source of sediment close to the monitoring point and sediment depletion in the channel system baniya et al 2019 on the contrary an anticlockwise hysteresis loop shows a long gap between the discharge and concentration peak which suggests that the source is located far from the monitoring point or bank collapse lloyd et al 2016 as for the ssl modeling it is clear from fig 12 that the ga anfis ii model displays excellent predictability and the hysteresis loop of anfis ga based predictions shows striking similarity with that of observed values himid 0 81 vs 0 97 the hysteresis loop of src based predictions shows a significant deviation from that of the observed data which indicates poor predictability power of the src model himid 0 38 hysteresis analysis for the bl model can be seen in fig 13 fig 13 implies that the ga anfis ii model shows fair performance in the prediction of the bl correctly while the src method could not simulate the bl of the river system well although there is a considerable difference between the calculated himid values for the observed loop and predicted ga anfis ii s loop 2 22 vs 6 12 this illustration clearly depicts that the ml model ga anfis was successful in regenerating the hysteresis loop in contrast the src failed in capturing the loop fig 13 that is the corresponding himid value for the src model is 0 03 which is close to zero and indicates no loop at all it is noteworthy that the data length in the present work covers five consecutive years from 1984 to 1989 thus the results obtained here are confined to a moderate time series dataset so more future works are needed for reaching holistic feedback on the merits of the usage of integrative ml models in bl and ssl prediction 7 conclusions this study performed a systematic evaluation of complexities in suspended sediment load ssl and bedload bl prediction in river flow through a multitude of statistical and machine learning ml methods the predictive methods included traditional models src mlr conventional ml models svr anfis and integrative ml models ga svr ga anfis the applied models were constructed based on the flow rate discharge data and by considering two different input scenarios with and without past records of sediment data from the major findings of this study the following general observations can be pointed out i the predictability of ssl was better than the prediction of bl irrespective of the model applied ii src and conventional models showed poor performance in prediction of both ssl and bl iii the inclusion of lagged inputs of sediment was more effective in improving the predictability of the ssl than bl iv regardless of the input scenarios the machine learning models were superior to the traditional methods in prediction of ssl and bl and v a blatant improvement in predicting ability of integrative ml models could be observed in comparison to the standard ml models an average improvement of 7 of rmse and 10 of r2 indeed the current study showed that ml models could be successfully employed to simulate and predict the nonlinear river ssl process in situations where both temporal river flow and sediment data are available however considering the complex nature of the bedload bl time series the utilization of the ml methods can be more beneficial by having access to extra physiographical information such as landslide susceptibility maps of the watershed credit authorship contribution statement mohammad zounemat kermani writing original draft writing review editing formal analysis amin mahdavi meymand data curation software formal analysis meysam alizamir writing original draft writing review editing methodology s adarsh writing original draft writing review editing zaher mundher yaseen writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
5523,there has been an unsettling rise in the river contamination due to the climate change and anthropogenic activities last decades research has immensely focussed on river basin water quality wq prediction risk assessment and pollutant classification techniques to design more potent management policies and advanced early warning system the next challenge is dealing with water related data as they are problematic to handle owing to their nonlinearity nonstationary feature and vague properties due to the unpredictable natural changes interdependent relationship human interference and complexity artificial intelligence ai models have shown remarkable success and superiority to handle such data owing to their higher accuracy to deal with non linear data robustness reliability cost effectiveness problem solving capability decision making capability efficiency and effectiveness ai models are the perfect tools for river wq monitoring management sustainability and policymaking this research reports the state of the art of various ai models implemented for river wq simulation over the past two decades 2000 2020 correspondingly over 200 research articles are reviewed from the web of science journals the survey covers the model structure input variability performance metrics regional generalisation investigation and comprehensive assessments of ai models progress in river water quality research the increasing contaminants the lack of funding and the deficiency in data numerous variables and unique data time series pattern based on the geological area have increased the need for river wq monitoring and control even more hence this is highly emphasising the involvement of ai models development which can deal with missing data able to integrate the features of a black box model and white box models benchmarked model and automated early warning system are few of many points need more research despite extensive research on wq simulation using ai models shortcomings remain according to the current survey and several possible future research directions are proposed overall this survey provides a new milestone in water resource engineering on the ai model implementation innovation and transformation in surface wq modelling with many formidable problems in different blossoming area and objectives to be achieved in the future keywords river water quality state of the art literature assessment and evaluation artificial intelligence hybrid model 1 introduction 1 1 research background humankind is blessed with a stunning piece of art that is the environment the growing desire for comfort as time progresses has left us with toxic air barren land and poisoned water the propensity has brought the present condition with a need to examine quantify and treat what was initially in its purest form consequently the need for testing water was realised back in the 1960s and water pollution acts were implemented to stop the deterioration of natural water quality barry 1969 water sources are divided into surface water sources e g river lake reservoirs and coastal areas and groundwater sources e g infiltration galleries and springs rivers have been the most used water source on account of their accessibility and availability this situation has led to the growth of most civilisation near river banks mustafa et al 2017 viessman et al 1998 water quality wq is divided into biological hydro morphological and physiochemical quality tchobanoglous and schroeder 1985 in addition to other variables physiochemical wq variables are widely used for river wq modelling wan mohtar et al 2019 only a few physical and chemical properties have been initially considered but various chemicals that affect wq have been discovered later physical and chemical variables produce synergistic effects on wq along with several other environmental factors that may produce unpredictable wq results wilhm and dorris 1968 there are predominantly few water quality variables that have been typically used to assess river health include dissolved oxygen do biochemical oxygen demand bod solids nitrogen compounds water temperature wt chlorophyll a chl a electrical conductivity ec chemical oxygen demand cod and ph tchobanoglous and schroeder 1985 another frequently applied indicator is the water quality index wqi which is calculated by a complicated numerical formula using surplus time and may have inaccurate values the process includes using multiple wq variables for calculation and comparing them with the standard value for improved understanding of the non scientific community such as policymakers smith 1990 wqi categorises wq into classes such as good bad and worst depending on the standard set by the study area governing bodies the results are numerical but are presented in a simplified form fernández et al 2004 water quality research plays an important role in river wq assessment monitoring and management henceforward the number of scientific approaches towards accessing managing and understanding wq data has increased considerably 1 2 problem statement wq assessment and its interpretation can be difficult to explain because they are influenced by several environmental factors and human activities kamel et al 2013 this complexity has started a new geological period called anthropocene in which all earth system processes are altered by humans activities that influence wq can be population explosion urbanisation industrialisation irrigation and water related engineering projects meybeck 2003 a global level study considered geospatial drivers including catchment disturbance pollution water resource development and biotic factors by using digital river networks and marine systems to obtain collective threat indices this study showed that 80 of the world population lives in areas where water security threat may exceed 75 percentiles unsecure water indicates unhealthy and contaminated water and is the cause of water related health risks vorosmarty et al 2010 wq statistics have difficulty in managing the large amount of data chapman 1992 many studies have attempted to estimate the river wq pollution however wq sample gathering testing and data handling are time consuming and costly in terms of chemical equipment and manpower traditional approaches bring difficulty in water related projects and result in losses in economic value these situations affect the decision making and productivity of the monitoring programmes ongley 2000 a productive and cost effective methodology for wq estimation with effective and robust advanced approaches are required to achieve the goal and overcome the previous limitations wq data are essential in defining the characteristics of the source water regulations addressing water management issues investment decisions and dealing with pollution ongley 1996 water related data are difficult to design as a result of their nonlinearity nonstationary feature and vague properties due to the unpredictable natural changes interdependent relationship and human interference votruba 1988 as a result these data have noise and are poor in quality therefore reliable methodologies such as artificial intelligence ai models and their advanced tools are needed 1 3 research motivation ai models which are based on the learning process of the human brain were proposed as forecasting and predictive tools by mccarthy 1956 ai models are powerful tools in many fields such as robotics hydrology climatology and agriculture including water resources they are popular for their reliability cost effectiveness problem solving capability decision making capability efficiency and effectiveness bandyopadhyay et al 2007 ai models are based on machine learning ml techniques and greatly impact human lives at present and will in the future according to mitchell 1997 the impact of machine learning is certain to grow over the coming years as more and more data come online we develop more effective algorithms and underlying theories for machine learning the futility of hand coding increasingly complex systems becomes clear and human organizations themselves learn the value of capturing and using historical data in river wq related studies various issues must be addressed carefully for current researchers to discuss and understand what previous studies have accomplished many published review papers have reported the capacity of ai models in wq studies for instance the first review reported prediction of wq variables in water resource modelling maier and dandy 2000 the review studied the employment of artificial neural network ann models until 1998 including model background data utilisation training and learning information network architecture optimisers and other model details however this study is outdated for the present scenario chau 2006 summarised the major ai models contribution in assessing and predicting coastal water quality researches this study acknowledged the potential of different ai models such as knowledge based system genetic algorithm ga ann and fuzzy inference system fis for wq modelling however this study did not consider the river water researches solomatine and ostfeld 2008 wrote an overview of data driven models and evolutionary optimisation for river basin management the review reported various gaps and limitations the authors used two water sources namely bagmati river basin in nepal and lake kinneret the sea of galilee watershed to assess the models that can provide the result on short term forecasting and classification of hydrology related data and flood related data maps using wq data and hydrological data this study considered fewer models and lacks the advanced model information since it only studied researches published before 2008 nicklow et al 2010 reviewed the evolutionary algorithms eas in planning and managing water supply groundwater and wq variable identification systems raghavendra and deka 2014 reviewed the application of support vector machine svm models on groundwater quality in hydrology the study provided a brief idea of svm models and their hybrid version for modelling hydrological data in 2010 a review research highlighted in detail the methods used to develop ann models for river systems over the period of 1999 2007 the taxonomy of ann model development selected inputs data division and model structure were evaluated maier et al 2010 the authors in another study elaborated the issue addressing the challenges and future aspect of eas in solving water resource problems in the last 25 years the study reviewed algorithms and their improvements in water distribution research and groundwater and river basin management maier et al 2014 che osmi et al 2016 conducted researches on river wq data modelled with fuzzy based methods the study dealt with model architecture membership function operations and perspective of the integration of fuzzy with other models considering all the previous review researches chau 2006 maier et al 2010 maier and dandy 2000 solomatine and ostfeld 2008 which are dated back to 2000 2008 the advancement of ai research is very rapid and there is a need of review research such as the current survey which elaborates the current status and future prospect based on the previous progression three of the literature studies selected different water sources such as groundwater and coastal which also makes this study unique considered this review strictly selected the studies on river wq assessment additionally out of eight past review studies six of them is reporting only one model out of all ai models e g ea maier et al 2014 nicklow et al 2010 ann maier et al 2010 maier and dandy 2000 svm raghavendra and deka 2014 and fuzzy based models che osmi et al 2016 whereas this survey is considered all the popular ai models thus this review is up to date takes in account the last 20 years of research progress in the field of ai researches and especially in the river wq research which also the need of the hour and its novelty in recent decades ai models have gained the trust of the scientific community as a predictive and classification tool considerable researches have progressed on river wq prediction monitoring and management using various ai models with each progressive year new models have been developed thus a comprehensive milestone that facilitates the contemporary researchers to understand the features of these models and other variables needed for modelling as a result the forthcoming studies can evaluate and design the next generation models many reported studies are in a scattered form and various models with their distinctive capability have been illustrated by researchers thus the current review research tries to organise all the research findings into one survey reviewing various works of scientists worldwide reveals that this review is exclusive in its kind and such an in depth study of river wq modelling and assessment has not been done previously to the best knowledge of the authors the current study deals with ai models used for river wq modelling numerous models have been designed and applied over the years fig 1 shows the classes and subclasses of these models for the better understanding ai models have been divided into six subdivisions namely ann model kernel based model fuzzy based models complementary models hybrid models natural algorithms that combine architectures of more than one model or techniques and other metaheuristic models that come from different model classifications the first three classes are the conventional ai models and their improved versions frequently classified as the same by past researchers however complementary models take an account of the possible application of wavelet with the combination of other models thus they have been categorized in a separate group which allows the readers to better understand the comparative analysis of its performance and effectiveness to deal with river wq data when coupled with ai models the fifth category was created considering the studies which dealt with the nature inspired algorithm for river wq modelling as these algorithms behaviour are based on a similar concept which makes them suitable for the same class the last category was created only for the convenience of the readers and study analysis since the number of papers available is limited and will create no advantage in the present review thus it classifies all other metaheuristic models which don t fall under any previous categories however in future these other models can be further divided as per their architecture or concept when there is a considerable increase in the research articles which is also a present gap and future aspects 1 4 research objectives the research on river quality modelling has increased considerably over time the contributions of the present survey are summarised as follows i this review is summarised 209 research works based on ai models and their advanced applications growth over the past two decades 2000 2020 output data consideration most preferred study area performance indices prediction time step and comprehensive assessment ii this review is highlighted the capacity of the conventional models which are applied to the research field of river wq are taken over by hybrid and complementary ai models as the result of unprecedented attention from scholars the assessment of the researches will open a new path for researchers in the field of ai and soft computing with forthcoming ideas to fill the gaps presented iii the survey is emphasised the breaches in the implementation of ai models in river wq research and models that have not been tested with river wq data iv finally the survey reveals the advantages and weaknesses of each model need for additional exploration of various river areas issues with data collection and recommendation for future enhancements consequently this review paper presents a snapshot of the historical development of ai models over the years the in depth description of the ai model architecture and mathematical theory has not been detailed in this review however an appropriate references have been cited in each introductory part of the ai models class for the readers desiring further profound knowledge the rest of the review article is divided into nine sections sections 2 to 7 details the major classes of ai models as previously described in fig 1 along with the subsection that briefly describes each model with related citation the related bibliographic discussions are cited and reviewed and the sections are assessed section 8 presents a general assessment of the reviewed papers section 9 and 10 contain the conclusion and recommendation for future research possibilities of the impact of river wq changes and modelling 2 artificial neural network ann 2 1 conceptual background ann models are popular ai models due to their robustness and capability to deal with nonlinear data and solve complex problems ann model is the brainchild of mcculloch 1943 ann has been continuously progressing and its efficiency can be increased with the help of various data optimisation process training algorithms and by selecting appropriate input techniques ann consists of three layers namely input hidden and output layers the number of layer increases when the problem is complex thus the computational efforts also increase ann trains with the data provided using various training or learning algorithms the most popular ann learning algorithms are generalised regression neural network grnn antanasijević et al 2014 2013 radial basis function neural network rbfnn chen et al 1991 backpropagation bp levenberg marquardt lm bayesian regularization br gradient descent steepest descent gauss newton quick propagation and adaptive learning maier and dandy 1999 rumelhart et al 1988 samarasinghe 2006 a new version of ann model called extreme learning machine elm is recently gaining popularity due to its simple structured single hidden layer feed forward neural network ffnn it works as a linear in the parameter model and easily reaches global optima huang and chen 2007 huang et al 2015 another time series model that can handle nonlinear data is a dynamic neural network called nonlinear autoregressive with exogenous narx network it is a subclass of the recurrent neural network rnn it uses a gradient descending learning algorithm that makes it effective in learning this feature results in its fast network convergence with improved generalisation and memory retention diaconescu 2008 tsungnan lin et al 1996 the typical architecture of ann is depicted in fig 2 hameed et al 2017 ann can work efficiently because it can use an input significance approach that can determine the potential input for output variables diop et al 2018 ann can use a model based approach that constructs individual models for different inputs to determine the important one salih et al 2019 thus its time consumption is high by contrast the model free approach provides developers with choices or uses mutual information table 1 presents all the papers that reported the application of ann models 2 2 bibliographic review of ann models 2 2 1 comparative studies of ann with other ai models numerous studies have been conducted in the field of river wq using ann models jeong et al 2001 applied recurrent ann to predict chlorophyll a chl a using various inputs such as meteorological hydrological and environmental variables the model can produce a good result with 3 days of time lag input data four of the studies found that ann performs better than the regression models such as mlr and nonlinear regression models the results concluded that ann is an efficient accurate and economic tool for river wq modelling anmala and venkateshwarlu 2019 huang and foo 2002 mitrović et al 2019 olyaie and banejad 2011 four studies based on river wq modelling determined that bpnn and ffnn models which use feed forward and back propagation algorithm are capable in predicting long term trends and perform accurately and their effectiveness is high because their ability to grasp the nonlinear relationship between the input and output variables in compare to models like linear partial least square pls regression basant et al 2010 dogan et al 2009 najah et al 2011 yang et al 2008 khalil et al 2011 used ann ensemble ann enn and enn coupled with canonical correspondence analysis cca cca was used to manage the functional relationship and standardisation of variables cca enn was established as the improved model and can estimate the wq mean value for sites niroobakhsh 2012 performed a comparative study to assess the prediction capability of two ann models namely multi layer perceptron mlp and rbf the results showed that rbf can handle an immense number of data and can thus perform effectively in total dissolved solids tds prediction antanasijević et al 2013 studied the predictive competencies of grnn bpnn and rnn models and used a regression mlr model amongst the three ann models rnn is the most efficient and is also better than mlr rnn shows least over training and improved do prediction capability grbić et al 2013 demonstrated ann and mlr model performance for chl a prediction and found that the ann model is more effective in handling nonstationary variables when compared to mlr adaptive neuro fuzzy interference system anfis and ann models ann and mlr models use bp and lm algorithms ann model is the most efficient and accurate model for do prediction amongst the considered models sinha and saha 2015 used ann to establish a relationship between wqi and source network clustering analysis ca was conducted to identify the similarities feed forward bp and lm algorithms were used for the best performance of the ann model in another two studies ann model was used as a tool to predict the amount of tds in the river these algorithms are accurate and reliable for such prediction and current scenario naseh et al 2016 tarke et al 2016 ahmed 2017 determined that feed forward neural network ffnn and rbfnn produce satisfactory results for do prediction but ffnn is slightly better in overall performance another research addressed the issue by reducing the tenacious application of wq variables and satellite data modelling by using ai model bpnn was used for mapping and the results are surprisingly accurate and simpler than before another three studies used the same process to reduce the cost and timing of the project whilst ensuring easy interpretation of data easy for the decision body for improved management planning liu et al 2012 sharaf el din et al 2017 sharaf el din and zhang 2017 antanasijević et al 2019 applied ward neural network wnn system along with som as a tool to pre process the dataset to extract the important features of the data and create a simple process wnn model was used to split the data and had two parallel hidden layers for identifying a different part of wq data patterns thus this model is unique and increases the accuracy compared with grnn results suen and eheart 2003 considered two ann models namely bpnn and rbfnn which were modelled and compared to predict nitrate contamination the outcome from rbfnn is quicker than that from bpnn because the number of hidden layers is determined by the fuzzy min max clustering algorithm where bpnn applies a trial and error approach this model is robust and highly accurate but both present similar false negative frequency similarly the results of a study done by najah et al 2013 presented that the performance of rbfnn is more accurate and faster than that of the linear regression model lrm and multi layer perceptron mlp in wq assessment rbfnn and ffnn were used in a study to find the do with the help of input data as bod and cod as they can influence the do variation piotrowski et al 2015 performed an extensive model assessment using ann fuzzy wavelet and instance based model that is k nearest neighbours knn the wt modelling results showed that each model is unique depending on the training algorithm optimisation and data sources ann performs better but the authors suggested that any new model must be assessed using various criteria to establish its performance efficiency heddam 2016a studied rbfnn and mlp techniques for do modelling and both models were able to successfully predict the do at 72 hrs ahead of time however the reliability of the forecasting reduced with increase in time step ahead another model grnn is gaining popularity because of its good performance thus three different studies compared it with mlr mlp rbfnn bpnn and rnn for wq modelling the results show that grnn performance is accurate efficient and faster as it doesn t need iterative training and overtraining chances are less csábrági et al 2017 2016 heddam 2014a dezfooli et al 2018 studied svm knn and probabilistic neural network pnn as wq models and established the effect of each input variable using the trial and error method pnn is the best model and performs well when few variables are omitted knn works well with all variables included and svm performs better with fewest variables asadollahfardi et al 2018 applied autoregressive integrated moving average arima box jenkins time series and mlp model for tds estimation mlp used 10 hidden layers lm as an optimisation algorithm with tansig transfer function which resulted in a better and more reliable model than the others abba et al 2018 simultaneously studied mlr ann and anfis models to predict do the results showed that the performance of ann is superior to those of anfis and mlr models as they suffered from the drawbacks of over estimation and under estimation respectively 2 2 2 studies incorporated with various input output selection techniques bowden et al 2005 enhanced the grnn model performance by using mutual information to characterise the important input and output wq variables som to reduce the dimensionality of inputs and ga to establish a relationship between them zali et al 2011 identified the relationship of wq variables using sensitivity analysis technique on inputs considered in the research with the classification of pollution sources ann successfully correlates and finds the pollution problems in the study area that is agricultural runoff and animal farm wastage similarly nasir 2011 used sensitivity input analysis which is a model based technique it was used to identify the effective input output relationship and eliminate the rest for ensuring the effectiveness of the ann model prediction for predicting wqi gazzaz et al 2012 reduced the massive quantity of data using principal factor analysis pfa to identify variables affecting wq in the study area mlp with ann model was used to construct the relationship and the result is fast and accurate because it can use achieved data to create a model that can be used for direct calculation of the river wq from raw data a combined model was introduced by chu et al 2013 where hopfield neural network hnn was used as a classifier modelling tool and factor analysis fa were used together for classification and dimensionality reduction respectively the combination model can overcome overfitting caused by wq inputs and performs better than other evaluation models rahim and ahmad 2013 used cca to reduce input variables with least or no predictive utility in the creation of the ann model for bod prediction which increased the computational cost and modelling accuracy wq estimation comes with uncertainty and very complex model design and was addressed by jiang et al 2013 using monte carlo simulation mcs with ann to reduce time and cost without compromising the accuracy mcs helps produce improved model wq variables including input and output along with possibility and numerical distribution but needs high computation labour similar to previous research antanasijević et al 2014 used mcs to address uncertainty they also used two methods for input selection namely a model free approach with correlation analysis and model based approach with ga to obtain the best result when incorporated with grnn these combined techniques are effective and produce enhanced do prediction results šiljić tomić et al 2018a focused on interpolation and extrapolation of the ann model by using pnn with emphasis on the right data selection for the learning process to create the number of possible models and select the optimum competent model the results of extrapolation are unaffected by less substantial inputs but may be biased yet do modelling results were good the same researchers used box behnken design for optimisation and multi filter approach for input correlation which was then modelled with ann and found the coupled technique is effective in do prediction šiljić tomić et al 2018b voza and vuković 2018 studied two analysis techniques namely clustering and discriminant analysis da to reduce the initial dataset and isolate the main source of pollutants this screening increases the efficiency of the ann model which in turn can provide a coherent and reliable wq management strategy chen et al 2009 used correlation analysis and quadratic polynomial stepwise regression analyses for selecting appropriate input to obtain improved results during bpnn modelling the results are good fast easy to manage and can be useful for river and agricultural water management chang et al 2015 conducted modelling using dynamic ann coupled with gamma test to establish a spatiotemporal relationship and select the combination of best fitted inputs by evaluating the noise the model was accompanied by narx ann and anfis models gamma test helped in the input selection and improved prediction performance the model can find the water pollutant source and produce the most accurate results villas boas et al 2017 evaluated the performance of auto associative nn coupled with nonlinear principal component analysis pca to address the issue of budget difficulties and inadequate wq network design the nonlinear pca can understand the wq relationship and perform and address the issues another paper reported the use of bpnn modelling along with correlation analysis for normalisation similar to previous works pca was added in place of polynomial analysis to reduce the correlation of neurons the results can cope with the missing data and decrease the monitoring index and can thus be used for wq management tools zhang et al 2010a b li et al 2019 used d s evidence theory dempster shafer to deal with wq data uncertainty by data fusion and improve data performance by combining it with rnn the results are promising since they are comparable to those of support vector regression svr bpnn and conventional rnn models isiyaka et al 2019 investigated wq by using the ann model and multivariate statistical tools hierarchical agglomerative cluster hac analysis helped in clustering the monitoring site in two and pca was applied pollution source identification such as anthropogenic surface runoff and rock weathering in which rock weather was the highest contributor of pollution a sensitivity test was applied to recognise the most sensitive variable affected by pollution all the techniques coupled with ann model increased the overall performance 2 2 3 modelling with distinctive indicators kim and seo 2015 used chl a as an indicator to assess algal growth by integrating ann and sensitivity analysis to find the most sensitive input to the required output the authors also used clustering and partitioning to balance training which led to highly accurate results using the ann model heddam 2016b used phycocyanin as an indicator for phytoplankton and algal growth mlp ann and mlr models were used for modelling and lm was used for optimisation mlp model performs well during training validation testing and prediction two research studies selected tds as the output variables since tds can be used as an indicator of salinity salt deposits in the study area as often present due to the geographical location on of the study applied time delay nn tdnn and rbf models whose prediction accuracy was high and other modelled the wq variables with mlp and rnn in which mlp obtained results faster than rnn but rnn applicability and accurate was more than mlp asadollahfardi et al 2011 gholamreza et al 2016 wq can be assessed using indicators such as macrophytes which were used by gebler et al 2017 as an indicator for the testing of the extent of river contamination this study explored the possibility of using plants as bio indicators for wq monitoring and management similar output variables namely macrophytes were taken as indicators in 2018 but the relative relation was established by considering water pollutants hydro morphological changes and physical chemical and biological variables the authors suggested that the relationship must be observed in more than one aspect such as environmental and ecological to increase model accuracy gebler et al 2018 kim et al 2019 used chl a as an indicator to predict algal bloom using the ann model in their study the results are helpful for environmental management and assessing other factors affecting the algal changing aspects during the sensitivity analysis nitrogen shows the most impact on algal bloom variation in the study area 2 2 4 models addressing the issue of missing data and cost effective approaches diamantopoulou et al 2008 examined the ann model and estimated the missing data by using the available relevant wq variables a similar outcome was achieved by amiri and nakane 2009 where data were taken using geographic information system gis the lack of meticulous data was dealt by randomisation of the data to produce accurate results using ann model singh et al 2009 tested the bpnn model for do and bod computation the model is able to capture longterm trends of wq variation both in time and space thus the study concluded that it can be used as a predictive tool for assessing river health sahoo et al 2009 successfully predicted wt even with a lack of detailed data the time delay approach was used to adjust nonlinear data for overcoming the predicament and mutual information limited the time delay up to 3 days ga was used for optimisation and data were fed to a chaotic nonlinear dynamic algorithm cnda and bpnn model the results showed that the bpnn model produces the best results a related study of heydari et al 2013 solved the problem of missing data and created the ann model using available data of other wq variables then the backpropagation mlp model was used for the network architecture and produced accurate results nhantumbo et al 2018 addressed the same issue of cost and lack of details of variables using the ann model and comparing with the physical process based model ppbm with lm optimiser the physical process based model is satisfactory when calibrated and can be used along with the ann model to obtain the best possible result the data unavailability can be sometimes due to an inactive monitoring station to address this point mitrović et al 2019 used ann model for virtual wq monitoring and mcs algorithm for data sensitivity analysis mcs with the ann model is successful for complex multi output targets salami and ehteshami 2015 selected inputs such as wt ph and ec because these experiments are easy and low cost for do prediction using ffnn along with lm and transign for the learning process the study concluded that ann model is a good tool for missing data finding the relationship between data variables and overcoming problems from data collection and experimentation peña guzmán et al 2019 used ann model for handling wq prediction for a large population which is difficult costly and time consuming with the traditional methods the results are satisfactory and concluded that ann model can be used for similar conditions chebud et al 2012 used the ann model with gis to quantify and establish a relationship between the inputs and minimise project cost gis was used for landscape analysis and dynamic monitoring and produces good quality images by removing haziness and cloud effect the model can reduce uncertainty and manage the complexity of the relationship between wq variables iglesias et al 2014 minimised the cost and time of physiochemical testing by integrating ann the study used turbidity as a wq indicator to reduce excessive modelling time and the results are satisfactory sarkar and pandey 2015 proposed ann model for predicting do and suggested that ann can be used as an active tool for river wq monitoring for developing countries the only consideration will be consistent data and the same controlling factors for training and testing datasets gazzaz et al 2015 correlated and used wqi as an indicator and applied ann modelling during the research wqi was influenced by mining rubber industries forestry urbanisation and agricultural activities chang et al 2016 compared mlr static type bpnn dynamic type narx and subclass of rnn models gamma test was used to estimate the importance and interdependence of the input variables and the noise narx model can predict the spatiotemporal features in the inputs outperform other models and can perform effectively under missing data and costly wq variables alves et al 2018 proposed replacing the older method of wq analysis with uv spectrophotometry with ann modelling tool to decrease the time need of costly infrastructures and other expenses of the project the study introduced a simple and fast way to monitor wq four research study applied elm and modified elm models i e optimally pruned extreme learning machine op elm radial basis elm online sequential elm and compared their performance with mlp mlr lr bpnn and anfis models op elm model demonstrates higher predictable performance when compared to mlp and could predict wq in advance from several hours to 7 days with improved accuracy elm models outperform others as the result of its use of a single hidden layer feed forward network can learn faster than other ann models and has lesser number of epochs it is superior in prediction accuracy speed and in generalisation thus the model is easy to apply elm can be applied using different activation functions such as sigmoidal sine rbf hard line and triangular function in which sigmoidal and rbf has the highest success among all thus the designer can opt for the best design as per the feasibility of the project heddam 2016c heddam and kisi 2017 yi et al 2018 zhu et al 2019c 2 3 model assessment assessment of the various literature surveys on ann modelling for river wq reveals the following matters the popularity of the ann model is due to the flexibility in its implementation in river wq the ann model can process complex nonlinear nonstationary and vague data of river wq without assumptions between input and output variables thus ann models are categorised as a black box model which uses the numerical approach without understanding the mechanism juditsky et al 1995 thus this model can be applied easily ann models have been proven excellent predictive tools by the literature considered in this study for predicting the change in river wq in advance which is helpful for decision makers and policymakers around the world as shown in fig 3 the pie chart presents various ann models compares to the applied models in the 76 review papers and concludes that ann performance is the highest the traditional ann model has been applied in 30 of the studies and remains the most popular with the development in the ann model architecture the new generation of ann models such as grnn 4 pnn 1 elm 1 and narx 1 models continuously try to take the place of the previous ones such as ann 30 bpnn 13 and mlp 9 models these new models are gaining popularity in the last few years few hybrid models such as rbfnn 4 and rnn 3 models have been studied along with the traditional models and has shown promising performance fig 3 illustrates a few models such as mlr 9 anfis 4 and other ai models 13 used for comparison against ann models ann models perform better when coupled with various dimensionality reduction tools e g pca cca som pfa and fa and clustering tools e g ca da and ga chen et al 2009 khalil et al 2011 sinha and saha 2015 voza and vuković 2018 the efficiency and accuracy of the results can be increased because of the enhanced understanding of function relation identifying the similarities decreasing the huge input data into a manageable amount and standardising the data similarly time and cost can be decreased but quality can be increased using satellite and integration tool coupled with the ann model such as som gis satellite data modelling and remote sensing these tools are also able to get the most important features from data resulting in increased efficiency and performance ahmed 2017 antanasijević et al 2019 diamantopoulou et al 2008 sharaf el din et al 2017 sharaf el din and zhang 2017 the literature reveals that many comparative studies have been done using conventional ann and other modified versions of the ann model different models of ann show good results in varying scenarios and advantages over one another out of 74 studies 30 of the researchers have successfully used conventional ann and most of them have found that ann is better than most models such as anfis mlr wavelet and knn models this popularity is subjected to ann model flexibility computationally economical reliable consistent predictability and capability to handle nonlinearity few examples supporting the efficiency of traditional ann model anmala and venkateshwarlu 2019 banejad and ehsan 2011 grbić et al 2013 huang and foo 2002 the second most popular model is bpnn which uses the bp algorithm along with lm algorithm lm is the most famous training algorithm and finds optimum results in a minimisation problem this feature gives the model high stability and efficiency during the learning process gorashi and abdullah 2012 even though rnn model has been implemented less compared with other popular ann models but has the aptitude to achieve the least over training with good prediction capability antanasijević et al 2013 asadollahfardi et al 2011 grnn model is fast in data processing as it does not require an iterative training process thus this model can deal with large data this condition is common in wq assessment and predictions which makes it more suitable for handling wq data cigizoglu and alp 2006 enhancement tools of multiple input variables can be applied with the ann model to increase the efficiency of the model selection of the significant input attributes is essential because excessive input may cause overtraining introduces extra local minima and compromises the exact meaning of the input output relationship for input selection a model free approach and model based approach can be used antanasijević et al 2014 mutual information and multi filter approach for variable characterisation can be helpful considering they do not depend on model performance and use nonlinear statistical dependence to measure and determine inputs and thus are called model free approach bowden et al 2005 methods such as sensitivity and quadratic polynomial stepwise regression analyses can be used in river wq models to identify the most influential inputs over the outputs and eliminate the rest chen et al 2009 nasir 2011 another method of extrapolation can be used in data selection considering its ability to neglects the variables with least influence šiljić tomić et al 2018a various ann models in river wq modelling use indicator outputs to assess other pollutants for instance kim and seo 2015 used chlorophyll as an indicator for algal growth in the river heddam 2016a b c used phycocyanin as the phytoplankton and algal growth indicator and gebler et al 2017 used macrophytes for pollutant indication such studies are useful when collecting specific water samples is difficult due to unavailability of required fund manpower or risk in reaching the specific area for data collection the indicators can help fill the gap in those studies and achieve the goal of river health assessment ann models reduce the cost of the project and can deal with missing data and insufficient meticulous data using randomisation time delay mutual information and virtual wq modelling amiri and nakane 2009 mitrović et al 2019 sahoo et al 2009 they address the issue faced by many projects where the overall modelling monitoring and assessment suffer due to insufficient fund and inadequate data specifically in developing countries where ann models can be an economic solution several new models of ann with good potential in the area or river wq such as elm coupled with optimally prune method can predict wq in advance by many days similarly elm can process data in high speed has high accuracy and good generalisation capability by achieving the least training error and the smallest norm of output weight and performs fast due to less number of epochs heddam 2016c zhu et al 2019c this model has universal approximation capacity and improves overfitting problem by random feature mapping approach the simple design and the learning without hidden layer tuning make elm applicable to wq modelling huang et al 2015 in many cases including saline water elm and conventional ann has successfully predicted wq several hours ahead of time alizadeh et al 2018 another model known as narx can deal with missing data noise and nonlinear inputs chang et al 2016 wnn with som can find import data simplify a process by using data splitting and apply parallel hidden layer technique which makes it unique antanasijević et al 2019 least explored models can be implemented in the river wq modelling combined with other ai models to achieve superior model performance furthermore the challenges regarding the uniqueness of each study area seasonal variation and other abnormalities common in wq data must be assessed data is normally split into two training set and validation set generally ann models are not able to extrapolate beyond the range of training data which leads to poor prediction values and thus it becomes hard to get good results with small data set to solve the problem holdout method synthetic testing data trial method and cross validation methods have been applied to improve the generalization of the model maier and dandy 2001 master 1993 the most popular technique is cross validation technique which splits the data into three training testing and validation which helps in regulate when the training has to be dismissed maier and dandy 2000 but unfortunately very less thought has been given over the issue in the recent research considering wq data may present itself with the issue of unavailability of uniform long term data as an example of these two research where data availability was one year monthly data amiri and nakane 2009 chang et al 2001 3 fuzzy logic based modelling strategy 3 1 conceptual background fuzzy logic was developed to deal with uncertainty imprecision and vagueness zadeh 1965 introduced a fuzzy set as the class with defined criteria of membership the fuzzy set was established with the idea of inclusion blending balance and relation a fuzzy set consists of a membership function a discourse and a membership value each fuzzy set is defined by a fuzzy membership function which allocates a membership value to every conceivable input with two types of rules antecedents if and consequents then the membership value is between 0 and 1 where 0 represents absolute non membership and 1 represents full membership the consideration of the rules is depended upon the type of interference systems such as mamdani sugeno tsumoto and kang mamdani and assilian 1975 sugeno and kang 1988 takagi and sugeno 1985 the number of fuzzy rules needed for inputs is depended on the complexity of the real system and hence the number of rules increases with the complexity fis is able to better understand the relationship between the variables and then interpreted them in simple language it has been considered as grey box instead of black box model lindskog 1997 the architecture of adaptive network based fuzzy inference system presented by jang 1993 uses the hybrid learning process with input output mapping and has functional blocks as a rule base a database a decision making unit a fuzzification interface and a defuzzification interface anfis model has the advantage over ann models in adaptive filtering adaptive signal processing such as identification inverse coding and noise cancelling fuzzy rules are determined by three identification methods namely grid partition gp2 subtractive clustering sc and fuzzy c mean fcm clustering jang 1996 the typical architecture of the five layer anfis has been shown in fig 4 yaseen et al 2018a zhu et al 2019b concluded that the anfis model is a flexible ai model that can identify complexity and nonlinearity between variables another popular type of fis model is dynamic evolving neural fuzzy inference system denfis which can learn online and offline denfis advances through incremental hybrid learning and adds new inputs new classes and fuzzy rules thus it is superior to mlp anfis and evolving fuzzy neural network efunn wright 1991a b fis has been successfully applied for river wq for prediction assessment and classification all these fis applications have been reported in studies related to river wq tables 2a and 2b classifies fis model applications into a predictive and b classification models 3 2 bibliographic review of fuzzy based models 3 2 1 predictive models fis has been applied mostly as a classification tool however in any case it has been applied to compare with existing models such as pnn bn and grey relation method it followed the modelling pattern of fuzzification membership selection rule determination and defuzzification fis was used with water pollution index to incorporate and administer information e g individual knowledge and experience and qualitative environmental variables fis shows the good result when coupled with mcs or cascade type fis is applied which increases accuracy and speed li et al 2016a b mahapatra et al 2011 nikoo et al 2011 nirmala et al 2015 one of the most popular implemented models of fuzzy is anfis which proved to be a better model than pnn fis and mlp in five different studies anfis performance is good accurate and quicker than mlp and pnn models as these model cannot produce reliable solution due to the nonlinear characteristic of the wq variables and fis takes longer in data interpretation moreover this model is economic than laboratory analysis and can deal with a large amount of data data normalisation correlation and regression analyses and modelling conversion inverse transformation were applied to find important input variables which increased the performance many folds ahmed et al 2017 houari et al 2019 mahmoodabadi and rezaei arshad 2018 najah et al 2014 yan et al 2010 deng et al 2015 compared gaussian cloud transformation fuzzy time series gct fts arima rbfnn nonlinear auto regression nar svm order series method osm and ann gt gaussian transformation models the study aimed to develop multifactor wq time series where gaussian transformation was applied to historical data and multifactor fts model was used on two different time period datasets the new model can perform soft partitioning of uncertain data decrease noise and construct improved quality training data thus adaptive expectation model was applied to enhance the performance tiwari et al 2018 incorporated fcm and sc techniques which are powerful tools for multidimensional wq data analysis and were clustered with anfis to verify their predicting and classifying capabilities sc is more accurate than fcm technique thus it was used for sensitivity analysis for better understanding the impact of the input variables on the output yaseen et al 2018c used sc fcm and gp2 method to find the most effective predictive model the result shows that sc is the most effective model then fcm and gp2 respectively the first two models are less complex robust and consume less time in wqi prediction zhu et al 2019b performed similar modelling combination of anfis with three identification methods i e sc fcm gp and different functions like genfis 1 2 and 3 and mlp model mlp performs better but inaccuracy is less in fcm anfis and gp anfis models as the models can well manage input data and thus performs better an integrated model for river wq was introduced by heddam 2014b as denfis it is based on evolving clustering method ecm was used for do prediction and the results were compared with those of mlr and mlp models online based denfis outperforms other models with high accuracy heddam 2017 applied an evolving fuzzy neural network efunn model and compared its performance with that of the mlr model the result is highly accurate when efunn model is used thus the model is a good alternative for do prediction chen et al 2019 experimented on a hybrid model called possibility measured based fuzzy support function machine pmfsfm to overcome the shortcoming of the individual methods the hybrid model is accurate considers the fuzziness of wq variables and is less time consuming under few dimensions 3 2 2 classification models wq classification has been the primary and initial goal of many researchers chang et al 2001 used fuzzy synthetic evaluation fse approach in achieving this goal using the emerging technique of ai techniques fse can deal with the uncertainties of wq and lack of the boundary of wq and water to be utilised it is also more relevant than other techniques in this previous study simple fuzzy classification fuzzy information intensity and defuzzification were applied to the wq data to interpret the data with high accuracy ning and chang 2004 developed a fuzzy multi objective evaluation fmo e model to deal with a long standing arbitrary situation wq analysis might increase the level of monitoring for reasonable utilisation of water at each location gis was used as the data retriever and an optimiser the model can handle multiple objectives with a pragmatic approach which increases the success of screening selecting and sequencing the optimal expansion substitutes in another study interactive fmoe was utilised by lee and chang 2005 for efficient wq management considering financially viable factors the model can balance the economic and environmental factors to achieve high wq model performance which in turn increases the options for decision makers chen et al 2005 applied the fuzzy contingent valuation fcv method to improve the river wq by providing supportive information for cost effective analysis which can improve the management plan similarly nasiri et al 2007 applied fuzzy multiple attribute fma decision support expert this method is suitable for comprehensive data investigation and easy to assess and can evaluate wq effectively the model helps classify the wq and improve the administration plan singh et al 2007 explored the use of fmo lp linear programming for wq evaluation for different disposal location the model is flexible and enables water related policies to be managed easily and cost efficiently huang et al 2010 classified river wq according to the pollution zones and examined wq features pollution source and change according to the sources these questions were solved efficiently using statistical analysis such as fuzzy comprehensive analysis fca and factor analysis fa scannapieco et al 2012 applied fuzzy logic for wq assessment and added mann kendall test to analyse the trends when sampling regularity was decreased the classification was based on the pollution level of macro indicators and extended biotic index the study also considers only 5 membership functions to void crossing of more than two classes this model allows an improved understanding of the limits of the wq variables and thus increases the accuracy of the evaluation fis model has been successfully integrated for river assessment for estimating the river health and evaluating the need for water treatment in four studies the model has shown good accuracy flexibility to develop an enhanced classification ability to deal with the nonlinear input variables and classify river wq in natural language thus the model helps decision making more convenient babaei et al 2011 mourhir et al 2014 ocampo duque et al 2006 raman et al 2009 liu and zou 2012 examined the improved fuzzy matter element evaluation method by using the coefficient of variation to determine the weight and normal membership degree the new method is more scientific inclusive and effective than traditional calculating super scale method by avoiding abnormal values during the wq modelling angulo et al 2012 used fuzzy logic to assess the anthropogenic effect on river wq variables fis model can detect the surges of wastewater discharge changes due to eutrophication in the river risk on fish growth and develop a cause and effect relationship ocampo duque et al 2013 hybridised fis as a probabilistic fuzzy hybrid model and added mcs to handle imprecise and vague input data the model can identify the water pollution source and flexibly classify them into natural language thus can be used for wq indexing singh et al 2015 applied fuzzy analytical hierarchy process f ahp to evaluate river health on the basis of chang s extension analysis the method is easy and effective and can be applied to obtain priority weight the model is effective and improves water treatment plans and projects in another study the improved fuzzy matter element evaluation method was used by zhang et al 2019 along with the construction of pressure state response model for river health which is based on the relationship of the variables and urban river health index the model can solve incompatible complex problems related to wq and asses the multi index as urban wqi deng et al 2015 extensively compared the hybrid fuzzy time series fts model with arima rbfnn nar svm ann gct and osm models fts used heuristic gct algorithm and gaussian cloud algorithm the model can reduce noise by calculating the length of the periodicity and improve the prediction performance considerably when compared with other models for wq management singh et al 2019 proposed a fuzzy based model along with the gis model which is a geographical regression method the model can manage the vagueness of the data and index the wq variables is considerably comprehensive form and track the changes in wq this information can help decision makers to develop improved water management and monitoring policies lu et al 2010 utilised fse model for river wq assessment by incorporating entropy method and the results are comparable to those of the conventional fse performance the combined technique is effective as the entropy method can simplify the calculation process by determining the weight of the assessment constraints fuzzy wqi was generated in the study fuzzy wqi can interpret the uncertainty and vagueness of wq better than the normal wq model this way allows decision makers to interpret and manage water associated projects effectively xu et al 2012 examined fca coupled with ca and seasonal kendall test fca classifies the wq data into various quality levels whereas kendall test classifies them into different periods and identifies the change in the wq which makes it an excellent wq classification model wang et al 2014 designed a fuzzy evaluation model by integrating fuzzy binary comparison method and variable fuzzy sets this model uses eigenvector of level h and thus increases the wq assessment performance to a higher level by using developing interval scale rather than point scale liou et al 2003 explored the use of fuzzy set theory for data condensation using wq indicators the authors also applied the fuzzy c mean approach for assessment the model enhances the freedom of the decision makers this method can evaluate different scenarios and can present an enhanced assessment lee and chang 2005 implemented pca and fuzzy pca to manage compress and extract a large amount of wq data they considerably reduced the shortcomings such as sensitivity to outlines missing data and managing poorly distributed data by adding fuzzy with pca fpca results are sharper than those of normal pca wang et al 2008 coupled fse with pca this method helps in the correlation of variables and thus contributes to an improved assessment by eliminating the less sensitive variables the results are satisfactory and more efficient and considerably easier to perform than those of the typical pca karamouz et al 2009 applied fuzzy clustering for classification kriging method for regionalising spatiotemporal changes ahp for selection of suitable sampling station entropy theory for sample frequency calculation and ga optimisation various combinations of each method were used for classification river monitoring station selection wq variable selection and standardisation the two models can achieve the desired objective of finding potential monitoring station and can therefore be helpful in river wq monitoring mouton et al 2009 compared an expert knowledge based method i e hill climbing algorithm and a data driven model i e fuzzy rule based modelling for wq modelling fuzzy sets were optimised by nearest ascent hill climbing algorithm however data driven models outperform all others they also provide a suitable habitat for modellers in a similar study alias et al 2009 applied fuzzy ahp and compared it with the conventional techniques the combined multi criteria technique was used by reason of its flexibility applicability simplified use and capability to create wqi this model can manage the vagueness of the data and rank results as fuzzy wqi compared with wqi models 3 3 model assessment an assessment of the various studies on fuzzy based modelling of river wq shows the following all the scrutinised papers based on fuzzy models take the second place and anfis is the top related model since it has the advantages of ann and fis models anfis can manage nonlinearity uncertainty and fuzziness related to river wq anfis has several advantages in signal identification inverse coding and noise cancelling anfis produces enhanced results when data are normalised and reduced ahmed et al 2017 most studies use either one or a combination of multidimensional data analysis method in anfis namely gp sc and fcm clustering however sc is a better tool than the others in handling river wq classification tiwari et al 2018 yaseen et al 2018a b c d anfis model has shown good performance in handling river quality data as it has two types of parameter linear and non linear which can be attuned accordingly through the training stage jang 1993 along with the member function plays a vital role and right choice leads to the best optimization of parameters and hence results in higher accuracy jang 1996 another deciding factor for designing a good anfis model is the identification method applied for splitting the input space popular techniques applied are grid partition subtractive clustering and fuzzy c means clustering with various function such as genfis 1 2 and 3 jang et al 1997 therefore anfis can perform well with non linear data along with proper selective parameters decided by the designer few models such as denfis and efunn models are introduced recently for river water modelling they perform well in managing river wq however the considered comparative models are not against the basic benchmarked models and other popularly used models fts with gaussian transformation can decrease noise construct enhanced training data and apply soft partitioning this method is superior to arima rbfnn nar svm ann and osm models deng et al 2015 fis fse fmoe and fmolp approaches can deal with wq uncertainties and are flexible in creating fuzzy rules classifying them into classes as bad average or good according to criteria interpreting the skewed information and understanding the relationship between input variables fmoe model has been used to identify the monitoring station and increase the success of screening selecting and sequencing the optimal expansion substitutes ning and chang 2004 all these tools can efficiently classify river wq and help monitor and manage the river system to create improved monitoring projects various modified and hybrid versions of fuzzy set rules are available but each can handle river wq and create fuzzy wqi in addition to that they coupled with pca they can extract large amounts of data outgrow the problem of outliners handle missing data and poorly scattered data and remove less related data lee and chang 2005 wang et al 2008 fuzzy based model is able to produce a high level result and easily incorporates natural language prior knowledge to the model this allows the parameter estimation algorithm to allocate a practical preliminary value which decreases the chance of getting unnecessary local minima another advantage is that the ability of extrapolation which can be used for analysis and revealing new information from the data lindskog 1997 the fuzzy rule based model describes the input output relation more realistically and has physical interpretation which has allowed many researchers in wq research to choose fis model rather than ann models ocampo duque et al 2006 raman et al 2009 fuzzy models are able to analyse and conclude from the given data about the behaviour of a complex system without prior specification of a functional structure in comparison to other black box models jacquin and shamseldin 2009 nevertheless the ability to establish a relationship between input output variable becomes its limitation when too many input variables are there resulting to a number of rules and a complex system which is also known as the curse of dimensionality introduced by bellman 1966 thus calibration become difficult 4 kernel based ai models 4 1 conceptual background the concept of non separable data in support vector network was founded in 1995 this type of learning machine uses nonlinear input mapping to a very high dimensional space and ensures high generalisation svm depends on the so called large margin factor and built based on the structural risk minimization principle svm can produce excellent accuracy compared with linear knn and nn classifier because it does not include knowledge svm comprises regularisation kernel function and regression model complexity thus it is known as a kernel model cortes and vapnik 1995 vapnik 2000 kernel functions and parameter are selected to reduce the bound on the vapnik chervonenkis dimension the extended svm was able to solve function estimation problems by applying vapnik s epsilon insensitive loss function and huber loss function as shown in fig 5 with the general architecture of svm chen and yu 2007 yaseen et al 2019c svm can be designed as linear polynomial spline rbf network and mlp suykens and vandewalle 1999 vapnik 1998 svm has been prevalently used to build a classification model for trend prediction and solving regression and time series problems raghavendra and deka 2014 various models developed using kernel architecture are listed in table 3 4 2 bibliographic review of svm models wang et al 2011 tested the use of semi supervised regression model with svm and compared it with mlr and svm ga models the data in this project were retrieved using remote sensing and accuracy of the regression model is improved thus the interpretation and monitoring of the wq of the study area are also enhanced in another study in the same year by el shafie 2011 svm was compared with mlp and enn ensemble models to assess the level of performance in identifying a complex nonlinear relationship between wq data to minimise expenses and labour charges svm performance is accurate more robust and faster than other models with the need for minimum computational cost singh et al 2011 applied support vector classification svc for data reduction used svr as a predictive model and compared kernel based discriminant analysis da kernel based partial least square kpls ordinary da and pls techniques svm modelling results are promising in handling optimisation classification and prediction of a large amount of wq data noori et al 2012 developed reduced order svm ro svm by using orthogonal decomposition to reduce time consumption and compared it with the conventional svm model the obtained results are acceptable for bod prediction modaresi and araghinejad 2014 evaluated classification models such as svm pnn and knn svm performance is superior to others because it produces no errors during calibration and validation as it uses kernel function and only depends on support vector which makes it a better model than ann models for wqi modelling kar et al 2016 used spectral angle mapper sam and svm to classify and identify metal contamination in river water svm performance is superior as it provides classes based on a priori spectral knowledge selected by the modeller spectral absorption depth is a good source of information regarding metals and can be utilised for other remote sensing techniques bozorg haddad et al 2017 applied lssvr gp with pca input optimiser and hybrid ga lssvr model since lssvr doesn t have a mechanism for selecting coefficient and yet its precision is dependent on it ga optimises it by finding the neighbouring global optima and selects the correct coefficient which modifies coefficient of the svr producing better result than other models similarly two other studies evaluated svr performance it is able to identify the most important wq variables generalized svm and canonical correlation analysis based multivariable data down scaling method when applied the accuracy and efficiency of the model increases considerably kamyab talesh et al 2019 shan et al 2018 shen et al 2019 addressed the problem of the complex interaction of wq variables and inter annual variation of eutrophication by using ls svm modelling and empirical orthogonal function eof as a dimension reducing tool to better comprehend the spatiotemporal patterns the proposed ai model can handle the uncertain and multifaceted data and identify the point of nutrient loading which concurrently encourages algal bloom thus this identification can help to control and manage algal bloom another study compared ls svm and svm model performance for wqi prediction polynomial kernel function outperformed linear and rbf thus chosen for final prediction ls svm is a superior model than svm as it can reduce the complexity of the problem by using linear equation rather than using quadratic programming like the conventional svm model leong et al 2019 gamble and babbar sebens 2012 analysed the performance of predictive models by applying pca method for the linear variable dimensional reduction and kohomen som for nonlinear wq variable reduction the results from dimensional reduction were assembled using k nn clustering analysis to reduce computational cost also the authors applied linear da to establish a relation between clusters as a linear classification method i e svm to deal with nonlinear variables the results are promising svm is superior but both models perform well chen et al 2012 coupled svm model with factor analysis and non negative constraints which together are responsible for the variable reduction and classification to identify the source of water pollution the results are satisfactory and provide an opportunity to understand the environmental status and decide on management strategies jiake et al 2013 assessed the capability of hybrid svm in handling nonlinearity and nonstationary of wq variables against arima and bpnn models pso was applied to determine the variables for the svm model this way improves the accuracy of the results by avoiding overfitting or under fitting the hybrid svm model outperforms arima and bpnn models li et al 2013 used svm linear discriminant ld analysis and quadratic discriminant qd analysis models for wq variables estimation they found that svm is better than other considered models svm is an effective classifier and predictive model but lacks the analytic capability in terms of spatiotemporal distribution in another study nikoo and mahjouri 2013 developed a probabilistic svm psvm model wq data were fetched from fis in a monte carlo analysis and were compared with som and fuzzy clustering technique fct the psvm model performance is better than the others two studies found that svm is a good alternative to ann the study used trial and error method and ga optimisation for both models the authors found that svm generalisation capacity is high as a result over training is decreased and wq can be predicted for non point source with good accuracy and low risk abobakr yahya et al 2019 liu and lu 2014 in another comparative study olyaie et al 2017 assessed mlp rbf linear genetic programming lgp and svm models together for do prediction the efficiency and accuracy of the model follow the order svm the highest then lgp rbf and least mlp model for do estimation though lgp becomes highly applicable when it can present the empirical formula in a simple form in the same year ji et al 2017 applied svm for hypoxic river systems and compared its results with those of mlr bpnn and grnn bpnn is a traditional nonlinear regression model grnn is similar to bpnn but has no fixed architecture and needs an optimum number of hidden layers to deal with large datasets svm is superior with good performance and excellent do prediction accuracy li et al 2017a b coupled ensemble empirical mode decomposition eemd with svr and compared it with standard svr and bpnn models the hybrid model data were used for multimodal decomposition with eemd since it is practical sensitive direct and self adaptive regression analysis using svr was performed and the hybrid model was assembled to predict do which showed that svr is a better model than bpnn haghiabi et al 2018 scrutinised the performance of ann and group method of data handling gmdh using ffnn model and used a network of simplified processes and svm which utilised transign rbf as the transfer and kernel function svm outperforms the others gmdh and ann models produce satisfactory results in wq prediction fan et al 2018 explored the effectiveness of the results of the coupling of swat soil and water assessment tool and svm model to assess the relationship between aquatic organisms the results showed significant spatiotemporal deviation between variables and promising efficiency of the coupled model shan et al 2018 hybridised svm with fuzzy logic the performance of the new fsvm is superior to that of the conventional model the new fsvm can deal with noise by giving importance to different values and varying samples and manage high dimensional wq data 4 3 model assessment svm is a statistical learning technique that can be applied for classification and regression problems this method has good generalisation high flexibility global optimisation and statistical analysis capabilities svm model is accurate robust and fast the approach can identify complex nonlinear relationship better than other models such as mlp and enn due to the capacity of the kernel model to construct expert knowledge raghavendra and deka 2014 thus svm is known as a kernel model and its selection is a priority to achieve excellent performance the kernel can operate in input space and form nonlinear boundaries many functions such as linear polynomial sigmoid and radial basis function however rbf is popular owing to its less or no error advantage during testing and validation and reliable performance compared with other models such as pnn and knn haghiabi et al 2018 modaresi and araghinejad 2014 the principle of structural risk minimization makes svm superior model than others since it reduces the upper bound of the expected risk whereas the traditional empirical risk minimization theory which is applied in ann reduces error in the training data set wankhede and doye 2005 this risk management process helps svm models in better generalization capability svm performance is better when used as a classification tool svm training process is difficult than others since the parameter c of the algorithm has to be selected by the user and optimized for each class modaresi and araghinejad 2014 svm has been used as a regression model in many river wq studies this method improves the regression accuracy and interpretation and monitoring of nonlinear data as river wq svr needs pre processing of the training variables by mapping the input space to manage nonlinear data svr can be simultaneously used in data optimisation classification and forecasting singh et al 2011 a variant of svm such as ls svm can be a good tool for regression and classification this approach uses karush kuhn tucker equation from the traditional equation dimensionality reduction tools such as empirical orthogonal function can be incorporated to comprehend the spatiotemporal patterns shen et al 2019 this way makes the model flexible to the nonlinear input variables of river wq clustering techniques can be used with svm to manage large datasets and decrease computational cost and data attribute for separating objects in a group accordingly the speed of the training process increases by utilising distribution properties bhagat et al 2019 gamble and babbar sebens 2012 nikoo and mahjouri 2013 for similar results dimensionality reduction tools such as fa pca and svc can be used to deal with a large amount of data chen et al 2012 svm can efficiently predict the river wq and simultaneously classify them thus monitoring and managing by policymakers become easy to understand as river wq is divided into standardised and defined wq classes 5 complementary models 5 1 conceptual background data driven models of ai can be coupled with wavelet transformation to enhance their ability and deal with their limitations this way greatly helps towards taking advantage of both techniques because these models are individually incapable of handling the difficulties related to understanding the complex and nonlinear wq variable interaction in 1984 wavelet was first presented as dilation of a single function and its transformation grossmann and morlet 1984 wavelet algorithm consists of a dilation factor a temporal translation function and a mother wavelet wavelet algorithm can overcome the shortcoming of other models with its capacity to extract important information from a large dataset obtain data in a readable form by decomposing nonstationary signals into sub signals at different levels and solving diagnostic classification and forecasting problems when combined with various ai models wavelet algorithm can present signals in the time scale and analyse the relationship nourani et al 2014 rao 2002 various models developed using wavelet algorithm are listed in table 4 the general process diagram of the wavelet ai model has been shown in fig 6 yaseen et al 2018a 5 2 bibliographic review of complementary models wavelet de noising technique wdt was coupled with anfis model its performance was compared in two studies with rbfnn and normal anfis wdt anfis model is accurate and fast with improved properties of de noising and successfully predicts wq variables as well as found better than the other two models for optimum performance of the model the selection of various variables is important for instance orthogonal wavelet was selected in the study because it is concise easy to calculate and satisfactorily restores the original signal a similar level of decomposition and threshold methods was considered and the soft threshold technique is preferred since it produces an enhanced outcome najah et al 2012 najah ahmed et al 2019 parmar and bhardwaj 2015 developed ann neuro fuzzy logic wavelet and anfis models with wavelet transformation neuro fuzzy wavelet was used with daubechies wavelet to deal with random and spike series the result showed that the wavelet couple model produced better results than of single models considered in the study barzegar et al 2016 explored ann anfis wnn and wanfis models for salinity estimation discrete wavelet dw was used for pre processing of the data to improve accuracy thus wanfis and wnn models outperformed other conventional models barzegar et al 2018 explored the performance accuracy of elm wavelet elm welm and wanfis models the hybrid model outperforms the conventional models as a consequence of the enhancement made by the application of wavelet transformation which can deal with non stationary wq data in addition to that the application of boosting ensemble method helps to reduce error rates which allow improvement in overall model performance two studies coupled wavelet algorithm with mlp and anfis and compared them with traditional mlp anfis and mlr models dw was applied because of its high efficiency wmlp and wanfis exhibit improved accuracy and performance during extreme weather conditions affecting wt and bod values parmar et al 2019 zhu et al 2019a elkiran et al 2019 implemented bpnn svm arima and anfis model along with simple averaged ensemble sae weighted average ensemble wae and ensemble neural network enn models for wq modelling single models were tested against the models which were coupled with ensemble technique among which ensemble technique coupled with anfis model performance was superior to others ensemble technique was able to improve the performance of the models wang et al 2013 applied bootstrapped wavelet bw with ann bwnn and compared it with ann wnn and arima models bwnn model used morlet wavelet basis function wbf with ann and handled severely unpredictable and non seasonal time series and missing wq data bwnn model shows a good result but must be improved in terms of cost and prediction three studies applied wavelet transformation dw and wavelet based regression wr with the ann model to decompose wq data into a multi frequency time series against the conventional ann dw helped in noise reduction and manage nonstationary signals this method produces an accurate and superior result than others however wr produces a better result with higher accuracy than wnn models khani and rajaee 2017 ravansalar et al 2016 ravansalar and rajaee 2015 similar work was presented by solgi et al 2017 with svr and anfis models the data were decomposed using wavelet transformation and pca was used for wq data relation identification and to determine the main sub signal to increase the modelling speed wsvr model with rbf kernel performance is found superior to all considered models in this study montaseri et al 2018 applied anfis gp2 anfis sc1 gene expression programming gep wanfis and wgep models for tds prediction the hybrid models perform well but the results from wgep are exceptional because wavelet transformation is used to decompose the data into sub time series rajaee and jafari 2018 integrated dwt with ann gep and dt models to evaluate their performance for wq prediction mother wavelets applied in the study were db2 db5 haar bior1 1 and meyer amongst them db2 and meyer help the most in improving all the models performance decrease noise by separating the signals and deal with the extreme data however wgep performs slightly better than other models in prediction accuracy and error although all successfully produce better results than their conventional counterparts huang et al 2018 explored the use of fuzzy wavelet neural network fwnn ann and fuzzy logic models and included self adapted fcm clustering for determination of fuzzy rules ga and gradient descent algorithm were incorporated as the optimiser fwnn outperforms other models because of its capacity to manage uncertainty fluctuation and non seasonal time series in wq data and produce high accuracy and feasibility rajaee et al 2018 compared ann wnn mlr and wmlr models the ph prediction performance of the wnn model is better than those of the other models and can predict 2 3 days ahead due to the application of a trous wavelet transformation algorithm this algorithm dilates the mother wavelet and maintains the same length wnn performance was superior to others by removing the noise instigated by the ph shift 5 3 model assessment wavelet has been popularly used for time series analysis in river wq studies this method tries to present localised and momentary change mapping in the system between two types of wavelet namely continuous cw and discrete dw dw is more frequently used in river wq studies as river wq signals are mostly discrete and noisy thus they need decomposition and de noising dw in combination with de noising increases the accuracy of the model such as anfis and ann and decreases computational cost barzegar et al 2018 wavelet input time series analysis is crucial to river wq model because of the combined benefit of the wavelet algorithm and model can improve accuracy and performance wavelet analysis can be used for periodic river contamination identification and monitoring as it can identify the trend and the periodic changes olyaie et al 2015 a study by solgi et al 2017 reveals that the modelling speed of a hybrid model can be considerably increased if pca is used to select the main sub signals among the numerous signals decomposed by w then these sub signals can be used as input in the model pca applies kaiser meyer olkin test to assess the correlation between the variables the test value less than 0 5 is considered inadequate for analysis whereas value more than 0 7 is allowed for further analysis hutcheson and sofroniou 1999 the combined form of the hybrid model and pre processing analysis can be very helpful to deal with multi variable wq data wavelet can considerably increase the overall performance of a model and can be combined with various models such as ann they have the ability to explicate spectral and temporal information they are able to analyse time series data and establish a relationship within non stationary data allowing the couple ai model to perform better wavelet transform analysis has proved to more efficient than fourier transformation and the energy variation plotted in time frequency allows assessing the hydrological variation within the data at different scale and location partal and kişi 2007 the selected mother wavelet is important to the performance of the model orthogonal wavelet can be a good choice because it is concise easy to calculate and satisfactorily restores original signal and has a similar level of decomposition and threshold methods thus this wavelet produces an enhanced outcome daubechies wavelet can also be used with increased random and spike series morlet wavelet can be applied in unpredictable and non seasonal scenarios and in case of lack of data najah et al 2012 parmar and bhardwaj 2015 wang et al 2013 many mother wavelets can be used to deal with multifaceted wq data and must be select depending on the scenario and data availability thus a mother wavelet with flexible and wide features is suitable to study time series trends in river wq research the simplicity of the wavelet coefficient and sub signal endows the wavelet several specific characteristics such as hidden period dependence and easy diagnosis of the jump nourani et al 2014 wavelet combined with anfis model provides the hybrid model using fuzzy rules with the advantage of a reliable result since it can handle uncertain and spatiotemporal seasonal wq data the hybrid model can handle extreme data fluctuation accurately under structural missing data barzegar et al 2016 wang et al 2013 6 hybrid ai models 6 1 conceptual background ai models perform better with optimiser than without them because they have few limitations such as high computation cost inability to deal with np hard problems and difficulty with complex problems ghorbani et al 2018 optimisers such as nature inspired ni optimisation algorithms have been applied to address these issues many ni algorithms mimic the natural behaviour of humans animals and insects ml is a full fledged system with its own algorithm data structuring and learning process but it must learn adapt and evolve as nature does to create a robust system ni algorithm has gained popularity owing to its advantages i it is inspired by simple concept mimicked from natural examples such as animal insect or genetic behaviour ii it is flexible and does not need special changes in the algorithmic structure thus it is easily incorporated as an optimiser iii it only needs the representation of input and output variables iv it applies deviation free mechanism and random approach v it can avoid local optima and deal with the challenges of real problems thus it is more applied in many research areas than conventional algorithms the general architecture of optimisers coupled with ai model such as ann has been presented in fig 7 ga was introduced in 1962 and improved considerably as time progresses it works on selection crossover and mutation operators goldberg and holland 1988 holland 1962 ga uses binary strings for coding thus it uses real variable vectors as chromosomes real variables as genes and real numbers as alleles the vector is decoded and undergoes fitness evaluation which helps decide whether the vector undergoes mutation or crossover the evolution process repeats until the best performing model is found maier et al 2014 wright 1991a b ga search by allocating efforts to regions of the search space based on an estimate of the relative performance of competing regions in complex domain one expects perpetual novelty to be a characteristic feature in this case traditional search techniques are likely to be misled and ga may be the search technique of the choice for machine learning system fitzpatrick and grefenstette 1988 gp models which are a class of ea that combine ga and gp are based on the darwinian principle of evolution theory proposed by koza 1997 it is a systematic domain independent method that spontaneously solves the problem without requiring the designers to have in depth knowledge of the solution structure gp functions as an optimiser and classifier this method includes a syntax tree with branches as functions with arguments and leaves of the tree as variables and constant since gp uses ga the primary operators are crossover and mutation poli et al 2008 compared with ga gp models are more flexible and can evolve variable length gp has various versions such as linear gp grammar based gp graph based gp and tree based gp each with different presentations this approach applies stochastic search properties acts as a global search is least trapped in local optima varies in solution architecture has freedom of expression to obtain an improved solution by searching relationships has automatic removal of unwanted variables and finds meaningful associations from the given data jabeen and baig 2010 various algorithms are based on the behaviours of organisms for example particle swarm optimisation pso algorithm uses the concept of bird flocking fish schooling and swarming theory pso is based on a simple concept with the least coding its advantages over ga include enhanced performance due to group interaction and memory retention eberhart and kennedy 2002 another ni algorithm is the ant colony optimisation aco algorithm which is based on ant system as the name suggests this algorithm has positive feedback that rapidly discovers the appropriate answer its distributed computation evades early convergence and uses constructive greedy heuristic for fast results this approach is flexible tough and population based dorigo et al 1996 shuffled frog leaping algorithm sfla was introduced to solve discrete optimisation problems sfla transforms frogs into a memetic evolution chain that is a system of behaviour that must be passed from one frog to another similar to an infection no physical change occurs but the idea held by each frog improves the difference from ga is that it only allows genetically alike individuals to interact whereas sfla spreads the idea to all characters eusuff and lansey 2003 similar to the natural behaviour of insects such as fireflies that produce light to communicate the hunt has been used to develop an algorithm on the basis of this theory the firefly algorithm ffa has been designed ffa has several benefits over pso and ga i ffa can estimate better and converge faster towards optimality and ii is more efficient in finding the global optima yang 2009 consistent with the previous theory of ffa bat algorithm ba has been designed based on bats echolocation behaviour ba consists of a good combination of pso and ga yang 2010 various models developed using hybrid nature based algorithm are summarised in table 5 6 2 bibliographic review of hybrid ai models ga is the earliest of the natural algorithms applied in river wq studies ng and perera 2003 applied ga which works on the principle of natural selection where parent population is generated and improved by selection crossover and mutation and used as an optimiser for the wq model ga operators play an important role along with sensitivity analysis to obtain the convergence point which makes the model robust and effective in another study icaga 2005 used ga as an optimisation tool to find and apply the best possible input combination ga performance is better than dynamic programming burchard levine et al 2014 evaluated the performance of ga and ann models to increase the response time of the early warning system ga ann model successfully provides a response 8 h ahead of time and can effectively understand nonstationary and vague data in another study chatterjee et al 2018 studied non dominated sorting ns ga ii modelling which is similar to ga but optimises multiple objectives with ann model and compared it with nn ga and nn pso models nn nsga ii is superior to and more stable than other models jin et al 2019 developed a model by integrating improved ga which uses multiple data sets of the sliding window for choosing optimum initial parameters for bpnn which was able to adjust the proper architecture to recognize the wq deviation the result from the integrated model and the normal bpnn were compared and shown significant improvement in predictability effectiveness and reliability zhou et al 2006 enhanced ann modelling result by integrating pso optimisation technique which is based on the cognitive and social interaction of flocking birds where particles are induced to their most promising solution the solutions were compared with ga and bpnn algorithm and result show that pso is robust and good tool for predictive models piotrowski et al 2014 explored lm ann model as the main model and compared it with pso differential evolution de with global and local neighbourhood based mutational operators degl degl proxin differential evolution separate groups de sg ja de self adaptive de and other adaptive methods a total of 23 different training methods were used and most were selected from de evolution strategies direct search and pso most of them are inferior to lm nn performance in wt modelling li et al 2016a b demonstrated the implementation of mlr bpnn and svr coupled with pso as an optimiser the authors prevented overfitting and bias by applying the leave one out cross validation method during the training process performance capability is highest for pso svm then pso bpnn and lowest for mlr since among all svm is more capable to handle the nonlinear relationship between variables keshtegar et al 2019 evaluated the performance between polynomial chaos expansion pce a model that predicts practical problems using a stochastic model mlp pso mlp and mlr the performance of pce and mlp pso is similar and has higher predictive accuracy than others considered in the latest research article by azad et al 2019 anfis pso anfis acor ant colony optimisation based technique used by ants to find food and ann were equated gp sc and fcm were used for fis generation anfis acor provides good results during testing and pso performs well during testing therefore ea is a good optimising tool for modelling ec tds and sodium absorption ratio sar mahmoudi et al 2016 explored sfla optimizer which is based on the social behaviours of frogs which are sorted based on reducing or arising of the problem and gp was applied with the svr model sfla svr is better than gp svr in terms of accuracy in another research by raheli et al 2017 ffa which is a swarm intelligence optimisation method based on the movement of the firefly was introduced and coupled with mlp the hybrid model accuracy in do and bod prediction exceeds that of conventional mlp and the method can be used in other scenarios with available data in another study li et al 2017a b integrated ffa optimisation technique with svr the hybrid model is better and robust than the traditional svm model in wq indexing ffa svm saves money and time as it is a direct and rapid testing technique yaseen et al 2018a b c d verified the improved version of lssvm with ba which uses the principle of echolocation capacity of the bat for locating its prey model tree m5 and multivariate adaptive regression splines mars model were used for comparison lssvm ba outperforms all other models considered chen et al 2018 optimised bpnn model with an improved artificial bee colony abc algorithm were applied for do estimation the results stipulated that improved abc bpnn is superior to traditional bpnn due to the better predictive capability and higher accuracy due to the improvement in the speed of convergence and ability for local searching and generalisation azad et al 2017 investigated the performance of ga aco and de coupled with anfis model anfis de is the best optimiser for its high velocity simple operation and capacity to detect the best response and the ability to improve uncertainty in wq data anfis de outperforms others but all ni algorithms have the aptitude to optimise anfis as a predictive model ahmadi et al 2018 evaluated ca for classifying wq and fa to determine the important variables five input selection methods were applied which are correlation model pca and gamma test with backward regression and ga with gamma test for bod modelling lr ann and gp models were used the results showed that the best input method is the gamma test with backward regression integrated with lr gamma test with ga integrated with ann is the best model 6 3 model assessment ni algorithms are also known as eas since they solve the problems inspired by biological mechanisms that evolved by a long extended time of learning the concept makes this group of algorithms unique as the algorithms are based on real life system and easy to grasp they are easy to couple with other models as optimisers which helps deal with nonlinear and uncertain data ashrafzadeh et al 2019 maroufpoor et al 2019 their ability to deal with the complex problem in addition to their capability to perform a global search and local search and find the nearest optima popularise their use amongst optimisation techniques the hybrid models that are used in river wq assessment are population based algorithms such as ga pso acor ffa and ba a pso can be more effectively implemented for hydrological data since it has low computational volume easy to operate not dependent on the problem high convergence rate global search capability can deal with complex problems and can escape local minima azad et al 2019 taormina and chau 2015 b acor uses a probabilistic approach that can find the best path through graphs although it has high affinity solve discrete problems it can solve continuous wq problems by applying probability density function it applies global search techniques can escape from local minima and can solve most of the complex issues but suffers from low convergence speed socha and dorigo 2008 c ga is a population based stochastic optimization tool which can effectively deal with non linear and non differential wq data issues by achieving optimum solution by the repetitive process the operators can leap to different spaces with the look space to find the new best solution it is a non exhaustive process until the desired solution is achieved jakubcova et al 2015 yaseen et al 2019b these advantages allow them to solve highly complex and multi parameter problems d another swarm optimisation technique is sfla which has been a least explored optimiser in river wq studies this method uses a set of frogs as a representation of solution and spreads similar to an infectious disease from one frog to another without discriminating similar to ga only blood relatives are accounted for mahmoudi et al 2016 e similar algorithms such as ffa ba abc and acor have been explained in recent years in river wq monitoring studies as an optimisation tool they have high convergence speed propensity for local and global searching good generalisation and direct and rapid testing method naganna et al 2019 these qualities enable the model integrated with them to achieve superior accuracy and great efficiency ga is an established and robust nondeterministic optimisation tool ga generates parent population is enhanced with selection crossover and mutation utilises probabilistic transition rule and easily converges ga provides stable and efficient results ng and perera 2003 however limited research has considered gp models gp perform well when data are pre processed using wavelet transformation the linear and explicit representations of such model depend on convenience efficiency and genetic operators additional research is needed for better utilisation of these models considering they can be easily manipulated evolve during training and solve complex problems in an unexpected manner gp is a powerful tool to establish the relationship among input and out of non linear system thus a prevailing tool for environmentalists and hydrologists olyaie et al 2017 gp is a systematic domain independent a self parameterizing tool which doesn t require pre defined structure knowledge and tuning mehr et al 2014 few optimisation algorithms use behaviour patterns for example ga goes to the in depth knowledge and concept of genetics pso has no crossover and mutation transformation similar to ga pso is combined with different models such as ann anfis and mlr to increase predictive and classification potential in each case this approach is proven to be a good optimiser because it can enhance performance and has a retentive memory particles are persuaded to achieve the most promising result in a short period which also works as an advantage of decreased computational cost zhou et al 2006 7 other ai models 7 1 conceptual background various models are least explored than others in the field of river wq assessment prediction and classification thus all the other models that do not belong to the other classes discussed in the previous section are collated here model tree m5p uses a binary decision tree dt along with multilinear regression to predict continuous numerical attributes the first step consists of splitting criteria to generate a dt the second step consists of a pruning method to eliminate overfitting and the construction of a linear regression function compared with ann and svr m5p model reveals the pattern and relationship in the data this model is simple yet efficient and accurate for pattern recognition and relation establishment for large scale data etemad shahidi and bonakdar 2009 quinlan 1992 random forest rf also uses the regression approach with a combination of tree predictors this model uses a randomly selected section of training dataset for each tree the method uses only one third of the data and the remaining is called out of bag rf consists of several input variables and requires a large number of trees breiman 1996 breiman et al 1983 another regression model developed during the 1990s by friedman 1991 known as multivariate adaptive regression splines mars which is a combination of recursive partitioning and regression the approach is a hierarchical forward backwards subset selection procedure this model consists of product degree knots dependent variables intercepts and basic function the model is flexible as it allows recursive splitting and produces a continuous model by substituting the step function gep is based on a similar concept as gp and ga however it has the features of a model danandeh mehr et al 2018 specifically gep utilises individual population fitness test and genetic operators sanikhani et al 2019 gep encodes individual population as linear strings of fixed length and later expresses them as nonlinear entities of different sizes and shapes during the operation the first step of gep is similar to that of ga whereas the second step is similar to that of gp gep can adapt and evolve this method can be easily manipulated as a consequence of its use of chromosomes that are linear compact and small the approach always produces valid expression trees reproduces nominated chromosomes with alteration and expresses them as expression trees for the next generation ferreira 2001 arima model process includes model identification variable assessment and diagnostic scrutiny identification is done to obtain stationarity and normality temporal correlation is verified by autocorrelation and partial autocorrelation by following these steps arima determines the minimum akaike information criterion to obtain the best model shahwan and odening 2007 table 6 reports the studies conducted on the other ai models 7 2 bibliographic review of other ai models džeroski et al 2000 applied m5 and ordinary regression tree rt models to address the issue of selective chemical wq monitoring and its effect on river health rt model successfully produces a good sized structured generalisation of the input that is easy to interpret the model can establish the relationship between the variables which are expressed in mini and max values therefore bio indicators can be influenced by seasonal deviations the biological state of the river can also be influenced by the chemical state nikoo et al 2013 applied m5p and svr models for the valuation of integrated water quantity management to minimise load on water supply and targets during the planning of projects m5p model is a combination of a dt and multiple linear regression model which is applied on input output variables using deduction learning for the better understanding of the input output relationship the better management skill of m5p model in handling environmental data and its capability shows the pattern and relationships in the data by the regression equation thus its performance is superior to svr sepahvand et al 2019 examined the performance of m5p rf and bagging m5p along with gmdh models bagging m5p model outperforms other models because of the least standard deviation from the predicted value and shows high accuracy and validity due to low values of the vagueness indices its flexible approach also decreases the computational cost kisi and parmar 2016 compared least square svm lssvm mars and m5 tree models mars can manage the complex nonlinear relationship and perform on forward and backwards stepwise patterns as a result the model can exclude unnecessary variables and select suitable variables furthermore lssvm which works in the principle of structural risk minimisation can deal with estimation classification and regression analysis with a simple approach it is robust against noises and has lower computational cost than the conventional svm models the results showed that both models are more accurate and better than m5 tree in predicting river wq heddam and kisi 2018 presented the application of lssvm mars and m5 tree models the performance of the three models is excellent but each performs better than others in a different scenario for do prediction input max scaling was used for dimensionality reduction the result concluded the effect of discharge may vary by place but ph and wt influence over do are undeniable and essential for correct do prediction maier and keller 2018 tested knn rf svm mars and extreme gradient boosting xgb models the models were coupled with pca as a pre processing tool for managing high dimensional data and compared with the models without pre processing the regression models with pca perform better than the other models due to their higher accuracy lesser error and ability to handle high dimensional regression problem di et al 2019 applied hierarchical clustering expectation maximisation clustering algorithm and time series analyses to classify pollutants short time pollution condition and sudden unusual events the data were normalised using ward s method the models perform well and can classify the pollutants rankinen et al 2019 applied the generalised linear model glm which can manage non normal error distribution and boosted regression tree brt model which can handle nonlinearity and missing data their study aimed to predict river wq condition in various future scenarios considering indirect factors such as climate change agricultural measures and environment policies the model predicts the increase in annual mean wt to 17 3 c between 2025 2034 and approximately 19 3 c by 2055 2064 with an increase in precipitation of 10 in addition summer is predicted to face low flow the study can predict an increase in annual concentration nitrate suspended sediments and phosphorus by 16 63 45 146 and 38 100 respectively in 2025 2034 geetha jenifel and jemila rose 2019 applied a linear model svm and dt recursive partitioning technique was applied to identify the relationship between variables dt shows the least error rate manages considerable numerical data produces good data quality and handles dataset with errors and outliners ho et al 2019 evaluated the productivity of dt model to simplify analyse and classify the wqi for decreasing its complexity and the nonlinearity of data the study concluded that dt model can be a cost effective and process efficient modelling methodology sharif et al 2015 coupled som and knn to examine the classification and monitoring capacity of the combined model for river wq the clustering technique was used to reduce the number of variables and k nn was used for classification the model can identify the point of pollutant source and recognise patterns in the data sattari et al 2016 applied the knn algorithm for classification and regression along with traditional svr model both models could successfully predict wq but the study suggested that svr model with the rbf performs better and is more applicable than the other model due to its high performance easy execution and flexibility in case of sudden changes in wq variables ömer faruk 2010 explored the possibility of hybridising arima with neural network models because both are individually incapable of handling linear and nonlinear time series data efficiently thus both were used separately and combined afterwards for improved modelling and prediction performance the combined advantage of both models produces good results in identifying time series patterns and nonlinear characteristics cole et al 2014 tested the performance of generalised least square model with a cosine trend glscos arima and ann models for wt modelling arima model performance is least accurate in predicting ahead of time yet it does not show over estimation bias and under or over prediction glscos model is better and highly accurate even though all models perform well guo et al 2014 applied hybrid arima svm arima and svm models were optimised with pso for do and ph prediction the hybrid model uses both components of the models and can process linear and nonlinear data with overall enhanced forecasting accuracy su et al 2011 implemented rotated pca and da to identify the point source of water pollution and evaluate the temporal changes in wq som was applied for clustering and visualisation and ann was applied for partitioning absolute principle component score with mlr was applied to obtain the quantity information the results showed that the model is best for identifying pollutant sources which help in better manage the river pollution grbić et al 2013 applied a probabilistic nonparametric approach that is gaussian process regression gpr with lr to resolve nonlinear regression water pollution issues the inputs were fetched by least square criterion and mlr was used with mutual share information the first model can understand the periodicity of wq the second one can handle short term non periodic components fahmi et al 2011 combined pca with mlr to simplify and better understand the complicated and vague relationship between wq variables the new model is better than the conventional one reduces sampling time and cost and eliminates data collinearity keller et al 2018 studied a large number of models such as lr partial lr rt extremely randomised trees et gb knn svm ann and som models et svm and ann models are the best amongst the models et has the superior performance after pre processing with pca and ann is the second best model with mini max scaled pre processing of wq data another study also considered the application of the lr model for the prediction of ec different combination of logarithmic and inverse transformation statistical technique was applied for model improvement the ability of the lr model to fit on the non monotonic behaviour of data resulted in better performance in handling wq data salarijazi and ghorbani 2019 jiang et al 2018 applied growing hierarchical self organising map ghsom as a classification model the model can establish the correlation between the wq variables and detect the main pollutants the model is fast because it automatically generates neurons to achieve the specific clustering accuracy applies hierarchical inheritance approach for assessment and creates clear boundaries peterson et al 2019 implemented various predictive models such as mlr plsr gpr svm and elmr models with cca for spectral analysis of river wq variables the study aimed to incorporate decision level fusion method which produces promising results the fusion increases the overall accuracy and efficiency of the model and eliminates biases zaman zad ghavidel and montaseri 2014 predicted tds as an indicator for wq assessment using ann anfis gp anfis sc and gep models inspired by the genotype phenotype system the performance follows the order gep anfis sc anfis gp models najafzadeh et al 2018 examined gep evolutionary polynomial regression epr and model tree mt gamma test was coupled to better understand the relationship between the variables epr which is a nonlinear global stepwise regression method is a better model than others mt performs well as a classifier 7 3 model assessment the models that fall in the categories in the previous sections are accumulated here the number of users of such models are few yet their performance is promising the literature shows that numerous models have gained popularity in recent years one such model is arima which was reported in 2010 ömer faruk 2010 its performance improves when it is coupled with another model for it cannot deal with nonlinear time series data which may be the reason why it has been less implemented in river wq studies wang et al 2015 its ability in likelihood estimation and forecasting score test for model checking and time series modelling box et al 2015 similarly knn model can perform classification with good accuracy but its performance is inferior to that of svr which may be why knn has been used less in river wq research sattari et al 2016 however this model needs exploration along with research possibility of hybrid k nn models regression models are popular models after conventional models for example m5 can yield good generalisation better understand the variable relationship avoid overfitting and achieve high accuracy sepahvand et al 2019 dt models have been successful in event prediction and can be applied for recognising wq variation they are able to solve classification and regression problems this model applies top down greedy search without backtracking and can be used for categorical and numerical data management brown and myles 2009 dt can decrease complexity classify and handle nonlinearity with least error rate and handle a considerable amount of data geetha jenifel and jemila rose 2019 there are many variants of dt which are yet to be tested in the river wq research such as logistic mt reduced error pruning tree naïve bayes trees alternative dt khosravi et al 2018 due to model problem solving technique recursive dive and conquer and simplification of the complex issue allows more applicability in complex wq data modelling addition to that dt models are easy to interpret and can predict an unpredictable outcome ho et al 2019 mlr model in an older model but recent studies have shown that the hybrid version of the mlr model has been mostly applied the reason mlr is a mediocre model as concluded from section 2 2 compared with the ann model the studies have shown that mlr coupled with dimensionality reduction tools or optimiser can perform well in pollutant source identification and handle non periodic variation moreover it can understand complex nonlinear and vague river wq data when optimised fahmi et al 2011 grbić et al 2013 models like mars have been least implemented in river wq as it easily gets trapped with overfitting and solving regression problems is narrow abdulelah al sudani et al 2019 however pruning can help to increase the forecasting accuracy which can be achieved by the backward process using generalized cross validation wang et al 2010 mars model flexibly and capability to manage high dimensional regression and classification problems makes it a good model to be tested in river wq modelling it can separately identify the additive contributions friedman 1991 8 a general appraisal of global literature review 8 1 prerequisites of new model developments the application of ai models has rapidly progressed over the last two decades along with various improvements a continuous innovative attempt has been to develop the best model for river wq fig 8 shows the research development in river wq field over the last two decades from 2000 to 2007 the average research published was 2 per year steady growth was observed from 2009 to 2012 during when the average research published grew to 10 studies per year river wq modelling gained momentum during 2009 2012 due to increased awareness of the application of ai models and the advantages for wq prediction and assessment for river health management furthermore rapid advancement in ai model practices can be observed from 2013 to 2019 average reported research publication was 20 per year and still increasing additionally the data from 2018 31 papers and 2019 31 papers in the coming years the advancement of the application of ai models and optimising tools will grow more popular in the scientific community than before in the last few years synchronous growth of published research has indicated increased concern about the river water pollution and its effect on the study area which is ubiquitous worldwide increased frequency of ai model research can realise its possible implementation in river wq research and in real life uses such as river health monitoring classification of a pollutant point source customised policy making and water treatment management bhagat and tiyasha 2018 this apprehension is affected by factors such as increasing population agriculture industrialisation and urbanisation which directly and indirectly affect river health thus ai models are needed as a result of their superior understanding and applicability to handle the complex relationship between the river wq and various factors responsible for the change in wq in previous assessment sections the individual ai models have been assessed on the basis of model strength to deal with complex and nonstationary river wq data fig 8 clearly presents the growth of ai models over the decades moreover numerous architectural changes have been observed along with this exponential growth of application of ai model the continuous progression implies the need for further exploration because each model has its own limitations and benefits this section highlights a few weaknesses of the models for the need of designing new advanced models a the 209 reviewed studies revealed that various models were used 311 times ann or any form of ann was implemented successfully as a good predictive model for 133 times 43 as shown in fig 9 despite the success rate of ann it has disadvantages such as the need for large data for training overfitting problem local minima issues and false negative frequency issues ann also lacks the understanding of complex environmental data b fuzzy logic and fuzzy interference systems are the oldest and extensively applied algorithms in river wq after ann their application in 48 studies 15 makes them the second most applied model after ann models however they have limitations such as needing rules for combining the appropriate membership function which prevents the less experienced user from achieving the best performance out of the data moreover the rule cannot differentiate amongst important input factors c the next is svm 32 studies which was implemented in 10 of research and can solve regression classification and prediction problems this approach faces problems in the choice of kernel and high computational cost svm may suffer due to data inconsistency and inability to handle probabilistic forecasting the nonlinear models cannot be easily deduced due to the complication in mapping nonlinear space into high dimensional space which interferes with the computational speed d various optimisation techniques using ni 18 studies were integrated with these models as support but they also faced various issues for instance pso faces the problem of unrestrained particles which tends to leave the feasible space as a result its convergence speed decreases sfla needs prior input normalisation to achieve good accuracy acor is hindered by random initialisation and excess parameter requirement and needs tuning e eas such as ga suffer from early convergence issue do not use local search information and take a long time to tune gp is dictated by natural behaviour which makes it random and unable to guarantee the required results gp suffers from bloating that is excessive growth of the code without any substantial growth in the fitness silva and costa 2009 ga and gp designed with binary expression produce invalid expression and cause increased computational cost gp ga and gep can be easily manipulated but lead to functional complexity this complexity hinders the redesign of the same model and production of the same result ferreira 2001 f the performance of the wavelet algorithm 16 studies depends on the choice of the mother wavelet and the decomposition level this condition results in its unpredictable accuracy despite a few issues the wavelet algorithm complements other models very well and increases their performance level g it was observed that river wq modelling is associated with uncertainty feature and thus uncertainty analysis for the dataset models and input variables should be investigated for better understanding of the predictability performance chen and chau 2019 shamshirband et al 2019 yaseen et al 2019a h it has been observed that most of the research study did not give much thought for the data division techniques during the study commonly employed data splitting is simple random sampling which is an unsupervised technique it is efficient simple in application and produces low bias lohr 1999 however it suffers from a high discrepancy of the model performance error estimation under this technique other methods are som physical process based domain knowledge based trail and error and user rule based methods are few which have been frequently applied among them the trial and error method has less variance in the model performance and can be combined with more techniques but takes a lot of time and there is no proper theoretical background bowden et al 2002 however this minute consideration of data splitting ration can have a significant effect on the result dawson and wilby 1998 thus utmost precaution should be taken when considering wq data and its statistical properties i throughout the literature it was observed that several types of research were conducted on the baseline of comparative ai models capacity with respect to the predictability performance this was seen in journals mainly related to water quality researches such as journal of hydrology environmental monitoring and assessment environmental science and pollution research stochastic environmental research and risk assessment water supply water resources management science of the total environment etc as a matter of fact this kind of researches adds no value to the base knowledge of river water quality modelling the establishment of water quality modelling using the feasibility of artificial intelligence models should be incorporated an innovative contribution where insightful aspects of water quality are discussed debated and recognized in addition there must be an informative reason explained for the behaviour of the predictive model 8 2 most explored rivers fig 10 shows the number of studies in each country along with a map that presents the most explored and modelled river streams worldwide in the last two decades the leading ai research on river wq area have been accomplished in china 42 out of 209 this result suggests that ai models are popular and gaining interest as time progresses most study areas are from asian countries such as china 42 iran 31 india 22 malaysia 23 taiwan 8 korea 4 iraq 4 bangladesh 2 thailand 1 and hong kong 1 representing 138 out of 209 papers this result can explain why ai models are continuously gaining popularity in developing countries moreover asian countries are endowed with perennial and non perennial rivers which demand much research on surface water resources such as rivers rivers are the lifeline for agricultural and industrial growth and agricultural countries that grow crops such as rice and sugarcane need a substantial amount of water for irrigation thus increased research evidently manages and monitors river wq to maintain healthy crops after china usa has the second majority of 31 papers which can be justified by its large land area with rivers and advanced monitoring station where data are freely available for study worldwide thus usa is a popular choice since modelling scientists need good quality data for testing new models many countries and river sources are yet to be explored a large number of studies should be done considering diverse conditions for each study area which can help design models applicable to various situations although the african continent ranks third by land size and comprises 54 countries only 2 studies have been reported the reasons are i many of its countries are under developed and developing thus still working on their water related policies and don t have comprehensive policies ii many countries are still in the initial stage of industrialisation and use natural methods of farming which leads to minimal pollution concerns iii the mass population is less educated leading to less acceptability and addition to that there is less or no teachers for ai powered education to prepare the next generation iv fewer funds for ai research and education v concerns in the data collection transparency ethics and proper utilization of the data pedró et al 2019 ukpong et al 2019 however additional studies must explore the unique diversity amongst various african river streams similarly the number of river wq research reported in australia are only 2 possibly due to the least orientation of researchers towards ai techniques the cause of such alignment is due to the acceptance of the ai technique since it will cause a shift in the job will need to upskill the workforce needs implementation of safer and ethical policies increased cybersecurity privacy and advanced data collection system hajkowicz et al 2019 the ecological quality of river water quality can be articulated as organic and non organic variables regular monitoring the environmental and hydrological condition of a river zone can help to a better insight into the changes in the variables even the macro or microhabitat regarding this there is a challenge in dealing with the existing quality indicators and the specified reference value of them it has been pointed out in the introduction that most of the changes in water resources are related to anthropogenic activities the only salvation for humankind to solve the self created problems in designing effective water related policies which should be knowledge based on the catchment area frequent intensive monitoring data environmental indicators effects of previous legislation and the social and economic activities in the area to reduce the sudden change in wq due to industrial or municipal wastewater discharge or an extreme condition like a flood it is essential to rely on advanced water and wastewater treatment integrated environmental monitoring and automatic water quality modelling system both last techniques can be equipped with remote sensing and sensor technology to obtain high quality data nevertheless this kind of technology implementation is the need of the hour but still a challenge for the hydrologists environmentalist and data scientists as of the wq has a wide range of indicators and variables their measurement and understanding of inter relationship and the influence of each other can be difficult to interpret 8 3 water quality output consideration all previous review and research papers have mostly emphasised on input data which are essential for modelling process and various input optimisation techniques have been used to ensure the most potential input is used relative to the relationship established with the output variable although researchers have considered the input output relationship for modelling the least thought and analysis have been considered in the wq review papers about the output variable selection the reason is that the basic approach of these studies is to establish the relationship between the input and output another reason can be those input variables are used for learning optimisation and dimensionality reduction and a relation is established based on their sensitivity towards the chosen output variables thus they are the focus of the study furthermore the output is commonly decided based the issue addressed by the researchers such as if the issue in hand is algal bloom then output considered is macrophytes whereas if the problem is salinity then tds or ec is taken as output not by applying any predefined technique the major outputs highlighted in fig 11 represent the number of papers that have used each output variable out of all the considered studies thus the current study emphasises the assessment of the output and why few selected outputs or a single rather than multiple output is selected in many cases the figure presents that out of 209 assessed papers 55 papers used wqi which indicates the multiple numbers of output variables the remaining 154 used single or few outputs wqi is mainly considered in the case of river wq classification and trend determination where multiple variables are assessed against the government standards and classified in simplified categories the most popular wq variable is do do is a critical wq and river health indicator do is part of various water related reactions such as aeration underwater photosynthesis chemical oxidation and decomposition sufficient amount of do is essential for not only for humans but also aquatic plants and animals gray 2017 do holds the highest part in chemical wq assessment and is very easily affected by other variables thus finding the do can provide a considerable amount of insight on river health wq changes and further treatment requirements few variables may have an indirect and synergistic effect wt affects the solubility of the water and works as a catalyst in various chemical and biological processes in the river it also inversely affects the solubility of do another essential wq variable is ph which is the potential of hydrogen ion and one of the largest initiators of all chemical and biological processes such as corrosion decomposition solubility and toxicity similarly bod and cod which are the fourth and ninth most used variables respectively are the wq indicators that manifest microbial and chemical reactions occurring in the presence of oxygen in the water bod is one of the first wq variables discovered for river health detection bod and cod signify the need for treatment or the extent of river pollution few wq variables are considered indicators of another major pollutant contaminating the river water for instance an increase in chl a signifies an elevated chance of algal bloom macrophytes indicate the growth of phytoplankton and eutrophication in the water which kills aquatic plants and animals such as fish nitrogen compounds which are second to do also indicate and encourage algal bloom eutrophication and dendrification they create nox that leads to global warming along with nitrogen phosphorous indicates the same but also informs about industrial wastewater contamination similarly ec indicates mineralisation and salinity in the water al shujairi et al 2015 as per the reported survey it is evident that the performance capability of ai is dependent on the water quality multifaceted nature while designing a predictive or classification model the complexity depends on the number of different inputs integrated i e fewer is the better whereas too many inputs increase the intricacy of the model it is worth to highlight the applicability of ai models with the various model version as classified in fig 1 can change depending upon the geographical location government policies local population behaviour climate change and other unique scenarios thus there is no issue in the application of ai model in simple cases however the ever changing wq due to the dependent variables can cause a serious impact on the modelling result for instance oxygen depletion or organic decomposition or biological activities aquatic plants animals or microbes can alter the amount of do bod and cod another example can be nitrogen related compounds which changes its structure quite often due to change of other factors nitrogen fixation ammonia nitrification nitrate denitrification nitrite to molecular nitrogen 8 4 wq data variation time scales the survey shows that most ai model papers have considered the use of monthly data for river wq modelling as shown in fig 12 a total of 92 papers provided information about the uses of monthly data out of 110 papers which provided information on the data step this percentage can be considered as 50 because 46 papers have not reported on the data collection interval amongst all reviewed papers followed by weekly 9 papers yearly bi weekly and bi monthly 3 papers each the main reason of the highly conducted research on monthly river wq include unavailability of sufficient project budget few analytical laboratories lack of technical and skilled human resources policies of decision makers and meeting the basic need for modelling monitoring and managing river health in addition monthly wq monitoring can be highly essential for multiple water supply usage agriculture and water treatment plant design thus the prediction of the monthly time scale can contribute to several environmental engineering perspectives to obtain considerable insightful information a total of 12 research papers conducted time series hourly data 8 from the usa 3 from china and 2 from uk accordingly hourly data are from developed countries with sufficient funding and advanced monitoring stations that can obtain hourly data effectively with highly equipped laboratory facilities similar findings can be observed in case of daily data out of 26 papers 9 are from usa and 8 are from european countries which may again be due to availability of funds and facilities this finding signifies that these countries can manage and collect large amounts of hourly and daily data to produce good and effective models consequently better measures can be taken against river pollution one of the unique time steps is seasonal where few specific months are targeted a total of 15 papers which used seasonal data collection to save funding by collecting data for a precise period of the year which were already evaluated for changing trends in the specific time of the year thus the resources must be concentrated on those specific time intervals another possible reason is that the rivers selected for the study are non perennial seasonal furthermore the decision of selecting the appropriate data time scale depends on the objective of the study for instance if the researcher aims to understand the point source of pollution then daily time scale will most likely be used to provide improved insight into the wq changes due to industrial effluent discharge domestic wastewater discharge and agricultural runoff similarly if the study targets seasonal variation such as flood drought or any other unique natural changes affecting river wq then specific months or weeks of the year and seasonal time steps are preferred using quarterly and yearly data collection may be inappropriate as it does not add any value to the research selecting the correct time interval of data collection is important to achieve the objectives because the river has the capacity for self purification which indicates the wq can change naturally over time thus it is important to select the correct time interval of data collection to achieve the objectives 8 5 performance metrics performance metrics are statistical criteria that help developers assess the calibrated modelling performance on various platforms they also translate performance accuracy and efficiency into understandable and expressible form over 30 evaluation criteria have been used in river wq modelling and few are represented in fig 13 ai models mostly use quantitative error measuring technique the most frequently used square error measuring systems are root mean square error rmse 101 papers nash sutcliffe efficiency nse 19 mean square error mse 3 and sum of square error sse 3 based on the square of the differences between the actual and predicted values influenced by the error rmse is popular as of it can show several deviations is reliable and provides high weight to error however outliers should be removed coefficient of determination dc 69 which is the second most preferred matrix evaluates the predicted value produced by the model in respect of the actual value which provides the model performance and ranges from 0 to 1 nagelkerke 1991 another group consists of absolute errors namely mean absolute error mae 50 mean absolute percentage error mape 20 and absolute relative error are 2 they are the absolute difference between the actual and predicted values they only provide information about the extent of the error but not model validity however they have good sharpness willmott and matsuura 2005 correlation of coefficient cc 10 coefficient of efficiency ce 7 coefficient of variance cv 3 and nash sutcliffe coefficient nsc 12 gauge the strong relation between data and relative movement of two datasets with different units mccuen et al 2006 many studies have reported classified river wq into classes c namely good average and worst per the standard wq guidelines of the study area for better understanding these studies have kept separate cs and 32 papers have reported this classification yaseen et al 2018c among all the computed performance metrics although correlation coefficient r and dc determination coefficient was widely used for models evaluation they are oversensitive to high extreme values and insensitive to additive and proportional differences between model predictions and observed data legates and mccabe 1999 moriasi et al 2007 on the other hand the mae was majorly used for evaluation owing to its less sensitivity to the extreme values in the predicted dataset in comparison with the rmse fox 1981 studies reported nash sutcliffe efficiency nse is a normalized statistic that determines the relative magnitude of the residual variance compared to the measured data variance nash and sutcliffe 1970 according to the guidelines of hydrological model performance evaluation proposed by moriasi et al 2007 the performance of a hydrological model is very good if nse is more than 0 75 hence this is another remarkable metric to be investigated for such type of modelling other informative metrics can be examined for better modelling evaluation and assessment which have not applied are volumetric efficiency ve metric can be explored to circumvent some problems associated with nse unlike the usual correlation coefficients or the nse ve would be particularly helpful in comparing the performance of similarly scaled it has the additional advantage of being easy to calculate the modified index of agreement m ia developed by willmott 1981 as a standardized measure of the degree of model prediction error is one of the essential metrics for evaluating predictive models and thus it is giving more insightful aspect on the modelling certification although it provides some improvement over dc it is still sensitive to extreme values due to the squared differences in the mean square error in the numerator legates and mccabe 1999 in addition the disadvantage of the results given by the previous dc and nse arises from the fact that the differences of observed and predicted wq use the squared values consequently large errors in time series can be overestimated whereas small values can be neglected in order to overcome this limitation willmott 1984 introduced a generic form of index of agreement willmott s index wi the advantage of the wi is that the errors and differences are given their appropriate weighting and are not inflated by their squared values to reduce the effect of absolute differences during peak values of wq and to improve the effect of absolute low values differences the relative index of agreement r ia is applied which is a substantial metric that measures the differences between the observed and simulated values as relative deviations chadalawada and babovic 2019 another significant metric is kling gupta efficiency kge it provides a diagnostically interesting decomposition of the nse which facilitates the analysis of the relative importance of its different components correlation bias and variability in the context of hydrological modelling gupta et al 2009 persistence index cp based on the assumption that the process is a wiener process that aims of comparing the performance of the models against a simple model using the observed value of the previous day as the prediction for the current day as opposed to a constant mean the percent bias pbias measures the average tendency of the simulated data to be either higher or lower compared to the observed data according to moriasi et al 2007 the pbias 10 indicates very good performance model the performance of the predictive models could be evaluated as well through visual inspection of graphical representations such as scatter plot box plot relative error taylor dia0gram and violin plot those plots are very useful to have a better understanding of the prediction capacity 9 conclusion river water quality research interest has grown over the years and the amount of data analysis generated from such research needs efficient handling assessing and predicting tools correspondingly ai technology has proved to be a powerful tool which has been successfully applied in various field including hydrology and environmental engineering considering the sub classes of the ai models most popular model is ann models then fuzzy kernel based models complementary wavelet and hybrid nature inspired models the review has gone through more than 200 papers which have addressed the river water quality modelling to better assess predict and manage the current issue of surface water pollution the assessment has been divided into two parts in this study the first part is the individual assessment of each model groups which describes the unique assessment derived from the bibliographic review however the reviewed literature reveals that these traditional models fail to grasp the full aspect of uncertain non stationary noisy and nonlinear data when compared to the complementary and hybrid model though each of them has their own strength allowing them efficiently working in the wq modelling and monitoring area thus to better understand the ai models a general appraisal has been prepared thus the second part of the valuation has been categorized into five sub section i it focuses on the disadvantages of each models leading to the next innovative modelling algorithm it also explains why there was and still is need of more advanced models research which will allow further research to fill the gaps pointed out in the review ii since the review research focused on river wq modelling thus all the rivers which have been studied around the world are mapped in a single figure which shows the most explored river even though the researches in river wq modelling has significantly amplified although the literature survey found that many of the river water sources are still unexplored worldwide especially african and australian continent this assessment allows researchers to focus on the new study area with unique environmental ecological hydrological and geological signature furthermore it gives the opportunity to test the new model in different scenarios and validates its performance iii the section pointed out the most considered output variables while these models performance is based on the input out selection it is evident that result is more optimistic when the relation between the input output is considered more minutely and tools like dimensionality reduction sensitivity analysis mutual information and extrapolation are employed to find the most sensitive input out association this allows the researchers working in the field of hydrology data science and computer modelling to work more on the consideration of the relationship and factors influencing the variables iv this section discusses the time step chosen by the reviewed papers revealing that many of them opted for longer time steps which may affect the time series analysis of wq larger time scale also limits the scope of visualization of seasonal and periodic variation which is may severely damn the decision making in case of emergency and disasters like flood and drought v the last part of the general assessment deals with the choice of performance metrics there are many performance metrics widely used however the selection of the most appropriate statistical criteria is very essential for proper judgement of the model thus this section gives information about the application of the most common techniques and the frequency of their preference in section 8 2 most explored river also points out another challenge the researchers are facing and continue to face the tremendous expansion of ai application is affecting the work and everyday life ai involvement in many industries including water and wastewater management and decision making policies sometimes makes the users reject it as these systems are inscrutable and biased thus there are countries which are still not implementing ai africa australia russia north america refer to fig 10 it is true that the ai system is needed to solve the complex problem but gaining users and decision maker trust is also essential to realise the full potential of ai technology providing more information on the system accuracy comparative assessment of the performance indices water quality indexing and system behaviour can increase model acceptability in real life application such information will give better feedback from the user which can be used for model improvement through feature engineering architectural adjustment parameter tuning research work on river wq modelling with ai is distributed over a wide domain and it is very much difficult to collect the whole range of wq which may also include heavy metals agricultural waste and chemicals immerging contaminants sediments industrial chemicals land use etc which is one of the limitations of the study thus the survey has been limited to the research studies who considered the most common and easily identifiable wq variables another limitation of the study is ever changing river wq and thus there will always need new models and testing them in a new environment there is much scope in the field of river water quality modelling and these challenges will keep the generation of new innovative ideas the next section presents the potential research and challenges which need to be addressed by forthcoming researchers 10 potential future research directions to get a better system lot of application of an expert system and decision support system has to be coupled together to overcome the barrier to achieve more such the system will also have to deal complexity uncertainty inconsistency imperfectness incompatibility etc stephanou and sage 1987 ai models have been continuously successfully and effectively implemented in river wq modelling studies as concluded by 209 reviewed research papers published in high index international journals from 2000 till 2020 ai models are combined tools of mathematics statistics and biological science they can overcome the individual weaknesses by behaving thinking and learning ai becomes machine learning when combined with learning human like behaviour can be called as ai but unless it automatically learns from data and improves it is not machine learning carbonell et al 1984 ai models have several advantages in solving complex problems of nonlinear river wq data they are reliable lets easy decision for policy makers easy and effective in the implementation and cost effective and can deal with large scale data however they need large labelled training datasets and suffer from limited capability and functionality various stages such as inputs architecture and training can be altered depending on the preferences of the researcher to achieve desired performance and outcome ai models can still be improved in river wq because wq concerns are increasing worldwide this paper is a glimpse of what has been done with one step forward and what may be done in the future here are several suggestions to achieve the goal a ai models are progressing massively to provide reliable and robust intelligence methodologies for solving environmental engineering problem theoretically thus the application must be practised as real life problem solutions b ai models are data extensive tools and can achieve high accuracy with a consistent regular and adequate amount of data if proper and competent monitoring stations are established which can provide continuous stable and accurate data worldwide c many study areas have problems with obtaining the data and several issues are difficult to overcome thus additional ai models that can overcome the problem of missing data and lack of continuous data should be designed d the issue of missing data and data unavailability specifically stations unreachable due to climatic condition can be overcome by utilising the recent advancement of technologies such as gis and remote sensing these technologies can be used often for resource management and environmental modelling issues the high resolution data from the satellite can be used for improved spatial river wq modelling e with a similar problem about data additional models should integrate the features of a black box model and white box models in another term the conjugal between the physiochemical mechanism happening in river systems must be considered and numerical approach must be used to predict river wq changes understanding the relationship between the wq and the mechanisms that influence each other can produce an improved result with fewer data inputs f different inputs and outputs are used in river wq analysis and few works with new variables given that every change around the study area may affect river wq future research studies must include additional variables such as population change seasonal runoff and amount of industrial influent and effluent the influences of these factors on one another should be established to provide a broad spectrum for understanding and identifying river pollutant sources and predicting possible sudden changes these studies will provide a good chance for water treatment plants to cope with emergencies g a new model that is designed and tested should be tested against the benchmarked models techniques and issues in river wq this kind of benchmarking technique will help researchers around the world find better solutions for real time crises already identified by other researchers such as data from arid areas semi arid areas flood prone zones and other diverse conditions where model competency can be checked for a scenario this method will develop robust and field applicable models to help solve real life river wq management issues h research data monitoring station data modelling information and benchmarked model application should be easily and freely available online to broaden the horizon of environmental research freedom for data access will provide a broad aspect of model performance based on information of benchmarked models and available data moreover researchers can evaluate their work easily and efficiently whilst producing models applicable to various environmental scenarios i few branch models are less explored in river wq assessments and need additional research such as ward nn hopfield nn dempster shaft theory knn dt and deep learning models these models have not been implemented in this field deep learning uses multilayer architecture can compute nonlinear input output mapping and learn through a general purpose learning technique sulaiman et al 2018 this method can understand and extract natural language and complex information achieve high accuracy provide an effective optimisation approach for end to end performance provide a fast and minimum need of tuning and use unsupervised learning lecun et al 2015 schmidhuber 2015 j attempts have been already made to create a hybrid model with high strength and power to deal with nonstationary random complex and vague data these efforts should be encouraged for the proposal of superior models in the near future tao et al 2018 various optimisers have been developed over the years and many remain unexplored in river wq such optimisers include bacterial foraging optimisation das et al 2009 amoeba based algorithm zhang et al 2013 artificial plant optimisation cui et al 2012 flower pollination algorithms yang 2012 grasshopper insect based algorithm saremi et al 2017 wasp insect based algorithm theraulaz 1991 fruitfly insect based algorithm xing and gao 2014 glow worm insect based algorithm krishnanand and ghose 2009 dragonfly insect based algorithm mirjalili 2016 shark optimisation hersovici et al 1998 whale optimisation mirjalili and lewis 2016 bean optimisation xiaoming zhang et al 2010a b dove bird based algorithm su et al 2009 eagle bird based algorithm yang and deb 2010 cuckoo search yang and suash deb 2009 bird mating askarzadeh and rezazadeh 2013 monkey animal based algorithm mucherino et al 2007 wolf animal based algorithm liu et al 2011 lion animal based algorithms yazdani and jolai 2016 artificial fish swarm algorithm li 2003 termite roth 2005 marriage in honey bees abbass 2001 bee collecting pollen algorithm lu and zhou 2008 krill herd gandomi and alavi 2012 grey wolf optimiser mirjalili et al 2014 earthworm wang et al 2018 salp swarm mirjalili et al 2017 nomadic people salih and alsewari 2019 sooty tern dhiman and kaur 2019 harris hawks heidari et al 2019 side blotched maciel et al 2020 and color hormony zaeimi and ghoddosian 2020 can be implemented in future studies for better visualisation the timeline is presented in fig 14 k many models such as rbf rnn pnn elm denfis efunn mars and regression models have been successfully applied for river wq assessment but never coupled with any bioinspired optimisation technique fig 14 presents the combined architecture of possible hybrid modelling using wq input output with ai models and ni algorithms for future research l regression models such as gpr dt rt mt glm and et are least explored in river wq studies they hold promise in classification and prediction competencies and close attention is needed to explore and enhance their performance their performance can be increased using optimisers as recommended earlier m close attention should be paid towards the architecture of the model such as the optimum number of layers weight and bias values data allocation for training testing and validation and method selection for model calibration n the performance of wavelet transformation with various ai models in river wq research has been considered for data pre processing to extract the underlying features and de noising time series it has been used in wq modelling but pre processing of temporal and spatial data utilised in river wq models need further research additionally w can also be evaluated against other ai models that can deal with nonlinear data such as grnn pnn denfis efunn fis narx mars enn dt rt and mt moreover these models must be comparatively studied to establish the extent of their success o the computational explosion is an issue yet not fully addressed by ai researchers the explosive increase in the knowledge growth leads to the need for the understanding of the interaction of the networks which are coordinating in a methodical fashion to solve the problem by equational discovery and symbolic regression technique this technique focuses on the structure identification parameter estimation system variables and decreases the discrepancies between simulated behaviour and observed system behaviour to find an optimal model in contrast to that ai models estimated the parameter value with fixed structure and losses the illustrate ability of the model thus needs additional implications tanevski et al 2020 thus with the increasing accessibility of data symbolic regression technique and artificial intelligence have to come together to better understand the internal networking of the model and on field data interaction to design more applicable model quantifying investigation and getting structural knowledge is the only redemption for an effective solution to the complex real life river pollution issues p increasing river pollution and its dangerous effect on life has ensured the need for environmentalist and hydrologist to work towards better solutions to overcome this life threatening disaster and a political issue beven 2016 they need to work on designing better assessing and predicting model additionally by the study of 209 papers which contain wq data ranges from 1968 to 2018 it is evident that river wq is subjected to change over time may get influence by various other variables there is a chance of emergence of new contaminants and other uncertainty which may follow with time this a limitation of river wq modelling which the scientist has to face since there is always a probability that a superior performing model may not perform very well next few years and new conditions thus continuous progress and testing have to be done to deal with river pollution and manage it well q after reviewing all the research paper it can be concluded that the process of contaminants mixing in rivers or natural streams is a complex and cause a synergistic reaction leading to change in the wq composition thus it should be considerated during the experimental process to include other variables such irregular velocities bed configuration sediment load and the dead zones kisi and yaseen 2019 11 abbreviation accuracy acc absolute mean prediction error ampe absolute average deviation aad absolute principle component score apcs absolute error ae absolute percentage error ape accuracy factor af adaptive boosting adaboost adaptive neuro fuzzy interference system anfis alkalinity al alkaike index aic aluminum al alternative fitness genetic algorithm afga ammonia nh3 ammonical nitrogen nh3 n analytical hierarchy process ahp anionic surfactant ais ant colony optimization acor arsenic as artificial neural network ann artificial bee colony abc artificial intelligence ai auto associative neural network aann auto regressive integrated moving average arima average absolute relative error aare average accuracy aa average information theoretic criterion aic average relative error are air temperature at back propagation neural network bpnn bat algorithm ba bayesian network bn bayesian regulization br biochemical oxygen demand bod5 bi carbonate hco3 blue green algae bga bod decay rate constant kb boosted regression trees brt bootstrapped wavelet neural network bwnn boron b calcium ca cadmium cd calcium sulphate caso4 carbon di oxide co2 canadian council of ministers of the environment ccme canonical correspondence analysis cca carbonate hardness ch cascaded fuzzy system cfs chaotic nonlinear dynamic algorithm cnda chemical oxygen demand cod chemical oxygen demand digested by potassium dichromate codcr chloride cl chloride sulphate clso4 chlorophyll α chl α chromium cr cladocera clad class precision pc classical neuro fuzzy cnf cluster analysis ca co active neuro fuzzy inference system canfis coefficient of efficiency ce coefficient of variation cv colored dissolved organic matter cdom continuous wavelet cw copepod cop crossover rates cr copper cu cyanide cn day of the year doy decision tree dt degree of agreement d delta percentage δ depth z determination coefficient coefficient correlation dc discrete wavelet dw discriminant analysis da dissolved inorganic nitrogen din differential evolution de differential evolution separate groups de sg differential evolution with global and local neighborhood based mutational operators degl dissolved oxygen do dynamic evolving neural fuzzy inference system denfis dynamic factor analysis dfa electrical conductivity ec escherichia coli e coli empirical orthogonal function eof ensemble empirical mode decomposition eemd ensemble neural network enn evaporation evap evolutionary algorithm ea evolutionary polynomial regression epr evolving clustering method ecm evolving fuzzy neural network efunn expectation maximization cluster emc extreme gradient boosting xgb extreme learning machine elm error rate er extreme randomized trees et error value ev forest land use factor f fluoride f factor analysis fa fat and oil f o fecal coliform fc feed forward back propagation ffbp feed forward neural network ffnn final predictor error fpe firefly algorithm ffa full complexity prediction square error fcpse fussy interference system fis fuzzy analytic hierarchy process fahp fuzzy clustering technique fct fuzzy c mean fcm fuzzy comprehensive evaluation fca fuzzy contingent evaluation fcv fuzzy multi attribute analysis fmaa fuzzy multi objective evaluation fmoe fuzzy sets theory fst fuzzy similarity measures fsm fuzzy synthetic evaluation fse fuzzy time series model ftsm fuzzy water pollution index fwpi gaussian cloud transformation gct gaussian process regression gpr gene expression programming gep general regression neural network grnn generalized least square model with cosine trend glscos genetic algorithm ga genetic programming gp geographic information system gis gradient boosting gb green algae ga grey relational method grm grid partition gp2 group method of data handling gmdh group method of data handling gmdh growing hierarchical gh hardness h habitat quality assessment hqa habitat modification score hms heat flux model hfm heavy metal hm hierarchical agglomerative cluster hac hierarchical clustering analysis hca hopfield neural network hnn humidity hs hybrid evolutionary algorithm hea hydrazine nh4 n improved fuzzy matter element evaluation method ifmem index of agreement ia inflow qin interactive fuzzy multi objective linear programming ifmolp iterative self organizing data analysis isodata iron fe irradiance irad kling gupta efficiency kge k nearest neighbors knn kling gupta efficiency kge latitude lat length l lead pb levenberg marquardt lm linear discriminant ld linear regression lr linear alkylbenzene sulphonate las location similarity index lsi longitude long macrophytes ma machine learning ml macrophytes index of river mir magnesium mg manganese mn magnesium sulphate mgso4 modified index of agreement m ia matthews correlation coefficient mcc mean absolute error mae macrophytes biological index of river ibmr mean error me mean absolute relative error mare mean absolute deviation mad mean absolute percentage error mape mean bias error mbe mean percentage error mpe mean prediction interval mpi mean relative error mre mean sea level pressure msp mean square relative error msre mean square error mse mercury hg methylene blue active substance mbas min max autocorrelation factor analysis mafa mineral oil m oil model tree mt modified response surface method mrsm monte carlo simulation mcs multi layer perceptron mlp multi linear regression mlr multi non linear regression mnlr multiple regression analysis mra multivariate adaptive regression spline mars multivariate linear regression model mlrm mutation rate mr naïve bayesian nb nash sutcliffe efficiency nse nash sutcliffe efficiency nse nash criterion nash nature inspired ni net ecosystem metabolism with system dynamic model nem sdm nitrogen n nitrate no3 nitrate nitrogen no3 n nitrification rate k1 nitrite no2 non dominated sorting genetic algorithm ii nsga ii nonlinear auto regression with exogenous input narx not applicable na optimally pruned op order series method osm organic nitrogen norg output weight optimization hidden weight optimization owo hwo oxygen o2 oxidation rate of nitrite k2 partial least square pls partial least square regression plsr particle swarm optimization pso pearson correlation coefficient r percentage of mean m persistence index cp permanganate index pi percent bias pbias persistence index cp petroleum pet phosphate po 4 potassium dichromate k2cr2o7 potassium permanganate kmno4 phosphate phosphorus po4 p phycocyanin pc1 physical process based model ppbm polynomial chaos expansions pce possibility measure based fuzzy support function machine pmf sfm potassium k precipitation ppre prediction accuracy ap prediction interval coverage probability picp principal factor analysis pfa probabilistic neural network psvm probabilistic probabilistic neural network pnn quadratic discriminant qd discharge q quantity of assimilated polluted water q1 quantity of water evaporation q2 quantity of water leaked to ground q3 quantity of water precipitation from runoff q4 radial basis function neural network rbfnn rainfall r pre reactive phosphorus preact recurrent neural network rnn recursive partitioning rp regression model rm regression tree rt regression value r value relative index of agreement r ia relative error re relative humidity rh relative error distribution red release from reservoir r1 residual chlorine clr re substitution error re river pollution index rpi river macrophytes nutrient index rmni root mean square error rmse root relative squared error rrse root mean square error proportional rmsep root mean square relative error rmsre rotated principal component analysis pca rotifera rot reduced order support vector machine rosvm runoff rf salinity sa secchi depth sd scatter index si sediment rating curve src sediment oxygen demand sod self organizing network based monitoring som short radiation rs shuffle complex evolution sce shuffled frog leap algorithm sfla silica si silicon oxide so2 simulated annealing sa single factor evaluation sfe single averaging ensemble sae simpson diversity index d sodium na sodium absorption ratio sar soil and water assessment tool swat spearman correlation sc spectral angle mapper sam spillage s standard error of prediction sep streptococcus strep subtractive clustering sc1 sulfide s2 sulfate so4 selenium se sum of squared error sse sunshine hour sh support function machine sfm support vectorclassification svc support vector machine svm support vector regression svr the daily average tav the daily max air temperature tmx the daily run off the declination of sun s the mean bias bias thermo tolerant coliform tf time delay neural network tdnn total dissolved solid tds total nitrogen n tot total coliform tc total organic carbon toc total phosphorus ptot total solid ts total suspended solid tss total volatile solid tvs transparency tr travel time tt turbidity tu ultraviolet uv urban land use factor u variable fuzzy evaluation model vfem variance inflation factor vif volatile hydroxyl benzene vhb volatile phenol v aroh volatile phenol vp volumetric efficiency ve volume error ve water quality wq water quality index wqi water temperature wt wavelet w wavelet basis function wbf wavelet de noising technique wdt wavelet neural network wnn ward neural network wnn weighted averaging ensemble wae willmott s index wi wind speed w1 zinc zn declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors acknowledge the funding support by the ton duc thang university also the authors would like to acknowledge their gratitude and appreciation to the cited relevant references of the current survey that are discussed the application of rive wq simulation 
5523,there has been an unsettling rise in the river contamination due to the climate change and anthropogenic activities last decades research has immensely focussed on river basin water quality wq prediction risk assessment and pollutant classification techniques to design more potent management policies and advanced early warning system the next challenge is dealing with water related data as they are problematic to handle owing to their nonlinearity nonstationary feature and vague properties due to the unpredictable natural changes interdependent relationship human interference and complexity artificial intelligence ai models have shown remarkable success and superiority to handle such data owing to their higher accuracy to deal with non linear data robustness reliability cost effectiveness problem solving capability decision making capability efficiency and effectiveness ai models are the perfect tools for river wq monitoring management sustainability and policymaking this research reports the state of the art of various ai models implemented for river wq simulation over the past two decades 2000 2020 correspondingly over 200 research articles are reviewed from the web of science journals the survey covers the model structure input variability performance metrics regional generalisation investigation and comprehensive assessments of ai models progress in river water quality research the increasing contaminants the lack of funding and the deficiency in data numerous variables and unique data time series pattern based on the geological area have increased the need for river wq monitoring and control even more hence this is highly emphasising the involvement of ai models development which can deal with missing data able to integrate the features of a black box model and white box models benchmarked model and automated early warning system are few of many points need more research despite extensive research on wq simulation using ai models shortcomings remain according to the current survey and several possible future research directions are proposed overall this survey provides a new milestone in water resource engineering on the ai model implementation innovation and transformation in surface wq modelling with many formidable problems in different blossoming area and objectives to be achieved in the future keywords river water quality state of the art literature assessment and evaluation artificial intelligence hybrid model 1 introduction 1 1 research background humankind is blessed with a stunning piece of art that is the environment the growing desire for comfort as time progresses has left us with toxic air barren land and poisoned water the propensity has brought the present condition with a need to examine quantify and treat what was initially in its purest form consequently the need for testing water was realised back in the 1960s and water pollution acts were implemented to stop the deterioration of natural water quality barry 1969 water sources are divided into surface water sources e g river lake reservoirs and coastal areas and groundwater sources e g infiltration galleries and springs rivers have been the most used water source on account of their accessibility and availability this situation has led to the growth of most civilisation near river banks mustafa et al 2017 viessman et al 1998 water quality wq is divided into biological hydro morphological and physiochemical quality tchobanoglous and schroeder 1985 in addition to other variables physiochemical wq variables are widely used for river wq modelling wan mohtar et al 2019 only a few physical and chemical properties have been initially considered but various chemicals that affect wq have been discovered later physical and chemical variables produce synergistic effects on wq along with several other environmental factors that may produce unpredictable wq results wilhm and dorris 1968 there are predominantly few water quality variables that have been typically used to assess river health include dissolved oxygen do biochemical oxygen demand bod solids nitrogen compounds water temperature wt chlorophyll a chl a electrical conductivity ec chemical oxygen demand cod and ph tchobanoglous and schroeder 1985 another frequently applied indicator is the water quality index wqi which is calculated by a complicated numerical formula using surplus time and may have inaccurate values the process includes using multiple wq variables for calculation and comparing them with the standard value for improved understanding of the non scientific community such as policymakers smith 1990 wqi categorises wq into classes such as good bad and worst depending on the standard set by the study area governing bodies the results are numerical but are presented in a simplified form fernández et al 2004 water quality research plays an important role in river wq assessment monitoring and management henceforward the number of scientific approaches towards accessing managing and understanding wq data has increased considerably 1 2 problem statement wq assessment and its interpretation can be difficult to explain because they are influenced by several environmental factors and human activities kamel et al 2013 this complexity has started a new geological period called anthropocene in which all earth system processes are altered by humans activities that influence wq can be population explosion urbanisation industrialisation irrigation and water related engineering projects meybeck 2003 a global level study considered geospatial drivers including catchment disturbance pollution water resource development and biotic factors by using digital river networks and marine systems to obtain collective threat indices this study showed that 80 of the world population lives in areas where water security threat may exceed 75 percentiles unsecure water indicates unhealthy and contaminated water and is the cause of water related health risks vorosmarty et al 2010 wq statistics have difficulty in managing the large amount of data chapman 1992 many studies have attempted to estimate the river wq pollution however wq sample gathering testing and data handling are time consuming and costly in terms of chemical equipment and manpower traditional approaches bring difficulty in water related projects and result in losses in economic value these situations affect the decision making and productivity of the monitoring programmes ongley 2000 a productive and cost effective methodology for wq estimation with effective and robust advanced approaches are required to achieve the goal and overcome the previous limitations wq data are essential in defining the characteristics of the source water regulations addressing water management issues investment decisions and dealing with pollution ongley 1996 water related data are difficult to design as a result of their nonlinearity nonstationary feature and vague properties due to the unpredictable natural changes interdependent relationship and human interference votruba 1988 as a result these data have noise and are poor in quality therefore reliable methodologies such as artificial intelligence ai models and their advanced tools are needed 1 3 research motivation ai models which are based on the learning process of the human brain were proposed as forecasting and predictive tools by mccarthy 1956 ai models are powerful tools in many fields such as robotics hydrology climatology and agriculture including water resources they are popular for their reliability cost effectiveness problem solving capability decision making capability efficiency and effectiveness bandyopadhyay et al 2007 ai models are based on machine learning ml techniques and greatly impact human lives at present and will in the future according to mitchell 1997 the impact of machine learning is certain to grow over the coming years as more and more data come online we develop more effective algorithms and underlying theories for machine learning the futility of hand coding increasingly complex systems becomes clear and human organizations themselves learn the value of capturing and using historical data in river wq related studies various issues must be addressed carefully for current researchers to discuss and understand what previous studies have accomplished many published review papers have reported the capacity of ai models in wq studies for instance the first review reported prediction of wq variables in water resource modelling maier and dandy 2000 the review studied the employment of artificial neural network ann models until 1998 including model background data utilisation training and learning information network architecture optimisers and other model details however this study is outdated for the present scenario chau 2006 summarised the major ai models contribution in assessing and predicting coastal water quality researches this study acknowledged the potential of different ai models such as knowledge based system genetic algorithm ga ann and fuzzy inference system fis for wq modelling however this study did not consider the river water researches solomatine and ostfeld 2008 wrote an overview of data driven models and evolutionary optimisation for river basin management the review reported various gaps and limitations the authors used two water sources namely bagmati river basin in nepal and lake kinneret the sea of galilee watershed to assess the models that can provide the result on short term forecasting and classification of hydrology related data and flood related data maps using wq data and hydrological data this study considered fewer models and lacks the advanced model information since it only studied researches published before 2008 nicklow et al 2010 reviewed the evolutionary algorithms eas in planning and managing water supply groundwater and wq variable identification systems raghavendra and deka 2014 reviewed the application of support vector machine svm models on groundwater quality in hydrology the study provided a brief idea of svm models and their hybrid version for modelling hydrological data in 2010 a review research highlighted in detail the methods used to develop ann models for river systems over the period of 1999 2007 the taxonomy of ann model development selected inputs data division and model structure were evaluated maier et al 2010 the authors in another study elaborated the issue addressing the challenges and future aspect of eas in solving water resource problems in the last 25 years the study reviewed algorithms and their improvements in water distribution research and groundwater and river basin management maier et al 2014 che osmi et al 2016 conducted researches on river wq data modelled with fuzzy based methods the study dealt with model architecture membership function operations and perspective of the integration of fuzzy with other models considering all the previous review researches chau 2006 maier et al 2010 maier and dandy 2000 solomatine and ostfeld 2008 which are dated back to 2000 2008 the advancement of ai research is very rapid and there is a need of review research such as the current survey which elaborates the current status and future prospect based on the previous progression three of the literature studies selected different water sources such as groundwater and coastal which also makes this study unique considered this review strictly selected the studies on river wq assessment additionally out of eight past review studies six of them is reporting only one model out of all ai models e g ea maier et al 2014 nicklow et al 2010 ann maier et al 2010 maier and dandy 2000 svm raghavendra and deka 2014 and fuzzy based models che osmi et al 2016 whereas this survey is considered all the popular ai models thus this review is up to date takes in account the last 20 years of research progress in the field of ai researches and especially in the river wq research which also the need of the hour and its novelty in recent decades ai models have gained the trust of the scientific community as a predictive and classification tool considerable researches have progressed on river wq prediction monitoring and management using various ai models with each progressive year new models have been developed thus a comprehensive milestone that facilitates the contemporary researchers to understand the features of these models and other variables needed for modelling as a result the forthcoming studies can evaluate and design the next generation models many reported studies are in a scattered form and various models with their distinctive capability have been illustrated by researchers thus the current review research tries to organise all the research findings into one survey reviewing various works of scientists worldwide reveals that this review is exclusive in its kind and such an in depth study of river wq modelling and assessment has not been done previously to the best knowledge of the authors the current study deals with ai models used for river wq modelling numerous models have been designed and applied over the years fig 1 shows the classes and subclasses of these models for the better understanding ai models have been divided into six subdivisions namely ann model kernel based model fuzzy based models complementary models hybrid models natural algorithms that combine architectures of more than one model or techniques and other metaheuristic models that come from different model classifications the first three classes are the conventional ai models and their improved versions frequently classified as the same by past researchers however complementary models take an account of the possible application of wavelet with the combination of other models thus they have been categorized in a separate group which allows the readers to better understand the comparative analysis of its performance and effectiveness to deal with river wq data when coupled with ai models the fifth category was created considering the studies which dealt with the nature inspired algorithm for river wq modelling as these algorithms behaviour are based on a similar concept which makes them suitable for the same class the last category was created only for the convenience of the readers and study analysis since the number of papers available is limited and will create no advantage in the present review thus it classifies all other metaheuristic models which don t fall under any previous categories however in future these other models can be further divided as per their architecture or concept when there is a considerable increase in the research articles which is also a present gap and future aspects 1 4 research objectives the research on river quality modelling has increased considerably over time the contributions of the present survey are summarised as follows i this review is summarised 209 research works based on ai models and their advanced applications growth over the past two decades 2000 2020 output data consideration most preferred study area performance indices prediction time step and comprehensive assessment ii this review is highlighted the capacity of the conventional models which are applied to the research field of river wq are taken over by hybrid and complementary ai models as the result of unprecedented attention from scholars the assessment of the researches will open a new path for researchers in the field of ai and soft computing with forthcoming ideas to fill the gaps presented iii the survey is emphasised the breaches in the implementation of ai models in river wq research and models that have not been tested with river wq data iv finally the survey reveals the advantages and weaknesses of each model need for additional exploration of various river areas issues with data collection and recommendation for future enhancements consequently this review paper presents a snapshot of the historical development of ai models over the years the in depth description of the ai model architecture and mathematical theory has not been detailed in this review however an appropriate references have been cited in each introductory part of the ai models class for the readers desiring further profound knowledge the rest of the review article is divided into nine sections sections 2 to 7 details the major classes of ai models as previously described in fig 1 along with the subsection that briefly describes each model with related citation the related bibliographic discussions are cited and reviewed and the sections are assessed section 8 presents a general assessment of the reviewed papers section 9 and 10 contain the conclusion and recommendation for future research possibilities of the impact of river wq changes and modelling 2 artificial neural network ann 2 1 conceptual background ann models are popular ai models due to their robustness and capability to deal with nonlinear data and solve complex problems ann model is the brainchild of mcculloch 1943 ann has been continuously progressing and its efficiency can be increased with the help of various data optimisation process training algorithms and by selecting appropriate input techniques ann consists of three layers namely input hidden and output layers the number of layer increases when the problem is complex thus the computational efforts also increase ann trains with the data provided using various training or learning algorithms the most popular ann learning algorithms are generalised regression neural network grnn antanasijević et al 2014 2013 radial basis function neural network rbfnn chen et al 1991 backpropagation bp levenberg marquardt lm bayesian regularization br gradient descent steepest descent gauss newton quick propagation and adaptive learning maier and dandy 1999 rumelhart et al 1988 samarasinghe 2006 a new version of ann model called extreme learning machine elm is recently gaining popularity due to its simple structured single hidden layer feed forward neural network ffnn it works as a linear in the parameter model and easily reaches global optima huang and chen 2007 huang et al 2015 another time series model that can handle nonlinear data is a dynamic neural network called nonlinear autoregressive with exogenous narx network it is a subclass of the recurrent neural network rnn it uses a gradient descending learning algorithm that makes it effective in learning this feature results in its fast network convergence with improved generalisation and memory retention diaconescu 2008 tsungnan lin et al 1996 the typical architecture of ann is depicted in fig 2 hameed et al 2017 ann can work efficiently because it can use an input significance approach that can determine the potential input for output variables diop et al 2018 ann can use a model based approach that constructs individual models for different inputs to determine the important one salih et al 2019 thus its time consumption is high by contrast the model free approach provides developers with choices or uses mutual information table 1 presents all the papers that reported the application of ann models 2 2 bibliographic review of ann models 2 2 1 comparative studies of ann with other ai models numerous studies have been conducted in the field of river wq using ann models jeong et al 2001 applied recurrent ann to predict chlorophyll a chl a using various inputs such as meteorological hydrological and environmental variables the model can produce a good result with 3 days of time lag input data four of the studies found that ann performs better than the regression models such as mlr and nonlinear regression models the results concluded that ann is an efficient accurate and economic tool for river wq modelling anmala and venkateshwarlu 2019 huang and foo 2002 mitrović et al 2019 olyaie and banejad 2011 four studies based on river wq modelling determined that bpnn and ffnn models which use feed forward and back propagation algorithm are capable in predicting long term trends and perform accurately and their effectiveness is high because their ability to grasp the nonlinear relationship between the input and output variables in compare to models like linear partial least square pls regression basant et al 2010 dogan et al 2009 najah et al 2011 yang et al 2008 khalil et al 2011 used ann ensemble ann enn and enn coupled with canonical correspondence analysis cca cca was used to manage the functional relationship and standardisation of variables cca enn was established as the improved model and can estimate the wq mean value for sites niroobakhsh 2012 performed a comparative study to assess the prediction capability of two ann models namely multi layer perceptron mlp and rbf the results showed that rbf can handle an immense number of data and can thus perform effectively in total dissolved solids tds prediction antanasijević et al 2013 studied the predictive competencies of grnn bpnn and rnn models and used a regression mlr model amongst the three ann models rnn is the most efficient and is also better than mlr rnn shows least over training and improved do prediction capability grbić et al 2013 demonstrated ann and mlr model performance for chl a prediction and found that the ann model is more effective in handling nonstationary variables when compared to mlr adaptive neuro fuzzy interference system anfis and ann models ann and mlr models use bp and lm algorithms ann model is the most efficient and accurate model for do prediction amongst the considered models sinha and saha 2015 used ann to establish a relationship between wqi and source network clustering analysis ca was conducted to identify the similarities feed forward bp and lm algorithms were used for the best performance of the ann model in another two studies ann model was used as a tool to predict the amount of tds in the river these algorithms are accurate and reliable for such prediction and current scenario naseh et al 2016 tarke et al 2016 ahmed 2017 determined that feed forward neural network ffnn and rbfnn produce satisfactory results for do prediction but ffnn is slightly better in overall performance another research addressed the issue by reducing the tenacious application of wq variables and satellite data modelling by using ai model bpnn was used for mapping and the results are surprisingly accurate and simpler than before another three studies used the same process to reduce the cost and timing of the project whilst ensuring easy interpretation of data easy for the decision body for improved management planning liu et al 2012 sharaf el din et al 2017 sharaf el din and zhang 2017 antanasijević et al 2019 applied ward neural network wnn system along with som as a tool to pre process the dataset to extract the important features of the data and create a simple process wnn model was used to split the data and had two parallel hidden layers for identifying a different part of wq data patterns thus this model is unique and increases the accuracy compared with grnn results suen and eheart 2003 considered two ann models namely bpnn and rbfnn which were modelled and compared to predict nitrate contamination the outcome from rbfnn is quicker than that from bpnn because the number of hidden layers is determined by the fuzzy min max clustering algorithm where bpnn applies a trial and error approach this model is robust and highly accurate but both present similar false negative frequency similarly the results of a study done by najah et al 2013 presented that the performance of rbfnn is more accurate and faster than that of the linear regression model lrm and multi layer perceptron mlp in wq assessment rbfnn and ffnn were used in a study to find the do with the help of input data as bod and cod as they can influence the do variation piotrowski et al 2015 performed an extensive model assessment using ann fuzzy wavelet and instance based model that is k nearest neighbours knn the wt modelling results showed that each model is unique depending on the training algorithm optimisation and data sources ann performs better but the authors suggested that any new model must be assessed using various criteria to establish its performance efficiency heddam 2016a studied rbfnn and mlp techniques for do modelling and both models were able to successfully predict the do at 72 hrs ahead of time however the reliability of the forecasting reduced with increase in time step ahead another model grnn is gaining popularity because of its good performance thus three different studies compared it with mlr mlp rbfnn bpnn and rnn for wq modelling the results show that grnn performance is accurate efficient and faster as it doesn t need iterative training and overtraining chances are less csábrági et al 2017 2016 heddam 2014a dezfooli et al 2018 studied svm knn and probabilistic neural network pnn as wq models and established the effect of each input variable using the trial and error method pnn is the best model and performs well when few variables are omitted knn works well with all variables included and svm performs better with fewest variables asadollahfardi et al 2018 applied autoregressive integrated moving average arima box jenkins time series and mlp model for tds estimation mlp used 10 hidden layers lm as an optimisation algorithm with tansig transfer function which resulted in a better and more reliable model than the others abba et al 2018 simultaneously studied mlr ann and anfis models to predict do the results showed that the performance of ann is superior to those of anfis and mlr models as they suffered from the drawbacks of over estimation and under estimation respectively 2 2 2 studies incorporated with various input output selection techniques bowden et al 2005 enhanced the grnn model performance by using mutual information to characterise the important input and output wq variables som to reduce the dimensionality of inputs and ga to establish a relationship between them zali et al 2011 identified the relationship of wq variables using sensitivity analysis technique on inputs considered in the research with the classification of pollution sources ann successfully correlates and finds the pollution problems in the study area that is agricultural runoff and animal farm wastage similarly nasir 2011 used sensitivity input analysis which is a model based technique it was used to identify the effective input output relationship and eliminate the rest for ensuring the effectiveness of the ann model prediction for predicting wqi gazzaz et al 2012 reduced the massive quantity of data using principal factor analysis pfa to identify variables affecting wq in the study area mlp with ann model was used to construct the relationship and the result is fast and accurate because it can use achieved data to create a model that can be used for direct calculation of the river wq from raw data a combined model was introduced by chu et al 2013 where hopfield neural network hnn was used as a classifier modelling tool and factor analysis fa were used together for classification and dimensionality reduction respectively the combination model can overcome overfitting caused by wq inputs and performs better than other evaluation models rahim and ahmad 2013 used cca to reduce input variables with least or no predictive utility in the creation of the ann model for bod prediction which increased the computational cost and modelling accuracy wq estimation comes with uncertainty and very complex model design and was addressed by jiang et al 2013 using monte carlo simulation mcs with ann to reduce time and cost without compromising the accuracy mcs helps produce improved model wq variables including input and output along with possibility and numerical distribution but needs high computation labour similar to previous research antanasijević et al 2014 used mcs to address uncertainty they also used two methods for input selection namely a model free approach with correlation analysis and model based approach with ga to obtain the best result when incorporated with grnn these combined techniques are effective and produce enhanced do prediction results šiljić tomić et al 2018a focused on interpolation and extrapolation of the ann model by using pnn with emphasis on the right data selection for the learning process to create the number of possible models and select the optimum competent model the results of extrapolation are unaffected by less substantial inputs but may be biased yet do modelling results were good the same researchers used box behnken design for optimisation and multi filter approach for input correlation which was then modelled with ann and found the coupled technique is effective in do prediction šiljić tomić et al 2018b voza and vuković 2018 studied two analysis techniques namely clustering and discriminant analysis da to reduce the initial dataset and isolate the main source of pollutants this screening increases the efficiency of the ann model which in turn can provide a coherent and reliable wq management strategy chen et al 2009 used correlation analysis and quadratic polynomial stepwise regression analyses for selecting appropriate input to obtain improved results during bpnn modelling the results are good fast easy to manage and can be useful for river and agricultural water management chang et al 2015 conducted modelling using dynamic ann coupled with gamma test to establish a spatiotemporal relationship and select the combination of best fitted inputs by evaluating the noise the model was accompanied by narx ann and anfis models gamma test helped in the input selection and improved prediction performance the model can find the water pollutant source and produce the most accurate results villas boas et al 2017 evaluated the performance of auto associative nn coupled with nonlinear principal component analysis pca to address the issue of budget difficulties and inadequate wq network design the nonlinear pca can understand the wq relationship and perform and address the issues another paper reported the use of bpnn modelling along with correlation analysis for normalisation similar to previous works pca was added in place of polynomial analysis to reduce the correlation of neurons the results can cope with the missing data and decrease the monitoring index and can thus be used for wq management tools zhang et al 2010a b li et al 2019 used d s evidence theory dempster shafer to deal with wq data uncertainty by data fusion and improve data performance by combining it with rnn the results are promising since they are comparable to those of support vector regression svr bpnn and conventional rnn models isiyaka et al 2019 investigated wq by using the ann model and multivariate statistical tools hierarchical agglomerative cluster hac analysis helped in clustering the monitoring site in two and pca was applied pollution source identification such as anthropogenic surface runoff and rock weathering in which rock weather was the highest contributor of pollution a sensitivity test was applied to recognise the most sensitive variable affected by pollution all the techniques coupled with ann model increased the overall performance 2 2 3 modelling with distinctive indicators kim and seo 2015 used chl a as an indicator to assess algal growth by integrating ann and sensitivity analysis to find the most sensitive input to the required output the authors also used clustering and partitioning to balance training which led to highly accurate results using the ann model heddam 2016b used phycocyanin as an indicator for phytoplankton and algal growth mlp ann and mlr models were used for modelling and lm was used for optimisation mlp model performs well during training validation testing and prediction two research studies selected tds as the output variables since tds can be used as an indicator of salinity salt deposits in the study area as often present due to the geographical location on of the study applied time delay nn tdnn and rbf models whose prediction accuracy was high and other modelled the wq variables with mlp and rnn in which mlp obtained results faster than rnn but rnn applicability and accurate was more than mlp asadollahfardi et al 2011 gholamreza et al 2016 wq can be assessed using indicators such as macrophytes which were used by gebler et al 2017 as an indicator for the testing of the extent of river contamination this study explored the possibility of using plants as bio indicators for wq monitoring and management similar output variables namely macrophytes were taken as indicators in 2018 but the relative relation was established by considering water pollutants hydro morphological changes and physical chemical and biological variables the authors suggested that the relationship must be observed in more than one aspect such as environmental and ecological to increase model accuracy gebler et al 2018 kim et al 2019 used chl a as an indicator to predict algal bloom using the ann model in their study the results are helpful for environmental management and assessing other factors affecting the algal changing aspects during the sensitivity analysis nitrogen shows the most impact on algal bloom variation in the study area 2 2 4 models addressing the issue of missing data and cost effective approaches diamantopoulou et al 2008 examined the ann model and estimated the missing data by using the available relevant wq variables a similar outcome was achieved by amiri and nakane 2009 where data were taken using geographic information system gis the lack of meticulous data was dealt by randomisation of the data to produce accurate results using ann model singh et al 2009 tested the bpnn model for do and bod computation the model is able to capture longterm trends of wq variation both in time and space thus the study concluded that it can be used as a predictive tool for assessing river health sahoo et al 2009 successfully predicted wt even with a lack of detailed data the time delay approach was used to adjust nonlinear data for overcoming the predicament and mutual information limited the time delay up to 3 days ga was used for optimisation and data were fed to a chaotic nonlinear dynamic algorithm cnda and bpnn model the results showed that the bpnn model produces the best results a related study of heydari et al 2013 solved the problem of missing data and created the ann model using available data of other wq variables then the backpropagation mlp model was used for the network architecture and produced accurate results nhantumbo et al 2018 addressed the same issue of cost and lack of details of variables using the ann model and comparing with the physical process based model ppbm with lm optimiser the physical process based model is satisfactory when calibrated and can be used along with the ann model to obtain the best possible result the data unavailability can be sometimes due to an inactive monitoring station to address this point mitrović et al 2019 used ann model for virtual wq monitoring and mcs algorithm for data sensitivity analysis mcs with the ann model is successful for complex multi output targets salami and ehteshami 2015 selected inputs such as wt ph and ec because these experiments are easy and low cost for do prediction using ffnn along with lm and transign for the learning process the study concluded that ann model is a good tool for missing data finding the relationship between data variables and overcoming problems from data collection and experimentation peña guzmán et al 2019 used ann model for handling wq prediction for a large population which is difficult costly and time consuming with the traditional methods the results are satisfactory and concluded that ann model can be used for similar conditions chebud et al 2012 used the ann model with gis to quantify and establish a relationship between the inputs and minimise project cost gis was used for landscape analysis and dynamic monitoring and produces good quality images by removing haziness and cloud effect the model can reduce uncertainty and manage the complexity of the relationship between wq variables iglesias et al 2014 minimised the cost and time of physiochemical testing by integrating ann the study used turbidity as a wq indicator to reduce excessive modelling time and the results are satisfactory sarkar and pandey 2015 proposed ann model for predicting do and suggested that ann can be used as an active tool for river wq monitoring for developing countries the only consideration will be consistent data and the same controlling factors for training and testing datasets gazzaz et al 2015 correlated and used wqi as an indicator and applied ann modelling during the research wqi was influenced by mining rubber industries forestry urbanisation and agricultural activities chang et al 2016 compared mlr static type bpnn dynamic type narx and subclass of rnn models gamma test was used to estimate the importance and interdependence of the input variables and the noise narx model can predict the spatiotemporal features in the inputs outperform other models and can perform effectively under missing data and costly wq variables alves et al 2018 proposed replacing the older method of wq analysis with uv spectrophotometry with ann modelling tool to decrease the time need of costly infrastructures and other expenses of the project the study introduced a simple and fast way to monitor wq four research study applied elm and modified elm models i e optimally pruned extreme learning machine op elm radial basis elm online sequential elm and compared their performance with mlp mlr lr bpnn and anfis models op elm model demonstrates higher predictable performance when compared to mlp and could predict wq in advance from several hours to 7 days with improved accuracy elm models outperform others as the result of its use of a single hidden layer feed forward network can learn faster than other ann models and has lesser number of epochs it is superior in prediction accuracy speed and in generalisation thus the model is easy to apply elm can be applied using different activation functions such as sigmoidal sine rbf hard line and triangular function in which sigmoidal and rbf has the highest success among all thus the designer can opt for the best design as per the feasibility of the project heddam 2016c heddam and kisi 2017 yi et al 2018 zhu et al 2019c 2 3 model assessment assessment of the various literature surveys on ann modelling for river wq reveals the following matters the popularity of the ann model is due to the flexibility in its implementation in river wq the ann model can process complex nonlinear nonstationary and vague data of river wq without assumptions between input and output variables thus ann models are categorised as a black box model which uses the numerical approach without understanding the mechanism juditsky et al 1995 thus this model can be applied easily ann models have been proven excellent predictive tools by the literature considered in this study for predicting the change in river wq in advance which is helpful for decision makers and policymakers around the world as shown in fig 3 the pie chart presents various ann models compares to the applied models in the 76 review papers and concludes that ann performance is the highest the traditional ann model has been applied in 30 of the studies and remains the most popular with the development in the ann model architecture the new generation of ann models such as grnn 4 pnn 1 elm 1 and narx 1 models continuously try to take the place of the previous ones such as ann 30 bpnn 13 and mlp 9 models these new models are gaining popularity in the last few years few hybrid models such as rbfnn 4 and rnn 3 models have been studied along with the traditional models and has shown promising performance fig 3 illustrates a few models such as mlr 9 anfis 4 and other ai models 13 used for comparison against ann models ann models perform better when coupled with various dimensionality reduction tools e g pca cca som pfa and fa and clustering tools e g ca da and ga chen et al 2009 khalil et al 2011 sinha and saha 2015 voza and vuković 2018 the efficiency and accuracy of the results can be increased because of the enhanced understanding of function relation identifying the similarities decreasing the huge input data into a manageable amount and standardising the data similarly time and cost can be decreased but quality can be increased using satellite and integration tool coupled with the ann model such as som gis satellite data modelling and remote sensing these tools are also able to get the most important features from data resulting in increased efficiency and performance ahmed 2017 antanasijević et al 2019 diamantopoulou et al 2008 sharaf el din et al 2017 sharaf el din and zhang 2017 the literature reveals that many comparative studies have been done using conventional ann and other modified versions of the ann model different models of ann show good results in varying scenarios and advantages over one another out of 74 studies 30 of the researchers have successfully used conventional ann and most of them have found that ann is better than most models such as anfis mlr wavelet and knn models this popularity is subjected to ann model flexibility computationally economical reliable consistent predictability and capability to handle nonlinearity few examples supporting the efficiency of traditional ann model anmala and venkateshwarlu 2019 banejad and ehsan 2011 grbić et al 2013 huang and foo 2002 the second most popular model is bpnn which uses the bp algorithm along with lm algorithm lm is the most famous training algorithm and finds optimum results in a minimisation problem this feature gives the model high stability and efficiency during the learning process gorashi and abdullah 2012 even though rnn model has been implemented less compared with other popular ann models but has the aptitude to achieve the least over training with good prediction capability antanasijević et al 2013 asadollahfardi et al 2011 grnn model is fast in data processing as it does not require an iterative training process thus this model can deal with large data this condition is common in wq assessment and predictions which makes it more suitable for handling wq data cigizoglu and alp 2006 enhancement tools of multiple input variables can be applied with the ann model to increase the efficiency of the model selection of the significant input attributes is essential because excessive input may cause overtraining introduces extra local minima and compromises the exact meaning of the input output relationship for input selection a model free approach and model based approach can be used antanasijević et al 2014 mutual information and multi filter approach for variable characterisation can be helpful considering they do not depend on model performance and use nonlinear statistical dependence to measure and determine inputs and thus are called model free approach bowden et al 2005 methods such as sensitivity and quadratic polynomial stepwise regression analyses can be used in river wq models to identify the most influential inputs over the outputs and eliminate the rest chen et al 2009 nasir 2011 another method of extrapolation can be used in data selection considering its ability to neglects the variables with least influence šiljić tomić et al 2018a various ann models in river wq modelling use indicator outputs to assess other pollutants for instance kim and seo 2015 used chlorophyll as an indicator for algal growth in the river heddam 2016a b c used phycocyanin as the phytoplankton and algal growth indicator and gebler et al 2017 used macrophytes for pollutant indication such studies are useful when collecting specific water samples is difficult due to unavailability of required fund manpower or risk in reaching the specific area for data collection the indicators can help fill the gap in those studies and achieve the goal of river health assessment ann models reduce the cost of the project and can deal with missing data and insufficient meticulous data using randomisation time delay mutual information and virtual wq modelling amiri and nakane 2009 mitrović et al 2019 sahoo et al 2009 they address the issue faced by many projects where the overall modelling monitoring and assessment suffer due to insufficient fund and inadequate data specifically in developing countries where ann models can be an economic solution several new models of ann with good potential in the area or river wq such as elm coupled with optimally prune method can predict wq in advance by many days similarly elm can process data in high speed has high accuracy and good generalisation capability by achieving the least training error and the smallest norm of output weight and performs fast due to less number of epochs heddam 2016c zhu et al 2019c this model has universal approximation capacity and improves overfitting problem by random feature mapping approach the simple design and the learning without hidden layer tuning make elm applicable to wq modelling huang et al 2015 in many cases including saline water elm and conventional ann has successfully predicted wq several hours ahead of time alizadeh et al 2018 another model known as narx can deal with missing data noise and nonlinear inputs chang et al 2016 wnn with som can find import data simplify a process by using data splitting and apply parallel hidden layer technique which makes it unique antanasijević et al 2019 least explored models can be implemented in the river wq modelling combined with other ai models to achieve superior model performance furthermore the challenges regarding the uniqueness of each study area seasonal variation and other abnormalities common in wq data must be assessed data is normally split into two training set and validation set generally ann models are not able to extrapolate beyond the range of training data which leads to poor prediction values and thus it becomes hard to get good results with small data set to solve the problem holdout method synthetic testing data trial method and cross validation methods have been applied to improve the generalization of the model maier and dandy 2001 master 1993 the most popular technique is cross validation technique which splits the data into three training testing and validation which helps in regulate when the training has to be dismissed maier and dandy 2000 but unfortunately very less thought has been given over the issue in the recent research considering wq data may present itself with the issue of unavailability of uniform long term data as an example of these two research where data availability was one year monthly data amiri and nakane 2009 chang et al 2001 3 fuzzy logic based modelling strategy 3 1 conceptual background fuzzy logic was developed to deal with uncertainty imprecision and vagueness zadeh 1965 introduced a fuzzy set as the class with defined criteria of membership the fuzzy set was established with the idea of inclusion blending balance and relation a fuzzy set consists of a membership function a discourse and a membership value each fuzzy set is defined by a fuzzy membership function which allocates a membership value to every conceivable input with two types of rules antecedents if and consequents then the membership value is between 0 and 1 where 0 represents absolute non membership and 1 represents full membership the consideration of the rules is depended upon the type of interference systems such as mamdani sugeno tsumoto and kang mamdani and assilian 1975 sugeno and kang 1988 takagi and sugeno 1985 the number of fuzzy rules needed for inputs is depended on the complexity of the real system and hence the number of rules increases with the complexity fis is able to better understand the relationship between the variables and then interpreted them in simple language it has been considered as grey box instead of black box model lindskog 1997 the architecture of adaptive network based fuzzy inference system presented by jang 1993 uses the hybrid learning process with input output mapping and has functional blocks as a rule base a database a decision making unit a fuzzification interface and a defuzzification interface anfis model has the advantage over ann models in adaptive filtering adaptive signal processing such as identification inverse coding and noise cancelling fuzzy rules are determined by three identification methods namely grid partition gp2 subtractive clustering sc and fuzzy c mean fcm clustering jang 1996 the typical architecture of the five layer anfis has been shown in fig 4 yaseen et al 2018a zhu et al 2019b concluded that the anfis model is a flexible ai model that can identify complexity and nonlinearity between variables another popular type of fis model is dynamic evolving neural fuzzy inference system denfis which can learn online and offline denfis advances through incremental hybrid learning and adds new inputs new classes and fuzzy rules thus it is superior to mlp anfis and evolving fuzzy neural network efunn wright 1991a b fis has been successfully applied for river wq for prediction assessment and classification all these fis applications have been reported in studies related to river wq tables 2a and 2b classifies fis model applications into a predictive and b classification models 3 2 bibliographic review of fuzzy based models 3 2 1 predictive models fis has been applied mostly as a classification tool however in any case it has been applied to compare with existing models such as pnn bn and grey relation method it followed the modelling pattern of fuzzification membership selection rule determination and defuzzification fis was used with water pollution index to incorporate and administer information e g individual knowledge and experience and qualitative environmental variables fis shows the good result when coupled with mcs or cascade type fis is applied which increases accuracy and speed li et al 2016a b mahapatra et al 2011 nikoo et al 2011 nirmala et al 2015 one of the most popular implemented models of fuzzy is anfis which proved to be a better model than pnn fis and mlp in five different studies anfis performance is good accurate and quicker than mlp and pnn models as these model cannot produce reliable solution due to the nonlinear characteristic of the wq variables and fis takes longer in data interpretation moreover this model is economic than laboratory analysis and can deal with a large amount of data data normalisation correlation and regression analyses and modelling conversion inverse transformation were applied to find important input variables which increased the performance many folds ahmed et al 2017 houari et al 2019 mahmoodabadi and rezaei arshad 2018 najah et al 2014 yan et al 2010 deng et al 2015 compared gaussian cloud transformation fuzzy time series gct fts arima rbfnn nonlinear auto regression nar svm order series method osm and ann gt gaussian transformation models the study aimed to develop multifactor wq time series where gaussian transformation was applied to historical data and multifactor fts model was used on two different time period datasets the new model can perform soft partitioning of uncertain data decrease noise and construct improved quality training data thus adaptive expectation model was applied to enhance the performance tiwari et al 2018 incorporated fcm and sc techniques which are powerful tools for multidimensional wq data analysis and were clustered with anfis to verify their predicting and classifying capabilities sc is more accurate than fcm technique thus it was used for sensitivity analysis for better understanding the impact of the input variables on the output yaseen et al 2018c used sc fcm and gp2 method to find the most effective predictive model the result shows that sc is the most effective model then fcm and gp2 respectively the first two models are less complex robust and consume less time in wqi prediction zhu et al 2019b performed similar modelling combination of anfis with three identification methods i e sc fcm gp and different functions like genfis 1 2 and 3 and mlp model mlp performs better but inaccuracy is less in fcm anfis and gp anfis models as the models can well manage input data and thus performs better an integrated model for river wq was introduced by heddam 2014b as denfis it is based on evolving clustering method ecm was used for do prediction and the results were compared with those of mlr and mlp models online based denfis outperforms other models with high accuracy heddam 2017 applied an evolving fuzzy neural network efunn model and compared its performance with that of the mlr model the result is highly accurate when efunn model is used thus the model is a good alternative for do prediction chen et al 2019 experimented on a hybrid model called possibility measured based fuzzy support function machine pmfsfm to overcome the shortcoming of the individual methods the hybrid model is accurate considers the fuzziness of wq variables and is less time consuming under few dimensions 3 2 2 classification models wq classification has been the primary and initial goal of many researchers chang et al 2001 used fuzzy synthetic evaluation fse approach in achieving this goal using the emerging technique of ai techniques fse can deal with the uncertainties of wq and lack of the boundary of wq and water to be utilised it is also more relevant than other techniques in this previous study simple fuzzy classification fuzzy information intensity and defuzzification were applied to the wq data to interpret the data with high accuracy ning and chang 2004 developed a fuzzy multi objective evaluation fmo e model to deal with a long standing arbitrary situation wq analysis might increase the level of monitoring for reasonable utilisation of water at each location gis was used as the data retriever and an optimiser the model can handle multiple objectives with a pragmatic approach which increases the success of screening selecting and sequencing the optimal expansion substitutes in another study interactive fmoe was utilised by lee and chang 2005 for efficient wq management considering financially viable factors the model can balance the economic and environmental factors to achieve high wq model performance which in turn increases the options for decision makers chen et al 2005 applied the fuzzy contingent valuation fcv method to improve the river wq by providing supportive information for cost effective analysis which can improve the management plan similarly nasiri et al 2007 applied fuzzy multiple attribute fma decision support expert this method is suitable for comprehensive data investigation and easy to assess and can evaluate wq effectively the model helps classify the wq and improve the administration plan singh et al 2007 explored the use of fmo lp linear programming for wq evaluation for different disposal location the model is flexible and enables water related policies to be managed easily and cost efficiently huang et al 2010 classified river wq according to the pollution zones and examined wq features pollution source and change according to the sources these questions were solved efficiently using statistical analysis such as fuzzy comprehensive analysis fca and factor analysis fa scannapieco et al 2012 applied fuzzy logic for wq assessment and added mann kendall test to analyse the trends when sampling regularity was decreased the classification was based on the pollution level of macro indicators and extended biotic index the study also considers only 5 membership functions to void crossing of more than two classes this model allows an improved understanding of the limits of the wq variables and thus increases the accuracy of the evaluation fis model has been successfully integrated for river assessment for estimating the river health and evaluating the need for water treatment in four studies the model has shown good accuracy flexibility to develop an enhanced classification ability to deal with the nonlinear input variables and classify river wq in natural language thus the model helps decision making more convenient babaei et al 2011 mourhir et al 2014 ocampo duque et al 2006 raman et al 2009 liu and zou 2012 examined the improved fuzzy matter element evaluation method by using the coefficient of variation to determine the weight and normal membership degree the new method is more scientific inclusive and effective than traditional calculating super scale method by avoiding abnormal values during the wq modelling angulo et al 2012 used fuzzy logic to assess the anthropogenic effect on river wq variables fis model can detect the surges of wastewater discharge changes due to eutrophication in the river risk on fish growth and develop a cause and effect relationship ocampo duque et al 2013 hybridised fis as a probabilistic fuzzy hybrid model and added mcs to handle imprecise and vague input data the model can identify the water pollution source and flexibly classify them into natural language thus can be used for wq indexing singh et al 2015 applied fuzzy analytical hierarchy process f ahp to evaluate river health on the basis of chang s extension analysis the method is easy and effective and can be applied to obtain priority weight the model is effective and improves water treatment plans and projects in another study the improved fuzzy matter element evaluation method was used by zhang et al 2019 along with the construction of pressure state response model for river health which is based on the relationship of the variables and urban river health index the model can solve incompatible complex problems related to wq and asses the multi index as urban wqi deng et al 2015 extensively compared the hybrid fuzzy time series fts model with arima rbfnn nar svm ann gct and osm models fts used heuristic gct algorithm and gaussian cloud algorithm the model can reduce noise by calculating the length of the periodicity and improve the prediction performance considerably when compared with other models for wq management singh et al 2019 proposed a fuzzy based model along with the gis model which is a geographical regression method the model can manage the vagueness of the data and index the wq variables is considerably comprehensive form and track the changes in wq this information can help decision makers to develop improved water management and monitoring policies lu et al 2010 utilised fse model for river wq assessment by incorporating entropy method and the results are comparable to those of the conventional fse performance the combined technique is effective as the entropy method can simplify the calculation process by determining the weight of the assessment constraints fuzzy wqi was generated in the study fuzzy wqi can interpret the uncertainty and vagueness of wq better than the normal wq model this way allows decision makers to interpret and manage water associated projects effectively xu et al 2012 examined fca coupled with ca and seasonal kendall test fca classifies the wq data into various quality levels whereas kendall test classifies them into different periods and identifies the change in the wq which makes it an excellent wq classification model wang et al 2014 designed a fuzzy evaluation model by integrating fuzzy binary comparison method and variable fuzzy sets this model uses eigenvector of level h and thus increases the wq assessment performance to a higher level by using developing interval scale rather than point scale liou et al 2003 explored the use of fuzzy set theory for data condensation using wq indicators the authors also applied the fuzzy c mean approach for assessment the model enhances the freedom of the decision makers this method can evaluate different scenarios and can present an enhanced assessment lee and chang 2005 implemented pca and fuzzy pca to manage compress and extract a large amount of wq data they considerably reduced the shortcomings such as sensitivity to outlines missing data and managing poorly distributed data by adding fuzzy with pca fpca results are sharper than those of normal pca wang et al 2008 coupled fse with pca this method helps in the correlation of variables and thus contributes to an improved assessment by eliminating the less sensitive variables the results are satisfactory and more efficient and considerably easier to perform than those of the typical pca karamouz et al 2009 applied fuzzy clustering for classification kriging method for regionalising spatiotemporal changes ahp for selection of suitable sampling station entropy theory for sample frequency calculation and ga optimisation various combinations of each method were used for classification river monitoring station selection wq variable selection and standardisation the two models can achieve the desired objective of finding potential monitoring station and can therefore be helpful in river wq monitoring mouton et al 2009 compared an expert knowledge based method i e hill climbing algorithm and a data driven model i e fuzzy rule based modelling for wq modelling fuzzy sets were optimised by nearest ascent hill climbing algorithm however data driven models outperform all others they also provide a suitable habitat for modellers in a similar study alias et al 2009 applied fuzzy ahp and compared it with the conventional techniques the combined multi criteria technique was used by reason of its flexibility applicability simplified use and capability to create wqi this model can manage the vagueness of the data and rank results as fuzzy wqi compared with wqi models 3 3 model assessment an assessment of the various studies on fuzzy based modelling of river wq shows the following all the scrutinised papers based on fuzzy models take the second place and anfis is the top related model since it has the advantages of ann and fis models anfis can manage nonlinearity uncertainty and fuzziness related to river wq anfis has several advantages in signal identification inverse coding and noise cancelling anfis produces enhanced results when data are normalised and reduced ahmed et al 2017 most studies use either one or a combination of multidimensional data analysis method in anfis namely gp sc and fcm clustering however sc is a better tool than the others in handling river wq classification tiwari et al 2018 yaseen et al 2018a b c d anfis model has shown good performance in handling river quality data as it has two types of parameter linear and non linear which can be attuned accordingly through the training stage jang 1993 along with the member function plays a vital role and right choice leads to the best optimization of parameters and hence results in higher accuracy jang 1996 another deciding factor for designing a good anfis model is the identification method applied for splitting the input space popular techniques applied are grid partition subtractive clustering and fuzzy c means clustering with various function such as genfis 1 2 and 3 jang et al 1997 therefore anfis can perform well with non linear data along with proper selective parameters decided by the designer few models such as denfis and efunn models are introduced recently for river water modelling they perform well in managing river wq however the considered comparative models are not against the basic benchmarked models and other popularly used models fts with gaussian transformation can decrease noise construct enhanced training data and apply soft partitioning this method is superior to arima rbfnn nar svm ann and osm models deng et al 2015 fis fse fmoe and fmolp approaches can deal with wq uncertainties and are flexible in creating fuzzy rules classifying them into classes as bad average or good according to criteria interpreting the skewed information and understanding the relationship between input variables fmoe model has been used to identify the monitoring station and increase the success of screening selecting and sequencing the optimal expansion substitutes ning and chang 2004 all these tools can efficiently classify river wq and help monitor and manage the river system to create improved monitoring projects various modified and hybrid versions of fuzzy set rules are available but each can handle river wq and create fuzzy wqi in addition to that they coupled with pca they can extract large amounts of data outgrow the problem of outliners handle missing data and poorly scattered data and remove less related data lee and chang 2005 wang et al 2008 fuzzy based model is able to produce a high level result and easily incorporates natural language prior knowledge to the model this allows the parameter estimation algorithm to allocate a practical preliminary value which decreases the chance of getting unnecessary local minima another advantage is that the ability of extrapolation which can be used for analysis and revealing new information from the data lindskog 1997 the fuzzy rule based model describes the input output relation more realistically and has physical interpretation which has allowed many researchers in wq research to choose fis model rather than ann models ocampo duque et al 2006 raman et al 2009 fuzzy models are able to analyse and conclude from the given data about the behaviour of a complex system without prior specification of a functional structure in comparison to other black box models jacquin and shamseldin 2009 nevertheless the ability to establish a relationship between input output variable becomes its limitation when too many input variables are there resulting to a number of rules and a complex system which is also known as the curse of dimensionality introduced by bellman 1966 thus calibration become difficult 4 kernel based ai models 4 1 conceptual background the concept of non separable data in support vector network was founded in 1995 this type of learning machine uses nonlinear input mapping to a very high dimensional space and ensures high generalisation svm depends on the so called large margin factor and built based on the structural risk minimization principle svm can produce excellent accuracy compared with linear knn and nn classifier because it does not include knowledge svm comprises regularisation kernel function and regression model complexity thus it is known as a kernel model cortes and vapnik 1995 vapnik 2000 kernel functions and parameter are selected to reduce the bound on the vapnik chervonenkis dimension the extended svm was able to solve function estimation problems by applying vapnik s epsilon insensitive loss function and huber loss function as shown in fig 5 with the general architecture of svm chen and yu 2007 yaseen et al 2019c svm can be designed as linear polynomial spline rbf network and mlp suykens and vandewalle 1999 vapnik 1998 svm has been prevalently used to build a classification model for trend prediction and solving regression and time series problems raghavendra and deka 2014 various models developed using kernel architecture are listed in table 3 4 2 bibliographic review of svm models wang et al 2011 tested the use of semi supervised regression model with svm and compared it with mlr and svm ga models the data in this project were retrieved using remote sensing and accuracy of the regression model is improved thus the interpretation and monitoring of the wq of the study area are also enhanced in another study in the same year by el shafie 2011 svm was compared with mlp and enn ensemble models to assess the level of performance in identifying a complex nonlinear relationship between wq data to minimise expenses and labour charges svm performance is accurate more robust and faster than other models with the need for minimum computational cost singh et al 2011 applied support vector classification svc for data reduction used svr as a predictive model and compared kernel based discriminant analysis da kernel based partial least square kpls ordinary da and pls techniques svm modelling results are promising in handling optimisation classification and prediction of a large amount of wq data noori et al 2012 developed reduced order svm ro svm by using orthogonal decomposition to reduce time consumption and compared it with the conventional svm model the obtained results are acceptable for bod prediction modaresi and araghinejad 2014 evaluated classification models such as svm pnn and knn svm performance is superior to others because it produces no errors during calibration and validation as it uses kernel function and only depends on support vector which makes it a better model than ann models for wqi modelling kar et al 2016 used spectral angle mapper sam and svm to classify and identify metal contamination in river water svm performance is superior as it provides classes based on a priori spectral knowledge selected by the modeller spectral absorption depth is a good source of information regarding metals and can be utilised for other remote sensing techniques bozorg haddad et al 2017 applied lssvr gp with pca input optimiser and hybrid ga lssvr model since lssvr doesn t have a mechanism for selecting coefficient and yet its precision is dependent on it ga optimises it by finding the neighbouring global optima and selects the correct coefficient which modifies coefficient of the svr producing better result than other models similarly two other studies evaluated svr performance it is able to identify the most important wq variables generalized svm and canonical correlation analysis based multivariable data down scaling method when applied the accuracy and efficiency of the model increases considerably kamyab talesh et al 2019 shan et al 2018 shen et al 2019 addressed the problem of the complex interaction of wq variables and inter annual variation of eutrophication by using ls svm modelling and empirical orthogonal function eof as a dimension reducing tool to better comprehend the spatiotemporal patterns the proposed ai model can handle the uncertain and multifaceted data and identify the point of nutrient loading which concurrently encourages algal bloom thus this identification can help to control and manage algal bloom another study compared ls svm and svm model performance for wqi prediction polynomial kernel function outperformed linear and rbf thus chosen for final prediction ls svm is a superior model than svm as it can reduce the complexity of the problem by using linear equation rather than using quadratic programming like the conventional svm model leong et al 2019 gamble and babbar sebens 2012 analysed the performance of predictive models by applying pca method for the linear variable dimensional reduction and kohomen som for nonlinear wq variable reduction the results from dimensional reduction were assembled using k nn clustering analysis to reduce computational cost also the authors applied linear da to establish a relation between clusters as a linear classification method i e svm to deal with nonlinear variables the results are promising svm is superior but both models perform well chen et al 2012 coupled svm model with factor analysis and non negative constraints which together are responsible for the variable reduction and classification to identify the source of water pollution the results are satisfactory and provide an opportunity to understand the environmental status and decide on management strategies jiake et al 2013 assessed the capability of hybrid svm in handling nonlinearity and nonstationary of wq variables against arima and bpnn models pso was applied to determine the variables for the svm model this way improves the accuracy of the results by avoiding overfitting or under fitting the hybrid svm model outperforms arima and bpnn models li et al 2013 used svm linear discriminant ld analysis and quadratic discriminant qd analysis models for wq variables estimation they found that svm is better than other considered models svm is an effective classifier and predictive model but lacks the analytic capability in terms of spatiotemporal distribution in another study nikoo and mahjouri 2013 developed a probabilistic svm psvm model wq data were fetched from fis in a monte carlo analysis and were compared with som and fuzzy clustering technique fct the psvm model performance is better than the others two studies found that svm is a good alternative to ann the study used trial and error method and ga optimisation for both models the authors found that svm generalisation capacity is high as a result over training is decreased and wq can be predicted for non point source with good accuracy and low risk abobakr yahya et al 2019 liu and lu 2014 in another comparative study olyaie et al 2017 assessed mlp rbf linear genetic programming lgp and svm models together for do prediction the efficiency and accuracy of the model follow the order svm the highest then lgp rbf and least mlp model for do estimation though lgp becomes highly applicable when it can present the empirical formula in a simple form in the same year ji et al 2017 applied svm for hypoxic river systems and compared its results with those of mlr bpnn and grnn bpnn is a traditional nonlinear regression model grnn is similar to bpnn but has no fixed architecture and needs an optimum number of hidden layers to deal with large datasets svm is superior with good performance and excellent do prediction accuracy li et al 2017a b coupled ensemble empirical mode decomposition eemd with svr and compared it with standard svr and bpnn models the hybrid model data were used for multimodal decomposition with eemd since it is practical sensitive direct and self adaptive regression analysis using svr was performed and the hybrid model was assembled to predict do which showed that svr is a better model than bpnn haghiabi et al 2018 scrutinised the performance of ann and group method of data handling gmdh using ffnn model and used a network of simplified processes and svm which utilised transign rbf as the transfer and kernel function svm outperforms the others gmdh and ann models produce satisfactory results in wq prediction fan et al 2018 explored the effectiveness of the results of the coupling of swat soil and water assessment tool and svm model to assess the relationship between aquatic organisms the results showed significant spatiotemporal deviation between variables and promising efficiency of the coupled model shan et al 2018 hybridised svm with fuzzy logic the performance of the new fsvm is superior to that of the conventional model the new fsvm can deal with noise by giving importance to different values and varying samples and manage high dimensional wq data 4 3 model assessment svm is a statistical learning technique that can be applied for classification and regression problems this method has good generalisation high flexibility global optimisation and statistical analysis capabilities svm model is accurate robust and fast the approach can identify complex nonlinear relationship better than other models such as mlp and enn due to the capacity of the kernel model to construct expert knowledge raghavendra and deka 2014 thus svm is known as a kernel model and its selection is a priority to achieve excellent performance the kernel can operate in input space and form nonlinear boundaries many functions such as linear polynomial sigmoid and radial basis function however rbf is popular owing to its less or no error advantage during testing and validation and reliable performance compared with other models such as pnn and knn haghiabi et al 2018 modaresi and araghinejad 2014 the principle of structural risk minimization makes svm superior model than others since it reduces the upper bound of the expected risk whereas the traditional empirical risk minimization theory which is applied in ann reduces error in the training data set wankhede and doye 2005 this risk management process helps svm models in better generalization capability svm performance is better when used as a classification tool svm training process is difficult than others since the parameter c of the algorithm has to be selected by the user and optimized for each class modaresi and araghinejad 2014 svm has been used as a regression model in many river wq studies this method improves the regression accuracy and interpretation and monitoring of nonlinear data as river wq svr needs pre processing of the training variables by mapping the input space to manage nonlinear data svr can be simultaneously used in data optimisation classification and forecasting singh et al 2011 a variant of svm such as ls svm can be a good tool for regression and classification this approach uses karush kuhn tucker equation from the traditional equation dimensionality reduction tools such as empirical orthogonal function can be incorporated to comprehend the spatiotemporal patterns shen et al 2019 this way makes the model flexible to the nonlinear input variables of river wq clustering techniques can be used with svm to manage large datasets and decrease computational cost and data attribute for separating objects in a group accordingly the speed of the training process increases by utilising distribution properties bhagat et al 2019 gamble and babbar sebens 2012 nikoo and mahjouri 2013 for similar results dimensionality reduction tools such as fa pca and svc can be used to deal with a large amount of data chen et al 2012 svm can efficiently predict the river wq and simultaneously classify them thus monitoring and managing by policymakers become easy to understand as river wq is divided into standardised and defined wq classes 5 complementary models 5 1 conceptual background data driven models of ai can be coupled with wavelet transformation to enhance their ability and deal with their limitations this way greatly helps towards taking advantage of both techniques because these models are individually incapable of handling the difficulties related to understanding the complex and nonlinear wq variable interaction in 1984 wavelet was first presented as dilation of a single function and its transformation grossmann and morlet 1984 wavelet algorithm consists of a dilation factor a temporal translation function and a mother wavelet wavelet algorithm can overcome the shortcoming of other models with its capacity to extract important information from a large dataset obtain data in a readable form by decomposing nonstationary signals into sub signals at different levels and solving diagnostic classification and forecasting problems when combined with various ai models wavelet algorithm can present signals in the time scale and analyse the relationship nourani et al 2014 rao 2002 various models developed using wavelet algorithm are listed in table 4 the general process diagram of the wavelet ai model has been shown in fig 6 yaseen et al 2018a 5 2 bibliographic review of complementary models wavelet de noising technique wdt was coupled with anfis model its performance was compared in two studies with rbfnn and normal anfis wdt anfis model is accurate and fast with improved properties of de noising and successfully predicts wq variables as well as found better than the other two models for optimum performance of the model the selection of various variables is important for instance orthogonal wavelet was selected in the study because it is concise easy to calculate and satisfactorily restores the original signal a similar level of decomposition and threshold methods was considered and the soft threshold technique is preferred since it produces an enhanced outcome najah et al 2012 najah ahmed et al 2019 parmar and bhardwaj 2015 developed ann neuro fuzzy logic wavelet and anfis models with wavelet transformation neuro fuzzy wavelet was used with daubechies wavelet to deal with random and spike series the result showed that the wavelet couple model produced better results than of single models considered in the study barzegar et al 2016 explored ann anfis wnn and wanfis models for salinity estimation discrete wavelet dw was used for pre processing of the data to improve accuracy thus wanfis and wnn models outperformed other conventional models barzegar et al 2018 explored the performance accuracy of elm wavelet elm welm and wanfis models the hybrid model outperforms the conventional models as a consequence of the enhancement made by the application of wavelet transformation which can deal with non stationary wq data in addition to that the application of boosting ensemble method helps to reduce error rates which allow improvement in overall model performance two studies coupled wavelet algorithm with mlp and anfis and compared them with traditional mlp anfis and mlr models dw was applied because of its high efficiency wmlp and wanfis exhibit improved accuracy and performance during extreme weather conditions affecting wt and bod values parmar et al 2019 zhu et al 2019a elkiran et al 2019 implemented bpnn svm arima and anfis model along with simple averaged ensemble sae weighted average ensemble wae and ensemble neural network enn models for wq modelling single models were tested against the models which were coupled with ensemble technique among which ensemble technique coupled with anfis model performance was superior to others ensemble technique was able to improve the performance of the models wang et al 2013 applied bootstrapped wavelet bw with ann bwnn and compared it with ann wnn and arima models bwnn model used morlet wavelet basis function wbf with ann and handled severely unpredictable and non seasonal time series and missing wq data bwnn model shows a good result but must be improved in terms of cost and prediction three studies applied wavelet transformation dw and wavelet based regression wr with the ann model to decompose wq data into a multi frequency time series against the conventional ann dw helped in noise reduction and manage nonstationary signals this method produces an accurate and superior result than others however wr produces a better result with higher accuracy than wnn models khani and rajaee 2017 ravansalar et al 2016 ravansalar and rajaee 2015 similar work was presented by solgi et al 2017 with svr and anfis models the data were decomposed using wavelet transformation and pca was used for wq data relation identification and to determine the main sub signal to increase the modelling speed wsvr model with rbf kernel performance is found superior to all considered models in this study montaseri et al 2018 applied anfis gp2 anfis sc1 gene expression programming gep wanfis and wgep models for tds prediction the hybrid models perform well but the results from wgep are exceptional because wavelet transformation is used to decompose the data into sub time series rajaee and jafari 2018 integrated dwt with ann gep and dt models to evaluate their performance for wq prediction mother wavelets applied in the study were db2 db5 haar bior1 1 and meyer amongst them db2 and meyer help the most in improving all the models performance decrease noise by separating the signals and deal with the extreme data however wgep performs slightly better than other models in prediction accuracy and error although all successfully produce better results than their conventional counterparts huang et al 2018 explored the use of fuzzy wavelet neural network fwnn ann and fuzzy logic models and included self adapted fcm clustering for determination of fuzzy rules ga and gradient descent algorithm were incorporated as the optimiser fwnn outperforms other models because of its capacity to manage uncertainty fluctuation and non seasonal time series in wq data and produce high accuracy and feasibility rajaee et al 2018 compared ann wnn mlr and wmlr models the ph prediction performance of the wnn model is better than those of the other models and can predict 2 3 days ahead due to the application of a trous wavelet transformation algorithm this algorithm dilates the mother wavelet and maintains the same length wnn performance was superior to others by removing the noise instigated by the ph shift 5 3 model assessment wavelet has been popularly used for time series analysis in river wq studies this method tries to present localised and momentary change mapping in the system between two types of wavelet namely continuous cw and discrete dw dw is more frequently used in river wq studies as river wq signals are mostly discrete and noisy thus they need decomposition and de noising dw in combination with de noising increases the accuracy of the model such as anfis and ann and decreases computational cost barzegar et al 2018 wavelet input time series analysis is crucial to river wq model because of the combined benefit of the wavelet algorithm and model can improve accuracy and performance wavelet analysis can be used for periodic river contamination identification and monitoring as it can identify the trend and the periodic changes olyaie et al 2015 a study by solgi et al 2017 reveals that the modelling speed of a hybrid model can be considerably increased if pca is used to select the main sub signals among the numerous signals decomposed by w then these sub signals can be used as input in the model pca applies kaiser meyer olkin test to assess the correlation between the variables the test value less than 0 5 is considered inadequate for analysis whereas value more than 0 7 is allowed for further analysis hutcheson and sofroniou 1999 the combined form of the hybrid model and pre processing analysis can be very helpful to deal with multi variable wq data wavelet can considerably increase the overall performance of a model and can be combined with various models such as ann they have the ability to explicate spectral and temporal information they are able to analyse time series data and establish a relationship within non stationary data allowing the couple ai model to perform better wavelet transform analysis has proved to more efficient than fourier transformation and the energy variation plotted in time frequency allows assessing the hydrological variation within the data at different scale and location partal and kişi 2007 the selected mother wavelet is important to the performance of the model orthogonal wavelet can be a good choice because it is concise easy to calculate and satisfactorily restores original signal and has a similar level of decomposition and threshold methods thus this wavelet produces an enhanced outcome daubechies wavelet can also be used with increased random and spike series morlet wavelet can be applied in unpredictable and non seasonal scenarios and in case of lack of data najah et al 2012 parmar and bhardwaj 2015 wang et al 2013 many mother wavelets can be used to deal with multifaceted wq data and must be select depending on the scenario and data availability thus a mother wavelet with flexible and wide features is suitable to study time series trends in river wq research the simplicity of the wavelet coefficient and sub signal endows the wavelet several specific characteristics such as hidden period dependence and easy diagnosis of the jump nourani et al 2014 wavelet combined with anfis model provides the hybrid model using fuzzy rules with the advantage of a reliable result since it can handle uncertain and spatiotemporal seasonal wq data the hybrid model can handle extreme data fluctuation accurately under structural missing data barzegar et al 2016 wang et al 2013 6 hybrid ai models 6 1 conceptual background ai models perform better with optimiser than without them because they have few limitations such as high computation cost inability to deal with np hard problems and difficulty with complex problems ghorbani et al 2018 optimisers such as nature inspired ni optimisation algorithms have been applied to address these issues many ni algorithms mimic the natural behaviour of humans animals and insects ml is a full fledged system with its own algorithm data structuring and learning process but it must learn adapt and evolve as nature does to create a robust system ni algorithm has gained popularity owing to its advantages i it is inspired by simple concept mimicked from natural examples such as animal insect or genetic behaviour ii it is flexible and does not need special changes in the algorithmic structure thus it is easily incorporated as an optimiser iii it only needs the representation of input and output variables iv it applies deviation free mechanism and random approach v it can avoid local optima and deal with the challenges of real problems thus it is more applied in many research areas than conventional algorithms the general architecture of optimisers coupled with ai model such as ann has been presented in fig 7 ga was introduced in 1962 and improved considerably as time progresses it works on selection crossover and mutation operators goldberg and holland 1988 holland 1962 ga uses binary strings for coding thus it uses real variable vectors as chromosomes real variables as genes and real numbers as alleles the vector is decoded and undergoes fitness evaluation which helps decide whether the vector undergoes mutation or crossover the evolution process repeats until the best performing model is found maier et al 2014 wright 1991a b ga search by allocating efforts to regions of the search space based on an estimate of the relative performance of competing regions in complex domain one expects perpetual novelty to be a characteristic feature in this case traditional search techniques are likely to be misled and ga may be the search technique of the choice for machine learning system fitzpatrick and grefenstette 1988 gp models which are a class of ea that combine ga and gp are based on the darwinian principle of evolution theory proposed by koza 1997 it is a systematic domain independent method that spontaneously solves the problem without requiring the designers to have in depth knowledge of the solution structure gp functions as an optimiser and classifier this method includes a syntax tree with branches as functions with arguments and leaves of the tree as variables and constant since gp uses ga the primary operators are crossover and mutation poli et al 2008 compared with ga gp models are more flexible and can evolve variable length gp has various versions such as linear gp grammar based gp graph based gp and tree based gp each with different presentations this approach applies stochastic search properties acts as a global search is least trapped in local optima varies in solution architecture has freedom of expression to obtain an improved solution by searching relationships has automatic removal of unwanted variables and finds meaningful associations from the given data jabeen and baig 2010 various algorithms are based on the behaviours of organisms for example particle swarm optimisation pso algorithm uses the concept of bird flocking fish schooling and swarming theory pso is based on a simple concept with the least coding its advantages over ga include enhanced performance due to group interaction and memory retention eberhart and kennedy 2002 another ni algorithm is the ant colony optimisation aco algorithm which is based on ant system as the name suggests this algorithm has positive feedback that rapidly discovers the appropriate answer its distributed computation evades early convergence and uses constructive greedy heuristic for fast results this approach is flexible tough and population based dorigo et al 1996 shuffled frog leaping algorithm sfla was introduced to solve discrete optimisation problems sfla transforms frogs into a memetic evolution chain that is a system of behaviour that must be passed from one frog to another similar to an infection no physical change occurs but the idea held by each frog improves the difference from ga is that it only allows genetically alike individuals to interact whereas sfla spreads the idea to all characters eusuff and lansey 2003 similar to the natural behaviour of insects such as fireflies that produce light to communicate the hunt has been used to develop an algorithm on the basis of this theory the firefly algorithm ffa has been designed ffa has several benefits over pso and ga i ffa can estimate better and converge faster towards optimality and ii is more efficient in finding the global optima yang 2009 consistent with the previous theory of ffa bat algorithm ba has been designed based on bats echolocation behaviour ba consists of a good combination of pso and ga yang 2010 various models developed using hybrid nature based algorithm are summarised in table 5 6 2 bibliographic review of hybrid ai models ga is the earliest of the natural algorithms applied in river wq studies ng and perera 2003 applied ga which works on the principle of natural selection where parent population is generated and improved by selection crossover and mutation and used as an optimiser for the wq model ga operators play an important role along with sensitivity analysis to obtain the convergence point which makes the model robust and effective in another study icaga 2005 used ga as an optimisation tool to find and apply the best possible input combination ga performance is better than dynamic programming burchard levine et al 2014 evaluated the performance of ga and ann models to increase the response time of the early warning system ga ann model successfully provides a response 8 h ahead of time and can effectively understand nonstationary and vague data in another study chatterjee et al 2018 studied non dominated sorting ns ga ii modelling which is similar to ga but optimises multiple objectives with ann model and compared it with nn ga and nn pso models nn nsga ii is superior to and more stable than other models jin et al 2019 developed a model by integrating improved ga which uses multiple data sets of the sliding window for choosing optimum initial parameters for bpnn which was able to adjust the proper architecture to recognize the wq deviation the result from the integrated model and the normal bpnn were compared and shown significant improvement in predictability effectiveness and reliability zhou et al 2006 enhanced ann modelling result by integrating pso optimisation technique which is based on the cognitive and social interaction of flocking birds where particles are induced to their most promising solution the solutions were compared with ga and bpnn algorithm and result show that pso is robust and good tool for predictive models piotrowski et al 2014 explored lm ann model as the main model and compared it with pso differential evolution de with global and local neighbourhood based mutational operators degl degl proxin differential evolution separate groups de sg ja de self adaptive de and other adaptive methods a total of 23 different training methods were used and most were selected from de evolution strategies direct search and pso most of them are inferior to lm nn performance in wt modelling li et al 2016a b demonstrated the implementation of mlr bpnn and svr coupled with pso as an optimiser the authors prevented overfitting and bias by applying the leave one out cross validation method during the training process performance capability is highest for pso svm then pso bpnn and lowest for mlr since among all svm is more capable to handle the nonlinear relationship between variables keshtegar et al 2019 evaluated the performance between polynomial chaos expansion pce a model that predicts practical problems using a stochastic model mlp pso mlp and mlr the performance of pce and mlp pso is similar and has higher predictive accuracy than others considered in the latest research article by azad et al 2019 anfis pso anfis acor ant colony optimisation based technique used by ants to find food and ann were equated gp sc and fcm were used for fis generation anfis acor provides good results during testing and pso performs well during testing therefore ea is a good optimising tool for modelling ec tds and sodium absorption ratio sar mahmoudi et al 2016 explored sfla optimizer which is based on the social behaviours of frogs which are sorted based on reducing or arising of the problem and gp was applied with the svr model sfla svr is better than gp svr in terms of accuracy in another research by raheli et al 2017 ffa which is a swarm intelligence optimisation method based on the movement of the firefly was introduced and coupled with mlp the hybrid model accuracy in do and bod prediction exceeds that of conventional mlp and the method can be used in other scenarios with available data in another study li et al 2017a b integrated ffa optimisation technique with svr the hybrid model is better and robust than the traditional svm model in wq indexing ffa svm saves money and time as it is a direct and rapid testing technique yaseen et al 2018a b c d verified the improved version of lssvm with ba which uses the principle of echolocation capacity of the bat for locating its prey model tree m5 and multivariate adaptive regression splines mars model were used for comparison lssvm ba outperforms all other models considered chen et al 2018 optimised bpnn model with an improved artificial bee colony abc algorithm were applied for do estimation the results stipulated that improved abc bpnn is superior to traditional bpnn due to the better predictive capability and higher accuracy due to the improvement in the speed of convergence and ability for local searching and generalisation azad et al 2017 investigated the performance of ga aco and de coupled with anfis model anfis de is the best optimiser for its high velocity simple operation and capacity to detect the best response and the ability to improve uncertainty in wq data anfis de outperforms others but all ni algorithms have the aptitude to optimise anfis as a predictive model ahmadi et al 2018 evaluated ca for classifying wq and fa to determine the important variables five input selection methods were applied which are correlation model pca and gamma test with backward regression and ga with gamma test for bod modelling lr ann and gp models were used the results showed that the best input method is the gamma test with backward regression integrated with lr gamma test with ga integrated with ann is the best model 6 3 model assessment ni algorithms are also known as eas since they solve the problems inspired by biological mechanisms that evolved by a long extended time of learning the concept makes this group of algorithms unique as the algorithms are based on real life system and easy to grasp they are easy to couple with other models as optimisers which helps deal with nonlinear and uncertain data ashrafzadeh et al 2019 maroufpoor et al 2019 their ability to deal with the complex problem in addition to their capability to perform a global search and local search and find the nearest optima popularise their use amongst optimisation techniques the hybrid models that are used in river wq assessment are population based algorithms such as ga pso acor ffa and ba a pso can be more effectively implemented for hydrological data since it has low computational volume easy to operate not dependent on the problem high convergence rate global search capability can deal with complex problems and can escape local minima azad et al 2019 taormina and chau 2015 b acor uses a probabilistic approach that can find the best path through graphs although it has high affinity solve discrete problems it can solve continuous wq problems by applying probability density function it applies global search techniques can escape from local minima and can solve most of the complex issues but suffers from low convergence speed socha and dorigo 2008 c ga is a population based stochastic optimization tool which can effectively deal with non linear and non differential wq data issues by achieving optimum solution by the repetitive process the operators can leap to different spaces with the look space to find the new best solution it is a non exhaustive process until the desired solution is achieved jakubcova et al 2015 yaseen et al 2019b these advantages allow them to solve highly complex and multi parameter problems d another swarm optimisation technique is sfla which has been a least explored optimiser in river wq studies this method uses a set of frogs as a representation of solution and spreads similar to an infectious disease from one frog to another without discriminating similar to ga only blood relatives are accounted for mahmoudi et al 2016 e similar algorithms such as ffa ba abc and acor have been explained in recent years in river wq monitoring studies as an optimisation tool they have high convergence speed propensity for local and global searching good generalisation and direct and rapid testing method naganna et al 2019 these qualities enable the model integrated with them to achieve superior accuracy and great efficiency ga is an established and robust nondeterministic optimisation tool ga generates parent population is enhanced with selection crossover and mutation utilises probabilistic transition rule and easily converges ga provides stable and efficient results ng and perera 2003 however limited research has considered gp models gp perform well when data are pre processed using wavelet transformation the linear and explicit representations of such model depend on convenience efficiency and genetic operators additional research is needed for better utilisation of these models considering they can be easily manipulated evolve during training and solve complex problems in an unexpected manner gp is a powerful tool to establish the relationship among input and out of non linear system thus a prevailing tool for environmentalists and hydrologists olyaie et al 2017 gp is a systematic domain independent a self parameterizing tool which doesn t require pre defined structure knowledge and tuning mehr et al 2014 few optimisation algorithms use behaviour patterns for example ga goes to the in depth knowledge and concept of genetics pso has no crossover and mutation transformation similar to ga pso is combined with different models such as ann anfis and mlr to increase predictive and classification potential in each case this approach is proven to be a good optimiser because it can enhance performance and has a retentive memory particles are persuaded to achieve the most promising result in a short period which also works as an advantage of decreased computational cost zhou et al 2006 7 other ai models 7 1 conceptual background various models are least explored than others in the field of river wq assessment prediction and classification thus all the other models that do not belong to the other classes discussed in the previous section are collated here model tree m5p uses a binary decision tree dt along with multilinear regression to predict continuous numerical attributes the first step consists of splitting criteria to generate a dt the second step consists of a pruning method to eliminate overfitting and the construction of a linear regression function compared with ann and svr m5p model reveals the pattern and relationship in the data this model is simple yet efficient and accurate for pattern recognition and relation establishment for large scale data etemad shahidi and bonakdar 2009 quinlan 1992 random forest rf also uses the regression approach with a combination of tree predictors this model uses a randomly selected section of training dataset for each tree the method uses only one third of the data and the remaining is called out of bag rf consists of several input variables and requires a large number of trees breiman 1996 breiman et al 1983 another regression model developed during the 1990s by friedman 1991 known as multivariate adaptive regression splines mars which is a combination of recursive partitioning and regression the approach is a hierarchical forward backwards subset selection procedure this model consists of product degree knots dependent variables intercepts and basic function the model is flexible as it allows recursive splitting and produces a continuous model by substituting the step function gep is based on a similar concept as gp and ga however it has the features of a model danandeh mehr et al 2018 specifically gep utilises individual population fitness test and genetic operators sanikhani et al 2019 gep encodes individual population as linear strings of fixed length and later expresses them as nonlinear entities of different sizes and shapes during the operation the first step of gep is similar to that of ga whereas the second step is similar to that of gp gep can adapt and evolve this method can be easily manipulated as a consequence of its use of chromosomes that are linear compact and small the approach always produces valid expression trees reproduces nominated chromosomes with alteration and expresses them as expression trees for the next generation ferreira 2001 arima model process includes model identification variable assessment and diagnostic scrutiny identification is done to obtain stationarity and normality temporal correlation is verified by autocorrelation and partial autocorrelation by following these steps arima determines the minimum akaike information criterion to obtain the best model shahwan and odening 2007 table 6 reports the studies conducted on the other ai models 7 2 bibliographic review of other ai models džeroski et al 2000 applied m5 and ordinary regression tree rt models to address the issue of selective chemical wq monitoring and its effect on river health rt model successfully produces a good sized structured generalisation of the input that is easy to interpret the model can establish the relationship between the variables which are expressed in mini and max values therefore bio indicators can be influenced by seasonal deviations the biological state of the river can also be influenced by the chemical state nikoo et al 2013 applied m5p and svr models for the valuation of integrated water quantity management to minimise load on water supply and targets during the planning of projects m5p model is a combination of a dt and multiple linear regression model which is applied on input output variables using deduction learning for the better understanding of the input output relationship the better management skill of m5p model in handling environmental data and its capability shows the pattern and relationships in the data by the regression equation thus its performance is superior to svr sepahvand et al 2019 examined the performance of m5p rf and bagging m5p along with gmdh models bagging m5p model outperforms other models because of the least standard deviation from the predicted value and shows high accuracy and validity due to low values of the vagueness indices its flexible approach also decreases the computational cost kisi and parmar 2016 compared least square svm lssvm mars and m5 tree models mars can manage the complex nonlinear relationship and perform on forward and backwards stepwise patterns as a result the model can exclude unnecessary variables and select suitable variables furthermore lssvm which works in the principle of structural risk minimisation can deal with estimation classification and regression analysis with a simple approach it is robust against noises and has lower computational cost than the conventional svm models the results showed that both models are more accurate and better than m5 tree in predicting river wq heddam and kisi 2018 presented the application of lssvm mars and m5 tree models the performance of the three models is excellent but each performs better than others in a different scenario for do prediction input max scaling was used for dimensionality reduction the result concluded the effect of discharge may vary by place but ph and wt influence over do are undeniable and essential for correct do prediction maier and keller 2018 tested knn rf svm mars and extreme gradient boosting xgb models the models were coupled with pca as a pre processing tool for managing high dimensional data and compared with the models without pre processing the regression models with pca perform better than the other models due to their higher accuracy lesser error and ability to handle high dimensional regression problem di et al 2019 applied hierarchical clustering expectation maximisation clustering algorithm and time series analyses to classify pollutants short time pollution condition and sudden unusual events the data were normalised using ward s method the models perform well and can classify the pollutants rankinen et al 2019 applied the generalised linear model glm which can manage non normal error distribution and boosted regression tree brt model which can handle nonlinearity and missing data their study aimed to predict river wq condition in various future scenarios considering indirect factors such as climate change agricultural measures and environment policies the model predicts the increase in annual mean wt to 17 3 c between 2025 2034 and approximately 19 3 c by 2055 2064 with an increase in precipitation of 10 in addition summer is predicted to face low flow the study can predict an increase in annual concentration nitrate suspended sediments and phosphorus by 16 63 45 146 and 38 100 respectively in 2025 2034 geetha jenifel and jemila rose 2019 applied a linear model svm and dt recursive partitioning technique was applied to identify the relationship between variables dt shows the least error rate manages considerable numerical data produces good data quality and handles dataset with errors and outliners ho et al 2019 evaluated the productivity of dt model to simplify analyse and classify the wqi for decreasing its complexity and the nonlinearity of data the study concluded that dt model can be a cost effective and process efficient modelling methodology sharif et al 2015 coupled som and knn to examine the classification and monitoring capacity of the combined model for river wq the clustering technique was used to reduce the number of variables and k nn was used for classification the model can identify the point of pollutant source and recognise patterns in the data sattari et al 2016 applied the knn algorithm for classification and regression along with traditional svr model both models could successfully predict wq but the study suggested that svr model with the rbf performs better and is more applicable than the other model due to its high performance easy execution and flexibility in case of sudden changes in wq variables ömer faruk 2010 explored the possibility of hybridising arima with neural network models because both are individually incapable of handling linear and nonlinear time series data efficiently thus both were used separately and combined afterwards for improved modelling and prediction performance the combined advantage of both models produces good results in identifying time series patterns and nonlinear characteristics cole et al 2014 tested the performance of generalised least square model with a cosine trend glscos arima and ann models for wt modelling arima model performance is least accurate in predicting ahead of time yet it does not show over estimation bias and under or over prediction glscos model is better and highly accurate even though all models perform well guo et al 2014 applied hybrid arima svm arima and svm models were optimised with pso for do and ph prediction the hybrid model uses both components of the models and can process linear and nonlinear data with overall enhanced forecasting accuracy su et al 2011 implemented rotated pca and da to identify the point source of water pollution and evaluate the temporal changes in wq som was applied for clustering and visualisation and ann was applied for partitioning absolute principle component score with mlr was applied to obtain the quantity information the results showed that the model is best for identifying pollutant sources which help in better manage the river pollution grbić et al 2013 applied a probabilistic nonparametric approach that is gaussian process regression gpr with lr to resolve nonlinear regression water pollution issues the inputs were fetched by least square criterion and mlr was used with mutual share information the first model can understand the periodicity of wq the second one can handle short term non periodic components fahmi et al 2011 combined pca with mlr to simplify and better understand the complicated and vague relationship between wq variables the new model is better than the conventional one reduces sampling time and cost and eliminates data collinearity keller et al 2018 studied a large number of models such as lr partial lr rt extremely randomised trees et gb knn svm ann and som models et svm and ann models are the best amongst the models et has the superior performance after pre processing with pca and ann is the second best model with mini max scaled pre processing of wq data another study also considered the application of the lr model for the prediction of ec different combination of logarithmic and inverse transformation statistical technique was applied for model improvement the ability of the lr model to fit on the non monotonic behaviour of data resulted in better performance in handling wq data salarijazi and ghorbani 2019 jiang et al 2018 applied growing hierarchical self organising map ghsom as a classification model the model can establish the correlation between the wq variables and detect the main pollutants the model is fast because it automatically generates neurons to achieve the specific clustering accuracy applies hierarchical inheritance approach for assessment and creates clear boundaries peterson et al 2019 implemented various predictive models such as mlr plsr gpr svm and elmr models with cca for spectral analysis of river wq variables the study aimed to incorporate decision level fusion method which produces promising results the fusion increases the overall accuracy and efficiency of the model and eliminates biases zaman zad ghavidel and montaseri 2014 predicted tds as an indicator for wq assessment using ann anfis gp anfis sc and gep models inspired by the genotype phenotype system the performance follows the order gep anfis sc anfis gp models najafzadeh et al 2018 examined gep evolutionary polynomial regression epr and model tree mt gamma test was coupled to better understand the relationship between the variables epr which is a nonlinear global stepwise regression method is a better model than others mt performs well as a classifier 7 3 model assessment the models that fall in the categories in the previous sections are accumulated here the number of users of such models are few yet their performance is promising the literature shows that numerous models have gained popularity in recent years one such model is arima which was reported in 2010 ömer faruk 2010 its performance improves when it is coupled with another model for it cannot deal with nonlinear time series data which may be the reason why it has been less implemented in river wq studies wang et al 2015 its ability in likelihood estimation and forecasting score test for model checking and time series modelling box et al 2015 similarly knn model can perform classification with good accuracy but its performance is inferior to that of svr which may be why knn has been used less in river wq research sattari et al 2016 however this model needs exploration along with research possibility of hybrid k nn models regression models are popular models after conventional models for example m5 can yield good generalisation better understand the variable relationship avoid overfitting and achieve high accuracy sepahvand et al 2019 dt models have been successful in event prediction and can be applied for recognising wq variation they are able to solve classification and regression problems this model applies top down greedy search without backtracking and can be used for categorical and numerical data management brown and myles 2009 dt can decrease complexity classify and handle nonlinearity with least error rate and handle a considerable amount of data geetha jenifel and jemila rose 2019 there are many variants of dt which are yet to be tested in the river wq research such as logistic mt reduced error pruning tree naïve bayes trees alternative dt khosravi et al 2018 due to model problem solving technique recursive dive and conquer and simplification of the complex issue allows more applicability in complex wq data modelling addition to that dt models are easy to interpret and can predict an unpredictable outcome ho et al 2019 mlr model in an older model but recent studies have shown that the hybrid version of the mlr model has been mostly applied the reason mlr is a mediocre model as concluded from section 2 2 compared with the ann model the studies have shown that mlr coupled with dimensionality reduction tools or optimiser can perform well in pollutant source identification and handle non periodic variation moreover it can understand complex nonlinear and vague river wq data when optimised fahmi et al 2011 grbić et al 2013 models like mars have been least implemented in river wq as it easily gets trapped with overfitting and solving regression problems is narrow abdulelah al sudani et al 2019 however pruning can help to increase the forecasting accuracy which can be achieved by the backward process using generalized cross validation wang et al 2010 mars model flexibly and capability to manage high dimensional regression and classification problems makes it a good model to be tested in river wq modelling it can separately identify the additive contributions friedman 1991 8 a general appraisal of global literature review 8 1 prerequisites of new model developments the application of ai models has rapidly progressed over the last two decades along with various improvements a continuous innovative attempt has been to develop the best model for river wq fig 8 shows the research development in river wq field over the last two decades from 2000 to 2007 the average research published was 2 per year steady growth was observed from 2009 to 2012 during when the average research published grew to 10 studies per year river wq modelling gained momentum during 2009 2012 due to increased awareness of the application of ai models and the advantages for wq prediction and assessment for river health management furthermore rapid advancement in ai model practices can be observed from 2013 to 2019 average reported research publication was 20 per year and still increasing additionally the data from 2018 31 papers and 2019 31 papers in the coming years the advancement of the application of ai models and optimising tools will grow more popular in the scientific community than before in the last few years synchronous growth of published research has indicated increased concern about the river water pollution and its effect on the study area which is ubiquitous worldwide increased frequency of ai model research can realise its possible implementation in river wq research and in real life uses such as river health monitoring classification of a pollutant point source customised policy making and water treatment management bhagat and tiyasha 2018 this apprehension is affected by factors such as increasing population agriculture industrialisation and urbanisation which directly and indirectly affect river health thus ai models are needed as a result of their superior understanding and applicability to handle the complex relationship between the river wq and various factors responsible for the change in wq in previous assessment sections the individual ai models have been assessed on the basis of model strength to deal with complex and nonstationary river wq data fig 8 clearly presents the growth of ai models over the decades moreover numerous architectural changes have been observed along with this exponential growth of application of ai model the continuous progression implies the need for further exploration because each model has its own limitations and benefits this section highlights a few weaknesses of the models for the need of designing new advanced models a the 209 reviewed studies revealed that various models were used 311 times ann or any form of ann was implemented successfully as a good predictive model for 133 times 43 as shown in fig 9 despite the success rate of ann it has disadvantages such as the need for large data for training overfitting problem local minima issues and false negative frequency issues ann also lacks the understanding of complex environmental data b fuzzy logic and fuzzy interference systems are the oldest and extensively applied algorithms in river wq after ann their application in 48 studies 15 makes them the second most applied model after ann models however they have limitations such as needing rules for combining the appropriate membership function which prevents the less experienced user from achieving the best performance out of the data moreover the rule cannot differentiate amongst important input factors c the next is svm 32 studies which was implemented in 10 of research and can solve regression classification and prediction problems this approach faces problems in the choice of kernel and high computational cost svm may suffer due to data inconsistency and inability to handle probabilistic forecasting the nonlinear models cannot be easily deduced due to the complication in mapping nonlinear space into high dimensional space which interferes with the computational speed d various optimisation techniques using ni 18 studies were integrated with these models as support but they also faced various issues for instance pso faces the problem of unrestrained particles which tends to leave the feasible space as a result its convergence speed decreases sfla needs prior input normalisation to achieve good accuracy acor is hindered by random initialisation and excess parameter requirement and needs tuning e eas such as ga suffer from early convergence issue do not use local search information and take a long time to tune gp is dictated by natural behaviour which makes it random and unable to guarantee the required results gp suffers from bloating that is excessive growth of the code without any substantial growth in the fitness silva and costa 2009 ga and gp designed with binary expression produce invalid expression and cause increased computational cost gp ga and gep can be easily manipulated but lead to functional complexity this complexity hinders the redesign of the same model and production of the same result ferreira 2001 f the performance of the wavelet algorithm 16 studies depends on the choice of the mother wavelet and the decomposition level this condition results in its unpredictable accuracy despite a few issues the wavelet algorithm complements other models very well and increases their performance level g it was observed that river wq modelling is associated with uncertainty feature and thus uncertainty analysis for the dataset models and input variables should be investigated for better understanding of the predictability performance chen and chau 2019 shamshirband et al 2019 yaseen et al 2019a h it has been observed that most of the research study did not give much thought for the data division techniques during the study commonly employed data splitting is simple random sampling which is an unsupervised technique it is efficient simple in application and produces low bias lohr 1999 however it suffers from a high discrepancy of the model performance error estimation under this technique other methods are som physical process based domain knowledge based trail and error and user rule based methods are few which have been frequently applied among them the trial and error method has less variance in the model performance and can be combined with more techniques but takes a lot of time and there is no proper theoretical background bowden et al 2002 however this minute consideration of data splitting ration can have a significant effect on the result dawson and wilby 1998 thus utmost precaution should be taken when considering wq data and its statistical properties i throughout the literature it was observed that several types of research were conducted on the baseline of comparative ai models capacity with respect to the predictability performance this was seen in journals mainly related to water quality researches such as journal of hydrology environmental monitoring and assessment environmental science and pollution research stochastic environmental research and risk assessment water supply water resources management science of the total environment etc as a matter of fact this kind of researches adds no value to the base knowledge of river water quality modelling the establishment of water quality modelling using the feasibility of artificial intelligence models should be incorporated an innovative contribution where insightful aspects of water quality are discussed debated and recognized in addition there must be an informative reason explained for the behaviour of the predictive model 8 2 most explored rivers fig 10 shows the number of studies in each country along with a map that presents the most explored and modelled river streams worldwide in the last two decades the leading ai research on river wq area have been accomplished in china 42 out of 209 this result suggests that ai models are popular and gaining interest as time progresses most study areas are from asian countries such as china 42 iran 31 india 22 malaysia 23 taiwan 8 korea 4 iraq 4 bangladesh 2 thailand 1 and hong kong 1 representing 138 out of 209 papers this result can explain why ai models are continuously gaining popularity in developing countries moreover asian countries are endowed with perennial and non perennial rivers which demand much research on surface water resources such as rivers rivers are the lifeline for agricultural and industrial growth and agricultural countries that grow crops such as rice and sugarcane need a substantial amount of water for irrigation thus increased research evidently manages and monitors river wq to maintain healthy crops after china usa has the second majority of 31 papers which can be justified by its large land area with rivers and advanced monitoring station where data are freely available for study worldwide thus usa is a popular choice since modelling scientists need good quality data for testing new models many countries and river sources are yet to be explored a large number of studies should be done considering diverse conditions for each study area which can help design models applicable to various situations although the african continent ranks third by land size and comprises 54 countries only 2 studies have been reported the reasons are i many of its countries are under developed and developing thus still working on their water related policies and don t have comprehensive policies ii many countries are still in the initial stage of industrialisation and use natural methods of farming which leads to minimal pollution concerns iii the mass population is less educated leading to less acceptability and addition to that there is less or no teachers for ai powered education to prepare the next generation iv fewer funds for ai research and education v concerns in the data collection transparency ethics and proper utilization of the data pedró et al 2019 ukpong et al 2019 however additional studies must explore the unique diversity amongst various african river streams similarly the number of river wq research reported in australia are only 2 possibly due to the least orientation of researchers towards ai techniques the cause of such alignment is due to the acceptance of the ai technique since it will cause a shift in the job will need to upskill the workforce needs implementation of safer and ethical policies increased cybersecurity privacy and advanced data collection system hajkowicz et al 2019 the ecological quality of river water quality can be articulated as organic and non organic variables regular monitoring the environmental and hydrological condition of a river zone can help to a better insight into the changes in the variables even the macro or microhabitat regarding this there is a challenge in dealing with the existing quality indicators and the specified reference value of them it has been pointed out in the introduction that most of the changes in water resources are related to anthropogenic activities the only salvation for humankind to solve the self created problems in designing effective water related policies which should be knowledge based on the catchment area frequent intensive monitoring data environmental indicators effects of previous legislation and the social and economic activities in the area to reduce the sudden change in wq due to industrial or municipal wastewater discharge or an extreme condition like a flood it is essential to rely on advanced water and wastewater treatment integrated environmental monitoring and automatic water quality modelling system both last techniques can be equipped with remote sensing and sensor technology to obtain high quality data nevertheless this kind of technology implementation is the need of the hour but still a challenge for the hydrologists environmentalist and data scientists as of the wq has a wide range of indicators and variables their measurement and understanding of inter relationship and the influence of each other can be difficult to interpret 8 3 water quality output consideration all previous review and research papers have mostly emphasised on input data which are essential for modelling process and various input optimisation techniques have been used to ensure the most potential input is used relative to the relationship established with the output variable although researchers have considered the input output relationship for modelling the least thought and analysis have been considered in the wq review papers about the output variable selection the reason is that the basic approach of these studies is to establish the relationship between the input and output another reason can be those input variables are used for learning optimisation and dimensionality reduction and a relation is established based on their sensitivity towards the chosen output variables thus they are the focus of the study furthermore the output is commonly decided based the issue addressed by the researchers such as if the issue in hand is algal bloom then output considered is macrophytes whereas if the problem is salinity then tds or ec is taken as output not by applying any predefined technique the major outputs highlighted in fig 11 represent the number of papers that have used each output variable out of all the considered studies thus the current study emphasises the assessment of the output and why few selected outputs or a single rather than multiple output is selected in many cases the figure presents that out of 209 assessed papers 55 papers used wqi which indicates the multiple numbers of output variables the remaining 154 used single or few outputs wqi is mainly considered in the case of river wq classification and trend determination where multiple variables are assessed against the government standards and classified in simplified categories the most popular wq variable is do do is a critical wq and river health indicator do is part of various water related reactions such as aeration underwater photosynthesis chemical oxidation and decomposition sufficient amount of do is essential for not only for humans but also aquatic plants and animals gray 2017 do holds the highest part in chemical wq assessment and is very easily affected by other variables thus finding the do can provide a considerable amount of insight on river health wq changes and further treatment requirements few variables may have an indirect and synergistic effect wt affects the solubility of the water and works as a catalyst in various chemical and biological processes in the river it also inversely affects the solubility of do another essential wq variable is ph which is the potential of hydrogen ion and one of the largest initiators of all chemical and biological processes such as corrosion decomposition solubility and toxicity similarly bod and cod which are the fourth and ninth most used variables respectively are the wq indicators that manifest microbial and chemical reactions occurring in the presence of oxygen in the water bod is one of the first wq variables discovered for river health detection bod and cod signify the need for treatment or the extent of river pollution few wq variables are considered indicators of another major pollutant contaminating the river water for instance an increase in chl a signifies an elevated chance of algal bloom macrophytes indicate the growth of phytoplankton and eutrophication in the water which kills aquatic plants and animals such as fish nitrogen compounds which are second to do also indicate and encourage algal bloom eutrophication and dendrification they create nox that leads to global warming along with nitrogen phosphorous indicates the same but also informs about industrial wastewater contamination similarly ec indicates mineralisation and salinity in the water al shujairi et al 2015 as per the reported survey it is evident that the performance capability of ai is dependent on the water quality multifaceted nature while designing a predictive or classification model the complexity depends on the number of different inputs integrated i e fewer is the better whereas too many inputs increase the intricacy of the model it is worth to highlight the applicability of ai models with the various model version as classified in fig 1 can change depending upon the geographical location government policies local population behaviour climate change and other unique scenarios thus there is no issue in the application of ai model in simple cases however the ever changing wq due to the dependent variables can cause a serious impact on the modelling result for instance oxygen depletion or organic decomposition or biological activities aquatic plants animals or microbes can alter the amount of do bod and cod another example can be nitrogen related compounds which changes its structure quite often due to change of other factors nitrogen fixation ammonia nitrification nitrate denitrification nitrite to molecular nitrogen 8 4 wq data variation time scales the survey shows that most ai model papers have considered the use of monthly data for river wq modelling as shown in fig 12 a total of 92 papers provided information about the uses of monthly data out of 110 papers which provided information on the data step this percentage can be considered as 50 because 46 papers have not reported on the data collection interval amongst all reviewed papers followed by weekly 9 papers yearly bi weekly and bi monthly 3 papers each the main reason of the highly conducted research on monthly river wq include unavailability of sufficient project budget few analytical laboratories lack of technical and skilled human resources policies of decision makers and meeting the basic need for modelling monitoring and managing river health in addition monthly wq monitoring can be highly essential for multiple water supply usage agriculture and water treatment plant design thus the prediction of the monthly time scale can contribute to several environmental engineering perspectives to obtain considerable insightful information a total of 12 research papers conducted time series hourly data 8 from the usa 3 from china and 2 from uk accordingly hourly data are from developed countries with sufficient funding and advanced monitoring stations that can obtain hourly data effectively with highly equipped laboratory facilities similar findings can be observed in case of daily data out of 26 papers 9 are from usa and 8 are from european countries which may again be due to availability of funds and facilities this finding signifies that these countries can manage and collect large amounts of hourly and daily data to produce good and effective models consequently better measures can be taken against river pollution one of the unique time steps is seasonal where few specific months are targeted a total of 15 papers which used seasonal data collection to save funding by collecting data for a precise period of the year which were already evaluated for changing trends in the specific time of the year thus the resources must be concentrated on those specific time intervals another possible reason is that the rivers selected for the study are non perennial seasonal furthermore the decision of selecting the appropriate data time scale depends on the objective of the study for instance if the researcher aims to understand the point source of pollution then daily time scale will most likely be used to provide improved insight into the wq changes due to industrial effluent discharge domestic wastewater discharge and agricultural runoff similarly if the study targets seasonal variation such as flood drought or any other unique natural changes affecting river wq then specific months or weeks of the year and seasonal time steps are preferred using quarterly and yearly data collection may be inappropriate as it does not add any value to the research selecting the correct time interval of data collection is important to achieve the objectives because the river has the capacity for self purification which indicates the wq can change naturally over time thus it is important to select the correct time interval of data collection to achieve the objectives 8 5 performance metrics performance metrics are statistical criteria that help developers assess the calibrated modelling performance on various platforms they also translate performance accuracy and efficiency into understandable and expressible form over 30 evaluation criteria have been used in river wq modelling and few are represented in fig 13 ai models mostly use quantitative error measuring technique the most frequently used square error measuring systems are root mean square error rmse 101 papers nash sutcliffe efficiency nse 19 mean square error mse 3 and sum of square error sse 3 based on the square of the differences between the actual and predicted values influenced by the error rmse is popular as of it can show several deviations is reliable and provides high weight to error however outliers should be removed coefficient of determination dc 69 which is the second most preferred matrix evaluates the predicted value produced by the model in respect of the actual value which provides the model performance and ranges from 0 to 1 nagelkerke 1991 another group consists of absolute errors namely mean absolute error mae 50 mean absolute percentage error mape 20 and absolute relative error are 2 they are the absolute difference between the actual and predicted values they only provide information about the extent of the error but not model validity however they have good sharpness willmott and matsuura 2005 correlation of coefficient cc 10 coefficient of efficiency ce 7 coefficient of variance cv 3 and nash sutcliffe coefficient nsc 12 gauge the strong relation between data and relative movement of two datasets with different units mccuen et al 2006 many studies have reported classified river wq into classes c namely good average and worst per the standard wq guidelines of the study area for better understanding these studies have kept separate cs and 32 papers have reported this classification yaseen et al 2018c among all the computed performance metrics although correlation coefficient r and dc determination coefficient was widely used for models evaluation they are oversensitive to high extreme values and insensitive to additive and proportional differences between model predictions and observed data legates and mccabe 1999 moriasi et al 2007 on the other hand the mae was majorly used for evaluation owing to its less sensitivity to the extreme values in the predicted dataset in comparison with the rmse fox 1981 studies reported nash sutcliffe efficiency nse is a normalized statistic that determines the relative magnitude of the residual variance compared to the measured data variance nash and sutcliffe 1970 according to the guidelines of hydrological model performance evaluation proposed by moriasi et al 2007 the performance of a hydrological model is very good if nse is more than 0 75 hence this is another remarkable metric to be investigated for such type of modelling other informative metrics can be examined for better modelling evaluation and assessment which have not applied are volumetric efficiency ve metric can be explored to circumvent some problems associated with nse unlike the usual correlation coefficients or the nse ve would be particularly helpful in comparing the performance of similarly scaled it has the additional advantage of being easy to calculate the modified index of agreement m ia developed by willmott 1981 as a standardized measure of the degree of model prediction error is one of the essential metrics for evaluating predictive models and thus it is giving more insightful aspect on the modelling certification although it provides some improvement over dc it is still sensitive to extreme values due to the squared differences in the mean square error in the numerator legates and mccabe 1999 in addition the disadvantage of the results given by the previous dc and nse arises from the fact that the differences of observed and predicted wq use the squared values consequently large errors in time series can be overestimated whereas small values can be neglected in order to overcome this limitation willmott 1984 introduced a generic form of index of agreement willmott s index wi the advantage of the wi is that the errors and differences are given their appropriate weighting and are not inflated by their squared values to reduce the effect of absolute differences during peak values of wq and to improve the effect of absolute low values differences the relative index of agreement r ia is applied which is a substantial metric that measures the differences between the observed and simulated values as relative deviations chadalawada and babovic 2019 another significant metric is kling gupta efficiency kge it provides a diagnostically interesting decomposition of the nse which facilitates the analysis of the relative importance of its different components correlation bias and variability in the context of hydrological modelling gupta et al 2009 persistence index cp based on the assumption that the process is a wiener process that aims of comparing the performance of the models against a simple model using the observed value of the previous day as the prediction for the current day as opposed to a constant mean the percent bias pbias measures the average tendency of the simulated data to be either higher or lower compared to the observed data according to moriasi et al 2007 the pbias 10 indicates very good performance model the performance of the predictive models could be evaluated as well through visual inspection of graphical representations such as scatter plot box plot relative error taylor dia0gram and violin plot those plots are very useful to have a better understanding of the prediction capacity 9 conclusion river water quality research interest has grown over the years and the amount of data analysis generated from such research needs efficient handling assessing and predicting tools correspondingly ai technology has proved to be a powerful tool which has been successfully applied in various field including hydrology and environmental engineering considering the sub classes of the ai models most popular model is ann models then fuzzy kernel based models complementary wavelet and hybrid nature inspired models the review has gone through more than 200 papers which have addressed the river water quality modelling to better assess predict and manage the current issue of surface water pollution the assessment has been divided into two parts in this study the first part is the individual assessment of each model groups which describes the unique assessment derived from the bibliographic review however the reviewed literature reveals that these traditional models fail to grasp the full aspect of uncertain non stationary noisy and nonlinear data when compared to the complementary and hybrid model though each of them has their own strength allowing them efficiently working in the wq modelling and monitoring area thus to better understand the ai models a general appraisal has been prepared thus the second part of the valuation has been categorized into five sub section i it focuses on the disadvantages of each models leading to the next innovative modelling algorithm it also explains why there was and still is need of more advanced models research which will allow further research to fill the gaps pointed out in the review ii since the review research focused on river wq modelling thus all the rivers which have been studied around the world are mapped in a single figure which shows the most explored river even though the researches in river wq modelling has significantly amplified although the literature survey found that many of the river water sources are still unexplored worldwide especially african and australian continent this assessment allows researchers to focus on the new study area with unique environmental ecological hydrological and geological signature furthermore it gives the opportunity to test the new model in different scenarios and validates its performance iii the section pointed out the most considered output variables while these models performance is based on the input out selection it is evident that result is more optimistic when the relation between the input output is considered more minutely and tools like dimensionality reduction sensitivity analysis mutual information and extrapolation are employed to find the most sensitive input out association this allows the researchers working in the field of hydrology data science and computer modelling to work more on the consideration of the relationship and factors influencing the variables iv this section discusses the time step chosen by the reviewed papers revealing that many of them opted for longer time steps which may affect the time series analysis of wq larger time scale also limits the scope of visualization of seasonal and periodic variation which is may severely damn the decision making in case of emergency and disasters like flood and drought v the last part of the general assessment deals with the choice of performance metrics there are many performance metrics widely used however the selection of the most appropriate statistical criteria is very essential for proper judgement of the model thus this section gives information about the application of the most common techniques and the frequency of their preference in section 8 2 most explored river also points out another challenge the researchers are facing and continue to face the tremendous expansion of ai application is affecting the work and everyday life ai involvement in many industries including water and wastewater management and decision making policies sometimes makes the users reject it as these systems are inscrutable and biased thus there are countries which are still not implementing ai africa australia russia north america refer to fig 10 it is true that the ai system is needed to solve the complex problem but gaining users and decision maker trust is also essential to realise the full potential of ai technology providing more information on the system accuracy comparative assessment of the performance indices water quality indexing and system behaviour can increase model acceptability in real life application such information will give better feedback from the user which can be used for model improvement through feature engineering architectural adjustment parameter tuning research work on river wq modelling with ai is distributed over a wide domain and it is very much difficult to collect the whole range of wq which may also include heavy metals agricultural waste and chemicals immerging contaminants sediments industrial chemicals land use etc which is one of the limitations of the study thus the survey has been limited to the research studies who considered the most common and easily identifiable wq variables another limitation of the study is ever changing river wq and thus there will always need new models and testing them in a new environment there is much scope in the field of river water quality modelling and these challenges will keep the generation of new innovative ideas the next section presents the potential research and challenges which need to be addressed by forthcoming researchers 10 potential future research directions to get a better system lot of application of an expert system and decision support system has to be coupled together to overcome the barrier to achieve more such the system will also have to deal complexity uncertainty inconsistency imperfectness incompatibility etc stephanou and sage 1987 ai models have been continuously successfully and effectively implemented in river wq modelling studies as concluded by 209 reviewed research papers published in high index international journals from 2000 till 2020 ai models are combined tools of mathematics statistics and biological science they can overcome the individual weaknesses by behaving thinking and learning ai becomes machine learning when combined with learning human like behaviour can be called as ai but unless it automatically learns from data and improves it is not machine learning carbonell et al 1984 ai models have several advantages in solving complex problems of nonlinear river wq data they are reliable lets easy decision for policy makers easy and effective in the implementation and cost effective and can deal with large scale data however they need large labelled training datasets and suffer from limited capability and functionality various stages such as inputs architecture and training can be altered depending on the preferences of the researcher to achieve desired performance and outcome ai models can still be improved in river wq because wq concerns are increasing worldwide this paper is a glimpse of what has been done with one step forward and what may be done in the future here are several suggestions to achieve the goal a ai models are progressing massively to provide reliable and robust intelligence methodologies for solving environmental engineering problem theoretically thus the application must be practised as real life problem solutions b ai models are data extensive tools and can achieve high accuracy with a consistent regular and adequate amount of data if proper and competent monitoring stations are established which can provide continuous stable and accurate data worldwide c many study areas have problems with obtaining the data and several issues are difficult to overcome thus additional ai models that can overcome the problem of missing data and lack of continuous data should be designed d the issue of missing data and data unavailability specifically stations unreachable due to climatic condition can be overcome by utilising the recent advancement of technologies such as gis and remote sensing these technologies can be used often for resource management and environmental modelling issues the high resolution data from the satellite can be used for improved spatial river wq modelling e with a similar problem about data additional models should integrate the features of a black box model and white box models in another term the conjugal between the physiochemical mechanism happening in river systems must be considered and numerical approach must be used to predict river wq changes understanding the relationship between the wq and the mechanisms that influence each other can produce an improved result with fewer data inputs f different inputs and outputs are used in river wq analysis and few works with new variables given that every change around the study area may affect river wq future research studies must include additional variables such as population change seasonal runoff and amount of industrial influent and effluent the influences of these factors on one another should be established to provide a broad spectrum for understanding and identifying river pollutant sources and predicting possible sudden changes these studies will provide a good chance for water treatment plants to cope with emergencies g a new model that is designed and tested should be tested against the benchmarked models techniques and issues in river wq this kind of benchmarking technique will help researchers around the world find better solutions for real time crises already identified by other researchers such as data from arid areas semi arid areas flood prone zones and other diverse conditions where model competency can be checked for a scenario this method will develop robust and field applicable models to help solve real life river wq management issues h research data monitoring station data modelling information and benchmarked model application should be easily and freely available online to broaden the horizon of environmental research freedom for data access will provide a broad aspect of model performance based on information of benchmarked models and available data moreover researchers can evaluate their work easily and efficiently whilst producing models applicable to various environmental scenarios i few branch models are less explored in river wq assessments and need additional research such as ward nn hopfield nn dempster shaft theory knn dt and deep learning models these models have not been implemented in this field deep learning uses multilayer architecture can compute nonlinear input output mapping and learn through a general purpose learning technique sulaiman et al 2018 this method can understand and extract natural language and complex information achieve high accuracy provide an effective optimisation approach for end to end performance provide a fast and minimum need of tuning and use unsupervised learning lecun et al 2015 schmidhuber 2015 j attempts have been already made to create a hybrid model with high strength and power to deal with nonstationary random complex and vague data these efforts should be encouraged for the proposal of superior models in the near future tao et al 2018 various optimisers have been developed over the years and many remain unexplored in river wq such optimisers include bacterial foraging optimisation das et al 2009 amoeba based algorithm zhang et al 2013 artificial plant optimisation cui et al 2012 flower pollination algorithms yang 2012 grasshopper insect based algorithm saremi et al 2017 wasp insect based algorithm theraulaz 1991 fruitfly insect based algorithm xing and gao 2014 glow worm insect based algorithm krishnanand and ghose 2009 dragonfly insect based algorithm mirjalili 2016 shark optimisation hersovici et al 1998 whale optimisation mirjalili and lewis 2016 bean optimisation xiaoming zhang et al 2010a b dove bird based algorithm su et al 2009 eagle bird based algorithm yang and deb 2010 cuckoo search yang and suash deb 2009 bird mating askarzadeh and rezazadeh 2013 monkey animal based algorithm mucherino et al 2007 wolf animal based algorithm liu et al 2011 lion animal based algorithms yazdani and jolai 2016 artificial fish swarm algorithm li 2003 termite roth 2005 marriage in honey bees abbass 2001 bee collecting pollen algorithm lu and zhou 2008 krill herd gandomi and alavi 2012 grey wolf optimiser mirjalili et al 2014 earthworm wang et al 2018 salp swarm mirjalili et al 2017 nomadic people salih and alsewari 2019 sooty tern dhiman and kaur 2019 harris hawks heidari et al 2019 side blotched maciel et al 2020 and color hormony zaeimi and ghoddosian 2020 can be implemented in future studies for better visualisation the timeline is presented in fig 14 k many models such as rbf rnn pnn elm denfis efunn mars and regression models have been successfully applied for river wq assessment but never coupled with any bioinspired optimisation technique fig 14 presents the combined architecture of possible hybrid modelling using wq input output with ai models and ni algorithms for future research l regression models such as gpr dt rt mt glm and et are least explored in river wq studies they hold promise in classification and prediction competencies and close attention is needed to explore and enhance their performance their performance can be increased using optimisers as recommended earlier m close attention should be paid towards the architecture of the model such as the optimum number of layers weight and bias values data allocation for training testing and validation and method selection for model calibration n the performance of wavelet transformation with various ai models in river wq research has been considered for data pre processing to extract the underlying features and de noising time series it has been used in wq modelling but pre processing of temporal and spatial data utilised in river wq models need further research additionally w can also be evaluated against other ai models that can deal with nonlinear data such as grnn pnn denfis efunn fis narx mars enn dt rt and mt moreover these models must be comparatively studied to establish the extent of their success o the computational explosion is an issue yet not fully addressed by ai researchers the explosive increase in the knowledge growth leads to the need for the understanding of the interaction of the networks which are coordinating in a methodical fashion to solve the problem by equational discovery and symbolic regression technique this technique focuses on the structure identification parameter estimation system variables and decreases the discrepancies between simulated behaviour and observed system behaviour to find an optimal model in contrast to that ai models estimated the parameter value with fixed structure and losses the illustrate ability of the model thus needs additional implications tanevski et al 2020 thus with the increasing accessibility of data symbolic regression technique and artificial intelligence have to come together to better understand the internal networking of the model and on field data interaction to design more applicable model quantifying investigation and getting structural knowledge is the only redemption for an effective solution to the complex real life river pollution issues p increasing river pollution and its dangerous effect on life has ensured the need for environmentalist and hydrologist to work towards better solutions to overcome this life threatening disaster and a political issue beven 2016 they need to work on designing better assessing and predicting model additionally by the study of 209 papers which contain wq data ranges from 1968 to 2018 it is evident that river wq is subjected to change over time may get influence by various other variables there is a chance of emergence of new contaminants and other uncertainty which may follow with time this a limitation of river wq modelling which the scientist has to face since there is always a probability that a superior performing model may not perform very well next few years and new conditions thus continuous progress and testing have to be done to deal with river pollution and manage it well q after reviewing all the research paper it can be concluded that the process of contaminants mixing in rivers or natural streams is a complex and cause a synergistic reaction leading to change in the wq composition thus it should be considerated during the experimental process to include other variables such irregular velocities bed configuration sediment load and the dead zones kisi and yaseen 2019 11 abbreviation accuracy acc absolute mean prediction error ampe absolute average deviation aad absolute principle component score apcs absolute error ae absolute percentage error ape accuracy factor af adaptive boosting adaboost adaptive neuro fuzzy interference system anfis alkalinity al alkaike index aic aluminum al alternative fitness genetic algorithm afga ammonia nh3 ammonical nitrogen nh3 n analytical hierarchy process ahp anionic surfactant ais ant colony optimization acor arsenic as artificial neural network ann artificial bee colony abc artificial intelligence ai auto associative neural network aann auto regressive integrated moving average arima average absolute relative error aare average accuracy aa average information theoretic criterion aic average relative error are air temperature at back propagation neural network bpnn bat algorithm ba bayesian network bn bayesian regulization br biochemical oxygen demand bod5 bi carbonate hco3 blue green algae bga bod decay rate constant kb boosted regression trees brt bootstrapped wavelet neural network bwnn boron b calcium ca cadmium cd calcium sulphate caso4 carbon di oxide co2 canadian council of ministers of the environment ccme canonical correspondence analysis cca carbonate hardness ch cascaded fuzzy system cfs chaotic nonlinear dynamic algorithm cnda chemical oxygen demand cod chemical oxygen demand digested by potassium dichromate codcr chloride cl chloride sulphate clso4 chlorophyll α chl α chromium cr cladocera clad class precision pc classical neuro fuzzy cnf cluster analysis ca co active neuro fuzzy inference system canfis coefficient of efficiency ce coefficient of variation cv colored dissolved organic matter cdom continuous wavelet cw copepod cop crossover rates cr copper cu cyanide cn day of the year doy decision tree dt degree of agreement d delta percentage δ depth z determination coefficient coefficient correlation dc discrete wavelet dw discriminant analysis da dissolved inorganic nitrogen din differential evolution de differential evolution separate groups de sg differential evolution with global and local neighborhood based mutational operators degl dissolved oxygen do dynamic evolving neural fuzzy inference system denfis dynamic factor analysis dfa electrical conductivity ec escherichia coli e coli empirical orthogonal function eof ensemble empirical mode decomposition eemd ensemble neural network enn evaporation evap evolutionary algorithm ea evolutionary polynomial regression epr evolving clustering method ecm evolving fuzzy neural network efunn expectation maximization cluster emc extreme gradient boosting xgb extreme learning machine elm error rate er extreme randomized trees et error value ev forest land use factor f fluoride f factor analysis fa fat and oil f o fecal coliform fc feed forward back propagation ffbp feed forward neural network ffnn final predictor error fpe firefly algorithm ffa full complexity prediction square error fcpse fussy interference system fis fuzzy analytic hierarchy process fahp fuzzy clustering technique fct fuzzy c mean fcm fuzzy comprehensive evaluation fca fuzzy contingent evaluation fcv fuzzy multi attribute analysis fmaa fuzzy multi objective evaluation fmoe fuzzy sets theory fst fuzzy similarity measures fsm fuzzy synthetic evaluation fse fuzzy time series model ftsm fuzzy water pollution index fwpi gaussian cloud transformation gct gaussian process regression gpr gene expression programming gep general regression neural network grnn generalized least square model with cosine trend glscos genetic algorithm ga genetic programming gp geographic information system gis gradient boosting gb green algae ga grey relational method grm grid partition gp2 group method of data handling gmdh group method of data handling gmdh growing hierarchical gh hardness h habitat quality assessment hqa habitat modification score hms heat flux model hfm heavy metal hm hierarchical agglomerative cluster hac hierarchical clustering analysis hca hopfield neural network hnn humidity hs hybrid evolutionary algorithm hea hydrazine nh4 n improved fuzzy matter element evaluation method ifmem index of agreement ia inflow qin interactive fuzzy multi objective linear programming ifmolp iterative self organizing data analysis isodata iron fe irradiance irad kling gupta efficiency kge k nearest neighbors knn kling gupta efficiency kge latitude lat length l lead pb levenberg marquardt lm linear discriminant ld linear regression lr linear alkylbenzene sulphonate las location similarity index lsi longitude long macrophytes ma machine learning ml macrophytes index of river mir magnesium mg manganese mn magnesium sulphate mgso4 modified index of agreement m ia matthews correlation coefficient mcc mean absolute error mae macrophytes biological index of river ibmr mean error me mean absolute relative error mare mean absolute deviation mad mean absolute percentage error mape mean bias error mbe mean percentage error mpe mean prediction interval mpi mean relative error mre mean sea level pressure msp mean square relative error msre mean square error mse mercury hg methylene blue active substance mbas min max autocorrelation factor analysis mafa mineral oil m oil model tree mt modified response surface method mrsm monte carlo simulation mcs multi layer perceptron mlp multi linear regression mlr multi non linear regression mnlr multiple regression analysis mra multivariate adaptive regression spline mars multivariate linear regression model mlrm mutation rate mr naïve bayesian nb nash sutcliffe efficiency nse nash sutcliffe efficiency nse nash criterion nash nature inspired ni net ecosystem metabolism with system dynamic model nem sdm nitrogen n nitrate no3 nitrate nitrogen no3 n nitrification rate k1 nitrite no2 non dominated sorting genetic algorithm ii nsga ii nonlinear auto regression with exogenous input narx not applicable na optimally pruned op order series method osm organic nitrogen norg output weight optimization hidden weight optimization owo hwo oxygen o2 oxidation rate of nitrite k2 partial least square pls partial least square regression plsr particle swarm optimization pso pearson correlation coefficient r percentage of mean m persistence index cp permanganate index pi percent bias pbias persistence index cp petroleum pet phosphate po 4 potassium dichromate k2cr2o7 potassium permanganate kmno4 phosphate phosphorus po4 p phycocyanin pc1 physical process based model ppbm polynomial chaos expansions pce possibility measure based fuzzy support function machine pmf sfm potassium k precipitation ppre prediction accuracy ap prediction interval coverage probability picp principal factor analysis pfa probabilistic neural network psvm probabilistic probabilistic neural network pnn quadratic discriminant qd discharge q quantity of assimilated polluted water q1 quantity of water evaporation q2 quantity of water leaked to ground q3 quantity of water precipitation from runoff q4 radial basis function neural network rbfnn rainfall r pre reactive phosphorus preact recurrent neural network rnn recursive partitioning rp regression model rm regression tree rt regression value r value relative index of agreement r ia relative error re relative humidity rh relative error distribution red release from reservoir r1 residual chlorine clr re substitution error re river pollution index rpi river macrophytes nutrient index rmni root mean square error rmse root relative squared error rrse root mean square error proportional rmsep root mean square relative error rmsre rotated principal component analysis pca rotifera rot reduced order support vector machine rosvm runoff rf salinity sa secchi depth sd scatter index si sediment rating curve src sediment oxygen demand sod self organizing network based monitoring som short radiation rs shuffle complex evolution sce shuffled frog leap algorithm sfla silica si silicon oxide so2 simulated annealing sa single factor evaluation sfe single averaging ensemble sae simpson diversity index d sodium na sodium absorption ratio sar soil and water assessment tool swat spearman correlation sc spectral angle mapper sam spillage s standard error of prediction sep streptococcus strep subtractive clustering sc1 sulfide s2 sulfate so4 selenium se sum of squared error sse sunshine hour sh support function machine sfm support vectorclassification svc support vector machine svm support vector regression svr the daily average tav the daily max air temperature tmx the daily run off the declination of sun s the mean bias bias thermo tolerant coliform tf time delay neural network tdnn total dissolved solid tds total nitrogen n tot total coliform tc total organic carbon toc total phosphorus ptot total solid ts total suspended solid tss total volatile solid tvs transparency tr travel time tt turbidity tu ultraviolet uv urban land use factor u variable fuzzy evaluation model vfem variance inflation factor vif volatile hydroxyl benzene vhb volatile phenol v aroh volatile phenol vp volumetric efficiency ve volume error ve water quality wq water quality index wqi water temperature wt wavelet w wavelet basis function wbf wavelet de noising technique wdt wavelet neural network wnn ward neural network wnn weighted averaging ensemble wae willmott s index wi wind speed w1 zinc zn declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors acknowledge the funding support by the ton duc thang university also the authors would like to acknowledge their gratitude and appreciation to the cited relevant references of the current survey that are discussed the application of rive wq simulation 
5524,many applications require fine resolution soil moisture maps that exhibit realistic statistical properties e g spatial variance and correlation existing downscaling models can estimate soil moisture based on its dependence on topography vegetation and soil characteristics however observed soil moisture patterns also contain stochastic variations around such estimates the objectives of this research are to perform a geostatistical analysis of the stochastic variations in soil moisture and to develop a downscaling model that reproduces the observed statistical features while including the dependence on topography vegetation and soil properties extensive soil moisture observations from two catchments 8 0 and 10 5 ha are used for the geostatistical analysis and model development and two other catchments 6 0 and 60 ha are used for model evaluation the equilibrium moisture from topography vegetation and soil emt vs model is used to estimate soil moisture and the difference between the point measurements and the emt vs estimates are considered to be the stochastic variations the stochastic variations contain a temporally stable pattern along with temporally unstable patterns all of these patterns include spatially correlated and uncorrelated variations moreover the spatial variance of the stochastic patterns increases in absolute terms with the spatial average moisture content the emt vs model can reproduce the observed statistical features if it is generalized to include stochastic deviations from equilibrium soil moisture variations in porosity and measurement errors keywords soil moisture downscaling geostatistical analysis semivariograms variability spatial statistics 1 introduction fine resolution maps 10 30 m grid cells of volumetric water content soil moisture are important for many applications they can improve agricultural production holzman et al 2014 phillips et al 2014 vector borne infectious disease outbreak prediction montosi et al 2012 patz et al 1998 weather and climate modeling pal and eltahir 2001 seuffert et al 2002 forest fire prediction bartsch et al 2009 and crop yield quantification de wit and van diepen 2007 green and erskine 2004 for some applications it is particularly important for the soil moisture maps to reproduce the statistical properties of the observed patterns for example accurate assessment of spatial and temporal soil moisture variability supports crop and water management chen et al 2011 in addition wood 1997 demonstrated that proper characterization of soil moisture s spatial variability is important for accurate estimation of coarse resolution evaporation during different atmospheric states both low and high demands moreover proper characterization of the soil moisture probability density function pdf is useful for improving simulation of sub grid processes in land surface models evaluating remotely sensed soil moisture data and estimating fine scale hydrologic ecological and biogeochemical fluxes ryu and famiglietti 2005 because soil moisture is a principle variable in determining soil strength horn and fleige 2003 reproducing observed ranges of soil moisture is also vital for assessing vehicle trafficability flores et al 2014 vehicle impacts shoop et al 2005 and soil damage vero et al 2014 several studies have characterized the statistical properties of soil moisture patterns including the pdf spatial variability and correlation structure various pdfs have been evaluated by their ability to describe the observed spatial distribution of soil moisture for large regions a beta distribution ryu and famiglietti 2005 and a lognormal distribution choi and jacobs 2007 can fit the sample distributions well during dry conditions however these same studies concluded that a normal distribution fits the data better when considering the full range of conditions for small catchments a normal distribution has also been found to adequately describe the pdf of soil moisture for intermediate conditions while the distribution becomes skewed in very wet or very dry periods western et al 2002 in addition the spatial variability of soil moisture has been demonstrated to change with the spatial average soil moisture famiglietti et al 2008 some studies have reported increasing spatial variability with increasing spatial average de lannoy et al 2006 famiglietti et al 1998 western and grayson 1998 while others have reported an inverse relationship brocca et al 2007 famiglietti et al 1999 hupet and vanclooster 2004 still others observed maximum variability at intermediate values of the average rosenbaum et al 2012 owe et al 1982 vereecken et al 2007 also the spatial correlation length of soil moisture varies between regions and can occasionally vary temporally within the same region for example studies have found increasing brocca et al 2007 decreasing western et al 1998 and site dependent western et al 2004 relationships between correlation length and spatial average soil moisture fine resolution maps of soil moisture can be produced by downscaling coarse resolution data coarse resolution soil moisture is globally available from various resources including the advanced microwave scanning radiometer eos amsr e njoku et al 2003 soil moisture and ocean salinity smos kerr et al 2010 and soil moisture active passive smap satellite sensors entekhabi et al 2010 reichle et al 2017 geoinformation based downscaling methods use a combination of fine resolution topography vegetation and soil data to infer fine scale variations in soil moisture busch et al 2012 coleman and niemann 2013 pellenq et al 2003 ranney et al 2015 nasta et al 2018 these methods rely on known relationships between soil moisture and topography grayson et al 1997 western et al 1999 wilson et al 2005 vegetation ranney et al 2015 and soil characteristics famiglietti et al 1998 takagi and lin 2011 the soil moisture patterns generated by these methods reproduce the spatial structures implied by the site characteristics but they have not been shown to reproduce the statistical properties of the observed soil moisture patterns other downscaling methods specifically aim to reproduce soil moisture s statistical properties for example multifractal interpolation techniques have been proposed to downscale soil moisture kim and barros 2002b kumar 1999 mascaro et al 2010 while these methods can approximate the observed soil moisture variability and correlation structure at multiple spatial scales they have been used to downscale soil moisture to spatial resolutions 200 825 m that may be too coarse for some applications the primary objectives of this research are 1 to characterize the stochastic variability of soil moisture within catchments and 2 to develop a downscaling model that reproduces the observed statistical features of soil moisture while including soil moisture s dependence on topography vegetation and soil characteristics extensive ground based soil moisture measurements from two catchments tarrawarra and cache la poudre are used for the stochastic analysis and model development and two other catchments nerrigundah and satellite station are used for model evaluation the equilibrium moisture from topography vegetation and soil emt vs model ranney et al 2015 grieco et al 2018 is used to estimate soil moisture based on the available site properties topography and vegetation the deviations between the observations and emt vs estimates are considered estimates of the stochastic variations geostatistical analysis is used to analyze these variations then the emt vs model is generalized to simulate the stochastic variations this generalized model hereafter referred to as the probabilistic model introduces stochastic variability through the site properties that are supplied to the emt vs model the following section resources describes the study catchments and the existing emt vs model then section 3 soil moisture analysis presents the methodology and results of the geostatistical analysis section 4 model development shows the methodology and results for the generalized model finally section 5 conclusions summarizes the main conclusions from this study and discusses avenues for further research 2 resources 2 1 study sites soil moisture data are used from four catchments tarrawarra cache la poudre nerrigundah and satellite station tarrawarra and cache la poudre are used for model development because they have sampling locations that are dense enough to calculate reliable semivariograms for the geostatistical analysis additionally both catchments have enough sample dates to observe how the semivariograms change with the spatial average moisture content nerrigundah and satellite station have fewer sampling locations and or fewer observation dates so they are used for model evaluation the tarrawarra catchment western and grayson 1998 is in southern victoria australia 37 39 s and 145 26 e and has an approximate area of 10 5 ha the vegetation consists of perennial improved pastures but detailed vegetation data are unavailable the climate is sub humid with a mean annual precipitation of 820 mm the soil generally has a silty loam a horizon and a b horizon with higher clay content elevation data are available from a 5 m digital elevation model dem fig 1 a and the maximum elevation difference total relief is approximately 25 m soil moisture data are available on a 10 by 20 m grid at 454 locations these data were collected using a time domain reflectometer tdr in the top 30 cm of the soil western et al 1999 samples were taken on 13 dates from september 27 1995 to november 29 1996 and describe the typical range of conditions in this catchment each observation represents essentially an instantaneous soil moisture value sometime during the observation date the cache la poudre catchment lehman and niemann 2008 is near rustic colorado usa 40 41 56 n and 105 30 30 w and has an approximate area of 8 0 ha the climate is semiarid with a mean annual precipitation of 400 mm elevation data are available from a 15 m dem fig 1b and the total relief is approximately 118 m the catchment has aspect dependent vegetation with coniferous trees on the north facing hillslope and shrubs on the south facing hillslope fractional vegetation cover data generated from litter depth measurements and vertical photographs are available on the 15 m dem grid the soil is also aspect dependent with shallower depths and sandy composition on the south facing hillslope and a thicker mineral layer and more litter and organic matter on the north facing hillslope soil moisture data are available on the same 15 m grid at 350 locations these data were collected using a tdr in the top 5 cm of the soil samples were taken on nine dates from april 22 2008 to june 24 2008 and range from wet conditions immediately after storm events to very dry conditions the nerrigundah catchment walker et al 2001 is near dungog new south wales australia 32 19 s and 151 43 e and has an approximate area of 6 0 ha the vegetation consists of natural grasses the climate is sub humid with a mean annual precipitation of 1000 mm elevation data are available from a 20 m dem fig 1c and the total relief is approximately 38 m soil moisture data are available on the same 20 m grid at 238 locations these data were collected using a tdr in the top 15 cm of the soil walker et al 2001 samples were taken on 12 dates from august 27 1997 to september 22 1997 the satellite station catchment western et al 2004 is approximately 70 km north of auckland new zealand 36 24 s and 174 42 e and has an approximate area of 60 ha the vegetation is predominately pasture the climate is sub humid with a mean annual precipitation of 1 200 mm elevation data are available from a 40 m dem fig 1d and the total relief is approximately 80 m soil moisture data are available on the 40 m grid at 370 locations these data were collected using a tdr in the top 30 cm of the soil western et al 2004 samples were taken on six dates from march 25 1998 to october 30 1999 2 2 pre existing emt vs model the emt vs model uses an analytical expression to calculate fine resolution soil moisture patterns from temporally varying spatial average soil moisture values the model is constructed so that the fine resolution soil moisture patterns reproduce the provided spatial average soil moisture but include spatial variations fine resolution variations in soil moisture are inferred from fine resolution topographic data and fine resolution vegetation and soil data if available a detailed description of the emt vs model is presented by coleman and niemann 2013 and ranney et al 2015 so only a summary is provided here the emt vs model is based on the water balance for a soil layer whose upper limit is at the ground surface four processes can add or remove water from this layer infiltration f deep drainage g lateral flow l and evapotranspiration e assuming equilibrium at each time the water balance can be written 1 a fda a gda l a eda where a is the land area that is upslope from the edge of a fine resolution grid cell infiltration is described using a simple approach that accounts for interception by vegetation 2 f f 0 1 λ v where f 0 is the infiltration rate where the canopy is absent which does not need to be specified because it ultimately cancels out of the model λ is the interception efficiency of the vegetation and v is the fractional vegetation cover the infiltration model can also account for orographic precipitation and elevation dependent potential evapotranspiration cowley et al 2017 but those components are neglected here due to the small elevation ranges of the catchments deep drainage is described using darcy s law under the assumption that gravity controls the hydraulic gradient and using the campbell 1974 equation to estimate the unsaturated hydraulic conductivity specifically 3 g k s v θ ϕ γ v where k s v is vertical saturated hydraulic conductivity θ is the depth averaged volumetric soil moisture in the soil layer ϕ is porosity and γ v is the vertical pore disconnectedness index lateral flow is also described using darcy s law under the assumption that the lateral hydraulic gradient is a function of the topographic slope which is similar to topmodel beven and kirkby 1979 the campbell 1974 equation is again used to estimate the unsaturated hydraulic conductivity and anisotropy is allowed the thickness of the soil layer is modeled as a function of topographic curvature heimsath et al 1999 thus lateral flow is 4 l δ 0 κ min κ κ min c ι k s v θ ϕ γ h s ε where δ 0 is the soil layer thickness where topographic curvature is zero κ min is the minimum topographic curvature where the layer is present and κ is topographic curvature the variable c is the length of the fine resolution grid cell ι is the anisotropy of the saturated hydraulic conductivity γ h is the horizontal pore disconnectedness index s is topographic slope and ε is a parameter relating the horizontal hydraulic gradient to topographic slope the evapotranspiration et expression begins with a supplied spatial average potential et the potential et is partitioned into a potential evaporation and a potential transpiration using the fractional vegetation cover v it is also partitioned into radiation and aerodynamic terms using the priestley taylor assumption priestley and taylor 1972 spatial variations in solar insolation are included in the radiation terms using the potential solar radiation index prsi which depends on the topographic slope and aspect among other variables dingman 2002 the effects of vegetation shading on soil evaporation are also included the et expression is 5 e e p η v 1 v μ i p 1 α θ ϕ β r α 1 α θ ϕ β a where e p is the potential et i p is the psri η is the portion of transpiration that is derived from the soil layer μ is the shading effect on soil evaporation α is the priestly taylor coefficient minus one β r is the radiation et exponent and β a is the aerodynamic et exponent the soil moisture is determined from the water balance using a solution strategy from coleman and niemann 2013 first a set of analytical solutions is obtained for soil moisture under the assumption that each of the outflow terms in the water balance dominates then the final soil moisture estimate is determined by a weighted average of the analytical solutions where the weights are the magnitudes of the outflow terms in the water balance the final soil moisture estimate θ is 6 θ w g θ g w l θ l w r θ r w a θ a w g w l w r w a where θ g θ l θ r and θ a are the analytical soil moisture values if deep drainage lateral flow radiation et and aerodynamic et dominate respectively the variables w g w l w r and w a are the associated weights the analytical soil moisture values are 7 θ g θ ddi ddi 8 θ l θ lfi lfi 9 θ r θ rei rei 10 θ a θ aei aei where θ is the spatial average soil moisture ddi is the deep drainage index lfi is the lateral flow index rei is the radiation et index and aei is the aerodynamic et index the variables ddi lfi rei and aei are the spatial averages of the indices the indices are 11 ddi ϕ 1 λ v k s v 1 γ v 12 lfi ϕ 1 λ v δ 0 ι k s v 1 γ h a c s ε 1 γ h κ min κ min κ 1 γ h 13 rei ϕ 1 α e p 1 β r 1 i p 1 β r 1 λ v η v 1 v μ 1 β r 14 aei ϕ 1 α e p α 1 β a 1 λ v η v 1 v μ 1 β a spatial variations in ddi are produced by spatial variations in v and soil properties if fine resolution data are available to describe soil variations spatial variations in lfi are produced by variations in κ a and s and potentially vegetation and soil properties spatial variations in rei are produced by variations in i p and possibly vegetation and soil variations spatial variations in aei are produced by vegetation and soil variations if fine resolution data are available the weights are 15 w g θ ddi γ v 16 w l θ lfi γ h 17 w r θ rei β r 18 w a θ aei β a the weights vary in time due to temporal variations in θ for the present study fine resolution topographic and vegetation data are used as inputs at cache la poudre while only topographic data are used at the other catchments it is assumed that v 1 0 for these other catchments fine resolution soil data were not included due to data limitations ranney et al 2015 the spatial average soil moisture θ is calculated from the available point soil moisture observations on each date the remaining parameter values are from the calibrations performed by hoehn 2016 and hoehn et al 2017 table 1 in those calibrations the allowable parameter ranges were determined from catchment information that is relevant for each parameter e g soil and climate data within those ranges the parameter values were chosen to maximize the average nash sutcliffe coefficient of efficiency of the estimated soil moisture from all available dates 3 soil moisture analysis 3 1 analysis methodology the soil moisture observations from the study catchments are assumed to be the sum of a deterministic and a stochastic component the deterministic component is caused by soil moisture s dependence on topography and other fine resolution variables and can be estimated using the pre existing emt vs model the stochastic component represents variations around the deterministic component for any given date the observed stochastic component π obs can be estimated as 19 π obs θ obs θ where θ obs is the observed soil moisture pattern and θ is the emt vs model s estimated pattern π obs includes all variation that is unresolved by the deterministic downscaling and is an estimate of the true stochastic component in the soil moisture variation this approach assumes that the pre existing emt vs model successfully removes the deterministic dependence of θ obs on topographic and other catchment characteristics this assumption was checked by calculating the correlations between π obs and available catchment characteristics elevation contributing area slope psri and fractional vegetation cover and correlations between θ and π obs the magnitudes of the correlation coefficients averaged over all dates are below 0 10 for both catchments which suggests the model captures a large portion of the dependence nonetheless the calculation of π obs depends on the model used to estimate θ and other models are expected to produce different results the π obs patterns can be decomposed into temporally stable and unstable patterns the stable pattern is a time invariant stochastic pattern that contributes to π obs to some extent on every sample date the stable pattern π s o b s can be estimated as the temporal average of the observed stochastic patterns 20 π s o b s e π obs where e denotes the temporal average the unstable patterns π u o b s are the variations around the stable pattern on each date and can be estimated as 21 π u o b s π obs π s o b s the patterns for θ obs π obs π s o b s and π u o b s are analyzed using semivariograms this technique was introduced by matheron 1963 and has been previously applied to θ obs patterns de lannoy et al 2006 korres et al 2015 petrone et al 2004 western et al 1998 western et al 2004 however it has not been used to examine π obs π s o b s or π u o b s the sample semivariogram g s is calculated using 22 g s h 1 2 n h i j z i z j 2 where h is a lag or separation distance between two selected points in a catchment n is the number of pairs of points for each lag i and j are indices for the two locations separated by distance h and z i and z j are the values of the variable of interest at those two locations i e θ obs π obs π s o b s and π u o b s in the analyses below the semivariogram i e graph of g s as a function of h has three main properties the nugget range and sill the nugget is the y intercept of a semivariogram the range is the lag beyond which the semivariance becomes relatively constant and the sill is the value of that relatively constant semivariance the nugget is produced by spatially uncorrelated variability and can be caused by measurement error and or sub grid variability western et al 2004 the difference between the sill and the nugget the partial sill describes the contribution of spatially correlated variability the range is related to the correlation length an exponential semivariogram model with a nugget was fit to the sample semivariogram for each pattern using a weighted least squares method cressie 1985 the exponential form was selected because it usually fits sample semivariograms better than other models spherical circular etc mcbratney and webster 1986 western et al 2004 the exponential semivariogram g e has the form 23 g e h σ n 2 σ s 2 1 e h r where σ n 2 is the nugget σ s 2 is the partial sill r is the correlation length and the sill is equal to σ n 2 σ s 2 thus the nugget partial sill and correlation length of the sample semivariograms can be estimated by σ n 2 σ s 2 and r respectively 3 2 analysis results the semivariograms of θ obs and π obs were calculated for each date in the soil moisture datasets and then averaged between dates the temporal average semivariograms of θ obs and π obs are shown for tarrawarra in fig 2 a and for cache la poudre 2b all figures in this section also show modeling results which are variables that include asterisks but those results are discussed later the θ obs semivariogram exhibits both a nonzero nugget and partial sill at both catchments if the soil moisture patterns consistently conformed to fractal geometry then the semivariograms would follow power functions over a wide range of separation distances before reaching a sill burrough 1983 green and erskine 2004 because well defined sills are reached at a small separation distances in our study the soil moisture patterns are typically not well described by a fractal in contrast with patterns observed at coarser resolutions 1 km2 and larger domains 1000 s of km2 by kim and barros 2002a b the sill at tarrawarra is larger than cache la poudre furthermore the nugget comprises a much smaller portion of the sill at tarrawarra 13 than at cache la poudre 55 which suggests that correlated variability plays a much larger role in θ obs at tarrawarra than at cache la poudre the correlation lengths are similar at both catchments about 30 m at tarrawarra and about 40 m at cache la poudre western et al 1998 used visual inspection to estimate the semivariogram properties for θ obs at tarrawarra they estimated that the nugget comprises 29 of the sill and found an average correlation length of 50 m rogowski and engman 2006 found correlation lengths from 120 m to 180 m for their remotely sensed soil moisture dataset the contribution of the stochastic component to the overall soil moisture observations can be examined by comparing the sills of π obs and θ obs at each catchment the sill for π obs is approximately 64 of the sill for θ obs at tarrawarra and about 84 at cache la poudre thus the stochastic variations are important at both catchments but more so at cache la poudre at both catchments the nugget for π obs is roughly half of its sill it is 47 of the sill at tarrawarra and 56 of the sill at cache la poudre thus both catchments have roughly equal contributions from uncorrelated and correlated variability the average correlation length is about 34 m at tarrawarra and about 21 m at cache la poudre at tarrawarra the correlation lengths of π obs range from 19 to 135 m for individual dates compared to 18 to 65 m for θ obs while at cache la poudre they range from 9 to 31 m compared to 10 to 71 m for θ obs these characteristic lengths may be compared with a break in scaling invariance observed by kim and barros 2002a at a length around 3 200 m or an area of 10 km2 fig 2c and d show the semivariograms of π s o b s at the two catchments the sill for π s o b s is a substantial portion of the sill for π obs at both catchments 30 at tarrawarra and 41 at cache la poudre thus the stable pattern accounts for a sizeable part of the overall stochastic variability the higher percentage at cache la poudre suggests that the stable stochastic pattern plays a larger role at this catchment at tarrawarra the nugget for π s o b s is 14 of the sill and the correlation length is approximately 31 m at cache la poudre the nugget for π s o b s is 48 of the sill and the correlation length is approximately 25 m thus uncorrelated variability plays a larger relative role in π s o b s for cache la poudre than tarrawarra fig 2c and d also show the temporal average semivariograms of π u o b s at the two catchments at tarrawarra the nugget for π u o b s is 62 of the sill and the correlation length is approximately 45 m at cache la poudre the nugget for π u o b s is 48 of the sill and the correlation length is approximately 14 m thus in contrast to the stable patterns uncorrelated variation plays a smaller relative role in π u o b s for cache la poudre than tarrawarra fig 3 plots the semivariogram properties of π obs on each date against the associated spatial average soil moisture θ the nugget remains relatively constant at tarrawarra but it increases with θ at cache la poudre the correlation length of π obs exhibits no dependence on θ at either catchment western et al 2004 found that the correlation length of soil moisture θ obs increases with θ at multiple catchments the present results suggest that those increasing trends are due to the deterministic component rather than the stochastic component the partial sill for π obs increases with θ at tarrawarra which indicates a greater contribution from correlated variation on wetter dates however the partial sill remains fairly constant at cache la poudre western et al 2004 reported that the variance of θ obs increases with θ at multiple catchments similar behavior is implied by the nuggets and partial sills of π obs at both catchments however the increasing variance is due to an increasing contribution from spatially correlated variation at tarrawarra and an increasing contribution from spatially uncorrelated variation at cache la poudre fig 4 plots the semivariogram properties of π u o b s on each date against the associated θ the nugget exhibits no dependence on θ at either catchment indicating that the uncorrelated variance in π u o b s remains fairly constant similarly the correlation lengths exhibit no clear relationship with θ at either catchment for two dates at tarrawarra the exponential semivariogram fits the sample semivariogram poorly to accommodate for this anomaly the 7 largest lags of the 23 total were excluded when fitting the exponential semivariogram this modification produced more reasonable semivariogram properties for one date but an unusually large correlation length 197 m was still estimated for the other date this value falls beyond the limits of the graph in fig 4 the partial sill increases with θ at both catchments which indicates a greater contribution from correlated variance during wetter conditions overall these results suggest that the behavior of the unstable stochastic patterns is similar at both catchments the differences between the semivariogram properties in figs 3 and 4 reveal the influence of π s o b s on the stochastic patterns at cache la poudre for example subtracting π s o b s from π obs results in a larger nugget in π u o b s compared to π obs for dry conditions in contrast this subtraction tends to decrease the nugget in π u o b s for wet conditions this example demonstrates how the combination of a constant stable pattern and the unstable patterns can decrease the nugget of π obs on drier dates and increases the nugget on wetter dates thus at cache la poudre the nugget of π obs has a positive relationship with θ while the nugget of π u o b s remains relatively constant 4 model development 4 1 probabilistic model methodology the generalization of the emt vs model introduces stochastic variations by treating some model inputs as random variables although many inputs might be considered random variables the goal is to reproduce the observed stochastic features using as few random variables as possible thus stochastic variations are included in only three ways porosity soil moisture disequilibrium and measurement error these three were selected based on comparisons to the observed semivariograms and literature that has demonstrated their variability porosity has been shown to vary substantially at the catchment scale bakr et al 1978 a stochastic porosity ϕ is included in the model by combining the existing calibrated porosity value ϕ with a stochastic perturbation p 24 ϕ ϕ 1 p because porosity is temporally constant under most conditions p is considered a stable stochastic pattern thus a single pattern is generated at each catchment and used on every sample date studies have also demonstrated that porosity can have both spatial correlation bakr 1976 wang and shao 2013 and sub grid variability duffera et al 2007 thus p is constructed using a correlated random field p c and an uncorrelated random field p u 25 p p c p u both p c and p u are assumed to be normally distributed with zero mean and spatially constant variances heteroscedasticity of the π obs π s o b s and π u o b s patterns was explored but no consistent behavior was observed for the two catchments p c is assumed to have a separable exponential correlation function and is generated using fast sequential simulation dolloff and doucette 2014 generating fields of p c requires specification of its standard deviation σ p c and correlation length ρ p similarly generating fields of p u requires specification of its standard deviation σ p u the pre existing emt vs model calculates soil moisture by assuming equilibrium between the inflows and outflows of the soil layer in reality these flows are usually unbalanced and soil moisture is dynamic e g gaur and mohanty 2016 to allow deviations from equilibrium the probabilistic model includes a stochastic variable specifically when the equilibrium condition is imposed the equilibrium soil moisture is considered stochastic θ and assumed to be 26 θ θ 1 d where d is a random field that characterizes the deviations of θ from equilibrium because such deviations vary in time d is considered an unstable stochastic variable so different patterns are generated for each date to maintain parsimony d is assumed to contain only a correlated pattern similar to porosity d is assumed to be normally distributed with zero mean and spatially constant variance thus generating fields of d requires specification of its standard deviation σ d and correlation length ρ d including the porosity perturbation p and the deviation from equilibrium d in the emt vs model development produces new stochastic indices ddi lfi rei and aei 27 ddi ϕ 1 p 1 d 1 λ v k s v 1 γ v 28 lfi ϕ 1 p 1 d 1 λ v δ 0 ι k s v 1 γ h a c s ε 1 γ h κ min κ min κ 1 γ h 29 rei ϕ 1 p 1 d 1 α e p 1 β r 1 i p 1 β r 1 λ v η v 1 v μ 1 β r 30 aei ϕ 1 p 1 d 1 α e p α 1 β a 1 λ v η v 1 v μ 1 β a these stochastic indices are then used to calculate new stochastic soil moisture values using equations 7 10 θ g θ l θ r and θ a new stochastic weights are calculated using equations 15 18 w g w l w r and w a in addition to the natural stochastic variations the soil moisture observations also include measurement errors coleman and niemann 2013 western and grayson 1998 measurement errors must be simulated in order for the model to reproduce the properties of the observed soil moisture patterns measurement errors e are included by revising equation 6 to become 31 θ w g θ g w l θ l w r θ r w a θ a w g w l w r w a e tdr measurement errors do not depend on spatial average soil moisture roth et al 1990 so equation 31 assumes that the measurement errors are additive the measurement errors differ on each sampling date so e is considered temporally unstable and different patterns are generated for each date measurement error is also expected to be independent between sampling locations so e is considered an uncorrelated random field thus generating fields of e requires only specification of its standard deviation σ e in the end the probabilistic model introduces six new time invariant parameters σ p c ρ p σ p u σ d ρ d and σ e that must be estimated before soil moisture simulations can be generated for tarrawarra and cache la poudre these parameters are estimated using figs 3 and 4 the probabilistic model s stochastic component π stable pattern π s and unstable patterns π u are determined based on the same procedure used on the observations 32 π θ θ 33 π s e π 34 π u π π s to produce reliable semivariograms 2000 model realizations were generated for each date and their semivariograms were averaged the parameters were manually calibrated to minimize the root mean squared error rmse between the observed and modeled semivariogram properties specifically the parameters associated with unstable patterns σ d ρ d and σ e were first adjusted to minimize rmse between π u o b s and π u then the parameters associated with stable patterns σ p c ρ p and σ p u were adjusted to minimize rmse between π obs and π the calibrated parameters for the probabilistic model are shown in table 2 it is worth noting that the calibrated values of σ e are between 0 018 and 0 019 which are similar to the estimate of 0 014 from repeated measurements of soil moisture within small areas of tarrawarra and other sites wilson et al 2004 the probabilistic model also allows calculation of confidence limits for the emt vs model s estimated soil moisture θ for each fine resolution grid cell all 2 000 realizations of π were sorted from smallest to largest and the empirical cumulative distribution function cdf was computed using the plotting position formula from cunnane 1978 the desired quantiles are computed by linearly interpolating between the cdf values that are represented in the dataset 4 2 calibrated model results the temporal average semivariograms for θ and π are shown for the two catchments in fig 2a and b for both soil moisture and its stochastic component the probabilistic model reproduces the observed nugget correlation length and partial sill at both catchments reproducing the nugget and partial sill indicates that the probabilistic model includes the correct amounts of uncorrelated and correlated variations respectively the reproduction of the correlation length suggests that the probabilistic model includes the appropriate correlation lengths in its correlated patterns the semivariograms for π s and π u are shown for the two catchments in fig 2c and d the probabilistic model closely approximates the contribution of the stable pattern to the overall stochastic component 31 at tarrawarra and 40 at cache la poudre for the probabilistic model compared to 30 and 41 respectively for the observations the probabilistic model also closely approximates the observed semivariogram shapes at tarrawarra for example the nugget for π s is 19 of its sill and the correlation length is approximately 35 m compared 14 and 31 m respectively for π s o b s at tarrawarra the nugget for π u is 62 of its sill and the correlation length is approximately 41 m compared to 62 and 45 m respectively for π u o b s overall these results indicate that the probabilistic model reproduces the semivariogram features of both the stable and unstable patterns fig 3 plots the semivariogram properties of π on each date against the associated θ at tarrawarra the probabilistic model produces a relatively constant nugget which is also seen for the observations for the probabilistic model the constant nugget is caused by e and its additive relationship with θ which implies that the contribution of measurement error remains constant as θ changes the measurement error term enters the final soil moisture equation additively equation 31 and each analytical soil moisture value in the same equation depends on θ equations 7 10 at cache la poudre the probabilistic model reproduces the positive trend between the nugget and θ this trend primarily results from p u and its multiplicative relationship with θ equations 25 and 27 30 as θ increases uncorrelated variations in porosity produce a larger nugget in π for both catchments the modeled correlation length does not change with θ which is consistent with the observations the constant correlation length is determined by the prescribed correlation lengths of the stochastic variations for both catchments the probabilistic model produces a positive trend between partial sill and θ this trend results from p c and d and their multiplicative relationships with θ as θ increases correlated variations in porosity and disequilibrium produce a larger partial sill in π this behavior matches the observations at tarrawarra but not at cache la poudre fig 4 plots the semivariogram properties of π u on each date against the associated θ at both catchments the probabilistic model produces a relatively constant nugget as θ changes which matches the observations this behavior is due to the influence of e and its additive relationship with θ at both catchments the probabilistic model reproduces the relatively constant correlation lengths at both catchments the probabilistic model is also able to reproduce the positive trend between partial sill and θ this trend is primarily due to the influence of d and its multiplicative relationship with θ as θ increases correlated variations in disequilibrium produce a larger partial sill in π u examples of the observed soil moisture pattern θ obs the pre existing emt vs model estimate θ and the probabilistic model s simulated soil moisture θ are shown in fig 5 other dates are shown in the supplemental materials the pre existing model θ reproduces the observed dependence on topography see fig 1 and vegetation at tarrawarra the wettest locations tend to occur in the valley bottoms where water accumulates due to lateral flow at cache la poudre they tend to occur on the north facing hillslopes which are oriented away from the sun and shaded by thicker vegetation cover ranney et al 2015 the probabilistic model maintains much of that dependence but also produces patterns that are more visually similar to the observations however the probabilistic model is not able to reproduce all observed tendencies at tarrawarra for example the observations have contiguous wet locations in the valleys while the probabilistic model has less continuity of these features additionally the observations have a dry patch on the north facing hillslope that is not fully reproduced by the probabilistic model the probabilistic model s inability to reproduce these features may be caused in part by the use of homogeneous random fields as expected the probabilistic model does not produce wet and dry conditions at exactly the right locations but the tendencies of the modeled patterns are very similar to the observations histograms of θ obs θ and θ for dry intermediate and wet dates at tarrawarra and cache la poudre are shown in fig 6 the pre existing emt vs model does not reproduce the observed histograms or the extreme values of soil moisture in the catchments the probabilistic model is able to reproduce the histogram shape on all three dates at both catchments fig 7 plots the percentage of the soil moisture observations from all dates that fall within the confidence intervals y axis as a function of the selected confidence level x axis at tarrawarra too many observations fall within the confidence intervals when the selected confidence level is low if the selected confidence level is 50 for example about 56 of the observations fall within the model s interval this result implies that the modeled soil moisture distribution has a somewhat different shape than the observed distribution which could arise from the use of normal distributions and or the assumed homogeneity of the stochastic patterns at cache la poudre the confidence interval error is less than 2 for all confidence levels considered 4 3 uncalibrated model results the previous section showed that the probabilistic model can reproduce nearly all the observed statistical properties if the model is calibrated with local soil moisture observations in many practical circumstances however sufficient data may not be available to allow catchment specific calibration of the new parameters this section examines the performance if the model is applied to the nerrigundah and satellite station catchments without local calibration of the new probabilistic parameters instead these parameters which produce the stable and unstable stochastic variations are estimated by taking the average of the calibrated parameters at tarrawarra and cache la poudre see average columns in table 2 one could alternatively use the parameters from a single catchment but the averages are expected to be less region specific than the parameters from a single catchment the locally calibrated parameters for the pre existing emt vs model were still used for each catchment table 1 example soil moisture patterns θ obs θ and θ are shown in fig 8 similar to tarrawarra and cache la poudre the pre existing emt vs model reproduces the dependence on topography see fig 1 the probabilistic model maintains much of that dependence but also produces patterns that are more visually similar to the observations however at satellite station the observed pattern exhibits more spatially continuous wet locations in the valleys than the pattern produced by the probabilistic model at nerrigundah a large dry region occurs towards the top of the figure for the observations while the probabilistic model produces only smaller dry regions histograms of θ obs θ and θ for dry intermediate and wet dates at nerrigundah and satellite station are shown in fig 9 the pre existing emt vs model again does not reproduce the observed histograms of soil moisture and it does not capture the extreme values of soil moisture in the catchments the probabilistic model better approximates the histogram shapes for all cases shown the performance of the probabilistic model confidence intervals is shown in fig 10 at nerrigundah the probabilistic model consistently underestimates the confidence interval because it underestimates the variance of stochastic component at this site at satellite station the confidence intervals are relatively accurate for confidence levels smaller than about 80 above this level the confidence interval is underestimated overall the results suggest that the average parameter values from tarrawarra and cache la poudre provide reasonable approximations of the stochastic variations at the other catchments the reasons for and limits to such transferability are not clear svoray and shoshany 2004 suggested that stochastic variations in soil characteristics can arise from extrinsic factors other variables or intrinsic factors aspects of the variable itself it is possible that the hillslope size affects the correlation lengths in the porosity and disequilibrium patterns so similarity in the hillslope sizes between catchments might produce similarity in the correlation lengths it is also possible that the limited range over which porosity can realistically vary constrains the standard deviations for both porosity and disequilibrium however further study is needed to test these speculations 5 conclusions the primary objectives of this study were 1 to characterize the stochastic variability of soil moisture at the catchment scale and 2 to develop a downscaling model that reproduces the observed statistical features of soil moisture the stochastic variations in soil moisture were estimated by removing the deterministic dependence on site properties topography and vegetation from soil moisture observations using the emt vs downscaling model the stochastic variations were then decomposed into a stable pattern that can be present to some extent on every date and unstable patterns that vary through time semivariograms were then used to analyze each of those patterns in the proposed probabilistic model stochastic variations were introduced through porosity perturbations deviations from equilibrium moisture and measurement errors the following conclusions can be made from the results 1 the stochastic component of soil moisture represents a substantial portion of the overall soil moisture variation in the analyzed catchments the sill of the stochastic component is on average 64 and 84 of the sill of soil moisture at tarrawarra and cache la poudre respectively thus a majority of the variation at both catchments can be considered stochastic 2 the stochastic component exhibits non trivial semivariogram features i e a nonzero nugget correlation length and partial sill in the analyzed catchments the presence of a nonzero nugget and partial sill indicates that the stochastic component includes both correlated and uncorrelated patterns at both catchments the nugget is on average about half of the total sill which implies that the correlated and uncorrelated patterns contribute about equal variation on average 3 the semivariogram of the stochastic component also depends on the spatial average soil moisture for the datasets considered at tarrawarra the nugget remains relatively constant while the partial sill increases with spatial average soil moisture at cache la poudre the nugget increases with spatial average soil moisture while the partial sill remains relatively constant the correlation length remains approximately constant at both catchments 4 the stochastic variations also include a temporally stable pattern with substantial variability in both catchments the sill of the stable pattern is 30 and 41 of the sill of the stochastic component at tarrawarra and cache la poudre respectively the stable patterns at both catchments also exhibit nonzero nuggets and partial sills which indicate contributions from both correlated and uncorrelated patterns 5 the semivariograms of the unstable patterns depend on the spatial average soil moisture and this dependence is similar at both catchments in particular the nugget and the correlation length remain relatively constant while the partial sill increases with spatial average soil moisture 6 the probabilistic downscaling model is able to reproduce nearly all the observed statistical features for the catchments where its stochastic parameters i e the standard deviations and correlation lengths were calibrated specifically it reproduces the semivariograms of the soil moisture stochastic component stable pattern and unstable patterns it also reproduces the appropriate dependencies on the spatial average soil moisture aside from the partial sill of the stochastic component at cache la poudre in addition the probabilistic model adequately reproduces the soil moisture histograms for both catchments at low confidence levels the probabilistic model s confidence intervals can include as much as 6 too many observations i e the estimated intervals are too wide however the intervals become more accurate for larger confidence levels 7 the probabilistic model provides better statistical results than the pre existing emt vs model when its stochastic parameters are not calibrated to local observations for both catchments the soil moisture histograms and confidence intervals remain relatively accurate without calibration thus the probabilistic model may be able to approximate the overall soil moisture frequency distribution without requiring large local soil moisture datasets overall the probabilistic model performs well for these small catchments where the soil moisture patterns depend on topographic and vegetation characteristics and the soil moisture patterns do not display fractal behavior however the model may not apply directly to coarser resolutions and larger regions previous studies have shown that such soil moisture patterns exhibit multifractal properties kim and barros 2002a 2002b which would not be reproduced by the proposed model in its current form four specific avenues are open for future research first similar analyses should be performed using additional small catchments the physical factors that control the stochastic model parameters remain unknown thus these parameters currently cannot be estimated without calibration if additional catchments were analyzed and compared to the present study the controlling factors might become clearer second similar analyses could be performed using alternative models to remove the dependence on catchment characteristics the calculated stochastic component depends on the selected model so some differences are expected if a different model were used third the performance of geostatistical methods and multifractal methods could be compared for both small and large regions fourth a method could be developed that includes both the fine scale patterns of variation that are considered in the present analysis and the coarse scale patterns of variation studied by others as suggested by vinnikov et al 1999 such a method would describe the statistical properties of soil moisture across a very wide range of spatial scales and extents credit authorship contribution statement jordan p deshon methodology formal analysis investigation validation visualization writing original draft jeffrey d niemann funding acquisition conceptualization methodology supervision writing review editing timothy r green validation writing review editing andrew s jones funding acquisition validation writing review editing peter j grazaitis funding acquisition writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we gratefully acknowledge the united states army research laboratory for its financial support through the small business innovation research program partial support was also provided by the usda national institute of food and agriculture hatch project 1009616 we also thank two anonymous reviewers and andrew western for their help improving this manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124711 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5524,many applications require fine resolution soil moisture maps that exhibit realistic statistical properties e g spatial variance and correlation existing downscaling models can estimate soil moisture based on its dependence on topography vegetation and soil characteristics however observed soil moisture patterns also contain stochastic variations around such estimates the objectives of this research are to perform a geostatistical analysis of the stochastic variations in soil moisture and to develop a downscaling model that reproduces the observed statistical features while including the dependence on topography vegetation and soil properties extensive soil moisture observations from two catchments 8 0 and 10 5 ha are used for the geostatistical analysis and model development and two other catchments 6 0 and 60 ha are used for model evaluation the equilibrium moisture from topography vegetation and soil emt vs model is used to estimate soil moisture and the difference between the point measurements and the emt vs estimates are considered to be the stochastic variations the stochastic variations contain a temporally stable pattern along with temporally unstable patterns all of these patterns include spatially correlated and uncorrelated variations moreover the spatial variance of the stochastic patterns increases in absolute terms with the spatial average moisture content the emt vs model can reproduce the observed statistical features if it is generalized to include stochastic deviations from equilibrium soil moisture variations in porosity and measurement errors keywords soil moisture downscaling geostatistical analysis semivariograms variability spatial statistics 1 introduction fine resolution maps 10 30 m grid cells of volumetric water content soil moisture are important for many applications they can improve agricultural production holzman et al 2014 phillips et al 2014 vector borne infectious disease outbreak prediction montosi et al 2012 patz et al 1998 weather and climate modeling pal and eltahir 2001 seuffert et al 2002 forest fire prediction bartsch et al 2009 and crop yield quantification de wit and van diepen 2007 green and erskine 2004 for some applications it is particularly important for the soil moisture maps to reproduce the statistical properties of the observed patterns for example accurate assessment of spatial and temporal soil moisture variability supports crop and water management chen et al 2011 in addition wood 1997 demonstrated that proper characterization of soil moisture s spatial variability is important for accurate estimation of coarse resolution evaporation during different atmospheric states both low and high demands moreover proper characterization of the soil moisture probability density function pdf is useful for improving simulation of sub grid processes in land surface models evaluating remotely sensed soil moisture data and estimating fine scale hydrologic ecological and biogeochemical fluxes ryu and famiglietti 2005 because soil moisture is a principle variable in determining soil strength horn and fleige 2003 reproducing observed ranges of soil moisture is also vital for assessing vehicle trafficability flores et al 2014 vehicle impacts shoop et al 2005 and soil damage vero et al 2014 several studies have characterized the statistical properties of soil moisture patterns including the pdf spatial variability and correlation structure various pdfs have been evaluated by their ability to describe the observed spatial distribution of soil moisture for large regions a beta distribution ryu and famiglietti 2005 and a lognormal distribution choi and jacobs 2007 can fit the sample distributions well during dry conditions however these same studies concluded that a normal distribution fits the data better when considering the full range of conditions for small catchments a normal distribution has also been found to adequately describe the pdf of soil moisture for intermediate conditions while the distribution becomes skewed in very wet or very dry periods western et al 2002 in addition the spatial variability of soil moisture has been demonstrated to change with the spatial average soil moisture famiglietti et al 2008 some studies have reported increasing spatial variability with increasing spatial average de lannoy et al 2006 famiglietti et al 1998 western and grayson 1998 while others have reported an inverse relationship brocca et al 2007 famiglietti et al 1999 hupet and vanclooster 2004 still others observed maximum variability at intermediate values of the average rosenbaum et al 2012 owe et al 1982 vereecken et al 2007 also the spatial correlation length of soil moisture varies between regions and can occasionally vary temporally within the same region for example studies have found increasing brocca et al 2007 decreasing western et al 1998 and site dependent western et al 2004 relationships between correlation length and spatial average soil moisture fine resolution maps of soil moisture can be produced by downscaling coarse resolution data coarse resolution soil moisture is globally available from various resources including the advanced microwave scanning radiometer eos amsr e njoku et al 2003 soil moisture and ocean salinity smos kerr et al 2010 and soil moisture active passive smap satellite sensors entekhabi et al 2010 reichle et al 2017 geoinformation based downscaling methods use a combination of fine resolution topography vegetation and soil data to infer fine scale variations in soil moisture busch et al 2012 coleman and niemann 2013 pellenq et al 2003 ranney et al 2015 nasta et al 2018 these methods rely on known relationships between soil moisture and topography grayson et al 1997 western et al 1999 wilson et al 2005 vegetation ranney et al 2015 and soil characteristics famiglietti et al 1998 takagi and lin 2011 the soil moisture patterns generated by these methods reproduce the spatial structures implied by the site characteristics but they have not been shown to reproduce the statistical properties of the observed soil moisture patterns other downscaling methods specifically aim to reproduce soil moisture s statistical properties for example multifractal interpolation techniques have been proposed to downscale soil moisture kim and barros 2002b kumar 1999 mascaro et al 2010 while these methods can approximate the observed soil moisture variability and correlation structure at multiple spatial scales they have been used to downscale soil moisture to spatial resolutions 200 825 m that may be too coarse for some applications the primary objectives of this research are 1 to characterize the stochastic variability of soil moisture within catchments and 2 to develop a downscaling model that reproduces the observed statistical features of soil moisture while including soil moisture s dependence on topography vegetation and soil characteristics extensive ground based soil moisture measurements from two catchments tarrawarra and cache la poudre are used for the stochastic analysis and model development and two other catchments nerrigundah and satellite station are used for model evaluation the equilibrium moisture from topography vegetation and soil emt vs model ranney et al 2015 grieco et al 2018 is used to estimate soil moisture based on the available site properties topography and vegetation the deviations between the observations and emt vs estimates are considered estimates of the stochastic variations geostatistical analysis is used to analyze these variations then the emt vs model is generalized to simulate the stochastic variations this generalized model hereafter referred to as the probabilistic model introduces stochastic variability through the site properties that are supplied to the emt vs model the following section resources describes the study catchments and the existing emt vs model then section 3 soil moisture analysis presents the methodology and results of the geostatistical analysis section 4 model development shows the methodology and results for the generalized model finally section 5 conclusions summarizes the main conclusions from this study and discusses avenues for further research 2 resources 2 1 study sites soil moisture data are used from four catchments tarrawarra cache la poudre nerrigundah and satellite station tarrawarra and cache la poudre are used for model development because they have sampling locations that are dense enough to calculate reliable semivariograms for the geostatistical analysis additionally both catchments have enough sample dates to observe how the semivariograms change with the spatial average moisture content nerrigundah and satellite station have fewer sampling locations and or fewer observation dates so they are used for model evaluation the tarrawarra catchment western and grayson 1998 is in southern victoria australia 37 39 s and 145 26 e and has an approximate area of 10 5 ha the vegetation consists of perennial improved pastures but detailed vegetation data are unavailable the climate is sub humid with a mean annual precipitation of 820 mm the soil generally has a silty loam a horizon and a b horizon with higher clay content elevation data are available from a 5 m digital elevation model dem fig 1 a and the maximum elevation difference total relief is approximately 25 m soil moisture data are available on a 10 by 20 m grid at 454 locations these data were collected using a time domain reflectometer tdr in the top 30 cm of the soil western et al 1999 samples were taken on 13 dates from september 27 1995 to november 29 1996 and describe the typical range of conditions in this catchment each observation represents essentially an instantaneous soil moisture value sometime during the observation date the cache la poudre catchment lehman and niemann 2008 is near rustic colorado usa 40 41 56 n and 105 30 30 w and has an approximate area of 8 0 ha the climate is semiarid with a mean annual precipitation of 400 mm elevation data are available from a 15 m dem fig 1b and the total relief is approximately 118 m the catchment has aspect dependent vegetation with coniferous trees on the north facing hillslope and shrubs on the south facing hillslope fractional vegetation cover data generated from litter depth measurements and vertical photographs are available on the 15 m dem grid the soil is also aspect dependent with shallower depths and sandy composition on the south facing hillslope and a thicker mineral layer and more litter and organic matter on the north facing hillslope soil moisture data are available on the same 15 m grid at 350 locations these data were collected using a tdr in the top 5 cm of the soil samples were taken on nine dates from april 22 2008 to june 24 2008 and range from wet conditions immediately after storm events to very dry conditions the nerrigundah catchment walker et al 2001 is near dungog new south wales australia 32 19 s and 151 43 e and has an approximate area of 6 0 ha the vegetation consists of natural grasses the climate is sub humid with a mean annual precipitation of 1000 mm elevation data are available from a 20 m dem fig 1c and the total relief is approximately 38 m soil moisture data are available on the same 20 m grid at 238 locations these data were collected using a tdr in the top 15 cm of the soil walker et al 2001 samples were taken on 12 dates from august 27 1997 to september 22 1997 the satellite station catchment western et al 2004 is approximately 70 km north of auckland new zealand 36 24 s and 174 42 e and has an approximate area of 60 ha the vegetation is predominately pasture the climate is sub humid with a mean annual precipitation of 1 200 mm elevation data are available from a 40 m dem fig 1d and the total relief is approximately 80 m soil moisture data are available on the 40 m grid at 370 locations these data were collected using a tdr in the top 30 cm of the soil western et al 2004 samples were taken on six dates from march 25 1998 to october 30 1999 2 2 pre existing emt vs model the emt vs model uses an analytical expression to calculate fine resolution soil moisture patterns from temporally varying spatial average soil moisture values the model is constructed so that the fine resolution soil moisture patterns reproduce the provided spatial average soil moisture but include spatial variations fine resolution variations in soil moisture are inferred from fine resolution topographic data and fine resolution vegetation and soil data if available a detailed description of the emt vs model is presented by coleman and niemann 2013 and ranney et al 2015 so only a summary is provided here the emt vs model is based on the water balance for a soil layer whose upper limit is at the ground surface four processes can add or remove water from this layer infiltration f deep drainage g lateral flow l and evapotranspiration e assuming equilibrium at each time the water balance can be written 1 a fda a gda l a eda where a is the land area that is upslope from the edge of a fine resolution grid cell infiltration is described using a simple approach that accounts for interception by vegetation 2 f f 0 1 λ v where f 0 is the infiltration rate where the canopy is absent which does not need to be specified because it ultimately cancels out of the model λ is the interception efficiency of the vegetation and v is the fractional vegetation cover the infiltration model can also account for orographic precipitation and elevation dependent potential evapotranspiration cowley et al 2017 but those components are neglected here due to the small elevation ranges of the catchments deep drainage is described using darcy s law under the assumption that gravity controls the hydraulic gradient and using the campbell 1974 equation to estimate the unsaturated hydraulic conductivity specifically 3 g k s v θ ϕ γ v where k s v is vertical saturated hydraulic conductivity θ is the depth averaged volumetric soil moisture in the soil layer ϕ is porosity and γ v is the vertical pore disconnectedness index lateral flow is also described using darcy s law under the assumption that the lateral hydraulic gradient is a function of the topographic slope which is similar to topmodel beven and kirkby 1979 the campbell 1974 equation is again used to estimate the unsaturated hydraulic conductivity and anisotropy is allowed the thickness of the soil layer is modeled as a function of topographic curvature heimsath et al 1999 thus lateral flow is 4 l δ 0 κ min κ κ min c ι k s v θ ϕ γ h s ε where δ 0 is the soil layer thickness where topographic curvature is zero κ min is the minimum topographic curvature where the layer is present and κ is topographic curvature the variable c is the length of the fine resolution grid cell ι is the anisotropy of the saturated hydraulic conductivity γ h is the horizontal pore disconnectedness index s is topographic slope and ε is a parameter relating the horizontal hydraulic gradient to topographic slope the evapotranspiration et expression begins with a supplied spatial average potential et the potential et is partitioned into a potential evaporation and a potential transpiration using the fractional vegetation cover v it is also partitioned into radiation and aerodynamic terms using the priestley taylor assumption priestley and taylor 1972 spatial variations in solar insolation are included in the radiation terms using the potential solar radiation index prsi which depends on the topographic slope and aspect among other variables dingman 2002 the effects of vegetation shading on soil evaporation are also included the et expression is 5 e e p η v 1 v μ i p 1 α θ ϕ β r α 1 α θ ϕ β a where e p is the potential et i p is the psri η is the portion of transpiration that is derived from the soil layer μ is the shading effect on soil evaporation α is the priestly taylor coefficient minus one β r is the radiation et exponent and β a is the aerodynamic et exponent the soil moisture is determined from the water balance using a solution strategy from coleman and niemann 2013 first a set of analytical solutions is obtained for soil moisture under the assumption that each of the outflow terms in the water balance dominates then the final soil moisture estimate is determined by a weighted average of the analytical solutions where the weights are the magnitudes of the outflow terms in the water balance the final soil moisture estimate θ is 6 θ w g θ g w l θ l w r θ r w a θ a w g w l w r w a where θ g θ l θ r and θ a are the analytical soil moisture values if deep drainage lateral flow radiation et and aerodynamic et dominate respectively the variables w g w l w r and w a are the associated weights the analytical soil moisture values are 7 θ g θ ddi ddi 8 θ l θ lfi lfi 9 θ r θ rei rei 10 θ a θ aei aei where θ is the spatial average soil moisture ddi is the deep drainage index lfi is the lateral flow index rei is the radiation et index and aei is the aerodynamic et index the variables ddi lfi rei and aei are the spatial averages of the indices the indices are 11 ddi ϕ 1 λ v k s v 1 γ v 12 lfi ϕ 1 λ v δ 0 ι k s v 1 γ h a c s ε 1 γ h κ min κ min κ 1 γ h 13 rei ϕ 1 α e p 1 β r 1 i p 1 β r 1 λ v η v 1 v μ 1 β r 14 aei ϕ 1 α e p α 1 β a 1 λ v η v 1 v μ 1 β a spatial variations in ddi are produced by spatial variations in v and soil properties if fine resolution data are available to describe soil variations spatial variations in lfi are produced by variations in κ a and s and potentially vegetation and soil properties spatial variations in rei are produced by variations in i p and possibly vegetation and soil variations spatial variations in aei are produced by vegetation and soil variations if fine resolution data are available the weights are 15 w g θ ddi γ v 16 w l θ lfi γ h 17 w r θ rei β r 18 w a θ aei β a the weights vary in time due to temporal variations in θ for the present study fine resolution topographic and vegetation data are used as inputs at cache la poudre while only topographic data are used at the other catchments it is assumed that v 1 0 for these other catchments fine resolution soil data were not included due to data limitations ranney et al 2015 the spatial average soil moisture θ is calculated from the available point soil moisture observations on each date the remaining parameter values are from the calibrations performed by hoehn 2016 and hoehn et al 2017 table 1 in those calibrations the allowable parameter ranges were determined from catchment information that is relevant for each parameter e g soil and climate data within those ranges the parameter values were chosen to maximize the average nash sutcliffe coefficient of efficiency of the estimated soil moisture from all available dates 3 soil moisture analysis 3 1 analysis methodology the soil moisture observations from the study catchments are assumed to be the sum of a deterministic and a stochastic component the deterministic component is caused by soil moisture s dependence on topography and other fine resolution variables and can be estimated using the pre existing emt vs model the stochastic component represents variations around the deterministic component for any given date the observed stochastic component π obs can be estimated as 19 π obs θ obs θ where θ obs is the observed soil moisture pattern and θ is the emt vs model s estimated pattern π obs includes all variation that is unresolved by the deterministic downscaling and is an estimate of the true stochastic component in the soil moisture variation this approach assumes that the pre existing emt vs model successfully removes the deterministic dependence of θ obs on topographic and other catchment characteristics this assumption was checked by calculating the correlations between π obs and available catchment characteristics elevation contributing area slope psri and fractional vegetation cover and correlations between θ and π obs the magnitudes of the correlation coefficients averaged over all dates are below 0 10 for both catchments which suggests the model captures a large portion of the dependence nonetheless the calculation of π obs depends on the model used to estimate θ and other models are expected to produce different results the π obs patterns can be decomposed into temporally stable and unstable patterns the stable pattern is a time invariant stochastic pattern that contributes to π obs to some extent on every sample date the stable pattern π s o b s can be estimated as the temporal average of the observed stochastic patterns 20 π s o b s e π obs where e denotes the temporal average the unstable patterns π u o b s are the variations around the stable pattern on each date and can be estimated as 21 π u o b s π obs π s o b s the patterns for θ obs π obs π s o b s and π u o b s are analyzed using semivariograms this technique was introduced by matheron 1963 and has been previously applied to θ obs patterns de lannoy et al 2006 korres et al 2015 petrone et al 2004 western et al 1998 western et al 2004 however it has not been used to examine π obs π s o b s or π u o b s the sample semivariogram g s is calculated using 22 g s h 1 2 n h i j z i z j 2 where h is a lag or separation distance between two selected points in a catchment n is the number of pairs of points for each lag i and j are indices for the two locations separated by distance h and z i and z j are the values of the variable of interest at those two locations i e θ obs π obs π s o b s and π u o b s in the analyses below the semivariogram i e graph of g s as a function of h has three main properties the nugget range and sill the nugget is the y intercept of a semivariogram the range is the lag beyond which the semivariance becomes relatively constant and the sill is the value of that relatively constant semivariance the nugget is produced by spatially uncorrelated variability and can be caused by measurement error and or sub grid variability western et al 2004 the difference between the sill and the nugget the partial sill describes the contribution of spatially correlated variability the range is related to the correlation length an exponential semivariogram model with a nugget was fit to the sample semivariogram for each pattern using a weighted least squares method cressie 1985 the exponential form was selected because it usually fits sample semivariograms better than other models spherical circular etc mcbratney and webster 1986 western et al 2004 the exponential semivariogram g e has the form 23 g e h σ n 2 σ s 2 1 e h r where σ n 2 is the nugget σ s 2 is the partial sill r is the correlation length and the sill is equal to σ n 2 σ s 2 thus the nugget partial sill and correlation length of the sample semivariograms can be estimated by σ n 2 σ s 2 and r respectively 3 2 analysis results the semivariograms of θ obs and π obs were calculated for each date in the soil moisture datasets and then averaged between dates the temporal average semivariograms of θ obs and π obs are shown for tarrawarra in fig 2 a and for cache la poudre 2b all figures in this section also show modeling results which are variables that include asterisks but those results are discussed later the θ obs semivariogram exhibits both a nonzero nugget and partial sill at both catchments if the soil moisture patterns consistently conformed to fractal geometry then the semivariograms would follow power functions over a wide range of separation distances before reaching a sill burrough 1983 green and erskine 2004 because well defined sills are reached at a small separation distances in our study the soil moisture patterns are typically not well described by a fractal in contrast with patterns observed at coarser resolutions 1 km2 and larger domains 1000 s of km2 by kim and barros 2002a b the sill at tarrawarra is larger than cache la poudre furthermore the nugget comprises a much smaller portion of the sill at tarrawarra 13 than at cache la poudre 55 which suggests that correlated variability plays a much larger role in θ obs at tarrawarra than at cache la poudre the correlation lengths are similar at both catchments about 30 m at tarrawarra and about 40 m at cache la poudre western et al 1998 used visual inspection to estimate the semivariogram properties for θ obs at tarrawarra they estimated that the nugget comprises 29 of the sill and found an average correlation length of 50 m rogowski and engman 2006 found correlation lengths from 120 m to 180 m for their remotely sensed soil moisture dataset the contribution of the stochastic component to the overall soil moisture observations can be examined by comparing the sills of π obs and θ obs at each catchment the sill for π obs is approximately 64 of the sill for θ obs at tarrawarra and about 84 at cache la poudre thus the stochastic variations are important at both catchments but more so at cache la poudre at both catchments the nugget for π obs is roughly half of its sill it is 47 of the sill at tarrawarra and 56 of the sill at cache la poudre thus both catchments have roughly equal contributions from uncorrelated and correlated variability the average correlation length is about 34 m at tarrawarra and about 21 m at cache la poudre at tarrawarra the correlation lengths of π obs range from 19 to 135 m for individual dates compared to 18 to 65 m for θ obs while at cache la poudre they range from 9 to 31 m compared to 10 to 71 m for θ obs these characteristic lengths may be compared with a break in scaling invariance observed by kim and barros 2002a at a length around 3 200 m or an area of 10 km2 fig 2c and d show the semivariograms of π s o b s at the two catchments the sill for π s o b s is a substantial portion of the sill for π obs at both catchments 30 at tarrawarra and 41 at cache la poudre thus the stable pattern accounts for a sizeable part of the overall stochastic variability the higher percentage at cache la poudre suggests that the stable stochastic pattern plays a larger role at this catchment at tarrawarra the nugget for π s o b s is 14 of the sill and the correlation length is approximately 31 m at cache la poudre the nugget for π s o b s is 48 of the sill and the correlation length is approximately 25 m thus uncorrelated variability plays a larger relative role in π s o b s for cache la poudre than tarrawarra fig 2c and d also show the temporal average semivariograms of π u o b s at the two catchments at tarrawarra the nugget for π u o b s is 62 of the sill and the correlation length is approximately 45 m at cache la poudre the nugget for π u o b s is 48 of the sill and the correlation length is approximately 14 m thus in contrast to the stable patterns uncorrelated variation plays a smaller relative role in π u o b s for cache la poudre than tarrawarra fig 3 plots the semivariogram properties of π obs on each date against the associated spatial average soil moisture θ the nugget remains relatively constant at tarrawarra but it increases with θ at cache la poudre the correlation length of π obs exhibits no dependence on θ at either catchment western et al 2004 found that the correlation length of soil moisture θ obs increases with θ at multiple catchments the present results suggest that those increasing trends are due to the deterministic component rather than the stochastic component the partial sill for π obs increases with θ at tarrawarra which indicates a greater contribution from correlated variation on wetter dates however the partial sill remains fairly constant at cache la poudre western et al 2004 reported that the variance of θ obs increases with θ at multiple catchments similar behavior is implied by the nuggets and partial sills of π obs at both catchments however the increasing variance is due to an increasing contribution from spatially correlated variation at tarrawarra and an increasing contribution from spatially uncorrelated variation at cache la poudre fig 4 plots the semivariogram properties of π u o b s on each date against the associated θ the nugget exhibits no dependence on θ at either catchment indicating that the uncorrelated variance in π u o b s remains fairly constant similarly the correlation lengths exhibit no clear relationship with θ at either catchment for two dates at tarrawarra the exponential semivariogram fits the sample semivariogram poorly to accommodate for this anomaly the 7 largest lags of the 23 total were excluded when fitting the exponential semivariogram this modification produced more reasonable semivariogram properties for one date but an unusually large correlation length 197 m was still estimated for the other date this value falls beyond the limits of the graph in fig 4 the partial sill increases with θ at both catchments which indicates a greater contribution from correlated variance during wetter conditions overall these results suggest that the behavior of the unstable stochastic patterns is similar at both catchments the differences between the semivariogram properties in figs 3 and 4 reveal the influence of π s o b s on the stochastic patterns at cache la poudre for example subtracting π s o b s from π obs results in a larger nugget in π u o b s compared to π obs for dry conditions in contrast this subtraction tends to decrease the nugget in π u o b s for wet conditions this example demonstrates how the combination of a constant stable pattern and the unstable patterns can decrease the nugget of π obs on drier dates and increases the nugget on wetter dates thus at cache la poudre the nugget of π obs has a positive relationship with θ while the nugget of π u o b s remains relatively constant 4 model development 4 1 probabilistic model methodology the generalization of the emt vs model introduces stochastic variations by treating some model inputs as random variables although many inputs might be considered random variables the goal is to reproduce the observed stochastic features using as few random variables as possible thus stochastic variations are included in only three ways porosity soil moisture disequilibrium and measurement error these three were selected based on comparisons to the observed semivariograms and literature that has demonstrated their variability porosity has been shown to vary substantially at the catchment scale bakr et al 1978 a stochastic porosity ϕ is included in the model by combining the existing calibrated porosity value ϕ with a stochastic perturbation p 24 ϕ ϕ 1 p because porosity is temporally constant under most conditions p is considered a stable stochastic pattern thus a single pattern is generated at each catchment and used on every sample date studies have also demonstrated that porosity can have both spatial correlation bakr 1976 wang and shao 2013 and sub grid variability duffera et al 2007 thus p is constructed using a correlated random field p c and an uncorrelated random field p u 25 p p c p u both p c and p u are assumed to be normally distributed with zero mean and spatially constant variances heteroscedasticity of the π obs π s o b s and π u o b s patterns was explored but no consistent behavior was observed for the two catchments p c is assumed to have a separable exponential correlation function and is generated using fast sequential simulation dolloff and doucette 2014 generating fields of p c requires specification of its standard deviation σ p c and correlation length ρ p similarly generating fields of p u requires specification of its standard deviation σ p u the pre existing emt vs model calculates soil moisture by assuming equilibrium between the inflows and outflows of the soil layer in reality these flows are usually unbalanced and soil moisture is dynamic e g gaur and mohanty 2016 to allow deviations from equilibrium the probabilistic model includes a stochastic variable specifically when the equilibrium condition is imposed the equilibrium soil moisture is considered stochastic θ and assumed to be 26 θ θ 1 d where d is a random field that characterizes the deviations of θ from equilibrium because such deviations vary in time d is considered an unstable stochastic variable so different patterns are generated for each date to maintain parsimony d is assumed to contain only a correlated pattern similar to porosity d is assumed to be normally distributed with zero mean and spatially constant variance thus generating fields of d requires specification of its standard deviation σ d and correlation length ρ d including the porosity perturbation p and the deviation from equilibrium d in the emt vs model development produces new stochastic indices ddi lfi rei and aei 27 ddi ϕ 1 p 1 d 1 λ v k s v 1 γ v 28 lfi ϕ 1 p 1 d 1 λ v δ 0 ι k s v 1 γ h a c s ε 1 γ h κ min κ min κ 1 γ h 29 rei ϕ 1 p 1 d 1 α e p 1 β r 1 i p 1 β r 1 λ v η v 1 v μ 1 β r 30 aei ϕ 1 p 1 d 1 α e p α 1 β a 1 λ v η v 1 v μ 1 β a these stochastic indices are then used to calculate new stochastic soil moisture values using equations 7 10 θ g θ l θ r and θ a new stochastic weights are calculated using equations 15 18 w g w l w r and w a in addition to the natural stochastic variations the soil moisture observations also include measurement errors coleman and niemann 2013 western and grayson 1998 measurement errors must be simulated in order for the model to reproduce the properties of the observed soil moisture patterns measurement errors e are included by revising equation 6 to become 31 θ w g θ g w l θ l w r θ r w a θ a w g w l w r w a e tdr measurement errors do not depend on spatial average soil moisture roth et al 1990 so equation 31 assumes that the measurement errors are additive the measurement errors differ on each sampling date so e is considered temporally unstable and different patterns are generated for each date measurement error is also expected to be independent between sampling locations so e is considered an uncorrelated random field thus generating fields of e requires only specification of its standard deviation σ e in the end the probabilistic model introduces six new time invariant parameters σ p c ρ p σ p u σ d ρ d and σ e that must be estimated before soil moisture simulations can be generated for tarrawarra and cache la poudre these parameters are estimated using figs 3 and 4 the probabilistic model s stochastic component π stable pattern π s and unstable patterns π u are determined based on the same procedure used on the observations 32 π θ θ 33 π s e π 34 π u π π s to produce reliable semivariograms 2000 model realizations were generated for each date and their semivariograms were averaged the parameters were manually calibrated to minimize the root mean squared error rmse between the observed and modeled semivariogram properties specifically the parameters associated with unstable patterns σ d ρ d and σ e were first adjusted to minimize rmse between π u o b s and π u then the parameters associated with stable patterns σ p c ρ p and σ p u were adjusted to minimize rmse between π obs and π the calibrated parameters for the probabilistic model are shown in table 2 it is worth noting that the calibrated values of σ e are between 0 018 and 0 019 which are similar to the estimate of 0 014 from repeated measurements of soil moisture within small areas of tarrawarra and other sites wilson et al 2004 the probabilistic model also allows calculation of confidence limits for the emt vs model s estimated soil moisture θ for each fine resolution grid cell all 2 000 realizations of π were sorted from smallest to largest and the empirical cumulative distribution function cdf was computed using the plotting position formula from cunnane 1978 the desired quantiles are computed by linearly interpolating between the cdf values that are represented in the dataset 4 2 calibrated model results the temporal average semivariograms for θ and π are shown for the two catchments in fig 2a and b for both soil moisture and its stochastic component the probabilistic model reproduces the observed nugget correlation length and partial sill at both catchments reproducing the nugget and partial sill indicates that the probabilistic model includes the correct amounts of uncorrelated and correlated variations respectively the reproduction of the correlation length suggests that the probabilistic model includes the appropriate correlation lengths in its correlated patterns the semivariograms for π s and π u are shown for the two catchments in fig 2c and d the probabilistic model closely approximates the contribution of the stable pattern to the overall stochastic component 31 at tarrawarra and 40 at cache la poudre for the probabilistic model compared to 30 and 41 respectively for the observations the probabilistic model also closely approximates the observed semivariogram shapes at tarrawarra for example the nugget for π s is 19 of its sill and the correlation length is approximately 35 m compared 14 and 31 m respectively for π s o b s at tarrawarra the nugget for π u is 62 of its sill and the correlation length is approximately 41 m compared to 62 and 45 m respectively for π u o b s overall these results indicate that the probabilistic model reproduces the semivariogram features of both the stable and unstable patterns fig 3 plots the semivariogram properties of π on each date against the associated θ at tarrawarra the probabilistic model produces a relatively constant nugget which is also seen for the observations for the probabilistic model the constant nugget is caused by e and its additive relationship with θ which implies that the contribution of measurement error remains constant as θ changes the measurement error term enters the final soil moisture equation additively equation 31 and each analytical soil moisture value in the same equation depends on θ equations 7 10 at cache la poudre the probabilistic model reproduces the positive trend between the nugget and θ this trend primarily results from p u and its multiplicative relationship with θ equations 25 and 27 30 as θ increases uncorrelated variations in porosity produce a larger nugget in π for both catchments the modeled correlation length does not change with θ which is consistent with the observations the constant correlation length is determined by the prescribed correlation lengths of the stochastic variations for both catchments the probabilistic model produces a positive trend between partial sill and θ this trend results from p c and d and their multiplicative relationships with θ as θ increases correlated variations in porosity and disequilibrium produce a larger partial sill in π this behavior matches the observations at tarrawarra but not at cache la poudre fig 4 plots the semivariogram properties of π u on each date against the associated θ at both catchments the probabilistic model produces a relatively constant nugget as θ changes which matches the observations this behavior is due to the influence of e and its additive relationship with θ at both catchments the probabilistic model reproduces the relatively constant correlation lengths at both catchments the probabilistic model is also able to reproduce the positive trend between partial sill and θ this trend is primarily due to the influence of d and its multiplicative relationship with θ as θ increases correlated variations in disequilibrium produce a larger partial sill in π u examples of the observed soil moisture pattern θ obs the pre existing emt vs model estimate θ and the probabilistic model s simulated soil moisture θ are shown in fig 5 other dates are shown in the supplemental materials the pre existing model θ reproduces the observed dependence on topography see fig 1 and vegetation at tarrawarra the wettest locations tend to occur in the valley bottoms where water accumulates due to lateral flow at cache la poudre they tend to occur on the north facing hillslopes which are oriented away from the sun and shaded by thicker vegetation cover ranney et al 2015 the probabilistic model maintains much of that dependence but also produces patterns that are more visually similar to the observations however the probabilistic model is not able to reproduce all observed tendencies at tarrawarra for example the observations have contiguous wet locations in the valleys while the probabilistic model has less continuity of these features additionally the observations have a dry patch on the north facing hillslope that is not fully reproduced by the probabilistic model the probabilistic model s inability to reproduce these features may be caused in part by the use of homogeneous random fields as expected the probabilistic model does not produce wet and dry conditions at exactly the right locations but the tendencies of the modeled patterns are very similar to the observations histograms of θ obs θ and θ for dry intermediate and wet dates at tarrawarra and cache la poudre are shown in fig 6 the pre existing emt vs model does not reproduce the observed histograms or the extreme values of soil moisture in the catchments the probabilistic model is able to reproduce the histogram shape on all three dates at both catchments fig 7 plots the percentage of the soil moisture observations from all dates that fall within the confidence intervals y axis as a function of the selected confidence level x axis at tarrawarra too many observations fall within the confidence intervals when the selected confidence level is low if the selected confidence level is 50 for example about 56 of the observations fall within the model s interval this result implies that the modeled soil moisture distribution has a somewhat different shape than the observed distribution which could arise from the use of normal distributions and or the assumed homogeneity of the stochastic patterns at cache la poudre the confidence interval error is less than 2 for all confidence levels considered 4 3 uncalibrated model results the previous section showed that the probabilistic model can reproduce nearly all the observed statistical properties if the model is calibrated with local soil moisture observations in many practical circumstances however sufficient data may not be available to allow catchment specific calibration of the new parameters this section examines the performance if the model is applied to the nerrigundah and satellite station catchments without local calibration of the new probabilistic parameters instead these parameters which produce the stable and unstable stochastic variations are estimated by taking the average of the calibrated parameters at tarrawarra and cache la poudre see average columns in table 2 one could alternatively use the parameters from a single catchment but the averages are expected to be less region specific than the parameters from a single catchment the locally calibrated parameters for the pre existing emt vs model were still used for each catchment table 1 example soil moisture patterns θ obs θ and θ are shown in fig 8 similar to tarrawarra and cache la poudre the pre existing emt vs model reproduces the dependence on topography see fig 1 the probabilistic model maintains much of that dependence but also produces patterns that are more visually similar to the observations however at satellite station the observed pattern exhibits more spatially continuous wet locations in the valleys than the pattern produced by the probabilistic model at nerrigundah a large dry region occurs towards the top of the figure for the observations while the probabilistic model produces only smaller dry regions histograms of θ obs θ and θ for dry intermediate and wet dates at nerrigundah and satellite station are shown in fig 9 the pre existing emt vs model again does not reproduce the observed histograms of soil moisture and it does not capture the extreme values of soil moisture in the catchments the probabilistic model better approximates the histogram shapes for all cases shown the performance of the probabilistic model confidence intervals is shown in fig 10 at nerrigundah the probabilistic model consistently underestimates the confidence interval because it underestimates the variance of stochastic component at this site at satellite station the confidence intervals are relatively accurate for confidence levels smaller than about 80 above this level the confidence interval is underestimated overall the results suggest that the average parameter values from tarrawarra and cache la poudre provide reasonable approximations of the stochastic variations at the other catchments the reasons for and limits to such transferability are not clear svoray and shoshany 2004 suggested that stochastic variations in soil characteristics can arise from extrinsic factors other variables or intrinsic factors aspects of the variable itself it is possible that the hillslope size affects the correlation lengths in the porosity and disequilibrium patterns so similarity in the hillslope sizes between catchments might produce similarity in the correlation lengths it is also possible that the limited range over which porosity can realistically vary constrains the standard deviations for both porosity and disequilibrium however further study is needed to test these speculations 5 conclusions the primary objectives of this study were 1 to characterize the stochastic variability of soil moisture at the catchment scale and 2 to develop a downscaling model that reproduces the observed statistical features of soil moisture the stochastic variations in soil moisture were estimated by removing the deterministic dependence on site properties topography and vegetation from soil moisture observations using the emt vs downscaling model the stochastic variations were then decomposed into a stable pattern that can be present to some extent on every date and unstable patterns that vary through time semivariograms were then used to analyze each of those patterns in the proposed probabilistic model stochastic variations were introduced through porosity perturbations deviations from equilibrium moisture and measurement errors the following conclusions can be made from the results 1 the stochastic component of soil moisture represents a substantial portion of the overall soil moisture variation in the analyzed catchments the sill of the stochastic component is on average 64 and 84 of the sill of soil moisture at tarrawarra and cache la poudre respectively thus a majority of the variation at both catchments can be considered stochastic 2 the stochastic component exhibits non trivial semivariogram features i e a nonzero nugget correlation length and partial sill in the analyzed catchments the presence of a nonzero nugget and partial sill indicates that the stochastic component includes both correlated and uncorrelated patterns at both catchments the nugget is on average about half of the total sill which implies that the correlated and uncorrelated patterns contribute about equal variation on average 3 the semivariogram of the stochastic component also depends on the spatial average soil moisture for the datasets considered at tarrawarra the nugget remains relatively constant while the partial sill increases with spatial average soil moisture at cache la poudre the nugget increases with spatial average soil moisture while the partial sill remains relatively constant the correlation length remains approximately constant at both catchments 4 the stochastic variations also include a temporally stable pattern with substantial variability in both catchments the sill of the stable pattern is 30 and 41 of the sill of the stochastic component at tarrawarra and cache la poudre respectively the stable patterns at both catchments also exhibit nonzero nuggets and partial sills which indicate contributions from both correlated and uncorrelated patterns 5 the semivariograms of the unstable patterns depend on the spatial average soil moisture and this dependence is similar at both catchments in particular the nugget and the correlation length remain relatively constant while the partial sill increases with spatial average soil moisture 6 the probabilistic downscaling model is able to reproduce nearly all the observed statistical features for the catchments where its stochastic parameters i e the standard deviations and correlation lengths were calibrated specifically it reproduces the semivariograms of the soil moisture stochastic component stable pattern and unstable patterns it also reproduces the appropriate dependencies on the spatial average soil moisture aside from the partial sill of the stochastic component at cache la poudre in addition the probabilistic model adequately reproduces the soil moisture histograms for both catchments at low confidence levels the probabilistic model s confidence intervals can include as much as 6 too many observations i e the estimated intervals are too wide however the intervals become more accurate for larger confidence levels 7 the probabilistic model provides better statistical results than the pre existing emt vs model when its stochastic parameters are not calibrated to local observations for both catchments the soil moisture histograms and confidence intervals remain relatively accurate without calibration thus the probabilistic model may be able to approximate the overall soil moisture frequency distribution without requiring large local soil moisture datasets overall the probabilistic model performs well for these small catchments where the soil moisture patterns depend on topographic and vegetation characteristics and the soil moisture patterns do not display fractal behavior however the model may not apply directly to coarser resolutions and larger regions previous studies have shown that such soil moisture patterns exhibit multifractal properties kim and barros 2002a 2002b which would not be reproduced by the proposed model in its current form four specific avenues are open for future research first similar analyses should be performed using additional small catchments the physical factors that control the stochastic model parameters remain unknown thus these parameters currently cannot be estimated without calibration if additional catchments were analyzed and compared to the present study the controlling factors might become clearer second similar analyses could be performed using alternative models to remove the dependence on catchment characteristics the calculated stochastic component depends on the selected model so some differences are expected if a different model were used third the performance of geostatistical methods and multifractal methods could be compared for both small and large regions fourth a method could be developed that includes both the fine scale patterns of variation that are considered in the present analysis and the coarse scale patterns of variation studied by others as suggested by vinnikov et al 1999 such a method would describe the statistical properties of soil moisture across a very wide range of spatial scales and extents credit authorship contribution statement jordan p deshon methodology formal analysis investigation validation visualization writing original draft jeffrey d niemann funding acquisition conceptualization methodology supervision writing review editing timothy r green validation writing review editing andrew s jones funding acquisition validation writing review editing peter j grazaitis funding acquisition writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we gratefully acknowledge the united states army research laboratory for its financial support through the small business innovation research program partial support was also provided by the usda national institute of food and agriculture hatch project 1009616 we also thank two anonymous reviewers and andrew western for their help improving this manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124711 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
