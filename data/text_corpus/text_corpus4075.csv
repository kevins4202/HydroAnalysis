index,text
20375,in this paper an improved meshless artificial viscosity av method is proposed and combined with the local radial point interpolation method lrpim and the maccormack method to establish a newly developed meshless numerical model which can efficiently and accurately solve wet dry moving interfaces problems of shallow water flow as an important model describing shallow water flow the two dimensional 2d shallow water equations swes are a hyperbolic system of 1st order nonlinear partial differential equations which have a characteristic of strong gradient the lrpim and maccormack method are adopted to discretize the 2d swes spatially and temporally respectively meanwhile the method of selecting the different shape of support domain in the lrpim is employed for properly cooperating with the maccormack method to accurately capture the direction of wave propagation for eliminating the non physical oscillation at the discontinuity of shallow water flow the improved meshless av form is first presented four challenging numerical examples were selected to verify the proposed model by comparing with the other solutions and experimental observations the results indicate that the proposed method with improved meshless av can accurately capture the shock waves and efficiently simulate the wet dry front changes keywords two dimensional shallow water equations local radial point interpolation method artificial viscosity shock waves wet dry moving interfaces author contributions ting zhang conceptualization methodology formal analysis funding acquisition investigation writing original draft chang xun zhan validation formal analysis visualization software writing review editing hai wei wang validation formal analysis visualization chuan lin software resources review editing xiao mei guo software review editing 1 introduction in many practical phenomena such as offshore tides estuarine tidal and dam break flood the horizontal scale is extremely larger than the vertical scale so these phenomena are usually simplified to the two dimensional 2d shallow water flow which generally involve the wet dry moving interfaces from the perspective of engineering application accurate simulations of the shallow water flow are quite significance for the prediction of tidal oscillations in coastal estuarine water and of flood waves generated by dam break e g ying and fredric 2002 al ghosoun et al 2019 the 2d shallow water equations swes are an important mathematical model describing shallow water flows and were derived from navier stokes equations by assuming the uniform distribution of hydrostatic pressure and velocity along the vertical direction according to the presence of the source terms the 2d swes can be divided into two main categories named non conservative form and conservative form compared with the non conservative form the conservative form is superior in preserving the flow variables and is more accurate in the simulation by using the same numerical scheme fennema and chaudhry 1990 therefore based on the conservative form of 2d swes a numerical model which can accurately capture wet dry moving interfaces of shallow water flow is attempted to establish in this paper the 2d swes are a hyperbolic system of 1st order nonlinear partial differential equations which have a characteristic of strong gradient in addition there are many challenges in solving the equations for wet dry moving interfaces problems such as dealing with discontinuous flow wet dry interfaces complex bottom mixed flow pattern and so on kao and chang 2012 consequently various numerical methods have been developed for simulating the 2d swes in recent decades the basic methods adopted by most researchers are mesh methods such as finite difference method fdm e g lu and li 2011 khakimzyanov et al 2019 lundgren and mattsson 2020 finite element method fem seyedashraf and akhtari 2017 and finite volume method fvm e g kuiry et al 2008 kurganov and alexander 2018 since the 2d swes are a hyperbolic system accurately capturing propagation direction of waves is an important factor affecting the numerical results maccormack 1969 proposed an explicit maccormack method based on prediction correction process this method has been widely applied to catch the wave propagation and proved that it is highly suitable for the flow with discontinuity and has 2nd order accuracy in time and space however the numerical solution of the classical maccormack scheme may produce spurious oscillations near the discontinuities therefore it is necessary to improve it with other methods fennema and chaudhry 1990 proposed a finite difference maccormack format to simulate the free surface flow by solving 2d swes with artificial viscosity av term garcí navarro et al 1992 introduced a finite difference tvd maccormak explicit scheme to analyze one dimensional 1d open channel flow and this scheme was widely adopted to simulate shallow water flow e g liang et al 2010 kalita 2016 for the simulations of wet dry moving interfaces problems in the case of discontinuous flow there will be the non physical oscillation due to the strong gradient of sews which leads to the instability of numerical simulation results near the discontinuity many scholars have been studying how to avoid the oscillation e g toro 2001 amiri et al 2013 gerardo and abdelaziz 2016 with the development of computational technology the high resolution shock capture methods have been successfully applied to solve the homogeneous form of swes xu et al 2018 which eliminates the oscillation phenomenon of solutions at the cost of the complexity of algorithms among these remarkable methods av technology proposed by jameson et al 1981 is a simpler and effective scheme to minimize the non physical oscillation near the discontinuity by adding appropriate viscosity to the equations in the discontinuous region jameson et al 1981 initiated the development of av technology in the form of the famous jameson schmidt turkel jst scheme which was adopted to simulate euler equations later the technology has been proved that can reduce the oscillation caused by strong shock wave e g van der burg et al 1992 ducros et al 2000 jameson 2017 the further development of av technology is attributed to many scholars fennema and chaudhry 1990 used explicit 2nd order fdm and av method to reduce high frequency oscillations and simulate 1d and 2d swes fiedler and ramirez 2000 simulated the 2d overland flow in open channels using the fdm and av method sabbagh yazdi et al 2009 applied the unstructured galerkin fvm combined with av method to simulate the 2d swes of tidal current in recent years ginting 2017 contributed to the development of av technology including modification of av method by using the cell centered finite volume ccfv and the laplacian operator on the basis of jameson et al 1981 then the modified av method is adopted to deal with discontinuous flow and the 2d non hydrostatic swes by ginting 2019 2020 gerardo and abdelaziz 2016 proposed a new high resolution non oscillatory semi discrete central upwind scheme with av method to simulate shallow water flow in channels niklas et al 2018 extended the entropy stable discontinuous galerkin spectral element method to solve nonlinear 2d swes and an av term was introduced into the equation for shock capturing which was proved that the numerical scheme remains entropy stable mousa and ma 2020 developed the av method to overcome the problem of shock waves of two layer shallow water flow according to these results the av technology has the capacity to effectively minimize the non physical oscillations and ensure the accuracy of calculation another challenge for wet dry moving interfaces problems of shallow water flow is to alleviate the numerical instability caused by the small water depth near the wet dry interfaces for example the model may predict the wrong high speeds and lead to the prediction of negative water depth without physical significance on the wet dry interfaces in order to accurately simulate the movement of interfaces it is necessary to deal with the wet dry interfaces defina 2000 describes a finite element algorithm for solving moving interfaces problems on a fixed computational grid wu et al 2014 established a shallow water flow model with wet dry interfaces based on fvm with the unstructured mesh liu 2020 develops a novel well balanced and positivity preserving fvm for the shallow water flow in open channels with non uniform width and irregular bottom topography in recent years in order to overcome the difficulties of mesh generation and numerical integration the meshless methods are considered as the promising alternative methods which have been employed to analyze the various problems such as the obstacle problems chan et al 2013 the wave propagation and transformation zhang et al 2016 2020 and the wave structure interaction rijas et al 2019 the meshless methods were also adopted to solve swes by many scholars among them the development of radial basis function rbf as a meshless method has attracted many scholars attention wong et al 2002 approximate the swes by compactly supported rbf sun et al 2013 used the local radial basis function based differential quadrature method lrbfdqm to solve the swes chou et al 2015 proposed the extrapolated local radial basis functions collocation method elrbfcm to simulate the linear and nonlinear problems of shallow water flow these numerical results showed that the method had good interpolation accuracy but the selection of shape parameters was sensitive different from rbf point interpolation method pim is a meshless interpolation technique proposed by liu and gu 1999 which uses the shape function constructed by the nodes in the sub region to approximate the field variables however the singularity of the interpolation matrix may exist in order to overcome the defect of the above methods the local radial point interpolation method lrpim e g liu et al 2002 saeedpanah et al 2011 combining rbf and polynomial basis function pbf is adopted to construct the shape function the results demonstrate that the lrpim has well convergence precision and is not sensitivity to the selection of shape parameters compared with other meshless methods the previous studies on av technology are based on mesh schemes which have time consuming meshing generation and numerical quadrature such as fdm and fvm to deal with the wet dry moving interfaces problems wu et al 2016 and hsu et al 2019 proposed an effective scheme combined meshless method in which they minimize the non physical oscillation near the discontinuity by adopting weighted least square wls approach rather than adding av term to the equation in order to combine with lrpim in this paper an improved meshless av method is first proposed and introduced into the scheme of wu et al 2016 and hsu et al 2019 on the basis of fennema and chaudhry 1990 using the traditional 2nd order difference method to solve the av term the meshless scheme is adopted to construct the newly developed av term the appropriate viscosity is added to the governing equations by the improved meshless av term which avoids the detection and smoothing of ragged free surface the lrpim and the maccormack method are respectively employed to discretize the spatial and temporal terms of the governing equations the computational domain is distributed and the spatial coordinate of each node is determined for every node in each time step the value of variables would be predicted and corrected by the maccormack method then lrpim is adopted to solve swes at the present time step the numerical results obtained depict that the present numerical scheme is successfully applied in the wet dry moving interfaces problems with complex bottom topography this paper is organized as follows in section 2 the governing equations and the boundary condition are explained including wall and open boundary condition the proposed model with improved meshless av method is presented in section 3 then four challenging cases are adopted to evaluate the accuracy and stability of the numerical model and the numerical results are compared with other solutions in section 4 finally some conclusions are given in section 5 2 governing equations and boundary conditions 2 1 two dimensional shallow water equations in conservative form based on the presumption of hydrostatic pressure and uniform velocity profile along the vertical direction the 2d swes simplified by the three dimensional incompressible navier stokes equations are widely adopted to describe shallow water flow the sketch of which is shown in fig 1 a for the flow variable u h u h v h t the 2d swes in conservative form can be expressed as follows abbott 1979 chaudhry 2008 1 u t e x f y s in which e and f are the flux vectors s represents the source term vector and are defined as respectively 2 e u h u 2 h g h 2 2 u v h f v h u v h v 2 h g h 2 2 s 0 g h s 0 x g h s f x g h s 0 y g h s f y where u and v represent the vertically averaged velocity components in x and y directions h denotes the water depth g is the gravity acceleration s 0x s 0y s fx and s fy stand for the channel bottom slope and bed friction in x and y directions respectively and can be demonstrated as 3 s 0 x z b x s 0 y z b y 4 s f x n 2 u u 2 v 2 h 4 3 s f y n 2 v u 2 v 2 h 4 3 where z b is the bed elevation n denotes the manning s roughness coefficient 2 2 boundary conditions as shown in fig 1 a the boundary conditions of simulating shallow water flow in non flat bottom channel are divided into two types namely wall boundary and open boundary the two sides of the channel are impermeable wall boundary applied reflective boundary conditions and the upstream boundary conditions and downstream boundary conditions are set according to different flow states when considering the free outflow of dam break flow from the downstream boundary the reflective boundary condition is specified along the upstream boundary and the outflow boundary condition is specified along the downstream boundary when considering the dam break flow in a closed area the upstream boundary and downstream boundary are both wall boundaries so the reflective boundary conditions are adopted in this paper the reflective boundary conditions for the wall boundary are imposed as 5 h n 0 v n 0 v τ n 0 where v u v t denotes the velocity vector n n x n y t represents the outward normal vector τ τ x τ y t is a tangent vector open boundary conditions are divided into inflow boundary conditions and outflow boundary conditions which are also related to the flow pattern for the inflow boundary conditions when the flow is subcritical only the flow discharge is required while both the flow discharge and water depth should be given if the supercritical flow occurs for the outflow boundary conditions if subcritical flow occurs the water depth should be specified and no boundary condition is needed if the flow is supercritical however the governing equations have three dependent variables h u and v therefore when the boundary conditions are missing the governing equation is applied to fill the lack of boundary conditions 3 numerical methods 3 1 local radial point interpolation method lrpim the lrpim combines the rbf and pbf to form the interpolation shape function of subregion whose basic idea is to construct the interpolation shape function to obtain the derivative of the unknown function at a certain node the method avoids the singularity problem of the interpolation matrix and has good convergence and precision and is not sensitive to the selection of shape parameters as shown in fig 1 b distributing randomly nodes in the calculation domain the interpolation function is constructed in the semicircular subregion that each node is taken as the center radius d s the support domain includes n s adjacent nodes including the center point and the accuracy of interpolation depends on the nodes in the support domain therefore only by selecting the appropriate support region the efficient and accurate approximation can be ensured according to the researches of liu and gu 2005 d s 2 0 3 0 d c in which d c can be defined as an average nodal spacing in the support domain of node x i x i y i considering the function f x defined in the computational domain the lrpim interpolation of node x i can be written as 6 f x i j 1 n s r j x i j α j k 1 m p k x i β k r 1 x i 1 r 2 x i 2 r n s x i n s α 1 α 2 α n s p 1 x i p 2 x i p m x i β 1 β 2 β m r x i α p x i β where r x i p x i are a set of rbf and pbf centered on node x i respectively α and β represent the unknown coefficients of r x i and p x i m denotes the number of monomials as a rbf mq function is the most widely used one because it performs best franke 1982 kansa 1990 the two dimensional form of mq function is defined as 7 r j x c 2 r 2 where the distance between the point of support domain and node x i is r x x i 2 y y i 2 c represents the shape parameter and directly affects the convergence accuracy and effectiveness of numerical model it is a sensitive parameter for the determination of the range of c needing further study generally the optimal value can be determined by numerical test the monomial basis function p k x i k 1 2 m in eq 6 is established by pascal triangle ghehsareh et al 2018 then the linear polynomial m 3 is employed to combine with rbf in this paper the coefficients α and β in eq 6 can be determined by satisfying interpolation function f x at n s adjacent nodes in the support domain the matrix form of equations is depicted as follows 8 f r 0 α p m β where f f x 1 f x 2 f x 3 f x n s t is the vector of function values there are n s m unknown variables in eq 8 the polynomial term has to satisfy an extra constraint to obtain a unique solution the following formula is adopted 9 p m t α j 1 n s p k x j α j 0 k 1 2 m combining eqs 8 and 9 we yield 10 α β r 0 p m p m t 0 1 f 0 g 1 f 0 substituting the coefficient into eq 6 we have 11 f x i r x i p x i g 1 f 0 φ 0 x i f 0 the vector shape function corresponds to n s nodes so eq 11 is rewritten as 12 f x i φ x i f where φ x i φ 1 x i φ 2 x i φ n s x i is shape function corresponding to n s nodes the derivative of the function f can be converted into the derivation of the shape function therefore the 1st order and 2nd order partial derivative of the x i node in the x direction are respectively given as 13 f x i φ x i x f j 1 n s φ j x i x f j 14 2 f x 2 i 2 φ x i x 2 f j 1 n s 2 φ j x i x 2 f j similarly the 1st order and 2nd order partial derivative of the x i node in the y direction can also be obtained from the above the lrpim is based on rbf and pbf to construct interpolation shape functions of each node through the derivation of shape function the derivatives of the unknown variables for each node are transformed into linear combinations of function values for nodes in the local support domain and then the governing equation is transformed into constant coefficient equation this feature shows that the lrpim has the flexibility of spatial discretization and the simplicity of implementation process 3 2 solving shallow water equations in this paper based on the av technology introduced by jameson et al 1981 an improved meshless av term is added to the governing equation which can prevent non physical oscillation near discontinuity in solving the wet dry moving interfaces problem of shallow water flow with strong discontinuity then eq 1 are converted to the following form 15 u t e x f y s d u s ε x 2 u x 2 ε y 2 u y 2 where d is a dissipative operator d u denotes artificial viscous term ε x and ε y are represent the viscosity coefficients and calculated in the following sections respectively maccormack method is used to discretize the time term which includes two steps of prediction and correction prediction step 16 u p u n δ t e n x b δ t f n y b δ t s n δ t ε x 2 u n x 2 b δ t ε y 2 u n y 2 b correction step 17 u c u n δ t e p x f δ t f p y f δ t s p δ t ε x 2 u p x 2 f δ t ε y 2 u p y 2 f where the superscripts p and c donate the physical quantities of the predicted and corrected time steps and b and f represent the backward and forward direction of differencing respectively then the numerical solution at the n 1 th time step can be calculated as follows 18 u n 1 u p u c 2 in the traditional maccormack method the difference form is used to calculate the spatial partial derivative and the forward and backward difference operators are used alternately between the different directions of the spatial partial derivative and between the prediction and correction steps of each continuous time step the cyclic change can eliminate the directional deviation of the method and correct its non uniformity in 1d case there are two distinct difference combinations one is that forward difference is used in prediction step and backward difference is adopted in correction step the other is the opposite then calculations of two different combinations are alternately repeated to execute in 2d case there are four various difference combinations franke 1982 fennema and chaudhry 1990 the first combination is represented in eqs 16 and 17 in order to cooperate with maccormack method the wave propagation directions at x i node are divided into four types from up down left and right direction through x i node as shown in fig 1 c the lrpim is used to change the shape of the previous circular support region and improve the selection method of the support region to semicircle the corresponding support region direction is selected according to the forward and backward difference when backward difference is used for spatial partial derivative in x direction support domain in left direction is selected when forward difference is used for spatial partial derivative term in x direction support domain in right direction is selected when backward difference is used for spatial partial derivative term in y direction support domain in down direction is selected when forward difference is used for spatial partial derivative term in y direction support domain in up direction is selected therefore the selection of local support domains can be divided into four types left side right side down side and up side of x i node as shown in fig 1 b when the wave is transmitted from the left hand side of the x i node the local support domain should be selected in the left side of the x i node and other directions are similar according to the selection method of the support domain shape the repeat sequence that four different combinations are alternately applied in four consecutive time steps is adopted table 1 gives the example of a repeated sequence the directions of support domain of prediction and correction step at nth time step are determined by the remainder k which is obtained by dividing nth time step by 4 from the derivation of eqs 13 and 14 the 1st order and 2nd order spatial derivatives of x i node are expressed as 19 f x i b φ x l x i f 2 f x 2 i b φ x x l x i f 20 f x i f φ x r x i f 2 f x 2 i f φ x x r x i f 21 f y i b φ y d x i f f y i b φ y y d x i f 22 f y i f φ y u x i f f y i f φ y y u x i f where the superscripts l r d and u represent the direction of the selected local support domain respectively the improved lrpim is used to discretize the spatial terms in eqs 16 and 17 when the remainder k 1 the discrete form of governing equations will be eventuated as follows 23 u i p u i n δ t j 1 n s φ j x l x i e i n δ t j 1 n s φ j y d x i f i n δ t s i n δ t ε x i j 1 n s φ j x x l x i u i n δ t ε y i j 1 n s φ j y y d x i u i n i 1 2 n i 24 u i c u i n δ t j 1 n s φ j x r x i e i p δ t j 1 n s φ j y u x i f i p δ t s i p δ t ε x i j 1 n s φ j x x r x i u i p δ t ε y i j 1 n s φ j y y u x i u i p i 1 2 n i the other combinations are similar all interior node need to satisfy the governing equation and every boundary node ought to satisfy the boundary conditions then the new system of linear algebraic equations can be generated 25 c 3 n 3 n u 3 n 1 f 3 n 1 where c is a sparse coefficient matrix with respect to variable u and f is a non homogeneous term of the equation the physical quantities h i u i h i v h i i i 1 2 n of each node can be obtained by solving eq 25 the numerical solution at the next time step can be obtained from eq 18 3 3 artificial viscosity based on meshless method based on the traditional 2nd order difference method a new developed meshless scheme of av term is proposed to minimize the non physical oscillation at the discontinuity and accurately capture the shock waves in this paper the 2nd order partial differential form of av term is depicted as 26 d u d x u d y u ε x 2 u x 2 ε y 2 u y 2 in which d x u d y u is the value corresponding to two coordinate directions this paper modifies the calculation of viscous coefficient ε x and ε y based on fennema and chaudhry 1990 we can acquire the viscous coefficient as follows 27 ε x i κ δ x 2 δ y 2 δ t ν x i 28 ε y i κ δ x 2 δ y 2 δ t ν y i where κ is a positive viscosity parameter which is used to adjust the amount of viscosity according to the experience described in this paper the range of its value is between 0 1 2 v x i and v y i denote smoothing parameter in the x direction and y direction respectively in order to cooperate with selecting the local support region of the different direction in meshless method the smoothing parameter of the traditional form is improved into the newly developed meshless form which is computed using the water depth h of all nodes in the support domain the improved meshless v x i and v y i are yielded as follows respectively 29 ν x i j 1 n s h i j r 2 n s h i j 1 n s h i j l j 1 n s h i j r 2 n s h i j 1 n s h i j l 30 ν y i j 1 n s h i j u 2 n s h i j 1 n s h i j d j 1 n s h i j u 2 n s h i j 1 n s h i j d therefore the viscosity coefficient ε is proportional to the water depth h and the viscosity parameter κ selecting the viscosity parameter is a key step in dealing with the numerical instability in the wet dry moving interfaces problem in this paper the av method is to obtain high order accurate solutions in smooth regions and high resolution solutions near strong discontinuities by adding appropriate viscosity kurganov and liu 2012 it is necessary to add enough stable diffusion at the discontinuity but not in the smooth region to maintain the high accuracy of the solution in this paper the strategy is using fewer nodes in the computational domain firstly to find a prior value and then using more nodes in the computational domain for high resolution calculation which can make the calculation cost of the adjustment process lower 3 4 dealing with wet dry moving interfaces in order to accurately simulate the movement of wet dry interfaces in shallow water flow special treatment of wet dry interfaces is needed a simple and effective method to deal with the wet dry interfaces was proposed by hsu et al 2019 the scheme adopts the wls approach to smooth ragged water surface after obtaining the values of the variable based on this method this paper adds av term in the process of obtaining the values of the variable to minimize the oscillation which is not required to detect and smooth ragged water surface the discrete nodes are divided into two groups corresponding to the dry and wet regions the time stepping method only deals with the wet nodes to simulate the movement of wet dry interfaces the nodes around the moving front can switch their states the threshold depth h thre is defined as the critical value of water depth for the transition between the two states when the water depth of the node is equal to or greater than the h thre the node is a wet node otherwise the node is a dry node unless at least one of its adjacent nodes is a wet node whose water depth is higher than the bottom elevation or water level of the node when the water depth is lower than the h thre the wet node switches to the dry node similar to the study of hsu et al 2019 the adjacent nodes in this paper are nodes whose distance from the central node is less than 1 5 times the average distance of local domain nodes the flow chart of the numerical algorithm of wet and dry node change is shown in fig 2 4 numerical results and validations 4 1 one dimensional dam break problem in order to test the ability and merit of the proposed numerical model based on the improve meshless av technology to solve the problem of discontinuous initial conditions and extreme water flow conditions the first example considers the 1d dam break problem that can be used to test the capacity of numerical method to capture shock waves as shown in fig 3 the computational planar domain is a rectangular area with 50 m in length and 10 m in width and the dam is located at x 25 m the channel bottom is flat and frictionless at the beginning of the simulation assuming that the dam is instantaneously removed for some reason t 0 s the entire flow in the domain remains subcritical the ratio of water depth between upstream and downstream is expressed as 31 γ h h u h d in which h u and h d represent upstream and downstream water depth respectively this case contains three tests respectively considering γ h 2 γ h 10 and γ h 100 the water depth in upstream area is set as 1 m and the corresponding downstream water depths are set as 0 5 m 0 1 m and 0 01 m respectively the following parameters are used n 78876 t 0 001s c 0 05 when γ h 2 the viscosity parameter κ is defined as 2 by numerical experiments similarly when γ h 10 and γ h 100 κ is 0 45 and 0 3 respectively in all cases of this paper we adopt d s 2 5 d c and the numerical simulation shows that it can ensure the non singularity of the coefficient matrix and the accuracy of the numerical results the numerical results of water depth h and velocity u in x direction along the central horizontal axis at different times for different γ h are given in figs 4 6 respectively the obtained results are in good agreement with the analytical solution wu et al 1999 which can validate the effectiveness of capturing shock waves by the proposed meshless av method when γ h 2 the provided results accurately describe the motion of shock waves toward the downstream although there are some small difference from the analytical solution with increasing of γ h the results still remain satisfying stability in the discontinuities therefore the meshless numerical model can achieve acceptable expectation moreover in order to verify the accuracy and convergence of the proposed numerical model the comparison between the analytical solutions and the numerical results of different total number of nodes n 3276 n 12801 and n 78876 at t 4 s γ h 2 is depicted in fig 7 it can be seen that with the increase of number of nodes the simulation accuracy gradually improves in addition in order to explore the cost of computing time consumed by the av term the cpu time of each time step expended to obtain the results by adding and not adding av term for different total number of nodes is given in table 2 all of the numerical calculations in this study are conducted on an intel r core tm i7 pc equipped with a 8 gb ram it can be seen that the addition of av term slightly increased cpu time but the ability to eliminate the non physical oscillations was significantly improved it indicates that the calculation cost has little impact by adding av term meanwhile the cpu time is mainly affected by the total number of nodes and is increased as the number of nodes rises the numerical results exhibit that the improve meshless av method can effectively enhance the numerical entropy stable capture shock waves and have enough accuracy in dealing with discontinuous wave problems 4 2 oscillatory flow in a parabolic bowl in this subsection the numerical results are compared with the analytical solutions to verify the feasibility and accuracy of the proposed numerical model in dealing with wet dry moving interfaces problems thacker 1981 proposed two different types of solutions for time dependent nonlinear vibrations one of which contains geometric periodic solutions based on parabolic circular and elliptic bowls the case chosen in this subsection becomes more challenge to involve for a numerical model since the initial configuration of wet dry procedure is non radially symmetric the correct determination of the wet region with acceptable accuracy is the key technology for proposed numerical model as shown in fig 8 the water surface rotates around the center of the area in a parabolic bowl the calculation domain is 4 m 4 m and the bottom terrain is described as 32 z r 1 h 0 1 x 2 y 2 a 2 where the positive constant h 0 0 1 m is the water depth at the center point for the horizontal water surface and the positive constant a 1 m is the horizontal distance from the center point to horizontal water surface of the shoreline the elevation h velocity u and v corresponding to the x and y directions of water surface have the following periodic analytical solutions thacker 1981 nikolos and delis 2009 33 h x y t max 0 1 η h 0 a 2 2 x cos ω t 2 y sin ω t η z 34 u x y t η ω sin ω t 35 v x y t η ω cos ω t where ω 2 g h 0 a and the constant η 0 5 determines the amplitude of the motion the exact solution at t 0 s is used as the initial condition of solving free surface elevation and velocity field this exact solution simulates a free horizontal surface with constant gradient which moves around the center of the bowl at a constant angular velocity at any time without changing its shape the period of solution is t 2 π ω although the solution is relatively simple it is regarded as a test case for most two dimensional methods because it is not driven by external boundary conditions the boundary condition is set to the solid side wall because the flow will never reach the region boundary the following parameters are used n 90601 t t 1000 0 0045 s c 0 007 κ 0 2 and the threshold depth h t h r e 0 001 m the cpu time consumed by each time step is 6 87 s the contour map of water depth at t 2 and t time in a complete rotation period is described at fig 9 comparing the provided results with thacker s analytical solution there are well consistency during the whole period the water surface solved by the numerical method is almost flat and the coastline is almost circular which is close to the analytical solution without distortion figs 10 and 11 exhibit the comparison of the numerical results and analytical solutions along the centerline y 0 at two moments t 2 and t for water depth the numerical solution shows satisfactory agreement with the analytical solution thacker 1981 the moving coastline is accurately calculated there is no false oscillation and the plane form of the free surface remains unchanged throughout the calculation process obtaining the approximation of accurate velocity field is a more difficult for dealing with the moving boundary problem from the comparison of velocity v in figs 10 and 11 a small disturbance appears near the interface of the wet dry interfaces however the position of the wet dry interfaces has been captured and the moving coastline has been accurately simulated therefore we can conclude that the proposed numerical model can be successfully applied to the shallow water flow with wetting drying moving interfaces and improve meshless av method can accurately and stably deal with the wet dry change 4 3 dam break flow past triangle weir from the successful validation in the previous demonstrated cases the proposed numerical scheme with improve meshless av method can simulate shock wave and wet dry processes respectively then a more challenging case conducted by concerted action on dambreak modeling cadam morris 2000 is chosen in the third test to further examine the performance of present scheme since it simultaneously involves discontinuous wave wet dry moving interfaces and complex terrain cadam provided many useful benchmark tests of dam break for numerical verification which are helpful to study the influence of different downstream boundary conditions on dam break flow in the channel with bottom convex and includes various free surface flow patterns such as supercritical subcritical transcritical flow shock surface propagation overtopping flow local reflection hydraulic jump hydraulic head drop and multi wave interaction e g kao and chang 2012 hsu et al 2019 the experimental domain demonstrated in fig 12 a is a rectangular channel with 38 m in length and 1 75 m in width the length of upstream reservoir is 15 5 m the initial water depth is 0 75 m and the gate is located at x 15 5 m there is a symmetrical triangular weir 6 0 m long and 0 4 m high which the top is 13 m away from the gate and the bottom is 10 m away from the gate on the downstream riverbed manning coefficient of the channel is set as 0 0125 and four bathymetric instruments are located 4 m 10 m 13 m and 20 m downstream of the gate for fig 12 a g4 g10 g13 and g20 respectively three different downstream boundary conditions are considered in the experiment one is dry riverbed condition and others are wet riverbed conditions for dry riverbed the whole channel is dry when the gate is opened and the end of the channel is an open boundary as shown in fig 12 a for both wet riverbed the water depth after the triangular weir is 0 15 m two different boundary conditions are applied at the end of the channel one is a closed boundary to prevent water from flowing out of the channel as shown in fig 12 b and the other is open boundary as depicted in fig 12 c the following parameters are used n 4575 t 0 005 s c 0 1 κ 0 2 the threshold depth h t h r e 0 001 m and the total simulation time 40 s the cpu time of each time step is 0 58 s in this case corresponding to three downstream boundary conditions fig 13 a d 14 a d and 15 a d illustrate the numerical results of water depth temporal variations at four measuring points g4 g10 g13 and g20 for three different downstream boundary conditions respectively at g4 near the reservoir when t 12 s and t 35 s the water depth suddenly rises which indicates the passing of incident shock wave and the local reflection of overtopping shock wave through the bulge respectively g10 is located at the upstream slope toe of the bulge and the water depth evolutions of the three conditions are almost identical however the variations of water depth at g13 at the top of the bulge and g20 downstream of the bulge are somewhat different because the different boundary conditions at the end of the channel the comparisons with the experimental results and the numerical results of kao and chang 2012 and hsu et al 2019 show that the simulated results can predict the flow evolutions as well for the open downstream boundary conditions as exhibited in figs 13 and 15 the water depth and arriving time of shock waves at g4 and g10 are slightly different by comparing with experimental data but the simulated results are closer to the experimental results than the results of kao and chang 2012 in the process of water depth decline the consistency between the results of present method and the experimental results can be clearly observed at g13 at g20 the simulated results can track the trend of experimental results and have only few discrepancies for the closed downstream boundary conditions as shown in fig 14 the simulated results are quite close to the numerical results of hsu et al 2019 the differences from experimental data at g4 and g10 also exist in the results of hsu et al 2019 at g13 and g20 the model can accurately predict water depth it should be noted that the oscillations still occur at strong discontinuity in fig 14 when the end of the channel is closed the possible reason may be that the simulated results of the closed downstream boundary conditions are quite sensitive to the selection of viscosity parameter κ because the flow is reflective and highly complex when the end of the channel is closed the selection of κ as kurganov and liu 2012 expressed is a delicate issue and key step to eliminate oscillations by the av method the optimizations of κ election will be our future work for further study to eliminate the remaining oscillations in addition according to fennema and chaudhry 1990 the oscillations near discontinuities are due to truncation errors and are part of the diffusive properties of the numerical scheme since the tuning of av is based on the κ and the water depth h by eqs 27 30 and the value of av can be adjusted continuously according to the varying h the proposed av method has some certain applicability in dealing with real problems in this way the sharp resolution of the discontinuities without producing non physical oscillations can be obtained while the viscosity hardly need be adjusted in the smooth region in general the proposed numerical model has the ability to reasonably and effectively simulate complex dam break flow with wet dry moving interfaces 4 4 dam break flow past three cone shaped mounds as a last case the wet dry change process of dam break flow passing three cone shaped mounds is simulated for the further validation of the proposed meshless model this experiment conducted by kawahara and umetsu 1986 can be adopted as a 2d numerical experiment to test the wet dry change process and many researchers have also done relevant research e g brufau and garcıa navarro 2003 delis and katsaounis 2005 nikolos and delis 2009 hsu et al 2019 as shown in fig 16 the computational domain is a 75 m 30 m rectangular channel and the gate is located at x 16 m the initial water depth in upstream region is 1 875 m the downstream region is dry initially and the manning s coefficient is set as 0 018 the whole channel is closed and the four side boundaries are set as wall boundary the topography in the downstream region is defined as 36 z x y max 0 1 4 30 x 30 2 y 22 5 2 1 4 30 x 30 2 y 7 5 2 2 5 0 25 x 47 5 2 y 15 2 in this case the following parameters are adopted n 25351 t 0 001 s c 0 2 κ 0 1 and the threshold depth h thre 0 001 m the cpu time of each time step is 1 45 s the three dimensional views of the propagation of dam break flood at 2 5 8 13 5 20 28 and 100 s are described at fig 17 which illustrate that the propagation has the expected physical characteristics at t 2 5 s fig 17a the dam break wave reaches the top of two lower mounds at t 8 s fig 17b two lower mounds have been submerged and the water flow reaches the highest point of slope in front of the latter higher mound at t 13 5 s the water passing through the three mounds has reached the downstream side wall as depicted in fig 17 c so the water level can be seen to rise in the two corners of the downstream meanwhile the backward propagating wave reflected from the higher mound is obvious at t 20 s the reflected wave from the higher mound has just reached upstream side wall while another reflected wave has just appeared at the downstream side wall seen in fig 17 d at t 28 s the reflected wave from the downstream side wall has reached the back of the higher mound as shown in fig 17 e after the interaction of the wave wave wave topography and wave wall the water in the flume gradually calms down due to the friction dissipation effect at the bottom at t 100 s fig 17f the water flow has become stable in order to further verify the accuracy of the simulated results the evolutionary profiles along the horizontal central axis of the dome y 7 5 m and 15 m at t 8 s and 28 s are depicted in fig 18 a d at t 8 s the free surface profiles are almost identical with the research results of local polynomial approximation lpa with wls by hsu et al 2019 the surface profile along y 15 m is higher than along y 7 5 m due to the latter higher mound when time t 28 s the surface profiles both fluctuate slightly and calm down gradually from the results and comparisons it s demonstrated that the numerical model with improve meshless av method can stably and accurately simulate dam break flood with wet dry change process on complex terrain with steep slope 5 conclusions in this paper an improved meshless av method is proposed to effectively capture shock waves and combined with the lrpim and the maccormack method to establish a new numerical model for solving the moving wet dry interfaces problems of shallow water flow the lrpim is adopted to discretize the spatial terms of governing equation then the maccormack method is used to separate the temporal terms and accurately captures the propagation direction of the wave the selection direction of support region in lrpim is also introduced to cooperate with the maccormack method the proposed av method is a new meshless form combining with the lrpim whose viscosity coefficient is related to the direction of the local support region the gradient is adjusted by establishing the viscosity coefficient ε which is proportional to the water depth h and the viscosity parameter κ the value of viscosity coefficient is automatically adjusted according to the local properties of h in this way a large number of numerical viscosities are added to the non smooth region for smoothing oscillations while the viscosity is much smaller in the smooth region for remaining the high accuracy the advantage of this method is that the steep region is smoothed while the smooth region is not disturbed which maintains the entropy stable of numerical simulation of wet dry moving interfaces problems with the strong shock waves moreover the calculation process of this method is simple and effective four challenging numerical examples were selected to evaluate the numerical model firstly the capacity of the proposed meshless av method to capture the shock waves is successfully examined by 1d dam break problem the results obtained by adopting the different ratio of water depth γ h depict that the numerical model still maintains satisfying stability near discontinuities under discontinuous initial conditions and extreme flow conditions moreover there is well comparison with the analytical solution secondly the case of oscillatory flow in a parabolic bowl proves the feasibility and accuracy of the meshless numerical model for dealing with wet dry moving interfaces finally the propagations of 1d and 2d dam break flow with wet dry change and complex bottom topography are simulated by the numerical model because of the flexible distribution of nodes the meshless model has strong adaptability to the complex terrain the water flow profiles are precisely acquired which agree well with other numerical and analytical solution in general the numerical simulation results demonstrate that the proposed model with improved meshless av scheme can be a promising method for solving wet dry moving interfaces problems in the complex bottom terrain of shallow water flow however the nonlinear oscillation has not been completely eliminated in the simulation of the complex dam break flow because of the sensitivity of viscosity parameter κ the optimizations of κ election will be our future work for further study to improve the accuracy and parallel calculation can be considered to improve the calculation efficiency declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors are grateful to the national natural science foundation of china grant no 51679042 and no 52079032 for the financial support of this research 
20375,in this paper an improved meshless artificial viscosity av method is proposed and combined with the local radial point interpolation method lrpim and the maccormack method to establish a newly developed meshless numerical model which can efficiently and accurately solve wet dry moving interfaces problems of shallow water flow as an important model describing shallow water flow the two dimensional 2d shallow water equations swes are a hyperbolic system of 1st order nonlinear partial differential equations which have a characteristic of strong gradient the lrpim and maccormack method are adopted to discretize the 2d swes spatially and temporally respectively meanwhile the method of selecting the different shape of support domain in the lrpim is employed for properly cooperating with the maccormack method to accurately capture the direction of wave propagation for eliminating the non physical oscillation at the discontinuity of shallow water flow the improved meshless av form is first presented four challenging numerical examples were selected to verify the proposed model by comparing with the other solutions and experimental observations the results indicate that the proposed method with improved meshless av can accurately capture the shock waves and efficiently simulate the wet dry front changes keywords two dimensional shallow water equations local radial point interpolation method artificial viscosity shock waves wet dry moving interfaces author contributions ting zhang conceptualization methodology formal analysis funding acquisition investigation writing original draft chang xun zhan validation formal analysis visualization software writing review editing hai wei wang validation formal analysis visualization chuan lin software resources review editing xiao mei guo software review editing 1 introduction in many practical phenomena such as offshore tides estuarine tidal and dam break flood the horizontal scale is extremely larger than the vertical scale so these phenomena are usually simplified to the two dimensional 2d shallow water flow which generally involve the wet dry moving interfaces from the perspective of engineering application accurate simulations of the shallow water flow are quite significance for the prediction of tidal oscillations in coastal estuarine water and of flood waves generated by dam break e g ying and fredric 2002 al ghosoun et al 2019 the 2d shallow water equations swes are an important mathematical model describing shallow water flows and were derived from navier stokes equations by assuming the uniform distribution of hydrostatic pressure and velocity along the vertical direction according to the presence of the source terms the 2d swes can be divided into two main categories named non conservative form and conservative form compared with the non conservative form the conservative form is superior in preserving the flow variables and is more accurate in the simulation by using the same numerical scheme fennema and chaudhry 1990 therefore based on the conservative form of 2d swes a numerical model which can accurately capture wet dry moving interfaces of shallow water flow is attempted to establish in this paper the 2d swes are a hyperbolic system of 1st order nonlinear partial differential equations which have a characteristic of strong gradient in addition there are many challenges in solving the equations for wet dry moving interfaces problems such as dealing with discontinuous flow wet dry interfaces complex bottom mixed flow pattern and so on kao and chang 2012 consequently various numerical methods have been developed for simulating the 2d swes in recent decades the basic methods adopted by most researchers are mesh methods such as finite difference method fdm e g lu and li 2011 khakimzyanov et al 2019 lundgren and mattsson 2020 finite element method fem seyedashraf and akhtari 2017 and finite volume method fvm e g kuiry et al 2008 kurganov and alexander 2018 since the 2d swes are a hyperbolic system accurately capturing propagation direction of waves is an important factor affecting the numerical results maccormack 1969 proposed an explicit maccormack method based on prediction correction process this method has been widely applied to catch the wave propagation and proved that it is highly suitable for the flow with discontinuity and has 2nd order accuracy in time and space however the numerical solution of the classical maccormack scheme may produce spurious oscillations near the discontinuities therefore it is necessary to improve it with other methods fennema and chaudhry 1990 proposed a finite difference maccormack format to simulate the free surface flow by solving 2d swes with artificial viscosity av term garcí navarro et al 1992 introduced a finite difference tvd maccormak explicit scheme to analyze one dimensional 1d open channel flow and this scheme was widely adopted to simulate shallow water flow e g liang et al 2010 kalita 2016 for the simulations of wet dry moving interfaces problems in the case of discontinuous flow there will be the non physical oscillation due to the strong gradient of sews which leads to the instability of numerical simulation results near the discontinuity many scholars have been studying how to avoid the oscillation e g toro 2001 amiri et al 2013 gerardo and abdelaziz 2016 with the development of computational technology the high resolution shock capture methods have been successfully applied to solve the homogeneous form of swes xu et al 2018 which eliminates the oscillation phenomenon of solutions at the cost of the complexity of algorithms among these remarkable methods av technology proposed by jameson et al 1981 is a simpler and effective scheme to minimize the non physical oscillation near the discontinuity by adding appropriate viscosity to the equations in the discontinuous region jameson et al 1981 initiated the development of av technology in the form of the famous jameson schmidt turkel jst scheme which was adopted to simulate euler equations later the technology has been proved that can reduce the oscillation caused by strong shock wave e g van der burg et al 1992 ducros et al 2000 jameson 2017 the further development of av technology is attributed to many scholars fennema and chaudhry 1990 used explicit 2nd order fdm and av method to reduce high frequency oscillations and simulate 1d and 2d swes fiedler and ramirez 2000 simulated the 2d overland flow in open channels using the fdm and av method sabbagh yazdi et al 2009 applied the unstructured galerkin fvm combined with av method to simulate the 2d swes of tidal current in recent years ginting 2017 contributed to the development of av technology including modification of av method by using the cell centered finite volume ccfv and the laplacian operator on the basis of jameson et al 1981 then the modified av method is adopted to deal with discontinuous flow and the 2d non hydrostatic swes by ginting 2019 2020 gerardo and abdelaziz 2016 proposed a new high resolution non oscillatory semi discrete central upwind scheme with av method to simulate shallow water flow in channels niklas et al 2018 extended the entropy stable discontinuous galerkin spectral element method to solve nonlinear 2d swes and an av term was introduced into the equation for shock capturing which was proved that the numerical scheme remains entropy stable mousa and ma 2020 developed the av method to overcome the problem of shock waves of two layer shallow water flow according to these results the av technology has the capacity to effectively minimize the non physical oscillations and ensure the accuracy of calculation another challenge for wet dry moving interfaces problems of shallow water flow is to alleviate the numerical instability caused by the small water depth near the wet dry interfaces for example the model may predict the wrong high speeds and lead to the prediction of negative water depth without physical significance on the wet dry interfaces in order to accurately simulate the movement of interfaces it is necessary to deal with the wet dry interfaces defina 2000 describes a finite element algorithm for solving moving interfaces problems on a fixed computational grid wu et al 2014 established a shallow water flow model with wet dry interfaces based on fvm with the unstructured mesh liu 2020 develops a novel well balanced and positivity preserving fvm for the shallow water flow in open channels with non uniform width and irregular bottom topography in recent years in order to overcome the difficulties of mesh generation and numerical integration the meshless methods are considered as the promising alternative methods which have been employed to analyze the various problems such as the obstacle problems chan et al 2013 the wave propagation and transformation zhang et al 2016 2020 and the wave structure interaction rijas et al 2019 the meshless methods were also adopted to solve swes by many scholars among them the development of radial basis function rbf as a meshless method has attracted many scholars attention wong et al 2002 approximate the swes by compactly supported rbf sun et al 2013 used the local radial basis function based differential quadrature method lrbfdqm to solve the swes chou et al 2015 proposed the extrapolated local radial basis functions collocation method elrbfcm to simulate the linear and nonlinear problems of shallow water flow these numerical results showed that the method had good interpolation accuracy but the selection of shape parameters was sensitive different from rbf point interpolation method pim is a meshless interpolation technique proposed by liu and gu 1999 which uses the shape function constructed by the nodes in the sub region to approximate the field variables however the singularity of the interpolation matrix may exist in order to overcome the defect of the above methods the local radial point interpolation method lrpim e g liu et al 2002 saeedpanah et al 2011 combining rbf and polynomial basis function pbf is adopted to construct the shape function the results demonstrate that the lrpim has well convergence precision and is not sensitivity to the selection of shape parameters compared with other meshless methods the previous studies on av technology are based on mesh schemes which have time consuming meshing generation and numerical quadrature such as fdm and fvm to deal with the wet dry moving interfaces problems wu et al 2016 and hsu et al 2019 proposed an effective scheme combined meshless method in which they minimize the non physical oscillation near the discontinuity by adopting weighted least square wls approach rather than adding av term to the equation in order to combine with lrpim in this paper an improved meshless av method is first proposed and introduced into the scheme of wu et al 2016 and hsu et al 2019 on the basis of fennema and chaudhry 1990 using the traditional 2nd order difference method to solve the av term the meshless scheme is adopted to construct the newly developed av term the appropriate viscosity is added to the governing equations by the improved meshless av term which avoids the detection and smoothing of ragged free surface the lrpim and the maccormack method are respectively employed to discretize the spatial and temporal terms of the governing equations the computational domain is distributed and the spatial coordinate of each node is determined for every node in each time step the value of variables would be predicted and corrected by the maccormack method then lrpim is adopted to solve swes at the present time step the numerical results obtained depict that the present numerical scheme is successfully applied in the wet dry moving interfaces problems with complex bottom topography this paper is organized as follows in section 2 the governing equations and the boundary condition are explained including wall and open boundary condition the proposed model with improved meshless av method is presented in section 3 then four challenging cases are adopted to evaluate the accuracy and stability of the numerical model and the numerical results are compared with other solutions in section 4 finally some conclusions are given in section 5 2 governing equations and boundary conditions 2 1 two dimensional shallow water equations in conservative form based on the presumption of hydrostatic pressure and uniform velocity profile along the vertical direction the 2d swes simplified by the three dimensional incompressible navier stokes equations are widely adopted to describe shallow water flow the sketch of which is shown in fig 1 a for the flow variable u h u h v h t the 2d swes in conservative form can be expressed as follows abbott 1979 chaudhry 2008 1 u t e x f y s in which e and f are the flux vectors s represents the source term vector and are defined as respectively 2 e u h u 2 h g h 2 2 u v h f v h u v h v 2 h g h 2 2 s 0 g h s 0 x g h s f x g h s 0 y g h s f y where u and v represent the vertically averaged velocity components in x and y directions h denotes the water depth g is the gravity acceleration s 0x s 0y s fx and s fy stand for the channel bottom slope and bed friction in x and y directions respectively and can be demonstrated as 3 s 0 x z b x s 0 y z b y 4 s f x n 2 u u 2 v 2 h 4 3 s f y n 2 v u 2 v 2 h 4 3 where z b is the bed elevation n denotes the manning s roughness coefficient 2 2 boundary conditions as shown in fig 1 a the boundary conditions of simulating shallow water flow in non flat bottom channel are divided into two types namely wall boundary and open boundary the two sides of the channel are impermeable wall boundary applied reflective boundary conditions and the upstream boundary conditions and downstream boundary conditions are set according to different flow states when considering the free outflow of dam break flow from the downstream boundary the reflective boundary condition is specified along the upstream boundary and the outflow boundary condition is specified along the downstream boundary when considering the dam break flow in a closed area the upstream boundary and downstream boundary are both wall boundaries so the reflective boundary conditions are adopted in this paper the reflective boundary conditions for the wall boundary are imposed as 5 h n 0 v n 0 v τ n 0 where v u v t denotes the velocity vector n n x n y t represents the outward normal vector τ τ x τ y t is a tangent vector open boundary conditions are divided into inflow boundary conditions and outflow boundary conditions which are also related to the flow pattern for the inflow boundary conditions when the flow is subcritical only the flow discharge is required while both the flow discharge and water depth should be given if the supercritical flow occurs for the outflow boundary conditions if subcritical flow occurs the water depth should be specified and no boundary condition is needed if the flow is supercritical however the governing equations have three dependent variables h u and v therefore when the boundary conditions are missing the governing equation is applied to fill the lack of boundary conditions 3 numerical methods 3 1 local radial point interpolation method lrpim the lrpim combines the rbf and pbf to form the interpolation shape function of subregion whose basic idea is to construct the interpolation shape function to obtain the derivative of the unknown function at a certain node the method avoids the singularity problem of the interpolation matrix and has good convergence and precision and is not sensitive to the selection of shape parameters as shown in fig 1 b distributing randomly nodes in the calculation domain the interpolation function is constructed in the semicircular subregion that each node is taken as the center radius d s the support domain includes n s adjacent nodes including the center point and the accuracy of interpolation depends on the nodes in the support domain therefore only by selecting the appropriate support region the efficient and accurate approximation can be ensured according to the researches of liu and gu 2005 d s 2 0 3 0 d c in which d c can be defined as an average nodal spacing in the support domain of node x i x i y i considering the function f x defined in the computational domain the lrpim interpolation of node x i can be written as 6 f x i j 1 n s r j x i j α j k 1 m p k x i β k r 1 x i 1 r 2 x i 2 r n s x i n s α 1 α 2 α n s p 1 x i p 2 x i p m x i β 1 β 2 β m r x i α p x i β where r x i p x i are a set of rbf and pbf centered on node x i respectively α and β represent the unknown coefficients of r x i and p x i m denotes the number of monomials as a rbf mq function is the most widely used one because it performs best franke 1982 kansa 1990 the two dimensional form of mq function is defined as 7 r j x c 2 r 2 where the distance between the point of support domain and node x i is r x x i 2 y y i 2 c represents the shape parameter and directly affects the convergence accuracy and effectiveness of numerical model it is a sensitive parameter for the determination of the range of c needing further study generally the optimal value can be determined by numerical test the monomial basis function p k x i k 1 2 m in eq 6 is established by pascal triangle ghehsareh et al 2018 then the linear polynomial m 3 is employed to combine with rbf in this paper the coefficients α and β in eq 6 can be determined by satisfying interpolation function f x at n s adjacent nodes in the support domain the matrix form of equations is depicted as follows 8 f r 0 α p m β where f f x 1 f x 2 f x 3 f x n s t is the vector of function values there are n s m unknown variables in eq 8 the polynomial term has to satisfy an extra constraint to obtain a unique solution the following formula is adopted 9 p m t α j 1 n s p k x j α j 0 k 1 2 m combining eqs 8 and 9 we yield 10 α β r 0 p m p m t 0 1 f 0 g 1 f 0 substituting the coefficient into eq 6 we have 11 f x i r x i p x i g 1 f 0 φ 0 x i f 0 the vector shape function corresponds to n s nodes so eq 11 is rewritten as 12 f x i φ x i f where φ x i φ 1 x i φ 2 x i φ n s x i is shape function corresponding to n s nodes the derivative of the function f can be converted into the derivation of the shape function therefore the 1st order and 2nd order partial derivative of the x i node in the x direction are respectively given as 13 f x i φ x i x f j 1 n s φ j x i x f j 14 2 f x 2 i 2 φ x i x 2 f j 1 n s 2 φ j x i x 2 f j similarly the 1st order and 2nd order partial derivative of the x i node in the y direction can also be obtained from the above the lrpim is based on rbf and pbf to construct interpolation shape functions of each node through the derivation of shape function the derivatives of the unknown variables for each node are transformed into linear combinations of function values for nodes in the local support domain and then the governing equation is transformed into constant coefficient equation this feature shows that the lrpim has the flexibility of spatial discretization and the simplicity of implementation process 3 2 solving shallow water equations in this paper based on the av technology introduced by jameson et al 1981 an improved meshless av term is added to the governing equation which can prevent non physical oscillation near discontinuity in solving the wet dry moving interfaces problem of shallow water flow with strong discontinuity then eq 1 are converted to the following form 15 u t e x f y s d u s ε x 2 u x 2 ε y 2 u y 2 where d is a dissipative operator d u denotes artificial viscous term ε x and ε y are represent the viscosity coefficients and calculated in the following sections respectively maccormack method is used to discretize the time term which includes two steps of prediction and correction prediction step 16 u p u n δ t e n x b δ t f n y b δ t s n δ t ε x 2 u n x 2 b δ t ε y 2 u n y 2 b correction step 17 u c u n δ t e p x f δ t f p y f δ t s p δ t ε x 2 u p x 2 f δ t ε y 2 u p y 2 f where the superscripts p and c donate the physical quantities of the predicted and corrected time steps and b and f represent the backward and forward direction of differencing respectively then the numerical solution at the n 1 th time step can be calculated as follows 18 u n 1 u p u c 2 in the traditional maccormack method the difference form is used to calculate the spatial partial derivative and the forward and backward difference operators are used alternately between the different directions of the spatial partial derivative and between the prediction and correction steps of each continuous time step the cyclic change can eliminate the directional deviation of the method and correct its non uniformity in 1d case there are two distinct difference combinations one is that forward difference is used in prediction step and backward difference is adopted in correction step the other is the opposite then calculations of two different combinations are alternately repeated to execute in 2d case there are four various difference combinations franke 1982 fennema and chaudhry 1990 the first combination is represented in eqs 16 and 17 in order to cooperate with maccormack method the wave propagation directions at x i node are divided into four types from up down left and right direction through x i node as shown in fig 1 c the lrpim is used to change the shape of the previous circular support region and improve the selection method of the support region to semicircle the corresponding support region direction is selected according to the forward and backward difference when backward difference is used for spatial partial derivative in x direction support domain in left direction is selected when forward difference is used for spatial partial derivative term in x direction support domain in right direction is selected when backward difference is used for spatial partial derivative term in y direction support domain in down direction is selected when forward difference is used for spatial partial derivative term in y direction support domain in up direction is selected therefore the selection of local support domains can be divided into four types left side right side down side and up side of x i node as shown in fig 1 b when the wave is transmitted from the left hand side of the x i node the local support domain should be selected in the left side of the x i node and other directions are similar according to the selection method of the support domain shape the repeat sequence that four different combinations are alternately applied in four consecutive time steps is adopted table 1 gives the example of a repeated sequence the directions of support domain of prediction and correction step at nth time step are determined by the remainder k which is obtained by dividing nth time step by 4 from the derivation of eqs 13 and 14 the 1st order and 2nd order spatial derivatives of x i node are expressed as 19 f x i b φ x l x i f 2 f x 2 i b φ x x l x i f 20 f x i f φ x r x i f 2 f x 2 i f φ x x r x i f 21 f y i b φ y d x i f f y i b φ y y d x i f 22 f y i f φ y u x i f f y i f φ y y u x i f where the superscripts l r d and u represent the direction of the selected local support domain respectively the improved lrpim is used to discretize the spatial terms in eqs 16 and 17 when the remainder k 1 the discrete form of governing equations will be eventuated as follows 23 u i p u i n δ t j 1 n s φ j x l x i e i n δ t j 1 n s φ j y d x i f i n δ t s i n δ t ε x i j 1 n s φ j x x l x i u i n δ t ε y i j 1 n s φ j y y d x i u i n i 1 2 n i 24 u i c u i n δ t j 1 n s φ j x r x i e i p δ t j 1 n s φ j y u x i f i p δ t s i p δ t ε x i j 1 n s φ j x x r x i u i p δ t ε y i j 1 n s φ j y y u x i u i p i 1 2 n i the other combinations are similar all interior node need to satisfy the governing equation and every boundary node ought to satisfy the boundary conditions then the new system of linear algebraic equations can be generated 25 c 3 n 3 n u 3 n 1 f 3 n 1 where c is a sparse coefficient matrix with respect to variable u and f is a non homogeneous term of the equation the physical quantities h i u i h i v h i i i 1 2 n of each node can be obtained by solving eq 25 the numerical solution at the next time step can be obtained from eq 18 3 3 artificial viscosity based on meshless method based on the traditional 2nd order difference method a new developed meshless scheme of av term is proposed to minimize the non physical oscillation at the discontinuity and accurately capture the shock waves in this paper the 2nd order partial differential form of av term is depicted as 26 d u d x u d y u ε x 2 u x 2 ε y 2 u y 2 in which d x u d y u is the value corresponding to two coordinate directions this paper modifies the calculation of viscous coefficient ε x and ε y based on fennema and chaudhry 1990 we can acquire the viscous coefficient as follows 27 ε x i κ δ x 2 δ y 2 δ t ν x i 28 ε y i κ δ x 2 δ y 2 δ t ν y i where κ is a positive viscosity parameter which is used to adjust the amount of viscosity according to the experience described in this paper the range of its value is between 0 1 2 v x i and v y i denote smoothing parameter in the x direction and y direction respectively in order to cooperate with selecting the local support region of the different direction in meshless method the smoothing parameter of the traditional form is improved into the newly developed meshless form which is computed using the water depth h of all nodes in the support domain the improved meshless v x i and v y i are yielded as follows respectively 29 ν x i j 1 n s h i j r 2 n s h i j 1 n s h i j l j 1 n s h i j r 2 n s h i j 1 n s h i j l 30 ν y i j 1 n s h i j u 2 n s h i j 1 n s h i j d j 1 n s h i j u 2 n s h i j 1 n s h i j d therefore the viscosity coefficient ε is proportional to the water depth h and the viscosity parameter κ selecting the viscosity parameter is a key step in dealing with the numerical instability in the wet dry moving interfaces problem in this paper the av method is to obtain high order accurate solutions in smooth regions and high resolution solutions near strong discontinuities by adding appropriate viscosity kurganov and liu 2012 it is necessary to add enough stable diffusion at the discontinuity but not in the smooth region to maintain the high accuracy of the solution in this paper the strategy is using fewer nodes in the computational domain firstly to find a prior value and then using more nodes in the computational domain for high resolution calculation which can make the calculation cost of the adjustment process lower 3 4 dealing with wet dry moving interfaces in order to accurately simulate the movement of wet dry interfaces in shallow water flow special treatment of wet dry interfaces is needed a simple and effective method to deal with the wet dry interfaces was proposed by hsu et al 2019 the scheme adopts the wls approach to smooth ragged water surface after obtaining the values of the variable based on this method this paper adds av term in the process of obtaining the values of the variable to minimize the oscillation which is not required to detect and smooth ragged water surface the discrete nodes are divided into two groups corresponding to the dry and wet regions the time stepping method only deals with the wet nodes to simulate the movement of wet dry interfaces the nodes around the moving front can switch their states the threshold depth h thre is defined as the critical value of water depth for the transition between the two states when the water depth of the node is equal to or greater than the h thre the node is a wet node otherwise the node is a dry node unless at least one of its adjacent nodes is a wet node whose water depth is higher than the bottom elevation or water level of the node when the water depth is lower than the h thre the wet node switches to the dry node similar to the study of hsu et al 2019 the adjacent nodes in this paper are nodes whose distance from the central node is less than 1 5 times the average distance of local domain nodes the flow chart of the numerical algorithm of wet and dry node change is shown in fig 2 4 numerical results and validations 4 1 one dimensional dam break problem in order to test the ability and merit of the proposed numerical model based on the improve meshless av technology to solve the problem of discontinuous initial conditions and extreme water flow conditions the first example considers the 1d dam break problem that can be used to test the capacity of numerical method to capture shock waves as shown in fig 3 the computational planar domain is a rectangular area with 50 m in length and 10 m in width and the dam is located at x 25 m the channel bottom is flat and frictionless at the beginning of the simulation assuming that the dam is instantaneously removed for some reason t 0 s the entire flow in the domain remains subcritical the ratio of water depth between upstream and downstream is expressed as 31 γ h h u h d in which h u and h d represent upstream and downstream water depth respectively this case contains three tests respectively considering γ h 2 γ h 10 and γ h 100 the water depth in upstream area is set as 1 m and the corresponding downstream water depths are set as 0 5 m 0 1 m and 0 01 m respectively the following parameters are used n 78876 t 0 001s c 0 05 when γ h 2 the viscosity parameter κ is defined as 2 by numerical experiments similarly when γ h 10 and γ h 100 κ is 0 45 and 0 3 respectively in all cases of this paper we adopt d s 2 5 d c and the numerical simulation shows that it can ensure the non singularity of the coefficient matrix and the accuracy of the numerical results the numerical results of water depth h and velocity u in x direction along the central horizontal axis at different times for different γ h are given in figs 4 6 respectively the obtained results are in good agreement with the analytical solution wu et al 1999 which can validate the effectiveness of capturing shock waves by the proposed meshless av method when γ h 2 the provided results accurately describe the motion of shock waves toward the downstream although there are some small difference from the analytical solution with increasing of γ h the results still remain satisfying stability in the discontinuities therefore the meshless numerical model can achieve acceptable expectation moreover in order to verify the accuracy and convergence of the proposed numerical model the comparison between the analytical solutions and the numerical results of different total number of nodes n 3276 n 12801 and n 78876 at t 4 s γ h 2 is depicted in fig 7 it can be seen that with the increase of number of nodes the simulation accuracy gradually improves in addition in order to explore the cost of computing time consumed by the av term the cpu time of each time step expended to obtain the results by adding and not adding av term for different total number of nodes is given in table 2 all of the numerical calculations in this study are conducted on an intel r core tm i7 pc equipped with a 8 gb ram it can be seen that the addition of av term slightly increased cpu time but the ability to eliminate the non physical oscillations was significantly improved it indicates that the calculation cost has little impact by adding av term meanwhile the cpu time is mainly affected by the total number of nodes and is increased as the number of nodes rises the numerical results exhibit that the improve meshless av method can effectively enhance the numerical entropy stable capture shock waves and have enough accuracy in dealing with discontinuous wave problems 4 2 oscillatory flow in a parabolic bowl in this subsection the numerical results are compared with the analytical solutions to verify the feasibility and accuracy of the proposed numerical model in dealing with wet dry moving interfaces problems thacker 1981 proposed two different types of solutions for time dependent nonlinear vibrations one of which contains geometric periodic solutions based on parabolic circular and elliptic bowls the case chosen in this subsection becomes more challenge to involve for a numerical model since the initial configuration of wet dry procedure is non radially symmetric the correct determination of the wet region with acceptable accuracy is the key technology for proposed numerical model as shown in fig 8 the water surface rotates around the center of the area in a parabolic bowl the calculation domain is 4 m 4 m and the bottom terrain is described as 32 z r 1 h 0 1 x 2 y 2 a 2 where the positive constant h 0 0 1 m is the water depth at the center point for the horizontal water surface and the positive constant a 1 m is the horizontal distance from the center point to horizontal water surface of the shoreline the elevation h velocity u and v corresponding to the x and y directions of water surface have the following periodic analytical solutions thacker 1981 nikolos and delis 2009 33 h x y t max 0 1 η h 0 a 2 2 x cos ω t 2 y sin ω t η z 34 u x y t η ω sin ω t 35 v x y t η ω cos ω t where ω 2 g h 0 a and the constant η 0 5 determines the amplitude of the motion the exact solution at t 0 s is used as the initial condition of solving free surface elevation and velocity field this exact solution simulates a free horizontal surface with constant gradient which moves around the center of the bowl at a constant angular velocity at any time without changing its shape the period of solution is t 2 π ω although the solution is relatively simple it is regarded as a test case for most two dimensional methods because it is not driven by external boundary conditions the boundary condition is set to the solid side wall because the flow will never reach the region boundary the following parameters are used n 90601 t t 1000 0 0045 s c 0 007 κ 0 2 and the threshold depth h t h r e 0 001 m the cpu time consumed by each time step is 6 87 s the contour map of water depth at t 2 and t time in a complete rotation period is described at fig 9 comparing the provided results with thacker s analytical solution there are well consistency during the whole period the water surface solved by the numerical method is almost flat and the coastline is almost circular which is close to the analytical solution without distortion figs 10 and 11 exhibit the comparison of the numerical results and analytical solutions along the centerline y 0 at two moments t 2 and t for water depth the numerical solution shows satisfactory agreement with the analytical solution thacker 1981 the moving coastline is accurately calculated there is no false oscillation and the plane form of the free surface remains unchanged throughout the calculation process obtaining the approximation of accurate velocity field is a more difficult for dealing with the moving boundary problem from the comparison of velocity v in figs 10 and 11 a small disturbance appears near the interface of the wet dry interfaces however the position of the wet dry interfaces has been captured and the moving coastline has been accurately simulated therefore we can conclude that the proposed numerical model can be successfully applied to the shallow water flow with wetting drying moving interfaces and improve meshless av method can accurately and stably deal with the wet dry change 4 3 dam break flow past triangle weir from the successful validation in the previous demonstrated cases the proposed numerical scheme with improve meshless av method can simulate shock wave and wet dry processes respectively then a more challenging case conducted by concerted action on dambreak modeling cadam morris 2000 is chosen in the third test to further examine the performance of present scheme since it simultaneously involves discontinuous wave wet dry moving interfaces and complex terrain cadam provided many useful benchmark tests of dam break for numerical verification which are helpful to study the influence of different downstream boundary conditions on dam break flow in the channel with bottom convex and includes various free surface flow patterns such as supercritical subcritical transcritical flow shock surface propagation overtopping flow local reflection hydraulic jump hydraulic head drop and multi wave interaction e g kao and chang 2012 hsu et al 2019 the experimental domain demonstrated in fig 12 a is a rectangular channel with 38 m in length and 1 75 m in width the length of upstream reservoir is 15 5 m the initial water depth is 0 75 m and the gate is located at x 15 5 m there is a symmetrical triangular weir 6 0 m long and 0 4 m high which the top is 13 m away from the gate and the bottom is 10 m away from the gate on the downstream riverbed manning coefficient of the channel is set as 0 0125 and four bathymetric instruments are located 4 m 10 m 13 m and 20 m downstream of the gate for fig 12 a g4 g10 g13 and g20 respectively three different downstream boundary conditions are considered in the experiment one is dry riverbed condition and others are wet riverbed conditions for dry riverbed the whole channel is dry when the gate is opened and the end of the channel is an open boundary as shown in fig 12 a for both wet riverbed the water depth after the triangular weir is 0 15 m two different boundary conditions are applied at the end of the channel one is a closed boundary to prevent water from flowing out of the channel as shown in fig 12 b and the other is open boundary as depicted in fig 12 c the following parameters are used n 4575 t 0 005 s c 0 1 κ 0 2 the threshold depth h t h r e 0 001 m and the total simulation time 40 s the cpu time of each time step is 0 58 s in this case corresponding to three downstream boundary conditions fig 13 a d 14 a d and 15 a d illustrate the numerical results of water depth temporal variations at four measuring points g4 g10 g13 and g20 for three different downstream boundary conditions respectively at g4 near the reservoir when t 12 s and t 35 s the water depth suddenly rises which indicates the passing of incident shock wave and the local reflection of overtopping shock wave through the bulge respectively g10 is located at the upstream slope toe of the bulge and the water depth evolutions of the three conditions are almost identical however the variations of water depth at g13 at the top of the bulge and g20 downstream of the bulge are somewhat different because the different boundary conditions at the end of the channel the comparisons with the experimental results and the numerical results of kao and chang 2012 and hsu et al 2019 show that the simulated results can predict the flow evolutions as well for the open downstream boundary conditions as exhibited in figs 13 and 15 the water depth and arriving time of shock waves at g4 and g10 are slightly different by comparing with experimental data but the simulated results are closer to the experimental results than the results of kao and chang 2012 in the process of water depth decline the consistency between the results of present method and the experimental results can be clearly observed at g13 at g20 the simulated results can track the trend of experimental results and have only few discrepancies for the closed downstream boundary conditions as shown in fig 14 the simulated results are quite close to the numerical results of hsu et al 2019 the differences from experimental data at g4 and g10 also exist in the results of hsu et al 2019 at g13 and g20 the model can accurately predict water depth it should be noted that the oscillations still occur at strong discontinuity in fig 14 when the end of the channel is closed the possible reason may be that the simulated results of the closed downstream boundary conditions are quite sensitive to the selection of viscosity parameter κ because the flow is reflective and highly complex when the end of the channel is closed the selection of κ as kurganov and liu 2012 expressed is a delicate issue and key step to eliminate oscillations by the av method the optimizations of κ election will be our future work for further study to eliminate the remaining oscillations in addition according to fennema and chaudhry 1990 the oscillations near discontinuities are due to truncation errors and are part of the diffusive properties of the numerical scheme since the tuning of av is based on the κ and the water depth h by eqs 27 30 and the value of av can be adjusted continuously according to the varying h the proposed av method has some certain applicability in dealing with real problems in this way the sharp resolution of the discontinuities without producing non physical oscillations can be obtained while the viscosity hardly need be adjusted in the smooth region in general the proposed numerical model has the ability to reasonably and effectively simulate complex dam break flow with wet dry moving interfaces 4 4 dam break flow past three cone shaped mounds as a last case the wet dry change process of dam break flow passing three cone shaped mounds is simulated for the further validation of the proposed meshless model this experiment conducted by kawahara and umetsu 1986 can be adopted as a 2d numerical experiment to test the wet dry change process and many researchers have also done relevant research e g brufau and garcıa navarro 2003 delis and katsaounis 2005 nikolos and delis 2009 hsu et al 2019 as shown in fig 16 the computational domain is a 75 m 30 m rectangular channel and the gate is located at x 16 m the initial water depth in upstream region is 1 875 m the downstream region is dry initially and the manning s coefficient is set as 0 018 the whole channel is closed and the four side boundaries are set as wall boundary the topography in the downstream region is defined as 36 z x y max 0 1 4 30 x 30 2 y 22 5 2 1 4 30 x 30 2 y 7 5 2 2 5 0 25 x 47 5 2 y 15 2 in this case the following parameters are adopted n 25351 t 0 001 s c 0 2 κ 0 1 and the threshold depth h thre 0 001 m the cpu time of each time step is 1 45 s the three dimensional views of the propagation of dam break flood at 2 5 8 13 5 20 28 and 100 s are described at fig 17 which illustrate that the propagation has the expected physical characteristics at t 2 5 s fig 17a the dam break wave reaches the top of two lower mounds at t 8 s fig 17b two lower mounds have been submerged and the water flow reaches the highest point of slope in front of the latter higher mound at t 13 5 s the water passing through the three mounds has reached the downstream side wall as depicted in fig 17 c so the water level can be seen to rise in the two corners of the downstream meanwhile the backward propagating wave reflected from the higher mound is obvious at t 20 s the reflected wave from the higher mound has just reached upstream side wall while another reflected wave has just appeared at the downstream side wall seen in fig 17 d at t 28 s the reflected wave from the downstream side wall has reached the back of the higher mound as shown in fig 17 e after the interaction of the wave wave wave topography and wave wall the water in the flume gradually calms down due to the friction dissipation effect at the bottom at t 100 s fig 17f the water flow has become stable in order to further verify the accuracy of the simulated results the evolutionary profiles along the horizontal central axis of the dome y 7 5 m and 15 m at t 8 s and 28 s are depicted in fig 18 a d at t 8 s the free surface profiles are almost identical with the research results of local polynomial approximation lpa with wls by hsu et al 2019 the surface profile along y 15 m is higher than along y 7 5 m due to the latter higher mound when time t 28 s the surface profiles both fluctuate slightly and calm down gradually from the results and comparisons it s demonstrated that the numerical model with improve meshless av method can stably and accurately simulate dam break flood with wet dry change process on complex terrain with steep slope 5 conclusions in this paper an improved meshless av method is proposed to effectively capture shock waves and combined with the lrpim and the maccormack method to establish a new numerical model for solving the moving wet dry interfaces problems of shallow water flow the lrpim is adopted to discretize the spatial terms of governing equation then the maccormack method is used to separate the temporal terms and accurately captures the propagation direction of the wave the selection direction of support region in lrpim is also introduced to cooperate with the maccormack method the proposed av method is a new meshless form combining with the lrpim whose viscosity coefficient is related to the direction of the local support region the gradient is adjusted by establishing the viscosity coefficient ε which is proportional to the water depth h and the viscosity parameter κ the value of viscosity coefficient is automatically adjusted according to the local properties of h in this way a large number of numerical viscosities are added to the non smooth region for smoothing oscillations while the viscosity is much smaller in the smooth region for remaining the high accuracy the advantage of this method is that the steep region is smoothed while the smooth region is not disturbed which maintains the entropy stable of numerical simulation of wet dry moving interfaces problems with the strong shock waves moreover the calculation process of this method is simple and effective four challenging numerical examples were selected to evaluate the numerical model firstly the capacity of the proposed meshless av method to capture the shock waves is successfully examined by 1d dam break problem the results obtained by adopting the different ratio of water depth γ h depict that the numerical model still maintains satisfying stability near discontinuities under discontinuous initial conditions and extreme flow conditions moreover there is well comparison with the analytical solution secondly the case of oscillatory flow in a parabolic bowl proves the feasibility and accuracy of the meshless numerical model for dealing with wet dry moving interfaces finally the propagations of 1d and 2d dam break flow with wet dry change and complex bottom topography are simulated by the numerical model because of the flexible distribution of nodes the meshless model has strong adaptability to the complex terrain the water flow profiles are precisely acquired which agree well with other numerical and analytical solution in general the numerical simulation results demonstrate that the proposed model with improved meshless av scheme can be a promising method for solving wet dry moving interfaces problems in the complex bottom terrain of shallow water flow however the nonlinear oscillation has not been completely eliminated in the simulation of the complex dam break flow because of the sensitivity of viscosity parameter κ the optimizations of κ election will be our future work for further study to improve the accuracy and parallel calculation can be considered to improve the calculation efficiency declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors are grateful to the national natural science foundation of china grant no 51679042 and no 52079032 for the financial support of this research 
20376,the number of construction offshore wind turbines owts is gradually increasing with high clean energy demand and low technology costs during their service life a large number of ships will inevitably collide with owts which results in collapse load acting on the owt foundation this paper proposes a novel fender for the owt exposed to extreme collision using the fractal structure as the first step toward protecting the safety of the owt structure the proposed the fractal structure is based by the cartesian circle which defined by tangent circle theorem applied to ring protection design the paper investigates the anti collision performance of fractal structure fender on the simulated response of the tripod owt installed in the coastal waters by comparing tradition and fractal structure furthermore the difference of external diameter and different orders are discussed under the collision actions which are implemented in the ls dyna the results show that with the increase of the order of fractal pores structure of the first order fractal pores is good for the fender to absorb enough collision energy and the anti collision performance of fender increases by the greater mass keywords offshore wind turbine collision fractal structure fender ship 1 introduction wind turbines have been used in production and living by humans widely for many centuries such as pumping water and grinding grains ding et al 2018 feng et al 2015 recently the inherent kinetic energy of wind is an extremely efficient clean energy for providing endless power for developing society when the global energy demand has skyrocketed and increased pollution in fact the installed capacity of wind energy worldwide grew from 24 gw in 2001 to 741 7 gw in 2020 furthermore onshore wind energy is becoming saturated and the development tendency of it has been from the lands to the marine areas which reveals that the offshore wind turbines owts must be built quickly due to the high velocity of wind low degree of turbulence and less land resources occupied et al which are the advantage of offshore wind power however dense the navigation routes and an increase in the number of offshore wind farms lead to more collisions between owts and ships for the safety of owts two methods have been proposed in the engineering 1 the structure of the owt should maintain sufficient residual strength so that it can resist environmental and collisional loads before it can be repaired 2 guided by the conventional fender of oceanic platform we shall then design a suitable fender for owt based on the rubber material the common foundation types for owts are monopoles jacket and tripods which have been tried in several wind farms in fig 1 and the distributed wind power is developed widely so the tripod is primarily steered by the equipment construction level and high stability in china currently the fenders are mainly used in ship ship ship bridge pier and ship marine platform collision lehmann et al 2002 used the steel structure as fender to absorb the most energy in the process of collision between ships and verified the anti collision performance of the fender by experiment and numerical simulation wang et al 2008 have presented the new type of composite steel structure fender which has ability to protect the bridge from damage they discuss the steel material and structure as fender which essentially design the fender and describe the anti collision ability from material and structure in the field of wind turbines liu et al 2015 have provided detailed account of general dynamic behavior of fender of owts and optimized the material properties and material thickness of the fender ren et al 2009 proposed the spherical shell type prismatic fender with the monopile wind turbine by ship collision furthermore they provide new methods to improve the anti collision capability of fender in comparison to bridge and ocean platform there exist less detailed guidelines about fender structural design of wind turbine in order to reduce the cost and improve the performance of anti collision some new structures were designed zhou 2015 used fractal technology for the antenna in traditional communication equipment which made the modified antenna could realize the miniaturization of ultra wideband antenna fan et al 2019 realized the combination of light energy and mechanical energy gathering and storage and improve the energy storage efficiency of fabric devices by fractual structure staggered braiding however it is not found that the fractal theory is involved in the structural design in the field of traditional fender of owts this paper introduces the fractal characteristics into the fender for the first time in order to provide reference value for the research of anti collision and vibration reduction of owts 2 fractal theory the fractal theory is proposed by mandelbrot which has been applied in the structural design because of its two characteristics of self similarity and space filling fractal referred to the set of complex points in a simple space is a new discipline established by the predecessors to observe the natural landscape and the irregular movement of molecules and atoms which spans all fields and promotes the understanding of natural laws and physical essence the set mainly has the following geometric properties 1 fractal structure has space filling is irregular on the whole but has fine structure and from the mathematical perspective the definition of fractal structure is that the fractal dimension is greater than the topological dimension of the geometric structure 2 fractal structure has the characteristic of self similarity to some extent the whole is proportion to the part the classical fractal structure is mainly as follows koch sierpinski cantor minkowski et al as shown in fig 2 object representation can only be reflected through traditional geometry by defining integer dimension while fractional dimension reflects internal characteristics of the structure the study of fractal dimension can obtain the following properties 1 the fractal dimension does not change with the angle observed meanwhile the fractal dimension will not change when the fractal structure change linearly 2 fractal dimension can be measured by experiment 3 the definition and generation of fractals can be analyzed by iterative method strict fractals only exist in theoretical research and it is usually obtained after approximation in daily life here the concept of fractional dimension is introduced into the fractal theory which makes the fractal idea more complete so as to understand the natural things objectively in order to apply the fractal theory more accurately and conveniently the research method of iterated function system ifs is proposed and used to describe the fractal structure and the process is to iterate the simple structure step by step the linear transformation is mathematically called affine which can be expressed by formula 1 w x y a b c d x y e f s h o w w x y ax by e cx dy f 1 where a b c d e and f are all real numbers the self affine change can be expressed a b e c d f 2 where a b c d control the scaling and rotation angle e and f control linear forward and backward or up and down movement assuming an initial gather a exists there are various affine transformations of w1 w2 wn acting on a which can be written as follow 3 w a w 1 a w 2 a w n a n 1 n w n a iteration until convergence w a m a m can be obtained so a m is the attractor of the iterative system function the field of structural design can establish by iterative systems through the process of learning function generation 3 structural design the circular fractal fender proposed is based on cartesian circle theorem by using the tangent circle theorem the fractal circle shape can be divided by the relevant radius of the four tangent circles the radius of curvature of the geometric structure formed by the four tangent circles is expressed as follow a i b i c i d i 2 2 a i 2 b i 2 c i 2 d i 2 i 1 2 4 where a i 1 r a i b i 1 r b i c i 1 r c i d i 1 r d i are the curvatures of the original four tangent circles respectively the relative radiuses are r a i r b i r c i r d i separately i is a positive number expressing the order of the iteration as shown in fig 3 in the first iteration three inner circles with a radius of r b i r c i r d i serial number 2 4 are subtracted from the original circle with radius r a i serial number 1 which is called the first iteration structure then three arbitrary circles in the first iteration are selected to determine the fifth circle in the second iteration therefore a total of 4 additional circles have been generated inside with radius re2 1 serial number 5 7 and re2 2 serial number 8 respectively now these four circles are also subtracted from the original circle with radius rai serial number 1 which is called the second iteration structure in the third iteration order combine any two of the four initial circles in the first iteration order with any one of the four new circles in the second iteration order to determine the ninth circle in the third iteration order a total of 12 new circles with different radius sizes were created which are inner circles of rf3 1 serial number 9 14 rf3 1 serial number 15 17 rf3 1 serial number 18 20 respectively these 12 circles are also subtracted from the original circle with radius rai serial number 1 which is called the third iteration structure on the basis of cartesian circle theorem this iterative process can be repeated indefinitely however due to the limitation of processing conditions the boundless infinite iterative structure is impossible to achieve so this paper proposes fender with fractal hole whose structure is shown in fig 4 the overall size of the fractal holes rai 0 625 m rbi rci rdi 0 25 m re2 1 0 125 mm re2 2 0 03 mm rf3 1 0 06 mm rf3 2 0 025 mm rf3 3 0 01 mm 4 the description of motion equation and algorithm 4 1 motion equation the governing equation of collision system between ship and offshore wind turbine can be expressed as men et al 2015 abrate 2011 bai 2005 m u c u k u f h 1 m a f 0 2 where m is the mass matrix c is the damping matrix k is the stiffness matrix f is matrix of the impact load acting on the structure h is the viscous damping force matrix of the hourglass u u u is the acceleration velocity and displacement at the time of t m is the mass of ship a is the acceleration of the ship f is the collision force of the ship at the time of t 4 2 contact algorithm ls dyna provides different types of contact forms mainly including contact between deformable body and deformable body contact between discrete points and deformable body single sided contact between different parts of the deformable body itself contact between deformable body and rigid body contact with deformable structure and contact with deformable structure according to failure criteria han et al 2019 the interface of contact and collision mainly adopts three different algorithms node constraint method symmetric penalty function and assignment parameter method different structures may happen to contact by the surfaces which can be divided into master contact surface and slave contact surface the corresponding cells are called master and slave slices and the nodes are called master and slave nodes shen 2009 the node constraint method is the earliest contact algorithm its basic principle is to modify the configuration at each time step length check whether the slave node penetrates when there is no master slave contact and if so reduce the time step so that the slave node does not penetrate from the next moment the collision condition is applied to the slave node that has just reached the main surface and the constraint condition is applied to the slave node that has contacted the main surface so as to keep the slave node in contact with the main surface in addition check whether there is a tensile interface in the cell belonging to the slave node contacted by the main surface and if there is make the slave node separate from the main surface wang et al 2017 the distribution parameter method is only used for sliding processing in the program its principle is to distribute the half mass of each contact element to the main surface area of the contact and to determine the distributed pressure acting on the main surface area of the receiving mass by the internal stress of each slave element after the mass and pressure distribution is completed the acceleration of the main surface is modified and then the acceleration and velocity of the slave node are constrained to ensure the movement of the slave node along the main surface the basic principle of symmetric penalty function method is to check whether each slave node in each step penetrates the main surface if the slave node does not penetrate the slave node is not processed if the slave node penetrates it is assumed that a relatively large contact load is generated between the slave node and the penetrated main surface in addition the amount of contact load is proportional to the penetration depth and the stiffness of the main piece and the amount of contact load is defined as the penalty function value on the basis of processing the slave node according to the above principle the program processes the master node again according to the above principle which forms symmetry the symmetric penalty function method has the advantages of symmetry and momentum conservation but the value of the penalty function is constrained by the stability to some extent if it appears obvious penetration the value of the penalty function or reducing the time step can be adjusted by enlarging 4 2 1 hourglass energy the hourglass model which appears deformation without stress or strain in finite element analysis is a non physical zero energy deformation model a single point of integral method is used to integral space and gaussian point to the center unit overlap if the method can greatly reduce the cpu time and the unit calculation points less than the actual individual points of the shell unit and entity unit it s easy to generate zero pattern caused by the structural response of natural oscillation cycle which have a short integration time and jagged grid deformation the hourglass mode is presented in fig 5 the velocity gradient that defines the strain rate is centered on the element while the velocity and nodal force are centered on the node therefore the strain rate and shear rate in the x and y directions can be obtained from equations 3a 3b and 3c 3a ε x x x x x 2 x 4 y 3 y 1 y 2 y 4 x 3 x 1 2 a 3b ε y y y y y 2 y 4 y 3 y 1 y 2 y 4 y 3 y 1 2 a 3c ε x y 1 2 y x x y when a pair of nodes on the diagonal of the element has the same velocity the strain rate in equation 3 is zero indicating that the element stress does not limit the hourglass mode and the strain calculation is orthogonal to it so the hourglass energy can be ignored in the energy equation when the hourglass period is the same as the structural response period the hourglass pattern can be allowed to exist if the hourglass period is higher than the structural response period the hourglass model is not desirable in order to control the growth of the hourglass and avoid the excessive structural response caused by the suppression of the hourglass a viscous term is introduced to the local element stress in the control mode belytschko et al 1985 believes that in the two dimensional case there are only two modes of solid element and shell element and the hourglass control of axisymmetric solid element is consistent with the shell element method the hourglass vector τ i is introduced 4 τ i h i h j x ˆ α j b α i where subscript i represents the sum of all nodes of the cell α 2 b α i is the shape function derivative evaluated at the center of the element h i h j are the base vecter x ˆ α j is the regression coefficient that produce a deformation pattern which can be ignored under the single point integral method equation 5 is as follows 5 h i 1 1 1 1 the calculation formula of hourglass strain rate τ i is as follows 6a q α b τ i θ ˆ α i 6b q 3 b τ i υ ˆ z i 6c q α ℕ τ i υ ˆ α i where b and ℕ represent bending and thin film modes respectively q is the derivative of stress force υ ˆ α i is the rate function derivative of the element center in addition the calculation formula of the hourglass stress rate is as follows 7a q α b r θ e ς 3 a 192 b β i b β i q α b 7b q 3 b r w κ g ς 3 a 12 b β i b β i q 3 b 7c q α m r m e ς a 8 b β i b β i q α m where ς is the thickness of shell parameter r θ r w r m value range 0 01 0 05 e and g are shape parameters the calculation equation 8 of hourglass force can be obtained as follows 8a m ˆ α l h τ i q α b 8b f ˆ 3 l h τ i q 3 b 8c f ˆ α l h τ i q α m where h is the change coefficient of internal force caused by hourglass deformation q is the hourglass stress m ˆ α l h f ˆ α l h and f ˆ 3 l h are the hourglass forces of different shapes and positions the calculation equation 9 of the hourglass stress rate is as follows 9 q n 1 q n δ t q the internal node force control distortion is introduced in ls dyna with the keyword control hourglass 4 2 2 time step in this paper the explicit central difference is used to solve the motion equation when time is n the matrix expression of semi discrete motion equation is 10 y a n p n f n h n where y is diagonal mass matrix p n is the internal and external load matrix f n is the stress divergence h n is the hourglass resistance the global node velocity v and displacement vector u are calculated by the following equation 11 a n m 1 p n f n h n 12 v n 1 2 v n 1 2 a n δ t n 13 u n 1 u n v n 1 2 δ t n 1 2 14 δ t n 1 2 δ t n δ t n 1 2 where m 1 is the parameter t is the time it updates the geometry element by adding displacement increment to the initial geometry 15 x n 1 x 0 u n 1 system development can be determined without iterative computation but there are also some stability problems with this simple method the time discretization error changes with time so the explicit calculation method is considered to be conditional stability to avoid these problems the determination of time step should be based on stability in addition the time step is set to be less than the stable condition of it which can be determined according to the unit size and attributes for the one dimensional steady state problem the time step is usually limited by the courant condition 16 δ t δ x a where δ x is the minimum size variable of the unit a is the speed of sound in the material unit in ls dyna the equivalent formula of critical time step is 17 δ t 2 ω max where ω max is the highest natural frequency when considering damping the time step is reduced as follows 18 δ t 2 ω max 1 ξ 2 ξ the calculated time integral evaluates the minimum critical time step and reduces the safety factor value is 0 8 0 9 19 δ t α min δ t c r 1 δ t c r 2 δ t c r n 5 constitutive materials and finite element model 5 1 constitutive materials ls dyna is available for user defined development and has a wide variety of material models and collision between ship and offshore wind turbine involves the plastic deformation of materials which is a nonlinear dynamic response process moreover the material is in a high strain rate during the collision process which has obvious dynamic characteristics so the sensitivity of material strain rate should be taken into account in the calculation and analysis therefore according to the classification of elastic plastic material model five isotropic materials related to strain rate are selected follow up plasticity power hardening plasticity piecewise linear plasticity plasticity and power exponential plasticity 2 4 and 5 material models can be used for metal plastic molding analysis while 1 and 3 models can be used for steel the cowper symonds model has a high degree of agreement with experimental data and the influence of strain rate sensitivity of materials is taken into account to define material failure therefore this paper plans to use follow up plastic materials for simulation gurpinder et al 2020 5 1 1 steel the tower and bow materials of the wind turbine are q235 and the outermost shell materials of the single column three pile foundation and protective device are q345 according to nonlinear elastoplastic material model provided by ls dyna gladman 2007 and the effect of strain rate on material yield strength a steel constitutive model hyung et al 2018 was established based on the cowper symonds relation which can simulate the material properties of the impacted tower effectively the expression is as follows σ y 1 ε c 1 p σ 0 β e p ε e f f p 20 where σ y is the ultimate yield stress σ 0 is the initial yield stress c and p are a constant related to the properties of the material for general steel c 40 5 p 5 ε is the strain rate β 0 is the plastic follow up strengthening model and 1 is the isotropic strengthening model e p is the plastic strengthening modulus ε e f f p is the equivalent plastic strain rate the physical parameter of ρ is density e and e t are the elastic modulus and tangent modulus respectively and υ is the specific volume as shown in table 1 5 1 2 5ogden rubber the ogden rubber constitutive model in ls dyna is the core protection material and the contact mode of automatic surface to surface with the outer steel shell is to simulate the deformation contact of the structure during the collision the automatic single surface is adopted between the bow and the three pile wind turbine tower in which the dynamic and static friction coefficient is 0 2 and the attenuation coefficient is 0 the constitutive parameters are shown in table 2 5 2 fender fig 6 shows the finite element model of fractal structure fender built in the ansys workbench a pretreatment of software ls dyna in which the mesh was divided by multi domain partitioning method due to the complexity of fractal structure the quality of grid division has an impact on the accuracy and efficiency of calculation therefore selecting appropriate grid size is important to improve the generation rate and accurate calculation of grid as shown in fig 6 the structure complexity increases with the increase of fractal order the fender is divided into two meshing regions one is the domain where the fractal hole is located the other is general region according to the order of fractal hole the appropriate mesh size is selected after continuous simulation which is 0 05 m 0 06 m and 0 08 m respectively 5 3 tripod the basic structure of the tripod is mainly composed of column diagonal brace transverse brace and steel pipe column the steel pipe column is buried to a depth of 50 m and the pile tip enters the powdery sand layer on the seabed exposing the sea surface by 2 m 3 m the 4 mw wind motor is composed of tower nacelle hub blade and electrical system the specific parameters are shown in the literature hao et al 2017 the main parameters of single pillar and three piles foundation are shown in table 3 5 4 ship the common ships are selected and the type of bow is forward tilt according to the local damage characteristics and structural design of the ship a finite element model is established for the collision by shell163 which is divided into collision zone and non collision zone in the collision zone the interior calculation model of bow structure is composed of actual structure layout plate thickness and skeleton information besides the non collision zone mainly includes hull and stern in order to ensure the accuracy of the calculation results an appropriate mesh was encrypted at the contact surface between bow and the tripod structure at the same time the collision force is transferred reasonably between the hull and the tripod structure and the master slave contact method is adopted the dimensions of the ship s main components are shown in table 4 the interaction between ship and seawater cannot be neglected during collision between the ship and the tripod foundation in order to study the interaction between ship and water a fluid solid coupling model or an additional mass model is often used therefore the additional mass method is adopted for the interaction between the ships and water in this paper zhang et al 2017 and the additional mass coefficient is selected as 0 05 6 model validation under the collision conditions of 5000 t ship with 2 m s the fender of tripod is impacted by the ship and the process of energy conversion is shown in fig 7 hull initial kinetic energy is converted into multiple parts the ship s remaining kinetic energy kinetic energy tower structure deformation energy internal energy and sliding friction energy hourglass is generated due to the hourglass phenomenon and damping energy is came out tower in its damping external damping complex and does not affect the research purpose under the action of vibration damping et al fig 7 shows that with the increase of time the conversion of internal energy and kinetic energy occurs at tradition and fractal fender 0 75s 0 63s it can be seen that the existence of fractal structure makes the energy conversion time advance at 1 06s the maximum internal energy and minimum kinetic energy appear in the collision process and the difference between the tradition and fractal fender are 8 62 mj and 8 74 mj respectively the fractal has a certain influence on the energy absorption characteristics of the fender besides the deformation energy internal energy began to decline when ship is apart from point of the collision and the curve of energy happens a range fluctuation at the end of the collision in addition the more deformation energy can be converted into kinetic energy by fractal fender when the collision happens and the curve of system of kinetic energy relative to the trend of structure deformation can be symmetrical on the contrary and decreases slowly under the damping of sea and the action of wind and soil 7 different orders with the same external diameter 7 1 anti collision performance of fender the study keeps the original ring volume the same external diameter of three kinds of fractal hole fender constant and the fractal holes are only generated on the base of the original fender and the other parameters are not changed they are also compared with the solid protection device fig 8 shows the size of four fenders as shown in fig 8 when the overall volume of the protective device is constant the mass of the protective device decreased on the account of the existence of fractal holes in order to further study the anti collision performance of the fractal protection device the change of contact force in ship collision process can be seen in fig 9 fig 9 shows that the variation trend of contact force curves of the four types of fenders first order second order third order and solid is relatively same and with the increase of time the curve is always on the rise from the initial stage of ship movement to the initial deformation compared with the solid fender the three contact force of the fractal fenders increase slowly in the early stage of collision and are obviously smaller than the solid fender when the process of collision goes deeper the contact force of solid fender reaches the maximum earlier than the other curves of fractal fender the reason is that the fractal hole is impacted by ships and the walls are interlacing with each other which prevent the contact force from reaching the maximum value and during the compression process part of the collision contact force is eliminated through the interaction between the holes after the ship left the protective device the contact force curve of the solid protective device decreased rapidly and ended at 1 35s while the decline rate of the fractal structure was slower the curve ended at 1 51s which is 0 16s later than the solid device with the mass of the fender increases the collision contact force decreases accordingly and the contact force can be reduced by the first order fractal hole and the time of the contact force applied to the offshore wind turbine foundation is extended in the process of ship collision as seen in table 5 as shown in table 5 with the increase of the fractal order the maximum contact force first increases and then decreases compared with the solid fender maximum reduction ratio of the first order contact force is 3 93 it can be concluded that when the outer dimension of the fender keep constant the increase of fractal order has no obvious effect on the contact force and the required time for collision is greater than that for solid device in order to explore the structural change and energy absorption of fractal fender in the process of compression the change trend of fractal hole from elastic deformation to plastic deformation is analyzed 7 2 stress and energy absorption in the ls dyna the several moments are picked as following 0 42s 0 6s 0 87s 0 9s 1 11s and the moment when the plastic deformation is completed which could show the stress change and deformation of the fractal hole and the fender profile is given to analyze the dynamic characteristics of the hole after impact as depicted in fig 10 with the increase of time the maximum stress was concentrated in the impact zone of steel shell and only 43 5 mpa stress penetrated into the rubber material the super elastic energy of rubber material can be uniform under the action of the fractal holes and the fractal holes maintained in a certain shape in the impact without cross or overlap in addition the plastic deformation of the protective device with second order fractal holes is obviously large fig 11 shows the pressure distribution in the protection device under the maximum contact force of different orders the area with high pressure concentrates mainly on the outer steel shell and the connection between the protection device and the wind turbine foundation while the pressure in the fractal hole is balanced and the internal pressure of the second order protection device is still the maximum the resistance of internal pressure to external collision force inevitably causes the change of internal energy so the change rule of internal energy is analyzed as shown in fig 12 the change of internal energy of rubber with first order fractal hole is greater than that of steel shell however the internal energy of steel shell is greater than rubber with second or third order fractal hole this is because the plastic deformation of the first order deformation hole has a great impact on the elastic properties of rubber material the elastic properties of the second order and third order holes remain in the elastic plastic deformation zone when the peak of internal energy passes it changes little when system is stable 8 different orders with the different external diameter 8 1 contact force and energy absorption the condition is keeping the quality of the fender constant the different external diameter and three kinds of fractal fenders and solid fenders were compared analysis of its anti impact properties from the contact force is shown in fig 13 from fig 13 it can be seen that the size of the maximum contact force value second order third order first order in the next order the contact force of the same mass protection device first increases after the ship completely impact on the protection device the curve fluctuates obviously and the violent fluctuation of contact force is caused by the significant inertia effect because of the increase of mass of the fender which causes vibration response increase the reverse disturbance of fenders in the process of ship collision the statistics of collision parameters are shown by table 6 it can be seen from the table that the collision time increases with the increase of order of fractal hole compared with the solid protective device the fractal protective device with the same mass has better protective effect in addition the variation of the internal energy of the protective device is analyzed as shown in fig 14 it can be seen from fig 14 that before the ship leaves the wind turbine the internal energy value of the rubber material in the fender is larger than that of the steel shell and then it is reduced to the minimum value at this time the fractal hole is in the elastic plastic deformation stage the elastic part recovers a certain shape to affect the change of the internal energy of the rubber since the internal structure of the second order fractal hole is not under uniform stress the rubber structure fails to recover energy quickly 8 2 stress strain analysis based on this the stress and strain of the first second and third order fender are analyzed and the impact response of the fenders under ship collision is further studied as shown in fig 15 compared with the second order fractal the reduction percentage of maximum fractal stress of first order and second order is 3 27 and 1 74 respectively the strain of the second order protective device is intense as the increase of collision time the effect of strain slows down and the plastic strain increases the maximum plastic strain of the first order second order and third order protective device are 0 0137 0 0196 0 0144 respectively it can be known that the second order fractal hole is not suitable for the protection device but the first order fractal hole improves the anti collision performance see fig 16 9 top acceleration response the offshore wind turbine is affected by the collision of ship its top acceleration changes are shown in fig 17 as time goes on the acceleration curve has different nonlinear properties under different fractal protection device compared with solid the acceleration response of fractal protection device is more severe and the acceleration response would increase with the increase of the mass of the fractal protective device table 7 shows the difference of the acceleration as shown in table 4 when the mass of fractal protection device increases the average acceleration increases in addition the average acceleration decreases as the fractal order increases under the same volume while the acceleration decreases first and then increases under the same mass according to simens the maximum allowable acceleration of engine room is 6 m s 1 the acceleration of the fractal protection device is under this value but it is still greater than the solid protection device which is the result of the vibration increased by the fractal hole 10 conclusions the paper is based on the internal and external dynamics the ls dyna is used to simulate the collision process where the ship impact the tripod by introducing fractal geometry and combining with the existing ring structure the cartesian circle fractal structure is constructed by tangent circle theorem to realize the protection device with fractal structure and the collision resistance performance of the protection device with different fractal order under the same and the different external diameter has been compared and analyzed firstly by comparing the collision resistance characteristics of the same external diameter with different order protection devices it is found that the contact force reduction ratio of the first order fractal structure is at most 3 93 and its plastic deformation region promotes the enhancement of energy absorption of rubber material under the different external diameter the same mass the first order fractal structure reduces the collision force of ships by 12 94 and has better internal energy and stress strain capacity than the second order and third order fractal structure secondly the comparative study of fractal holes of different order shows that the effect of the first order fractal on improving the impact resistance of the protection device is particularly obvious while the second order fractal has poor performance in the aspects of contact force internal energy change and stress strain the interaction deformation between elasticity and plasticity is the main reason for the unstable impact resistance of fractal holes under different orders finally by comparing the anti collision characteristics of different mass protection devices it is found that the anti collision ability of fractal protection is enhanced with the increase of mass but the response effect of fractal structure to the acceleration suppression of tower top is significantly weakened compared with that of solid structure under the permissible range of acceleration of wind turbine nacelle credit authorship contribution statement xinzhi yue writing original draft conceptualization data curation formal analysis zhiwei han investigation methodology chun li resources supervision project administration funding acquisition xinlei zhao investigation qingsong liu writing review editing validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is supported by the national natural science foundation of china 51976131 51676131 shanghai university science and technology innovation action plan local university capacity building project 19060502200 
20376,the number of construction offshore wind turbines owts is gradually increasing with high clean energy demand and low technology costs during their service life a large number of ships will inevitably collide with owts which results in collapse load acting on the owt foundation this paper proposes a novel fender for the owt exposed to extreme collision using the fractal structure as the first step toward protecting the safety of the owt structure the proposed the fractal structure is based by the cartesian circle which defined by tangent circle theorem applied to ring protection design the paper investigates the anti collision performance of fractal structure fender on the simulated response of the tripod owt installed in the coastal waters by comparing tradition and fractal structure furthermore the difference of external diameter and different orders are discussed under the collision actions which are implemented in the ls dyna the results show that with the increase of the order of fractal pores structure of the first order fractal pores is good for the fender to absorb enough collision energy and the anti collision performance of fender increases by the greater mass keywords offshore wind turbine collision fractal structure fender ship 1 introduction wind turbines have been used in production and living by humans widely for many centuries such as pumping water and grinding grains ding et al 2018 feng et al 2015 recently the inherent kinetic energy of wind is an extremely efficient clean energy for providing endless power for developing society when the global energy demand has skyrocketed and increased pollution in fact the installed capacity of wind energy worldwide grew from 24 gw in 2001 to 741 7 gw in 2020 furthermore onshore wind energy is becoming saturated and the development tendency of it has been from the lands to the marine areas which reveals that the offshore wind turbines owts must be built quickly due to the high velocity of wind low degree of turbulence and less land resources occupied et al which are the advantage of offshore wind power however dense the navigation routes and an increase in the number of offshore wind farms lead to more collisions between owts and ships for the safety of owts two methods have been proposed in the engineering 1 the structure of the owt should maintain sufficient residual strength so that it can resist environmental and collisional loads before it can be repaired 2 guided by the conventional fender of oceanic platform we shall then design a suitable fender for owt based on the rubber material the common foundation types for owts are monopoles jacket and tripods which have been tried in several wind farms in fig 1 and the distributed wind power is developed widely so the tripod is primarily steered by the equipment construction level and high stability in china currently the fenders are mainly used in ship ship ship bridge pier and ship marine platform collision lehmann et al 2002 used the steel structure as fender to absorb the most energy in the process of collision between ships and verified the anti collision performance of the fender by experiment and numerical simulation wang et al 2008 have presented the new type of composite steel structure fender which has ability to protect the bridge from damage they discuss the steel material and structure as fender which essentially design the fender and describe the anti collision ability from material and structure in the field of wind turbines liu et al 2015 have provided detailed account of general dynamic behavior of fender of owts and optimized the material properties and material thickness of the fender ren et al 2009 proposed the spherical shell type prismatic fender with the monopile wind turbine by ship collision furthermore they provide new methods to improve the anti collision capability of fender in comparison to bridge and ocean platform there exist less detailed guidelines about fender structural design of wind turbine in order to reduce the cost and improve the performance of anti collision some new structures were designed zhou 2015 used fractal technology for the antenna in traditional communication equipment which made the modified antenna could realize the miniaturization of ultra wideband antenna fan et al 2019 realized the combination of light energy and mechanical energy gathering and storage and improve the energy storage efficiency of fabric devices by fractual structure staggered braiding however it is not found that the fractal theory is involved in the structural design in the field of traditional fender of owts this paper introduces the fractal characteristics into the fender for the first time in order to provide reference value for the research of anti collision and vibration reduction of owts 2 fractal theory the fractal theory is proposed by mandelbrot which has been applied in the structural design because of its two characteristics of self similarity and space filling fractal referred to the set of complex points in a simple space is a new discipline established by the predecessors to observe the natural landscape and the irregular movement of molecules and atoms which spans all fields and promotes the understanding of natural laws and physical essence the set mainly has the following geometric properties 1 fractal structure has space filling is irregular on the whole but has fine structure and from the mathematical perspective the definition of fractal structure is that the fractal dimension is greater than the topological dimension of the geometric structure 2 fractal structure has the characteristic of self similarity to some extent the whole is proportion to the part the classical fractal structure is mainly as follows koch sierpinski cantor minkowski et al as shown in fig 2 object representation can only be reflected through traditional geometry by defining integer dimension while fractional dimension reflects internal characteristics of the structure the study of fractal dimension can obtain the following properties 1 the fractal dimension does not change with the angle observed meanwhile the fractal dimension will not change when the fractal structure change linearly 2 fractal dimension can be measured by experiment 3 the definition and generation of fractals can be analyzed by iterative method strict fractals only exist in theoretical research and it is usually obtained after approximation in daily life here the concept of fractional dimension is introduced into the fractal theory which makes the fractal idea more complete so as to understand the natural things objectively in order to apply the fractal theory more accurately and conveniently the research method of iterated function system ifs is proposed and used to describe the fractal structure and the process is to iterate the simple structure step by step the linear transformation is mathematically called affine which can be expressed by formula 1 w x y a b c d x y e f s h o w w x y ax by e cx dy f 1 where a b c d e and f are all real numbers the self affine change can be expressed a b e c d f 2 where a b c d control the scaling and rotation angle e and f control linear forward and backward or up and down movement assuming an initial gather a exists there are various affine transformations of w1 w2 wn acting on a which can be written as follow 3 w a w 1 a w 2 a w n a n 1 n w n a iteration until convergence w a m a m can be obtained so a m is the attractor of the iterative system function the field of structural design can establish by iterative systems through the process of learning function generation 3 structural design the circular fractal fender proposed is based on cartesian circle theorem by using the tangent circle theorem the fractal circle shape can be divided by the relevant radius of the four tangent circles the radius of curvature of the geometric structure formed by the four tangent circles is expressed as follow a i b i c i d i 2 2 a i 2 b i 2 c i 2 d i 2 i 1 2 4 where a i 1 r a i b i 1 r b i c i 1 r c i d i 1 r d i are the curvatures of the original four tangent circles respectively the relative radiuses are r a i r b i r c i r d i separately i is a positive number expressing the order of the iteration as shown in fig 3 in the first iteration three inner circles with a radius of r b i r c i r d i serial number 2 4 are subtracted from the original circle with radius r a i serial number 1 which is called the first iteration structure then three arbitrary circles in the first iteration are selected to determine the fifth circle in the second iteration therefore a total of 4 additional circles have been generated inside with radius re2 1 serial number 5 7 and re2 2 serial number 8 respectively now these four circles are also subtracted from the original circle with radius rai serial number 1 which is called the second iteration structure in the third iteration order combine any two of the four initial circles in the first iteration order with any one of the four new circles in the second iteration order to determine the ninth circle in the third iteration order a total of 12 new circles with different radius sizes were created which are inner circles of rf3 1 serial number 9 14 rf3 1 serial number 15 17 rf3 1 serial number 18 20 respectively these 12 circles are also subtracted from the original circle with radius rai serial number 1 which is called the third iteration structure on the basis of cartesian circle theorem this iterative process can be repeated indefinitely however due to the limitation of processing conditions the boundless infinite iterative structure is impossible to achieve so this paper proposes fender with fractal hole whose structure is shown in fig 4 the overall size of the fractal holes rai 0 625 m rbi rci rdi 0 25 m re2 1 0 125 mm re2 2 0 03 mm rf3 1 0 06 mm rf3 2 0 025 mm rf3 3 0 01 mm 4 the description of motion equation and algorithm 4 1 motion equation the governing equation of collision system between ship and offshore wind turbine can be expressed as men et al 2015 abrate 2011 bai 2005 m u c u k u f h 1 m a f 0 2 where m is the mass matrix c is the damping matrix k is the stiffness matrix f is matrix of the impact load acting on the structure h is the viscous damping force matrix of the hourglass u u u is the acceleration velocity and displacement at the time of t m is the mass of ship a is the acceleration of the ship f is the collision force of the ship at the time of t 4 2 contact algorithm ls dyna provides different types of contact forms mainly including contact between deformable body and deformable body contact between discrete points and deformable body single sided contact between different parts of the deformable body itself contact between deformable body and rigid body contact with deformable structure and contact with deformable structure according to failure criteria han et al 2019 the interface of contact and collision mainly adopts three different algorithms node constraint method symmetric penalty function and assignment parameter method different structures may happen to contact by the surfaces which can be divided into master contact surface and slave contact surface the corresponding cells are called master and slave slices and the nodes are called master and slave nodes shen 2009 the node constraint method is the earliest contact algorithm its basic principle is to modify the configuration at each time step length check whether the slave node penetrates when there is no master slave contact and if so reduce the time step so that the slave node does not penetrate from the next moment the collision condition is applied to the slave node that has just reached the main surface and the constraint condition is applied to the slave node that has contacted the main surface so as to keep the slave node in contact with the main surface in addition check whether there is a tensile interface in the cell belonging to the slave node contacted by the main surface and if there is make the slave node separate from the main surface wang et al 2017 the distribution parameter method is only used for sliding processing in the program its principle is to distribute the half mass of each contact element to the main surface area of the contact and to determine the distributed pressure acting on the main surface area of the receiving mass by the internal stress of each slave element after the mass and pressure distribution is completed the acceleration of the main surface is modified and then the acceleration and velocity of the slave node are constrained to ensure the movement of the slave node along the main surface the basic principle of symmetric penalty function method is to check whether each slave node in each step penetrates the main surface if the slave node does not penetrate the slave node is not processed if the slave node penetrates it is assumed that a relatively large contact load is generated between the slave node and the penetrated main surface in addition the amount of contact load is proportional to the penetration depth and the stiffness of the main piece and the amount of contact load is defined as the penalty function value on the basis of processing the slave node according to the above principle the program processes the master node again according to the above principle which forms symmetry the symmetric penalty function method has the advantages of symmetry and momentum conservation but the value of the penalty function is constrained by the stability to some extent if it appears obvious penetration the value of the penalty function or reducing the time step can be adjusted by enlarging 4 2 1 hourglass energy the hourglass model which appears deformation without stress or strain in finite element analysis is a non physical zero energy deformation model a single point of integral method is used to integral space and gaussian point to the center unit overlap if the method can greatly reduce the cpu time and the unit calculation points less than the actual individual points of the shell unit and entity unit it s easy to generate zero pattern caused by the structural response of natural oscillation cycle which have a short integration time and jagged grid deformation the hourglass mode is presented in fig 5 the velocity gradient that defines the strain rate is centered on the element while the velocity and nodal force are centered on the node therefore the strain rate and shear rate in the x and y directions can be obtained from equations 3a 3b and 3c 3a ε x x x x x 2 x 4 y 3 y 1 y 2 y 4 x 3 x 1 2 a 3b ε y y y y y 2 y 4 y 3 y 1 y 2 y 4 y 3 y 1 2 a 3c ε x y 1 2 y x x y when a pair of nodes on the diagonal of the element has the same velocity the strain rate in equation 3 is zero indicating that the element stress does not limit the hourglass mode and the strain calculation is orthogonal to it so the hourglass energy can be ignored in the energy equation when the hourglass period is the same as the structural response period the hourglass pattern can be allowed to exist if the hourglass period is higher than the structural response period the hourglass model is not desirable in order to control the growth of the hourglass and avoid the excessive structural response caused by the suppression of the hourglass a viscous term is introduced to the local element stress in the control mode belytschko et al 1985 believes that in the two dimensional case there are only two modes of solid element and shell element and the hourglass control of axisymmetric solid element is consistent with the shell element method the hourglass vector τ i is introduced 4 τ i h i h j x ˆ α j b α i where subscript i represents the sum of all nodes of the cell α 2 b α i is the shape function derivative evaluated at the center of the element h i h j are the base vecter x ˆ α j is the regression coefficient that produce a deformation pattern which can be ignored under the single point integral method equation 5 is as follows 5 h i 1 1 1 1 the calculation formula of hourglass strain rate τ i is as follows 6a q α b τ i θ ˆ α i 6b q 3 b τ i υ ˆ z i 6c q α ℕ τ i υ ˆ α i where b and ℕ represent bending and thin film modes respectively q is the derivative of stress force υ ˆ α i is the rate function derivative of the element center in addition the calculation formula of the hourglass stress rate is as follows 7a q α b r θ e ς 3 a 192 b β i b β i q α b 7b q 3 b r w κ g ς 3 a 12 b β i b β i q 3 b 7c q α m r m e ς a 8 b β i b β i q α m where ς is the thickness of shell parameter r θ r w r m value range 0 01 0 05 e and g are shape parameters the calculation equation 8 of hourglass force can be obtained as follows 8a m ˆ α l h τ i q α b 8b f ˆ 3 l h τ i q 3 b 8c f ˆ α l h τ i q α m where h is the change coefficient of internal force caused by hourglass deformation q is the hourglass stress m ˆ α l h f ˆ α l h and f ˆ 3 l h are the hourglass forces of different shapes and positions the calculation equation 9 of the hourglass stress rate is as follows 9 q n 1 q n δ t q the internal node force control distortion is introduced in ls dyna with the keyword control hourglass 4 2 2 time step in this paper the explicit central difference is used to solve the motion equation when time is n the matrix expression of semi discrete motion equation is 10 y a n p n f n h n where y is diagonal mass matrix p n is the internal and external load matrix f n is the stress divergence h n is the hourglass resistance the global node velocity v and displacement vector u are calculated by the following equation 11 a n m 1 p n f n h n 12 v n 1 2 v n 1 2 a n δ t n 13 u n 1 u n v n 1 2 δ t n 1 2 14 δ t n 1 2 δ t n δ t n 1 2 where m 1 is the parameter t is the time it updates the geometry element by adding displacement increment to the initial geometry 15 x n 1 x 0 u n 1 system development can be determined without iterative computation but there are also some stability problems with this simple method the time discretization error changes with time so the explicit calculation method is considered to be conditional stability to avoid these problems the determination of time step should be based on stability in addition the time step is set to be less than the stable condition of it which can be determined according to the unit size and attributes for the one dimensional steady state problem the time step is usually limited by the courant condition 16 δ t δ x a where δ x is the minimum size variable of the unit a is the speed of sound in the material unit in ls dyna the equivalent formula of critical time step is 17 δ t 2 ω max where ω max is the highest natural frequency when considering damping the time step is reduced as follows 18 δ t 2 ω max 1 ξ 2 ξ the calculated time integral evaluates the minimum critical time step and reduces the safety factor value is 0 8 0 9 19 δ t α min δ t c r 1 δ t c r 2 δ t c r n 5 constitutive materials and finite element model 5 1 constitutive materials ls dyna is available for user defined development and has a wide variety of material models and collision between ship and offshore wind turbine involves the plastic deformation of materials which is a nonlinear dynamic response process moreover the material is in a high strain rate during the collision process which has obvious dynamic characteristics so the sensitivity of material strain rate should be taken into account in the calculation and analysis therefore according to the classification of elastic plastic material model five isotropic materials related to strain rate are selected follow up plasticity power hardening plasticity piecewise linear plasticity plasticity and power exponential plasticity 2 4 and 5 material models can be used for metal plastic molding analysis while 1 and 3 models can be used for steel the cowper symonds model has a high degree of agreement with experimental data and the influence of strain rate sensitivity of materials is taken into account to define material failure therefore this paper plans to use follow up plastic materials for simulation gurpinder et al 2020 5 1 1 steel the tower and bow materials of the wind turbine are q235 and the outermost shell materials of the single column three pile foundation and protective device are q345 according to nonlinear elastoplastic material model provided by ls dyna gladman 2007 and the effect of strain rate on material yield strength a steel constitutive model hyung et al 2018 was established based on the cowper symonds relation which can simulate the material properties of the impacted tower effectively the expression is as follows σ y 1 ε c 1 p σ 0 β e p ε e f f p 20 where σ y is the ultimate yield stress σ 0 is the initial yield stress c and p are a constant related to the properties of the material for general steel c 40 5 p 5 ε is the strain rate β 0 is the plastic follow up strengthening model and 1 is the isotropic strengthening model e p is the plastic strengthening modulus ε e f f p is the equivalent plastic strain rate the physical parameter of ρ is density e and e t are the elastic modulus and tangent modulus respectively and υ is the specific volume as shown in table 1 5 1 2 5ogden rubber the ogden rubber constitutive model in ls dyna is the core protection material and the contact mode of automatic surface to surface with the outer steel shell is to simulate the deformation contact of the structure during the collision the automatic single surface is adopted between the bow and the three pile wind turbine tower in which the dynamic and static friction coefficient is 0 2 and the attenuation coefficient is 0 the constitutive parameters are shown in table 2 5 2 fender fig 6 shows the finite element model of fractal structure fender built in the ansys workbench a pretreatment of software ls dyna in which the mesh was divided by multi domain partitioning method due to the complexity of fractal structure the quality of grid division has an impact on the accuracy and efficiency of calculation therefore selecting appropriate grid size is important to improve the generation rate and accurate calculation of grid as shown in fig 6 the structure complexity increases with the increase of fractal order the fender is divided into two meshing regions one is the domain where the fractal hole is located the other is general region according to the order of fractal hole the appropriate mesh size is selected after continuous simulation which is 0 05 m 0 06 m and 0 08 m respectively 5 3 tripod the basic structure of the tripod is mainly composed of column diagonal brace transverse brace and steel pipe column the steel pipe column is buried to a depth of 50 m and the pile tip enters the powdery sand layer on the seabed exposing the sea surface by 2 m 3 m the 4 mw wind motor is composed of tower nacelle hub blade and electrical system the specific parameters are shown in the literature hao et al 2017 the main parameters of single pillar and three piles foundation are shown in table 3 5 4 ship the common ships are selected and the type of bow is forward tilt according to the local damage characteristics and structural design of the ship a finite element model is established for the collision by shell163 which is divided into collision zone and non collision zone in the collision zone the interior calculation model of bow structure is composed of actual structure layout plate thickness and skeleton information besides the non collision zone mainly includes hull and stern in order to ensure the accuracy of the calculation results an appropriate mesh was encrypted at the contact surface between bow and the tripod structure at the same time the collision force is transferred reasonably between the hull and the tripod structure and the master slave contact method is adopted the dimensions of the ship s main components are shown in table 4 the interaction between ship and seawater cannot be neglected during collision between the ship and the tripod foundation in order to study the interaction between ship and water a fluid solid coupling model or an additional mass model is often used therefore the additional mass method is adopted for the interaction between the ships and water in this paper zhang et al 2017 and the additional mass coefficient is selected as 0 05 6 model validation under the collision conditions of 5000 t ship with 2 m s the fender of tripod is impacted by the ship and the process of energy conversion is shown in fig 7 hull initial kinetic energy is converted into multiple parts the ship s remaining kinetic energy kinetic energy tower structure deformation energy internal energy and sliding friction energy hourglass is generated due to the hourglass phenomenon and damping energy is came out tower in its damping external damping complex and does not affect the research purpose under the action of vibration damping et al fig 7 shows that with the increase of time the conversion of internal energy and kinetic energy occurs at tradition and fractal fender 0 75s 0 63s it can be seen that the existence of fractal structure makes the energy conversion time advance at 1 06s the maximum internal energy and minimum kinetic energy appear in the collision process and the difference between the tradition and fractal fender are 8 62 mj and 8 74 mj respectively the fractal has a certain influence on the energy absorption characteristics of the fender besides the deformation energy internal energy began to decline when ship is apart from point of the collision and the curve of energy happens a range fluctuation at the end of the collision in addition the more deformation energy can be converted into kinetic energy by fractal fender when the collision happens and the curve of system of kinetic energy relative to the trend of structure deformation can be symmetrical on the contrary and decreases slowly under the damping of sea and the action of wind and soil 7 different orders with the same external diameter 7 1 anti collision performance of fender the study keeps the original ring volume the same external diameter of three kinds of fractal hole fender constant and the fractal holes are only generated on the base of the original fender and the other parameters are not changed they are also compared with the solid protection device fig 8 shows the size of four fenders as shown in fig 8 when the overall volume of the protective device is constant the mass of the protective device decreased on the account of the existence of fractal holes in order to further study the anti collision performance of the fractal protection device the change of contact force in ship collision process can be seen in fig 9 fig 9 shows that the variation trend of contact force curves of the four types of fenders first order second order third order and solid is relatively same and with the increase of time the curve is always on the rise from the initial stage of ship movement to the initial deformation compared with the solid fender the three contact force of the fractal fenders increase slowly in the early stage of collision and are obviously smaller than the solid fender when the process of collision goes deeper the contact force of solid fender reaches the maximum earlier than the other curves of fractal fender the reason is that the fractal hole is impacted by ships and the walls are interlacing with each other which prevent the contact force from reaching the maximum value and during the compression process part of the collision contact force is eliminated through the interaction between the holes after the ship left the protective device the contact force curve of the solid protective device decreased rapidly and ended at 1 35s while the decline rate of the fractal structure was slower the curve ended at 1 51s which is 0 16s later than the solid device with the mass of the fender increases the collision contact force decreases accordingly and the contact force can be reduced by the first order fractal hole and the time of the contact force applied to the offshore wind turbine foundation is extended in the process of ship collision as seen in table 5 as shown in table 5 with the increase of the fractal order the maximum contact force first increases and then decreases compared with the solid fender maximum reduction ratio of the first order contact force is 3 93 it can be concluded that when the outer dimension of the fender keep constant the increase of fractal order has no obvious effect on the contact force and the required time for collision is greater than that for solid device in order to explore the structural change and energy absorption of fractal fender in the process of compression the change trend of fractal hole from elastic deformation to plastic deformation is analyzed 7 2 stress and energy absorption in the ls dyna the several moments are picked as following 0 42s 0 6s 0 87s 0 9s 1 11s and the moment when the plastic deformation is completed which could show the stress change and deformation of the fractal hole and the fender profile is given to analyze the dynamic characteristics of the hole after impact as depicted in fig 10 with the increase of time the maximum stress was concentrated in the impact zone of steel shell and only 43 5 mpa stress penetrated into the rubber material the super elastic energy of rubber material can be uniform under the action of the fractal holes and the fractal holes maintained in a certain shape in the impact without cross or overlap in addition the plastic deformation of the protective device with second order fractal holes is obviously large fig 11 shows the pressure distribution in the protection device under the maximum contact force of different orders the area with high pressure concentrates mainly on the outer steel shell and the connection between the protection device and the wind turbine foundation while the pressure in the fractal hole is balanced and the internal pressure of the second order protection device is still the maximum the resistance of internal pressure to external collision force inevitably causes the change of internal energy so the change rule of internal energy is analyzed as shown in fig 12 the change of internal energy of rubber with first order fractal hole is greater than that of steel shell however the internal energy of steel shell is greater than rubber with second or third order fractal hole this is because the plastic deformation of the first order deformation hole has a great impact on the elastic properties of rubber material the elastic properties of the second order and third order holes remain in the elastic plastic deformation zone when the peak of internal energy passes it changes little when system is stable 8 different orders with the different external diameter 8 1 contact force and energy absorption the condition is keeping the quality of the fender constant the different external diameter and three kinds of fractal fenders and solid fenders were compared analysis of its anti impact properties from the contact force is shown in fig 13 from fig 13 it can be seen that the size of the maximum contact force value second order third order first order in the next order the contact force of the same mass protection device first increases after the ship completely impact on the protection device the curve fluctuates obviously and the violent fluctuation of contact force is caused by the significant inertia effect because of the increase of mass of the fender which causes vibration response increase the reverse disturbance of fenders in the process of ship collision the statistics of collision parameters are shown by table 6 it can be seen from the table that the collision time increases with the increase of order of fractal hole compared with the solid protective device the fractal protective device with the same mass has better protective effect in addition the variation of the internal energy of the protective device is analyzed as shown in fig 14 it can be seen from fig 14 that before the ship leaves the wind turbine the internal energy value of the rubber material in the fender is larger than that of the steel shell and then it is reduced to the minimum value at this time the fractal hole is in the elastic plastic deformation stage the elastic part recovers a certain shape to affect the change of the internal energy of the rubber since the internal structure of the second order fractal hole is not under uniform stress the rubber structure fails to recover energy quickly 8 2 stress strain analysis based on this the stress and strain of the first second and third order fender are analyzed and the impact response of the fenders under ship collision is further studied as shown in fig 15 compared with the second order fractal the reduction percentage of maximum fractal stress of first order and second order is 3 27 and 1 74 respectively the strain of the second order protective device is intense as the increase of collision time the effect of strain slows down and the plastic strain increases the maximum plastic strain of the first order second order and third order protective device are 0 0137 0 0196 0 0144 respectively it can be known that the second order fractal hole is not suitable for the protection device but the first order fractal hole improves the anti collision performance see fig 16 9 top acceleration response the offshore wind turbine is affected by the collision of ship its top acceleration changes are shown in fig 17 as time goes on the acceleration curve has different nonlinear properties under different fractal protection device compared with solid the acceleration response of fractal protection device is more severe and the acceleration response would increase with the increase of the mass of the fractal protective device table 7 shows the difference of the acceleration as shown in table 4 when the mass of fractal protection device increases the average acceleration increases in addition the average acceleration decreases as the fractal order increases under the same volume while the acceleration decreases first and then increases under the same mass according to simens the maximum allowable acceleration of engine room is 6 m s 1 the acceleration of the fractal protection device is under this value but it is still greater than the solid protection device which is the result of the vibration increased by the fractal hole 10 conclusions the paper is based on the internal and external dynamics the ls dyna is used to simulate the collision process where the ship impact the tripod by introducing fractal geometry and combining with the existing ring structure the cartesian circle fractal structure is constructed by tangent circle theorem to realize the protection device with fractal structure and the collision resistance performance of the protection device with different fractal order under the same and the different external diameter has been compared and analyzed firstly by comparing the collision resistance characteristics of the same external diameter with different order protection devices it is found that the contact force reduction ratio of the first order fractal structure is at most 3 93 and its plastic deformation region promotes the enhancement of energy absorption of rubber material under the different external diameter the same mass the first order fractal structure reduces the collision force of ships by 12 94 and has better internal energy and stress strain capacity than the second order and third order fractal structure secondly the comparative study of fractal holes of different order shows that the effect of the first order fractal on improving the impact resistance of the protection device is particularly obvious while the second order fractal has poor performance in the aspects of contact force internal energy change and stress strain the interaction deformation between elasticity and plasticity is the main reason for the unstable impact resistance of fractal holes under different orders finally by comparing the anti collision characteristics of different mass protection devices it is found that the anti collision ability of fractal protection is enhanced with the increase of mass but the response effect of fractal structure to the acceleration suppression of tower top is significantly weakened compared with that of solid structure under the permissible range of acceleration of wind turbine nacelle credit authorship contribution statement xinzhi yue writing original draft conceptualization data curation formal analysis zhiwei han investigation methodology chun li resources supervision project administration funding acquisition xinlei zhao investigation qingsong liu writing review editing validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is supported by the national natural science foundation of china 51976131 51676131 shanghai university science and technology innovation action plan local university capacity building project 19060502200 
20377,this paper reported on the free surface wave behavior in a rectangular open channel induced by sluice gate maneuvers the numerical solver was based on the 2 4 dissipative scheme being used for the numerical discretization of the one dimensional extended st venant model embedding the boussinesq add on term the numerical solver was firstly validated against experimental data and alternative numerical solver quoted in the literature then the fundamental pulsation of the hydraulic system was inspected using the analogy with the water hammer theory observed in pressurized pipe flow different flow scenarios were reported including the superposition between a downstream water hammer maneuver and sine excitation of upstream flow depth using different pulsation values results highlighted that such sluice gates maneuvers involved severe scenarios leading to significant amplification of the depth peak and crest values above the initial value keywords 1d extended st venant model 2 4 dissipative scheme boussinesq add on free surface resonance open channel propagation prismatic reflection wave 1 introduction forecasting of shallow water flow behavior due to normal setting operations e g pump shutdowns starts or changes in sluice gate position fig 1 or accidental events e g dam break is of great practical interest in hydraulic engineering in specific conditions these maneuvers may lead to severe surge waves and even a resonating behavior of the free surface waves chow 1973 triki and hajtaieb 2010 2012 2013 2014a 2014b 2016 2017 2021 brito et al 2020 young and papini 2020 mnassri and triki 2020a 2020b 2021a 2021b 2021c 2021d this undesirable behavior is pertinent to many engineering applications including the efficient design of hydraulic structures and operational procedures of sluice gates and in emergency flood management operations despite the practical applications forecasts of free surface wave behaviors have relied more on empirical formulations and far less on more concise computations as in other fields of fluid mechanics dagan 1982 mohammadian and le roux 2006 a b szymkiewicz 2010 shirkhani et al 2016 seyedashraf et al 2018 seyedashraf and akhtari 2017 gholami et al 2019 reeve et al 2019 viero et al 2017 zarmehi and tavakoli 2016 in this context triki and hajtaieb 2010 2012 and triki 2014 a 2016 2017 2021 investigated the resonating behavior of free surface waves including positive and negative induced surge waves in these studies numerical computations were based on the discretization of the 1d st venant model using the mccormack scheme triki and hajtaieb 2010 2012 triki 2014b 2016 mnassri and triki 2021d or the discretization of the 1d boussinesq model using the 2 4 dissipative scheme triki 2017 2021 mnassri and triki 2020 a b c incidentally the boussinesq model is generally used to account for the variation of vertical velocity that might arise from fast transient events specifically this model embeds a supplement term to the st venant momentum equation assuming a linear distribution of the vertical velocity profile increasing linearly from zero at the open channel bottom to a maximal value at the free surface soares frazão and zech 2002 soares frazão and guinot 2008 fennema and chaudhry 1987 gharangik and chaudhry 1991 garcia navarro and saviron 1992 chaudhry 2008 prüser and zielek 1994 treske 1994 triki and hajtaieb 2010 2012 triki 2013 2014a b 2016 2017 2021 mnassri and triki 2020 a b 2021 a b c d alternatively chen 1992 performed a simplified formulation using a momentum correction factor in order to improve the representation of the vertical velocity distribution in fast transient flow problems fig 2 the momentum correction factor collectively called the boussinesq momentum coefficient is theoretically evaluated in order to use accurately the cross section averaged velocity in the momentum equations of unidirectional flow chen 1992 developed a complete analysis of the velocity distribution coefficient in open channel and pressurized pipe flows with reference to flow resistance the author demonstrated that for practice cases the velocity distribution coefficient could be derived from the laminar flow regime and the prandt power law velocity distribution expressed in terms of the darcy weisbach resistance coefficient for turbulent flow regime besides this formulation has better capacity than the original boussinesq formulation in terms of simplicity of implementation and consumed computational time however this formulation could not be applied for a high froude number from a numerical point of view considerable attention has been devoted to free surface flow solutions in principle these solutions are based on the finite difference method fennema and chaudhry 1987 prasada 2002 prasada and medina 2003 triki 2014a b 2016 2017 2021 hernandez duenas and beljadid 2016 ginting 2017 2019 ginting and mundani 2018 ginting and ginting 2019 2020 mnassri and triki 2020a 2021a b the finite element method fem cooley and moin 1976 szymkiewicz 1991 2010 triki 2013 2014b 2014b katopodes 1980 2018 mnassri and triki 2021b c or the finite volume method toro 2000 for example ginting 2019 and ginting and ginting 2019 proposed a hybrid artificial viscosity central upwind scheme to simulate recirculating turbulent shallow water specifically the authors used the artificial viscosity technique to solve the two dimensional depth averaged reynolds averaged navier stokes equations and a central upwind scheme to solve the κ ε model the authors suggested that the hybrid approach is more efficient and accurate than the original central upwind method for practical engineering purposes to simulate turbulent shallow water flows in addition ginting 2017 and ginting and mundani 2018 developed an artificial viscosity technique instead of the riemann solver to reduce the numerical oscillations arising from the two dimensional cell centered finite volume scheme based solution of shallow water flows including sharp gradients subsequently ginting and ginting 2020 applied the artificial viscosity technique used by ginting 2017 to achieve a second order accuracy solution of the 2d non hydrostatic shallow water equations the authors highlighted that the proposed solver reduced consumed computational time ginting et al 2021 developed a godunov type model as an alternative to the boussinesq equations based solvers to describe the free surface wave behavior in a wet dry flow scenario and the wave structure interactions the authors demonstrated that such a numerical solver is competitive as compared with the boussinesq equations based and could be applied for numerous engineering applications thanks to its simplicity of implementation attribute despite the robustness of the high order shock capturing method based solver in describing accurately sharp gradients with low level oscillations these methods lead to important computational efforts as previously stated the resonance of free surface waves involves large surge wave magnitudes which may critically affect the channel traffic or cause damages to hydraulic equipment therefore it is crucial to avoid or at least anticipate their onset to improve readiness for such a critical scenario accordingly we planned in this study to investigate the resonance phenomenon within the free surface flow framework incidentally such a transient wave behavior necessitates the implementation of an extended st venant model based solver to account for the vertical velocity distribution or favre waves specifically the extended st venant model embedding the boussinesq add on term is adopted in this study in this regard the boussinesq add on term involves third order term and hence requires at least a third order accurate numerical scheme consequently the 2 4 dissipative scheme which is a second order precision in time and fourth order in space explicit finite difference scheme is selected in this study thanks to its simplicity of implementation and accuracy of the solution of the transient scenarios developed in this study in the following the numerical discretization of the 1 d extended st venant model using the 2 4 dissipative scheme is outlined 2 methodology as per mohapatra and chaudhry 2004 triki 2014b 2016a and mnassri and triki 2020b 2021c the 1 d extended st venant model proposed by boussinesq to describe fast transient flows in open channels may be expressed as follows 1 w t f x h wherein w a q t designates the vector of flow variables f q q 2 a g a 2 2 t b t stands for the flux vector and h q l a g s 0 s f t denotes the source term vector q and a t d correspond to the discharge and the cross section area of the channel respectively t refers to the channel width d refers to the flow depth q l corresponds to the lateral inflow per unit of channel width s 0 denotes the longitudinal slope of the channel bed s f n 2 q 2 a 2 r h 4 3 corresponds to friction slope n designates the manning s roughness coefficient r h stands for the hydraulic radius b a 3 3 t 2 2 q a x t q a 2 q a x 2 q a x 2 designates the boussinesq add on term accounting for the vertical component of the flow acceleration and t and x are the time and distance along the channel respectively incidentally the uniform flow condition is described by 2 s f s 0 expressing s f according to manning rule and substituting in eq 2 leads to 3 n 2 q 2 η a d 2 r h d 4 3 s 0 wherein η is a conversion coefficient η 1 or η 1 49 for si or en units respectively for example the normal depth d 0 value corresponding to a normal flow q 0 is determined by solving eq 3 using a trial and error method 4 d 0 n q 0 η b 5 3 s 0 2 3 b 2 d 0 2 5 in order to provide an accurate numerical solution of the 1 d extended st venant model 1 involving discontinuities such as shock waves at least a third order accurate numerical scheme is needed in this regard katopodes 1984 and mohapatra and chaudhry 2004 demonstrated that the 2 4 dissipative scheme which is fourth order accurate in space and second order accurate in time allows satisfactory numerical solution near shock waves principally this scheme may be outlined into a predictor and corrector steps jameson et al 1981 katopodes 1984 mohapatra and chaudhry 2004 triki 2014b 2016 2017 5 i predictor step w w i k σ 6 f i 2 k 8 f i 1 k 7 f i k δ t 2 h i 1 k h i k i 1 n 6 ii corrector step w i k 1 1 2 w i k w i σ 12 7 f i k 8 f i 1 k f i 2 k δ t 2 h i 1 k h i k i 1 n wherein σ δ t δ x denotes the grid mesh ratio the subscripts i 1 i n s and k designate the grid points in the x and t directions respectively n s corresponds to the number of sections equally spaced along the channel the single and the double over bars stand for the computed values in the prediction and the correction steps respectively in the above numerical procedure the intermediate flow variables are evaluated excluding the mixed time space derivative of the boussinesq term i e 2 q a x t accordingly the intermediate velocity value is adjusted according to the following equation mohapatra and chaudhry 2004 7 q a t x 2 q a x t 0 wherein 2 q a x t is estimated using the variable values at the known time level and the intermediate level 8 2 q a x t x q q a t q i 1 q i 1 q i 1 k q i 1 k 2 a δ x δ t i 1 n furthermore the space derivative terms 2 q a x 2 and q a x of the boussinesq add on term b are discretized using a three point central finite difference scheme 9 2 q a x 2 i k 1 q i 1 k 2 q i k q i 1 k a i 1 k δ x 2 a n d q a x i k 1 q i 1 k q i 1 k 2 a i 1 k δ x i 1 n in addition to the predictor and corrector steps of the 2 4 dissipative scheme an updating step of the hydraulic parameter values based on the artificial viscosity adjustment technique is used to suppress superior oscillations arising from accordingly the vector of unknown parameters is expressed as follows mohapatra and chaudhry 2004 10 w i k 1 w i k 1 κ i 1 2 w i 1 k 1 w i k 1 κ i 1 2 w i k 1 w i 1 k 1 i 1 n wherein κ is determined by κ i w i 1 k 2 w i k w i 1 k w i 1 k 2 w i k w i 1 k and κ i 1 2 κ σ max κ i 1 κ i it should be emphasized herein that the unknown flow parameter values i e a and q should be specified for three nodes from the up and down boundaries at each computational time level see eqs 2 and 3 thereby three fictitious nodes are added at each boundary to achieve numerical computations fig 3 in order to compute the flow parameters at the dummy nodes reflective and transmissive conditions may be used in this regard the fictitious points are replaced by the immediate interior points for example a reflective condition may be employed to describe a boundary condition involved by the closure of an inlet sluice gate i e q x 0 t 0 0 in such a case an antisymmetric reflection condition is incorporated by changing the sign of the flow rate to describe the flow reflection upon the sluice gate accordingly the hydraulic values of fictitious cells at the downstream side of the channel are expressed as follows yost et al 2000 11 d i k 1 d i k 1 and q i k 1 q i k 1 i 1 2 3 however a transmissive condition may be used to describe a constant flow depth condition maintained at the downstream boundary of the channel i e d x 0 t 0 h 0 specifically this condition assumes that the boundary to be at infinity such that they do not affect the local behavior of the flow consequently the hydraulic values of fictitious cells at the upstream side of the channel are expressed as follows yost et al 2000 12 d n i k 1 d n i 1 k 1 and q n i k 1 q n i 1 k 1 i 1 2 3 finally it should be emphasized that the numerical stability of the forgoing numerical procedure is ensured basing on the courant friedrichs lewy condition gharangik and chaudhry 1991 rahman and chaudhry 1995 13 σ c r u c m a x where c g d is the celerity of gravity wave in a rectangular channel and c r is the courant number c r 2 3 jameson et al 1981 2 1 model validation in order to demonstrate the performance of the developed numerical procedure in capturing shock waves in open channel the experimental measurements carried out by gharangik and chaudhry 1991 on a horizontal rectangular flume l 14 0 m t 0 46 m equipped with a large constant head tank at its upstream and a weighing tank at its downstream extremity fig 4 the initial steady state flow corresponds to a gradually varied flow regime which is described by the following relationship between flow depth and velocity along the flume d d 0 d x s 0 s f 1 u 2 g u the transient event studied by the authors concerns a hydraulic jump provoked and controlled by an adjustable sluice gate placed at the downstream extremity of the flume for flow velocity u x l 3 831 m s corresponding to the froude number value f r 7 the depth magnitudes measured at up and down stream sides of the hydraulic jump are d x 0 m 0 031 m and d x l 0 265 m respectively fig 5 compares the measured free surface profile versus length at the instant t 63 4 s and the numerical ones computed using the mccormack scheme for discretizing the conventional and the 2 4 dissipative scheme discretizing of the 1d extended st venant model as per this figure the free surface profiles computed using both models agree well with experimental traces in terms of jump magnitude furthermore the mccormack and 2 4 dissipative schemes based solvers provide similar results at locations away from the jump on the other side concerning the jump location fig 5 infers that the hydraulic jump predicted by the 2 4 dissipative scheme based on the extended st venant model is situated slightly downstream of the measured one precisely the computed hydraulic jump is located exactly 0 61 m downstream from the observed one however a significant shift is observed between the observed jump location and the computed one using the mccormack scheme based on the conventional st venant model this shift is mainly attributed to the boussinesq add on term embedded in the extended st venant model katopodes 1984 in the next section the 2 4 dissipative scheme based numerical procedure is applied to describe several test cases involved by sluice gates maneuvers 3 applications results and discussion the test case relates to a rectangular open channel equipped with two sluice gates at both extremities fig 6 the channel characteristics are length l 305 m width t 6 1 m longitudinal slope of the open channel bed s 0 10 3 and manning roughness coefficient n 0 014 wylie and streeter 1993 triki and hajtaieb 2010 triki 2021 the initial steady state flow regime is uniform characterized by a flow rate q 0 20 388 m 3 s which corresponds to the uniform depth value equal to d 0 2 4 m eq 4 concerning the 2 4 dissipative scheme algorithm computations were performed using a number of equal space step n s 130 and a courant number c r 0 6 as a first investigation step the fundamental pulsation of the free surface wave is identified based on the analogy with the waterhammer concept used in pressurized pipe flow 3 1 identification of the fundamental pulsation of the hydraulic system the fundamental pulsation of the hydraulic system is inspected through analogy with the waterhammer phenomenon in pressurized pipe flows accordingly the open channel is subjected to abrupt and full closure of the downstream sluice gate while a constant depth value equal to an initial uniform depth is maintained at the channel inlet such a transient event may be expressed as follows 14 q t 0 x l 0 and d t 0 x 0 d 0 fig 7 displays the depth signals versus time computed at different sections along the channel x 0 l 4 l 2 3 l 4 and l in addition the main characteristics of the 9th firsts wave oscillation cycles plotted in fig 6 are listed in table 1 wherein d upsurge and d downsurge designate the depth peak and crest values t 1 2 upsurge and t 1 2 downsurge denote the duration of up and down surge wave portions and t t 1 2 upsurge t 1 2 downsurge corresponds to the duration of wave oscillation cycles as per fig 7 the wave propagation and reflection mechanisms induced by the waterhammer event are characterized by damped oscillatory flow patterns accompanied by an expansion of the wave oscillation period firstly in order to comprehensively address the wave propagation and reflection mechanisms occurring during the transient regime the free surface profiles are reported in fig 8 at several times of the first cycle of depth wave oscillation for example the free surface profile computed at t 34 895 s corresponds to an up surge propagating upstream toward the reservoir while the profile one estimated at t 99 927 s involves an up surge reflecting downstream toward the sluice gate likewise the free surface profile plotted at t 164 958 s corresponds to a down surge propagating upstream however the profile displayed at t 229 990 s involves a down surge reflecting downstream secondly fig 7 illustrates a depth rise succeeding to the closure maneuver of downstream sluice gate and subsequently a significant depth drop in this case the magnitudes of up and down depth surges are δ d upsurge d max d 0 3 7 2 4 1 3 m and δ d downsurge d 0 d min 2 4 1 4 1 0 m respectively this result indicates asymmetry between the up and down surge depth magnitudes similarly fig 7 together with table 1 illustrates asymmetry between the up and down depth surge durations in this case the duration of up surge depth t 1 1 2 upsurge 137 8518 s is more important than the down surge depth t 1 1 2 downsurge 114 9091 s this means that the up surge wave travels slower than the down surge one physically this asymmetry is attributed to the direction of the propagating or reflecting wave portion more precisely the celerity value of positive wave propagating toward the upstream extremity is equal to v w u a which is greater than the celerity value of positive wave propagation toward the downstream extremity is equal to v w u a incidentally the period of the first cycle of wave oscillation is equal to t 1 t 1 1 2 upsurge t 1 1 2 downsurge 137 8518 114 9091 252 7610 s which corresponds to the fundamental pulsation of the hydraulic system ω f 2 π t 1 2 π 252 7610 0 0248 rd s it is worth emphasizing herein that this period value is almost equal to the theoretical period value t a 4 l a 4 l g d 0 4 305 9 81 2 4 251 431 s thirdly fig 7 shows that the ultimate values of depth peak or crest are observed in the first cycle of depth wave oscillation however these values are attenuated for the subsequent depth wave oscillation cycles physically this attenuation effect is due to friction effects furthermore the asymmetry between up and down depth surge magnitude is mainly attributed to mixed boundary conditions at the free surface and the bottom of the flow as regards the period of the depth wave oscillation cycle fig 7 indicates that the minimum period value is observed in the first cycle of depth wave oscillation thereafter the period value increases significantly in the second cycle of depth oscillation and decreases gradually in the subsequent cycles of depth wave oscillation cycles physically this trend may be explained by the proportional relationship between the period and depth values triki 2016 2021 2021 as far analysis permitted identification of the hydraulic system harmonics therefore it is interesting to study the free surface wave behavior due to a sine excitation of the hydraulic system with the above deduced pulsations 3 2 analysis of sine excitation of upstream depth this subsection investigates the free surface waves behavior due to a sine excitation of the upstream flow depth into the open channel initially at rest the boundary conditions associated with such a situation may be as follows 15 q t 0 0 a n d d t 0 x l d 0 δ d sin ω t wherein δ d 0 3 m as a first investigation stage the sine excitation uses the fundamental pulsation of the hydraulic system already deduced i e ω ω f fig 9 shows the depth signals versus time computed at different sections along the channel x 0 l 4 l 2 3 l 4 and l in addition the main characteristics of the 9th firsts wave oscillation cycles plotted in fig 9 are reported in table 2 referring to fig 9 the wave propagation and reflection mechanisms during the transient event are characterized by amplified oscillatory flow patterns accompanied by an expansion of the wave oscillation period specifically the depth reaches a maximum or minimum values equal to d max 3 7 m or d min 1 2 m respectively in other words the amplification or reduction ratios of depth relative to initial uniform value is equal to d max d 0 1 54 or d min d 0 0 5 respectively on the other hand the period of the first cycle of depth oscillation is equal to t 1 311 233 s as regards the wave propagation and reflection mechanisms occurring during the transient regime fig 10 reports the free surface profiles at several times of the first cycle of depth wave oscillation for example the free surface profile computed at t 49 849 s corresponds to an up surge propagating upstream toward the reservoir while the profiles estimated at t 99 698 s and t 1968 575 s involve an up surge reflecting downstream toward the sluice gate likewise the free surface profile plotted at t 2327 673 s corresponds to a down surge propagating upstream however the profile displayed at t 159 702 s involves a down surge reflecting downstream as a second investigation stage the hydraulic system is excited using ω 3 ω f fig 11 shows the depth signals versus time computed at different sections along the channel x 0 l 4 l 2 3 l 4 and l in addition fig 12 illustrates the free surface profiles displayed at several times of the first cycle of depth wave oscillation the general pattern of fig 11 reveals a beating phenomenon of the depth signals particularly the beating of upstream flow depth is driven by the pulsation of the sine excitation of the downstream depth furthermore as per fig 11 the beating period of the downstream depth is equal to τ 1189 407 s concerning the wave propagation and reflection mechanisms occurring during the transient regime fig 12 reports the free surface profiles at several times of the first cycle of depth wave oscillation for example the free surface profiles computed at t 74 775 s and t 99 698 s correspond to an up surge propagating upstream toward the reservoir while the profile one estimated at t 124 758 s involves an up surge reflecting downstream toward the sluice gate likewise the free surface profile plotted at t 149 950 s corresponds to a down surge propagating upstream however the profile displayed at t 249 917 s involves a down surge reflecting downstream the third investigation stage addresses the superposition of the 9th first odd pulsations as being a more realistic description of the free surface wave distortion triki 2016 this scenario may be coded as follows 16 q t 0 0 and d t 0 x l d 0 δ d l 1 9 sin ω l t wherein δ d 0 3 m fig 13 illustrates the depth signals versus time computed at different sections along the channel x 0 l 4 l 2 3 l 4 and l in fact these curves show the superposition of two surge waves propagating in the opposite direction and which superimpose before separately continuing unaffected by superposition incidentally during the superposition scenario the depth amplitudes are subtracted from one another whenever the two waves that have encountered are of out phases in addition it is clearly shown from these curves that the depth signals due to superposition are quantitatively driven by the water hammer waves at all sections of the channel in this regard the extremity the downstream depth signal reaches a maximum or minimum values equal to d max 3 9 m at t 99 966 s or d min 1 5 m at t 986 445 s respectively 4 conclusion overall this study highlighted that the 1 d extended st venant equations based on the boussinesq add on term allows a more realistic description of free surface wave behavior in open channels besides unlike the mccormack scheme based solver the 2 4 dissipative scheme based one leads to an accurate discretization on the boussinesq add on term on the other hand the water hammer theory used in pressurized pipe flows could help estimate the fundamental pulsation of the free surface wave likewise the superposition between a sine excitation of the upstream depth and the downstream water hammer maneuver involved severe scenarios leading to important amplifications of the depth peak and crest values above the initial flow depth value credit authorship contribution statement souad mnassri writing original draft writing review editing investigation software conceptualization methodology ali triki writing original draft writing review editing investigation software conceptualization methodology supervision reviewing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper notation the following symbols are used in this paper a wetted cross sectional area of the channel m 2 t channel width m c celerity m s c r courant number g acceleration of gravity m s 2 l channel length m n manning roughness coefficient s m 1 3 q discharge m 3 s r h hydraulic radius m s 0 longitudinal slope of the channel bottom m m s f m 2 v 2 r h 4 3 friction slope m m t time s v w surge celerity m s u depth averaged velocity m s x abscissa measured along the channel bed m d flow depth measured perpendicular to the channel bed m greek symbols ω pulsation s 1 ω f fundamental pulsation s 1 subscripts 0 initial flow condition i mesh index in the x direction k mesh index in the t direction n number of mesh 
20377,this paper reported on the free surface wave behavior in a rectangular open channel induced by sluice gate maneuvers the numerical solver was based on the 2 4 dissipative scheme being used for the numerical discretization of the one dimensional extended st venant model embedding the boussinesq add on term the numerical solver was firstly validated against experimental data and alternative numerical solver quoted in the literature then the fundamental pulsation of the hydraulic system was inspected using the analogy with the water hammer theory observed in pressurized pipe flow different flow scenarios were reported including the superposition between a downstream water hammer maneuver and sine excitation of upstream flow depth using different pulsation values results highlighted that such sluice gates maneuvers involved severe scenarios leading to significant amplification of the depth peak and crest values above the initial value keywords 1d extended st venant model 2 4 dissipative scheme boussinesq add on free surface resonance open channel propagation prismatic reflection wave 1 introduction forecasting of shallow water flow behavior due to normal setting operations e g pump shutdowns starts or changes in sluice gate position fig 1 or accidental events e g dam break is of great practical interest in hydraulic engineering in specific conditions these maneuvers may lead to severe surge waves and even a resonating behavior of the free surface waves chow 1973 triki and hajtaieb 2010 2012 2013 2014a 2014b 2016 2017 2021 brito et al 2020 young and papini 2020 mnassri and triki 2020a 2020b 2021a 2021b 2021c 2021d this undesirable behavior is pertinent to many engineering applications including the efficient design of hydraulic structures and operational procedures of sluice gates and in emergency flood management operations despite the practical applications forecasts of free surface wave behaviors have relied more on empirical formulations and far less on more concise computations as in other fields of fluid mechanics dagan 1982 mohammadian and le roux 2006 a b szymkiewicz 2010 shirkhani et al 2016 seyedashraf et al 2018 seyedashraf and akhtari 2017 gholami et al 2019 reeve et al 2019 viero et al 2017 zarmehi and tavakoli 2016 in this context triki and hajtaieb 2010 2012 and triki 2014 a 2016 2017 2021 investigated the resonating behavior of free surface waves including positive and negative induced surge waves in these studies numerical computations were based on the discretization of the 1d st venant model using the mccormack scheme triki and hajtaieb 2010 2012 triki 2014b 2016 mnassri and triki 2021d or the discretization of the 1d boussinesq model using the 2 4 dissipative scheme triki 2017 2021 mnassri and triki 2020 a b c incidentally the boussinesq model is generally used to account for the variation of vertical velocity that might arise from fast transient events specifically this model embeds a supplement term to the st venant momentum equation assuming a linear distribution of the vertical velocity profile increasing linearly from zero at the open channel bottom to a maximal value at the free surface soares frazão and zech 2002 soares frazão and guinot 2008 fennema and chaudhry 1987 gharangik and chaudhry 1991 garcia navarro and saviron 1992 chaudhry 2008 prüser and zielek 1994 treske 1994 triki and hajtaieb 2010 2012 triki 2013 2014a b 2016 2017 2021 mnassri and triki 2020 a b 2021 a b c d alternatively chen 1992 performed a simplified formulation using a momentum correction factor in order to improve the representation of the vertical velocity distribution in fast transient flow problems fig 2 the momentum correction factor collectively called the boussinesq momentum coefficient is theoretically evaluated in order to use accurately the cross section averaged velocity in the momentum equations of unidirectional flow chen 1992 developed a complete analysis of the velocity distribution coefficient in open channel and pressurized pipe flows with reference to flow resistance the author demonstrated that for practice cases the velocity distribution coefficient could be derived from the laminar flow regime and the prandt power law velocity distribution expressed in terms of the darcy weisbach resistance coefficient for turbulent flow regime besides this formulation has better capacity than the original boussinesq formulation in terms of simplicity of implementation and consumed computational time however this formulation could not be applied for a high froude number from a numerical point of view considerable attention has been devoted to free surface flow solutions in principle these solutions are based on the finite difference method fennema and chaudhry 1987 prasada 2002 prasada and medina 2003 triki 2014a b 2016 2017 2021 hernandez duenas and beljadid 2016 ginting 2017 2019 ginting and mundani 2018 ginting and ginting 2019 2020 mnassri and triki 2020a 2021a b the finite element method fem cooley and moin 1976 szymkiewicz 1991 2010 triki 2013 2014b 2014b katopodes 1980 2018 mnassri and triki 2021b c or the finite volume method toro 2000 for example ginting 2019 and ginting and ginting 2019 proposed a hybrid artificial viscosity central upwind scheme to simulate recirculating turbulent shallow water specifically the authors used the artificial viscosity technique to solve the two dimensional depth averaged reynolds averaged navier stokes equations and a central upwind scheme to solve the κ ε model the authors suggested that the hybrid approach is more efficient and accurate than the original central upwind method for practical engineering purposes to simulate turbulent shallow water flows in addition ginting 2017 and ginting and mundani 2018 developed an artificial viscosity technique instead of the riemann solver to reduce the numerical oscillations arising from the two dimensional cell centered finite volume scheme based solution of shallow water flows including sharp gradients subsequently ginting and ginting 2020 applied the artificial viscosity technique used by ginting 2017 to achieve a second order accuracy solution of the 2d non hydrostatic shallow water equations the authors highlighted that the proposed solver reduced consumed computational time ginting et al 2021 developed a godunov type model as an alternative to the boussinesq equations based solvers to describe the free surface wave behavior in a wet dry flow scenario and the wave structure interactions the authors demonstrated that such a numerical solver is competitive as compared with the boussinesq equations based and could be applied for numerous engineering applications thanks to its simplicity of implementation attribute despite the robustness of the high order shock capturing method based solver in describing accurately sharp gradients with low level oscillations these methods lead to important computational efforts as previously stated the resonance of free surface waves involves large surge wave magnitudes which may critically affect the channel traffic or cause damages to hydraulic equipment therefore it is crucial to avoid or at least anticipate their onset to improve readiness for such a critical scenario accordingly we planned in this study to investigate the resonance phenomenon within the free surface flow framework incidentally such a transient wave behavior necessitates the implementation of an extended st venant model based solver to account for the vertical velocity distribution or favre waves specifically the extended st venant model embedding the boussinesq add on term is adopted in this study in this regard the boussinesq add on term involves third order term and hence requires at least a third order accurate numerical scheme consequently the 2 4 dissipative scheme which is a second order precision in time and fourth order in space explicit finite difference scheme is selected in this study thanks to its simplicity of implementation and accuracy of the solution of the transient scenarios developed in this study in the following the numerical discretization of the 1 d extended st venant model using the 2 4 dissipative scheme is outlined 2 methodology as per mohapatra and chaudhry 2004 triki 2014b 2016a and mnassri and triki 2020b 2021c the 1 d extended st venant model proposed by boussinesq to describe fast transient flows in open channels may be expressed as follows 1 w t f x h wherein w a q t designates the vector of flow variables f q q 2 a g a 2 2 t b t stands for the flux vector and h q l a g s 0 s f t denotes the source term vector q and a t d correspond to the discharge and the cross section area of the channel respectively t refers to the channel width d refers to the flow depth q l corresponds to the lateral inflow per unit of channel width s 0 denotes the longitudinal slope of the channel bed s f n 2 q 2 a 2 r h 4 3 corresponds to friction slope n designates the manning s roughness coefficient r h stands for the hydraulic radius b a 3 3 t 2 2 q a x t q a 2 q a x 2 q a x 2 designates the boussinesq add on term accounting for the vertical component of the flow acceleration and t and x are the time and distance along the channel respectively incidentally the uniform flow condition is described by 2 s f s 0 expressing s f according to manning rule and substituting in eq 2 leads to 3 n 2 q 2 η a d 2 r h d 4 3 s 0 wherein η is a conversion coefficient η 1 or η 1 49 for si or en units respectively for example the normal depth d 0 value corresponding to a normal flow q 0 is determined by solving eq 3 using a trial and error method 4 d 0 n q 0 η b 5 3 s 0 2 3 b 2 d 0 2 5 in order to provide an accurate numerical solution of the 1 d extended st venant model 1 involving discontinuities such as shock waves at least a third order accurate numerical scheme is needed in this regard katopodes 1984 and mohapatra and chaudhry 2004 demonstrated that the 2 4 dissipative scheme which is fourth order accurate in space and second order accurate in time allows satisfactory numerical solution near shock waves principally this scheme may be outlined into a predictor and corrector steps jameson et al 1981 katopodes 1984 mohapatra and chaudhry 2004 triki 2014b 2016 2017 5 i predictor step w w i k σ 6 f i 2 k 8 f i 1 k 7 f i k δ t 2 h i 1 k h i k i 1 n 6 ii corrector step w i k 1 1 2 w i k w i σ 12 7 f i k 8 f i 1 k f i 2 k δ t 2 h i 1 k h i k i 1 n wherein σ δ t δ x denotes the grid mesh ratio the subscripts i 1 i n s and k designate the grid points in the x and t directions respectively n s corresponds to the number of sections equally spaced along the channel the single and the double over bars stand for the computed values in the prediction and the correction steps respectively in the above numerical procedure the intermediate flow variables are evaluated excluding the mixed time space derivative of the boussinesq term i e 2 q a x t accordingly the intermediate velocity value is adjusted according to the following equation mohapatra and chaudhry 2004 7 q a t x 2 q a x t 0 wherein 2 q a x t is estimated using the variable values at the known time level and the intermediate level 8 2 q a x t x q q a t q i 1 q i 1 q i 1 k q i 1 k 2 a δ x δ t i 1 n furthermore the space derivative terms 2 q a x 2 and q a x of the boussinesq add on term b are discretized using a three point central finite difference scheme 9 2 q a x 2 i k 1 q i 1 k 2 q i k q i 1 k a i 1 k δ x 2 a n d q a x i k 1 q i 1 k q i 1 k 2 a i 1 k δ x i 1 n in addition to the predictor and corrector steps of the 2 4 dissipative scheme an updating step of the hydraulic parameter values based on the artificial viscosity adjustment technique is used to suppress superior oscillations arising from accordingly the vector of unknown parameters is expressed as follows mohapatra and chaudhry 2004 10 w i k 1 w i k 1 κ i 1 2 w i 1 k 1 w i k 1 κ i 1 2 w i k 1 w i 1 k 1 i 1 n wherein κ is determined by κ i w i 1 k 2 w i k w i 1 k w i 1 k 2 w i k w i 1 k and κ i 1 2 κ σ max κ i 1 κ i it should be emphasized herein that the unknown flow parameter values i e a and q should be specified for three nodes from the up and down boundaries at each computational time level see eqs 2 and 3 thereby three fictitious nodes are added at each boundary to achieve numerical computations fig 3 in order to compute the flow parameters at the dummy nodes reflective and transmissive conditions may be used in this regard the fictitious points are replaced by the immediate interior points for example a reflective condition may be employed to describe a boundary condition involved by the closure of an inlet sluice gate i e q x 0 t 0 0 in such a case an antisymmetric reflection condition is incorporated by changing the sign of the flow rate to describe the flow reflection upon the sluice gate accordingly the hydraulic values of fictitious cells at the downstream side of the channel are expressed as follows yost et al 2000 11 d i k 1 d i k 1 and q i k 1 q i k 1 i 1 2 3 however a transmissive condition may be used to describe a constant flow depth condition maintained at the downstream boundary of the channel i e d x 0 t 0 h 0 specifically this condition assumes that the boundary to be at infinity such that they do not affect the local behavior of the flow consequently the hydraulic values of fictitious cells at the upstream side of the channel are expressed as follows yost et al 2000 12 d n i k 1 d n i 1 k 1 and q n i k 1 q n i 1 k 1 i 1 2 3 finally it should be emphasized that the numerical stability of the forgoing numerical procedure is ensured basing on the courant friedrichs lewy condition gharangik and chaudhry 1991 rahman and chaudhry 1995 13 σ c r u c m a x where c g d is the celerity of gravity wave in a rectangular channel and c r is the courant number c r 2 3 jameson et al 1981 2 1 model validation in order to demonstrate the performance of the developed numerical procedure in capturing shock waves in open channel the experimental measurements carried out by gharangik and chaudhry 1991 on a horizontal rectangular flume l 14 0 m t 0 46 m equipped with a large constant head tank at its upstream and a weighing tank at its downstream extremity fig 4 the initial steady state flow corresponds to a gradually varied flow regime which is described by the following relationship between flow depth and velocity along the flume d d 0 d x s 0 s f 1 u 2 g u the transient event studied by the authors concerns a hydraulic jump provoked and controlled by an adjustable sluice gate placed at the downstream extremity of the flume for flow velocity u x l 3 831 m s corresponding to the froude number value f r 7 the depth magnitudes measured at up and down stream sides of the hydraulic jump are d x 0 m 0 031 m and d x l 0 265 m respectively fig 5 compares the measured free surface profile versus length at the instant t 63 4 s and the numerical ones computed using the mccormack scheme for discretizing the conventional and the 2 4 dissipative scheme discretizing of the 1d extended st venant model as per this figure the free surface profiles computed using both models agree well with experimental traces in terms of jump magnitude furthermore the mccormack and 2 4 dissipative schemes based solvers provide similar results at locations away from the jump on the other side concerning the jump location fig 5 infers that the hydraulic jump predicted by the 2 4 dissipative scheme based on the extended st venant model is situated slightly downstream of the measured one precisely the computed hydraulic jump is located exactly 0 61 m downstream from the observed one however a significant shift is observed between the observed jump location and the computed one using the mccormack scheme based on the conventional st venant model this shift is mainly attributed to the boussinesq add on term embedded in the extended st venant model katopodes 1984 in the next section the 2 4 dissipative scheme based numerical procedure is applied to describe several test cases involved by sluice gates maneuvers 3 applications results and discussion the test case relates to a rectangular open channel equipped with two sluice gates at both extremities fig 6 the channel characteristics are length l 305 m width t 6 1 m longitudinal slope of the open channel bed s 0 10 3 and manning roughness coefficient n 0 014 wylie and streeter 1993 triki and hajtaieb 2010 triki 2021 the initial steady state flow regime is uniform characterized by a flow rate q 0 20 388 m 3 s which corresponds to the uniform depth value equal to d 0 2 4 m eq 4 concerning the 2 4 dissipative scheme algorithm computations were performed using a number of equal space step n s 130 and a courant number c r 0 6 as a first investigation step the fundamental pulsation of the free surface wave is identified based on the analogy with the waterhammer concept used in pressurized pipe flow 3 1 identification of the fundamental pulsation of the hydraulic system the fundamental pulsation of the hydraulic system is inspected through analogy with the waterhammer phenomenon in pressurized pipe flows accordingly the open channel is subjected to abrupt and full closure of the downstream sluice gate while a constant depth value equal to an initial uniform depth is maintained at the channel inlet such a transient event may be expressed as follows 14 q t 0 x l 0 and d t 0 x 0 d 0 fig 7 displays the depth signals versus time computed at different sections along the channel x 0 l 4 l 2 3 l 4 and l in addition the main characteristics of the 9th firsts wave oscillation cycles plotted in fig 6 are listed in table 1 wherein d upsurge and d downsurge designate the depth peak and crest values t 1 2 upsurge and t 1 2 downsurge denote the duration of up and down surge wave portions and t t 1 2 upsurge t 1 2 downsurge corresponds to the duration of wave oscillation cycles as per fig 7 the wave propagation and reflection mechanisms induced by the waterhammer event are characterized by damped oscillatory flow patterns accompanied by an expansion of the wave oscillation period firstly in order to comprehensively address the wave propagation and reflection mechanisms occurring during the transient regime the free surface profiles are reported in fig 8 at several times of the first cycle of depth wave oscillation for example the free surface profile computed at t 34 895 s corresponds to an up surge propagating upstream toward the reservoir while the profile one estimated at t 99 927 s involves an up surge reflecting downstream toward the sluice gate likewise the free surface profile plotted at t 164 958 s corresponds to a down surge propagating upstream however the profile displayed at t 229 990 s involves a down surge reflecting downstream secondly fig 7 illustrates a depth rise succeeding to the closure maneuver of downstream sluice gate and subsequently a significant depth drop in this case the magnitudes of up and down depth surges are δ d upsurge d max d 0 3 7 2 4 1 3 m and δ d downsurge d 0 d min 2 4 1 4 1 0 m respectively this result indicates asymmetry between the up and down surge depth magnitudes similarly fig 7 together with table 1 illustrates asymmetry between the up and down depth surge durations in this case the duration of up surge depth t 1 1 2 upsurge 137 8518 s is more important than the down surge depth t 1 1 2 downsurge 114 9091 s this means that the up surge wave travels slower than the down surge one physically this asymmetry is attributed to the direction of the propagating or reflecting wave portion more precisely the celerity value of positive wave propagating toward the upstream extremity is equal to v w u a which is greater than the celerity value of positive wave propagation toward the downstream extremity is equal to v w u a incidentally the period of the first cycle of wave oscillation is equal to t 1 t 1 1 2 upsurge t 1 1 2 downsurge 137 8518 114 9091 252 7610 s which corresponds to the fundamental pulsation of the hydraulic system ω f 2 π t 1 2 π 252 7610 0 0248 rd s it is worth emphasizing herein that this period value is almost equal to the theoretical period value t a 4 l a 4 l g d 0 4 305 9 81 2 4 251 431 s thirdly fig 7 shows that the ultimate values of depth peak or crest are observed in the first cycle of depth wave oscillation however these values are attenuated for the subsequent depth wave oscillation cycles physically this attenuation effect is due to friction effects furthermore the asymmetry between up and down depth surge magnitude is mainly attributed to mixed boundary conditions at the free surface and the bottom of the flow as regards the period of the depth wave oscillation cycle fig 7 indicates that the minimum period value is observed in the first cycle of depth wave oscillation thereafter the period value increases significantly in the second cycle of depth oscillation and decreases gradually in the subsequent cycles of depth wave oscillation cycles physically this trend may be explained by the proportional relationship between the period and depth values triki 2016 2021 2021 as far analysis permitted identification of the hydraulic system harmonics therefore it is interesting to study the free surface wave behavior due to a sine excitation of the hydraulic system with the above deduced pulsations 3 2 analysis of sine excitation of upstream depth this subsection investigates the free surface waves behavior due to a sine excitation of the upstream flow depth into the open channel initially at rest the boundary conditions associated with such a situation may be as follows 15 q t 0 0 a n d d t 0 x l d 0 δ d sin ω t wherein δ d 0 3 m as a first investigation stage the sine excitation uses the fundamental pulsation of the hydraulic system already deduced i e ω ω f fig 9 shows the depth signals versus time computed at different sections along the channel x 0 l 4 l 2 3 l 4 and l in addition the main characteristics of the 9th firsts wave oscillation cycles plotted in fig 9 are reported in table 2 referring to fig 9 the wave propagation and reflection mechanisms during the transient event are characterized by amplified oscillatory flow patterns accompanied by an expansion of the wave oscillation period specifically the depth reaches a maximum or minimum values equal to d max 3 7 m or d min 1 2 m respectively in other words the amplification or reduction ratios of depth relative to initial uniform value is equal to d max d 0 1 54 or d min d 0 0 5 respectively on the other hand the period of the first cycle of depth oscillation is equal to t 1 311 233 s as regards the wave propagation and reflection mechanisms occurring during the transient regime fig 10 reports the free surface profiles at several times of the first cycle of depth wave oscillation for example the free surface profile computed at t 49 849 s corresponds to an up surge propagating upstream toward the reservoir while the profiles estimated at t 99 698 s and t 1968 575 s involve an up surge reflecting downstream toward the sluice gate likewise the free surface profile plotted at t 2327 673 s corresponds to a down surge propagating upstream however the profile displayed at t 159 702 s involves a down surge reflecting downstream as a second investigation stage the hydraulic system is excited using ω 3 ω f fig 11 shows the depth signals versus time computed at different sections along the channel x 0 l 4 l 2 3 l 4 and l in addition fig 12 illustrates the free surface profiles displayed at several times of the first cycle of depth wave oscillation the general pattern of fig 11 reveals a beating phenomenon of the depth signals particularly the beating of upstream flow depth is driven by the pulsation of the sine excitation of the downstream depth furthermore as per fig 11 the beating period of the downstream depth is equal to τ 1189 407 s concerning the wave propagation and reflection mechanisms occurring during the transient regime fig 12 reports the free surface profiles at several times of the first cycle of depth wave oscillation for example the free surface profiles computed at t 74 775 s and t 99 698 s correspond to an up surge propagating upstream toward the reservoir while the profile one estimated at t 124 758 s involves an up surge reflecting downstream toward the sluice gate likewise the free surface profile plotted at t 149 950 s corresponds to a down surge propagating upstream however the profile displayed at t 249 917 s involves a down surge reflecting downstream the third investigation stage addresses the superposition of the 9th first odd pulsations as being a more realistic description of the free surface wave distortion triki 2016 this scenario may be coded as follows 16 q t 0 0 and d t 0 x l d 0 δ d l 1 9 sin ω l t wherein δ d 0 3 m fig 13 illustrates the depth signals versus time computed at different sections along the channel x 0 l 4 l 2 3 l 4 and l in fact these curves show the superposition of two surge waves propagating in the opposite direction and which superimpose before separately continuing unaffected by superposition incidentally during the superposition scenario the depth amplitudes are subtracted from one another whenever the two waves that have encountered are of out phases in addition it is clearly shown from these curves that the depth signals due to superposition are quantitatively driven by the water hammer waves at all sections of the channel in this regard the extremity the downstream depth signal reaches a maximum or minimum values equal to d max 3 9 m at t 99 966 s or d min 1 5 m at t 986 445 s respectively 4 conclusion overall this study highlighted that the 1 d extended st venant equations based on the boussinesq add on term allows a more realistic description of free surface wave behavior in open channels besides unlike the mccormack scheme based solver the 2 4 dissipative scheme based one leads to an accurate discretization on the boussinesq add on term on the other hand the water hammer theory used in pressurized pipe flows could help estimate the fundamental pulsation of the free surface wave likewise the superposition between a sine excitation of the upstream depth and the downstream water hammer maneuver involved severe scenarios leading to important amplifications of the depth peak and crest values above the initial flow depth value credit authorship contribution statement souad mnassri writing original draft writing review editing investigation software conceptualization methodology ali triki writing original draft writing review editing investigation software conceptualization methodology supervision reviewing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper notation the following symbols are used in this paper a wetted cross sectional area of the channel m 2 t channel width m c celerity m s c r courant number g acceleration of gravity m s 2 l channel length m n manning roughness coefficient s m 1 3 q discharge m 3 s r h hydraulic radius m s 0 longitudinal slope of the channel bottom m m s f m 2 v 2 r h 4 3 friction slope m m t time s v w surge celerity m s u depth averaged velocity m s x abscissa measured along the channel bed m d flow depth measured perpendicular to the channel bed m greek symbols ω pulsation s 1 ω f fundamental pulsation s 1 subscripts 0 initial flow condition i mesh index in the x direction k mesh index in the t direction n number of mesh 
20378,this paper proposes a control architecture of autonomous underwater vehicle auv for coverage mission in irregular region cmir with an improved task planner the cmir control architecture is structured in four layers perception layer reactive layer decision making layer and execution layer to improve the task planner in decision making layer of control architecture we adopted convex partitioning method and success history based adaptive differential evolution algorithm shade including linear population size reduction l shade as the computing engine which make cmir control architecture more suitable to coverage problems through statistical analysis we obtained a set of optimized control parameters simulation experiments were carried out three task planners were compared in terms of convergence speed optimized path length and computing time consumption the results show that the coverage efficiency of the task planner based on l shade is higher than that of task planner based on particle swarm optimization pso and differential evolution de sea trial was performed with sailfish auv which proved that the cmir control architecture is feasible in actual marine environment keywords auv task planner coverage mission irregular region control architecture 1 introduction as a self controlled underwater equipment autonomous underwater vehicles auvs are utilized for the purpose of collecting data of the ocean ahn et al 2017 they also play an important role in a wide range of applications such as intelligent detection lin et al 2017 mine detection kohntopp et al 2017 and military support hasvold et al 2006 aras et al 2016 though auv technology has been developed rapidly in recent years curtin et al 2005 atyabi et al 2018 compared with robots in other fields auv is still in the low level intelligence stage of predefined tasks brito et al 2018 if the autonomous level of auv is higher it will be able to complete more complex tasks which is beneficial to the development of marine industry control architecture is an important factor restricting the development of auv intelligence in scientific experiments and ocean environmental observation missions bian et al 2012 ellefsen et al 2017 it is common to detect regions with special terrain paull et al 2012 underwater structure or other underwater targets due to the scattered distribution of no navigation zone at sea and marine equipment in ports the shapes of exploration regions are mostly irregular current research for regional exploration mainly focuses on coverage path planning algorithms in regular regions there are few research on the coverage of irregular regions therefore it is of great significance to study the problem for coverage mission in irregular region we proposed a cmir control architecture including an improved task planner which can decompose irregular regions and determine task orders to generate an optimized coverage path the decomposition algorithm of irregular regions is based on convex partitioning method the task orders and optimized coverage path are determined by task planner the difficult problem is to traverse multiple regions after decomposition unlike the traveling salesman problem there are different traversal paths in each sub region this leads to a sharp increase in the dimensions of the problem therefore it is necessary to find the optimized sub region traversal order and optimized coverage path with an effective algorithm we designed an improved task planner based on l shade to solve this problem the improved task planner consists of two levels of optimization the upper level of optimization determines the traversal order of sub regions it is responsible for assigning traversal orders of sub regions the lower level determines the sub region coverage path it is responsible for selecting optimized paths of sub regions in order to reduce the occurrence of mission interruption due to emergencies the behavior of coverage mission is introduced based on a layer based control architecture palomeras et al 2012 there are three types of control architectures deliberate reactive and hybrid the deliberative architecture cycles through the process of perception modeling planning and execution hagen et al 2007 which has the advantage of clear logic in the reactive architecture perception action is regarded as the basic control component and the behavior of auvs directly depends on their environmental conditions the hybrid architecture which combines the deliberative and reactive architecture can be divided into planning layer control execution layer and functional response layer it has clear execution logic and can make rapid response to dynamic environment most architectures for robotics follow a hybrid pattern the cmir control architecture proposed in this paper implements a layered architecture model but with some peculiarities an improved task planner based on l shade are proposed to improve the coverage efficiency convex partitioning method is led into cmir control architecture to handle irregular regions behaviors for coverage mission are concluded in the control architecture the rest of this paper is organized as follows section 2 provides related work of control architecture and l shade the proposed cmir control architecture is presented in section 3 in section 4 experimental results are reported section 5 introduces the sea trial and show the results section 6 concludes with final remarks and suggestions for future work 2 related work several control architectures have been developed for agents to deal with complex missions the well known architectures in the research field include logic based architecture beliefs desire intention bdi architecture deliberative architecture reactive architecture and hybrid architecture veres et al 2011 2 1 control architecture logic based agent s decision making process is modeled through a set of deduction rules the architecture has been rapidly developed and applied to agents in the 1990s de giacomo et al 2000 lespérance et al 1996 bdi architecture has its root in efforts obtaining practical reasoning based on goals that a human want to achieve veres 2005 in bdi architecture the states of agents are divided into beliefs desires and intentions three functions are constructed to revise beliefs choose desires and filter intentions expressive logics that combine multiple modalities of beliefs desires and intentions with temporal modalities to describe or specify the behaviors of agents has developed based on bdi architecture however none of these logics have sound and complete axiomatizations or tractable constructive decision procedures rao 1995 deliberative architecture is based on planning using a world model which allows reasoning and making predictions about the environment it is made available for regular and structured environment carreras et al 2002 and can be developed to overcome limitations from pre planned mechanism through on board planning mcgann et al 2008 the most serious defect existing in deliberative architecture is the delay in response time when dealing with a highly dynamic environment ridao et al 2000 the reactive architecture which is also called behavioral architecture appeared in response to the problems with the computational complexity of deliberative architecture the behaviors are basic component to carry out actions a group of parallel behaviors are acted independently without planning according to the environmental conditions brooks 1986 reactive architecture is widely applied in auv and other agents because of its advantage of real time response muller et al 1994a müller et al 1994b rosenblatt et al 2002 gu et al 2003 flanagan et al 2003 however it is difficult to design a set of behaviors in order to plan and to specify high level goals hybrid architecture takes advantage of deliberative architecture and reactive architecture tangirala et al 2005 consequently it consists of three layers gat 1998 the lower layer based on reactive techniques the execution layer and the higher layer based on deliberate control these three layers may be named differently in different application scenarios but they generally have similar functions peter bonasso et al 1997 gat 1991 the deliberate layer converts the mission into a task sequence the execution layer further refines these tasks and forms specific tasks that are easy to execute the reaction layer is responsible for timely responding to dynamic environment the hybrid architecture has the advantages of clear execution logic and rapid system response in recent years many researchers focus on the study of mission and task management in high level and put forward some meaningful methods jalaoui et al presented a control architecture of underwater robots and applied it to auv taipan jalaoui et al 2005 nishida et al proposed a new control system for auvs using modular network som nishida et al 2007 bian et al described a hierarchical on board architecture for the execution of an autonomous mission and the lake experiments illustrated the feasibility and the adaptability of the mission management architecture bian et al 2009 albiez et al presented a control architecture which aims to fulfill the growing demand for other kinds of auv missions the architecture was a hybrid reactive deliberative system which consisted of individual tasks manager and an elaborate plan manager albiez et al 2010 a hierarchical on board architecture which was specified by increasingly detailed petri nets pn under the agent based distributed autonomous control structure of auv was suggested by bian et al 2012 the architecture was tested with lake trials in which the feasibility and effectiveness of the architecture was proven evertsz et al described a methodology and accompanying tool based on the bdi architecture to make design methodology for modeling tactical decision making systems easy to understand maintain and reuse evertsz et al 2015 somaiyeh et al provided a hierarchical dynamic mission planning framework for auv with a high level reactive mission planner and a low level motion planning system to accomplish task assign process and spatio temporal variability was taken into account mahmoudzadeh et al 2018 valerie winschel applied utility theory to the payload decision making processes of auv for mission planning and re planning purposes winschel 2018 shuo ma and jun lu presented a method of mission planning under uncertain conditions for uuv combat operations to enable uuv to adjust the plan autonomously ma and lu 2019 these studies have made great contributions to the development of control architecture however there are few researches on designing control architecture for coverage mission in irregular regions it is essential to design a control architecture that can efficiently deal with coverage mission in irregular regions therefore we propose a cmir control architecture with an improved task planner the goal is to provide a control architecture to improve coverage efficiency 2 2 l shade in coverage mission an auv must visit the whole region as the lawnmower does to explore underwater targets viswanathan et al 2017 algorithms to improve coverage efficiency have been put forward over years they can be divided into three classes cellular decomposition method grid based coverage method and optimal coverage method many coverage path planners use a cellular decomposition of the free space to achieve coverage a cellular decomposition breaks down the target region into cells such that coverage in each cell is simple choset 2001 elfes 1987 and moravec and elfes 1985 pioneered approximate cellular decomposition cells are all the same size and shape but the union of the cells only approximates the target region the conventional wavefront algorithm was used to determine a coverage path by zelinsky et al 1993 they can define their wavefront potential function to encode different types of cost functions to optimize with their coverage algorithm semi approximate cellular decomposition relies on a partial discretion of space where cells are fixed in width but the top and bottom can have any shape hert et al 1996 a robot following this algorithm may zigzag along parallel straight lines to cover the target region exact cellular decomposition breaks target region into a set of non intersecting regions trapezoidal decomposition is a popular exact cellular decomposition technique free space is decomposed into trapezoidal cells since each cell is a trapezoid coverage in each cell can easily be achieved with simple back and forth motions latombe 1991 grid based coverage method decomposes the space into a set of uniform grid cells it can be classified as cellular decomposition method the boustrophedon cellular decomposition is one of the grid based coverage method it was developed based on classical exact cellular decomposition target region was broken down into cells such that the robot can cover each cell with back and forth boustrophedon motions choset 2000 a line segment is swept through the environment whenever there is a change in connectivity of the slice a new cell is formed choset et al 2000 once a robot covers each cell it has completed the coverage mission the boustrophedon decomposition has a fewer number of cells than the trapezoidal decomposition the boustrophedon decomposition is a particular case of morse decomposition morse based cellular decomposition determined critical points by a morse function it can be used to accomplish different tasks by altering the morse function enric galceran et al summarized the features of coverage path planning methods including classical exact cellular decomposition methods morse based cellular decomposition methods and other popular coverage path planning methods galceran and carreras 2013b classical exact cellular decomposition guarantees complete coverage for a known polygonal environment morse based cellular decomposition method allows generation of different coverage patterns acar et al proposed complete coverage path planning method based on exact cellular decomposition in terms of critical points acar et al 2003 the results were verified by performing experiments in unstructured indoor environments cabreira et al revised some coverage algorithms proposed to deal with irregular shaped areas cabreira et al 2019b and addressed grid based solutions considering full and partial information about the workspace cabreira et al 2019a alia ghaddar and ahmad merei proposed a grid based algorithm to scan an area for reducing completion time and energy consumption ghaddar and merei 2019 optimal coverage method is superior to the cellular decomposition method and the grid based coverage method l shade is an extension of the basic differential evolution das and suganthan 2010 it attracts attentions as its excellent performance recent years the method and its variants have become the winners of recent ieee competitions in evolutionary computation piotrowski 2018 zamuda and sosa presents an application of l shade to an expert system for underwater glider path planning ugpp this new application of evolutionary algorithms to ugpp contributes significantly to the capacity of the decision makers zamuda and sosa 2019 although l shade has been applied to auv path planning there is no literature mentioning its application in the coverage mission of irregular region the coverage mission of irregular region involves the decomposition of region and the coverage of sub regions this problem is more complicated than the general path planning we proposed an improved task planner based on l shade to make coverage in irregular region be solved efficiently the optimized control parameters of l shade were obtained from simulation experiments the implementation flow chart of l shade is shown as fig 1 the process of l shade is as follows 1 mutation process set a is defined to store the eliminated individuals in the selection process and initialize them to be empty define arrays mf and mcr to store the mutation factors and crossover factors which performed well in the past generations their sizes are mf mcr h h is the control parameter of l shade algorithm and the value in the array is initialized to 0 5 f is defined as the mutation factor cr is the crossover factor the integer r is randomly selected from 1 to h the method to calculate mutation factor and crossover factor of the ith individual in g generation is 1 f i g mf r 0 1 tan rand π π 2 2 cr i g 0 mcr r 1 n o r m r n d mcr r 0 1 o t h e r w i s e where rand is a number sampled from the uniform distribution 0 1 and normrnd denotes the function that generates a number sampled from the normal distribution if the value of f i g exceeds the interval 0 1 f i g 0 5 then the fitness value of each individual in the population is calculated and the individual x r 1 g with the highest fitness is selected islam et al 2011 and then two different basis vectors x r 2 g and x r 3 g are randomly selected from the union of two sets the set of the remaining p individuals with the highest fitness and the set a to perform mutation operations 3 v i g x i g f i g x r 1 g x i g f i g x r 2 g x r 3 g 2 crossover process the crossover process refers to the crossover transformation of elements between the original individual and the mutated individual in the population if x i g j is the jth element of the ith individual in g generation population j 1 m 1 the crossover process is carried out according to the following rules 4 u i g j v i g j r a n d cr i g x i g j o t h e r w i s e where v i g j is the jth element of the ith mutation individual in g generation population u i g j is the crossover result of crossing the jth element of the ith individual and the ith mutation individual in g generation population u obtained after crossover should be within the range of feasible solution 3 selection process comparing between the results of the crossover process and the original population the individuals with high fitness are retained as the next generation population and the individuals with low fitness are eliminated and the eliminated individuals are stored in set a the formula is as follows 5 x i g 1 x i g f u i g f x i g u i g o t h e r w i s e 4 parameter updating process in the g generation population the initial set sf and scr are empty if the new individuals obtained after mutation crossover are successfully selected the mutation factors f i g and crossover factor cr i g of the individuals are stored in the set sf and scr respectively sf scr sf and scr are used to update mf and mcr assuming that k is the index of mf and mcr the following conditions are satisfied 6 k mod g h mod g h 0 h o t h e r w i s e where mod is modulo function represents the remainder of g h the parameters are updated according to the following rules 7 mf k l 1 sf w l sf l 2 l 1 sf w l sf l 8 mcr k l 1 scr w l scr l 2 l 1 scr w l scr l 9 w l δ f l α 1 scr δ f α 10 δ f l f u l g f x l g assuming the population size of generation g is np g the rule of linear population size reduction is as follows 11 np g 1 round np 0 np 0 min np max g g where round is an integral function min np is the smallest population size max g is the largest population iteration times and g is the current population iteration time the np g 1 individuals with the highest fitness in the g generation population are retained to form the g 1 generation population and the rest are stored in set a 3 cmir control architecture the main idea is to define related layers and components fig 2 overviews the layers and components of cmir control architecture it consists of four significant layers the perception layer the reactive layer the decision making layer and the execution layer the function of perception layer is to collect its own status and environmental information so as to find the threat caused by faults or obstacles in time the reactive layer receives evaluation information and estimates the behavior to response the decision making layer decompose the irregular region plans task orders coordinates the conflicting modules and decides what response to make the execution layer is responsible for receiving and analyzing instructions from decision making layer to control the speed course and attitude of auv 3 1 the perception layer the state of vehicle and data from surroundings which are obtained through sensors must be considered to improve the situation awareness therefore the perception layer is one of the most critical required factors for control architecture and it is conducive to promoting the capability of dealing with unforeseen events the sensors in perception layer is shown in fig 3 it perceives the environment through the auv s own structure or sensors the hardware includes battery doppler velocity log dvl multi beam sonar and side scan sonar the important modules of perception layer are energy position velocity obstacle and target perception the residual energy is obtained by monitoring the battery voltage its position and velocity are measured by dvl multi beam sonar is used to measure obstacle information and side scan sonar is used to explore environment and target the attitude of the vehicle is estimated with an attitude heading reference system ahrs after the perception information is obtained it is transmitted to the reaction layer 3 2 the reactive layer the reactive layer has four components of logical structure mission task and behavior components the internal structure and logical relationship of reactive layer are shown in fig 4 mission component is a message received by auv which contains the vertexes of irregular region task component refers to the phase of mission that auv is responsible for the goal of a task is to cover a sub region which is obtained by decomposing the irregular region multiple sub regions constitute the task sequence behavior is a sequence of actions to be executed to ensure that auv can reach a path point safely as the basic component of reaction layer behavior cannot be subdivided it usually includes path planning obstacle avoidance navigation calibration communication emergency floating and sensor control mission task and behavior can be interrupted in the process of execution 3 3 the decision making layer the decision making layer is similar to the deliberate layer in other architectures the components in the decision making layer manage that in the reaction layer the mission manager receives the mission from shore computer or mission component in reactive layer and reasonably decomposes the mission into task sequence the task planner encapsulates some planning algorithms to obtain optimized execution sequence of tasks the behavior arbiter is used to deal with the conflicting behaviors so that the auv complete the task orderly in complex and changeable environments the relationship between the decision making layer and other layers is shown in fig 5 3 3 1 mission manager the mission is to cover a region in the sea mission message is the vertexes of the region in most cases due to the influence of natural environment the shape of the region presents irregular concave polygon the complex shape of the region makes it very difficult to directly plan tasks and paths it is of great significance to use the mission manager in decision making layer to decompose irregular region generally convex region is easier to plan than concave area so the function of mission manager is to decompose concave polygon into several convex polygons we decompose irregular regions based on convex partitioning method wijeweera and kodituwakku 2017 suppose that the set of vertices of the sea area is v v 1 v n take the midpoint of v i 1 and v i 1 which is called vm to connect with v i then take two points from the line respectively near the two endpoints if none of them is in the sea area the angle where v i is located is concave angle where i 2 n 1 if i is equal to 1 v i 1 is v n if i is equal to n v i 1 is v 1 ray intersection method is adapted to determine whether the fixed point is in the sea area make rays from the fixed point to east west north and south four directions if a ray does not intersect the boundary of the sea area or the number of intersections between a ray and the region boundary is even the fixed point is outside the sea area otherwise the point is inside the sea area judging from the first vertex when a concave angle vertex is encountered the edge of the previous position where the concave angle vertex is located is extended the extension line of the edge and the sea area produce an intersection point which divides the whole area into two sub areas repeat this process until all the sub areas cannot be subdivided then the mission area decomposition is completed the mechanism of decomposition in mission manager is provided by algorithm 1 3 3 2 task planner after decomposition the determination of task orders becomes the key process therefore it is necessary to design a task planner to generate optimized task order according to the task objectives and constraints the optimized task orders are similar to the traveling salesman problem but more complex than that because the traveling salesman problem considers optimized order between points optimized order is optimized path however the coverage mission is to traverse an irregular region the task planner not only considers the coverage order between tasks but also selects the starting point of each area only after the starting points are determined can the optimized coverage path be fixed this is an np hard problem and the traditional algorithm consumes a lot of computing resources to get accurate solutions the long time calculation is usually intolerable heuristic intelligent algorithm has been widely accepted because of its excellent computing performance although it is difficult to get the global optimized solution it can obtain the satisfactory optimized solution in a short time success history based adaptive differential evolution algorithm shade including linear population size reduction l shade is a global optimization method with outstanding search performance which can overcome the difficulties of traditional algorithm zamuda and sosa 2019 therefore we design task planner based on l shade the challenge is that no one has applied l shade to coverage of irregular regions the dimension of this problem is higher than that of the traveling salesman problem we propose two levels of optimization to improve task planner the upper level is responsible for optimizing coverage order of sub regions suppose that there are n sub regions sr r 1 r i r n set a storage region number and set ℬ is empty randomly select a number from a and put it into ℬ until a becomes an empty set the sequence i r r a n d 1 r r a n d i r r a n d n in ℬ is a feasible solution also called an individual where r r a n d i is the number taken from a for the i th time it is an element of an individual according to the above method np individuals are generated as the initial population of the first level nf i 1 i np the lower level is responsible for optimizing the selection of paths in sub region each sub region is swept along the long side to generate a coverage path there are four possible cases as shown in fig 6 the main difference is that the starting points of the paths are different the four types of paths are represented by integers 1 to 4 randomly generate integers between 1 to 4 generate n times and finally form a sequence p p r a n d 1 4 1 p r a n d 1 4 i p r a n d 1 4 n where r a n d 1 4 is an integer randomly generated in the interval 1 4 according to this method np sequences are generated to form the population of the second level ns p 1 p np the initial population of the coverage mission is formed by merging the two levels of population n i 1 p 1 i np p np the constraint is that two identical elements in first level cannot appear at the same time in an individual to satisfy this constraint the elements in the mutated and crossed individuals are sorted according to the size and the sequence composed of elements positions is regarded as the new individual the fitness function is constructed with the shortest path as optimization objective the population size decreases linearly with the number of iterations when the population size is reduced to minimum size np e n d the iteration stopped the l shade implementation process is similar to differential evolution poláková 2017 which is divided into four stages mutation process crossover process selection process and parameter updating process the mutation process and the selection of mutation factors are carried out in accordance with the methods described in section 2 2 it is worth noting that the mutated individuals need to meet the requirements of the constraint assuming that the individuals in the first and second level are v f and v s after the treatment of eq 3 the mutated individuals satisfying the constraint need to be transformed as follow 12 v tf sort v f 13 v ts ceil mod v s 4 where v tf and v ts are the mutated individuals satisfying the constraint in the first and second level respectively sort is a function to obtain the arrangement of the elements in v f mod is a function to obtain the remainder after division of v s by 4 ceil is a function to round each element of mod v s 4 to the nearest integer greater than or equal to that element after the crossover operation the same transformation needs to be made the fitness function is established with the shortest total path length 14 f c n d s j 1 n 1 d j i 1 n p i where d s is the distance from the placement to the first sub region d j is the distance between two sub regions p i is the path length of a sub region after iterations the algorithm converges and gets the final population from the population the individual with the highest fitness is selected 3 3 3 behavior arbiter the ocean environment is complex and changeable and auv must make sensitive reactions to external conditions we define the action sequence of these reactions as behavior when multiple behaviors are triggered at the same time the problem of behavior selection and decision making will be faced therefore the behavior arbiter is designed to handle conflicts between behaviors the behavior arbiter evaluates the threat degree of auv based on the rule base and decides to suppress or activate a behavior to remove the threat rule base includes behavior name behavior current state threat degree and triggering events the rule base of behavior arbiter is shown as fig 7 guidance behavior is the default behavior after the task starts it has the lowest threat degree and belongs to the normal state the black stars represent threat degrees in the figure only when the guidance fails or other behaviors end the new target point will be assigned to trigger the new guidance behavior global positioning system gps calibration behavior is triggered by time when auv has been underwater for more than a certain period of time it will float up to the water surface for calibration obstacle avoidance is triggered by the detection of obstacles it can avoid collision between auv and obstacles and ensure navigation safety the floating behavior is triggered when auv software or hardware goes out of order such as guidance program emergency control program emergency navigation emergency communication emergency process death and thruster fault when the voltage of auv is too low or leakage occurs or the position is beyond predetermined depth it will trigger the behavior of throwing load and floating each behavior has two states activation and inhibition the behavior arbiter triggers the behavior according to the threat degree of the event the behavior with more black stars representing the threat degree was activated first while other behaviors were inhibited 3 4 the execution layer the execution layer is at the bottom of the architecture and is generally associated with the actuator the precise execution of command is the foundation of architecture it includes three main components action component velocity component and sensor component the action component controls the rudder of auv to adjust the course and depth the velocity component controls the propeller speed to adjust the navigation speed the sensor component is responsible for opening and closing sensors so that the sensors can work together efficiently the execution results are fed back to the upper layer of the architecture to influence the next decision forming a closed loop in this way 4 simulation results and discussion in order to test the performance of the architecture and obtain optimized control parameters of the improved task planner irregular regions are constructed for simulation 4 1 the optimized parameters of task planner in cmir control architecture we construct a complex irregular region the vertex coordinates is v 1 10 2 10 2 5 3 4 3 8 4 8 4 5 5 5 5 10 6 10 6 20 5 20 5 15 4 15 4 20 3 20 3 15 2 15 2 20 1 20 and the shape of the region is shown in fig 8 a the irregular region was decomposed by the method proposed in mission manager the result is shown in fig 8 b the common method to deal with this type of region is to construct the outer rectangle and then to make global planning in the rectangle the disadvantage of outer rectangle method is that it will increase the area of the mission causing unnecessary extra work the mission manager we designed overcomes these shortcomings by decomposing region and generating task order the parameters of the experiment were set as follows iteration 1000 scanning range 0 1 initial population size 126 minimum population size 4 percentage p 0 11 h 6 the task order and global path obtained by simulation experiment are shown in fig 9 a the blue dot is the auv placement position and the red star is the ending point the gray number represents the task order and the gray arrow indicates the traversal direction the variation of the average path length and the shortest path length is shown in fig 9 b it can be seen that the average path length of the population decreases with the increase of iterations when the number of iterations reaches 150 the minimum path length does not change it shows that the task planner is able to get the expected results but the computing time is as high as 18000 s which is unbearable therefore the number of iterations is set to 150 since other parameters except population size have little influence on the results we analyze the influence of the initial population size on the time consumption the initial population size is set at 126 105 70 49 28 and 14 respectively these numbers are multiples of 7 126 is 18 times of 7 105 is 15 times of 7 in the literature piotrowski 2018 the initial population is set as 18 times of the problem dimensionality the number of sub regions is 7 so we choose the multiple of 7 to test ten experiments are conducted for each parameter to obtain the box diagram of the shortest path length as shown in fig 10 a the mark indicates outlier and the red line in the middle of the box indicates the median of path length the results show that the decrease of the initial population size makes the final path length of task planner larger although the task planner cannot get the optimal solution the optimized solution in acceptable time can be satisfactory the advantage of the decrease of initial population size is that the time consumption is less and the disadvantage is that the path is longer the average path length and average time consumption are shown in table 1 it can be seen that when the initial population size is 28 and 14 computation time is shorter and the path length is not much larger compared with the population size of more than 50 so the most suitable initial population size is 28 in order to analyze the performance of task planner of cmir control architecture we compared the task planner based on l shade in cmir control architecture with the other two task planners based on de and pso the results are shown in fig 10 b the red solid line represents the path length of the task planner based on l shade with different iterations the blue dotted line and the black dotted line represent the path length of the task planner based on de and pso with different iterations respectively it can be seen that under the same number of iterations the path length of the proposed task planner based on l shade is shorter than that of the other two it shows that cmir control architecture is more efficient than architectures based on de and pso in irregular regions 4 2 comparison of different task planners task planner is an important component in decision making layer it can obtain optimized task order and the optimized coverage path we used three types of irregular regions to verify the proposed task planner based on l shade the computational efficiency of the task planner was compared with that of task planner based on de and pso there are three types of irregular regions as shown in fig 11 type 1 type 2 and type 3 contained three four and five sub regions respectively as shown in fig 11 a b and c the scanning range of type 1 was set to 150 and the starting point was set as 0 0 the scanning range of type 2 and type 3 were set to 0 3 the starting point was set as 1 10 the number of iterations was 150 and the initial population size was 20 each type of regions was calculated five times with three kinds of task planners and the box diagram was drawn for comparative analysis the mark indicates outlier and the red line in the middle of the box indicates the median of path length the computing time consumption is shown in fig 12 fig 12 a b and c show the computing time consumption of task planner based on l shade de and pso in type 1 2 and 3 regions respectively it can be seen that the time consumption of task planner based on l shade in three types of regions are much shorter than that based on de and pso the result of path length is shown in fig 13 fig 13 a b and c show the path lengths of task planner based on l shade de and pso in type 1 2 and 3 regions respectively in the region of type 1 the task planner results based on l shade are a straight line which shows that the results of the five times calculation are the same it obtained stable results in the region of type 1 the results of task planner based on de and pso fluctuate in a range in the regions of type 2 and type 3 the results of task planner based on l shade were similar to but more stable than those of task planner based on de and pso through the above results we can conclude that under the condition of getting similar or better results the computing time consumption of task planner based on l shade is lower than the other two kinds of task planners therefore the task planner based on l shade in cmir control architecture is more efficient we compare task planner based on l shade with boustrophedon method in type 1 region four different starting points are selected they are 0 0 0 3000 4500 3000 4500 0 the range of single side scan of sonar is 150 m boustrophedon algorithm decomposes type 1 region into one unit the whole region is swept with force and back motion regardless of the starting point the generated coverage path starts from the left to the right or from the right to the left when the starting point is close to the left end of the path it traverses from left to right when the starting point is close to the right end of the path it traverses from right to left four coverage paths are obtained by boustrophedon method compared with l shade the results are shown in fig 14 the light color histogram represents the length of coverage path obtained by l shade and the dark color histogram represents the length of coverage path obtained by boustrophedon method it can be seen that the length of the four paths obtained by l shade is smaller than boustrophedon method 4 3 simulation of the coverage mission in irregular region a coverage mission is considered with the irregular region of type 1 the mission manager in the decision making layer is called to decompose the region through the mission manager three task areas are obtained including a triangle and two quadrangles the task boundary is clear which makes the path planning easier to achieve and is conducive to monitoring the progress of the task the task planner in the decision making layer is used to obtain the task order and global path as shown in fig 15 the range of single side scan of sonar is 100 m the initial value of mf and mcr is 0 5 and the maximum iteration is 150 the size of the historical success parameter h is 6 the proportional parameter p is 0 11 and the initial position of auv is 0 0 the blue dot is the auv placement position and the red star is the task end point the gray arabic number represents the task order and the gray arrow indicates the traversal direction the red line represents the global path according to the planned global path auv should start from the coordinate origin first traverse the triangle area enter the area from the left bottom of the triangle drive out from the bottom of the right side then explore the quadrilateral area above enter from the bottom of the area drive out from the top and turn to the quadrilateral below to continue the task enter from the upper left side of the lower quadrilateral area and drive out from the lower right side after getting the global path the path points that have not yet reached are tracked by the guiding behavior before the guiding behavior is activated it is necessary to determine whether there are events triggering other behaviors the auv sails in the mission area at a speed of 3 m s assuming that there are three obstacles in the sea area the auv needs to float up every one hour for navigation calibration and an emergency behavior is triggered during navigation which can be corrected after floating according to our proposed architecture the simulation results are shown in fig 16 a the blue dot indicates the starting point and the red star indicates the end of the mission the dark green broken line represents the sailing path the black line represents the path generated by the calibration behavior and the red line represents the path generated by the floating behavior it can be seen that when there is no triggering event the behavior arbiter selects the guidance behavior to execute when navigating to the 5th 17th and 20th path points the obstacle avoidance behavior is triggered the guiding behavior is inhibited the obstacle avoidance behavior is activated to generate path points for avoiding obstacles at the end of obstacle avoidance it continues to switch to the guiding behavior to track the global path points when the navigation reaches the 15th 23rd and 31st path points the underwater time is longer than one hour the calibration behavior is triggered to generate path points for calibration after sailing along the path generated by the calibration behavior auv returns to the path point where calibration behavior is triggered by event to continue the task when sailing to the 32nd point it triggers floating behavior by errors in auv program after correcting the error it returns to the 32nd point until the mission is completed fig 16 b is a top view of the navigation path the gray circles represent the obstacles the black quadrilateral is the path generated by the calibration behavior and the red quadrilateral trajectory is the navigation path generated by the floating behavior it can be seen that the behavior arbitration module of decision making layer reasonably switches the behavior of auv which ensures the navigation safety and operation efficiency of auv 5 sea trial to verify the feasibility of cmir control architecture we use sailfish auv to carry out sea trial in tuandao bay qingdao china the diameter of sailfish auv is 324 mm shown as fig 17 a it is equipped with side scan sonar dvl and other sensors the depth and course are adjusted by rudder and the thrust is provided by propeller fig 17 b shows the sea trial scene after sailfish auv deployment ten points are selected as the vertex of the irregular region in tuandao bay due to the size limitation of tuandao bay we select a smaller irregular region in the bay so the shape is the same as the simulation region but the size is different parameters are modified according to the size of the irregular region the scanning range of the side scan sonar is set as 30 m the obstacle information is received after reaching the second turning point when sailfish auv has been underwater for more than 10 min and arrived next turning point the calibration task is triggered the navigation is carried out at a speed of 2 kn and a depth of 0 5 m the utm coordinates of the vertices are in table 2 the actual navigation route of cmir control architecture in irregular region is shown in fig 18 a the abscissa is utm x and the ordinate is utm y the blue solid line represents the irregular area the line formed by the red hollow dots is the actual navigation route of auv the route starts from the lower left corner of the area fig 18 b shows the 3d actual path of sailfish auv the black dot indicates the starting point of the path the red solid line indicates the auv coverage path and the blue dot indicates the end point of the path since forward looking sonar is not equipped on the auv virtual obstacles are set up we program the obstacle information into the auv when auv reaches the position with obstacle information the obstacle avoidance behavior is triggered the main purpose is to verify whether the behavior can be triggered the obstacle avoidance behavior is carried out between the second turning point and the third turning point as shown in the left dotted black circle in fig 18 a the dotted black circle in the right is the path generated by calibration behavior when sailfish auv was between the seventh and eighth turning points it was underwater for more than 10 min and the next turning point was the eighth turning point therefore when the auv reached the eighth turning point the calibration task was triggered and the calibration behavior was made we constructed a coverage mission in irregular region and used sailfish auv to test in the offshore which proved that the cmir control architecture is feasible in actual marine environment but there are still some shortcomings in the architecture due to the influence of control accuracy and environment auv may deviate from the generated path resulting in crossing the boundary of the irregular region if there is no navigation zone outside the boundary or the boundary is an impermeable wall structure auv will be at risk therefore when selecting irregular region the boundary of the region should be kept away from the no navigation zone and wall structures and there should be buffer zone to provide auv sufficient response time to ensure the safety 6 conclusion a cmir control architecture including an improved task planner based on l shade was presented the architecture consists of perception layer reaction layer decision making layer and execution layer particular attention has been paid to the decision making layer in which mission manager was introduced and task planner was designed to solve coverage problem in irregular regions mission manager was used to decompose irregular regions two levels of optimization were drawn into the improved task planner the upper level of optimization determines the traversal order of sub regions and the lower level determines the sub region coverage path other components of cmir control architecture enhanced the ability of auv to deal with emergencies a complex irregular region with 7 sub regions was constructed for simulation to obtain optimized control parameters of task planner three types of irregular region was used to compare the proposed task planner with task planner based on de and pso the results showed that the improved task planner is more efficient than the other two coverage mission in irregular region with three sub regions was simulated for testing the effectiveness of components in the cmir control architecture sea trial was organized in tuandao bay and sailfish auv completed the coverage of irregular region which showed that the cmir control architecture can be used in the actual marine environment at present the boundary vertices of irregular region are selected manually which may affect the autonomy of auv it is a good choice to generate the boundary of operation region by using map data and image processing method the buffer size between boundary of operation region and the danger zone is also a problem worthy of consideration in the future coral reefs and sand waves are generally distributed in irregular areas therefore cmir control architecture can be applied to the approach observation of objects in irregular regions on the seabed our method is mainly used for the detection of sand waves or coral reefs in flat terrain areas auv usually navigates in a fix deep so the proposed method operates in 2d underwater coverage approaches in 3d has more application scenarios galceran and carreras 2013a galceran et al 2015 in the future we will pay attention to 3d coverage path planning credit authorship contribution statement guanzhong chen methodology software validation formal analysis writing original draft writing review editing yue shen writing review editing supervision nanzhu qu investigation software dianrui wang data curation software bo he resources conceptualization project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is partially supported by the national key research and development program of china project number 2016yfc0301400 part of the codes in matlab for extending the optimization algorithms utilized are provided by qingfu zhang at http dces essex ac uk staff qzhang code and by ryoji tanabe at https sites google com site tanaberyoji home 
20378,this paper proposes a control architecture of autonomous underwater vehicle auv for coverage mission in irregular region cmir with an improved task planner the cmir control architecture is structured in four layers perception layer reactive layer decision making layer and execution layer to improve the task planner in decision making layer of control architecture we adopted convex partitioning method and success history based adaptive differential evolution algorithm shade including linear population size reduction l shade as the computing engine which make cmir control architecture more suitable to coverage problems through statistical analysis we obtained a set of optimized control parameters simulation experiments were carried out three task planners were compared in terms of convergence speed optimized path length and computing time consumption the results show that the coverage efficiency of the task planner based on l shade is higher than that of task planner based on particle swarm optimization pso and differential evolution de sea trial was performed with sailfish auv which proved that the cmir control architecture is feasible in actual marine environment keywords auv task planner coverage mission irregular region control architecture 1 introduction as a self controlled underwater equipment autonomous underwater vehicles auvs are utilized for the purpose of collecting data of the ocean ahn et al 2017 they also play an important role in a wide range of applications such as intelligent detection lin et al 2017 mine detection kohntopp et al 2017 and military support hasvold et al 2006 aras et al 2016 though auv technology has been developed rapidly in recent years curtin et al 2005 atyabi et al 2018 compared with robots in other fields auv is still in the low level intelligence stage of predefined tasks brito et al 2018 if the autonomous level of auv is higher it will be able to complete more complex tasks which is beneficial to the development of marine industry control architecture is an important factor restricting the development of auv intelligence in scientific experiments and ocean environmental observation missions bian et al 2012 ellefsen et al 2017 it is common to detect regions with special terrain paull et al 2012 underwater structure or other underwater targets due to the scattered distribution of no navigation zone at sea and marine equipment in ports the shapes of exploration regions are mostly irregular current research for regional exploration mainly focuses on coverage path planning algorithms in regular regions there are few research on the coverage of irregular regions therefore it is of great significance to study the problem for coverage mission in irregular region we proposed a cmir control architecture including an improved task planner which can decompose irregular regions and determine task orders to generate an optimized coverage path the decomposition algorithm of irregular regions is based on convex partitioning method the task orders and optimized coverage path are determined by task planner the difficult problem is to traverse multiple regions after decomposition unlike the traveling salesman problem there are different traversal paths in each sub region this leads to a sharp increase in the dimensions of the problem therefore it is necessary to find the optimized sub region traversal order and optimized coverage path with an effective algorithm we designed an improved task planner based on l shade to solve this problem the improved task planner consists of two levels of optimization the upper level of optimization determines the traversal order of sub regions it is responsible for assigning traversal orders of sub regions the lower level determines the sub region coverage path it is responsible for selecting optimized paths of sub regions in order to reduce the occurrence of mission interruption due to emergencies the behavior of coverage mission is introduced based on a layer based control architecture palomeras et al 2012 there are three types of control architectures deliberate reactive and hybrid the deliberative architecture cycles through the process of perception modeling planning and execution hagen et al 2007 which has the advantage of clear logic in the reactive architecture perception action is regarded as the basic control component and the behavior of auvs directly depends on their environmental conditions the hybrid architecture which combines the deliberative and reactive architecture can be divided into planning layer control execution layer and functional response layer it has clear execution logic and can make rapid response to dynamic environment most architectures for robotics follow a hybrid pattern the cmir control architecture proposed in this paper implements a layered architecture model but with some peculiarities an improved task planner based on l shade are proposed to improve the coverage efficiency convex partitioning method is led into cmir control architecture to handle irregular regions behaviors for coverage mission are concluded in the control architecture the rest of this paper is organized as follows section 2 provides related work of control architecture and l shade the proposed cmir control architecture is presented in section 3 in section 4 experimental results are reported section 5 introduces the sea trial and show the results section 6 concludes with final remarks and suggestions for future work 2 related work several control architectures have been developed for agents to deal with complex missions the well known architectures in the research field include logic based architecture beliefs desire intention bdi architecture deliberative architecture reactive architecture and hybrid architecture veres et al 2011 2 1 control architecture logic based agent s decision making process is modeled through a set of deduction rules the architecture has been rapidly developed and applied to agents in the 1990s de giacomo et al 2000 lespérance et al 1996 bdi architecture has its root in efforts obtaining practical reasoning based on goals that a human want to achieve veres 2005 in bdi architecture the states of agents are divided into beliefs desires and intentions three functions are constructed to revise beliefs choose desires and filter intentions expressive logics that combine multiple modalities of beliefs desires and intentions with temporal modalities to describe or specify the behaviors of agents has developed based on bdi architecture however none of these logics have sound and complete axiomatizations or tractable constructive decision procedures rao 1995 deliberative architecture is based on planning using a world model which allows reasoning and making predictions about the environment it is made available for regular and structured environment carreras et al 2002 and can be developed to overcome limitations from pre planned mechanism through on board planning mcgann et al 2008 the most serious defect existing in deliberative architecture is the delay in response time when dealing with a highly dynamic environment ridao et al 2000 the reactive architecture which is also called behavioral architecture appeared in response to the problems with the computational complexity of deliberative architecture the behaviors are basic component to carry out actions a group of parallel behaviors are acted independently without planning according to the environmental conditions brooks 1986 reactive architecture is widely applied in auv and other agents because of its advantage of real time response muller et al 1994a müller et al 1994b rosenblatt et al 2002 gu et al 2003 flanagan et al 2003 however it is difficult to design a set of behaviors in order to plan and to specify high level goals hybrid architecture takes advantage of deliberative architecture and reactive architecture tangirala et al 2005 consequently it consists of three layers gat 1998 the lower layer based on reactive techniques the execution layer and the higher layer based on deliberate control these three layers may be named differently in different application scenarios but they generally have similar functions peter bonasso et al 1997 gat 1991 the deliberate layer converts the mission into a task sequence the execution layer further refines these tasks and forms specific tasks that are easy to execute the reaction layer is responsible for timely responding to dynamic environment the hybrid architecture has the advantages of clear execution logic and rapid system response in recent years many researchers focus on the study of mission and task management in high level and put forward some meaningful methods jalaoui et al presented a control architecture of underwater robots and applied it to auv taipan jalaoui et al 2005 nishida et al proposed a new control system for auvs using modular network som nishida et al 2007 bian et al described a hierarchical on board architecture for the execution of an autonomous mission and the lake experiments illustrated the feasibility and the adaptability of the mission management architecture bian et al 2009 albiez et al presented a control architecture which aims to fulfill the growing demand for other kinds of auv missions the architecture was a hybrid reactive deliberative system which consisted of individual tasks manager and an elaborate plan manager albiez et al 2010 a hierarchical on board architecture which was specified by increasingly detailed petri nets pn under the agent based distributed autonomous control structure of auv was suggested by bian et al 2012 the architecture was tested with lake trials in which the feasibility and effectiveness of the architecture was proven evertsz et al described a methodology and accompanying tool based on the bdi architecture to make design methodology for modeling tactical decision making systems easy to understand maintain and reuse evertsz et al 2015 somaiyeh et al provided a hierarchical dynamic mission planning framework for auv with a high level reactive mission planner and a low level motion planning system to accomplish task assign process and spatio temporal variability was taken into account mahmoudzadeh et al 2018 valerie winschel applied utility theory to the payload decision making processes of auv for mission planning and re planning purposes winschel 2018 shuo ma and jun lu presented a method of mission planning under uncertain conditions for uuv combat operations to enable uuv to adjust the plan autonomously ma and lu 2019 these studies have made great contributions to the development of control architecture however there are few researches on designing control architecture for coverage mission in irregular regions it is essential to design a control architecture that can efficiently deal with coverage mission in irregular regions therefore we propose a cmir control architecture with an improved task planner the goal is to provide a control architecture to improve coverage efficiency 2 2 l shade in coverage mission an auv must visit the whole region as the lawnmower does to explore underwater targets viswanathan et al 2017 algorithms to improve coverage efficiency have been put forward over years they can be divided into three classes cellular decomposition method grid based coverage method and optimal coverage method many coverage path planners use a cellular decomposition of the free space to achieve coverage a cellular decomposition breaks down the target region into cells such that coverage in each cell is simple choset 2001 elfes 1987 and moravec and elfes 1985 pioneered approximate cellular decomposition cells are all the same size and shape but the union of the cells only approximates the target region the conventional wavefront algorithm was used to determine a coverage path by zelinsky et al 1993 they can define their wavefront potential function to encode different types of cost functions to optimize with their coverage algorithm semi approximate cellular decomposition relies on a partial discretion of space where cells are fixed in width but the top and bottom can have any shape hert et al 1996 a robot following this algorithm may zigzag along parallel straight lines to cover the target region exact cellular decomposition breaks target region into a set of non intersecting regions trapezoidal decomposition is a popular exact cellular decomposition technique free space is decomposed into trapezoidal cells since each cell is a trapezoid coverage in each cell can easily be achieved with simple back and forth motions latombe 1991 grid based coverage method decomposes the space into a set of uniform grid cells it can be classified as cellular decomposition method the boustrophedon cellular decomposition is one of the grid based coverage method it was developed based on classical exact cellular decomposition target region was broken down into cells such that the robot can cover each cell with back and forth boustrophedon motions choset 2000 a line segment is swept through the environment whenever there is a change in connectivity of the slice a new cell is formed choset et al 2000 once a robot covers each cell it has completed the coverage mission the boustrophedon decomposition has a fewer number of cells than the trapezoidal decomposition the boustrophedon decomposition is a particular case of morse decomposition morse based cellular decomposition determined critical points by a morse function it can be used to accomplish different tasks by altering the morse function enric galceran et al summarized the features of coverage path planning methods including classical exact cellular decomposition methods morse based cellular decomposition methods and other popular coverage path planning methods galceran and carreras 2013b classical exact cellular decomposition guarantees complete coverage for a known polygonal environment morse based cellular decomposition method allows generation of different coverage patterns acar et al proposed complete coverage path planning method based on exact cellular decomposition in terms of critical points acar et al 2003 the results were verified by performing experiments in unstructured indoor environments cabreira et al revised some coverage algorithms proposed to deal with irregular shaped areas cabreira et al 2019b and addressed grid based solutions considering full and partial information about the workspace cabreira et al 2019a alia ghaddar and ahmad merei proposed a grid based algorithm to scan an area for reducing completion time and energy consumption ghaddar and merei 2019 optimal coverage method is superior to the cellular decomposition method and the grid based coverage method l shade is an extension of the basic differential evolution das and suganthan 2010 it attracts attentions as its excellent performance recent years the method and its variants have become the winners of recent ieee competitions in evolutionary computation piotrowski 2018 zamuda and sosa presents an application of l shade to an expert system for underwater glider path planning ugpp this new application of evolutionary algorithms to ugpp contributes significantly to the capacity of the decision makers zamuda and sosa 2019 although l shade has been applied to auv path planning there is no literature mentioning its application in the coverage mission of irregular region the coverage mission of irregular region involves the decomposition of region and the coverage of sub regions this problem is more complicated than the general path planning we proposed an improved task planner based on l shade to make coverage in irregular region be solved efficiently the optimized control parameters of l shade were obtained from simulation experiments the implementation flow chart of l shade is shown as fig 1 the process of l shade is as follows 1 mutation process set a is defined to store the eliminated individuals in the selection process and initialize them to be empty define arrays mf and mcr to store the mutation factors and crossover factors which performed well in the past generations their sizes are mf mcr h h is the control parameter of l shade algorithm and the value in the array is initialized to 0 5 f is defined as the mutation factor cr is the crossover factor the integer r is randomly selected from 1 to h the method to calculate mutation factor and crossover factor of the ith individual in g generation is 1 f i g mf r 0 1 tan rand π π 2 2 cr i g 0 mcr r 1 n o r m r n d mcr r 0 1 o t h e r w i s e where rand is a number sampled from the uniform distribution 0 1 and normrnd denotes the function that generates a number sampled from the normal distribution if the value of f i g exceeds the interval 0 1 f i g 0 5 then the fitness value of each individual in the population is calculated and the individual x r 1 g with the highest fitness is selected islam et al 2011 and then two different basis vectors x r 2 g and x r 3 g are randomly selected from the union of two sets the set of the remaining p individuals with the highest fitness and the set a to perform mutation operations 3 v i g x i g f i g x r 1 g x i g f i g x r 2 g x r 3 g 2 crossover process the crossover process refers to the crossover transformation of elements between the original individual and the mutated individual in the population if x i g j is the jth element of the ith individual in g generation population j 1 m 1 the crossover process is carried out according to the following rules 4 u i g j v i g j r a n d cr i g x i g j o t h e r w i s e where v i g j is the jth element of the ith mutation individual in g generation population u i g j is the crossover result of crossing the jth element of the ith individual and the ith mutation individual in g generation population u obtained after crossover should be within the range of feasible solution 3 selection process comparing between the results of the crossover process and the original population the individuals with high fitness are retained as the next generation population and the individuals with low fitness are eliminated and the eliminated individuals are stored in set a the formula is as follows 5 x i g 1 x i g f u i g f x i g u i g o t h e r w i s e 4 parameter updating process in the g generation population the initial set sf and scr are empty if the new individuals obtained after mutation crossover are successfully selected the mutation factors f i g and crossover factor cr i g of the individuals are stored in the set sf and scr respectively sf scr sf and scr are used to update mf and mcr assuming that k is the index of mf and mcr the following conditions are satisfied 6 k mod g h mod g h 0 h o t h e r w i s e where mod is modulo function represents the remainder of g h the parameters are updated according to the following rules 7 mf k l 1 sf w l sf l 2 l 1 sf w l sf l 8 mcr k l 1 scr w l scr l 2 l 1 scr w l scr l 9 w l δ f l α 1 scr δ f α 10 δ f l f u l g f x l g assuming the population size of generation g is np g the rule of linear population size reduction is as follows 11 np g 1 round np 0 np 0 min np max g g where round is an integral function min np is the smallest population size max g is the largest population iteration times and g is the current population iteration time the np g 1 individuals with the highest fitness in the g generation population are retained to form the g 1 generation population and the rest are stored in set a 3 cmir control architecture the main idea is to define related layers and components fig 2 overviews the layers and components of cmir control architecture it consists of four significant layers the perception layer the reactive layer the decision making layer and the execution layer the function of perception layer is to collect its own status and environmental information so as to find the threat caused by faults or obstacles in time the reactive layer receives evaluation information and estimates the behavior to response the decision making layer decompose the irregular region plans task orders coordinates the conflicting modules and decides what response to make the execution layer is responsible for receiving and analyzing instructions from decision making layer to control the speed course and attitude of auv 3 1 the perception layer the state of vehicle and data from surroundings which are obtained through sensors must be considered to improve the situation awareness therefore the perception layer is one of the most critical required factors for control architecture and it is conducive to promoting the capability of dealing with unforeseen events the sensors in perception layer is shown in fig 3 it perceives the environment through the auv s own structure or sensors the hardware includes battery doppler velocity log dvl multi beam sonar and side scan sonar the important modules of perception layer are energy position velocity obstacle and target perception the residual energy is obtained by monitoring the battery voltage its position and velocity are measured by dvl multi beam sonar is used to measure obstacle information and side scan sonar is used to explore environment and target the attitude of the vehicle is estimated with an attitude heading reference system ahrs after the perception information is obtained it is transmitted to the reaction layer 3 2 the reactive layer the reactive layer has four components of logical structure mission task and behavior components the internal structure and logical relationship of reactive layer are shown in fig 4 mission component is a message received by auv which contains the vertexes of irregular region task component refers to the phase of mission that auv is responsible for the goal of a task is to cover a sub region which is obtained by decomposing the irregular region multiple sub regions constitute the task sequence behavior is a sequence of actions to be executed to ensure that auv can reach a path point safely as the basic component of reaction layer behavior cannot be subdivided it usually includes path planning obstacle avoidance navigation calibration communication emergency floating and sensor control mission task and behavior can be interrupted in the process of execution 3 3 the decision making layer the decision making layer is similar to the deliberate layer in other architectures the components in the decision making layer manage that in the reaction layer the mission manager receives the mission from shore computer or mission component in reactive layer and reasonably decomposes the mission into task sequence the task planner encapsulates some planning algorithms to obtain optimized execution sequence of tasks the behavior arbiter is used to deal with the conflicting behaviors so that the auv complete the task orderly in complex and changeable environments the relationship between the decision making layer and other layers is shown in fig 5 3 3 1 mission manager the mission is to cover a region in the sea mission message is the vertexes of the region in most cases due to the influence of natural environment the shape of the region presents irregular concave polygon the complex shape of the region makes it very difficult to directly plan tasks and paths it is of great significance to use the mission manager in decision making layer to decompose irregular region generally convex region is easier to plan than concave area so the function of mission manager is to decompose concave polygon into several convex polygons we decompose irregular regions based on convex partitioning method wijeweera and kodituwakku 2017 suppose that the set of vertices of the sea area is v v 1 v n take the midpoint of v i 1 and v i 1 which is called vm to connect with v i then take two points from the line respectively near the two endpoints if none of them is in the sea area the angle where v i is located is concave angle where i 2 n 1 if i is equal to 1 v i 1 is v n if i is equal to n v i 1 is v 1 ray intersection method is adapted to determine whether the fixed point is in the sea area make rays from the fixed point to east west north and south four directions if a ray does not intersect the boundary of the sea area or the number of intersections between a ray and the region boundary is even the fixed point is outside the sea area otherwise the point is inside the sea area judging from the first vertex when a concave angle vertex is encountered the edge of the previous position where the concave angle vertex is located is extended the extension line of the edge and the sea area produce an intersection point which divides the whole area into two sub areas repeat this process until all the sub areas cannot be subdivided then the mission area decomposition is completed the mechanism of decomposition in mission manager is provided by algorithm 1 3 3 2 task planner after decomposition the determination of task orders becomes the key process therefore it is necessary to design a task planner to generate optimized task order according to the task objectives and constraints the optimized task orders are similar to the traveling salesman problem but more complex than that because the traveling salesman problem considers optimized order between points optimized order is optimized path however the coverage mission is to traverse an irregular region the task planner not only considers the coverage order between tasks but also selects the starting point of each area only after the starting points are determined can the optimized coverage path be fixed this is an np hard problem and the traditional algorithm consumes a lot of computing resources to get accurate solutions the long time calculation is usually intolerable heuristic intelligent algorithm has been widely accepted because of its excellent computing performance although it is difficult to get the global optimized solution it can obtain the satisfactory optimized solution in a short time success history based adaptive differential evolution algorithm shade including linear population size reduction l shade is a global optimization method with outstanding search performance which can overcome the difficulties of traditional algorithm zamuda and sosa 2019 therefore we design task planner based on l shade the challenge is that no one has applied l shade to coverage of irregular regions the dimension of this problem is higher than that of the traveling salesman problem we propose two levels of optimization to improve task planner the upper level is responsible for optimizing coverage order of sub regions suppose that there are n sub regions sr r 1 r i r n set a storage region number and set ℬ is empty randomly select a number from a and put it into ℬ until a becomes an empty set the sequence i r r a n d 1 r r a n d i r r a n d n in ℬ is a feasible solution also called an individual where r r a n d i is the number taken from a for the i th time it is an element of an individual according to the above method np individuals are generated as the initial population of the first level nf i 1 i np the lower level is responsible for optimizing the selection of paths in sub region each sub region is swept along the long side to generate a coverage path there are four possible cases as shown in fig 6 the main difference is that the starting points of the paths are different the four types of paths are represented by integers 1 to 4 randomly generate integers between 1 to 4 generate n times and finally form a sequence p p r a n d 1 4 1 p r a n d 1 4 i p r a n d 1 4 n where r a n d 1 4 is an integer randomly generated in the interval 1 4 according to this method np sequences are generated to form the population of the second level ns p 1 p np the initial population of the coverage mission is formed by merging the two levels of population n i 1 p 1 i np p np the constraint is that two identical elements in first level cannot appear at the same time in an individual to satisfy this constraint the elements in the mutated and crossed individuals are sorted according to the size and the sequence composed of elements positions is regarded as the new individual the fitness function is constructed with the shortest path as optimization objective the population size decreases linearly with the number of iterations when the population size is reduced to minimum size np e n d the iteration stopped the l shade implementation process is similar to differential evolution poláková 2017 which is divided into four stages mutation process crossover process selection process and parameter updating process the mutation process and the selection of mutation factors are carried out in accordance with the methods described in section 2 2 it is worth noting that the mutated individuals need to meet the requirements of the constraint assuming that the individuals in the first and second level are v f and v s after the treatment of eq 3 the mutated individuals satisfying the constraint need to be transformed as follow 12 v tf sort v f 13 v ts ceil mod v s 4 where v tf and v ts are the mutated individuals satisfying the constraint in the first and second level respectively sort is a function to obtain the arrangement of the elements in v f mod is a function to obtain the remainder after division of v s by 4 ceil is a function to round each element of mod v s 4 to the nearest integer greater than or equal to that element after the crossover operation the same transformation needs to be made the fitness function is established with the shortest total path length 14 f c n d s j 1 n 1 d j i 1 n p i where d s is the distance from the placement to the first sub region d j is the distance between two sub regions p i is the path length of a sub region after iterations the algorithm converges and gets the final population from the population the individual with the highest fitness is selected 3 3 3 behavior arbiter the ocean environment is complex and changeable and auv must make sensitive reactions to external conditions we define the action sequence of these reactions as behavior when multiple behaviors are triggered at the same time the problem of behavior selection and decision making will be faced therefore the behavior arbiter is designed to handle conflicts between behaviors the behavior arbiter evaluates the threat degree of auv based on the rule base and decides to suppress or activate a behavior to remove the threat rule base includes behavior name behavior current state threat degree and triggering events the rule base of behavior arbiter is shown as fig 7 guidance behavior is the default behavior after the task starts it has the lowest threat degree and belongs to the normal state the black stars represent threat degrees in the figure only when the guidance fails or other behaviors end the new target point will be assigned to trigger the new guidance behavior global positioning system gps calibration behavior is triggered by time when auv has been underwater for more than a certain period of time it will float up to the water surface for calibration obstacle avoidance is triggered by the detection of obstacles it can avoid collision between auv and obstacles and ensure navigation safety the floating behavior is triggered when auv software or hardware goes out of order such as guidance program emergency control program emergency navigation emergency communication emergency process death and thruster fault when the voltage of auv is too low or leakage occurs or the position is beyond predetermined depth it will trigger the behavior of throwing load and floating each behavior has two states activation and inhibition the behavior arbiter triggers the behavior according to the threat degree of the event the behavior with more black stars representing the threat degree was activated first while other behaviors were inhibited 3 4 the execution layer the execution layer is at the bottom of the architecture and is generally associated with the actuator the precise execution of command is the foundation of architecture it includes three main components action component velocity component and sensor component the action component controls the rudder of auv to adjust the course and depth the velocity component controls the propeller speed to adjust the navigation speed the sensor component is responsible for opening and closing sensors so that the sensors can work together efficiently the execution results are fed back to the upper layer of the architecture to influence the next decision forming a closed loop in this way 4 simulation results and discussion in order to test the performance of the architecture and obtain optimized control parameters of the improved task planner irregular regions are constructed for simulation 4 1 the optimized parameters of task planner in cmir control architecture we construct a complex irregular region the vertex coordinates is v 1 10 2 10 2 5 3 4 3 8 4 8 4 5 5 5 5 10 6 10 6 20 5 20 5 15 4 15 4 20 3 20 3 15 2 15 2 20 1 20 and the shape of the region is shown in fig 8 a the irregular region was decomposed by the method proposed in mission manager the result is shown in fig 8 b the common method to deal with this type of region is to construct the outer rectangle and then to make global planning in the rectangle the disadvantage of outer rectangle method is that it will increase the area of the mission causing unnecessary extra work the mission manager we designed overcomes these shortcomings by decomposing region and generating task order the parameters of the experiment were set as follows iteration 1000 scanning range 0 1 initial population size 126 minimum population size 4 percentage p 0 11 h 6 the task order and global path obtained by simulation experiment are shown in fig 9 a the blue dot is the auv placement position and the red star is the ending point the gray number represents the task order and the gray arrow indicates the traversal direction the variation of the average path length and the shortest path length is shown in fig 9 b it can be seen that the average path length of the population decreases with the increase of iterations when the number of iterations reaches 150 the minimum path length does not change it shows that the task planner is able to get the expected results but the computing time is as high as 18000 s which is unbearable therefore the number of iterations is set to 150 since other parameters except population size have little influence on the results we analyze the influence of the initial population size on the time consumption the initial population size is set at 126 105 70 49 28 and 14 respectively these numbers are multiples of 7 126 is 18 times of 7 105 is 15 times of 7 in the literature piotrowski 2018 the initial population is set as 18 times of the problem dimensionality the number of sub regions is 7 so we choose the multiple of 7 to test ten experiments are conducted for each parameter to obtain the box diagram of the shortest path length as shown in fig 10 a the mark indicates outlier and the red line in the middle of the box indicates the median of path length the results show that the decrease of the initial population size makes the final path length of task planner larger although the task planner cannot get the optimal solution the optimized solution in acceptable time can be satisfactory the advantage of the decrease of initial population size is that the time consumption is less and the disadvantage is that the path is longer the average path length and average time consumption are shown in table 1 it can be seen that when the initial population size is 28 and 14 computation time is shorter and the path length is not much larger compared with the population size of more than 50 so the most suitable initial population size is 28 in order to analyze the performance of task planner of cmir control architecture we compared the task planner based on l shade in cmir control architecture with the other two task planners based on de and pso the results are shown in fig 10 b the red solid line represents the path length of the task planner based on l shade with different iterations the blue dotted line and the black dotted line represent the path length of the task planner based on de and pso with different iterations respectively it can be seen that under the same number of iterations the path length of the proposed task planner based on l shade is shorter than that of the other two it shows that cmir control architecture is more efficient than architectures based on de and pso in irregular regions 4 2 comparison of different task planners task planner is an important component in decision making layer it can obtain optimized task order and the optimized coverage path we used three types of irregular regions to verify the proposed task planner based on l shade the computational efficiency of the task planner was compared with that of task planner based on de and pso there are three types of irregular regions as shown in fig 11 type 1 type 2 and type 3 contained three four and five sub regions respectively as shown in fig 11 a b and c the scanning range of type 1 was set to 150 and the starting point was set as 0 0 the scanning range of type 2 and type 3 were set to 0 3 the starting point was set as 1 10 the number of iterations was 150 and the initial population size was 20 each type of regions was calculated five times with three kinds of task planners and the box diagram was drawn for comparative analysis the mark indicates outlier and the red line in the middle of the box indicates the median of path length the computing time consumption is shown in fig 12 fig 12 a b and c show the computing time consumption of task planner based on l shade de and pso in type 1 2 and 3 regions respectively it can be seen that the time consumption of task planner based on l shade in three types of regions are much shorter than that based on de and pso the result of path length is shown in fig 13 fig 13 a b and c show the path lengths of task planner based on l shade de and pso in type 1 2 and 3 regions respectively in the region of type 1 the task planner results based on l shade are a straight line which shows that the results of the five times calculation are the same it obtained stable results in the region of type 1 the results of task planner based on de and pso fluctuate in a range in the regions of type 2 and type 3 the results of task planner based on l shade were similar to but more stable than those of task planner based on de and pso through the above results we can conclude that under the condition of getting similar or better results the computing time consumption of task planner based on l shade is lower than the other two kinds of task planners therefore the task planner based on l shade in cmir control architecture is more efficient we compare task planner based on l shade with boustrophedon method in type 1 region four different starting points are selected they are 0 0 0 3000 4500 3000 4500 0 the range of single side scan of sonar is 150 m boustrophedon algorithm decomposes type 1 region into one unit the whole region is swept with force and back motion regardless of the starting point the generated coverage path starts from the left to the right or from the right to the left when the starting point is close to the left end of the path it traverses from left to right when the starting point is close to the right end of the path it traverses from right to left four coverage paths are obtained by boustrophedon method compared with l shade the results are shown in fig 14 the light color histogram represents the length of coverage path obtained by l shade and the dark color histogram represents the length of coverage path obtained by boustrophedon method it can be seen that the length of the four paths obtained by l shade is smaller than boustrophedon method 4 3 simulation of the coverage mission in irregular region a coverage mission is considered with the irregular region of type 1 the mission manager in the decision making layer is called to decompose the region through the mission manager three task areas are obtained including a triangle and two quadrangles the task boundary is clear which makes the path planning easier to achieve and is conducive to monitoring the progress of the task the task planner in the decision making layer is used to obtain the task order and global path as shown in fig 15 the range of single side scan of sonar is 100 m the initial value of mf and mcr is 0 5 and the maximum iteration is 150 the size of the historical success parameter h is 6 the proportional parameter p is 0 11 and the initial position of auv is 0 0 the blue dot is the auv placement position and the red star is the task end point the gray arabic number represents the task order and the gray arrow indicates the traversal direction the red line represents the global path according to the planned global path auv should start from the coordinate origin first traverse the triangle area enter the area from the left bottom of the triangle drive out from the bottom of the right side then explore the quadrilateral area above enter from the bottom of the area drive out from the top and turn to the quadrilateral below to continue the task enter from the upper left side of the lower quadrilateral area and drive out from the lower right side after getting the global path the path points that have not yet reached are tracked by the guiding behavior before the guiding behavior is activated it is necessary to determine whether there are events triggering other behaviors the auv sails in the mission area at a speed of 3 m s assuming that there are three obstacles in the sea area the auv needs to float up every one hour for navigation calibration and an emergency behavior is triggered during navigation which can be corrected after floating according to our proposed architecture the simulation results are shown in fig 16 a the blue dot indicates the starting point and the red star indicates the end of the mission the dark green broken line represents the sailing path the black line represents the path generated by the calibration behavior and the red line represents the path generated by the floating behavior it can be seen that when there is no triggering event the behavior arbiter selects the guidance behavior to execute when navigating to the 5th 17th and 20th path points the obstacle avoidance behavior is triggered the guiding behavior is inhibited the obstacle avoidance behavior is activated to generate path points for avoiding obstacles at the end of obstacle avoidance it continues to switch to the guiding behavior to track the global path points when the navigation reaches the 15th 23rd and 31st path points the underwater time is longer than one hour the calibration behavior is triggered to generate path points for calibration after sailing along the path generated by the calibration behavior auv returns to the path point where calibration behavior is triggered by event to continue the task when sailing to the 32nd point it triggers floating behavior by errors in auv program after correcting the error it returns to the 32nd point until the mission is completed fig 16 b is a top view of the navigation path the gray circles represent the obstacles the black quadrilateral is the path generated by the calibration behavior and the red quadrilateral trajectory is the navigation path generated by the floating behavior it can be seen that the behavior arbitration module of decision making layer reasonably switches the behavior of auv which ensures the navigation safety and operation efficiency of auv 5 sea trial to verify the feasibility of cmir control architecture we use sailfish auv to carry out sea trial in tuandao bay qingdao china the diameter of sailfish auv is 324 mm shown as fig 17 a it is equipped with side scan sonar dvl and other sensors the depth and course are adjusted by rudder and the thrust is provided by propeller fig 17 b shows the sea trial scene after sailfish auv deployment ten points are selected as the vertex of the irregular region in tuandao bay due to the size limitation of tuandao bay we select a smaller irregular region in the bay so the shape is the same as the simulation region but the size is different parameters are modified according to the size of the irregular region the scanning range of the side scan sonar is set as 30 m the obstacle information is received after reaching the second turning point when sailfish auv has been underwater for more than 10 min and arrived next turning point the calibration task is triggered the navigation is carried out at a speed of 2 kn and a depth of 0 5 m the utm coordinates of the vertices are in table 2 the actual navigation route of cmir control architecture in irregular region is shown in fig 18 a the abscissa is utm x and the ordinate is utm y the blue solid line represents the irregular area the line formed by the red hollow dots is the actual navigation route of auv the route starts from the lower left corner of the area fig 18 b shows the 3d actual path of sailfish auv the black dot indicates the starting point of the path the red solid line indicates the auv coverage path and the blue dot indicates the end point of the path since forward looking sonar is not equipped on the auv virtual obstacles are set up we program the obstacle information into the auv when auv reaches the position with obstacle information the obstacle avoidance behavior is triggered the main purpose is to verify whether the behavior can be triggered the obstacle avoidance behavior is carried out between the second turning point and the third turning point as shown in the left dotted black circle in fig 18 a the dotted black circle in the right is the path generated by calibration behavior when sailfish auv was between the seventh and eighth turning points it was underwater for more than 10 min and the next turning point was the eighth turning point therefore when the auv reached the eighth turning point the calibration task was triggered and the calibration behavior was made we constructed a coverage mission in irregular region and used sailfish auv to test in the offshore which proved that the cmir control architecture is feasible in actual marine environment but there are still some shortcomings in the architecture due to the influence of control accuracy and environment auv may deviate from the generated path resulting in crossing the boundary of the irregular region if there is no navigation zone outside the boundary or the boundary is an impermeable wall structure auv will be at risk therefore when selecting irregular region the boundary of the region should be kept away from the no navigation zone and wall structures and there should be buffer zone to provide auv sufficient response time to ensure the safety 6 conclusion a cmir control architecture including an improved task planner based on l shade was presented the architecture consists of perception layer reaction layer decision making layer and execution layer particular attention has been paid to the decision making layer in which mission manager was introduced and task planner was designed to solve coverage problem in irregular regions mission manager was used to decompose irregular regions two levels of optimization were drawn into the improved task planner the upper level of optimization determines the traversal order of sub regions and the lower level determines the sub region coverage path other components of cmir control architecture enhanced the ability of auv to deal with emergencies a complex irregular region with 7 sub regions was constructed for simulation to obtain optimized control parameters of task planner three types of irregular region was used to compare the proposed task planner with task planner based on de and pso the results showed that the improved task planner is more efficient than the other two coverage mission in irregular region with three sub regions was simulated for testing the effectiveness of components in the cmir control architecture sea trial was organized in tuandao bay and sailfish auv completed the coverage of irregular region which showed that the cmir control architecture can be used in the actual marine environment at present the boundary vertices of irregular region are selected manually which may affect the autonomy of auv it is a good choice to generate the boundary of operation region by using map data and image processing method the buffer size between boundary of operation region and the danger zone is also a problem worthy of consideration in the future coral reefs and sand waves are generally distributed in irregular areas therefore cmir control architecture can be applied to the approach observation of objects in irregular regions on the seabed our method is mainly used for the detection of sand waves or coral reefs in flat terrain areas auv usually navigates in a fix deep so the proposed method operates in 2d underwater coverage approaches in 3d has more application scenarios galceran and carreras 2013a galceran et al 2015 in the future we will pay attention to 3d coverage path planning credit authorship contribution statement guanzhong chen methodology software validation formal analysis writing original draft writing review editing yue shen writing review editing supervision nanzhu qu investigation software dianrui wang data curation software bo he resources conceptualization project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is partially supported by the national key research and development program of china project number 2016yfc0301400 part of the codes in matlab for extending the optimization algorithms utilized are provided by qingfu zhang at http dces essex ac uk staff qzhang code and by ryoji tanabe at https sites google com site tanaberyoji home 
20379,in the multi objective optimization discipline mod simultaneous optimization with four or more objectives is referred to as many objective optimization compared with the two objective and three objective optimization many objective optimization brings a series of new challenges such as the deterioration of the global search ability of an optimization algorithm the difficulty of the visualization of pareto solutions and the increase of the computational burden to address these challenges in this study an efficient many objective optimization system was proposed and this system was utilized to improve the aerodynamics of a vista class cruise ship at four crucial wind angles in the process of design optimization a parametric model with eight design variables was selected as the initial ship form the uniform design ud sampling technique was employed to design a group of transformed ship forms the reynolds averaged navier stokes rans solver was used to evaluate the aerodynamics of transformed ship forms and the nearest neighbor mesh nnm interpolation method was utilized for the initialization process of each numerical calculation to reduce the computational cost of a single simulation with the numerical results of all transformed ship forms four aerodynamic surrogate models were established using a combined method based on a particle swarm optimization and a radial basis neural network pso rbfnn to replace large scale numerical simulation in addition the sobol method was introduced to conduct the sensitivity analysis of the design variables a series of mature genetic algorithms gas were applied for the single point two point and four point optimization of the aerodynamics of a cruise ship in sequence additionally the optimal ship form was selected from the pareto solutions of the four point optimization based on the quantitative results of the analytical hierarchy process ahp eventually the dedicated experimental results of the optimized ship form showed that the aerodynamics at the four wind angles were improved together confirming the effectiveness of the many objective optimization system keywords many objective optimization aerodynamic performance vista class cruise ship nearest neighbor mesh interpolation analytical hierarchy process nomenclature l oa length overall of the ship m l pp length between perpendiculars m b breadth of the hull m d draft of the hull m h w height above the waterline m h s height of the superstructure m gt gross tonnage t θ wind angle α exponent of the velocity profile h 0 reference elevation m v 0 wind velocity at reference elevation m s re reynolds number ν kinematic viscosity m2 s f x longitudinal wind force n f y transverse wind force n m z yawing moment n m c x longitudinal wind force coefficient c y transverse wind force coefficient c n yawing moment coefficient ρ air density kg m3 a f frontal projected area m2 a l lateral projected area m2 p pressure n m2 p 0 atmospheric pressure n m2 c p pressure coefficient 1 introduction 1 1 background according to the statistical data from the united nations world tourism organization untwo 2013 tourism has accounted for almost 10 percent of the global gross domestic product and cruise ship travel has become one of the fastest growing tourism sectors in the world cruise line international association 2018 in recent years with the cruise tourism boom the global cruise capacity appears to be in short supply and the quantity of new orders of luxury cruise ships has also been increasing shipowners have expressed interest in improving the fuel economy and navigation safety of luxury cruise ships yet to be built for a generic ship type there is no doubt that the wave load should be regarded as a primary factor affecting these two aspects in order to optimize the wave load on a ship it is an effective way to reconstruct the hull geometry unlike most generic ships a luxury cruise ship has a tall superstructure with a large windward area and the wind load plays an important role in the fuel economy vettor et al 2018 and navigation safety briggs et al 2003 moreover a luxury cruise ship is usually designed to have the ability to sail in global waters so it has to be able to encounter several different wind environments during a voyage as illustrated above it will be of great significance to propose a simultaneous optimization scheme for the aerodynamic performance of a luxury cruise ship in several different wind environments 1 2 aerodynamic optimization in the field of ship engineering to date the study objects of the aerodynamic optimization of a ship are primarily several ship types with large windward areas such as a pure car carrier pcc wood chip carrier wcc oil tanker and container ship the prevailing optimization ideas can be roughly classified as follows the design for the drag reduction appendages the design for the wind assisted propulsions and the design for the ship structures mizutani et al 2014 and he et al 2019 investigated the effects of the cargo handling equipment and the side guards on the aerodynamic performance of a wcc respectively it was found that the application of these two appendages could considerably reduce the wind drag on the wcc the reduction ratio caused by the cargo handling equipment was 10 and that caused by the side guards was up to 40 at the wind angles of less than 40 viola et al 2015 proposed a kind of wing sail to improve the thrust of a kvlcc2m based on inspiration from the 24th american cup the 10 oil savings for a kvlcc2m has been reported additionally it was summarized that the thrust was sensitive to the wing sail aspect ratio a taller wing sail was more efficient than a shorter or larger wing sail similarly lee et al 2016 also attempted to maximize the thrust coefficient of multiple wing sails at an attack angle of 8 and an optimal design framework was used in their work the results showed that 10 17 increases in the thrust were acquired at attack angles of 45 90 and 135 nakashima et al 2009 systematically discussed the drag reduction mechanism of a square corner cut design for a ship s accommodation house and nihei et al 2010 applied a corner cut design to optimize the wind loads on a trimaran pcc he et al 2016 suggested a wind drag reduction method using the interaction effects between a hull and an accommodation house it was concluded that a streamlined accommodation located on foredecks could obviously reduce the wind drag the above investigations provided a great reference for the aerodynamic optimization of a ship but they were not completely combined with the design idea of multi objective optimization having two or three objectives or many objective optimization having four or more objectives in order to achieve many objective optimization fleming et al 2005 ishibuchi 2008 in this study the aerodynamic optimization of a luxury cruise ship was conducted based on the simulation based design sbd technique 1 3 development of the sbd technique in the field of ship engineering the sbd technique is mainly composed of three basic components parametric representation computational fluid dynamics cfd calculation and an optimization algorithm in the past 20 years extensive ship form optimization peri and campana 2003 tahara et al 2008 guo et al 2019 has been completed based on the sbd technique furthermore researchers have made great efforts to improve the sbd technique in order to improve the applicability of the sbd technique to the optimization of complex hull geometry a large number of parametric representations such as the bezier patch peri et al 2001 non uniform rational b spline surface campana et al 2006 shifting method wu et al 2017 free form deformation wang et al 2021 f spline form parameter curves han et al 2012 and self blending method zong et al 2018 have been proposed these techniques are almost enough to meet the requirements of the parametric representation of various complex ship forms in order to improve the optimization efficiency of the sbd technique the surrogate model has been introduced to replace the time consuming cfd calculation the common surrogate models can be roughly divided into three categories the data fitting model feng et al 2018 wang et al 2021 multi fidelity model pellegrini et al 2016 bonfiglio et al 2018 and reduced order model diez et al 2015 2016 to ensure the efficiency of the surrogate models the researchers have also paid sufficient attention to the design of the experiment doe the prevailing doe can be summarized as two categories the domain based method lee et al 2016 and the response based method diez et al 2019 serani et al 2019 yang et al 2020 the response based method can sequentially add sample points based on the feedback information of surrogate models such as the mean square error mse expected improvement ei and uncertainty quantification uq moreover ships usually navigate in several different conditions hence many multi objective optimization algorithms campana et al 2009 tahara et al 2011 kotinis and kulkarni 2012 based on gas and pso have also been widely applied to the two objective and three objective optimization of a ship form deterministic optimization pinto et al 2007 campana et al 2016 and robust optimization diez and peri 2010 jafaryeganeh et al 2020b have also become two popular research directions for the sbd technique in summary the sbd technique has been well developed for the multi objective optimization of a ship form however these efforts to some extent are insufficient to achieve real world applications with the increasing complexity of engineering projects it is not surprising that handling many objective optimization having four or more objectives has become a definite development trend of the sbd technique campana et al 2006 to the best of our knowledge the many objective optimization of ship form has been rarely reported to date compared with the two objective and three objective optimization many objective optimization has several inherent difficulties firstly the global search ability of most multi objective optimization algorithms would deteriorate in hyperspace so that these algorithms are not applicable for solving many objective optimization problems deb and jain 2014 secondly the intuitive visualization of pareto solutions in hyperspace is impossible resulting in difficulty in the selection of the pareto optimal solution thirdly there is a positive relationship between the number of optimization objectives and the numerical calculation burden the more optimization objectives there are the greater the computational burden is 1 4 state of the art many objective evolutionary algorithms although the research on many objective optimization problems has not been paid adequate attention in the field of ship engineering the literature references related to many objective evolutionary algorithms maoeas have been widely reported generally there are six categories of prevailing treatments for many objective optimization problems maops the first category adopts enhanced modified pareto dominance strategies to promote the convergence ikeda et al 2001 first suggested a relaxed α dominance to compare the dominance relationship between individuals following that laumanns et al 2002 proposed another relaxed ε dominance relation and a ε moea algorithm was put forward by deb et al 2005 the experimental results showed that ε moea had good performance in solving maops in addition a cdas algorithm control the dominance area of solutions was proposed by sato et al 2007 by changing the parameter s defined by users cdas could expand or compress the dominant area of individuals yuan et al 2016a designed a θ dea algorithm in which a new dominance strategy θ dominance was defined the experimental results demonstrated that the θ dominance strategy performed well in balancing convergence and diversity other representative pareto dominance strategies include fuzzy dominance farina and amato 2004 l optimality zou et al 2008 grid dominance yang et al 2013 and the knee point driven strategy zhang et al 2015 the second category is diversity enhancement based algorithms adra and fleming 2011 integrated a diversity maintenance mechanism called dm1 into a fast nondominant sorting genetic algorithm ii nsga ii dm1 could dynamically decide whether to activate diversity maintenance operations according to the distribution of individuals the experimental results of the twenty objective optimization problem indicated that the convergence and the distribution of a pareto set obtained with nsga ii dm1 were better than those obtained with nsga ii li et al 2014 proposed a shift based density estimation sde method the test results for the dtlz and tsp cases showed that sde could effectively balance the convergence and the diversity additionally a reference point based non dominated sorting many objective optimization algorithm nsgaiii deb and jain 2014 employed a series of reference vectors as the niche preservation operator the solutions close to these reference vectors were selected wang et al 2015 designed a two arch2 algorithm for which an lp norm based diversity maintenance scheme was utilized the experimental results showed that two arch2 could deal with twenty objective optimization problems with satisfactory convergence diversity and complexity the third category is called decomposition based algorithms which decompose a complex maop into a series of simple optimization sub problems and then cope with all of the sub problems in a cooperative way zhang and li 2007 first proposed a decomposition based multi objective evolutionary algorithm moea d over the past ten years a large number of research studies on the improvement of moea d have been reported liu et al 2014 presented a new approach that decomposed a maop into a group of simple multi objective optimization subproblems called m2m li et al 2015 suggested a moea dd algorithm by combining the pareto dominance with decomposition strategies cheng et al 2016 proposed a many objective evolutionary algorithm based on the reference vector rvea gu and cheung 2017 integrated a self organizing map som based weight design into moea d and m2m the experimental results showed the superiority of moea d som and m2m som in solving maops with incomplete pareto fronts other prevailing improvement strategies also include the distance based updating strategy yuan et al 2016b and the decomposition based sorting and angle based selection strategy cai et al 2016 the fourth category is known as performance indicator based algorithms for which the search process of an algorithm is guided by some performance metrics such as the hypervolume hv inverted generational distance igd and the coefficient of determination r2 zitzler and künzli 2004 proposed an indicator based evolutionary algorithm ibea for which an hv indicator and an additional binary ε indicator were employed together bader and zitzler 2011 suggested a fast hypervolume based algorithm hype for which a monte carlo simulation was used to estimate the hypervolume to reduce the time complexity presented an r2 indicator based multi objective evolutionary algorithm r2 moea for which the r2 indicator was integrated into the non dominated sorting program recently sun et al 2018 proposed an igd indicator based many objective evolutionary algorithm maoea igd the experimental results proved that maoea igd was fairly competitive in solving maops the fifth category is objective reduction based algorithms these algorithms are primarily used to solve maops with some redundant objectives to some extent they can simplify the process of solving maops by reducing the dimension of the objective space brockhoff and zitzler 2009 employed an ε dominance strategy to evaluate the conflictive degree among objectives thereby achieving the reduction of the objective dimension saxena et al 2013 proposed a principal component analysis based algorithm l pca for the dimensional reduction of linear objectives and a principal component analysis and maximum variance unfolding based algorithm nl mvu pca for the dimensional reduction of non linear objectives however it should be noted that when the reduced objective space still has a very high dimension these algorithms fail to tackle the maops fundamentally the sixth category is termed the preference based algorithms it has been known that the above five categories of maoeas have strong abilities to obtain well converged and distributed pareto fronts for solving maops however in engineering applications decision makers dms care more about how to get a satisfactory solution or a small solution set to guide the actual production the preference based algorithms are dedicated to approach a subset or a single solution of the pareto front based on a dm s preference according to the time when a preference is integrated into the optimization process the preference based algorithms can be divided into three types 1 priori preference based algorithms for this type of algorithm the dm s preference is set up before optimization then the defined preference information guides the individuals toward a subset of the pareto front qiu et al 2012 suggested a bipolar preferences dominance based maoea for which a positive pole and a negative pole are defined by the dm s preference then the dm s preference guides the individuals to gradually approach the positive pole and keep away from the negative pole during the optimization process kim et al 2012 designed an algorithm by combining a multi objective quantum inspired evolutionary algorithm mqea with a preference based selection strategy ps for which λ fuzzy evaluation was employed to quantify the preference degrees of a dm for each objective before optimization the experimental results showed that mqea ps had good performance in solving the seven objective dtlz case 2 interactive preference based algorithms this type of algorithm requires dms to progressively give their preferences to guide the search directions of different stages deb and kumar 2007 proposed a reference direction based nsgaii algorithm rd nsgaii for which the dm was allowed to give a reference direction in each iteration to find a group of representative solutions then based on a utility function a single solution was selected for further analysis rd ngsaii was not terminated until this single solution was no longer optimized gong et al 2013 designed an interactive evolutionary algorithm iea in which the strategy of a preference polyhedron was first proposed the iea periodically sent the non dominated solution set to the dm and then the dm selected the preference solution to construct the preference polyhedron 3 posteriori preference based algorithms in this type of algorithm the dm does not participate in decision making until the final non dominated solution set is obtained the algorithm designed by li and liu 2012 employs a marginal utility function to quantify the dm s preferred regions for each objective and the algorithm ensures that the optimal solution set obtained with further searching is included in the preferred regions schütze et al 2020 developed a global and local exploration tool called the pareto explorer pe for which the treatments for maops included two phases in the first phase the pareto set was obtained with a global search algorithm that ideally included the dm s preference in the second phase the pareto landscape was further searched along the dm s preference direction as stated by schütze et al 2020 a pe is similar to an interactive algorithm in fact it can also be seen as a posteriori preference based algorithm next a pe was also employed to achieve the seven objective design of the plastic injection molding process alvarado iniesta et al 2019 which proved its effectiveness additionally researchers jafaryeganeh et al 2020a 2020b applied multi criteria decision making mcdm methods to design the weight vectors of optimization objectives and then selected the final design scheme from a previously obtained pareto front in mcdm methods such as the weight sum method wsm the technique for order preferences by similarity to an ideal solution topsis and the elimination et choice translating reality electre the weight vectors are mostly obtained based on the dm s preference it is rare that the entropy weight method ewm shannon 1948 can give the weight vectors of the optimization problem according to merely the distribution of the pareto set but this method still has several limitations firstly a large scale pareto set is needed to reduce the uncertainty of the weight vectors obtained with the ewm secondly when several optimization objectives have a similar distribution the ewm will be invalid thirdly if many zero values are included in the pareto set the standardization result of the ewm will be prone to distortion apart from the above six categories of maoeas some researchers have also focused on how to solve maops with large scale design variables for example ma et al 2016 suggested a decision variable analysis based moea known as moea dva for solving multi objective optimization problems with large scale decision variables moea dva can divide decision variables into three types diversity related variables convergence related variables and variables related to both diversity and convergence then three types of variables are separately optimized by different schemes the experimental results have showed that moea dva performs well for solving two and three objective large scale optimization problems next based on moea dva zhang et al 2016 proposed a lmoea algorithm to deal with maops with large scale decision variables the experimental results for maops with 5000 variables demonstrated the superiority of lmoea in solving maops with large scale decision variables 1 5 related work in our previous study wang et al 2021 the authors proposed a many objective optimization system to conduct the hydrodynamic optimization of a deep sea aquaculture vessel at four different conditions and obtained satisfactory optimization results to better address the difficulties brought by many objective optimization in this study an improved many objective optimization system was established to achieve the aerodynamic optimization of a vista class cruise ship at four crucial wind angles the improvements between the present and previous many objective optimization systems were reflected in two aspects firstly the nnm interpolation was proposed for the initialization process of cfd calculation of all transformed ship forms to reduce the computational cost of a single simulation and improve the computational robustness secondly the ahp algorithm was introduced to aid the selection of the optimal solution based on the existing information of the pareto solutions and the researchers preferences the whole optimization design process of the luxury cruise ship is described as follows firstly a steady rans solver was applied to calculate the aerodynamics of the parent ship at the wind angles from 0 to 360 and the calculated results were compared with the wind tunnel test data to verify the accuracy of the numerical method then the ud sampling technique was employed to design a group of transformed ship forms and the rans solver was used to evaluate the aerodynamics of all transformed ship forms the nnm interpolation was utilized for the initialization process of each numerical calculation to reduce the computational cost of a single simulation with the numerical results of all transformed ship forms four aerodynamic surrogate models were established based on the pso rbfnn method and the prediction accuracy of the surrogate models was evaluated using the leave one out loo cross validation in addition the sobol method was introduced to conduct the sensitivity analysis of the design variables a genetic algorithm ga a fast nondominant sorting genetic algorithm ii nsgaii and a reference point based many objective evolutionary algorithm nsgaiii were applied for the single point two point and four point optimization of the aerodynamics of a cruise ship respectively a hypervolume hv indicator was used to measure the quality of the pareto solutions of the two point and four point optimization finally the optimal ship form was selected from the pareto solutions of the four point optimization based on the quantitative results of the ahp algorithm additionally the improved performance of the optimal ship form was confirmed through a dedicated experimental campaign 2 model test 2 1 parent ship the experimental results of the parent ship model were obtained from the authors prior work wang et al 2020 a vista class cruise ship with detailed geometric features including the lifeboats radar radomes waterslides masts and handrails was selected as the parent ship since the aerodynamic performance of the cruise ship was expected to be improved only the superstructure and the hull above the waterline were modeled the scale ratio of the ship model was 1 270 and the geometric tolerance was 1 mm the ship model is displayed in fig 1 and its principal parameters are listed in table 1 2 2 test devices the wind tunnel test was conducted in the versatile wind tunnel at shanghai jiao tong university sjtu as shown in fig 2 different wind angles θ could be obtained by adjusting the rotation angle of the turntable and several common wind velocity profiles could be simulated by adjusting the height of the ground roughness elements the characteristics of the sjtu wind tunnel are displayed in table 2 when the ship model was in the beam wind the maximum blockage ratio was only 0 79 which demonstrated that this wind tunnel test could avoid the blockage effect asce standard 2012 a six component balance with the limit bias of 0 05 was used to measure the wind force components on the ship model the pitot tubes and an electronic pressure gauge with the limit bias of 0 01 were utilized to capture the wind velocity profile these measuring instruments are exhibited in fig 3 2 3 test conditions in a real atmospheric boundary layer the wind velocity v h at different elevations h above the ocean is generally expressed as v h v 0 h h 0 α where α is the exponent of the velocity profile and v 0 is the wind velocity at the reference elevation h 0 which is usually assumed to be 10 m at full scale the corresponding reynolds number re at different elevations above the ocean is defined as re h v h l pp ν where ν is the kinematic viscosity of the air in this wind tunnel test the reference elevation at the model scale was set to 0 037 m due to the 1 270 scale of the ship model and a typical wind velocity profile α 0 125 was simulated the wind velocity profile and the reynolds number profile above the turntable see fig 2 are shown in fig 4 a prior investigation wang et al 2020 proved that the re used in this model test exceeded the critical reynolds number range of the parent ship model 2 4 test results all of the model tests were completed at the wind angles from 0 to 360 at 15 intervals at which the longitudinal wind force f x transverse wind force f y and yawing moment m z were measured according to the ittc s guidelines international towing tank conference 2017 three wind force components were defined as shown in fig 5 the center point o of the co rotational coordinate system was derived from the intersection of the longitudinal mid section transverse mid section and waterplane of the cruise ship due to the strict symmetry of the cruise ship the data measured on the port and starboard sides were averaged as the experimental results moreover to intuitively compare the aerodynamic performance of all of the transformed ship forms the experimental results are presented in dimensionless forms as shown in fig 6 the longitudinal wind force coefficient c x transverse wind force coefficient c y and yawing moment coefficient c n were defined as follows 1 c x f x 1 2 ρ v 0 2 a f c y f y 1 2 ρ v 0 2 a l c n m z 1 2 ρ v 0 2 a l l o a where ρ is the air density v 0 is the wind velocity at the reference elevation a f is the frontal projection area of the superstructure and the hull above the waterline and a l is the lateral projection area of the superstructure and the hull above the waterline for the parent ship model the values of a f and a l are 0 02587 m2 and 0 165 m2 respectively it can be seen from fig 6 that the longitudinal wind force coefficient c x reaches the maximum values at the wind angles of 15 and 165 the transverse wind force coefficient c y reaches the maximum values at the wind angles of 60 and 120 and the yawing moment coefficient c n has the maximum value at the wind angle of 135 in the design stage of a ship the fuel economy and the navigation safety are usually regarded as two crucial aspects in order to make sure that these two aspects of the vista class cruise ship are enhanced together this study chooses to optimize the c x at the wind angles of 0 and 15 the c y at the wind angle of 90 and the c n at the wind angle of 135 the detailed reasons are explained as follows 1 to improve the fuel economy of a ship it is effective to decrease the longitudinal wind resistance coefficient c x according to the general knowledge of ship maneuverability when encountering a strong wind it is generally preferable for a ship to sail against the headwind θ 0 so that the ship is easier to maneuver in some special cases when a ship sails against the headwind its pitch angle can be large resulting in a serious slamming situation at that time it will be necessary to make the ship follow a zigzag track with a small heading angle θ 5 30 to reduce the risk of damage to the hull fig 6 shows that the c x reached a maximum value at the wind angle of 15 hence the c x at the wind angles of 0 and 15 were selected as the optimization objectives together 2 to enhance the navigation safety of a ship the stability is generally considered as a primary concern according to the weather criteria adopted by the imo imo 2008 it is known that sufficient attention should be paid to the dynamic stability of a ship in severe weather conditions especially a beam wind and a beam sea in order to reduce the risk of the ship capsizing this study was focused on the optimization of the transverse wind force coefficient c y in a beam wind θ 90 in addition due to the large superstructure of the cruise ship it was easy to deviate from the original course under the influence of a strong wind to improve the course keeping ability of the cruise ship the yawing moment coefficient c n was expected to be optimized it can be seen from fig 6 that the c n had the maximum value at the wind angle of 135 therefore the c n at the wind angle of 135 was also regarded as one of the optimization objectives 3 numerical simulation 3 1 cfd solver the commercial cfd solver star ccm was used to simulate the flow around the cruise ship by solving the three dimensional steady incompressible continuity equation and the rans equations the rans equations were closed using the realizable k ε turbulence model the pressure velocity coupling equations were solved with the simplec algorithm a second order upwind scheme with high resolution was employed to the convective discretization the cad model used in the numerical simulation was slightly different from that in the wind tunnel test as shown in fig 7 a few small details including the handrails masts and waterslides which were considered to have no significant effect on the calculated wind forces were simplified to ensure the high mesh quality during the numerical simulation 3 2 computational domain and boundary conditions the cross section of the computational domain was consistent with that of the sjtu wind tunnel whose width and height are 6 0 m 3 5 m the length of the domain was 7 5l oa and the distances from the bow to the inlet and from the stern to the outlet were 3 0l oa and 3 5l oa respectively the detailed computational domain and the boundary conditions are depicted in fig 8 the inlet velocity of the computational domain was the same as the velocity profile α 0 125 above the turntable see fig 4 a during the wind tunnel test to keep the velocity profile unchanged as the wind flowed downstream the top and bottom of the computational domain were set as slip walls in addition when the wind angle was 90 the maximum blockage ratio of the numerical simulation was only 0 79 which indicated that the sidewalls of the computational domain had a fairly limited impact on the flow field distribution around the ship model hence the sidewalls were set as symmetry planes to ignore the effect of the boundary layer near the sidewalls the outlet of the computational domain was set as a pressure outlet the hull and the superstructure were set as non slip walls 3 3 mesh generation and resolution analysis the trimmer meshing technique developed by star ccm was utilized to generate the mesh three levels of cylinder control volumes were inserted near the ship to ensure sufficient accuracy of the flow details obtained by the numerical simulation the mesh around several geometric details including the chimney lifeboats radar radomes and balconies was also further refined by dividing the corresponding box control volumes to capture the curved surfaces with high fidelity 144 mesh nodes were distributed on these curved surfaces and the curvature deviation distance was set to 1 0 10 4 m furthermore eight layers of prism layer mesh with a fixed growth rate of 1 05 were generated on the surface of the cruise ship and the dimensionless wall distance y was controlled to within 1 generally speaking the mesh density is usually considered to be a critical factor affecting the calculation accuracy and efficiency it is an essential step for conducting a mesh resolution analysis to determine the suitable mesh density in the following optimization process this study was focused on the optimization of the aerodynamic performances at the wind angles of 0 15 90 and 135 hence the mesh resolution analyses at these four wind angles were carried out by adjusting the surface mesh size taking the length overall of the ship l oa as the base size four sets of meshes were generated based on different surface mesh sizes at a constant refinement ratio of r 2 the total numbers and the calculated results of the four sets of meshes are displayed in table 3 and table 4 respectively as shown in table 4 when the surface mesh size was 0 035l oa the prediction errors at the wind angles of 0 15 90 and 135 were less than 10 even if the surface mesh size continued to be decreased to 0 025l oa the prediction accuracy could not be significantly improved considering the cfd calculation s efficiency and accuracy the third set of meshes was used in the subsequent numerical simulation the details of which are shown in fig 9 3 4 convergence process of numerical simulation fig 10 displays the convergence process of the numerical simulation at the wind angle of 90 in this study the residuals of all cases decreased by 4 5 orders of magnitude and the calculated results could yield satisfactory convergence within 6000 iterations a small oscillation of the calculated results could be observed at several wind angles with massive flow separation in those conditions the data for the last 1000 iterations were averaged as the final numerical results 3 5 validation of numerical simulation the comparison between the wind tunnel test data and the numerical results is shown in fig 11 it can be seen that the numerical results agreed well with the test data the average prediction errors for the c x c y and c n were 10 70 4 66 and 9 59 respectively in addition the prediction errors for the c x at the wind angles of 0 and 15 the c y at the wind angle of 90 and the c n at the wind angle of 135 were 8 70 9 50 7 15 and 4 86 respectively in general the numerical simulation presented satisfactory prediction accuracy for the blunt body flow and it was suitable for the following optimization work 4 key techniques of many objective optimization system in this study a multi disciplinary many objective optimization system which was mainly comprised of the ud sampling technique the nnm interpolation technique the pso rbfnn surrogate model a series of genetic algorithms gas and the ahp algorithm was established the flowchart of this optimization system is displayed in fig 12 4 1 related definitions of multi objective optimization the mathematical model of a multi objective optimization problem can generally be expressed as follows 2 min f x f 1 x f 2 x f m x t s t x d r n where x x 1 x 2 x n t is a n dimensional vector having n design variables f d r m is a m dimensional vector having m objective functions m 4 for a many objective optimization problem f i x is the i th objective function i 1 2 m and d is a n dimensional design domain which can be expressed as follows 3 d g i x 0 i 1 2 k h j x 0 j 1 2 p x l x x u where g i x is the i th inequality constraint h j x is the j th equality constraint x l is the lower bound vector of the design variables and x u is the upper bound vector of the design variables the optimality of a multi objective optimization problem is usually determined based on the following definitions srinivas and deb 1994 definition 1 pareto dominance letting there be two design vector x y ε d if 4 f i x f i y i 1 2 m f j x f j y j 1 2 m then x is called non dominated by y x y definition 2 pareto optimal solution a design vector x is called pareto optimal if there is no x ε d such that x x definition 3 pareto set a set composed of all pareto optimal solutions is called a pareto set ps which is defined as follows p s x x d x x definition 4 pareto font the imagine of ps is called the pareto front pf which is defined as follows p f f x x p s 4 2 uniform design uniform design ud is a kind of space filling design and it was proposed by fang 1980 in essence ud is an application of a quasi monte carlo method in number theory and its aim is to pursue the one dimensional balance of all levels for each design variable and n dimensional uniformity fang et al 2000 compared with other popular space filling design methods such as the optimal latin hypercube design olhs park 1994 ud usually has an obvious advantage in high dimensional experimental design fig 13 shows the comparison of three dimensional experimental design between olhs and ud it can be clearly found from the figure that the experimental points designed by olhs and ud can be filled with the entire design space but the uniformity of the planar projected points designed by ud is better than that designed with olhs moreover wang et al 2021 also utilized the point set deviation theory and principal component analysis wold et al 1987 to systematically compare the ud and olhs the results also demonstrated that ud was superior to the olhs in a nine dimensional experimental design 4 3 nearest neighbor mesh interpolation the nearest neighbor mesh nnm interpolation could generate the flow field information of the new mesh elements by replicating those of the nearest old mesh elements as shown in fig 14 the centroid of the old mesh element i blue color was the closest point to the centroid of the new mesh element j red color hence the data from the old mesh element i was assigned to the new mesh element j as the mapped value it was assumed that the calculation of the flow field around an object had converged the converged flow field information was taken into the initial flow field of another object with a similar shape by utilizing nnm interpolation and then the subsequent numerical calculation was performed finally the computational efficiency of another object with a similar shape was improved to a certain extent the more similarity there was between the shapes of two objects the more obvious the computational efficiency improvement by the nnm interpolation was however it has to be noted that when two shapes were completely different the application of nnm interpolation was meaningless for sbd based ship form optimization an inevitable time consuming task is to perform the numerical calculations for a series of transformed ship forms in fact there are only slight differences in local structures among all transformed ship forms so the generated meshes and the calculated flow field information only have obvious differences in several local zones if the nnm interpolation was used to take the fully convergent flow field details of the no 1 transformed ship form into the initial flow fields of all other transformed ship forms it would undoubtedly improve the efficiency of the whole optimization process 4 4 pso rbfnn surrogate model radial basis function neural network rbfnn is a three layer feedforward neural network moody and darken 1989 that consists of an input layer a hidden layer and an output layer forming a multi input and multi output forward neural network as shown in fig 15 the hidden layer of an rbfnn is the gaussian function the expression for which is as follows 5 y k i 1 m w i k exp x c i 2 2 σ i 2 where m is the number of the nodes in the hidden layer w ik is the weight from the i th node in the hidden layer to the k th node in the output layer c i is the center of the i th hidden node and σ i is the width of the i th hidden node the uncertainty parameters for an rbfnn are w ik c i and σ i poggio and girosi 1990 proved mathematically that assuming the proper parameter selection the rbfnn could approximate any non linear continuous function in the best way the typical training procedure of an rbfnn selects the network parameters by trial and error which involves three steps firstly c i is obtained by utilizing the k means clustering algorithm then σ i is calculated according to k nearest neighbor rule finally w ik is obtained using several simple regressions such as the orthogonal least square method as a stochastic search method the pso algorithm has an excellent global optimization ability and it operates on structural objects without the restriction of continuity and derivative in addition the pso algorithm is easy to implement so it is very suitable for neural network training chen and qian 2009 ye et al 2016 previous work performed by the authors wang et al 2021 has proved that in a nine dimensional design space the pso rbfnn surrogate mode based on a small sample set only 60 cfd samples designed by the ud could achieve a 1 error level and the prediction effect of the pso rbfnn surrogate model was slightly superior to those of the kriging and svr surrogate models hence the pso rbfnn surrogate model was utilized in this optimization process again 4 5 genetic algorithms genetic algorithms gas is a kind of evolutionary algorithm which is originally inspired by some phenomena in evolutionary biology including heredity natural selection hybridization and mutation ga is widely applied to solve single objective optimization problems in computational mathematics to extend the ga to solve a common multi objective optimization deb et al 2002 proposed the nsgaii algorithm for which the strategies of elite reservation and spatial crowding distance were introduced into the ga this reduced the complexity of solving the two objective and three objective optimization problems and it improved the uniformity and convergence of pareto solutions unfortunately with the increasing demand for solving many objective optimization with four or more objectives it was found that nsgaii could not deal with this kind of optimization problems well the reason for this was that the crowding distance operator was ineffective in hyperspace to relieve this situation deb and jain 2014 proposed the nsgaiii algorithm for which the spatial reference point was used as the niche preservation operator instead of the crowing distance this strategy effectively improved the quality of the pareto solutions of nsgaii in solving many objective optimization in this study the ga nsgaii and nsgaiii were employed to cope with single point two point and four point optimization respectively 4 5 1 quality measure of pareto solutions gas search for the optimal solution based on the probability rule rather than the deterministic rule even if the iteration number of gas is sufficiently large the optimization result of each independent run is not the same to ensure the quality of the optimization result an essential step is to compare the optimization results among multiple independent runs and then select the best optimization result from the comparison for single objective optimization the above step is easy to practice the smaller the optimal solution is the higher the quality of the optimization result is for multi objective optimization and many objective optimization the optimization result is not a single optimal solution but rather a pareto solution set at present a popular quality measurement of pareto solutions is the approximated pareto front s hypervolume zitzler and thiele 1999 which is defined as the volume of a hypercube restricted by all non dominated solutions in the pareto front and the reference point set the hypervolume hv is generally used to evaluate the convergence and diversity of pareto solutions cao et al 2015 the greater the hv value is the better the quality of the pareto solutions is 4 6 analytical hierarchy process the analytical hierarchy process ahp is a decision making evaluation method that combines qualitative analysis with quantitative analysis to solve complex problems with multiple criteria the ahp was proposed by professor saaty 1977 this method uses the professional experience of decision makers to judge the relative importance of each criterion and it reasonably gives the weight of each decision making scheme and then evaluates the priority of each scheme based on the weights generally the application of the ahp involves four phases phase 1 establishing a hierarchical structure model the multi criteria decision making problem should be divided into at least three hierarchies the highest hierarchy target hierarchy the middle hierarchy criteria hierarchy and the lowest hierarchy scheme hierarchy as shown in fig 16 the number of criteria hierarchies in the structure model depends on the complexity of the problem phase 2 constructing the comparison matrix a of the criteria hierarchy in the criteria hierarchy the importance of each criterion to the target is different the comparison matrix a of the criteria hierarchy should be constructed based on the principle of pairwise comparison as follows 6 a c 11 c 1 j c i 1 c i j n n where i is the i th criterion j is the j th criterion n is the number of criteria c ij is the relative comparison of the importance between the i th criterion former criterion and the j th criterion latter criterion for which the scale of importance is summarized in table 5 phase 3 checking the consistency of the matrix a the matrix a is constructed based on a principle of pairwise comparison in order to check whether there is a contradiction in the importance ranking among all criteria reflected by matrix a it is necessary to conduct a consistency check for matrix a the entire check process requires two steps 1 calculating the consistency index ci λ max n n 1 where λ max is the largest eigenvalue of matrix a 2 calculating the consistency ratio cr ci ri where ri is the average random consistency index whose empirical value can be seen from table 6 saaty 1987 if cr 0 1 the hierarchical structure model and the matrix a will be acceptable otherwise the structure model should be redesigned and matrix a should be revised phase 4 hierarchical sorting the importance of each criterion in the criteria hierarchy is sorted quantitatively by calculating the weight vector of the matrix a where the weight vector is recommended to be obtained by the eigenvector method specified in eq 7 finally the weight vector w is normalized as the final weight of each criterion the greater the weight of the criterion is the more important the criterion is 7 aw λ max w where λ max is the largest eigenvalue of matrix a and w is the weight vector of matrix a the above content describes a simple hierarchical structure model of the ahp algorithm in fact the hierarchical structure can be expanded to be much more complex the ahp has been successfully applied to various multi criteria decision making fields cheng and mon 1994 yalcin 2008 dede et al 2011 mihi et al 2020 since the pareto solutions of many objective optimization are distributed in a four or higher dimensional space the visualization of pareto solutions is difficult and determining how to select a satisfactory pareto optimal solution has become a deep seated problem this study attempted to address this problem using the ahp algorithm 5 many objective optimization example for a vista class cruise ship 5 1 definition of optimization objectives in this study the longitudinal wind force coefficient c x at the wind angles of 0 and 15 the transverse wind force coefficient c y at the wind angle of 90 and the yawing moment coefficient c n at the wind angle of 135 were taken as the optimization objectives to intuitively reflect the performance change of the transformed ship form four objective functions were defined as follows 8 f o b j 0 c x o p t 0 c x o r g 0 f o b j 15 c x o p t 15 c x o r g 15 f o b j 90 c y o p t 90 c y o r g 90 m o b j 135 c n o p t 135 c n o r g 135 where cx0 org and cx0 opt are the longitudinal wind force coefficients of the parent ship and the transformed ship respectively at the wind angle of 0 cx15 org and cx15 opt are the longitudinal wind force coefficients of the parent ship and the transformed ship respectively at the wind angle of 15 cy90 org and cy90 opt are the transverse wind force coefficients of the parent ship and the transformed ship respectively at the wind angle of 90 c n 135 org and c n 135 opt are the yawing moment coefficients of the parent ship and the transformed ship respectively at the wind angle of 135 5 2 parametric model and constrained conditions the pressure drag is a primary component of the drag on a bluff body the reason for this lies in the occurrence of flow separation and the formation of reversed flow zones around a body it has been known from prior investigation wang et al 2020 that the flow separation around a vista class cruise ship mainly occurs at the side corners of the fore and aft decks and the sharp edges of the top deck in order to suppress the flow separation the side corners of the fore and aft decks and the sharp edge of the top deck were rounded in this study moreover to achieve the streamlined design of the superstructure the stepped open decks see fig 7 at the bow and stern were redesigned as closed curved surfaces the schematic diagram of the redesign ideas is illustrated in fig 17 it can be seen that there were eight design variables which are the angle β 1 between the curved surface at the upper part of the bow and the horizontal plane the angle β 2 between the curved surface at the lower part of the bow and the horizontal plane the angle β 3 between the curved surface at the stern and the horizontal plane the fillet radius r 1 on the both sides of the curved surface at the upper part of bow the fillet radius r 2 on the both sides of the curved surface at the lower part of bow the fillet radius r 3 on the both sides of the curved surface at the stern the fillet radius r 4 on the front sides and both sides of deck13 and deck14 and the fillet radius r 5 on both sides of deck12 a luxury cruise ship needs to provide transportation service and give tourists enjoyment therefore apart from the fuel economy and navigation safety the aesthetics of the exterior shape and the spaciousness of the internal space were also regarded as two additional concerns considering these two aspects the ranges of design variables were determined as shown in table 7 the constrained conditions are summarized as follows 9 β 1 β 2 10 r 1 r 2 8 5 3 numerical calculation of transformed ship forms according to the authors prior experience wang et al 2021 the ud was utilized to design a small sample set containing 64 transformed ship forms labelled no 1 to no 64 within the above constraints the aerodynamics of all of the transformed ship forms was evaluated based on the rans solver for which the numerical method was the same as that used in the calculation of the parent ship to improve the computational efficiency of a series of transformed ship forms the nnm interpolation was applied to the initialization process of the numerical calculation for which involved two steps firstly the flow detail of the no 1 transformed ship form was calculated to be fully convergent and then the convergent flow field details were replicated to the initial flow fields of all other transformed ship forms using the nnm interpolation fig 18 compares the numerical convergence process of the no 1 and no 2 transformed ship forms at the wind angle of 90 the variation ranges of the residuals and the numerical results had less than a 10 4 order of magnitude as the convergence criterion of the numerical calculation it can be clearly observed from fig 18 c and d that the numerical calculation of the no 1 transformed ship form had convergence after 4000 iterations but the numerical calculation of the no 2 transformed ship form only needed 3050 iterations to achieve convergence compared to the calculation efficiency of the no 1 transformed ship form that of the no 2 transformed ship form was improved by 23 75 since the structural difference between other transformed ship forms and the no 1 transformed ship was not the same the improved calculation efficiency of the other transformed ship forms was also not the same the statistics showed that the calculation efficiency of the other transformed ship forms from no 3 to no 64 was improved by 3 35 5 4 accuracy evaluation of surrogate models according to the above cfd sample data four mapping relationships between the design variables and the aerodynamic performance were established using the pso rbfnn surrogate model in order to ensure the high utilization ratio of the samples the leave one out loo cross validation was used to evaluate the prediction accuracy of the surrogate models for which 63 samples were utilized to establish the surrogate models the remaining one was used for the accuracy verification after the cross validation of 64 times the average prediction error of 64 evaluations was taken as the final prediction accuracy of the surrogate models the maximum absolute relative error max rerror the mean absolute relative error mean rerror and the root mean square error rmse were utilized as the evaluation indexes of the prediction accuracy as shown in table 8 it can be seen that the average prediction errors of the four surrogate models were at the 1 error level the maximum prediction errors were at the 2 error level and the root mean square errors had a 10 3 order of magnitude these results demonstrated that the pso rbfnn surrogate models based on 64 samples had enough prediction accuracy therefore it was appropriate to replace the numerical calculation in the subsequent optimization process 5 5 sensitivity analysis based on the pso rbfnn surrogate models the sensitivity analysis of the design variables was conducted with the sobol method sobol 1993 it can be seen from fig 19 that the angle β 1 between the closed curved surface at the upper part of the bow and the horizontal plane was a key design variable for the simultaneous optimization of the c x at the wind angles of 0 and 15 additionally the fillet radius r 4 on deck13 and deck14 as well as the fillet radius r 5 on deck12 had a significant impact on the simultaneous optimization of the c y at the wind angle of 90 and the c n at the wind angle of 135 moreover each design variable had a certain contribution rate for the four optimization objectives and this also reflected the fact that each design variable selected in this study is meaningful 5 6 results of optimization process in this study the ga nsgaii and nsgaiii were employed to conduct the single point two point and four point optimization of the aerodynamics of a cruise ship in sequence since the three genetic algorithms gas were the stochastic optimizers the optimization results after each independent run were not the same therefore the optimization results presented in this study were the best results after 50 independent runs the parameter settings of the gas are summarized in table 9 5 6 1 single point optimization fig 20 displays the best single point optimization results after 50 independent runs for which the c x at the wind angle of 0 was improved by 10 9 the c x at the wind angle of 15 was improved by 8 9 the c y at the wind angle of 90 was improved by 15 1 and the c n at the wind angle of 135 was improved by 11 6 the above results indicated that there were considerable optimization spaces for the four objectives and their optimization spaces were about 10 5 6 2 two point optimization as stated in section 4 5 1 in this study the hv indicator was utilized to measure the quality of the pareto solutions table 10 lists the statistical hv values of six groups of the two point optimization after 50 independent runs it can be found that the standard deviations std of the hv values of the six groups of two point optimization had an order of magnitude of less than 10 3 and the differences between the best and the worst hv values of the six groups of two point optimizations had a 10 3 order of magnitude these results fully proved the stability of the nsgaii algorithm in solving two point optimization dependent on the statistical hv values six groups of the best two point optimization results are presented in fig 21 it can be observed from the figure that there were trade off relationships among the four optimization objectives two groups of optimization with the most significant trade off relationship were f obj 15 and f obj 9 0 f obj 90 and m obj 135 as shown in fig 21 d and f when f obj 15 or m obj 135 was optimized by 1 the optimization space of f obj 90 would be reduced by 2 3 these results indicated that if f obj 15 or m obj 135 was prioritized in selecting the pareto optimal solution the optimization space of f obj 90 would be greatly reduced in contrast if f obj 90 was considered as a priority objective the effect on the optimization spaces of f obj 15 and m obj 135 would be comparatively small 5 6 3 four point optimization table 11 lists the statistical hv values of the four point optimization after 50 independent runs similar to the hv statistical results of the two point optimization described above these results in table 11 were also sufficient to reflect the stability of the nsgaiii algorithm in solving the four point optimization for which the standard deviation of the hv values had a 10 4 order of magnitude when the hv value was maximum the best pareto solutions of four point optimization were displayed in fig 22 for fig 22 a the fourth objective m obj 135 is exhibited by a color bar and the warmer the color is the greater the value m obj 135 is fig 22 b was drawn using the parallel coordinate with the horizontal axis corresponding to the four optimization objectives f obj 0 f obj 15 f obj 90 and m obj 13 labelled dimension no 1 2 3 and 4 and the vertical axis representing the magnitude of the four optimization objectives at present it seems to be an impossible task to intuitively present the distribution of pareto solutions in a four dimensional space this problem also caused great difficulty in the selection of the pareto optimal solution with reference to the successful application of the ahp algorithm in the multi criteria decision making fields in this study the ahp algorithm was introduced to address this problem by combining the existing information for each pareto solution with the authors preference 5 7 selection of the optimal ship form according to the application procedure of the ahp algorithm described in section 4 6 a hierarchical structure model of the aerodynamic optimization of the cruise ship was established as shown in fig 23 the criteria hierarchy was composed of four optimization objectives f obj 0 f obj 15 f obj 90 and m obj 135 in this study the aerodynamic optimization of a cruise ship account for two aspects which were fuel economy and navigation safety the optimization objectives f obj 0 and f obj 15 were used to represent the fuel economy of the cruise ship and the optimization objectives f obj 90 and m obj 135 were used to reflect the navigation safety in order to rank the importance of the four optimization objectives reasonably the authors considered the following points 1 for the fuel economy the f obj 0 was more important than the f obj 15 because a ship usually prefers to sail against a headwind in windy weather f obj 0 f obj 15 2 for the navigation safety the f obj 90 was more important than the m obj 135 because the safety risk of the ship in the beam wind was the highest and the optimization results in section 5 6 2 also reminded that it was reasonable to give priority to the optimization objective f obj 90 f obj 90 m obj 135 3 compared with the fuel economy the navigation safety was obviously a more important concern for ship owners f obj 90 f obj 0 4 on the voyage the ship s yawing moment could be effectively reduced by adjusting the rudder angle however the longitudinal and transverse wind forces on the ship could only be reduced by optimizing the exterior shape hence the m obj 135 could be regarded as the lowest priority among the four optimization objectives based on above analysis the order of importance of the four optimization objectives was summarized as follows f obj 90 f obj 0 f obj 15 m obj 135 then a criteria comparison matrix a was constructed as shown in table 12 where the results of the consistency check of matrix a and the weight vectors obtained with the eigenvector method are also displayed it can be seen that the cr value of matrix a was less than 0 1 which proved that the hierarchical structure model established in this study was acceptable and the constructed matrix a was also reasonable finally the weight vector shown in table 12 was multiplied by the optimized proportion vector of each pareto solution to obtain the value of the evaluation score of each pareto solution additionally the pareto solution with the highest score was selected as the optimal ship form table 13 presents the parameters of the optimal ship form and fig 24 displays the exterior shape of the optimal ship form in which each structural adjustment corresponds to a unique color 5 8 performance evaluation of the optimal ship form 5 8 1 performance comparison based on numerical campaign in order to verify the above optimization results the rans solver was utilized to evaluate the aerodynamics of the optimized ship form at the wind angles of 0 15 90 and 135 for which the numerical method was the same as that used in the calculation of the parent ship fig 25 compares the wind force coefficients between the parent ship form and the optimized ship form it can be seen that the aerodynamic performances of the optimized ship form on four objectives were all improved and their optimized ratios were 5 78 4 32 8 65 and 2 62 respectively the comparison of the flow field details between the parent ship form and the optimized ship form is shown in fig 26 where the velocity vector fields are presented using the line integral convolutions cabral and leedom 1993 it can be observed that the sizes of the reversed flow zones behind the optimized ship s stern were smaller than those behind the parent ship s stern at the wind angles of 0 and 15 when the wind angle was 90 the size of the reversed flow zone at the leeward side of the optimized ship s bow was smaller than that of the parent ship s bow and the distance from the center of the reversed flow zone to the optimized ship was also farther than that to the parent ship in addition at the wind angle of 135 the size of the reversed flow zone in front of the optimized ship s bow was also smaller than that in front of the parent ship s bow fig 27 displays the comparison of the pressure coefficients between the parent ship form and the optimized ship form where the pressure coefficient is defined as follows 10 c p p p 0 1 2 ρ v 0 2 where p is the absolute pressure p 0 is the atmospheric pressure and v 0 is the wind velocity at the reference elevation it can be seen that the pressure coefficients on many stern areas of the optimized ship were obviously higher than those of the parent ship at the wind angles of 0 and 15 when the wind angles were 90 and 135 the pressure coefficients on many leeward areas of the optimized ship s midship were also higher than those of the parent ship these flow field details reflected the fact that the streamlined design of the bow and aft decks and the rounded corner design on the deck sides adopted in this study were beneficial for suppressing the flow separation around the cruise ship and improving the pressure of the ship s leeward side 5 8 2 performance comparison based on experimental campaign in this study the error levels of the numerical calculation were approximately in the range of 5 10 in order to ensure the credibility of the optimization results a dedicated experimental investigation on the optimized ship form was conducted in the sjtu wind tunnel where the experimental conditions were the same as those of the parent ship model fig 28 shows the optimized ship model used in the wind tunnel experiment and fig 29 presents the comparison of the experimental results between the parent ship and the optimized ship except for the c x and c y at the wind angles of 60 and 75 the aerodynamics of the optimized ship were better than that of the parent ship at all the other wind angles for which the average optimized ratios for the c x c y and c n were 6 52 1 96 and 8 83 respectively moreover the optimized ratios for the c x at the wind angles of 0 and 15 the c y at the wind angle of 90 and the c n at the wind angle of 135 were 7 25 4 86 2 48 and 6 59 respectively the above results confirmed the effectiveness of the many objective optimization system proposed in this study 6 conclusions in order to better address the challenges brought by many objective optimization in this study an improved many objective optimization system was established by integrating the ud sampling method the nnm interpolation technique the pso rbfnn surrogate model the sobol sensitivity analysis gas and the ahp algorithm the improvements between the present and previous many objective optimization systems are reflected in two aspects firstly the nnm interpolation method was proposed for the initialization process of the cfd calculation for improving the computational efficiency and robustness secondly the ahp algorithm was introduced to aid the selection of the optimal solution then this optimization system was used to conduct the aerodynamic optimization of a vista class cruise ship at four crucial wind angles the comparison of the experimental results between the optimized ship form and the parent ship form showed a 7 25 reduction in the c x at the wind angle of 0 a 4 86 reduction in the c x at the wind angle of 15 a 2 48 reduction in the c y at the wind angle of 90 and a 6 59 reduction in the c n at the wind angle of 135 for the above work the conclusions are presented as follows 1 when the optimization design was required to make small scale modifications to the parent ship the application of the nnm interpolation greatly reduced the numerical calculation burden of a series of transformed ship forms thereby improving the optimization efficiency of the sbd technique 2 by introducing the hv value as the quality measure of pareto solutions it was found that the ngsaiii algorithm could be well applied to the four point optimization 3 when the visualization of the pareto solutions in hyperspace was difficult the ahp algorithm could aid to the selection of a reasonable optimal solution by combining the existing information of the pareto solutions with the researchers preference 4 the streamlined design on the front and rear of the superstructure and the rounded corner design on the deck sides were beneficial for reducing the sizes of the reversed flow zones around the ship and improving the pressure on the ship s leeward side this study confirmed the effectiveness of the improved many objective optimization system for the four point optimization of a vista class cruise ship future research will focus on the simultaneous optimization of various ship forms under more complex sailing conditions additionally it should be noted that compared with the offline surrogate model pso rbfnn used in this study an online surrogate model contributes more to improving the optimization efficiency of the sbd technique in future work the authors will also focus on the development of online surrogate models credit authorship contribution statement penghui wang conceptualization methodology software writing original draft visualization fei wang validation formal analysis investigation data curation zuogang chen resources writing review editing supervision projection administration funding acquisition yi dai validation investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors appreciate the academic support from the state key laboratory of ocean engineering skloe of shanghai jiao tong university and thank letpub for its linguistic assistance during the preparation of this paper 
20379,in the multi objective optimization discipline mod simultaneous optimization with four or more objectives is referred to as many objective optimization compared with the two objective and three objective optimization many objective optimization brings a series of new challenges such as the deterioration of the global search ability of an optimization algorithm the difficulty of the visualization of pareto solutions and the increase of the computational burden to address these challenges in this study an efficient many objective optimization system was proposed and this system was utilized to improve the aerodynamics of a vista class cruise ship at four crucial wind angles in the process of design optimization a parametric model with eight design variables was selected as the initial ship form the uniform design ud sampling technique was employed to design a group of transformed ship forms the reynolds averaged navier stokes rans solver was used to evaluate the aerodynamics of transformed ship forms and the nearest neighbor mesh nnm interpolation method was utilized for the initialization process of each numerical calculation to reduce the computational cost of a single simulation with the numerical results of all transformed ship forms four aerodynamic surrogate models were established using a combined method based on a particle swarm optimization and a radial basis neural network pso rbfnn to replace large scale numerical simulation in addition the sobol method was introduced to conduct the sensitivity analysis of the design variables a series of mature genetic algorithms gas were applied for the single point two point and four point optimization of the aerodynamics of a cruise ship in sequence additionally the optimal ship form was selected from the pareto solutions of the four point optimization based on the quantitative results of the analytical hierarchy process ahp eventually the dedicated experimental results of the optimized ship form showed that the aerodynamics at the four wind angles were improved together confirming the effectiveness of the many objective optimization system keywords many objective optimization aerodynamic performance vista class cruise ship nearest neighbor mesh interpolation analytical hierarchy process nomenclature l oa length overall of the ship m l pp length between perpendiculars m b breadth of the hull m d draft of the hull m h w height above the waterline m h s height of the superstructure m gt gross tonnage t θ wind angle α exponent of the velocity profile h 0 reference elevation m v 0 wind velocity at reference elevation m s re reynolds number ν kinematic viscosity m2 s f x longitudinal wind force n f y transverse wind force n m z yawing moment n m c x longitudinal wind force coefficient c y transverse wind force coefficient c n yawing moment coefficient ρ air density kg m3 a f frontal projected area m2 a l lateral projected area m2 p pressure n m2 p 0 atmospheric pressure n m2 c p pressure coefficient 1 introduction 1 1 background according to the statistical data from the united nations world tourism organization untwo 2013 tourism has accounted for almost 10 percent of the global gross domestic product and cruise ship travel has become one of the fastest growing tourism sectors in the world cruise line international association 2018 in recent years with the cruise tourism boom the global cruise capacity appears to be in short supply and the quantity of new orders of luxury cruise ships has also been increasing shipowners have expressed interest in improving the fuel economy and navigation safety of luxury cruise ships yet to be built for a generic ship type there is no doubt that the wave load should be regarded as a primary factor affecting these two aspects in order to optimize the wave load on a ship it is an effective way to reconstruct the hull geometry unlike most generic ships a luxury cruise ship has a tall superstructure with a large windward area and the wind load plays an important role in the fuel economy vettor et al 2018 and navigation safety briggs et al 2003 moreover a luxury cruise ship is usually designed to have the ability to sail in global waters so it has to be able to encounter several different wind environments during a voyage as illustrated above it will be of great significance to propose a simultaneous optimization scheme for the aerodynamic performance of a luxury cruise ship in several different wind environments 1 2 aerodynamic optimization in the field of ship engineering to date the study objects of the aerodynamic optimization of a ship are primarily several ship types with large windward areas such as a pure car carrier pcc wood chip carrier wcc oil tanker and container ship the prevailing optimization ideas can be roughly classified as follows the design for the drag reduction appendages the design for the wind assisted propulsions and the design for the ship structures mizutani et al 2014 and he et al 2019 investigated the effects of the cargo handling equipment and the side guards on the aerodynamic performance of a wcc respectively it was found that the application of these two appendages could considerably reduce the wind drag on the wcc the reduction ratio caused by the cargo handling equipment was 10 and that caused by the side guards was up to 40 at the wind angles of less than 40 viola et al 2015 proposed a kind of wing sail to improve the thrust of a kvlcc2m based on inspiration from the 24th american cup the 10 oil savings for a kvlcc2m has been reported additionally it was summarized that the thrust was sensitive to the wing sail aspect ratio a taller wing sail was more efficient than a shorter or larger wing sail similarly lee et al 2016 also attempted to maximize the thrust coefficient of multiple wing sails at an attack angle of 8 and an optimal design framework was used in their work the results showed that 10 17 increases in the thrust were acquired at attack angles of 45 90 and 135 nakashima et al 2009 systematically discussed the drag reduction mechanism of a square corner cut design for a ship s accommodation house and nihei et al 2010 applied a corner cut design to optimize the wind loads on a trimaran pcc he et al 2016 suggested a wind drag reduction method using the interaction effects between a hull and an accommodation house it was concluded that a streamlined accommodation located on foredecks could obviously reduce the wind drag the above investigations provided a great reference for the aerodynamic optimization of a ship but they were not completely combined with the design idea of multi objective optimization having two or three objectives or many objective optimization having four or more objectives in order to achieve many objective optimization fleming et al 2005 ishibuchi 2008 in this study the aerodynamic optimization of a luxury cruise ship was conducted based on the simulation based design sbd technique 1 3 development of the sbd technique in the field of ship engineering the sbd technique is mainly composed of three basic components parametric representation computational fluid dynamics cfd calculation and an optimization algorithm in the past 20 years extensive ship form optimization peri and campana 2003 tahara et al 2008 guo et al 2019 has been completed based on the sbd technique furthermore researchers have made great efforts to improve the sbd technique in order to improve the applicability of the sbd technique to the optimization of complex hull geometry a large number of parametric representations such as the bezier patch peri et al 2001 non uniform rational b spline surface campana et al 2006 shifting method wu et al 2017 free form deformation wang et al 2021 f spline form parameter curves han et al 2012 and self blending method zong et al 2018 have been proposed these techniques are almost enough to meet the requirements of the parametric representation of various complex ship forms in order to improve the optimization efficiency of the sbd technique the surrogate model has been introduced to replace the time consuming cfd calculation the common surrogate models can be roughly divided into three categories the data fitting model feng et al 2018 wang et al 2021 multi fidelity model pellegrini et al 2016 bonfiglio et al 2018 and reduced order model diez et al 2015 2016 to ensure the efficiency of the surrogate models the researchers have also paid sufficient attention to the design of the experiment doe the prevailing doe can be summarized as two categories the domain based method lee et al 2016 and the response based method diez et al 2019 serani et al 2019 yang et al 2020 the response based method can sequentially add sample points based on the feedback information of surrogate models such as the mean square error mse expected improvement ei and uncertainty quantification uq moreover ships usually navigate in several different conditions hence many multi objective optimization algorithms campana et al 2009 tahara et al 2011 kotinis and kulkarni 2012 based on gas and pso have also been widely applied to the two objective and three objective optimization of a ship form deterministic optimization pinto et al 2007 campana et al 2016 and robust optimization diez and peri 2010 jafaryeganeh et al 2020b have also become two popular research directions for the sbd technique in summary the sbd technique has been well developed for the multi objective optimization of a ship form however these efforts to some extent are insufficient to achieve real world applications with the increasing complexity of engineering projects it is not surprising that handling many objective optimization having four or more objectives has become a definite development trend of the sbd technique campana et al 2006 to the best of our knowledge the many objective optimization of ship form has been rarely reported to date compared with the two objective and three objective optimization many objective optimization has several inherent difficulties firstly the global search ability of most multi objective optimization algorithms would deteriorate in hyperspace so that these algorithms are not applicable for solving many objective optimization problems deb and jain 2014 secondly the intuitive visualization of pareto solutions in hyperspace is impossible resulting in difficulty in the selection of the pareto optimal solution thirdly there is a positive relationship between the number of optimization objectives and the numerical calculation burden the more optimization objectives there are the greater the computational burden is 1 4 state of the art many objective evolutionary algorithms although the research on many objective optimization problems has not been paid adequate attention in the field of ship engineering the literature references related to many objective evolutionary algorithms maoeas have been widely reported generally there are six categories of prevailing treatments for many objective optimization problems maops the first category adopts enhanced modified pareto dominance strategies to promote the convergence ikeda et al 2001 first suggested a relaxed α dominance to compare the dominance relationship between individuals following that laumanns et al 2002 proposed another relaxed ε dominance relation and a ε moea algorithm was put forward by deb et al 2005 the experimental results showed that ε moea had good performance in solving maops in addition a cdas algorithm control the dominance area of solutions was proposed by sato et al 2007 by changing the parameter s defined by users cdas could expand or compress the dominant area of individuals yuan et al 2016a designed a θ dea algorithm in which a new dominance strategy θ dominance was defined the experimental results demonstrated that the θ dominance strategy performed well in balancing convergence and diversity other representative pareto dominance strategies include fuzzy dominance farina and amato 2004 l optimality zou et al 2008 grid dominance yang et al 2013 and the knee point driven strategy zhang et al 2015 the second category is diversity enhancement based algorithms adra and fleming 2011 integrated a diversity maintenance mechanism called dm1 into a fast nondominant sorting genetic algorithm ii nsga ii dm1 could dynamically decide whether to activate diversity maintenance operations according to the distribution of individuals the experimental results of the twenty objective optimization problem indicated that the convergence and the distribution of a pareto set obtained with nsga ii dm1 were better than those obtained with nsga ii li et al 2014 proposed a shift based density estimation sde method the test results for the dtlz and tsp cases showed that sde could effectively balance the convergence and the diversity additionally a reference point based non dominated sorting many objective optimization algorithm nsgaiii deb and jain 2014 employed a series of reference vectors as the niche preservation operator the solutions close to these reference vectors were selected wang et al 2015 designed a two arch2 algorithm for which an lp norm based diversity maintenance scheme was utilized the experimental results showed that two arch2 could deal with twenty objective optimization problems with satisfactory convergence diversity and complexity the third category is called decomposition based algorithms which decompose a complex maop into a series of simple optimization sub problems and then cope with all of the sub problems in a cooperative way zhang and li 2007 first proposed a decomposition based multi objective evolutionary algorithm moea d over the past ten years a large number of research studies on the improvement of moea d have been reported liu et al 2014 presented a new approach that decomposed a maop into a group of simple multi objective optimization subproblems called m2m li et al 2015 suggested a moea dd algorithm by combining the pareto dominance with decomposition strategies cheng et al 2016 proposed a many objective evolutionary algorithm based on the reference vector rvea gu and cheung 2017 integrated a self organizing map som based weight design into moea d and m2m the experimental results showed the superiority of moea d som and m2m som in solving maops with incomplete pareto fronts other prevailing improvement strategies also include the distance based updating strategy yuan et al 2016b and the decomposition based sorting and angle based selection strategy cai et al 2016 the fourth category is known as performance indicator based algorithms for which the search process of an algorithm is guided by some performance metrics such as the hypervolume hv inverted generational distance igd and the coefficient of determination r2 zitzler and künzli 2004 proposed an indicator based evolutionary algorithm ibea for which an hv indicator and an additional binary ε indicator were employed together bader and zitzler 2011 suggested a fast hypervolume based algorithm hype for which a monte carlo simulation was used to estimate the hypervolume to reduce the time complexity presented an r2 indicator based multi objective evolutionary algorithm r2 moea for which the r2 indicator was integrated into the non dominated sorting program recently sun et al 2018 proposed an igd indicator based many objective evolutionary algorithm maoea igd the experimental results proved that maoea igd was fairly competitive in solving maops the fifth category is objective reduction based algorithms these algorithms are primarily used to solve maops with some redundant objectives to some extent they can simplify the process of solving maops by reducing the dimension of the objective space brockhoff and zitzler 2009 employed an ε dominance strategy to evaluate the conflictive degree among objectives thereby achieving the reduction of the objective dimension saxena et al 2013 proposed a principal component analysis based algorithm l pca for the dimensional reduction of linear objectives and a principal component analysis and maximum variance unfolding based algorithm nl mvu pca for the dimensional reduction of non linear objectives however it should be noted that when the reduced objective space still has a very high dimension these algorithms fail to tackle the maops fundamentally the sixth category is termed the preference based algorithms it has been known that the above five categories of maoeas have strong abilities to obtain well converged and distributed pareto fronts for solving maops however in engineering applications decision makers dms care more about how to get a satisfactory solution or a small solution set to guide the actual production the preference based algorithms are dedicated to approach a subset or a single solution of the pareto front based on a dm s preference according to the time when a preference is integrated into the optimization process the preference based algorithms can be divided into three types 1 priori preference based algorithms for this type of algorithm the dm s preference is set up before optimization then the defined preference information guides the individuals toward a subset of the pareto front qiu et al 2012 suggested a bipolar preferences dominance based maoea for which a positive pole and a negative pole are defined by the dm s preference then the dm s preference guides the individuals to gradually approach the positive pole and keep away from the negative pole during the optimization process kim et al 2012 designed an algorithm by combining a multi objective quantum inspired evolutionary algorithm mqea with a preference based selection strategy ps for which λ fuzzy evaluation was employed to quantify the preference degrees of a dm for each objective before optimization the experimental results showed that mqea ps had good performance in solving the seven objective dtlz case 2 interactive preference based algorithms this type of algorithm requires dms to progressively give their preferences to guide the search directions of different stages deb and kumar 2007 proposed a reference direction based nsgaii algorithm rd nsgaii for which the dm was allowed to give a reference direction in each iteration to find a group of representative solutions then based on a utility function a single solution was selected for further analysis rd ngsaii was not terminated until this single solution was no longer optimized gong et al 2013 designed an interactive evolutionary algorithm iea in which the strategy of a preference polyhedron was first proposed the iea periodically sent the non dominated solution set to the dm and then the dm selected the preference solution to construct the preference polyhedron 3 posteriori preference based algorithms in this type of algorithm the dm does not participate in decision making until the final non dominated solution set is obtained the algorithm designed by li and liu 2012 employs a marginal utility function to quantify the dm s preferred regions for each objective and the algorithm ensures that the optimal solution set obtained with further searching is included in the preferred regions schütze et al 2020 developed a global and local exploration tool called the pareto explorer pe for which the treatments for maops included two phases in the first phase the pareto set was obtained with a global search algorithm that ideally included the dm s preference in the second phase the pareto landscape was further searched along the dm s preference direction as stated by schütze et al 2020 a pe is similar to an interactive algorithm in fact it can also be seen as a posteriori preference based algorithm next a pe was also employed to achieve the seven objective design of the plastic injection molding process alvarado iniesta et al 2019 which proved its effectiveness additionally researchers jafaryeganeh et al 2020a 2020b applied multi criteria decision making mcdm methods to design the weight vectors of optimization objectives and then selected the final design scheme from a previously obtained pareto front in mcdm methods such as the weight sum method wsm the technique for order preferences by similarity to an ideal solution topsis and the elimination et choice translating reality electre the weight vectors are mostly obtained based on the dm s preference it is rare that the entropy weight method ewm shannon 1948 can give the weight vectors of the optimization problem according to merely the distribution of the pareto set but this method still has several limitations firstly a large scale pareto set is needed to reduce the uncertainty of the weight vectors obtained with the ewm secondly when several optimization objectives have a similar distribution the ewm will be invalid thirdly if many zero values are included in the pareto set the standardization result of the ewm will be prone to distortion apart from the above six categories of maoeas some researchers have also focused on how to solve maops with large scale design variables for example ma et al 2016 suggested a decision variable analysis based moea known as moea dva for solving multi objective optimization problems with large scale decision variables moea dva can divide decision variables into three types diversity related variables convergence related variables and variables related to both diversity and convergence then three types of variables are separately optimized by different schemes the experimental results have showed that moea dva performs well for solving two and three objective large scale optimization problems next based on moea dva zhang et al 2016 proposed a lmoea algorithm to deal with maops with large scale decision variables the experimental results for maops with 5000 variables demonstrated the superiority of lmoea in solving maops with large scale decision variables 1 5 related work in our previous study wang et al 2021 the authors proposed a many objective optimization system to conduct the hydrodynamic optimization of a deep sea aquaculture vessel at four different conditions and obtained satisfactory optimization results to better address the difficulties brought by many objective optimization in this study an improved many objective optimization system was established to achieve the aerodynamic optimization of a vista class cruise ship at four crucial wind angles the improvements between the present and previous many objective optimization systems were reflected in two aspects firstly the nnm interpolation was proposed for the initialization process of cfd calculation of all transformed ship forms to reduce the computational cost of a single simulation and improve the computational robustness secondly the ahp algorithm was introduced to aid the selection of the optimal solution based on the existing information of the pareto solutions and the researchers preferences the whole optimization design process of the luxury cruise ship is described as follows firstly a steady rans solver was applied to calculate the aerodynamics of the parent ship at the wind angles from 0 to 360 and the calculated results were compared with the wind tunnel test data to verify the accuracy of the numerical method then the ud sampling technique was employed to design a group of transformed ship forms and the rans solver was used to evaluate the aerodynamics of all transformed ship forms the nnm interpolation was utilized for the initialization process of each numerical calculation to reduce the computational cost of a single simulation with the numerical results of all transformed ship forms four aerodynamic surrogate models were established based on the pso rbfnn method and the prediction accuracy of the surrogate models was evaluated using the leave one out loo cross validation in addition the sobol method was introduced to conduct the sensitivity analysis of the design variables a genetic algorithm ga a fast nondominant sorting genetic algorithm ii nsgaii and a reference point based many objective evolutionary algorithm nsgaiii were applied for the single point two point and four point optimization of the aerodynamics of a cruise ship respectively a hypervolume hv indicator was used to measure the quality of the pareto solutions of the two point and four point optimization finally the optimal ship form was selected from the pareto solutions of the four point optimization based on the quantitative results of the ahp algorithm additionally the improved performance of the optimal ship form was confirmed through a dedicated experimental campaign 2 model test 2 1 parent ship the experimental results of the parent ship model were obtained from the authors prior work wang et al 2020 a vista class cruise ship with detailed geometric features including the lifeboats radar radomes waterslides masts and handrails was selected as the parent ship since the aerodynamic performance of the cruise ship was expected to be improved only the superstructure and the hull above the waterline were modeled the scale ratio of the ship model was 1 270 and the geometric tolerance was 1 mm the ship model is displayed in fig 1 and its principal parameters are listed in table 1 2 2 test devices the wind tunnel test was conducted in the versatile wind tunnel at shanghai jiao tong university sjtu as shown in fig 2 different wind angles θ could be obtained by adjusting the rotation angle of the turntable and several common wind velocity profiles could be simulated by adjusting the height of the ground roughness elements the characteristics of the sjtu wind tunnel are displayed in table 2 when the ship model was in the beam wind the maximum blockage ratio was only 0 79 which demonstrated that this wind tunnel test could avoid the blockage effect asce standard 2012 a six component balance with the limit bias of 0 05 was used to measure the wind force components on the ship model the pitot tubes and an electronic pressure gauge with the limit bias of 0 01 were utilized to capture the wind velocity profile these measuring instruments are exhibited in fig 3 2 3 test conditions in a real atmospheric boundary layer the wind velocity v h at different elevations h above the ocean is generally expressed as v h v 0 h h 0 α where α is the exponent of the velocity profile and v 0 is the wind velocity at the reference elevation h 0 which is usually assumed to be 10 m at full scale the corresponding reynolds number re at different elevations above the ocean is defined as re h v h l pp ν where ν is the kinematic viscosity of the air in this wind tunnel test the reference elevation at the model scale was set to 0 037 m due to the 1 270 scale of the ship model and a typical wind velocity profile α 0 125 was simulated the wind velocity profile and the reynolds number profile above the turntable see fig 2 are shown in fig 4 a prior investigation wang et al 2020 proved that the re used in this model test exceeded the critical reynolds number range of the parent ship model 2 4 test results all of the model tests were completed at the wind angles from 0 to 360 at 15 intervals at which the longitudinal wind force f x transverse wind force f y and yawing moment m z were measured according to the ittc s guidelines international towing tank conference 2017 three wind force components were defined as shown in fig 5 the center point o of the co rotational coordinate system was derived from the intersection of the longitudinal mid section transverse mid section and waterplane of the cruise ship due to the strict symmetry of the cruise ship the data measured on the port and starboard sides were averaged as the experimental results moreover to intuitively compare the aerodynamic performance of all of the transformed ship forms the experimental results are presented in dimensionless forms as shown in fig 6 the longitudinal wind force coefficient c x transverse wind force coefficient c y and yawing moment coefficient c n were defined as follows 1 c x f x 1 2 ρ v 0 2 a f c y f y 1 2 ρ v 0 2 a l c n m z 1 2 ρ v 0 2 a l l o a where ρ is the air density v 0 is the wind velocity at the reference elevation a f is the frontal projection area of the superstructure and the hull above the waterline and a l is the lateral projection area of the superstructure and the hull above the waterline for the parent ship model the values of a f and a l are 0 02587 m2 and 0 165 m2 respectively it can be seen from fig 6 that the longitudinal wind force coefficient c x reaches the maximum values at the wind angles of 15 and 165 the transverse wind force coefficient c y reaches the maximum values at the wind angles of 60 and 120 and the yawing moment coefficient c n has the maximum value at the wind angle of 135 in the design stage of a ship the fuel economy and the navigation safety are usually regarded as two crucial aspects in order to make sure that these two aspects of the vista class cruise ship are enhanced together this study chooses to optimize the c x at the wind angles of 0 and 15 the c y at the wind angle of 90 and the c n at the wind angle of 135 the detailed reasons are explained as follows 1 to improve the fuel economy of a ship it is effective to decrease the longitudinal wind resistance coefficient c x according to the general knowledge of ship maneuverability when encountering a strong wind it is generally preferable for a ship to sail against the headwind θ 0 so that the ship is easier to maneuver in some special cases when a ship sails against the headwind its pitch angle can be large resulting in a serious slamming situation at that time it will be necessary to make the ship follow a zigzag track with a small heading angle θ 5 30 to reduce the risk of damage to the hull fig 6 shows that the c x reached a maximum value at the wind angle of 15 hence the c x at the wind angles of 0 and 15 were selected as the optimization objectives together 2 to enhance the navigation safety of a ship the stability is generally considered as a primary concern according to the weather criteria adopted by the imo imo 2008 it is known that sufficient attention should be paid to the dynamic stability of a ship in severe weather conditions especially a beam wind and a beam sea in order to reduce the risk of the ship capsizing this study was focused on the optimization of the transverse wind force coefficient c y in a beam wind θ 90 in addition due to the large superstructure of the cruise ship it was easy to deviate from the original course under the influence of a strong wind to improve the course keeping ability of the cruise ship the yawing moment coefficient c n was expected to be optimized it can be seen from fig 6 that the c n had the maximum value at the wind angle of 135 therefore the c n at the wind angle of 135 was also regarded as one of the optimization objectives 3 numerical simulation 3 1 cfd solver the commercial cfd solver star ccm was used to simulate the flow around the cruise ship by solving the three dimensional steady incompressible continuity equation and the rans equations the rans equations were closed using the realizable k ε turbulence model the pressure velocity coupling equations were solved with the simplec algorithm a second order upwind scheme with high resolution was employed to the convective discretization the cad model used in the numerical simulation was slightly different from that in the wind tunnel test as shown in fig 7 a few small details including the handrails masts and waterslides which were considered to have no significant effect on the calculated wind forces were simplified to ensure the high mesh quality during the numerical simulation 3 2 computational domain and boundary conditions the cross section of the computational domain was consistent with that of the sjtu wind tunnel whose width and height are 6 0 m 3 5 m the length of the domain was 7 5l oa and the distances from the bow to the inlet and from the stern to the outlet were 3 0l oa and 3 5l oa respectively the detailed computational domain and the boundary conditions are depicted in fig 8 the inlet velocity of the computational domain was the same as the velocity profile α 0 125 above the turntable see fig 4 a during the wind tunnel test to keep the velocity profile unchanged as the wind flowed downstream the top and bottom of the computational domain were set as slip walls in addition when the wind angle was 90 the maximum blockage ratio of the numerical simulation was only 0 79 which indicated that the sidewalls of the computational domain had a fairly limited impact on the flow field distribution around the ship model hence the sidewalls were set as symmetry planes to ignore the effect of the boundary layer near the sidewalls the outlet of the computational domain was set as a pressure outlet the hull and the superstructure were set as non slip walls 3 3 mesh generation and resolution analysis the trimmer meshing technique developed by star ccm was utilized to generate the mesh three levels of cylinder control volumes were inserted near the ship to ensure sufficient accuracy of the flow details obtained by the numerical simulation the mesh around several geometric details including the chimney lifeboats radar radomes and balconies was also further refined by dividing the corresponding box control volumes to capture the curved surfaces with high fidelity 144 mesh nodes were distributed on these curved surfaces and the curvature deviation distance was set to 1 0 10 4 m furthermore eight layers of prism layer mesh with a fixed growth rate of 1 05 were generated on the surface of the cruise ship and the dimensionless wall distance y was controlled to within 1 generally speaking the mesh density is usually considered to be a critical factor affecting the calculation accuracy and efficiency it is an essential step for conducting a mesh resolution analysis to determine the suitable mesh density in the following optimization process this study was focused on the optimization of the aerodynamic performances at the wind angles of 0 15 90 and 135 hence the mesh resolution analyses at these four wind angles were carried out by adjusting the surface mesh size taking the length overall of the ship l oa as the base size four sets of meshes were generated based on different surface mesh sizes at a constant refinement ratio of r 2 the total numbers and the calculated results of the four sets of meshes are displayed in table 3 and table 4 respectively as shown in table 4 when the surface mesh size was 0 035l oa the prediction errors at the wind angles of 0 15 90 and 135 were less than 10 even if the surface mesh size continued to be decreased to 0 025l oa the prediction accuracy could not be significantly improved considering the cfd calculation s efficiency and accuracy the third set of meshes was used in the subsequent numerical simulation the details of which are shown in fig 9 3 4 convergence process of numerical simulation fig 10 displays the convergence process of the numerical simulation at the wind angle of 90 in this study the residuals of all cases decreased by 4 5 orders of magnitude and the calculated results could yield satisfactory convergence within 6000 iterations a small oscillation of the calculated results could be observed at several wind angles with massive flow separation in those conditions the data for the last 1000 iterations were averaged as the final numerical results 3 5 validation of numerical simulation the comparison between the wind tunnel test data and the numerical results is shown in fig 11 it can be seen that the numerical results agreed well with the test data the average prediction errors for the c x c y and c n were 10 70 4 66 and 9 59 respectively in addition the prediction errors for the c x at the wind angles of 0 and 15 the c y at the wind angle of 90 and the c n at the wind angle of 135 were 8 70 9 50 7 15 and 4 86 respectively in general the numerical simulation presented satisfactory prediction accuracy for the blunt body flow and it was suitable for the following optimization work 4 key techniques of many objective optimization system in this study a multi disciplinary many objective optimization system which was mainly comprised of the ud sampling technique the nnm interpolation technique the pso rbfnn surrogate model a series of genetic algorithms gas and the ahp algorithm was established the flowchart of this optimization system is displayed in fig 12 4 1 related definitions of multi objective optimization the mathematical model of a multi objective optimization problem can generally be expressed as follows 2 min f x f 1 x f 2 x f m x t s t x d r n where x x 1 x 2 x n t is a n dimensional vector having n design variables f d r m is a m dimensional vector having m objective functions m 4 for a many objective optimization problem f i x is the i th objective function i 1 2 m and d is a n dimensional design domain which can be expressed as follows 3 d g i x 0 i 1 2 k h j x 0 j 1 2 p x l x x u where g i x is the i th inequality constraint h j x is the j th equality constraint x l is the lower bound vector of the design variables and x u is the upper bound vector of the design variables the optimality of a multi objective optimization problem is usually determined based on the following definitions srinivas and deb 1994 definition 1 pareto dominance letting there be two design vector x y ε d if 4 f i x f i y i 1 2 m f j x f j y j 1 2 m then x is called non dominated by y x y definition 2 pareto optimal solution a design vector x is called pareto optimal if there is no x ε d such that x x definition 3 pareto set a set composed of all pareto optimal solutions is called a pareto set ps which is defined as follows p s x x d x x definition 4 pareto font the imagine of ps is called the pareto front pf which is defined as follows p f f x x p s 4 2 uniform design uniform design ud is a kind of space filling design and it was proposed by fang 1980 in essence ud is an application of a quasi monte carlo method in number theory and its aim is to pursue the one dimensional balance of all levels for each design variable and n dimensional uniformity fang et al 2000 compared with other popular space filling design methods such as the optimal latin hypercube design olhs park 1994 ud usually has an obvious advantage in high dimensional experimental design fig 13 shows the comparison of three dimensional experimental design between olhs and ud it can be clearly found from the figure that the experimental points designed by olhs and ud can be filled with the entire design space but the uniformity of the planar projected points designed by ud is better than that designed with olhs moreover wang et al 2021 also utilized the point set deviation theory and principal component analysis wold et al 1987 to systematically compare the ud and olhs the results also demonstrated that ud was superior to the olhs in a nine dimensional experimental design 4 3 nearest neighbor mesh interpolation the nearest neighbor mesh nnm interpolation could generate the flow field information of the new mesh elements by replicating those of the nearest old mesh elements as shown in fig 14 the centroid of the old mesh element i blue color was the closest point to the centroid of the new mesh element j red color hence the data from the old mesh element i was assigned to the new mesh element j as the mapped value it was assumed that the calculation of the flow field around an object had converged the converged flow field information was taken into the initial flow field of another object with a similar shape by utilizing nnm interpolation and then the subsequent numerical calculation was performed finally the computational efficiency of another object with a similar shape was improved to a certain extent the more similarity there was between the shapes of two objects the more obvious the computational efficiency improvement by the nnm interpolation was however it has to be noted that when two shapes were completely different the application of nnm interpolation was meaningless for sbd based ship form optimization an inevitable time consuming task is to perform the numerical calculations for a series of transformed ship forms in fact there are only slight differences in local structures among all transformed ship forms so the generated meshes and the calculated flow field information only have obvious differences in several local zones if the nnm interpolation was used to take the fully convergent flow field details of the no 1 transformed ship form into the initial flow fields of all other transformed ship forms it would undoubtedly improve the efficiency of the whole optimization process 4 4 pso rbfnn surrogate model radial basis function neural network rbfnn is a three layer feedforward neural network moody and darken 1989 that consists of an input layer a hidden layer and an output layer forming a multi input and multi output forward neural network as shown in fig 15 the hidden layer of an rbfnn is the gaussian function the expression for which is as follows 5 y k i 1 m w i k exp x c i 2 2 σ i 2 where m is the number of the nodes in the hidden layer w ik is the weight from the i th node in the hidden layer to the k th node in the output layer c i is the center of the i th hidden node and σ i is the width of the i th hidden node the uncertainty parameters for an rbfnn are w ik c i and σ i poggio and girosi 1990 proved mathematically that assuming the proper parameter selection the rbfnn could approximate any non linear continuous function in the best way the typical training procedure of an rbfnn selects the network parameters by trial and error which involves three steps firstly c i is obtained by utilizing the k means clustering algorithm then σ i is calculated according to k nearest neighbor rule finally w ik is obtained using several simple regressions such as the orthogonal least square method as a stochastic search method the pso algorithm has an excellent global optimization ability and it operates on structural objects without the restriction of continuity and derivative in addition the pso algorithm is easy to implement so it is very suitable for neural network training chen and qian 2009 ye et al 2016 previous work performed by the authors wang et al 2021 has proved that in a nine dimensional design space the pso rbfnn surrogate mode based on a small sample set only 60 cfd samples designed by the ud could achieve a 1 error level and the prediction effect of the pso rbfnn surrogate model was slightly superior to those of the kriging and svr surrogate models hence the pso rbfnn surrogate model was utilized in this optimization process again 4 5 genetic algorithms genetic algorithms gas is a kind of evolutionary algorithm which is originally inspired by some phenomena in evolutionary biology including heredity natural selection hybridization and mutation ga is widely applied to solve single objective optimization problems in computational mathematics to extend the ga to solve a common multi objective optimization deb et al 2002 proposed the nsgaii algorithm for which the strategies of elite reservation and spatial crowding distance were introduced into the ga this reduced the complexity of solving the two objective and three objective optimization problems and it improved the uniformity and convergence of pareto solutions unfortunately with the increasing demand for solving many objective optimization with four or more objectives it was found that nsgaii could not deal with this kind of optimization problems well the reason for this was that the crowding distance operator was ineffective in hyperspace to relieve this situation deb and jain 2014 proposed the nsgaiii algorithm for which the spatial reference point was used as the niche preservation operator instead of the crowing distance this strategy effectively improved the quality of the pareto solutions of nsgaii in solving many objective optimization in this study the ga nsgaii and nsgaiii were employed to cope with single point two point and four point optimization respectively 4 5 1 quality measure of pareto solutions gas search for the optimal solution based on the probability rule rather than the deterministic rule even if the iteration number of gas is sufficiently large the optimization result of each independent run is not the same to ensure the quality of the optimization result an essential step is to compare the optimization results among multiple independent runs and then select the best optimization result from the comparison for single objective optimization the above step is easy to practice the smaller the optimal solution is the higher the quality of the optimization result is for multi objective optimization and many objective optimization the optimization result is not a single optimal solution but rather a pareto solution set at present a popular quality measurement of pareto solutions is the approximated pareto front s hypervolume zitzler and thiele 1999 which is defined as the volume of a hypercube restricted by all non dominated solutions in the pareto front and the reference point set the hypervolume hv is generally used to evaluate the convergence and diversity of pareto solutions cao et al 2015 the greater the hv value is the better the quality of the pareto solutions is 4 6 analytical hierarchy process the analytical hierarchy process ahp is a decision making evaluation method that combines qualitative analysis with quantitative analysis to solve complex problems with multiple criteria the ahp was proposed by professor saaty 1977 this method uses the professional experience of decision makers to judge the relative importance of each criterion and it reasonably gives the weight of each decision making scheme and then evaluates the priority of each scheme based on the weights generally the application of the ahp involves four phases phase 1 establishing a hierarchical structure model the multi criteria decision making problem should be divided into at least three hierarchies the highest hierarchy target hierarchy the middle hierarchy criteria hierarchy and the lowest hierarchy scheme hierarchy as shown in fig 16 the number of criteria hierarchies in the structure model depends on the complexity of the problem phase 2 constructing the comparison matrix a of the criteria hierarchy in the criteria hierarchy the importance of each criterion to the target is different the comparison matrix a of the criteria hierarchy should be constructed based on the principle of pairwise comparison as follows 6 a c 11 c 1 j c i 1 c i j n n where i is the i th criterion j is the j th criterion n is the number of criteria c ij is the relative comparison of the importance between the i th criterion former criterion and the j th criterion latter criterion for which the scale of importance is summarized in table 5 phase 3 checking the consistency of the matrix a the matrix a is constructed based on a principle of pairwise comparison in order to check whether there is a contradiction in the importance ranking among all criteria reflected by matrix a it is necessary to conduct a consistency check for matrix a the entire check process requires two steps 1 calculating the consistency index ci λ max n n 1 where λ max is the largest eigenvalue of matrix a 2 calculating the consistency ratio cr ci ri where ri is the average random consistency index whose empirical value can be seen from table 6 saaty 1987 if cr 0 1 the hierarchical structure model and the matrix a will be acceptable otherwise the structure model should be redesigned and matrix a should be revised phase 4 hierarchical sorting the importance of each criterion in the criteria hierarchy is sorted quantitatively by calculating the weight vector of the matrix a where the weight vector is recommended to be obtained by the eigenvector method specified in eq 7 finally the weight vector w is normalized as the final weight of each criterion the greater the weight of the criterion is the more important the criterion is 7 aw λ max w where λ max is the largest eigenvalue of matrix a and w is the weight vector of matrix a the above content describes a simple hierarchical structure model of the ahp algorithm in fact the hierarchical structure can be expanded to be much more complex the ahp has been successfully applied to various multi criteria decision making fields cheng and mon 1994 yalcin 2008 dede et al 2011 mihi et al 2020 since the pareto solutions of many objective optimization are distributed in a four or higher dimensional space the visualization of pareto solutions is difficult and determining how to select a satisfactory pareto optimal solution has become a deep seated problem this study attempted to address this problem using the ahp algorithm 5 many objective optimization example for a vista class cruise ship 5 1 definition of optimization objectives in this study the longitudinal wind force coefficient c x at the wind angles of 0 and 15 the transverse wind force coefficient c y at the wind angle of 90 and the yawing moment coefficient c n at the wind angle of 135 were taken as the optimization objectives to intuitively reflect the performance change of the transformed ship form four objective functions were defined as follows 8 f o b j 0 c x o p t 0 c x o r g 0 f o b j 15 c x o p t 15 c x o r g 15 f o b j 90 c y o p t 90 c y o r g 90 m o b j 135 c n o p t 135 c n o r g 135 where cx0 org and cx0 opt are the longitudinal wind force coefficients of the parent ship and the transformed ship respectively at the wind angle of 0 cx15 org and cx15 opt are the longitudinal wind force coefficients of the parent ship and the transformed ship respectively at the wind angle of 15 cy90 org and cy90 opt are the transverse wind force coefficients of the parent ship and the transformed ship respectively at the wind angle of 90 c n 135 org and c n 135 opt are the yawing moment coefficients of the parent ship and the transformed ship respectively at the wind angle of 135 5 2 parametric model and constrained conditions the pressure drag is a primary component of the drag on a bluff body the reason for this lies in the occurrence of flow separation and the formation of reversed flow zones around a body it has been known from prior investigation wang et al 2020 that the flow separation around a vista class cruise ship mainly occurs at the side corners of the fore and aft decks and the sharp edges of the top deck in order to suppress the flow separation the side corners of the fore and aft decks and the sharp edge of the top deck were rounded in this study moreover to achieve the streamlined design of the superstructure the stepped open decks see fig 7 at the bow and stern were redesigned as closed curved surfaces the schematic diagram of the redesign ideas is illustrated in fig 17 it can be seen that there were eight design variables which are the angle β 1 between the curved surface at the upper part of the bow and the horizontal plane the angle β 2 between the curved surface at the lower part of the bow and the horizontal plane the angle β 3 between the curved surface at the stern and the horizontal plane the fillet radius r 1 on the both sides of the curved surface at the upper part of bow the fillet radius r 2 on the both sides of the curved surface at the lower part of bow the fillet radius r 3 on the both sides of the curved surface at the stern the fillet radius r 4 on the front sides and both sides of deck13 and deck14 and the fillet radius r 5 on both sides of deck12 a luxury cruise ship needs to provide transportation service and give tourists enjoyment therefore apart from the fuel economy and navigation safety the aesthetics of the exterior shape and the spaciousness of the internal space were also regarded as two additional concerns considering these two aspects the ranges of design variables were determined as shown in table 7 the constrained conditions are summarized as follows 9 β 1 β 2 10 r 1 r 2 8 5 3 numerical calculation of transformed ship forms according to the authors prior experience wang et al 2021 the ud was utilized to design a small sample set containing 64 transformed ship forms labelled no 1 to no 64 within the above constraints the aerodynamics of all of the transformed ship forms was evaluated based on the rans solver for which the numerical method was the same as that used in the calculation of the parent ship to improve the computational efficiency of a series of transformed ship forms the nnm interpolation was applied to the initialization process of the numerical calculation for which involved two steps firstly the flow detail of the no 1 transformed ship form was calculated to be fully convergent and then the convergent flow field details were replicated to the initial flow fields of all other transformed ship forms using the nnm interpolation fig 18 compares the numerical convergence process of the no 1 and no 2 transformed ship forms at the wind angle of 90 the variation ranges of the residuals and the numerical results had less than a 10 4 order of magnitude as the convergence criterion of the numerical calculation it can be clearly observed from fig 18 c and d that the numerical calculation of the no 1 transformed ship form had convergence after 4000 iterations but the numerical calculation of the no 2 transformed ship form only needed 3050 iterations to achieve convergence compared to the calculation efficiency of the no 1 transformed ship form that of the no 2 transformed ship form was improved by 23 75 since the structural difference between other transformed ship forms and the no 1 transformed ship was not the same the improved calculation efficiency of the other transformed ship forms was also not the same the statistics showed that the calculation efficiency of the other transformed ship forms from no 3 to no 64 was improved by 3 35 5 4 accuracy evaluation of surrogate models according to the above cfd sample data four mapping relationships between the design variables and the aerodynamic performance were established using the pso rbfnn surrogate model in order to ensure the high utilization ratio of the samples the leave one out loo cross validation was used to evaluate the prediction accuracy of the surrogate models for which 63 samples were utilized to establish the surrogate models the remaining one was used for the accuracy verification after the cross validation of 64 times the average prediction error of 64 evaluations was taken as the final prediction accuracy of the surrogate models the maximum absolute relative error max rerror the mean absolute relative error mean rerror and the root mean square error rmse were utilized as the evaluation indexes of the prediction accuracy as shown in table 8 it can be seen that the average prediction errors of the four surrogate models were at the 1 error level the maximum prediction errors were at the 2 error level and the root mean square errors had a 10 3 order of magnitude these results demonstrated that the pso rbfnn surrogate models based on 64 samples had enough prediction accuracy therefore it was appropriate to replace the numerical calculation in the subsequent optimization process 5 5 sensitivity analysis based on the pso rbfnn surrogate models the sensitivity analysis of the design variables was conducted with the sobol method sobol 1993 it can be seen from fig 19 that the angle β 1 between the closed curved surface at the upper part of the bow and the horizontal plane was a key design variable for the simultaneous optimization of the c x at the wind angles of 0 and 15 additionally the fillet radius r 4 on deck13 and deck14 as well as the fillet radius r 5 on deck12 had a significant impact on the simultaneous optimization of the c y at the wind angle of 90 and the c n at the wind angle of 135 moreover each design variable had a certain contribution rate for the four optimization objectives and this also reflected the fact that each design variable selected in this study is meaningful 5 6 results of optimization process in this study the ga nsgaii and nsgaiii were employed to conduct the single point two point and four point optimization of the aerodynamics of a cruise ship in sequence since the three genetic algorithms gas were the stochastic optimizers the optimization results after each independent run were not the same therefore the optimization results presented in this study were the best results after 50 independent runs the parameter settings of the gas are summarized in table 9 5 6 1 single point optimization fig 20 displays the best single point optimization results after 50 independent runs for which the c x at the wind angle of 0 was improved by 10 9 the c x at the wind angle of 15 was improved by 8 9 the c y at the wind angle of 90 was improved by 15 1 and the c n at the wind angle of 135 was improved by 11 6 the above results indicated that there were considerable optimization spaces for the four objectives and their optimization spaces were about 10 5 6 2 two point optimization as stated in section 4 5 1 in this study the hv indicator was utilized to measure the quality of the pareto solutions table 10 lists the statistical hv values of six groups of the two point optimization after 50 independent runs it can be found that the standard deviations std of the hv values of the six groups of two point optimization had an order of magnitude of less than 10 3 and the differences between the best and the worst hv values of the six groups of two point optimizations had a 10 3 order of magnitude these results fully proved the stability of the nsgaii algorithm in solving two point optimization dependent on the statistical hv values six groups of the best two point optimization results are presented in fig 21 it can be observed from the figure that there were trade off relationships among the four optimization objectives two groups of optimization with the most significant trade off relationship were f obj 15 and f obj 9 0 f obj 90 and m obj 135 as shown in fig 21 d and f when f obj 15 or m obj 135 was optimized by 1 the optimization space of f obj 90 would be reduced by 2 3 these results indicated that if f obj 15 or m obj 135 was prioritized in selecting the pareto optimal solution the optimization space of f obj 90 would be greatly reduced in contrast if f obj 90 was considered as a priority objective the effect on the optimization spaces of f obj 15 and m obj 135 would be comparatively small 5 6 3 four point optimization table 11 lists the statistical hv values of the four point optimization after 50 independent runs similar to the hv statistical results of the two point optimization described above these results in table 11 were also sufficient to reflect the stability of the nsgaiii algorithm in solving the four point optimization for which the standard deviation of the hv values had a 10 4 order of magnitude when the hv value was maximum the best pareto solutions of four point optimization were displayed in fig 22 for fig 22 a the fourth objective m obj 135 is exhibited by a color bar and the warmer the color is the greater the value m obj 135 is fig 22 b was drawn using the parallel coordinate with the horizontal axis corresponding to the four optimization objectives f obj 0 f obj 15 f obj 90 and m obj 13 labelled dimension no 1 2 3 and 4 and the vertical axis representing the magnitude of the four optimization objectives at present it seems to be an impossible task to intuitively present the distribution of pareto solutions in a four dimensional space this problem also caused great difficulty in the selection of the pareto optimal solution with reference to the successful application of the ahp algorithm in the multi criteria decision making fields in this study the ahp algorithm was introduced to address this problem by combining the existing information for each pareto solution with the authors preference 5 7 selection of the optimal ship form according to the application procedure of the ahp algorithm described in section 4 6 a hierarchical structure model of the aerodynamic optimization of the cruise ship was established as shown in fig 23 the criteria hierarchy was composed of four optimization objectives f obj 0 f obj 15 f obj 90 and m obj 135 in this study the aerodynamic optimization of a cruise ship account for two aspects which were fuel economy and navigation safety the optimization objectives f obj 0 and f obj 15 were used to represent the fuel economy of the cruise ship and the optimization objectives f obj 90 and m obj 135 were used to reflect the navigation safety in order to rank the importance of the four optimization objectives reasonably the authors considered the following points 1 for the fuel economy the f obj 0 was more important than the f obj 15 because a ship usually prefers to sail against a headwind in windy weather f obj 0 f obj 15 2 for the navigation safety the f obj 90 was more important than the m obj 135 because the safety risk of the ship in the beam wind was the highest and the optimization results in section 5 6 2 also reminded that it was reasonable to give priority to the optimization objective f obj 90 f obj 90 m obj 135 3 compared with the fuel economy the navigation safety was obviously a more important concern for ship owners f obj 90 f obj 0 4 on the voyage the ship s yawing moment could be effectively reduced by adjusting the rudder angle however the longitudinal and transverse wind forces on the ship could only be reduced by optimizing the exterior shape hence the m obj 135 could be regarded as the lowest priority among the four optimization objectives based on above analysis the order of importance of the four optimization objectives was summarized as follows f obj 90 f obj 0 f obj 15 m obj 135 then a criteria comparison matrix a was constructed as shown in table 12 where the results of the consistency check of matrix a and the weight vectors obtained with the eigenvector method are also displayed it can be seen that the cr value of matrix a was less than 0 1 which proved that the hierarchical structure model established in this study was acceptable and the constructed matrix a was also reasonable finally the weight vector shown in table 12 was multiplied by the optimized proportion vector of each pareto solution to obtain the value of the evaluation score of each pareto solution additionally the pareto solution with the highest score was selected as the optimal ship form table 13 presents the parameters of the optimal ship form and fig 24 displays the exterior shape of the optimal ship form in which each structural adjustment corresponds to a unique color 5 8 performance evaluation of the optimal ship form 5 8 1 performance comparison based on numerical campaign in order to verify the above optimization results the rans solver was utilized to evaluate the aerodynamics of the optimized ship form at the wind angles of 0 15 90 and 135 for which the numerical method was the same as that used in the calculation of the parent ship fig 25 compares the wind force coefficients between the parent ship form and the optimized ship form it can be seen that the aerodynamic performances of the optimized ship form on four objectives were all improved and their optimized ratios were 5 78 4 32 8 65 and 2 62 respectively the comparison of the flow field details between the parent ship form and the optimized ship form is shown in fig 26 where the velocity vector fields are presented using the line integral convolutions cabral and leedom 1993 it can be observed that the sizes of the reversed flow zones behind the optimized ship s stern were smaller than those behind the parent ship s stern at the wind angles of 0 and 15 when the wind angle was 90 the size of the reversed flow zone at the leeward side of the optimized ship s bow was smaller than that of the parent ship s bow and the distance from the center of the reversed flow zone to the optimized ship was also farther than that to the parent ship in addition at the wind angle of 135 the size of the reversed flow zone in front of the optimized ship s bow was also smaller than that in front of the parent ship s bow fig 27 displays the comparison of the pressure coefficients between the parent ship form and the optimized ship form where the pressure coefficient is defined as follows 10 c p p p 0 1 2 ρ v 0 2 where p is the absolute pressure p 0 is the atmospheric pressure and v 0 is the wind velocity at the reference elevation it can be seen that the pressure coefficients on many stern areas of the optimized ship were obviously higher than those of the parent ship at the wind angles of 0 and 15 when the wind angles were 90 and 135 the pressure coefficients on many leeward areas of the optimized ship s midship were also higher than those of the parent ship these flow field details reflected the fact that the streamlined design of the bow and aft decks and the rounded corner design on the deck sides adopted in this study were beneficial for suppressing the flow separation around the cruise ship and improving the pressure of the ship s leeward side 5 8 2 performance comparison based on experimental campaign in this study the error levels of the numerical calculation were approximately in the range of 5 10 in order to ensure the credibility of the optimization results a dedicated experimental investigation on the optimized ship form was conducted in the sjtu wind tunnel where the experimental conditions were the same as those of the parent ship model fig 28 shows the optimized ship model used in the wind tunnel experiment and fig 29 presents the comparison of the experimental results between the parent ship and the optimized ship except for the c x and c y at the wind angles of 60 and 75 the aerodynamics of the optimized ship were better than that of the parent ship at all the other wind angles for which the average optimized ratios for the c x c y and c n were 6 52 1 96 and 8 83 respectively moreover the optimized ratios for the c x at the wind angles of 0 and 15 the c y at the wind angle of 90 and the c n at the wind angle of 135 were 7 25 4 86 2 48 and 6 59 respectively the above results confirmed the effectiveness of the many objective optimization system proposed in this study 6 conclusions in order to better address the challenges brought by many objective optimization in this study an improved many objective optimization system was established by integrating the ud sampling method the nnm interpolation technique the pso rbfnn surrogate model the sobol sensitivity analysis gas and the ahp algorithm the improvements between the present and previous many objective optimization systems are reflected in two aspects firstly the nnm interpolation method was proposed for the initialization process of the cfd calculation for improving the computational efficiency and robustness secondly the ahp algorithm was introduced to aid the selection of the optimal solution then this optimization system was used to conduct the aerodynamic optimization of a vista class cruise ship at four crucial wind angles the comparison of the experimental results between the optimized ship form and the parent ship form showed a 7 25 reduction in the c x at the wind angle of 0 a 4 86 reduction in the c x at the wind angle of 15 a 2 48 reduction in the c y at the wind angle of 90 and a 6 59 reduction in the c n at the wind angle of 135 for the above work the conclusions are presented as follows 1 when the optimization design was required to make small scale modifications to the parent ship the application of the nnm interpolation greatly reduced the numerical calculation burden of a series of transformed ship forms thereby improving the optimization efficiency of the sbd technique 2 by introducing the hv value as the quality measure of pareto solutions it was found that the ngsaiii algorithm could be well applied to the four point optimization 3 when the visualization of the pareto solutions in hyperspace was difficult the ahp algorithm could aid to the selection of a reasonable optimal solution by combining the existing information of the pareto solutions with the researchers preference 4 the streamlined design on the front and rear of the superstructure and the rounded corner design on the deck sides were beneficial for reducing the sizes of the reversed flow zones around the ship and improving the pressure on the ship s leeward side this study confirmed the effectiveness of the improved many objective optimization system for the four point optimization of a vista class cruise ship future research will focus on the simultaneous optimization of various ship forms under more complex sailing conditions additionally it should be noted that compared with the offline surrogate model pso rbfnn used in this study an online surrogate model contributes more to improving the optimization efficiency of the sbd technique in future work the authors will also focus on the development of online surrogate models credit authorship contribution statement penghui wang conceptualization methodology software writing original draft visualization fei wang validation formal analysis investigation data curation zuogang chen resources writing review editing supervision projection administration funding acquisition yi dai validation investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors appreciate the academic support from the state key laboratory of ocean engineering skloe of shanghai jiao tong university and thank letpub for its linguistic assistance during the preparation of this paper 
