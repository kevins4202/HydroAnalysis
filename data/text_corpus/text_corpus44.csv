index,text
220,the propagation of tides and riverine floodwater in coastal wetlands is controlled by subtle topographic differences and a thick vegetation canopy high resolution numerical models have been used in recent years to simulate fluxes across wetlands however these models are based on sparse field data that can lead to unreliable results here we utilize high spatial resolution rapid repeat interferometric data from the uninhabited aerial vehicle synthetic aperture radar uavsar to provide a synoptic measurement of sub canopy water level change resulting from tide propagation into wetlands these data are used to constrain crucial model parameters and improve the performance and realism of simulations of the wax lake wetlands in coastal louisiana usa a sensitivity analysis shows that the boundary condition of river discharge should be calibrated first followed by iterative correction of terrain elevation specified originally by a digital terrain model derived from lidar measurements the calibration of bed friction becomes important only with the boundary and topography calibrated with the model parameters calibrated the overall nash sutcliffe model efficiency for water level change increases from 0 15 to 0 53 with the rmse reduced by 26 in areas with dense wetland grasses the lidar signal is unable to reach the soil surface but the l band uavsar instrument detects changes in water levels that can be used to infer the true ground elevation the high spatial resolution and repeat acquisition frequency minutes to hours observations provided by uavsar represent a groundbreaking opportunity for a deeper understanding of the complex hydrodynamics of coastal wetlands 1 introduction distributary channels in deltaic systems nourish wetlands with flow sediment and nutrients contributing to marsh elevation gain and resilience to sea level rise redfield 1972 morris et al 2002 fagherazzi et al 2012 fitzgerald and hughes 2019 schuerch et al 2018 field observations and modeling have been devoted to understand interactions of flows and sediment transport between channels tidal flats and wetlands donatelli et al 2020 field data have shown that when tidal and riverine waters propagate from channel to vegetation vegetation increases flow resistance attenuates waves and increases sediment settling reed et al 1999 nepf and vivoni 2000 the presence of vegetation enhances flows within the channels which become the main conveyers of water and sediments to the marsh platform temmerman et al 2005 in the wax lake delta in louisiana usa the channel wetland hydrological connectivity is significant with 23 54 of discharge flowing from adjacent channels into wetlands demanding detailed analyses of wetland hydrodynamics hiatt and passalacqua 2015 these findings imply complex and nonhomogeneous flow pathways within the vegetation despite the importance of collecting hydrodynamic data on the wetland platform expensive in situ measurements with reduced spatial sampling and resolution hamper progress in modeling flow in complex coastal wetlands physics based numerical models explicitly solve hydrodynamics and sediment transport equations to determine sediment budgets and morphological evolution most importantly numerical models can isolate different driving processes and provide reliable predictions under different scenarios of climate change and sea level rise for the wax lake delta numerical model results show that intermediate vegetation height and density are optimal for sediment deposition nardin and edmonds 2014 similarly oliver et al 2020 found that the presence of vegetation could increase vertical accretion within vegetation patches but reduce sediment retention within the entire delta models can also mimic vegetation establishment growth expansion and mortality and update vegetation parameters in each simulated time step interactively best et al 2018 the reliability of model results depends on careful calibration of model input parameters particularly topography and bed roughness and accurate information of boundary conditions that require synchronous spatial field observations often numerical models of wetlands use light detection and ranging lidar data to extract the topography of the vegetated area zhang et al 2020 which could lead to a positive bias in elevations due to the incapability of laser of penetrating into the vegetation canopy this would produce misleading results in marsh models because of the high sensitivity of marsh species and biomass to subtle topographic differences and inundation depths lidar errors vary spatially as a function of vegetation cover and a constant correction in elevation cannot capture this spatial complexity the errors are traditionally categorized by vegetation species and adjusted using point measurements of rtk and total stations lidar topography can be further refined by relating elevation to aboveground biomass density or using machine learning methods medeiros et al 2015 rogers et al 2018 cooper et al 2019 alizad et al 2016 calibrated a lidar digital terrain model dtm of the salt marshes in apalachicola bay florida usa by comparing the biomass distribution obtained from a model to remote sensing data the modeled biomass was calculated based on the empirical function between biomass and inundation depth put forward by morris et al 2002 model calibration is traditionally based on a few of tidal gauges in large channels which cannot capture complex flow dynamics within wetlands the flows on the wetland platform are seldom calibrated due to the challenge of collecting in situ measurements beneath the vegetation canopy alsdorf et al 2007 recent advances in the remote sensing of hydraulic variables e g inundation extent and water level provide an opportunity to fuse high resolution spatial data into numerical models through calibration e g mccabe et al 2017 wiberg et al 2020 the integration of remote sensing data and numerical models was indicated as one of the grand challenges in salt marsh morphodynamics fagherazzi et al 2020 spaceborne interferometry synthetic aperture rader insar has been successfully applied to estimate water level changes in wetlands especially in fluvial systems because the interferometric phase change of repeat pass sar backscattering from emergent flooded vegetation is dominated by the water level change with a high interferometric coherence e g alsdorf et al 2000 yuan et al 2015 oliver cabrera and wdowinski 2016 lee et al 2020 liao et al 2020 based on insar derived water level change jung et al 2012 calibrated manning s bed roughness in a 2 d floodplain model of the atchafalaya river floodplains reducing the mean absolute error to 5 7 cm in a 64 day simulation water levels derived from radar altimetry can be utilized for calibrations of depth and bed roughness in poorly gauged areas sun et al 2012 domeneghetti et al 2014 the application of radar altimetry measurements due to their low accuracy is limited to large channel systems such as the amazon river de paiva et al 2013 however the long temporal repeat of spaceborne insar days to months inhibits observation of tidal flows into wetlands and thus cannot be used to calibrate coastal numerical models airborne systems such as the uninhabited aerial vehicle synthetic aperture radar uavsar can fill this gap providing repeat pass differential interferometry for water level changes within 1 hour time window and with high accuracy e g rosen et al 2006 fore et al 2015 the goal of this paper is to use uavsar derived short timescale water level change to calibrate hydrodynamic models in tidal wetlands and to assess model sensitivity to boundary conditions lidar derived topography and bed roughness to this end we develop a 2 d delft3d hydro model with high spatial resolution 10 m covering the wax lake delta and adjacent wetlands we focus our calibration effort in the western wetland area dissected by meandering channels fig 1 the work presented here introduces a novel approach to integrate airborne insar observations into quantitative models of tidal flow propagation in coastal vegetated surfaces 2 study site the wax lake delta is a river dominated delta located in the atchafalaya bay within the greater mississippi river delta the atchafalaya river distributes water and sediment into atchafalaya bay through the wax lake outlet artificially dredged in 1942 the sediment has in time formed the wax lake delta robert et al 2015 shaw et al 2013 the delta is about 20 km from the calumet gauge usgs 07 381 590 and the width of main channel is 300 m fig 1a the low lying atchafalaya bay is affected by a mixed semidiurnal micro tide with the mean tidal range of 0 34 m the river discharge varies seasonally from 2500 m3 s to more than 5000 m3 s during river floods a portion of discharge is diverted along the engineered gulf intercostal waterway giww that crosses the wax lake outlet swarzenski and perrien 2015 extensive heterogeneous plant communities have developed along the two sides of the main channel a dendritic network of meandering channels departing form the main stem brings water and sediment to these vegetated areas here we focus on wax lake wl channel and hog bayou hb channel in the western side of the main channel fig 1b most research in the wax lake delta focuses on mechanisms controlling the naturally prograding delta itself without considering the role of these large scale wetlands in modulating water and sediment inputs carle et al 2015 oliver et al 2020 3 methods 3 1 uavsar interferometry uavsar is a fully polarimetric quad polarization l band wavelength λ 0 2379 m frequency ν 1 257 ghz synthetic aperture radar operated by the u s national aeronautics and space administration nasa and deployed on a gulfstream 3 aircraft the system is designed for both polarimetry polsar and repeat pass interferometry insar hensley et al 2003 insar processing of repeated observations of a surface from a same viewing geometry enables measurement of surface displacement in the line of sight direction rosen et al 2006 because the instrument is side looking the line of sight displacement is in general a combination of vertical and horizontal displacements relating the measured displacement to a change in surface elevation requires knowledge of the horizontal displacement through either measurement or ancillary information in flooded wetlands the backscattered signal is primarily due to double bounce scattering from the water and vegetation so the measured surface displacement is due to change in water level lu and kwoun 2008 wdowinski et al 2013 liao et al 2019 this study uses repeat pass uavsar data 6 m spatial resolution acquired in hh polarization mode horizontal transmit and receive to measure the net change in water level between 11 34 and 13 53 gmt on 08 may 2015 the measured interferometric phase change δφ is converted to elevation change δz by first phase unwrapping to remove the 2π ambiguities chen and zebker 2002 converting the unwrapped phase δφ to line of sight displacement δl δφλ 4π then projecting the value into the vertical direction δz δl cos θ using the incidence angle θ the errors of surface deformation can be controlled within 1 cm for repeat pass sar observations within hours making it well suited for imaging water level changes in coastal wetlands rosen et al 2006 more details about uavsar derived water level change maps can refer to jones et al 2020 10 3334 ornldaac 1823 3 2 hydrodynamic modeling setup a 2 d hydrodynamic model based on delft3d was developed to solve flow dynamics the model domain is a curvilinear grid of 2600 by 1700 cells with the size ranging from 100 m2 to 150 m2 in the area of wetlands fig 2 b c the model topography is a 10 m seamless dtm composed of lidar datasets http ned usgs gov sonar transects in channels and bathymetry elevations derived from diverse source data referred to the navd88 vertical datum denbina et al 2020 we specify river discharge at the calumet gauge station usgs 07 381 590 u s geological survey 2016 as the upstream boundary and tidal water levels at the noaa amerada pass station noaa 8 764 227 coops 2018 as the ocean boundary fig 2a the hourly wind speed 3 m s and direction measured at this noaa station are uniformly prescribed across the model domain to account for the influence of winds on hydrodynamics bed roughness is defined based on a 10 m sentinel 2 classification map thomas et al 2019 and a look up table for the chezy s coefficient ocean 60 m1 2 s channel water 55 m1 2 s shoals 45 m1 2 s marsh 35 m1 2 s and forest 8 m1 2 s chow 1959 straatsma and baptist 2008 the threshold depth for wetting and drying is set as 0 001 m to keep model stability for very shallow waters the simulation period is from 05 may 2015 at 00 00 to 09 may 2015 at 00 00 and a time step of 0 2 min is adopted to satisfy all stability criteria for the parallel computation the analysis is focused within the western wetland fig 1b in a 2 5 hour window on may 08 from 11 34 to 13 53 when the uavsar data were collected this time window corresponds to spring high tides and river floods thus is optimal for water level observations over the wetlands the nash sutcliffe model efficiency me root mean square error rmse and frequency curve of difference between model m and remote sensing data d are used to evaluate model performance 1 m e 1 d m 2 d d 2 r m s e d m 2 n where n is the number of observations and d is the mean of n values the value of me represents the model performance me 0 65 excellent 0 5 me 0 65 very good 0 2 me 0 5 good and me 0 2 poor allen et al 2007 3 3 calibration and validation of river discharge and wetland elevation the riverine flow from the wax lake outlet debouches seaward crossing the intercostal waterway fig 1a the giww likely modifies the discharge entering the wax lake delta and the lower wetlands as river flows can attenuate tidal propagation reducing temporal variations in water level sassi and hoitink 2013 the river discharge at the model boundary should be adjusted to account for the discharge diverted in the giww no synchronous discharge data from usgs is available along the giww at the period of the uavsar measurements we therefore validate the discharge adjustment based on an empirical calculation using water surface slope data derived from remote sensing the calibration of the model is performed in two steps fig 3 first we calibrate the river discharge to match uavsar data at the wetland margins bordering the wax lake outlet section 3 2 we then spatially modify the wetland topography in each cell if the uavsar change is larger than the model result we decrease the elevation of that cell the model is iteratively re run with the new bathymetry until the elevation correction is negligible and me and rmse are near constant the elevation correction is necessary for two reasons 1 marsh topography derived from lidar data is prone to errors because the laser signal cannot penetrate the thick vegetation resulting in an error see rosso et al 2006 this offset is very high for a wetland that is typically submerged by only few tens of centimeters at high tide precluding water flow in several areas 2 a simple adjustment of local friction would not be able to correct for the error and would lead to unrealistic friction values the correction in elevation proposed here is empirical and based on the assumption that lowering the bed elevation would likely allows for more tidal propagation and for spreading out the water level changes in facts water level changes are affected by flow conveyance one possible way of enhancing the flow conveyance is to increase water depth targeting a larger change in water depth however a change in elevation at one point would reverberate across the system changing the flow conveyance along the entire flow path to address this shortcoming we decided to iteratively change the elevation of a small amount so that the entire system can slowly adjust to the modification in conveyance this method is effective only if the iterative procedure converges and only if the final result is realistic i e the system does not present multiple equilibrium points here for simplicity we chose to modify the elevation by the change in elevation measured by uavsar in 2 5 hr δh 2 5hr this choice was arbitrary and a smaller change in elevation e g change in elevation measured by uavsar in 1 hr would lead to similar results after several iterations finally the sensitivity of the results to the friction coefficient for the marsh and forest surfaces is evaluated we designed 49 scenarios with 7 different friction values chézy coefficient ranging from 8 m1 2 s to 40 m1 2 s for the marsh and forest respectively and launch models with different combinations of frictions before and after the calibration of river discharge and topography the computed river discharge is validated using the empirical manning s equation that estimates flow rate in open channels as a function of water level slope channel cross section and bed friction chow 1959 2 q a c r h 1 2 s 1 2 where q is flow discharge m3 s a is channel cross section m2 c is chézy bed roughness m1 2 s rh is hydraulic radius m s is the water channel slope the manning equation is applied to two cross sections of the wax lake outlet one before the intersection with the giww cross section a a in fig 4 and one after cross section b b in fig 4 3 q 2 q 1 a 2 a 1 c 2 c 1 r h 2 r h 1 1 2 s 2 s 1 1 2 where subscript 1 refers to cross section a a subscript 2 refers to b b we thus obtain the value q2 of the discharge after the giww that can be compared to the calibrated discharge the channel slope in eq 3 is derived from airswot data denbina 2019 airswot is an airborne ka band synthetic aperture radar that measures water surface elevation in open waters with uncertainty below 0 3 cm km the airswot campaign was conducted at 17 14 gmt on 09 may 2015 and more details about the airswot measurements can be found in denbina et al 2021 the comparison allows quantifying the effect of the giww on river discharge the new wetland elevations obtained with our method are validated with high resolution elevation data at 10 long term sites of the coastwide reference monitoring system crms https lacoast gov crms see locations in fig 4 only four of these sites fall within the uavsar footprint and can therefore be used for the validation 4 results 4 1 tidal propagation beneath vegetation canopies observed by uavsar uavsar observed water level changes below vegetation canopies across the model domain in a 2 5 hour time window fig 4 changes in water levels are lower in the wetland interior due to tidal propagation dissipation and reduced hydraulic connectivity the zone with more pronounced flooding large change in water level extends about 8 10 km from the wax lake outlet mainly to wetlands along the channels with a width of 200 300 m at both sides of each channel uavsar cannot measure water level change in unvegetated areas such as ponds and channels fig 4 interestingly the hb channel has a width similar to the upper wl channel but features higher water level variations there is no clear spatial pattern of water level variations in different vegetation covers see figs 1a and 4 4 2 river discharge dominates the amplitude of water level change our model results show that imposing the river discharge measured at calumet in the wl channel underestimates tide induced water level changes along the hb channel the use of the discharge measured at the calumet station as the northern boundary condition gives rise to a uniform flow within the wetlands fed by the wl channel fig 5 a in disagreement with the uavsar observations fig 1b resulting in poor model performance fig 5c by lowering river discharge the tidal signal becomes more important and yields a distribution of water level variations comparable to uavsar observations especially in the hb channel fig 5b d generally we find that a lower river discharge gives better results in the subdomain of the wl channel increases me from 0 33 to 0 51 and reduces the rmse from 1 82 cm to 1 57 cm fig 5e f a reduced river discharge in the wl channel is likely caused by the intracoastal waterway that captures part of the river flow since the rmse is meaningless with negative values of me eqs 1 we used the averaged value of water level changes at the inlet of the hb channel for calibration fig 1b the difference between water level change estimates by the model and the uavsar observations decreases with reduced river discharges fig 5f overall the optimum river discharge initial discharge 1100 m3 s about 20 reduction in river discharge was determined by evaluation of me rmse and regional water level changes a flow diversion of 1100 m3 s in the giww is in accordance with the average discharge of 800 m3 s measured during peak flows by usgs swarzenski and perrien 2015 4 3 iterative modification of lidar derived topography despite the improvement in the magnitude of water level changes at the wetland margin after calibrating the river discharge fig 5 the model does not accurately capture tidal propagation on the wetland platform fig 6 a this is probably caused by errors in the lidar derived topography due to the inability of the laser to penetrate a dense canopy hladik and alber 2012 according to the delta x project datasets https deltax jpl nasa gov the lidar dtm may have biases of 20 cm and rmse of 24 cm in the wax lake delta which can significantly impact reliability of hydrodynamic models of coastal wetlands particularly in microtidal systems alizad et al 2020 instead of correcting the topography using limited rtk gps points we introduce an approach based on the coupling of uavsar observations with model simulations to iteratively correct the model dtm the correction is different at every point in the domain specifically we iteratively change the initial dtm by subtracting the difference between the modeled and uavsar observed water level change after each modification iteration of the dtm the model is re run with the updated dtm until the topography converges to the optimum scenario with tidal propagation and dissipation occurring in the wetland interior the final model results are more realistic and compare well to uavsar observations fig 6a b the improvement is especially evident in the hb subdomain fig 6c and fig 5d the model performance increases after each iteration and the dtm at iteration 7 is chosen as the optimum scenario given insignificant improvements in overall domain me and rmse in later iterations fig 6d overall the water level change me increased from 0 15 to 0 53 after 7 iterations while the rmse decreased from 2 16 cm to 1 60 cm for the wl channel subdomain the me improved from 0 51 to 0 63 with rmse decreasing from 1 57 cm to 1 35 cm for the hb channel subdomain the me improved from 0 52 to 0 22 while the rmse decreased from 3 14 cm to 2 25 cm the lower me value in the hb channel is mainly caused by the spatial resolution of the model which is too low to capture tidal propagation within the small scale creeks at the end of the domain dash red circle in fig 6b ignoring the area near the small scale creeks improves me from 0 22 to 0 38 and rmse from 2 25 cm to 2 03 cm the dtm correction varies in space and is generally larger along the channel margins fig 7 b the change is about 0 1 m in the wl channel but can reach 0 4 m along the hb channel positive value indicates a lowering of the elevation the modified dtm gives a lower elevation in general as expected when the lidar pulses do not reach the ground in the presence of dense vegetation high density marshes in the hb channel may cause the higher bias compared to the forested banks of the wl channel fig 1a after the river discharge calibration and subsequent dtm correction based on uavsar measurements the distribution of the error between model and uavsar is more symmetrical and with the centroid shifting toward zero fig 7c 4 4 sensitivity to bed roughness with initial river discharge and topography the calibration of bed friction for the marsh and forest little improved the model performance in terms of me and rmse tables 1 2 the forest friction dominates the me with less friction larger chézy coefficient in the forest decreasing the overall model performance table 1 the me is weakly related to variations in friction coefficients for instance model results with the friction combination marsh 35 m1 2 s forest 8 m1 2 s display same me and rmse values as the case marsh 35 m1 2 s forest 25 m1 2 s overall a me 0 2 in all simulations indicate a poor model performance allen et al 2007 therefore the calibration in bed frictions is less meaningful without a careful calibration of boundary conditions river discharge and initial conditions topography after modifications of river discharge and topography the model performance improves tables 3 4 it is interesting to note that the model with friction scenario marsh 35 m1 2 s forest 8 m1 2 s performs best achieving the highest me this is probably because we calibrated river discharge and topography with these friction values the modified topography therefore retains information about the friction distribution optimizing the model results the sensitivity analysis table 3 shows the me ranges from 0 38 to 0 53 and rmse from 1 6 cm to 1 85 cm therefore the influence of the friction coefficients on model results increases and becomes important only after calibration of river discharge and dtm elevation to shed more light on the effect of friction we compare two scenarios against the final model calibration by increasing marsh roughness marsh 8 m1 2 s forest 8 m1 2 s and decreasing forest roughness marsh 35 m1 2 s forest 35 m1 2 s fig 8 the watershed of the hb channel is characterized by salt marshes and more friction in the marsh constrains flows in the channel increasing variations in water levels along the channel banks fig 8a with a lower friction in the forest variations in water levels decrease near the wl channel but increase farther away fig 8c both scenarios lower the model performance compared to the initial bed friction scenario fig 8b 4 5 validation of calibrated river discharge and wetland elevations the slope of the water surface calculated by airswot is presented in fig 9 a see also denbina et al 2019 while the two cross sections extracted from bathymetric data before and after the giww are reported in fig 9b the geometric values of the two cross sections are a1 3945 m2 r h1 15 40 m a2 4041m2 r h2 15 49 m the bed roughness is assumed to be constant along the wlo c1 c2 to reduce possible noise in the airswot data we calculate the 300 m averaged slope values s1 4 75 cm km and s2 2 25 cm km and the 500 m averaged slope values s1 4 cm km and s2 2 33 cm km fig 9a see also denbina et al 2019 the corresponding value of q2 q1 is 0 71 for the 300 m slope and 0 78 for the 500 m slope which means that the giww receives 29 and 22 of the total river discharge respectively the calibrated river discharge obtained by reducing of 20 the total discharge at the calumet station is therefore reasonable and well accounts for the flow diversion in the intracoastal waterway we collected ground truth elevation data of all the crms sites n 10 within the model domain and compared them to the topographic data used in the model figs 4 10 the averaged positive error is 12 65 9 18 cm for 10 crms sites with a maximum error of 28 43 cm at crms 4016 therefore ground elevation data indicate a systematic positive error in lidar derived elevations a positive error in the lidar elevation of wetlands is very common and is due to the difficult penetration of the signal in the dense grass canopy see rosen et al 2006 for the 4 sites 0489 4779 4016 0479 within the uavsar area the dtm correction using our method reduces the error from 20 27 cm to 6 82 cm the correction little improves the elevation at crms 4779 fig 10 this is probably due to the very small value of water level change measured by uavsar fig 4 and the complex network of narrow channels not well represented in the modeling mesh despite this our method seems capable of reducing the elevation error at different locations 5 discussion uavsar repeat pass interferometry can detect water level changes beneath vegetation canopies at a time scale of minutes to hours making it possible to capture tidal propagation in coastal wetlands the high spatial resolution observations of water level change provided by this sensor can be used to calibrate hydrodynamic models we developed a high resolution hydrodynamic model and compared its output with the water level changes measured by uavsar over a 2 5 hour period during which tidal flow caused water level change in channels and adjacent wetlands we found that the accuracy of the lidar derived topography and of the river discharge used as a boundary condition are important for the overall model performance whereas the calibration of bed friction becomes regionally important only with boundary conditions and dtm calibrated 5 1 model calibration and measurements uncertainty a calibrated model should reproduce tidal and riverine fluxes at the boundaries because very small errors in water levels amplitude and phase can change flow patterns within the model domain abbott and skovgaard 1978 cunge 2003 pellettier 1987 showed that uncertainty of discharge measurements at river stations could be as high as 20 of the observed value calibration of numerical models of natural river streams e g po river in italy domeneghetti et al 2012 can produce unrealistic manning s coefficients to compensate for the uncertainty of discharge measurements horritt and bates 2002 in our study area potential sources of uncertainty include errors in the river discharge at the northern boundary due to interaction of the wax lake outlet with the giww the disconnection with adjacent wetlands east and west of the model domain and poor spatial information on hydrological connectivity from small scale creeks hiatt and passalacqua 2015 high river floods can attenuate tidal flows leading to small temporal variations in water level sassi and hoitink 2013 van de kreeke and brouwer 2017 as a first step the incoming river flow is calibrated to yield a comparable instantaneous water level change at the wetland margin we found that lowering the river discharge at the boundary does increase variations in water level particularly in lower marshes however the overall model performance as measured by the parameters me and rmse show little improvement fig 5 the hydrodynamic model performance can be significantly improved with a 2 d spatial comparison with measured water level changes during a tidal cycle correcting the dtm using the measured water level change had a much larger impact on model performance it is important to note that the calibration of the wetland dtm and friction coefficient are meaningful only if the correct tidal signal is present at the wetlands margin and at the inlet of the tidal channels a summary of previous studies at different sites show that the averaged lidar elevation error in salt marshes is 18 cm with a standard deviation of 14 cm this error is likely to result in misleading hydrodynamic modeling outcomes alizad et al 2020 buffington et al 2012 in wax lake delta we directly refine the wetland dtm by coupling a hydrodynamic model and uavsar data the model performance in terms of water level changes substantially improves the dtm adjustment the high positive lidar bias 0 4 m in the marsh and the low bias in the forest fig 11 indicates the necessity of dtm adjustment especially for marshes in low lying micro tidal coastal deltas in the forest area site 1 in fig 11 the average dtm elevation is between 0 4 and 0 6 m navd88 datum positive values indicate a higher elevation and the changes in water levels measured by uavsar are small 0 1 m in 2 5hr our topographic calibration increases the elevations of the platform but only slightly less than 0 1 m interestingly the correction yields a more uniform topography reducing the size of patches in the original dtm that are probably caused by tree crowns fig 11e in the marsh area site 2 fig 11 the elevation of the marsh at the channel banks is unrealistically high above 0 8 m likely due to the thick grass canopy that prevents the lidar signal from reaching the ground in the model simulations these areas are unrealistically dry note that the elevations are higher in the marsh than in the forest in the original dtm in disagreement with studies on vegetation patterns in the delta fig 11j morris et al 2005 the topographic error is confirmed by the large change in water level fig 11i that would be impossible in a place with such low water levels the correction proposed by our methodology reduces the elevations by up to 0 4 m fig 11l creating a more uniform and realistic topography fig 11k the correction is more pronounced in the marsh area which is more prone to lidar errors compare fig 11f and l after calibration the marsh site becomes slightly lower than the forest one compare figs 11e and 11 k in agreement with the vegetation zonation of the delta 5 2 limitations of the proposed method sar derived hydraulic variables have already been utilized to calibrate the bed friction of different landscapes on the assumption that errors in boundary conditions and initial topography have little influence on model results for instance the manning s coefficients of the main channel and floodplains of the po river in italy were calibrated with radar altimetry ers 2 and envisat water level data in a 2 d hydraulic model domeneghetti et al 2014 insar water level change data were also used to calibrate the manning s coefficients in a model of the central atchafalaya floodplain jung et al 2012 in our system wetland friction affects the regional water flow but its calibration did not improve the model performance after the correction of river discharge and topography tables 3 4 this might be because the calibration of discharge and topography contains information of bed friction and the initial friction setup can mildly influence the accuracy of the calibration of other parameters note that the friction coefficients used in the sensitivity analysis cover a very large range from 8 to 40 m1 2 s and yet they hardly affect me and rmse tables 1 4 another option would be to keep the wetland elevation constant and change the friction coefficient locally in an iterative way as we did for elevation however this would lead to very large spatial variations in friction which are unrealistic for these homogeneous vegetation covers and friction values very likely outside of the range reported in the literature our results are consistent with previous findings suggesting that friction is an inherent physical parameter therefore a calibration exclusively based on the adjustment of the friction coefficient could produce unrealistic model results cunge 2003 another possible approach would be to lower or elevate the entire topography of a fixed amount to correct for possible vegetation biases in the lidar data and then calibrate the friction coefficient a uniform decrease of 20 cm in elevation would increase the flow on the wetland surface increasing the temporal change in water depth fig s1c but it would concentrate less flow near the channels reducing the change in water depth near the hb channel where uavsar data show high values of water level change on the other hand a uniform increase in elevation would concentrate the flow in the channels fig s1d but it would reduce the flow on the wetland surface with large area completely dry even at high tide we therefore conclude that the wetland elevation needs to be selectively adjusted as a function of local hydrodynamic data this is also evident in fig 11 which shows higher lidar elevations in the marsh with respect to the forest while in reality it should be the opposite the forest is typically located at higher elevations in practice we suggest to set an initial bed friction coefficient for each geomorphic class based on roughness tables then carefully calibrate boundary conditions and topography based on uavsar data and lastly calibrate bed roughness within a meaningful range the complexity and nonlinear interactions between different parameters such as bed friction elevation and discharge demand a comprehensive method to optimize the model performance with multiple parameters calibrated simultaneously in a physical way the topography correction method adjusting elevation at each model cell by the difference in water level changes between model and uavsar may have limitations when applied to other systems 1 the method empirically relates elevation error to water level change without solving the physical functions between water level change elevation and friction 2 changes in bed elevation at one cell would affect tide propagation and water level changes at cells downstream therefore the empirical method may produce unrealistic results for a patchy and irregular topography all the calibrations are based on a sole parameter of water level change derived from uavsar however it is unknown whether this calibration would influence the model performance with respect to other parameters such as water level and flow velocity future research may involve multiple hydraulic parameters for model calibration e g a combination of water level change uavsar and water surface slope airswot as the water level changes little 10 cm during this 2 5 hour time window here we set constant values of bed friction for the marsh and forest by assuming that it includes the friction caused by vegetation canopy zhang et al 2020 however hydraulic models in rivers show that the effective friction is proportional to the bed elevation variance and inversely proportional to depth rodríguez et al 2020 models that require high accuracy can integrate remote sensed vegetation parameters defining a wetland friction variable in space and time fagherazzi et al 2020 the 2 5 hour uavsar campaign was conducted during river flood and high water levels when the vegetation is submerged large scale sheet flow becomes important and the relative difference in friction between the channels and platform decreases temmerman et al 2005 fagherazzi et al 2012 similarly the relative difference in friction between the marsh and forest would also decrease with increasing water depths future research can use consecutive uavsar observations covering a full tidal cycle to explore the sensitivity of bed friction to different vegetation species and submergence depths our model fails to capture water level variations in the lower hb channel fig 4b most likely due to the coarse mesh grid resolution that do not fully resolve the small scale creeks see area in the red dotted circle in fig 6b a discontinuous channel with a width of one cell does not allow the correct propagation of the tidal and riverine signal decreasing water fluxes and affecting water levels as a result the model performs better in the upper subdomain wl channel future research should evaluate the influence of bathymetric resolution on tidal propagation from the main wax lake outlet to the small creeks the acquisition time of the uavsar data is also important during low river discharge and neap tides the calibration can be very challenging due to the small magnitude of water level changes and the limited accuracy of wetting and drying schemes utilized by numerical models even during high riverine flow and with the wetlands inundated the water level change is only in the range of 5 cm hr for systems with larger tidal ranges e g the fly river delta canestrelli et al 2010 or the yangtze delta zhang et al 2018 the large temporal variations in water levels can be more easily detected by uavsar expanding the application of this technology 6 conclusions uavsar can detect water level changes beneath vegetation canopies with high spatial and temporal resolution we presented here the first comparison between uavsar observations of tide induced water level change and numerical simulations with a hydrodynamic model the following results were obtained from our analysis a comparison between model results and uavsar data indicates that small errors in bathymetry up to 20 cm have a strong effect on the hydrodynamics of the wetland platform this result is of general validity for microtidal areas and was never highlighted before for lack of distributed hydrodynamic data on the marsh platform state of the art topographic data of wetlands obtained for example from lidar are therefore inadequate for modeling purposes because they are often affected by vertical errors in the order of centimeters caused by the dense vegetation cover a correction of the topography is possible by combining uavsar data and a high resolution numerical model that solves the platform hydrodynamics this coupling is necessary because only a numerical model can convert the hydrodynamic information collected by uavsar in elevation the topographic correction is spatially distributed resolution of 10 m and physically based at every point of the mesh the elevation is improved by iteratively solving the hydrodynamics and comparing it to uavsar data this correction is therefore superior to previous corrections that were either uniform in space e g lowering the marsh of a fixed amount or based on ancillary data not directly linked to platform hydrodynamics e g vegetation biomass in conclusion our results demonstrate significant improvement in parametrizing a hydrodynamic model in particular we were able to correct wetland topography which traditionally requires labor intensive campaigns to collect sparse in situ measurements we provided a general framework for model calibration that adjusts river discharge and lidar derived wetland topography based on the uavsar data the calibration enables realistic tidal propagation in the wetlands with the model efficiency improving from 0 15 to 0 53 and the rmse decreasing by 26 our novel approach using airborne remote sensing to calibrate hydraulic variables will substantially improve the reliability and accuracy of model simulations and thus advance our understanding of hydrodynamics in coastal wetlands authors contribution xiaohe zhang1 x z cathleen jones2 c j talib oliver cabrera2 t o marc simard2 m s sergio fagherazzi1 s f x z implemented simulations analyzed the data and wrote the manuscript with support from s f s f and m s helped supervise the project x z and s f conceived the original idea c j and t o processed the uavsar data m s and c j provided critical feedback for writing and figures all the authors work for the national aeronautics and space administration nasa delta x mission declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work within nasa delta x project is funded by the science mission directorate s earth science division through the earth venture suborbital 3 program nnh17zda001n evs3 this work was partly performed by the jet propulsion laboratory california institute of technology under contract with the national aeronautics and space administration nasa s f was also partially funded by nsf grants deb 1832221 to the virginia coast reserve long term ecological research project and oce 1637630 to the plum island ecosystems long term ecological research project supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 104088 appendix supplementary materials image application 1 
220,the propagation of tides and riverine floodwater in coastal wetlands is controlled by subtle topographic differences and a thick vegetation canopy high resolution numerical models have been used in recent years to simulate fluxes across wetlands however these models are based on sparse field data that can lead to unreliable results here we utilize high spatial resolution rapid repeat interferometric data from the uninhabited aerial vehicle synthetic aperture radar uavsar to provide a synoptic measurement of sub canopy water level change resulting from tide propagation into wetlands these data are used to constrain crucial model parameters and improve the performance and realism of simulations of the wax lake wetlands in coastal louisiana usa a sensitivity analysis shows that the boundary condition of river discharge should be calibrated first followed by iterative correction of terrain elevation specified originally by a digital terrain model derived from lidar measurements the calibration of bed friction becomes important only with the boundary and topography calibrated with the model parameters calibrated the overall nash sutcliffe model efficiency for water level change increases from 0 15 to 0 53 with the rmse reduced by 26 in areas with dense wetland grasses the lidar signal is unable to reach the soil surface but the l band uavsar instrument detects changes in water levels that can be used to infer the true ground elevation the high spatial resolution and repeat acquisition frequency minutes to hours observations provided by uavsar represent a groundbreaking opportunity for a deeper understanding of the complex hydrodynamics of coastal wetlands 1 introduction distributary channels in deltaic systems nourish wetlands with flow sediment and nutrients contributing to marsh elevation gain and resilience to sea level rise redfield 1972 morris et al 2002 fagherazzi et al 2012 fitzgerald and hughes 2019 schuerch et al 2018 field observations and modeling have been devoted to understand interactions of flows and sediment transport between channels tidal flats and wetlands donatelli et al 2020 field data have shown that when tidal and riverine waters propagate from channel to vegetation vegetation increases flow resistance attenuates waves and increases sediment settling reed et al 1999 nepf and vivoni 2000 the presence of vegetation enhances flows within the channels which become the main conveyers of water and sediments to the marsh platform temmerman et al 2005 in the wax lake delta in louisiana usa the channel wetland hydrological connectivity is significant with 23 54 of discharge flowing from adjacent channels into wetlands demanding detailed analyses of wetland hydrodynamics hiatt and passalacqua 2015 these findings imply complex and nonhomogeneous flow pathways within the vegetation despite the importance of collecting hydrodynamic data on the wetland platform expensive in situ measurements with reduced spatial sampling and resolution hamper progress in modeling flow in complex coastal wetlands physics based numerical models explicitly solve hydrodynamics and sediment transport equations to determine sediment budgets and morphological evolution most importantly numerical models can isolate different driving processes and provide reliable predictions under different scenarios of climate change and sea level rise for the wax lake delta numerical model results show that intermediate vegetation height and density are optimal for sediment deposition nardin and edmonds 2014 similarly oliver et al 2020 found that the presence of vegetation could increase vertical accretion within vegetation patches but reduce sediment retention within the entire delta models can also mimic vegetation establishment growth expansion and mortality and update vegetation parameters in each simulated time step interactively best et al 2018 the reliability of model results depends on careful calibration of model input parameters particularly topography and bed roughness and accurate information of boundary conditions that require synchronous spatial field observations often numerical models of wetlands use light detection and ranging lidar data to extract the topography of the vegetated area zhang et al 2020 which could lead to a positive bias in elevations due to the incapability of laser of penetrating into the vegetation canopy this would produce misleading results in marsh models because of the high sensitivity of marsh species and biomass to subtle topographic differences and inundation depths lidar errors vary spatially as a function of vegetation cover and a constant correction in elevation cannot capture this spatial complexity the errors are traditionally categorized by vegetation species and adjusted using point measurements of rtk and total stations lidar topography can be further refined by relating elevation to aboveground biomass density or using machine learning methods medeiros et al 2015 rogers et al 2018 cooper et al 2019 alizad et al 2016 calibrated a lidar digital terrain model dtm of the salt marshes in apalachicola bay florida usa by comparing the biomass distribution obtained from a model to remote sensing data the modeled biomass was calculated based on the empirical function between biomass and inundation depth put forward by morris et al 2002 model calibration is traditionally based on a few of tidal gauges in large channels which cannot capture complex flow dynamics within wetlands the flows on the wetland platform are seldom calibrated due to the challenge of collecting in situ measurements beneath the vegetation canopy alsdorf et al 2007 recent advances in the remote sensing of hydraulic variables e g inundation extent and water level provide an opportunity to fuse high resolution spatial data into numerical models through calibration e g mccabe et al 2017 wiberg et al 2020 the integration of remote sensing data and numerical models was indicated as one of the grand challenges in salt marsh morphodynamics fagherazzi et al 2020 spaceborne interferometry synthetic aperture rader insar has been successfully applied to estimate water level changes in wetlands especially in fluvial systems because the interferometric phase change of repeat pass sar backscattering from emergent flooded vegetation is dominated by the water level change with a high interferometric coherence e g alsdorf et al 2000 yuan et al 2015 oliver cabrera and wdowinski 2016 lee et al 2020 liao et al 2020 based on insar derived water level change jung et al 2012 calibrated manning s bed roughness in a 2 d floodplain model of the atchafalaya river floodplains reducing the mean absolute error to 5 7 cm in a 64 day simulation water levels derived from radar altimetry can be utilized for calibrations of depth and bed roughness in poorly gauged areas sun et al 2012 domeneghetti et al 2014 the application of radar altimetry measurements due to their low accuracy is limited to large channel systems such as the amazon river de paiva et al 2013 however the long temporal repeat of spaceborne insar days to months inhibits observation of tidal flows into wetlands and thus cannot be used to calibrate coastal numerical models airborne systems such as the uninhabited aerial vehicle synthetic aperture radar uavsar can fill this gap providing repeat pass differential interferometry for water level changes within 1 hour time window and with high accuracy e g rosen et al 2006 fore et al 2015 the goal of this paper is to use uavsar derived short timescale water level change to calibrate hydrodynamic models in tidal wetlands and to assess model sensitivity to boundary conditions lidar derived topography and bed roughness to this end we develop a 2 d delft3d hydro model with high spatial resolution 10 m covering the wax lake delta and adjacent wetlands we focus our calibration effort in the western wetland area dissected by meandering channels fig 1 the work presented here introduces a novel approach to integrate airborne insar observations into quantitative models of tidal flow propagation in coastal vegetated surfaces 2 study site the wax lake delta is a river dominated delta located in the atchafalaya bay within the greater mississippi river delta the atchafalaya river distributes water and sediment into atchafalaya bay through the wax lake outlet artificially dredged in 1942 the sediment has in time formed the wax lake delta robert et al 2015 shaw et al 2013 the delta is about 20 km from the calumet gauge usgs 07 381 590 and the width of main channel is 300 m fig 1a the low lying atchafalaya bay is affected by a mixed semidiurnal micro tide with the mean tidal range of 0 34 m the river discharge varies seasonally from 2500 m3 s to more than 5000 m3 s during river floods a portion of discharge is diverted along the engineered gulf intercostal waterway giww that crosses the wax lake outlet swarzenski and perrien 2015 extensive heterogeneous plant communities have developed along the two sides of the main channel a dendritic network of meandering channels departing form the main stem brings water and sediment to these vegetated areas here we focus on wax lake wl channel and hog bayou hb channel in the western side of the main channel fig 1b most research in the wax lake delta focuses on mechanisms controlling the naturally prograding delta itself without considering the role of these large scale wetlands in modulating water and sediment inputs carle et al 2015 oliver et al 2020 3 methods 3 1 uavsar interferometry uavsar is a fully polarimetric quad polarization l band wavelength λ 0 2379 m frequency ν 1 257 ghz synthetic aperture radar operated by the u s national aeronautics and space administration nasa and deployed on a gulfstream 3 aircraft the system is designed for both polarimetry polsar and repeat pass interferometry insar hensley et al 2003 insar processing of repeated observations of a surface from a same viewing geometry enables measurement of surface displacement in the line of sight direction rosen et al 2006 because the instrument is side looking the line of sight displacement is in general a combination of vertical and horizontal displacements relating the measured displacement to a change in surface elevation requires knowledge of the horizontal displacement through either measurement or ancillary information in flooded wetlands the backscattered signal is primarily due to double bounce scattering from the water and vegetation so the measured surface displacement is due to change in water level lu and kwoun 2008 wdowinski et al 2013 liao et al 2019 this study uses repeat pass uavsar data 6 m spatial resolution acquired in hh polarization mode horizontal transmit and receive to measure the net change in water level between 11 34 and 13 53 gmt on 08 may 2015 the measured interferometric phase change δφ is converted to elevation change δz by first phase unwrapping to remove the 2π ambiguities chen and zebker 2002 converting the unwrapped phase δφ to line of sight displacement δl δφλ 4π then projecting the value into the vertical direction δz δl cos θ using the incidence angle θ the errors of surface deformation can be controlled within 1 cm for repeat pass sar observations within hours making it well suited for imaging water level changes in coastal wetlands rosen et al 2006 more details about uavsar derived water level change maps can refer to jones et al 2020 10 3334 ornldaac 1823 3 2 hydrodynamic modeling setup a 2 d hydrodynamic model based on delft3d was developed to solve flow dynamics the model domain is a curvilinear grid of 2600 by 1700 cells with the size ranging from 100 m2 to 150 m2 in the area of wetlands fig 2 b c the model topography is a 10 m seamless dtm composed of lidar datasets http ned usgs gov sonar transects in channels and bathymetry elevations derived from diverse source data referred to the navd88 vertical datum denbina et al 2020 we specify river discharge at the calumet gauge station usgs 07 381 590 u s geological survey 2016 as the upstream boundary and tidal water levels at the noaa amerada pass station noaa 8 764 227 coops 2018 as the ocean boundary fig 2a the hourly wind speed 3 m s and direction measured at this noaa station are uniformly prescribed across the model domain to account for the influence of winds on hydrodynamics bed roughness is defined based on a 10 m sentinel 2 classification map thomas et al 2019 and a look up table for the chezy s coefficient ocean 60 m1 2 s channel water 55 m1 2 s shoals 45 m1 2 s marsh 35 m1 2 s and forest 8 m1 2 s chow 1959 straatsma and baptist 2008 the threshold depth for wetting and drying is set as 0 001 m to keep model stability for very shallow waters the simulation period is from 05 may 2015 at 00 00 to 09 may 2015 at 00 00 and a time step of 0 2 min is adopted to satisfy all stability criteria for the parallel computation the analysis is focused within the western wetland fig 1b in a 2 5 hour window on may 08 from 11 34 to 13 53 when the uavsar data were collected this time window corresponds to spring high tides and river floods thus is optimal for water level observations over the wetlands the nash sutcliffe model efficiency me root mean square error rmse and frequency curve of difference between model m and remote sensing data d are used to evaluate model performance 1 m e 1 d m 2 d d 2 r m s e d m 2 n where n is the number of observations and d is the mean of n values the value of me represents the model performance me 0 65 excellent 0 5 me 0 65 very good 0 2 me 0 5 good and me 0 2 poor allen et al 2007 3 3 calibration and validation of river discharge and wetland elevation the riverine flow from the wax lake outlet debouches seaward crossing the intercostal waterway fig 1a the giww likely modifies the discharge entering the wax lake delta and the lower wetlands as river flows can attenuate tidal propagation reducing temporal variations in water level sassi and hoitink 2013 the river discharge at the model boundary should be adjusted to account for the discharge diverted in the giww no synchronous discharge data from usgs is available along the giww at the period of the uavsar measurements we therefore validate the discharge adjustment based on an empirical calculation using water surface slope data derived from remote sensing the calibration of the model is performed in two steps fig 3 first we calibrate the river discharge to match uavsar data at the wetland margins bordering the wax lake outlet section 3 2 we then spatially modify the wetland topography in each cell if the uavsar change is larger than the model result we decrease the elevation of that cell the model is iteratively re run with the new bathymetry until the elevation correction is negligible and me and rmse are near constant the elevation correction is necessary for two reasons 1 marsh topography derived from lidar data is prone to errors because the laser signal cannot penetrate the thick vegetation resulting in an error see rosso et al 2006 this offset is very high for a wetland that is typically submerged by only few tens of centimeters at high tide precluding water flow in several areas 2 a simple adjustment of local friction would not be able to correct for the error and would lead to unrealistic friction values the correction in elevation proposed here is empirical and based on the assumption that lowering the bed elevation would likely allows for more tidal propagation and for spreading out the water level changes in facts water level changes are affected by flow conveyance one possible way of enhancing the flow conveyance is to increase water depth targeting a larger change in water depth however a change in elevation at one point would reverberate across the system changing the flow conveyance along the entire flow path to address this shortcoming we decided to iteratively change the elevation of a small amount so that the entire system can slowly adjust to the modification in conveyance this method is effective only if the iterative procedure converges and only if the final result is realistic i e the system does not present multiple equilibrium points here for simplicity we chose to modify the elevation by the change in elevation measured by uavsar in 2 5 hr δh 2 5hr this choice was arbitrary and a smaller change in elevation e g change in elevation measured by uavsar in 1 hr would lead to similar results after several iterations finally the sensitivity of the results to the friction coefficient for the marsh and forest surfaces is evaluated we designed 49 scenarios with 7 different friction values chézy coefficient ranging from 8 m1 2 s to 40 m1 2 s for the marsh and forest respectively and launch models with different combinations of frictions before and after the calibration of river discharge and topography the computed river discharge is validated using the empirical manning s equation that estimates flow rate in open channels as a function of water level slope channel cross section and bed friction chow 1959 2 q a c r h 1 2 s 1 2 where q is flow discharge m3 s a is channel cross section m2 c is chézy bed roughness m1 2 s rh is hydraulic radius m s is the water channel slope the manning equation is applied to two cross sections of the wax lake outlet one before the intersection with the giww cross section a a in fig 4 and one after cross section b b in fig 4 3 q 2 q 1 a 2 a 1 c 2 c 1 r h 2 r h 1 1 2 s 2 s 1 1 2 where subscript 1 refers to cross section a a subscript 2 refers to b b we thus obtain the value q2 of the discharge after the giww that can be compared to the calibrated discharge the channel slope in eq 3 is derived from airswot data denbina 2019 airswot is an airborne ka band synthetic aperture radar that measures water surface elevation in open waters with uncertainty below 0 3 cm km the airswot campaign was conducted at 17 14 gmt on 09 may 2015 and more details about the airswot measurements can be found in denbina et al 2021 the comparison allows quantifying the effect of the giww on river discharge the new wetland elevations obtained with our method are validated with high resolution elevation data at 10 long term sites of the coastwide reference monitoring system crms https lacoast gov crms see locations in fig 4 only four of these sites fall within the uavsar footprint and can therefore be used for the validation 4 results 4 1 tidal propagation beneath vegetation canopies observed by uavsar uavsar observed water level changes below vegetation canopies across the model domain in a 2 5 hour time window fig 4 changes in water levels are lower in the wetland interior due to tidal propagation dissipation and reduced hydraulic connectivity the zone with more pronounced flooding large change in water level extends about 8 10 km from the wax lake outlet mainly to wetlands along the channels with a width of 200 300 m at both sides of each channel uavsar cannot measure water level change in unvegetated areas such as ponds and channels fig 4 interestingly the hb channel has a width similar to the upper wl channel but features higher water level variations there is no clear spatial pattern of water level variations in different vegetation covers see figs 1a and 4 4 2 river discharge dominates the amplitude of water level change our model results show that imposing the river discharge measured at calumet in the wl channel underestimates tide induced water level changes along the hb channel the use of the discharge measured at the calumet station as the northern boundary condition gives rise to a uniform flow within the wetlands fed by the wl channel fig 5 a in disagreement with the uavsar observations fig 1b resulting in poor model performance fig 5c by lowering river discharge the tidal signal becomes more important and yields a distribution of water level variations comparable to uavsar observations especially in the hb channel fig 5b d generally we find that a lower river discharge gives better results in the subdomain of the wl channel increases me from 0 33 to 0 51 and reduces the rmse from 1 82 cm to 1 57 cm fig 5e f a reduced river discharge in the wl channel is likely caused by the intracoastal waterway that captures part of the river flow since the rmse is meaningless with negative values of me eqs 1 we used the averaged value of water level changes at the inlet of the hb channel for calibration fig 1b the difference between water level change estimates by the model and the uavsar observations decreases with reduced river discharges fig 5f overall the optimum river discharge initial discharge 1100 m3 s about 20 reduction in river discharge was determined by evaluation of me rmse and regional water level changes a flow diversion of 1100 m3 s in the giww is in accordance with the average discharge of 800 m3 s measured during peak flows by usgs swarzenski and perrien 2015 4 3 iterative modification of lidar derived topography despite the improvement in the magnitude of water level changes at the wetland margin after calibrating the river discharge fig 5 the model does not accurately capture tidal propagation on the wetland platform fig 6 a this is probably caused by errors in the lidar derived topography due to the inability of the laser to penetrate a dense canopy hladik and alber 2012 according to the delta x project datasets https deltax jpl nasa gov the lidar dtm may have biases of 20 cm and rmse of 24 cm in the wax lake delta which can significantly impact reliability of hydrodynamic models of coastal wetlands particularly in microtidal systems alizad et al 2020 instead of correcting the topography using limited rtk gps points we introduce an approach based on the coupling of uavsar observations with model simulations to iteratively correct the model dtm the correction is different at every point in the domain specifically we iteratively change the initial dtm by subtracting the difference between the modeled and uavsar observed water level change after each modification iteration of the dtm the model is re run with the updated dtm until the topography converges to the optimum scenario with tidal propagation and dissipation occurring in the wetland interior the final model results are more realistic and compare well to uavsar observations fig 6a b the improvement is especially evident in the hb subdomain fig 6c and fig 5d the model performance increases after each iteration and the dtm at iteration 7 is chosen as the optimum scenario given insignificant improvements in overall domain me and rmse in later iterations fig 6d overall the water level change me increased from 0 15 to 0 53 after 7 iterations while the rmse decreased from 2 16 cm to 1 60 cm for the wl channel subdomain the me improved from 0 51 to 0 63 with rmse decreasing from 1 57 cm to 1 35 cm for the hb channel subdomain the me improved from 0 52 to 0 22 while the rmse decreased from 3 14 cm to 2 25 cm the lower me value in the hb channel is mainly caused by the spatial resolution of the model which is too low to capture tidal propagation within the small scale creeks at the end of the domain dash red circle in fig 6b ignoring the area near the small scale creeks improves me from 0 22 to 0 38 and rmse from 2 25 cm to 2 03 cm the dtm correction varies in space and is generally larger along the channel margins fig 7 b the change is about 0 1 m in the wl channel but can reach 0 4 m along the hb channel positive value indicates a lowering of the elevation the modified dtm gives a lower elevation in general as expected when the lidar pulses do not reach the ground in the presence of dense vegetation high density marshes in the hb channel may cause the higher bias compared to the forested banks of the wl channel fig 1a after the river discharge calibration and subsequent dtm correction based on uavsar measurements the distribution of the error between model and uavsar is more symmetrical and with the centroid shifting toward zero fig 7c 4 4 sensitivity to bed roughness with initial river discharge and topography the calibration of bed friction for the marsh and forest little improved the model performance in terms of me and rmse tables 1 2 the forest friction dominates the me with less friction larger chézy coefficient in the forest decreasing the overall model performance table 1 the me is weakly related to variations in friction coefficients for instance model results with the friction combination marsh 35 m1 2 s forest 8 m1 2 s display same me and rmse values as the case marsh 35 m1 2 s forest 25 m1 2 s overall a me 0 2 in all simulations indicate a poor model performance allen et al 2007 therefore the calibration in bed frictions is less meaningful without a careful calibration of boundary conditions river discharge and initial conditions topography after modifications of river discharge and topography the model performance improves tables 3 4 it is interesting to note that the model with friction scenario marsh 35 m1 2 s forest 8 m1 2 s performs best achieving the highest me this is probably because we calibrated river discharge and topography with these friction values the modified topography therefore retains information about the friction distribution optimizing the model results the sensitivity analysis table 3 shows the me ranges from 0 38 to 0 53 and rmse from 1 6 cm to 1 85 cm therefore the influence of the friction coefficients on model results increases and becomes important only after calibration of river discharge and dtm elevation to shed more light on the effect of friction we compare two scenarios against the final model calibration by increasing marsh roughness marsh 8 m1 2 s forest 8 m1 2 s and decreasing forest roughness marsh 35 m1 2 s forest 35 m1 2 s fig 8 the watershed of the hb channel is characterized by salt marshes and more friction in the marsh constrains flows in the channel increasing variations in water levels along the channel banks fig 8a with a lower friction in the forest variations in water levels decrease near the wl channel but increase farther away fig 8c both scenarios lower the model performance compared to the initial bed friction scenario fig 8b 4 5 validation of calibrated river discharge and wetland elevations the slope of the water surface calculated by airswot is presented in fig 9 a see also denbina et al 2019 while the two cross sections extracted from bathymetric data before and after the giww are reported in fig 9b the geometric values of the two cross sections are a1 3945 m2 r h1 15 40 m a2 4041m2 r h2 15 49 m the bed roughness is assumed to be constant along the wlo c1 c2 to reduce possible noise in the airswot data we calculate the 300 m averaged slope values s1 4 75 cm km and s2 2 25 cm km and the 500 m averaged slope values s1 4 cm km and s2 2 33 cm km fig 9a see also denbina et al 2019 the corresponding value of q2 q1 is 0 71 for the 300 m slope and 0 78 for the 500 m slope which means that the giww receives 29 and 22 of the total river discharge respectively the calibrated river discharge obtained by reducing of 20 the total discharge at the calumet station is therefore reasonable and well accounts for the flow diversion in the intracoastal waterway we collected ground truth elevation data of all the crms sites n 10 within the model domain and compared them to the topographic data used in the model figs 4 10 the averaged positive error is 12 65 9 18 cm for 10 crms sites with a maximum error of 28 43 cm at crms 4016 therefore ground elevation data indicate a systematic positive error in lidar derived elevations a positive error in the lidar elevation of wetlands is very common and is due to the difficult penetration of the signal in the dense grass canopy see rosen et al 2006 for the 4 sites 0489 4779 4016 0479 within the uavsar area the dtm correction using our method reduces the error from 20 27 cm to 6 82 cm the correction little improves the elevation at crms 4779 fig 10 this is probably due to the very small value of water level change measured by uavsar fig 4 and the complex network of narrow channels not well represented in the modeling mesh despite this our method seems capable of reducing the elevation error at different locations 5 discussion uavsar repeat pass interferometry can detect water level changes beneath vegetation canopies at a time scale of minutes to hours making it possible to capture tidal propagation in coastal wetlands the high spatial resolution observations of water level change provided by this sensor can be used to calibrate hydrodynamic models we developed a high resolution hydrodynamic model and compared its output with the water level changes measured by uavsar over a 2 5 hour period during which tidal flow caused water level change in channels and adjacent wetlands we found that the accuracy of the lidar derived topography and of the river discharge used as a boundary condition are important for the overall model performance whereas the calibration of bed friction becomes regionally important only with boundary conditions and dtm calibrated 5 1 model calibration and measurements uncertainty a calibrated model should reproduce tidal and riverine fluxes at the boundaries because very small errors in water levels amplitude and phase can change flow patterns within the model domain abbott and skovgaard 1978 cunge 2003 pellettier 1987 showed that uncertainty of discharge measurements at river stations could be as high as 20 of the observed value calibration of numerical models of natural river streams e g po river in italy domeneghetti et al 2012 can produce unrealistic manning s coefficients to compensate for the uncertainty of discharge measurements horritt and bates 2002 in our study area potential sources of uncertainty include errors in the river discharge at the northern boundary due to interaction of the wax lake outlet with the giww the disconnection with adjacent wetlands east and west of the model domain and poor spatial information on hydrological connectivity from small scale creeks hiatt and passalacqua 2015 high river floods can attenuate tidal flows leading to small temporal variations in water level sassi and hoitink 2013 van de kreeke and brouwer 2017 as a first step the incoming river flow is calibrated to yield a comparable instantaneous water level change at the wetland margin we found that lowering the river discharge at the boundary does increase variations in water level particularly in lower marshes however the overall model performance as measured by the parameters me and rmse show little improvement fig 5 the hydrodynamic model performance can be significantly improved with a 2 d spatial comparison with measured water level changes during a tidal cycle correcting the dtm using the measured water level change had a much larger impact on model performance it is important to note that the calibration of the wetland dtm and friction coefficient are meaningful only if the correct tidal signal is present at the wetlands margin and at the inlet of the tidal channels a summary of previous studies at different sites show that the averaged lidar elevation error in salt marshes is 18 cm with a standard deviation of 14 cm this error is likely to result in misleading hydrodynamic modeling outcomes alizad et al 2020 buffington et al 2012 in wax lake delta we directly refine the wetland dtm by coupling a hydrodynamic model and uavsar data the model performance in terms of water level changes substantially improves the dtm adjustment the high positive lidar bias 0 4 m in the marsh and the low bias in the forest fig 11 indicates the necessity of dtm adjustment especially for marshes in low lying micro tidal coastal deltas in the forest area site 1 in fig 11 the average dtm elevation is between 0 4 and 0 6 m navd88 datum positive values indicate a higher elevation and the changes in water levels measured by uavsar are small 0 1 m in 2 5hr our topographic calibration increases the elevations of the platform but only slightly less than 0 1 m interestingly the correction yields a more uniform topography reducing the size of patches in the original dtm that are probably caused by tree crowns fig 11e in the marsh area site 2 fig 11 the elevation of the marsh at the channel banks is unrealistically high above 0 8 m likely due to the thick grass canopy that prevents the lidar signal from reaching the ground in the model simulations these areas are unrealistically dry note that the elevations are higher in the marsh than in the forest in the original dtm in disagreement with studies on vegetation patterns in the delta fig 11j morris et al 2005 the topographic error is confirmed by the large change in water level fig 11i that would be impossible in a place with such low water levels the correction proposed by our methodology reduces the elevations by up to 0 4 m fig 11l creating a more uniform and realistic topography fig 11k the correction is more pronounced in the marsh area which is more prone to lidar errors compare fig 11f and l after calibration the marsh site becomes slightly lower than the forest one compare figs 11e and 11 k in agreement with the vegetation zonation of the delta 5 2 limitations of the proposed method sar derived hydraulic variables have already been utilized to calibrate the bed friction of different landscapes on the assumption that errors in boundary conditions and initial topography have little influence on model results for instance the manning s coefficients of the main channel and floodplains of the po river in italy were calibrated with radar altimetry ers 2 and envisat water level data in a 2 d hydraulic model domeneghetti et al 2014 insar water level change data were also used to calibrate the manning s coefficients in a model of the central atchafalaya floodplain jung et al 2012 in our system wetland friction affects the regional water flow but its calibration did not improve the model performance after the correction of river discharge and topography tables 3 4 this might be because the calibration of discharge and topography contains information of bed friction and the initial friction setup can mildly influence the accuracy of the calibration of other parameters note that the friction coefficients used in the sensitivity analysis cover a very large range from 8 to 40 m1 2 s and yet they hardly affect me and rmse tables 1 4 another option would be to keep the wetland elevation constant and change the friction coefficient locally in an iterative way as we did for elevation however this would lead to very large spatial variations in friction which are unrealistic for these homogeneous vegetation covers and friction values very likely outside of the range reported in the literature our results are consistent with previous findings suggesting that friction is an inherent physical parameter therefore a calibration exclusively based on the adjustment of the friction coefficient could produce unrealistic model results cunge 2003 another possible approach would be to lower or elevate the entire topography of a fixed amount to correct for possible vegetation biases in the lidar data and then calibrate the friction coefficient a uniform decrease of 20 cm in elevation would increase the flow on the wetland surface increasing the temporal change in water depth fig s1c but it would concentrate less flow near the channels reducing the change in water depth near the hb channel where uavsar data show high values of water level change on the other hand a uniform increase in elevation would concentrate the flow in the channels fig s1d but it would reduce the flow on the wetland surface with large area completely dry even at high tide we therefore conclude that the wetland elevation needs to be selectively adjusted as a function of local hydrodynamic data this is also evident in fig 11 which shows higher lidar elevations in the marsh with respect to the forest while in reality it should be the opposite the forest is typically located at higher elevations in practice we suggest to set an initial bed friction coefficient for each geomorphic class based on roughness tables then carefully calibrate boundary conditions and topography based on uavsar data and lastly calibrate bed roughness within a meaningful range the complexity and nonlinear interactions between different parameters such as bed friction elevation and discharge demand a comprehensive method to optimize the model performance with multiple parameters calibrated simultaneously in a physical way the topography correction method adjusting elevation at each model cell by the difference in water level changes between model and uavsar may have limitations when applied to other systems 1 the method empirically relates elevation error to water level change without solving the physical functions between water level change elevation and friction 2 changes in bed elevation at one cell would affect tide propagation and water level changes at cells downstream therefore the empirical method may produce unrealistic results for a patchy and irregular topography all the calibrations are based on a sole parameter of water level change derived from uavsar however it is unknown whether this calibration would influence the model performance with respect to other parameters such as water level and flow velocity future research may involve multiple hydraulic parameters for model calibration e g a combination of water level change uavsar and water surface slope airswot as the water level changes little 10 cm during this 2 5 hour time window here we set constant values of bed friction for the marsh and forest by assuming that it includes the friction caused by vegetation canopy zhang et al 2020 however hydraulic models in rivers show that the effective friction is proportional to the bed elevation variance and inversely proportional to depth rodríguez et al 2020 models that require high accuracy can integrate remote sensed vegetation parameters defining a wetland friction variable in space and time fagherazzi et al 2020 the 2 5 hour uavsar campaign was conducted during river flood and high water levels when the vegetation is submerged large scale sheet flow becomes important and the relative difference in friction between the channels and platform decreases temmerman et al 2005 fagherazzi et al 2012 similarly the relative difference in friction between the marsh and forest would also decrease with increasing water depths future research can use consecutive uavsar observations covering a full tidal cycle to explore the sensitivity of bed friction to different vegetation species and submergence depths our model fails to capture water level variations in the lower hb channel fig 4b most likely due to the coarse mesh grid resolution that do not fully resolve the small scale creeks see area in the red dotted circle in fig 6b a discontinuous channel with a width of one cell does not allow the correct propagation of the tidal and riverine signal decreasing water fluxes and affecting water levels as a result the model performs better in the upper subdomain wl channel future research should evaluate the influence of bathymetric resolution on tidal propagation from the main wax lake outlet to the small creeks the acquisition time of the uavsar data is also important during low river discharge and neap tides the calibration can be very challenging due to the small magnitude of water level changes and the limited accuracy of wetting and drying schemes utilized by numerical models even during high riverine flow and with the wetlands inundated the water level change is only in the range of 5 cm hr for systems with larger tidal ranges e g the fly river delta canestrelli et al 2010 or the yangtze delta zhang et al 2018 the large temporal variations in water levels can be more easily detected by uavsar expanding the application of this technology 6 conclusions uavsar can detect water level changes beneath vegetation canopies with high spatial and temporal resolution we presented here the first comparison between uavsar observations of tide induced water level change and numerical simulations with a hydrodynamic model the following results were obtained from our analysis a comparison between model results and uavsar data indicates that small errors in bathymetry up to 20 cm have a strong effect on the hydrodynamics of the wetland platform this result is of general validity for microtidal areas and was never highlighted before for lack of distributed hydrodynamic data on the marsh platform state of the art topographic data of wetlands obtained for example from lidar are therefore inadequate for modeling purposes because they are often affected by vertical errors in the order of centimeters caused by the dense vegetation cover a correction of the topography is possible by combining uavsar data and a high resolution numerical model that solves the platform hydrodynamics this coupling is necessary because only a numerical model can convert the hydrodynamic information collected by uavsar in elevation the topographic correction is spatially distributed resolution of 10 m and physically based at every point of the mesh the elevation is improved by iteratively solving the hydrodynamics and comparing it to uavsar data this correction is therefore superior to previous corrections that were either uniform in space e g lowering the marsh of a fixed amount or based on ancillary data not directly linked to platform hydrodynamics e g vegetation biomass in conclusion our results demonstrate significant improvement in parametrizing a hydrodynamic model in particular we were able to correct wetland topography which traditionally requires labor intensive campaigns to collect sparse in situ measurements we provided a general framework for model calibration that adjusts river discharge and lidar derived wetland topography based on the uavsar data the calibration enables realistic tidal propagation in the wetlands with the model efficiency improving from 0 15 to 0 53 and the rmse decreasing by 26 our novel approach using airborne remote sensing to calibrate hydraulic variables will substantially improve the reliability and accuracy of model simulations and thus advance our understanding of hydrodynamics in coastal wetlands authors contribution xiaohe zhang1 x z cathleen jones2 c j talib oliver cabrera2 t o marc simard2 m s sergio fagherazzi1 s f x z implemented simulations analyzed the data and wrote the manuscript with support from s f s f and m s helped supervise the project x z and s f conceived the original idea c j and t o processed the uavsar data m s and c j provided critical feedback for writing and figures all the authors work for the national aeronautics and space administration nasa delta x mission declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work within nasa delta x project is funded by the science mission directorate s earth science division through the earth venture suborbital 3 program nnh17zda001n evs3 this work was partly performed by the jet propulsion laboratory california institute of technology under contract with the national aeronautics and space administration nasa s f was also partially funded by nsf grants deb 1832221 to the virginia coast reserve long term ecological research project and oce 1637630 to the plum island ecosystems long term ecological research project supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 104088 appendix supplementary materials image application 1 
221,we present a new image velocimetry iv hybrid that estimates vector fields from images with widely different visualization pattern sizes such as those encountered in riverine bedform migration the iv approach is obtained by complementing the cross correlation method ccm with algorithms of optical flow methods ofm the ofm procedures are first applied to automatically determine the optimal search windows sws over the whole imaged area subsequently the ccm utilized the established sws to locally resolve velocity fields associated with the bedform movement the new approach labeled herein as high gradient pattern iv hgpiv combines the advantages of both parent techniques to improve the accuracy and spatial resolution of the resultant global velocity field and significantly reduces the computational time the hgpiv validation consists of comparing its results with those obtained with the ccm approaches applied for estimating the velocity field associated with bedform migration in a large river keywords image velocimetry acoustic mapping bedform movement optical flow acoustic mapping velocimetry 1 introduction image velocimetry iv is a well established flow measurement technique that estimates velocity fields associated with moving patterns captured in a succession of images velocities are obtained by dividing the statistically estimated displacements of the moving patterns with the time difference between successive images adrian 1991 while the initial versions of the technique were used to estimate velocities within planar surfaces illuminated in fluids its more recent versions have been extended to determine three component velocities in a plane wieneke 2005 or in a volume of fluid burgmann et al 2006 zhang et al 1997 the iv techniques are not limited to fluids they may be applied to detect movement of solid opaque surfaces that contain visible patterns traceable in successive images erf 1980 we successfully demonstrated through laboratory experiments that by combining acoustic maps converted to pseudo images with iv concepts it is possible to non intrusively characterize the planar dynamics of the bedform migration muste et al 2016 the technique labeled acoustic mapping velocimetry amv is currently transferred to field conditions using bathymetric surveys produced by multiple beam echo sounders mbes and acoustic doppler current profilers adcp measurements muste et al 2019 the goal of the transfer is to use amv processing protocols on time sequenced acoustic maps acquired through mbes or adcp bedform surveys repeated over pre established time intervals to capture the progression of the bedform movement in cross sectional swaths subsequently two dimensional 2d velocity distributions associated with the bedform migration can be obtained by applying particle iv algorithms onto these maps in the initial stage of the amv development we used the cross correlation method ccm raffel et al 2007 key elements for the processing accuracy of ccm correlation method in short include the adequate selection of the processing parameters i e the size of the elemental area containing the patterns to be tracked a k a interrogation area ia and of the size and orientation of the search window sw for pattern displacement estimation adrian 1991 the selection of the processing parameters and of the resolution of the grid for reporting the iv processing outcomes is made by user based on the inspection of the pattern geometry and dynamics and the quality of processing parameters the use of ccm with the same set of processing parameters for the whole imaged does not accurately resolve the movement of patterns if they are significantly different in size or they are exposed to widely different velocity magnitudes in sub regions of the imaged area large differences in the size of the visualization patterns are common for the images processed by amv as the bedform characteristics vary widely over the stream cross section commensurate with changes in the local depth and velocity consequently more flexible algorithms that adapt the processing parameters to the local image pattern characteristics should be used ideally in an automated mode researchers have addressed the ccm limitations in high gradient velocity situations by developing refined ccm algorithms i e not commonly implemented in commercial software these algorithms can be divided into three categories the first category focuses on improving the pattern matching technique locally cowen and monismith 1997 proposed to pre process images with a particle tracking algorithm for informing the selection of processing parameters for particle image velocimetry piv similarly westerweel et al 1997 and fleit baranya 2019 applied a first pass on the images with a discrete window offset to determine the local displacement followed by a second pass using the pre established sw wereley and meinhart 2001 applied the central difference interrogation technique in conjunction with a variable sw pattern matching willert 2008 proposed a set of criteria that determines the optimal cross correlation coefficient for each grid point the second category of algorithms focused on grid refinements for improved spatial resolution and dynamic range for various regions of the images for example theunissen et al 2010 applied the triangulated irregular network instead of the cartesian coordinate system for the grid and suggested a method of sampling the points organized in an irregular triangulated network yu and xu 2016 proposed a technique for sampling a judiciously selected irregular grid by iterating until a given objective function is satisfied the third algorithm category and the closest to our approach relies on the dynamic optimization of the size of the sw along this line astarita 2009 introduced a density predictor for the piv optimization and massulo and theunissen 2016 developed a multiple correlation peak analysis using self adaptive windows wieneke and pfeiffer 2010 and di florio et al 2002 proposed methods whereby the interrogation area ia is iteratively reshaped rotated to optimize the quality of the obtained velocity field there are fewer developments in dealing with ccm shortcomings when used for processing images that contain widely different sizes of the visualization patterns within the image in some cases the difference in pattern sizes can be attributed to the presence of high velocity gradients but this is not always the case as indicated by measurement situation while some of the above mentioned algorithms for handling high velocity gradients might resolve with sufficient accuracy the velocity field for images with high gradient pattern sizes testing them is beyond the scope of the present paper as the iv approach presented in this paper is not aimed to supersede the above mentioned ccm associated algorithms or ccm ofm hybrids e g liu et al 2020 the proposed combination of cross correlation and optical flow methods was suggested during our amv development when the use of cross correlation on bedform images failed to provide realistic results for some sub areas of the images it is then when we realized that the use of optical flow algorithms can be beneficial for our purpose as they are insensitive to the pattern size distribution as long as the distribution of the brightness intensity is smooth across all sub domains of the image and the it remains the same between image pairs by combining ofm with ccm algorithms we obtain a novel hybrid labeled high gradient pattern iv hgpiv that is suitable for processing continuous visualization patterns with constant size ias and variable sws irrespective of the difference in the patterns sizes to our knowledge this algorithm has not been reported in previous publications the hgpiv use is not limited to bedform visualization via amv but can be also used to quantify velocities in other transport processing occurring in the natural environment wind driven sand migration snow drifting debris conveyance or cloud movement in our approach we first apply the horn and schunck 1981 ofm approach to images for finding the optimal sw size and orientation followed by ccm implementation the present paper compares the performance of the newly developed hgpiv with ccm applied in two distinct ways labelled herein as global and local in the global ccm the cross correlation technique is applied to the whole image using one set of processing parameters in the local ccm the processing parameters are different for various sub areas of the raw image the paper is organized as follows first we present short summaries of the amv ccm and ofm to highlight the hgpiv role in amv and to lay out the ground for the description of the hgpiv protocol that combines elements of both techniques next we compare the outcomes of hgpiv processing with the ccm applied as described above to a series of acoustic maps acquired with acoustic instruments in a large natural river finally the paper closes with a short discussion comparing the hgpiv and ccm to illustrate its applicability and performance 2 hgpiv foundations the proposed hgpiv technique originates from the practical needs encountered during the transfer of the amv from the controlled laboratory experimental environment to field conditions in the laboratory experimental environment movement can be tracked only by particle tracking but it is difficult to represent the movement of the entire target only with particle tracking results in field conditions the difference in the velocity scale of the cross sectional velocity field defined as high gradient pattern in this paper although it is difficult to define mathematically like this situation the first step of the amv protocol is the acquisition of time sequenced bathymetric maps such maps are acquired by river management agencies interested in documenting bedform characteristics and their distribution in streams across sections and reaches ramirez et al 2018 there are multiple methods for non intrusively obtaining bathymetric maps as illustrated in fig 1 step 1 currently multi beam echo sounders mbes which survey swaths of the river bed with high spatial resolution along pre established directions produce the best quality maps for natural stream beds repeating the acoustic maps is useful not only to better describe the bedform geometries but also to estimate their migration dynamics in the second step of the amv the acoustic maps are first converted to image equivalent through resampling of the raw bathymetric information subsequently the series of repeated pseudo images are processed using image velocimetry protocols to obtain velocity fields that describe the bedform dynamics the physical meaning of the bedform velocity obtained with amv is related to complex processes occurring at the flow bed interface whereby the skin friction bedform induced roughness and subtle turbulence flow sediment interactions are all involved in determining the movement of the small and larger patterns contained within the largest bedforms previous experimental studies conducted by aberle et al 2012 duffy 2006 and leary and buscombe 2020 illustrate that the use of different methods for quantification of the bedform movement provide slightly different results in the absence of a widely accepted reference for estimating the actual bedload transport this subject continues to be under scrutiny while the subject of the physical meaning of amv and dune tracking methods outcomes is of scientific interest and deserves more in depth interpretation the present paper does not delve into further clarifications as its main purpose is to present a new measurement technology rather than elucidating details of the bedform dynamics it is however unquestionable that the geometrical and dynamic information provided by the amv is highly valuable for multiple aspects of the bedform transport investigations muste et al 2008 in the initial stages of the amv transfer from laboratory to field conditions we tested the performance of the ccm and ofm executed independently to produce velocity fields of the bedform movement during these tests we encountered challenges with ccm implementation that were not encountered with our previous laboratory acoustic maps the cause of the challenges is related to the fact that in the laboratory experiments the bedforms are uniformly distributed across the section as quasi two dimensional dunes while in natural scale rivers the bedform geometry varies widely over the stream cross section this difference in the bedfrom patterns required customization of the image processing approaches that eventually led to the hgpiv creation given that the hgpiv protocol is combining ccm and ofm principles a brief review of the techniques essential features is provided next 2 1 the cross correlation method ccm the ccm is among the first developed iv processing algorithms given that this technique is widely known only salient features to place it in the amv context are presented herein more details can be found in for example hesselink 1988 and adrian 1991 the ccm is suitable for medium to high density seeded photographic or digital images where the patterns formed by particle clusters can be easily matched adrian 1991 willert and gharib 1991 these patterns can appear as pixel arrangements or as spatial gradients of grayscale or color patterns formed by the irradiance of individual pixels fincham and spedding 1997 the first step in the correlation processing entails the selection of the computational grid and of the sizes of the processing parameters illustrated in fig 2 a 2b and 2c the selection of an optimum ia size is critical to improving the measurement spatial resolution but requires a judicious tradeoff between the desired dynamic range and signal to noise ratio quénot et al 1998 cross correlation for a specific ia is applied to detect its possible displacements within a specified search window in a pair of images the most probable pattern matching is associated with the maximum cross correlation coefficient rab defined as 1 r ab x 1 w y 1 h a x y a x y b x d x y d y b x d x y d y x 1 w y 1 h a x y a x y 2 x 1 w y 1 h b x d x y d y b x d x y d y 2 where x w and y h indicate the pixel coordinates defining each ia in the horizontal and vertical directions a x y and b x y are the distributions of the pixel intensities in the two ias separated by the time interval dt as shown in fig 2b and 2c the interrogation process leads to a cross correlation coefficient map of the same size as the sw see fig 2d the location of the maximum cross correlation peak on this map provides the most probable displacement direction the peak amplitude of the cross correlation coefficient indicates the quality of the pattern matching our algorithm for peak amplitude estimation uses the normalized correlation coefficient as it has been found both accurate and fast in practical applications briechle and hanebeck 2001 lewis 1995 the velocity associated with each ia is readily obtained by diving the best displacement candidate with the time interval between successive images the procedure described above is iteratively replicated for each grid point leading to a planar vector field covering the whole imaged area the ccm point by point interrogation process applied over a large number of images is computationally expensive use of two dimensional discrete fourier transform with digital images shortens the computational time willert and gharib 1993 while being familiar with the alternative methods previously proposed for improving the performance of the ccm in high gradient velocities reviewed in section 1 we opted herein for an ofm ccm combination for addressing the high gradient patterns encountered in our measurement situation 2 2 optical flow methods ofm the ccm algorithm is based on the estimation of displacements of an arbitrary region of the image by comparing how similar the patterns extracted from the first image are to those in its vicinity in a subsequent image in contrast the ofm directly determines the apparent displacements of moving brightness patterns by observing them through a fixed observational window in an sequence of images horn and schunck 1981 liu et al 2015 optical flow algorithms extract dense velocity fields from an image sequence assuming that the brightness of the pixel cluster is conserved during the movement quénot et al 1998 there are several approaches for implementing optical flows barron et al 1994 farnebäck 2003 quénot et al 1998 heitz et al 2010 broadly speaking they can be divided into methods that perform the image match globally or sparsely i e on an arbitrary selected image area zhang and chanson 2018 the sparse ofm is similar to the local ccm processing approach by analyzing moving patterns in sub parts of the images the sparse ofm is of relatively low accuracy compared to the global optical flow but boasts a higher computational speed mccane et al 1998 the optical flow methods were not originally developed for measurements of flows however more recently they were tested for such applications e g honbwei et al 2015 mendes et al 2020b and hybrid ccm ofm method have been created for piv applications e g liu et al 2015 yang and johnson 2017 the main advantages of the ofm over the ccm is that it does not require a sw for image analysis as the pattern movement is observed within a fixed ia and is less affected by noise and the visibility of the image patterns tauro et al 2018 it is increasingly realized that the integration of ofm and ccm can be beneficial for improving the piv results in comparison with other methods liu et a 2020 the ofm approach adopted in this study represents a combination of ccm with estimating searching window for the local area with lucas and kanade 1981 protocol that interprets the optical flow equation presented by horn and schunck 1981 this combination was suggested by the bathymetric maps used in conjunction with amv these maps are flat images of pattern brightness varying smoothly without spatial discontinuities a k a pattern occlusions the apparent velocity of the brightness gradients associated with the bedforms can be directly related to the movement of the bedform surfaces themselves the equation for calculating the velocity is based on a differential equation that relates the change in image brightness at a specific point to the motion of the brightness pattern horn and schunck 1981 liu et al 2008 liu and shen 2008 by denoting with i the brightness irradiance value at a point x y within the image pattern at time t and assuming that it remains constant during the image pattern movement one can write 2 d i x y t d t δ i δ x d x d t δ i δ y d y d t δ i δ t 0 i x u i y v i t 0 where ix iy and it are the partial derivatives of the pattern intensity gradients in the x y directions and in time respectively the notations dx dy are used for defining the displacement of the pixel patch in the x and y directions within time interval dt the time between images with u and v being the velocity components of the brightness patch movement in the x and y directions we obtain a linear equation with two unknowns the partial derivatives of the pattern intensity gradients are obtained from the information available in the set of image recordings the patch of pixels shown in fig 3 a is intentionally a set of the same size as the ia visualized in fig 2a e g miozzi 2004 this image patch is assumed to move with the same velocity in both space x and y directions and time between consecutive images eq 2 is only valid if assuming that the pixel clusters included in the same ia have the same velocity or displacement also this formula is similar to the process of finding the solution of the continuity equation and it has the same effect as calculating the velocity of the area represented by ia for the movement if bathymetry is applied with this so we can roughly estimate its movement from the multiple algorithms available to compute the partial derivatives of the pattern brightness horn and schunck 1981 quénot et al 1998 we chose the least squares method applied to minimize the sum of the spatial variation and the temporal variation for all pixels in the cluster by adopting the sparse ofm developed by lucas and kanade 1981 and applying it to the pixel cluster illustrated in fig 3 the total velocity v of the pattern patch is given by eq 3 3 a v b with 4 a i x p 1 i y p 1 i x p 2 i y p 2 i x p n i y p n v u v b i t p 1 i t p 2 i t p n where a is spatial gradient matrix for the ia and b is the temporal gradient matrix p i is the i th pixel intensity in the pixel cluster and n is the number of pixels within the cluster 3 high gradient pattern iv hgpiv the ccm and the ofm require pre establishment of the size of the cluster of pixels to initiate the image processing i e brightness pattern for the ofm and the ia for the ccm the user makes these determinations by observing the patterns in various regions of the recorded images besides specifying the ia the ccm requires determination of the sw based on the anticipated displacement of the patterns this determination is more difficult and subjective to make as the velocities of the patterns are not a priori known the hgpiv method proposed herein uses the ofm as a complementary pre processing tool to determine the possible pattern displacements notably the use of the optical flow principle in conjunction with the hgpiv aims at determining pattern displacements rather than velocities these displacements are subsequently used as input for the sw in the processing with the ccm the identification of the possible pattern displacements relies on the pyramidal feature tracking system developed by bouguet 2001 that identifies where an image point on the first image is located in the second image the tracking is made by iteratively changing the size of the sw until the brightness value of the pattern i e variable i in eq 2 centered on the point p in the two images is similar the degree of similarity is determined mathematically by minimizing a residual function characterizing the affine deformation of the image pattern bouguet 2001 the variation of the residual function ε due to incrementally increased displacements in x and y directions of a sw iteratively set at various size levels k is given by 5 ε x d x k d x k 1 a n d ε y d y k d y k 1 with dx and dy in pixels a threshold value of 0 5 is set for the for the residual function to test if its convergence is attained for increased k levels fig 4 visualizes a schematic of the above described pyramidal feature the recursive pyramidal tracking is typically made by adopting 3 or 4 iteration levels for k the first level is set at a small pixel value i e 0 5 pixel followed by multiples of 2 another rule of thumb is that level 4 of the pyramidal level should be smaller than the ia tomasi and kanade 1992 the recursive pyramidal feature tracking for a point in the image is simultaneously conducted in the x and y directions the outcomes of the pyramidal feature tracking can be graphically visualized as shown in fig 5 a the plots in this figure illustrate the variation of the residual function ε as a function of the pattern displacement and the size of the search length along the x and y directions for successive pyramidal feature tracking levels when the residual functions converge to a constant value it is considered that the pattern has been identified the corresponding values for the pattern displacement and the search length in the x and y directions are considered optimal these optimal values for the sw size are subsequently used in the processing of individual ias following the steps illustrated in fig 5b the computational time for the recursive ofm for an individual ia is relatively short compared with the ccm protocols 4 hgpiv implementation within amv context 4 1 study site and input data the case study presented herein uses the data collected by the united states us corps of engineers in the mississippi river to determine rates of bedform transport with the integrated section surface difference over time issdot method abraham et al 2011 this method has been extensively applied to acoustic maps collected with multi beam echosounders jones et al 2018 taking advantage of the fact that broadly speaking the issdot and amv methods require similar data inputs we selected one of the surveys for proof testing the capabilities of amv with field data the proof of concept amv implementation is subsequently demonstrated with measurements at river mile 435 of the mississippi river near vicksburg ms u s a at the time of the survey april 29 2013 the river width was about 1000 m the river depth was about 10 m depth and the streamflow rate was 32 050 m 3 s ramirez et al 2018 the maximum bedform wavelength and height were 70 m and 3 m respectively the bed material was predominantly sandy with d 50 0 4 mm detailed bathymetric surveys were assembled using the point clouds obtained with a 250 khz geoswath mbes ramirez et al 2018 the boat used for data collection was equipped with an rtk gps horizontal spatial accuracy of 2 cm and vertical resolution of 3 cm for 50 m flow depth the size of the surveyed area was 1290 m wide and 990 m long as show in fig 6 a due to the limited span of the mbes measurement footprint the streamwise swaths were acquired over about 100 m width one at a time the survey of the targeted area was finalized in about 1 5 h similarly to the amv the issdot requires repeated surveys acquired at time intervals commensurate with the bedform velocities four repeated mbes cross stream surveys covering the whole targeted area were acquired over the course of about 5 h the input for the amv consists of acoustic maps obtained by stitching the mbes streamwise swaths within the target area see fig 1 to ensure a reliable input for amv a judicious measurement design is needed for deciding the optimum combination between i the targeted resolution for the mapping ii the size of the survey footprint and iii the timing between the successive acquisition of the acoustic maps details on the optimization of the selection process for acquiring the acoustic maps commensurate with the bedform dynamics are discussed in you et al 2021 critical assumptions for the interpretation of the amv results are that a the bedforms are in equilibrium during the measurements and b that the time needed for collecting the entire map is short enough to consider the surveys as bedform snapshots given that the identical sequencing for the acquisition of the mbes streamwise swaths and that the image processing protocol is iteratively applied to sub regions of the image we can further assume that the image pairs for the sub regions are separated by identical time intervals the acoustic maps assembled as described above are ascii files storing the bedform location and elevation baranya and muste 2016 prior to applying iv algorithms to the acoustic maps we converted them to gray level images for this purpose the color coded depth measurements are converted into gray colored pixels using the conventional 0 255 scale e g poynton 1998 the conversion entails two steps muste et al 2016 the user decides the resolution of the pixel image as a trade off between a attaining the desirable resolution for describing the bedform patterns of interest and b limiting the output image size as the computational demand of processing increases with the size of the images for the present example we used an image size of 1140 by 880 pixels one pixel in the image corresponds to 1m2 in the acoustic maps the series of maps acquired by the four repeated area surveys are shown in fig 6b 4 2 setting the image processing parameters irrespective of the processing alternatives the selection of the image processing parameters is decided by the user with guidance from rules of thumb established by the user community e g adrian 1992 scharnowski and kähler 2020 for ccm and liu et al 2015 for ofm the rule implementation depends on the specific measurement situation therefore a visual inspection of the images is needed before to make decisions on the selection of the processing parameters for our case study we observe that the visualization patterns in the image equivalent maps are continuous grayscale gradients see fig 6b and fig 7 rather than clusters of discrete particles contrasting with their background as typically encountered in iv applications the nature of the image texture indicates that these images are more suitable for ofm rather than ccm based on the findings of hongwei et al 2015 and liu et al 2015 from sensitivity studies applied on real flows and synthetic respectively by reviewing the sequence of the four acoustic maps available for this study we also learn that the bedform displacements are predominantly one dimensional without detectable singularities and that the bedform shapes are preserved in the streamwise direction another observation regarding the images time series is that the magnitude of the displacements for the ripples and dunes are not considerably different among themselves and they are less than ¼ of their wavelengths the ia in ccm is the equivalent of the measurement volume for non intrusive measurements as each ia is associated with an estimated displacement that is subsequently used to determine its velocity the ia size should be large enough to encompass within easily recognizable or unique image patterns if the ia is too small no vectors or spurious ones might result as small changes within the feature s shape might confuse the pattern matching between the image pairs if the ia is too large the software is most likely tracking the most prominent features within this area i e most probably the image patterns of larger size as they are also less prone to significant distortions between image pairs large size ias can also decrease the confidence in accurately determining the displacement of the small size bedforms e g ripples migrating between dunes in summary the decisions on selecting appropriate size for ia are made by observing the geometry of patterns in various regions of the recorded images decision on the sw size are made by inspecting the dynamics of the patterns for various regions of the images the ofm can extract velocity fields of much higher spatial resolution than ccm when the processing parameters are suitable selected as a differential approach to image processing ofm needs accurate computations of the time derivative and the spatial gradient of the image intensity in eq 2 consequently the displacements should be smaller than the representative length of the pattern to be tracked and the pattern displacement between image pairs should be ideally less than those used in ccm liu et al 2015 the tests conducted in their study with ofm applied to piv images show that the accuracy of the optical flow depends on particle displacement particle velocity gradient particle image density and particle diameter similar to ccm trial and error tests are required before the execution of the final image processing prior to the production processing with ccm we conducted a sensitivity study to optimally select the sizes of ia and sw the summary of the sensitivity analysis processing parameters is listed in table 1 with bold fonts fig 8 shows results of these analysis conducted with various ia sizes and a constant sw i e 16 pixels in downstream in lateral directions that covers the expected displacement of the largest bedform fronts within pair of images i e zone 6 in fig 7 the inspection of the resultant whole field velocities leads to the conclusion that an ia of 128 pixels i e 128 m in natural scale was optimal for most of the image area used in the present case study as also shown by the cross correlation coefficient map defined by eq 1 fig 9 displays the processing results using variable ia and constant sw size corresponding to the maximum displacement of the bedforms for given that our interest was in tracking velocities for both ripple and dune fronts a dense grid with a step of 20 pixels i e 20 m in natural scale was used for computation for all the ia and sw size selection scenarios the visual inspection of the vector fields in fig 8 and fig 9 illustrates the failure of the ccm executed with a unique ia sw combination to provide the expected continuity of the bedform dynamics over the imaged area the above sensitivity analysis cannot provide general guidance on the range of gradients where ccm fails as such analysis requires iterative testing on a range of distributions of the pattern sizes and velocities using benchmark synthetic images e g mendes et al 2020a 4 3 testing the iv approaches in this section we test the three alternative iv approaches mentioned in sections 2 and 3 a global ccm applied to the whole image with one ia sw pair b local ccm applied with one ia sw pair for sub domains of the image of pattern sizes and c the hgpiv approach where the sw sizes for each grid point are automatically estimated over the entire image with the ofm for better substantiation of the comparison all iv approaches use the 2610 point grid illustrated in fig 7 for the first approach the user establishes both ia and sw based on visual inspection and experience with the ccm as discussed in section 4 1 in the second approach the user establishes the zoning based on the visual inspection of the local patterns within the imaged area the ia sw determination for approach b is the same as for approach a the new approach c minimizes the user input to only determining the ia size and relying on the software for detecting the optimal sw size for all the image zones described in section 3 the summary of the processing parameters for the three approaches is provided in table 1 as described above the hgpiv applies the ccm following the determination of the optimal sw with the ofm see fig 5a this condition is achieved if by applying the ofm with increasing sw size the pattern displacement in the x and y directions converge to a constant value implementation of the optimal sw size determination for areas located in the small and large size patterns is illustrated in fig 10 the vertical axes in these plots represent the range of the possible pattern displacements in the x and y directions although mathematically possible the displacement of the patterns after the convergence is attained cannot exceed the size of the sw as also pointed by liu et al 2015 for better visibility the triangles on the plots of fig 10 graphically illustrate where these criteria are not fulfilled we observed that the residual function converges in both areas despite that the difference between the pattern sizes is more than an order in magnitude we also note that the small size bedform zones converge more rapidly than those with large size bedforms the newly developed hgpiv software automatically determines the optimal sw for all ias covering the image fig 11 illustrates the result of the optimal sw estimation for subsets of grid points located in small and large size bedforms for the three pairs of images available i e the image pairs 1 2 2 3 and 3 4 in fig 6b also plotted in the figure are the velocity fields determined with hgpiv processing applied to a 128 by 128 pixel size ia given that during the approximately 5 h of the acquisition of the acoustic maps the flow was steady and the bedform movement in the equilibrium regime the bedform migration velocity fields shown in fig 11a 11b and 11c do not display significant differences for the image pairs separated by time intervals dt 0 dt 1 or dt 2 there are three notable comments regarding fig 11 the first one substantiates the capability of hgpiv to differentiate among the sizes of the sws for areas of widely different bedform sizes and keep consistent the sw size along the eight identified streamwise zones second the larger sws are located in the areas of larger size bedforms when using the ccm the user makes this assessment based on the inspection of the pattern movement in successive images if the patterns are widely different in size the user has to repeat this estimation for each area individually as discussed in section 4 2 finally it should be noted the smoothness and consistency of the whole velocity field which is a well recognized feature of the optical flow methods by adding the high resolution that can be obtained with ofm algorithms it can be concluded that these algorithms are well suited for the type of image texture handled by amv 4 4 comparison of the bedform migration velocities obtained with alternative iv approaches fig 12 shows the outcomes of the three iv processing approaches described in sections 2 and 3 the velocity fields derived with the alternative iv protocols are averages of the vector velocities obtained from the three image pairs available for testing the maximum bedform velocities over the image area do not exceed 0 001 m s which agrees with the values determined by the alternative issdot estimations ramirez et al 2018 all processing approaches used the same 128 by 128 pixels for the ia see table 1 the inspection of the overall velocity fields shown in fig 12 substantiates that while the three approaches are in overall agreement they display differences that are mere reflection of the processing errors involved lacking a reference measurement to compare with the interpretation of the results can be accomplished only in a qualitative manner it is obvious that there are considerable differences between global ccm using the same pair of processing parameters see the left area of fig 12 a the local ccm applied to zones of similar velocities and the hgpiv the last two approaches are similar but the amount of time needed for hgpiv protocol is considerably shorter than for the local ccm applied to velocity zones as subsequently discussed 5 closing comments and conclusions similar to previous developments the hybrid iv processing approach presented in this paper has originated from the need to cope with the challenges of applying available iv algorithms to a specific area of application in our case the challenges are related to implementing the amv to the velocity measurement of bedforms developing in natural scale conditions the challenges are directly connected to the iv component of the amv as the acquisition and processing of the acoustic maps in field conditions have a considerably longer period of development and testing given that the newly developed amv can dramatically transform our capabilities to non intrusively measure bedform in actual rivers the current development is both timely and impactful the main challenge with amv implementation in field conditions is that the processing parameters associated with the iv component need to be adjusted gradually over the imaged area commensurate with the size and velocity of the moving bedforms specifically we need to use smaller ia sizes in small bedform areas and larger sizes for the large bedform ones if the size difference is of an order of magnitude different while both the ccm and ofm in conjunction with additional laborious manipulations can be used in isolation to determine velocity fields over moving bedforms their combination in a new processing iv algorithm creates a synergy that blends the advantages of both parent techniques specifically the main advantages of hgpiv are that it retains the robustness and well documented knowledge of the ccm features developed by many teams over extensive years of research ensures the smoothness and high spatial resolution of the vector field produced by the ofm algorithm automates the laborious step of determining an optimal sw for ccm implementation over images displaying large differences of the visualization pattern sizes increases the accuracy and protocol uniformity in the selection of the parameters for ccm processing decrease considerably the processing time compared with the ccm even is they are executed with fast fourier transformation algorithms given that there are no widely recognized instruments to measure vector fields associated with the bedform movement if available at all the only above mentioned hgpiv aspect that can be quantitatively evaluated is the processing time for obtaining velocity fields specifically the processing duration for the same set of raw images with the global ccm local ccm and hgpiv approaches using an intel i5 3570 cpu 3 4 ghz and 8 ghz ram 4 ghz dual channel are 1 75 h 0 75 h and 0 4 h respectively we replicated five runs to check the consistency of the processing duration estimation fig 13 compares the savings in processing time for local ccm and hgpiv compared to the often used global ccm we found that the hgpiv requires 22 of the computational time for global ccm processing while local ccm requires about 44 notably the hgpiv execution times were made with the largest ia established by the processing with global and local ccm including the time required to calculate the optimum sw the large savings in computational time might be surprising but they can be briefly explained by the excessively large sw that is used by global ccm in the low velocity zones to increase the accuracy of the estimation of the velocity vectors in the high velocity zones this explanation reveals that the global ccm not only that provides erroneous results when processing velocity fields with high gradient patterns velocities as can be observed in fig 11a but also requires considerably larger computational times in contrast the local ccm improves the results accuracy and also saves computational time compared to the global ccm note that the above mentioned time duration for the local ccm does not include the time required for visually inspecting and estimating the size of the ia and sw for similar processing zones in summary we conclude that the hgpiv hybrid image velocimetry discussed in this paper improves the ccm accuracy and minimizes the computational time required for extracting velocity vector fields from images with high gradient patterns the improvement is brought about by determining the optimal sw for ccm processing with ofm protocols that are superior in spatial resolution and smoothness of the computed flow field the optimal sw detection is iteratively executed for the whole image area without user intervention this case study convincingly demonstrates improved accuracy in determining the vector fields in comparison with ccm and significant reduction of the computational time the optical flow component of the hgpiv eliminates some of the subjective choices made in cross correlation based methods for filtering the final vector fields e g elimination of strain vectors selection of correlation coefficient thresholds the hgpiv method can be adopted for quasi planar surface movements regardless of their nature i e solids or fluids the hgpiv as amv techniques are new and still under refinement future implementation of both techniques in field conditions will certainly reveal new challenges and suggest subsequent improvements one immediate need is the automation of the estimation of the ia used by all three iv approaches discussed herein that is currently decided by the user by conceptualizing the ia estimation via a machine learning process the image pattern recognition and the adaptive parameterization per type of patterns can be done computationally this new development will make image velocimetry increasingly attractive for a technique which is already widespread and recognized as user friendly declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the us geological survey cooperative grant agreement g19ac00257 and by the korea agency for infrastructure technology advancement kaia grant funded by the ministry of land infrastructure and transport 21awmp b121092 06 the third author was partially supported for this effort by the nsf award ear 1948944 
221,we present a new image velocimetry iv hybrid that estimates vector fields from images with widely different visualization pattern sizes such as those encountered in riverine bedform migration the iv approach is obtained by complementing the cross correlation method ccm with algorithms of optical flow methods ofm the ofm procedures are first applied to automatically determine the optimal search windows sws over the whole imaged area subsequently the ccm utilized the established sws to locally resolve velocity fields associated with the bedform movement the new approach labeled herein as high gradient pattern iv hgpiv combines the advantages of both parent techniques to improve the accuracy and spatial resolution of the resultant global velocity field and significantly reduces the computational time the hgpiv validation consists of comparing its results with those obtained with the ccm approaches applied for estimating the velocity field associated with bedform migration in a large river keywords image velocimetry acoustic mapping bedform movement optical flow acoustic mapping velocimetry 1 introduction image velocimetry iv is a well established flow measurement technique that estimates velocity fields associated with moving patterns captured in a succession of images velocities are obtained by dividing the statistically estimated displacements of the moving patterns with the time difference between successive images adrian 1991 while the initial versions of the technique were used to estimate velocities within planar surfaces illuminated in fluids its more recent versions have been extended to determine three component velocities in a plane wieneke 2005 or in a volume of fluid burgmann et al 2006 zhang et al 1997 the iv techniques are not limited to fluids they may be applied to detect movement of solid opaque surfaces that contain visible patterns traceable in successive images erf 1980 we successfully demonstrated through laboratory experiments that by combining acoustic maps converted to pseudo images with iv concepts it is possible to non intrusively characterize the planar dynamics of the bedform migration muste et al 2016 the technique labeled acoustic mapping velocimetry amv is currently transferred to field conditions using bathymetric surveys produced by multiple beam echo sounders mbes and acoustic doppler current profilers adcp measurements muste et al 2019 the goal of the transfer is to use amv processing protocols on time sequenced acoustic maps acquired through mbes or adcp bedform surveys repeated over pre established time intervals to capture the progression of the bedform movement in cross sectional swaths subsequently two dimensional 2d velocity distributions associated with the bedform migration can be obtained by applying particle iv algorithms onto these maps in the initial stage of the amv development we used the cross correlation method ccm raffel et al 2007 key elements for the processing accuracy of ccm correlation method in short include the adequate selection of the processing parameters i e the size of the elemental area containing the patterns to be tracked a k a interrogation area ia and of the size and orientation of the search window sw for pattern displacement estimation adrian 1991 the selection of the processing parameters and of the resolution of the grid for reporting the iv processing outcomes is made by user based on the inspection of the pattern geometry and dynamics and the quality of processing parameters the use of ccm with the same set of processing parameters for the whole imaged does not accurately resolve the movement of patterns if they are significantly different in size or they are exposed to widely different velocity magnitudes in sub regions of the imaged area large differences in the size of the visualization patterns are common for the images processed by amv as the bedform characteristics vary widely over the stream cross section commensurate with changes in the local depth and velocity consequently more flexible algorithms that adapt the processing parameters to the local image pattern characteristics should be used ideally in an automated mode researchers have addressed the ccm limitations in high gradient velocity situations by developing refined ccm algorithms i e not commonly implemented in commercial software these algorithms can be divided into three categories the first category focuses on improving the pattern matching technique locally cowen and monismith 1997 proposed to pre process images with a particle tracking algorithm for informing the selection of processing parameters for particle image velocimetry piv similarly westerweel et al 1997 and fleit baranya 2019 applied a first pass on the images with a discrete window offset to determine the local displacement followed by a second pass using the pre established sw wereley and meinhart 2001 applied the central difference interrogation technique in conjunction with a variable sw pattern matching willert 2008 proposed a set of criteria that determines the optimal cross correlation coefficient for each grid point the second category of algorithms focused on grid refinements for improved spatial resolution and dynamic range for various regions of the images for example theunissen et al 2010 applied the triangulated irregular network instead of the cartesian coordinate system for the grid and suggested a method of sampling the points organized in an irregular triangulated network yu and xu 2016 proposed a technique for sampling a judiciously selected irregular grid by iterating until a given objective function is satisfied the third algorithm category and the closest to our approach relies on the dynamic optimization of the size of the sw along this line astarita 2009 introduced a density predictor for the piv optimization and massulo and theunissen 2016 developed a multiple correlation peak analysis using self adaptive windows wieneke and pfeiffer 2010 and di florio et al 2002 proposed methods whereby the interrogation area ia is iteratively reshaped rotated to optimize the quality of the obtained velocity field there are fewer developments in dealing with ccm shortcomings when used for processing images that contain widely different sizes of the visualization patterns within the image in some cases the difference in pattern sizes can be attributed to the presence of high velocity gradients but this is not always the case as indicated by measurement situation while some of the above mentioned algorithms for handling high velocity gradients might resolve with sufficient accuracy the velocity field for images with high gradient pattern sizes testing them is beyond the scope of the present paper as the iv approach presented in this paper is not aimed to supersede the above mentioned ccm associated algorithms or ccm ofm hybrids e g liu et al 2020 the proposed combination of cross correlation and optical flow methods was suggested during our amv development when the use of cross correlation on bedform images failed to provide realistic results for some sub areas of the images it is then when we realized that the use of optical flow algorithms can be beneficial for our purpose as they are insensitive to the pattern size distribution as long as the distribution of the brightness intensity is smooth across all sub domains of the image and the it remains the same between image pairs by combining ofm with ccm algorithms we obtain a novel hybrid labeled high gradient pattern iv hgpiv that is suitable for processing continuous visualization patterns with constant size ias and variable sws irrespective of the difference in the patterns sizes to our knowledge this algorithm has not been reported in previous publications the hgpiv use is not limited to bedform visualization via amv but can be also used to quantify velocities in other transport processing occurring in the natural environment wind driven sand migration snow drifting debris conveyance or cloud movement in our approach we first apply the horn and schunck 1981 ofm approach to images for finding the optimal sw size and orientation followed by ccm implementation the present paper compares the performance of the newly developed hgpiv with ccm applied in two distinct ways labelled herein as global and local in the global ccm the cross correlation technique is applied to the whole image using one set of processing parameters in the local ccm the processing parameters are different for various sub areas of the raw image the paper is organized as follows first we present short summaries of the amv ccm and ofm to highlight the hgpiv role in amv and to lay out the ground for the description of the hgpiv protocol that combines elements of both techniques next we compare the outcomes of hgpiv processing with the ccm applied as described above to a series of acoustic maps acquired with acoustic instruments in a large natural river finally the paper closes with a short discussion comparing the hgpiv and ccm to illustrate its applicability and performance 2 hgpiv foundations the proposed hgpiv technique originates from the practical needs encountered during the transfer of the amv from the controlled laboratory experimental environment to field conditions in the laboratory experimental environment movement can be tracked only by particle tracking but it is difficult to represent the movement of the entire target only with particle tracking results in field conditions the difference in the velocity scale of the cross sectional velocity field defined as high gradient pattern in this paper although it is difficult to define mathematically like this situation the first step of the amv protocol is the acquisition of time sequenced bathymetric maps such maps are acquired by river management agencies interested in documenting bedform characteristics and their distribution in streams across sections and reaches ramirez et al 2018 there are multiple methods for non intrusively obtaining bathymetric maps as illustrated in fig 1 step 1 currently multi beam echo sounders mbes which survey swaths of the river bed with high spatial resolution along pre established directions produce the best quality maps for natural stream beds repeating the acoustic maps is useful not only to better describe the bedform geometries but also to estimate their migration dynamics in the second step of the amv the acoustic maps are first converted to image equivalent through resampling of the raw bathymetric information subsequently the series of repeated pseudo images are processed using image velocimetry protocols to obtain velocity fields that describe the bedform dynamics the physical meaning of the bedform velocity obtained with amv is related to complex processes occurring at the flow bed interface whereby the skin friction bedform induced roughness and subtle turbulence flow sediment interactions are all involved in determining the movement of the small and larger patterns contained within the largest bedforms previous experimental studies conducted by aberle et al 2012 duffy 2006 and leary and buscombe 2020 illustrate that the use of different methods for quantification of the bedform movement provide slightly different results in the absence of a widely accepted reference for estimating the actual bedload transport this subject continues to be under scrutiny while the subject of the physical meaning of amv and dune tracking methods outcomes is of scientific interest and deserves more in depth interpretation the present paper does not delve into further clarifications as its main purpose is to present a new measurement technology rather than elucidating details of the bedform dynamics it is however unquestionable that the geometrical and dynamic information provided by the amv is highly valuable for multiple aspects of the bedform transport investigations muste et al 2008 in the initial stages of the amv transfer from laboratory to field conditions we tested the performance of the ccm and ofm executed independently to produce velocity fields of the bedform movement during these tests we encountered challenges with ccm implementation that were not encountered with our previous laboratory acoustic maps the cause of the challenges is related to the fact that in the laboratory experiments the bedforms are uniformly distributed across the section as quasi two dimensional dunes while in natural scale rivers the bedform geometry varies widely over the stream cross section this difference in the bedfrom patterns required customization of the image processing approaches that eventually led to the hgpiv creation given that the hgpiv protocol is combining ccm and ofm principles a brief review of the techniques essential features is provided next 2 1 the cross correlation method ccm the ccm is among the first developed iv processing algorithms given that this technique is widely known only salient features to place it in the amv context are presented herein more details can be found in for example hesselink 1988 and adrian 1991 the ccm is suitable for medium to high density seeded photographic or digital images where the patterns formed by particle clusters can be easily matched adrian 1991 willert and gharib 1991 these patterns can appear as pixel arrangements or as spatial gradients of grayscale or color patterns formed by the irradiance of individual pixels fincham and spedding 1997 the first step in the correlation processing entails the selection of the computational grid and of the sizes of the processing parameters illustrated in fig 2 a 2b and 2c the selection of an optimum ia size is critical to improving the measurement spatial resolution but requires a judicious tradeoff between the desired dynamic range and signal to noise ratio quénot et al 1998 cross correlation for a specific ia is applied to detect its possible displacements within a specified search window in a pair of images the most probable pattern matching is associated with the maximum cross correlation coefficient rab defined as 1 r ab x 1 w y 1 h a x y a x y b x d x y d y b x d x y d y x 1 w y 1 h a x y a x y 2 x 1 w y 1 h b x d x y d y b x d x y d y 2 where x w and y h indicate the pixel coordinates defining each ia in the horizontal and vertical directions a x y and b x y are the distributions of the pixel intensities in the two ias separated by the time interval dt as shown in fig 2b and 2c the interrogation process leads to a cross correlation coefficient map of the same size as the sw see fig 2d the location of the maximum cross correlation peak on this map provides the most probable displacement direction the peak amplitude of the cross correlation coefficient indicates the quality of the pattern matching our algorithm for peak amplitude estimation uses the normalized correlation coefficient as it has been found both accurate and fast in practical applications briechle and hanebeck 2001 lewis 1995 the velocity associated with each ia is readily obtained by diving the best displacement candidate with the time interval between successive images the procedure described above is iteratively replicated for each grid point leading to a planar vector field covering the whole imaged area the ccm point by point interrogation process applied over a large number of images is computationally expensive use of two dimensional discrete fourier transform with digital images shortens the computational time willert and gharib 1993 while being familiar with the alternative methods previously proposed for improving the performance of the ccm in high gradient velocities reviewed in section 1 we opted herein for an ofm ccm combination for addressing the high gradient patterns encountered in our measurement situation 2 2 optical flow methods ofm the ccm algorithm is based on the estimation of displacements of an arbitrary region of the image by comparing how similar the patterns extracted from the first image are to those in its vicinity in a subsequent image in contrast the ofm directly determines the apparent displacements of moving brightness patterns by observing them through a fixed observational window in an sequence of images horn and schunck 1981 liu et al 2015 optical flow algorithms extract dense velocity fields from an image sequence assuming that the brightness of the pixel cluster is conserved during the movement quénot et al 1998 there are several approaches for implementing optical flows barron et al 1994 farnebäck 2003 quénot et al 1998 heitz et al 2010 broadly speaking they can be divided into methods that perform the image match globally or sparsely i e on an arbitrary selected image area zhang and chanson 2018 the sparse ofm is similar to the local ccm processing approach by analyzing moving patterns in sub parts of the images the sparse ofm is of relatively low accuracy compared to the global optical flow but boasts a higher computational speed mccane et al 1998 the optical flow methods were not originally developed for measurements of flows however more recently they were tested for such applications e g honbwei et al 2015 mendes et al 2020b and hybrid ccm ofm method have been created for piv applications e g liu et al 2015 yang and johnson 2017 the main advantages of the ofm over the ccm is that it does not require a sw for image analysis as the pattern movement is observed within a fixed ia and is less affected by noise and the visibility of the image patterns tauro et al 2018 it is increasingly realized that the integration of ofm and ccm can be beneficial for improving the piv results in comparison with other methods liu et a 2020 the ofm approach adopted in this study represents a combination of ccm with estimating searching window for the local area with lucas and kanade 1981 protocol that interprets the optical flow equation presented by horn and schunck 1981 this combination was suggested by the bathymetric maps used in conjunction with amv these maps are flat images of pattern brightness varying smoothly without spatial discontinuities a k a pattern occlusions the apparent velocity of the brightness gradients associated with the bedforms can be directly related to the movement of the bedform surfaces themselves the equation for calculating the velocity is based on a differential equation that relates the change in image brightness at a specific point to the motion of the brightness pattern horn and schunck 1981 liu et al 2008 liu and shen 2008 by denoting with i the brightness irradiance value at a point x y within the image pattern at time t and assuming that it remains constant during the image pattern movement one can write 2 d i x y t d t δ i δ x d x d t δ i δ y d y d t δ i δ t 0 i x u i y v i t 0 where ix iy and it are the partial derivatives of the pattern intensity gradients in the x y directions and in time respectively the notations dx dy are used for defining the displacement of the pixel patch in the x and y directions within time interval dt the time between images with u and v being the velocity components of the brightness patch movement in the x and y directions we obtain a linear equation with two unknowns the partial derivatives of the pattern intensity gradients are obtained from the information available in the set of image recordings the patch of pixels shown in fig 3 a is intentionally a set of the same size as the ia visualized in fig 2a e g miozzi 2004 this image patch is assumed to move with the same velocity in both space x and y directions and time between consecutive images eq 2 is only valid if assuming that the pixel clusters included in the same ia have the same velocity or displacement also this formula is similar to the process of finding the solution of the continuity equation and it has the same effect as calculating the velocity of the area represented by ia for the movement if bathymetry is applied with this so we can roughly estimate its movement from the multiple algorithms available to compute the partial derivatives of the pattern brightness horn and schunck 1981 quénot et al 1998 we chose the least squares method applied to minimize the sum of the spatial variation and the temporal variation for all pixels in the cluster by adopting the sparse ofm developed by lucas and kanade 1981 and applying it to the pixel cluster illustrated in fig 3 the total velocity v of the pattern patch is given by eq 3 3 a v b with 4 a i x p 1 i y p 1 i x p 2 i y p 2 i x p n i y p n v u v b i t p 1 i t p 2 i t p n where a is spatial gradient matrix for the ia and b is the temporal gradient matrix p i is the i th pixel intensity in the pixel cluster and n is the number of pixels within the cluster 3 high gradient pattern iv hgpiv the ccm and the ofm require pre establishment of the size of the cluster of pixels to initiate the image processing i e brightness pattern for the ofm and the ia for the ccm the user makes these determinations by observing the patterns in various regions of the recorded images besides specifying the ia the ccm requires determination of the sw based on the anticipated displacement of the patterns this determination is more difficult and subjective to make as the velocities of the patterns are not a priori known the hgpiv method proposed herein uses the ofm as a complementary pre processing tool to determine the possible pattern displacements notably the use of the optical flow principle in conjunction with the hgpiv aims at determining pattern displacements rather than velocities these displacements are subsequently used as input for the sw in the processing with the ccm the identification of the possible pattern displacements relies on the pyramidal feature tracking system developed by bouguet 2001 that identifies where an image point on the first image is located in the second image the tracking is made by iteratively changing the size of the sw until the brightness value of the pattern i e variable i in eq 2 centered on the point p in the two images is similar the degree of similarity is determined mathematically by minimizing a residual function characterizing the affine deformation of the image pattern bouguet 2001 the variation of the residual function ε due to incrementally increased displacements in x and y directions of a sw iteratively set at various size levels k is given by 5 ε x d x k d x k 1 a n d ε y d y k d y k 1 with dx and dy in pixels a threshold value of 0 5 is set for the for the residual function to test if its convergence is attained for increased k levels fig 4 visualizes a schematic of the above described pyramidal feature the recursive pyramidal tracking is typically made by adopting 3 or 4 iteration levels for k the first level is set at a small pixel value i e 0 5 pixel followed by multiples of 2 another rule of thumb is that level 4 of the pyramidal level should be smaller than the ia tomasi and kanade 1992 the recursive pyramidal feature tracking for a point in the image is simultaneously conducted in the x and y directions the outcomes of the pyramidal feature tracking can be graphically visualized as shown in fig 5 a the plots in this figure illustrate the variation of the residual function ε as a function of the pattern displacement and the size of the search length along the x and y directions for successive pyramidal feature tracking levels when the residual functions converge to a constant value it is considered that the pattern has been identified the corresponding values for the pattern displacement and the search length in the x and y directions are considered optimal these optimal values for the sw size are subsequently used in the processing of individual ias following the steps illustrated in fig 5b the computational time for the recursive ofm for an individual ia is relatively short compared with the ccm protocols 4 hgpiv implementation within amv context 4 1 study site and input data the case study presented herein uses the data collected by the united states us corps of engineers in the mississippi river to determine rates of bedform transport with the integrated section surface difference over time issdot method abraham et al 2011 this method has been extensively applied to acoustic maps collected with multi beam echosounders jones et al 2018 taking advantage of the fact that broadly speaking the issdot and amv methods require similar data inputs we selected one of the surveys for proof testing the capabilities of amv with field data the proof of concept amv implementation is subsequently demonstrated with measurements at river mile 435 of the mississippi river near vicksburg ms u s a at the time of the survey april 29 2013 the river width was about 1000 m the river depth was about 10 m depth and the streamflow rate was 32 050 m 3 s ramirez et al 2018 the maximum bedform wavelength and height were 70 m and 3 m respectively the bed material was predominantly sandy with d 50 0 4 mm detailed bathymetric surveys were assembled using the point clouds obtained with a 250 khz geoswath mbes ramirez et al 2018 the boat used for data collection was equipped with an rtk gps horizontal spatial accuracy of 2 cm and vertical resolution of 3 cm for 50 m flow depth the size of the surveyed area was 1290 m wide and 990 m long as show in fig 6 a due to the limited span of the mbes measurement footprint the streamwise swaths were acquired over about 100 m width one at a time the survey of the targeted area was finalized in about 1 5 h similarly to the amv the issdot requires repeated surveys acquired at time intervals commensurate with the bedform velocities four repeated mbes cross stream surveys covering the whole targeted area were acquired over the course of about 5 h the input for the amv consists of acoustic maps obtained by stitching the mbes streamwise swaths within the target area see fig 1 to ensure a reliable input for amv a judicious measurement design is needed for deciding the optimum combination between i the targeted resolution for the mapping ii the size of the survey footprint and iii the timing between the successive acquisition of the acoustic maps details on the optimization of the selection process for acquiring the acoustic maps commensurate with the bedform dynamics are discussed in you et al 2021 critical assumptions for the interpretation of the amv results are that a the bedforms are in equilibrium during the measurements and b that the time needed for collecting the entire map is short enough to consider the surveys as bedform snapshots given that the identical sequencing for the acquisition of the mbes streamwise swaths and that the image processing protocol is iteratively applied to sub regions of the image we can further assume that the image pairs for the sub regions are separated by identical time intervals the acoustic maps assembled as described above are ascii files storing the bedform location and elevation baranya and muste 2016 prior to applying iv algorithms to the acoustic maps we converted them to gray level images for this purpose the color coded depth measurements are converted into gray colored pixels using the conventional 0 255 scale e g poynton 1998 the conversion entails two steps muste et al 2016 the user decides the resolution of the pixel image as a trade off between a attaining the desirable resolution for describing the bedform patterns of interest and b limiting the output image size as the computational demand of processing increases with the size of the images for the present example we used an image size of 1140 by 880 pixels one pixel in the image corresponds to 1m2 in the acoustic maps the series of maps acquired by the four repeated area surveys are shown in fig 6b 4 2 setting the image processing parameters irrespective of the processing alternatives the selection of the image processing parameters is decided by the user with guidance from rules of thumb established by the user community e g adrian 1992 scharnowski and kähler 2020 for ccm and liu et al 2015 for ofm the rule implementation depends on the specific measurement situation therefore a visual inspection of the images is needed before to make decisions on the selection of the processing parameters for our case study we observe that the visualization patterns in the image equivalent maps are continuous grayscale gradients see fig 6b and fig 7 rather than clusters of discrete particles contrasting with their background as typically encountered in iv applications the nature of the image texture indicates that these images are more suitable for ofm rather than ccm based on the findings of hongwei et al 2015 and liu et al 2015 from sensitivity studies applied on real flows and synthetic respectively by reviewing the sequence of the four acoustic maps available for this study we also learn that the bedform displacements are predominantly one dimensional without detectable singularities and that the bedform shapes are preserved in the streamwise direction another observation regarding the images time series is that the magnitude of the displacements for the ripples and dunes are not considerably different among themselves and they are less than ¼ of their wavelengths the ia in ccm is the equivalent of the measurement volume for non intrusive measurements as each ia is associated with an estimated displacement that is subsequently used to determine its velocity the ia size should be large enough to encompass within easily recognizable or unique image patterns if the ia is too small no vectors or spurious ones might result as small changes within the feature s shape might confuse the pattern matching between the image pairs if the ia is too large the software is most likely tracking the most prominent features within this area i e most probably the image patterns of larger size as they are also less prone to significant distortions between image pairs large size ias can also decrease the confidence in accurately determining the displacement of the small size bedforms e g ripples migrating between dunes in summary the decisions on selecting appropriate size for ia are made by observing the geometry of patterns in various regions of the recorded images decision on the sw size are made by inspecting the dynamics of the patterns for various regions of the images the ofm can extract velocity fields of much higher spatial resolution than ccm when the processing parameters are suitable selected as a differential approach to image processing ofm needs accurate computations of the time derivative and the spatial gradient of the image intensity in eq 2 consequently the displacements should be smaller than the representative length of the pattern to be tracked and the pattern displacement between image pairs should be ideally less than those used in ccm liu et al 2015 the tests conducted in their study with ofm applied to piv images show that the accuracy of the optical flow depends on particle displacement particle velocity gradient particle image density and particle diameter similar to ccm trial and error tests are required before the execution of the final image processing prior to the production processing with ccm we conducted a sensitivity study to optimally select the sizes of ia and sw the summary of the sensitivity analysis processing parameters is listed in table 1 with bold fonts fig 8 shows results of these analysis conducted with various ia sizes and a constant sw i e 16 pixels in downstream in lateral directions that covers the expected displacement of the largest bedform fronts within pair of images i e zone 6 in fig 7 the inspection of the resultant whole field velocities leads to the conclusion that an ia of 128 pixels i e 128 m in natural scale was optimal for most of the image area used in the present case study as also shown by the cross correlation coefficient map defined by eq 1 fig 9 displays the processing results using variable ia and constant sw size corresponding to the maximum displacement of the bedforms for given that our interest was in tracking velocities for both ripple and dune fronts a dense grid with a step of 20 pixels i e 20 m in natural scale was used for computation for all the ia and sw size selection scenarios the visual inspection of the vector fields in fig 8 and fig 9 illustrates the failure of the ccm executed with a unique ia sw combination to provide the expected continuity of the bedform dynamics over the imaged area the above sensitivity analysis cannot provide general guidance on the range of gradients where ccm fails as such analysis requires iterative testing on a range of distributions of the pattern sizes and velocities using benchmark synthetic images e g mendes et al 2020a 4 3 testing the iv approaches in this section we test the three alternative iv approaches mentioned in sections 2 and 3 a global ccm applied to the whole image with one ia sw pair b local ccm applied with one ia sw pair for sub domains of the image of pattern sizes and c the hgpiv approach where the sw sizes for each grid point are automatically estimated over the entire image with the ofm for better substantiation of the comparison all iv approaches use the 2610 point grid illustrated in fig 7 for the first approach the user establishes both ia and sw based on visual inspection and experience with the ccm as discussed in section 4 1 in the second approach the user establishes the zoning based on the visual inspection of the local patterns within the imaged area the ia sw determination for approach b is the same as for approach a the new approach c minimizes the user input to only determining the ia size and relying on the software for detecting the optimal sw size for all the image zones described in section 3 the summary of the processing parameters for the three approaches is provided in table 1 as described above the hgpiv applies the ccm following the determination of the optimal sw with the ofm see fig 5a this condition is achieved if by applying the ofm with increasing sw size the pattern displacement in the x and y directions converge to a constant value implementation of the optimal sw size determination for areas located in the small and large size patterns is illustrated in fig 10 the vertical axes in these plots represent the range of the possible pattern displacements in the x and y directions although mathematically possible the displacement of the patterns after the convergence is attained cannot exceed the size of the sw as also pointed by liu et al 2015 for better visibility the triangles on the plots of fig 10 graphically illustrate where these criteria are not fulfilled we observed that the residual function converges in both areas despite that the difference between the pattern sizes is more than an order in magnitude we also note that the small size bedform zones converge more rapidly than those with large size bedforms the newly developed hgpiv software automatically determines the optimal sw for all ias covering the image fig 11 illustrates the result of the optimal sw estimation for subsets of grid points located in small and large size bedforms for the three pairs of images available i e the image pairs 1 2 2 3 and 3 4 in fig 6b also plotted in the figure are the velocity fields determined with hgpiv processing applied to a 128 by 128 pixel size ia given that during the approximately 5 h of the acquisition of the acoustic maps the flow was steady and the bedform movement in the equilibrium regime the bedform migration velocity fields shown in fig 11a 11b and 11c do not display significant differences for the image pairs separated by time intervals dt 0 dt 1 or dt 2 there are three notable comments regarding fig 11 the first one substantiates the capability of hgpiv to differentiate among the sizes of the sws for areas of widely different bedform sizes and keep consistent the sw size along the eight identified streamwise zones second the larger sws are located in the areas of larger size bedforms when using the ccm the user makes this assessment based on the inspection of the pattern movement in successive images if the patterns are widely different in size the user has to repeat this estimation for each area individually as discussed in section 4 2 finally it should be noted the smoothness and consistency of the whole velocity field which is a well recognized feature of the optical flow methods by adding the high resolution that can be obtained with ofm algorithms it can be concluded that these algorithms are well suited for the type of image texture handled by amv 4 4 comparison of the bedform migration velocities obtained with alternative iv approaches fig 12 shows the outcomes of the three iv processing approaches described in sections 2 and 3 the velocity fields derived with the alternative iv protocols are averages of the vector velocities obtained from the three image pairs available for testing the maximum bedform velocities over the image area do not exceed 0 001 m s which agrees with the values determined by the alternative issdot estimations ramirez et al 2018 all processing approaches used the same 128 by 128 pixels for the ia see table 1 the inspection of the overall velocity fields shown in fig 12 substantiates that while the three approaches are in overall agreement they display differences that are mere reflection of the processing errors involved lacking a reference measurement to compare with the interpretation of the results can be accomplished only in a qualitative manner it is obvious that there are considerable differences between global ccm using the same pair of processing parameters see the left area of fig 12 a the local ccm applied to zones of similar velocities and the hgpiv the last two approaches are similar but the amount of time needed for hgpiv protocol is considerably shorter than for the local ccm applied to velocity zones as subsequently discussed 5 closing comments and conclusions similar to previous developments the hybrid iv processing approach presented in this paper has originated from the need to cope with the challenges of applying available iv algorithms to a specific area of application in our case the challenges are related to implementing the amv to the velocity measurement of bedforms developing in natural scale conditions the challenges are directly connected to the iv component of the amv as the acquisition and processing of the acoustic maps in field conditions have a considerably longer period of development and testing given that the newly developed amv can dramatically transform our capabilities to non intrusively measure bedform in actual rivers the current development is both timely and impactful the main challenge with amv implementation in field conditions is that the processing parameters associated with the iv component need to be adjusted gradually over the imaged area commensurate with the size and velocity of the moving bedforms specifically we need to use smaller ia sizes in small bedform areas and larger sizes for the large bedform ones if the size difference is of an order of magnitude different while both the ccm and ofm in conjunction with additional laborious manipulations can be used in isolation to determine velocity fields over moving bedforms their combination in a new processing iv algorithm creates a synergy that blends the advantages of both parent techniques specifically the main advantages of hgpiv are that it retains the robustness and well documented knowledge of the ccm features developed by many teams over extensive years of research ensures the smoothness and high spatial resolution of the vector field produced by the ofm algorithm automates the laborious step of determining an optimal sw for ccm implementation over images displaying large differences of the visualization pattern sizes increases the accuracy and protocol uniformity in the selection of the parameters for ccm processing decrease considerably the processing time compared with the ccm even is they are executed with fast fourier transformation algorithms given that there are no widely recognized instruments to measure vector fields associated with the bedform movement if available at all the only above mentioned hgpiv aspect that can be quantitatively evaluated is the processing time for obtaining velocity fields specifically the processing duration for the same set of raw images with the global ccm local ccm and hgpiv approaches using an intel i5 3570 cpu 3 4 ghz and 8 ghz ram 4 ghz dual channel are 1 75 h 0 75 h and 0 4 h respectively we replicated five runs to check the consistency of the processing duration estimation fig 13 compares the savings in processing time for local ccm and hgpiv compared to the often used global ccm we found that the hgpiv requires 22 of the computational time for global ccm processing while local ccm requires about 44 notably the hgpiv execution times were made with the largest ia established by the processing with global and local ccm including the time required to calculate the optimum sw the large savings in computational time might be surprising but they can be briefly explained by the excessively large sw that is used by global ccm in the low velocity zones to increase the accuracy of the estimation of the velocity vectors in the high velocity zones this explanation reveals that the global ccm not only that provides erroneous results when processing velocity fields with high gradient patterns velocities as can be observed in fig 11a but also requires considerably larger computational times in contrast the local ccm improves the results accuracy and also saves computational time compared to the global ccm note that the above mentioned time duration for the local ccm does not include the time required for visually inspecting and estimating the size of the ia and sw for similar processing zones in summary we conclude that the hgpiv hybrid image velocimetry discussed in this paper improves the ccm accuracy and minimizes the computational time required for extracting velocity vector fields from images with high gradient patterns the improvement is brought about by determining the optimal sw for ccm processing with ofm protocols that are superior in spatial resolution and smoothness of the computed flow field the optimal sw detection is iteratively executed for the whole image area without user intervention this case study convincingly demonstrates improved accuracy in determining the vector fields in comparison with ccm and significant reduction of the computational time the optical flow component of the hgpiv eliminates some of the subjective choices made in cross correlation based methods for filtering the final vector fields e g elimination of strain vectors selection of correlation coefficient thresholds the hgpiv method can be adopted for quasi planar surface movements regardless of their nature i e solids or fluids the hgpiv as amv techniques are new and still under refinement future implementation of both techniques in field conditions will certainly reveal new challenges and suggest subsequent improvements one immediate need is the automation of the estimation of the ia used by all three iv approaches discussed herein that is currently decided by the user by conceptualizing the ia estimation via a machine learning process the image pattern recognition and the adaptive parameterization per type of patterns can be done computationally this new development will make image velocimetry increasingly attractive for a technique which is already widespread and recognized as user friendly declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the us geological survey cooperative grant agreement g19ac00257 and by the korea agency for infrastructure technology advancement kaia grant funded by the ministry of land infrastructure and transport 21awmp b121092 06 the third author was partially supported for this effort by the nsf award ear 1948944 
222,the regionalised characteristics of a sub basin s long term hydrological behaviour are used as multiple constraint filters for constraining hydrological model simulations in the congo basin using the monthly time step pitman model the results suggest that the constraints are appropriate in many sub basins 20 gauging stations but not all detailed examination of these results suggested that the effects of high slopes 7 could increase the runoff ratio and q90 mmq low flow index constraint values and that implementing an adjustment factor based on slope did improve some of the very poor results the percentage points on the fdc falling within the simulated uncertainty band has increased from 0 to 59 6 and 2 4 to 39 9 for the rift valley and batéké plateaux regions respectively future studies ideally need a range of different rainfall products to quantify the uncertainties related to the inappropriateness of the cru rainfall data in some parts of the congo basin keywords uncertainty constraints modeling pitman model congo basin 1 introduction adequate quantification of hydrological information across different spatial and temporal scales is essential to ensure sustainable management of water resources quesada montano et al 2018 hydrological models are used to generate such information fleischmann et al 2018 however the limitations of the available observed streamflow records short records missing data and lack of spatial representativeness typical of data scarce regions limit the use of traditional model calibration and validation approaches and contribute to increased uncertainty in the estimation of water resources in many large river basins including the congo river basin many of the available streamflow gauging stations are located in the downstream parts of the basin and represent cumulative streamflow characteristics from relatively large catchment areas the data are therefore not very useful for quantifying regional patterns of response in headwater areas kabuya et al 2020b this presents a serious limitation to hydrological modelling and makes it difficult to quantify model behavioural parameters those generating hydrological responses that match observed conditions for the individual upstream sub basins hughes 2016 it is therefore necessary to resort to hydrological modelling approaches that can realistically quantify the uncertainty associated with water resources estimations ndzabandzaba and hughes 2017 quesada montano et al 2018 however this also means that water resources decision making processes have to allow for this uncertainty mcmillan et al 2017 hughes 2019 although the congo river basin appears to be less studied than other large river basins of the world such as the amazon alsdorf et al 2016 laraque et al 2020 some published studies have tackled different aspects of hydrological research amongst the available studies relatively few have focused on the use of rainfall runoff models chishugi and alemaw 2009 beighley et al 2011 tshimanga et al 2011 tshimanga and hughes 2014 aloysius and saiers 2017 munzimi et al 2019 of different complexities for either process understanding present day water resource availability or future climate change impact assessment a common issue arising from the application of these models in the congo basin is the multiple uncertainty sources associated with the simulated hydrological response for example studies by beighley et al 2011 and aloysius and saiers 2017 reveal that the lack of a large and spatially extensive dataset at the appropriate scales can result in very high uncertainty they used a basin physiographic dataset in an a priori parameter estimation approach however the coarse resolution of the physiographic datasets that were not initially produced for hydrological applications are considered to remain as a main source of uncertainty in hydrological modelling o loughlin et al 2019 reported that the simulated daily discharges from beighley et al 2011 required bias correction before being used as input to a hydrodynamic model tshimanga and hughes 2014 identified the primary sources of uncertainty in the application of a monthly time step hydrological model in the congo river basin and recommended the use of regionalised hydrological indices or the characteristics of a sub basin s long term hydrological behaviour to overcome some of the problems of data scarcity these few examples show that uncertainty will always be present in hydrological simulations beven 2006 hughes 2016 uncertainties in water resources estimation can be caused by climate inputs mcmillan et al 2012 westerberg and mcmillan 2015 ehlers et al 2019 streamflow discharge data westerberg et al 2011b mcmahon and peel 2019 model structure gupta and govindaraju 2019 and model parameters mehdi et al 2018 other uncertainty sources include the shortness of available streamflow series and a poor representation of the long term flow regime westerberg et al 2014 lack of spatial representation making it difficult to interpolate to ungauged sub basins undocumented upstream water development infrastructure and the effects of large wetland areas tshimanga and hughes 2014 tumbo and hughes 2015 ndzabandzaba and hughes 2017 methods that quantify the uncertainty directly from the streamflow data are based on either discharge gaugings themselves coxon et al 2015 stage gaugings mcmillan et al 2012 horner et al 2018 or rating curve uncertainty westerberg and mcmillan 2015 kiang et al 2018 and mcmahon and peel 2019 reviewed some of these methods however their application in the context of the congo basin is difficult due to the small amount of streamflow data in the congo basin technical information on rating curves and associated uncertainty are not often available tshimanga and hughes 2014 this makes it impractical to quantify uncertainty from individual data sources and alternative methods are required to realistically quantify the total uncertainty associated with hydrological estimates these alternatives include the use of regionalised hydrological indices to constrain hydrological model simulation uncertainties previously such approaches were focused on the limits of acceptability based on flow duration curves fdcs beven 2006 blazkova and beven 2009 westerberg et al 2011a beven 2012 beven and binley 2014 teweldebrhan et al 2018 and later evolved to include additional signatures to reflect different water balance components yadav et al 2007 zhang et al 2008 westerberg and mcmillan 2015 shafii and tolson 2015 almeida et al 2016 ndzabandzaba and hughes 2017 nijzink et al 2018 such methods have the advantage of assessing the limits of model acceptability uncertainty rather than normal methods of measuring reliability such as objective functions based on comparisons with the measured data westerberg et al 2011a beven 2012 the limits or constraints on model acceptability are also model independent two studies tumbo and hughes 2015 ndzabandzaba and hughes 2017 conducted in the southern africa region used six hydrological indices representing the main water balance components these six indices were used to constrain the pitman model outputs and establish appropriate behavioural parameter sets the parameter sets that generated simulations that met all of the constraint ranges were referred to as behavioural quesada montano et al 2018 used four different constraints based on climate and runoff process characteristics at different time scales to reject hbv light model parameters that failed to represent hydrological process characteristics of a costa rican catchment nijzink et al 2018 constrained the feasible parameter space of conceptual hydrological models using different remote sensing products of soil moisture evaporation and total water storage and snow accumulation for 27 catchments across europe yadav et al 2007 developed prediction limits of hydrological constraint indices with associated confidence intervals for 30 uk catchments such limits were used by both yadav et al 2007 and kapangaziwiri et al 2012 to define regional constraint uncertainty similarly ndzabandzaba and hughes 2017 applied uncertainty bounds around previous simulations to define the constraint ranges and developed regional relationships between the aridity index ratio of the mean annual potential evapotranspiration and the mean annual rainfall and hydrological indices for eswatini formerly swaziland in contrast quesada montano et al 2018 applied a subjective 20 uncertainty to the runoff ratio inspired by uncertainty studies conducted elsewhere westerberg and mcmillan 2015 in another study by tumbo and hughes 2015 where it was difficult to find regional patterns in the relationships between sub basin physical attributes and the hydrological indices the constraint ranges were based on simple index ranges for each identified region in the great ruaha river basin of tanzania these few examples highlight the need for extracting the most possible information from the available data to define realistic constraint ranges in the context of ungauged basins hrachowitz et al 2013 in the congo basin the initial study by tshimanga and hughes 2014 used an a priori estimation approach to estimate uncertainty ranges for the pitman model parameters while the simulations were generally acceptable there remained some unresolved uncertainty issues partly due to the coarse resolution of the physical basin properties used to set the parameter ranges kabuya et al 2020b developed uncertainty ranges of some hydrological indices across different climate and physiographic regions of the congo river basin using confidence intervals of the predictive equations based on the aridity index the present study builds on the latter kabuya et al 2020b and mainly aims at testing the applicability of these index ranges in constraining the simulation uncertainties of a hydrological model of the congo river basin specifically the paper is focussed on applying the constraints for simulations using the pitman model and evaluating the results using the same set of sub basins mainly headwater areas used to develop the regional relationships as well as additional gauged data located downstream of groups of sub basins the validation data the overall objective is to assess the potential value of the approach for constraining hydrological model simulations in all the defined sub basins of the congo river basin and to identify where the likely methodological gaps are and how they might be filled 2 study area and available data the climate of the congo river basin is warm and humid with two distinct wet and dry seasons that vary with distance from the equator bultot 1974 samba et al 2008 land cover varies from tropical evergreen forest with little seasonal variation in the central parts to savannah in the north and south mayaux et al 2000 hansen et al 2008 forest constitutes the primary land cover with an area of 2 3 106 km2 representing about 18 of the world s tropical forests hansen et al 2008 somorin et al 2012 and placing the congo basin second in the world after only the amazon a total of 403 sub basins have been delineated in the congo river basin tshimanga et al 2020 and there are a total of 58 streamflow gauging stations kabuya et al 2020b the monthly streamflow time series fig 1 b and table 1 were obtained from several sources including the global runoff data centre fekete et al 1999 the office national de recherche et du developpement lempicka 1971 hydrosciences montpellier système d informations environnementales sierem http hydrosciences fr sierem and the annuaire hydrologique du congo belge devroey 1951 some of the gauges are on the main river or its main tributaries and represent a large number of upstream sub basins while others are affected by upstream large wetland systems these are not used in this study as it would be difficult to resolve either the upstream heterogeneity or the wetland impacts of the remaining 31 gauges 9 represent headwater sub basins or groups of no more than 6 upstream sub basins 7 and were used to develop initial regional hydrological index constraint ranges indicated by blue symbols in fig 1b based on relationships with the aridity index kabuya et al 2020b these indices consisted of mean monthly flow volume mmq and three non dimensional flow duration curve indices fdc10 mmq fdc50 mmq and fdc90 mmq the remaining 15 gauges represent some headwater sub basins 5 or groups of sub basins and these are used as the validation set in this study indicated by red symbols in fig 1 table 1 lists the stations used in this study while table 2 lists only the non headwater gauges and the number of upstream sub basins the monthly rainfall forcing data used for the model are the climate research unit cru ts 3 10 data for the period of 1901 to 2014 harris et al 2014 at a spatial resolution of 0 5 the unidel university of delaware rainfall dataset covering the same period and spatial resolution was used to check the appropriateness of the cru rainfall data in specific areas sun et al 2018 the cru rainfall data have previously been successfully used for hydrological modelling in the congo basin tshimanga and hughes 2014 however while gridded rainfall data might represent the general characteristics of the real rainfall i e seasonality and frequency characteristics they may not represent individual months very well the monthly distributions of potential evapotranspiration pet required by the model are derived from the international water management institute website http www iwmi org and have been computed using climate information derived from new et al 2002 for the period between 1961 and 1990 these climate data are used to calculate the aridity index using annual means of pet rainfall also the daily mod16a2 006 modis actual evapotranspiration aet estimates running et al 2017 with a spatial resolution of 500 m x 500 m aggregated by year were used to detect potential uncertainties in some of the long term water balance components stream flow rainfall evaporative losses these global climate datasets are used given the lack of adequate ground based information available for long periods and with good spatial coverage however the paucity of rainfall gauges over the congo river basin means that only limited observed records are used to construct and validate the global datasets contributing a source of input uncertainty that cannot be readily quantified tshimanga 2012 maidment et al 2015 sun et al 2018 mean monthly recharge mmr mm index values are available from the global database of annual long term average groundwater recharge döll and fiedler 2008 at a spatial resolution of 0 5 by 0 5 fig 2 but are expected to be very uncertain in the absence of any observed measurements across the basin 3 materials and methods 3 1 hydrological model arguably any single model or group of models could be used to achieve the stated objective of evaluating the usefulness of the regional hydrological indices for constraining the model s outputs largely because the general approach is model independent in this study the monthly time step pitman model pitman 1973 hughes 2013 has been used for two main reasons the first main reason is that it has been previously applied successfully in many parts of the southern africa region including the congo river basin itself kapangaziwiri et al 2012 hughes 2013 tshimanga and hughes 2014 tumbo and hughes 2015 ndzabandzaba and hughes 2017 oosthuizen et al 2018 kabuya 2020 further applications therefore build on the existing experience base of the model while that same experience base is helpful for establishing likely model parameter values the second main reason is that the model is packaged with a freely available model application interface spatsim https www ru ac za iwr research software spatsim that allows the model to be run in different ways that are appropriate to this study see below for more details spatsim consists of a variety of tools to store and manage the required data as well as set up and run the model and analyse the outputs this is not only valuable for this study but also benefits other potential users in the region who may wish to replicate and expand on this study or apply similar methods in other areas but who may not have access to the necessary software development tools or skills to adapt a different model the model consists of storages interception soil moisture and groundwater linked by functions to explicity represent the main runoff generation processes infiltration excess saturation excess and direct overland flow interflow and groundwater flow considered to occur at the sub basin scale fig 3 illustrates the model structure while a brief description of the model parameters is given in table 3 the model components and associated parameters are explained in more detail in previous publications hughes et al 2006 hughes 2013 tumbo and hughes 2015 hughes and mazibuko 2018 while a quite comprehensive guide is available on the website https www ru ac za iwr research software there is little doubt that the model has a relatively high number of parameters and a high level of equifinality compared to many more parsimonious models beven 2006 hughes 2016 quesada montano et al 2018 her and seong 2018 however in the context of this study this is not considered to be a limiting issue because the model outputs are constrained by the regionalised indices of hydrological behaviour and strictly speaking not based on any specific method of parameter calibration there are four main versions of the model as illustrated in fig 4 the first v1 is a simple single run version that uses a single climate input and parameter set to generate a single simulation for each sub basin this is largely used for manual calibration of the model and was not used in this study the second v2 represents stage 1 of a two stage uncertainty approach tumbo and hughes 2015 ndzabandzaba and hughes 2017 the first stage simulates incremental flow contributions from one or more sub basins independently i e no cumulative flow routing the parameter inputs consist of ranges of values for any parameters that are considered uncertain while the uncertainty ranges of a set of hydrological indices also form part of the input the model is run many times with a user selectable option of 10 000 50 000 or 100 000 with all the parameter values being randomly sampled from their ranges i e assuming a uniform distribution if any single model run generates a simulation that has characteristics falling within all of the ranges of a set of hydrological indices multiple constraint filters in fig 4 namely the mean monthly runoff volume mmq in m3 106 mean monthly groundwater recharge depth mmr in mm the 10th 50th and 90th percentiles of the flow duration curve expressed as a fraction of mmq q10 mmq q50 mmq q90 mmq and the percentage of time that zero flows are expected then it is accepted as behavioural and the parameter set is saved for later use in stage 2 v3b the model run stops when the user defined number of behavioural parameter sets has been generated the key issue is that not only must the constraint indices be compatible with each other e g flow duration curve 90th percentile must be compatible with the groundwater recharge constraint but the input parameter ranges must also be compatible with the constraint index ranges e g the groundwater parameters should be compatible with the groundwater recharge constraint index range there are built in facilities to guide users in the calibration of the input parameter ranges to ensure that they are appropriately compatible and to ensure the efficient achievement of the required number of behavioural ensemble outputs given the specified total number of possible model runs the third version of the model runs the model many times typically 10 000 for the whole basin to generate cumulative flows at each sub basin outlet this can be based on independent random sampling of the input parameter ranges v3a unconstrained uncertainty assessment or it can be based on re sampling the complete parameter sets that were saved during the stage 1 model runs referred to above v3b constrained uncertainty assessment in both cases if there are observed data available the outputs include a range of objective functions that can be used to evaluate individual ensemble members against the available observed data the former can be useful to explore parameter equifinality and sensitivity hughes and farinosi 2021 while the latter represents the second stage of the 2 stage uncertainty approach based on hydrological index constraints both of these options have been used in this study the final version is similar to the third except that the input rainfall data consists of ensembles rather than a single time series each rainfall input typically 500 is used in combination with either unconstrained v4a or constrained v4b parameter sampling to generate simulated flow ensembles that represent a combination of climate and parameter uncertainty this version has been used in climate change assessments hughes and farinosi 2020 but is not used in this study these model versions are well suited for the congo basin because it is known as one of the most ungauged tropical basins where the majority of the available gauging stations reflect cumulative flow characteristics making it difficult to distinguish the incremental flow contributions from different upstream sub drainage systems through the regionalised hydrological indices it is possible to identify behavioural parameters that reflect the sub basin s incremental flow contributions the model also provides the possibility of accounting for a sub basin s development conditions such as water abstraction e g reservoirs and different types of regulations e g hydropower dams in the stage 2 v3b of the modelling approach in addition the general model structure fig 3 provides a function that deals with wetlands where they are expected to exert considerable impacts on downstream flow regime 3 2 steps in the analysis in an iterative process kabuya et al 2020b identified the aridity index as the main predictor of the hydrological response across the basin the authors used climate and physiographic attributes topographic wetness index slope fractions of silt sand clay and curve number that are known to have potential relationships with sub basin hydrological response characteristics buchanan et al 2014 beck et al 2015 zeng et al 2017 they indicated that due to the scarcity of available headwater gauging stations it was impractical to develop predictive equations of the hydrological response for each identified physiographic region of the congo basin therefore the alternative approach of developing generic predictive equations for the whole basin was adopted with the aridity index producing the best results for all of the hydrological indices used however the authors did expect that this would pose some problems in areas where there may be additional factors apart from the aridity index that determine differences in hydrological response kabuya et al 2020b this challenge and others related to the temporal scaling of the constraints and identified convergence of the uncertainty bounds at low aridity index values are addressed in this analysis 3 2 1 step 1 temporal scaling of the constraints it is possible that the streamflow constraint indices are not independent of the time period being simulated kabuya et al 2020b indicated that while every attempt was made to adopt a similar period for all the gauges used in the regional analysis of hydrological indices the large differences between the gauges used and the lack of suitable adjacent stations available to extend the series means that quite different periods were used in some cases therefore the initial step in the assessment analysis is to re calculate the hydrological index range for the common simulation period used in this study 1901 to 2014 this involved using the unconstrained uncertainty model version v3a fig 4 and finding the ensemble that most closely matches the observed streamflow data for the common overlap period the hydrological indices mmq q10 mmq q50 mmq and q90 mmq were then calculated for the selected ensemble for the overlap period and for the total period and checked to identify if there were any significant differences 3 2 2 step 2 critical analysis of the constraint predictive equations the uncertainty bounds that were reported in kabuya et al 2020b fig 11 were based on fitting power relationships to the 5 and 95 confidence intervals around the regression relationships however it was subsequently noted that for both mmq and q90 mmq the lower and upper bounds started to converge at low aridity ai values given that a later step in the analysis see the results section uses downward adjustments to the ai values step 5 it was necessary to remove this convergence and new uncertainty bounds were established that were also extended to much lower ai values the results of this analysis as well as the equations for the uncertainty bounds are presented in appendix 1 3 2 3 step 3 constraints compatibility check and establishing behavioural sub basin parameters there is no guarantee that the groundwater recharge values of döll and fiedler 2008 are compatible with the low flow responses of the observed streamflow it was therefore necessary to check these as a first step in the application of model version 2 if they are not compatible then the approach will never find any behavioural simulations regardless of the parameter sets used fortunately the software utilities available see ndzabandzaba and hughes 2017 for further details and examples with the model allow these types of incompatibility to be determined quite efficiently this part of the initial processing therefore established new groundwater recharge constraints where necessary the initial model parameter ranges table 1a were established based on previous modelling experience in the congo river basin tshimanga and hughes 2014 kabuya 2020 in this study only model parameters responsible for a sub basin s natural hydrology 19 are used to simulate behavioural sub basin responses and five were considered as fixed values leaving fourteen being considered as uncertain and sampled using a uniform probability distribution 3 2 4 step 4 generating total cumulative flows model version 3b fig 4 is then run to generate ensembles of total cumulative flow at all of the gauging sites during this process some of the downstream routing parameters can also be considered fixed or uncertain no water use parameters were used in this study as all the gauges are considered to represent largely un developed conditions nilsson et al 2005 santini and caporaso 2018 a further option in versions 3 and 4 a and b of the model allows for the parameter sampling across all sub basins to be totally independent or grouped according to some user defined criteria of sub basin similarity in the former the uncertainty band downstream of a group of sub basins will be generally lower given that all of the upstream sub basins will contribute relatively wet or dry incremental simulations in a random manner in the latter the sampling scheme is such that generally wetter or drier simulations will be linked for all sub basins in the same group suggesting a higher band of uncertainty downstream 3 3 evaluation of model performance an additional utility program can be used to post process the time series ensembles to generate five time series representing the minimum the 5th 50th and 95th percentiles and the maximum simulated flows for each month of the total time series the 5th and 95th percentiles provide useful upper and lower uncertainty bounds covering 90 of all the simulated ensembles and excluding any outliers it should be noted that the simulation uncertainty bounds are a result of the uncertainty bounds derived from the regional analysis of the hydrological indices that are used to constrain the model in both gauged and ungauged basins ndzabandzaba and hughes 2017 kabuya et al 2020 they are therefore not arbitrary but represent the uncertainty in our understanding of regional differences in hydrological response whether or not the final simulation bounds are appropriate for any specific practical use e g the design of reservoir storage or abstraction operating rules is important but out of the scope of this paper the simulated uncertainty bounds can be compared with the observed flows at both headwater and downstream gauging stations using either hydrographs or flow duration curves fdcs but other performance measures nash and sutcliffe 1970 krause et al 2005 moriasi et al 2007 wöhling et al 2013 waseem et al 2016 such as nash sutcliffe coefficient of efficiency and mean monthly runoff bias for both untransformed ne and bias and transformed values ne ln and bias ln can also be used to assess individual ensembles in this study the key performance measures used are based on the extent to which the observed time series or percentage points on the fdc fall within the four quartiles representing the uncertainty band of the simulations for the same month or percentage point values of 0 and 3 for this containment index represent conditions where the observed data lie at the low or high end of the simulated range while 1 and 2 indicate that the observed data lie in the middle of the range similarly values of 1 or 4 indicate that the observed data fall outside the uncertainty range the purpose of the results evaluation is therefore to determine how many of the calibration and validation gauges have a high proportion of observed data that fall outside the simulated uncertainty bounds and to look for any patterns that might point to how the regionalisation can be improved using additional information about the sub basin characteristics the key issue is that the observed data are not used directly to calibrate the model although some of these data are used to develop the hydrological index constraint bounds the observed data are therefore mainly used to assess the extent to which the constraint bounds can be used to generate appropriate simulations in ungauged sub basins 4 results 4 1 assessment of the initial groundwater recharge estimates as mentioned before it is important to ensure that the ranges of the groundwater recharge estimates mmr are compatible with the q90 mmq constraint in many cases the results have shown that the groundwater recharge values of döll and fiedler 2008 were incompatible with the q90 mmq constraint and therefore were revised for consistency in the simulation of low flows fig 5 in stage 1 of the modelling framework since the original mmr values are model dependant it was expected that their use in this modelling exercise would constitute one of the major sources of uncertainty associated with low flows conversely there are also some sub basins in the upper lualaba kasai rift valley and batéké plateaux where the revised mmr values fall within the original range suggesting that this global data do have some value for constraining the groundwater components of a hydrological model 4 2 initial assessment of the results as noted above the first step prior to running the model was to check whether adjusments to the constraint values were required given the longer period of modelling compared to the observed data periods used for developing the regionalisation the large majority of the adjustments required were less than 5 and most are not considered likely to have any real impact on the results table 4 presents the results of the analysis using the output from the constrained version of the model based on identifying the number of months in either the time series or the fdcs where the observed data are bracketed by the simulated uncertainty bounds using the 95 and 5 exceeded values columns 3 to 5 list the number of months in the time series where the observed data are below within or above the simulated bounds while columns 6 to 8 repeat this information but using the fdcs the final three columns list the quartiles of the simulated bounds in which the observed data lie for the three key percentage points values between 0 and 3 indicate that the observed data are within the simulated bounds negative values indicate situations where the observed data are below i e over simulation while positive values indicate where the observed data are above i e under simulation the first observation is that even where the fdc results are acceptable where the last 3 columns of table 4 are all 0 or 3 and a high value for column 7 the of observed data falling within the simulation bounds for the time series column 4 is typically quite low maximum value of 47 for l cb261 fig 6 this is quite a common issue in data scarce regions where even if the input gridded climate data are acceptably representative of the overall seasonality and intra annual variability individual monthly rainfall values might be poorly representative of reality this means that the fdcs of the resulting simulated flows may be acceptable but there may be parts of the time series that are not very well simulated the second observation is that while there are some sites in both the calibration and validation data sets that show good results or at least adequate for parts of the fdc fig 7 a and 7b there are also many that are totally inadequate with extremely high positive quartile index values extreme under simulation fig 7c and some quite high negative values moderate to high over simulation fig 7d the remainder of this results section is therefore focused on attempting to resolve some of these discrepancies by identifying possible reasons why the regionalisation has failed in some areas and using the outcomes of this investigation to revise and improve the regioanlisation approach the order in which the sub basins are discussed is largely determined by the scale of the discrepancies between the observed data and the simulated uncertainty bounds 4 3 reassessment of the results one of the largest discrepancies between the simulations and the observed data occur for l cb191 a total of 12 sub basins lying near the rift valley to the west of rwanda and it is immediately evident that this area has high slopes 10 and some 20 relative to nearly all the rest of the congo river basin this observation prompted the use of a slope correction factor to reduce the aridity index in sub basins with slopes greater than about 7 after some trial and error attempts to find a suitable correction approach eqs 1 and 2 were used for adjusting the aridity index ai that is applied to the regional estimation equations for mmq and q90 mmq with the condition that the adjustment factors are limited to a maximum value of 1 for slopes of 8 or less both adjustment factors are relatively close to 1 while for a slope of 20 the mmq adjustment factor is 0 3 and the q90 factor is 0 7 reference to fig 2 suggests that the effects of reducing the ai value by these amounts will vary with the original ai value and have a large effect for ai values of less than about 0 8 the rationale for a lower q90 correction factor is that the actual q90 value will be affected by both an increase in the mmq constraints as well as in the q90 mmq constraint the adjustment factor required for the ai value used with the q10 mmq and q50 mmq relationships was expected to be less and was set to half way between 1 and the aiadjq90 value the format of eqs 1 and 2 was largely guided by the initial results for l cb191 but c cb138 and c cb169 also included sub basins with quite high slopes and can therefore be used to test the slope adjustments 1 a i adj mmq ln slope 3 8 2 a i adj q 90 ln slope 1 2 1 after applying the slope adjustments to l cb191 the results improved substantially table 4 2nd row for l cb191 but the under simulation remained it was further noted that many of the sub basins in the upper parts of the catchment have lower cru rainfall and higher ai values than the lower areas which appears to be somewhat counter intuitive the unidel rainfall data also show a similar pattern but the rainfall based on a water balance table 5 using modis actual evapotranspiration data observed runoff depth modis aet suggest rainfalls that are much higher for the upper parts of the catchment after the lower rainfall sub basins were adjusted to increase the total basin weighted rainfall by some 15 the results improved substantially table 4 3rd row for l cb191 the rainfall adjustments applied were very simplified given the lack of any detailed evidence that could be used for individual sub basins it is also acknowledged that the evidence for the adjustments is not very precise given the uncertainties inherent in the modis aet estimates however the balance of evidence suggests that they are justified even if the actual adjustments are not likely to be at all accurate for c cb169 batéké plateaux the original results suggest very high levels of under simulation for moderate to low flows and the observed flow duration curve has a very low slope which is inconsistent with the simulated constraint ranges the slopes are generally quite high 9 5 to 13 3 and the slope adjustments certainly improve the simulations table 4 the unidel rainfall is some 14 higher than the cru data table 5 and if the unidel data are used to force the model not only will there be more rainfall available but the ai values also decrease both of which improve the simulations table 4 3rd row for c cb169 but low flows remain under simulated these sub basins are the main ones draining the batéké plateaux and the major river valleys are deeply incised with floodplain wetlands this suggests the possibility of some high flow attenuation which was roughly simulated using uncertain ranges for the channel routing parameter in the second stage run of the model i e not affecting the sub basin incremental flow simulations driven by the estimated constraint ranges but only the routing through the sub basins this improves the results further table 4 4rd row for c cb169 despite the approach being a very simplified way of accounting for possible floodplain and wetland attenuation effects the original results for c cb138 inkisi suggest quite high levels of under simulation notably for low flows and the influence of the slope adjustments is quite small as the slopes are mostly about 8 or less there is some evidence from the water balance calculations table 5 that the rainfall might be slightly under estimated and there is some evidence that the mmq value based on the relatively short observed data period 1951 to 1959 under represents the long term mmq by some 10 applying these adjustments gives slightly better results table 4 but the observed flows remain under simulated the observed flows for k cb259 upper kasai are quite highly under simulated for moderate to low flows table 4 the slopes are all quite low but the basin is long and quite narrow suggesting that channel attenuation may play a role applying the channel routing parameter gives some improvements and this could have implications for other ungauged rivers in the south western partf of the congo river basin many of which have similar basin shape characteristics fig 1 l cb200 201 and 202 are gauged sub basins of lcb18 table 2 while l cb230 is in the same area while the results for the downstream site l cb18 table 4 improved the results for the smaller headwater catchments did not change much with some being under and others being over simulated l cb200 lcb202 and l cb230 remain quite highly under simulated for moderate to low flows and there is no currently available evidence to suggest why this region has an apparently different low flow regime than other parts of the total basin however previous work unpublished but including field observations in these zambian catchments confirm that sustained flows occur throughout the dry season it is possible that there is an influence related to geology but we were unable to identify any data sources that could suggest any unique characteristics of the geology that would contribute to sustaining low flows c cb185 itimbiri is generally over simulated particularly for moderate to low flows while the slope adjustment changes do not affect this set of sub basins the water balance check using modis aet data table 5 suggest that both the cru and unidel rainfalls could tend to over estimate the available moisture and the constraints were re set and the model re run with the cru rainfall data scaled by 94 the results are certainly better with low flows still being somewhat over simulated table 4 the results for the remaining sub basins were generally quite good or only moderate over or under simulated and the revisions did not change the situation very much with some improving slightly and others being somewhat poorer however table 4 indicates that in general terms the revisions have generated improved results s cb236 in the northwestern sub basins represents one of the few sub basins where there is a relatively large difference between the mmq for the short observation period 1951 to 1970 and the longer simulation period however the overall result did not change very much it is also an area that has very high forest cover and one of the changes that was made was based on turning off the surface runoff generation part of the model and simulating all flows as either interflow or groundwater discharge this improved the results table 4 partly because the final simulations had a larger uncertainty range than the original ones based partly on surface runoff generation 5 discussion fig 8 illustrates the frequency distributions of the containment indices for the original and revised simulations it is evident that there are relatively few changes in the q10 and q50 indices apart from the fact that some of the small number of large under simulations have been improved there are also quite a high number 20 gauging stations where the observed data were totally within both the original and revised simulated bounds there are far fewer 15 gauging stations where the low flows q90 are successfully simulated and there remain quite a high number where the low flows are either under simulated mostly or over simulated after the revisions to the constraint values this result could almost have been predicted given the large spread in q90 mmq values shown in fig a1 appendix 1 while some of the identified adjustments have improved the situation there are evidently other factors that have not been accounted for that cause quite large differences in low flow response in different parts of the congo river basin some of the adjustments made have been based on including the channel routing parameter to attenuate high flows and increase lower flows this parameter has the greatest impact on downstream flows from a number of upstream sub basins and has already been justified in some sub basins c cb169 and k cb259 but it may also apply in others where there is expected to be high flow attenuation however it is not a simple matter to identify those areas where the use of the channel routing parameter can be justified based on measurable physical characteristics tshimanga and hughes 2014 differences in land cover have not been taken into account in the regional analysis of the constraint values largely because there were no clear signals in the orginal analysis kabuya et al 2020b possibly because of the relatively small data set there are also no clear signals in the current analysis and therefore the effects of land cover on runoff ratio and the shapes of fdcs remain largely unknown for the congo river basin the effects of increased evapotranspiration losses from forestry areas has largely been accounted for through uncertainty ranges in the annual potential evaporation demand but differences in this range have not been fully related to the area of forest cover the lower value of the range has been set to the iwmi estimates http www iwmi org which could under estimate evapotranspiration losses in densely forested areas however this would mainly increase the simulated range of at least some of the constraint indices during the simulation runs it was noted that some of the simulated ranges were relatively low and certainly lower than the input constraint ranges this has the potential to exacerbate any over or under estimates relative to observed data as the quartiles of the simulated range will be quite small it is therefore considered to be important to ensure that the simulated ensembles cover the range of the input constraints i e are not biased to either extreme or concentrated in a small part of the range to ensure that the results reflect the input constraints rather than any bias in the model simulations within these constraints however this is not always straightforward to achieve given the large parameter space and inherent equifinalities hughes 2016 her and seong 2018 one observation is that it is often better to fix some of the parameters to achieve more clearer control over the uncertainty in the outputs i e reduce the equifinality in the uncertainty the situation for s cb236 including s cb332 illustrates this problem in that the original simulated range of the q10 mmq constraint was always limited to a narrow band within the middle of the input range various combinations of the surface runoff parameters affecting high flows made very little difference to this result while turning off the surface runoff generation parameters and focusing on simulating high flows with the interflow function made a large difference this is a justifiable result for a heavily forested area and it would be worthwhile to assess whether this approach would be beneficial in other heavily forested areas despite the fact that many of these already have acceptable results it should be noted that in the case of s cb236 table 4 all of the observed values for the constraint indices are well within the regionalised uncertainty ranges input to the model it is therefore evident that at least some of the results that show containment indices that are just outside of the ideal range of 0 to 3 are a modelling artefact where the observed data are inside the input constraint ranges but the model has generated an output range that is narrower and biased toward one end of the input range the same principles could be applied to c cb218 ruki ingende which has 10 sub basins table 2 all of which are forested one of the observations is that while the observed data have values for the constraint indices that fall within the input uncertainty range the observed q50 mmq and q90 mmq are close to the upper end of the uncertainty range the unidel rainfall data are some 8 higher than the cru data and using the unidel data has the effect of lowering the aridity index which in turn increases the runoff ratio q50 mmq and q90 mmq while slightly decreasing the q10 mmq constraint this effect places the observed constraint indices more within the input constrain ranges as well as providing more water re running the model with the new constraints and the increased rainfall improved the results with the three key containment indices largely improving q10 3 q50 1 and q90 2 the nash sutcliffe efficiency values also improved from approximately 0 3 for both untransformed and ln transformed data to values of better than 0 55 across the ensemble set this result offers further support for replacing the cru rainfall data with the unidel data for this set of sub basins it was also noted that the short record 97 months of available data creates an observed fdc that is not smooth and with quite large changes within a few percentage points particularly at the extremes making the containment results very sensitive to the exact percentage points chosen for comparison the overall result shows the ensemble of flow duration curves that were very close to the observed data for the most part but this was achieved with a low uncertainty range which meant that even relatively small deviations outside this range by the observed values lead to poor containment index values at some percentage points the conclusion for this site is that possible problems with the rainfall data possibly also the short record of observed flows combined with possible effects of forestry make the original constraint indices inappropriate table 1a one of the issues that is extremely difficult to account for is uncertainties in the observed streamflow input rainfall and evaporation demand data largely because there are not enough alternative datasets to confirm or deny the appropriateness of the data that have been used some attempts were made to use modis aet data and alternative rainfall data sets unidel to assess the validity of the cru data in some cases this analysis pointed to some potential problems in the cru data but the modis data are also very uncertain ruhoff et al 2013 velpuri et al 2013 as evidenced by some very low values in some areas table 5 the effects of all these data uncertainties has a compound effect they not only affect the simulations themselves e g not enough rainfall to force the model to achieve the observed outputs as noted for parts of l cb191 but they also affect the regional relationships that are used to quantify the input constraint values because they impact on the aridity estimates kabuya et al 2020b given that these compound effects could be quite different for each of the sub areas used in this analysis i e the uncertainties are likely to be quite random in their effects it is very difficult to resolve them to improve the results it is important to note that the model can be calibrated to closely reproduce the shapes of all the observed flow duration curves even if the statistics of fit for the time series can frequently be quite poor e g nash sutcliffe efficieny values of less then 0 4 in kabuya 2020 the key issue is therefore not that the model cannot be parameterised to generate appropriate responses but that the constraints which are model independent in combination with the input forcing data used do not generate outputs that are always a match to the observed data there are some situations where the model is not able to generate ensembles with constraint index values that are evenly distributed across the various input constraint ranges this is possibly because some parts of the input constraint ranges are incompatible with each other and the model is not able to generate ensembles that match the full ranges of multiple constraints one of the consequences of this is that the final uncertainty range of ensembles is much narrower than the input range of the constraints and even if the observed data are close but not within the range the containment indices suggest a poor fit notwithstanding these rather negative comments about the results fig 8 suggests that quite for a large proportion of the sub basins the results are quite good while the details for all sub basins in table 4 suggests that there is no real difference between the calibration and validation sites 6 conclusions the overall conclusion is that the orginal regionalised constraint indices based soley on aridity index are appropriate in many sub basins but not all further detailed examination of these results suggested that the effects of high slopes prevelant in a relatively small number of sub basins could increase the runoff ratio and q90 mmq values and that implementing an adjustment factor based on slope did improve some of the very poor results however it was also clear that some of the cru rainfall data under represented the real rainfall in some areas and this also removed some of the gross under simulations it was recognised that there are missing data in the cru dataset at the start and ends of the total record these are represented by mean monthly values in the time series an indication that there are few local data available to generate the gridded values the worst affected areas the most years with mean monthly values stretches across the total basin in a band from the south west to the north east and mainly covers sub basins c cb188 and c cb218 used in this analysis but also covers many ungauged sub basins not included here attempts to apply a water balance approach using observed flows plus modis aet data to compare with the available rainfall data were largely inconclusive because of some clearly incorrect modis values future studies ideally need to more critically assess the rainfall data used to force the model and in the absence of data to validate any rainfall products could consider the use of uncertain rainfall inputs into the model using a range of different rainfall products including satellite derived estimates to quantify the uncertainties multiple information sources of remote sensing products e g satellite water level observations jung et al 2010 may be also useful in the larger rivers to supplement in situ observations some minor improvements were made through the use of the channel routing parameter to reduce high flows and this approach was applied where there is some evidence that upstream high flows could be attenuated however this concept was not applied to all other sub basins partly because it is not always straightforward to identify where attenuation effects might be applicable there is some evidence that land cover and particularly the effects of dense tropical forest should be part of the approach to the regional estimation of the constraint indices however once again this result is far from conclusive as the effects do not appear to apply to all the sub basins that have high proportions of forest one of the recommendations for further work is that this issue should be investigated in more detail both from an empirical i e looking at response differences across all forested areas using the available observed data and conceptual persepective the conceptual perspective should include considerations of the likely runoff generation processes across all forested areas and how these should be represented in the model parameter sets some of the sub basins in the zambian part of the congo river basin appear to have very sustained dry season low flows resulting in higher q90 mmq values than other areas and certainly values that are at the very high end of the regional ranges for this constraint index we could not find any information that would explain this characteristic of the flow regimes and this also requires further investigation there is some evidence to suggest that sites with quite short records less than 10 years and sites with high proportions of missing data can skew the results even though only the simulated values that were matched with available observed data were included in the containment analysis there is very little that can be done to improve this situation although it is possible that some form of observed flow data patching could be attempted this type of approach however might simply end up adding another layer of uncertainty into an analysis that is already very uncertain it should be noted that previous work tshimanga et al 2011 tshimanga and hughes 2014 conducted in the congo basin has demonstrated that the pitman model can be calibrated with acceptable statistics in most gauged basins nash sutcliffe coefficient of efficiency for the majority of the gauging stations range from 0 5 to 0 9 and is therefore considered applicable to the region however this does not help to decide how to set the model up for all the many ungauged sub basins in the remainder of the basin the current paper attempted to address this problem by applying regionalised indices of sub basin hydrological response characteristics and testing the approach using the same gauged basins used in the regionalisation as well as a set of validation gauging stations that were not previously used most of the validation stations are downstream of multiple sub basins and therefore the validations are based on applying the regional constraint indices to sub basins and then assess whether the cumulative simulated flow bounds at the gauges are comparable to the observed data in terms of both fdc characteristics as well as their time series variations this study has not reported on the differences between parameter values across the sub basins partly because this would take up a great deal of space in an already lengthy paper and partly because the main focus of the study was to evaluate the regionalised constraint indices which are model independent however it is recommended that future studies should look at this issue more closely and try to ensure that there is a degree of consistency in the way in which the responses of sub basins with similar characteristics are simulated by the model credit authorship contribution statement pierre m kabuya conceptualization methodology writing original draft writing review editing denis a hughes supervision software writing review editing raphael m tshimanga data curation mark a trigg writing review editing paul bates writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the funding support of the congo river user hydraulics and morphology cruhm project which is wholly funded by the royal society dfid africa capacity building rs dfid under the grant number aq150005 paul bates is supported by a royal society wolfson research merit award the modelling tools spatsim and pitman model used in this study have been developed at the institute for water research rhodes university and can be accessed through the rhodes university website https www ru ac za iwr research software spatsim the model setup for the congo can be accessed by directly contacting the corresponding author appendix 1 re assessment of the constraint index regional relationship uncertainty bounds the runoff ratio rr used to calculate mmq bounds required extending to account for lower aridity index ai values after they have been adjusted downwards by the effect of slope the extensions of the two bounds are based on linear extrapolation of the slopes of the main bound relationships fitted to the 5 and 95 confidence limits of the regression equations eqs a1 and a2 between ai values of 0 75 and 0 65 fig a1 a suggests that this approach may under estimate the upper bound values for low ai for ai values 0 65 a1 rr lower 1 2944 ex p 2 508 ai a2 rr upper 0 2608 a i 0 951 for ai values 0 65 a3 rr lower 0 254 0 5758 0 65 ai a4 rr upper 0 395 0 5 0 65 ai the q90 mmq bounds also needed extending and the same approach was used for ai values 0 65 a5 q 90 mmq lower 0 4975 a i 2 1 4935 ai 1 1334 a6 q 90 mmq upper 0 4077 a i 1 037 for ai values 0 65 a7 q 90 mmq lower 0 373 0 8 0 65 ai a8 q 90 mmq upper 0 637 0 879 0 65 ai there is no need to extend the q10 mmq and q50 mmq bound relationships as the slope adjustments are smaller and the relationships fitted to the confidence limits are smoother without any signs of convergence at low or high ai values a10 q 10 mmq lower 1 635 a i 0 843 a11 q 10 mmq upper 2 4425 a i 0 5614 a12 q 50 mmq lower 0 58 a i 0 695 a13 q 50 mmq upper 0 8383 a i 0 599 
222,the regionalised characteristics of a sub basin s long term hydrological behaviour are used as multiple constraint filters for constraining hydrological model simulations in the congo basin using the monthly time step pitman model the results suggest that the constraints are appropriate in many sub basins 20 gauging stations but not all detailed examination of these results suggested that the effects of high slopes 7 could increase the runoff ratio and q90 mmq low flow index constraint values and that implementing an adjustment factor based on slope did improve some of the very poor results the percentage points on the fdc falling within the simulated uncertainty band has increased from 0 to 59 6 and 2 4 to 39 9 for the rift valley and batéké plateaux regions respectively future studies ideally need a range of different rainfall products to quantify the uncertainties related to the inappropriateness of the cru rainfall data in some parts of the congo basin keywords uncertainty constraints modeling pitman model congo basin 1 introduction adequate quantification of hydrological information across different spatial and temporal scales is essential to ensure sustainable management of water resources quesada montano et al 2018 hydrological models are used to generate such information fleischmann et al 2018 however the limitations of the available observed streamflow records short records missing data and lack of spatial representativeness typical of data scarce regions limit the use of traditional model calibration and validation approaches and contribute to increased uncertainty in the estimation of water resources in many large river basins including the congo river basin many of the available streamflow gauging stations are located in the downstream parts of the basin and represent cumulative streamflow characteristics from relatively large catchment areas the data are therefore not very useful for quantifying regional patterns of response in headwater areas kabuya et al 2020b this presents a serious limitation to hydrological modelling and makes it difficult to quantify model behavioural parameters those generating hydrological responses that match observed conditions for the individual upstream sub basins hughes 2016 it is therefore necessary to resort to hydrological modelling approaches that can realistically quantify the uncertainty associated with water resources estimations ndzabandzaba and hughes 2017 quesada montano et al 2018 however this also means that water resources decision making processes have to allow for this uncertainty mcmillan et al 2017 hughes 2019 although the congo river basin appears to be less studied than other large river basins of the world such as the amazon alsdorf et al 2016 laraque et al 2020 some published studies have tackled different aspects of hydrological research amongst the available studies relatively few have focused on the use of rainfall runoff models chishugi and alemaw 2009 beighley et al 2011 tshimanga et al 2011 tshimanga and hughes 2014 aloysius and saiers 2017 munzimi et al 2019 of different complexities for either process understanding present day water resource availability or future climate change impact assessment a common issue arising from the application of these models in the congo basin is the multiple uncertainty sources associated with the simulated hydrological response for example studies by beighley et al 2011 and aloysius and saiers 2017 reveal that the lack of a large and spatially extensive dataset at the appropriate scales can result in very high uncertainty they used a basin physiographic dataset in an a priori parameter estimation approach however the coarse resolution of the physiographic datasets that were not initially produced for hydrological applications are considered to remain as a main source of uncertainty in hydrological modelling o loughlin et al 2019 reported that the simulated daily discharges from beighley et al 2011 required bias correction before being used as input to a hydrodynamic model tshimanga and hughes 2014 identified the primary sources of uncertainty in the application of a monthly time step hydrological model in the congo river basin and recommended the use of regionalised hydrological indices or the characteristics of a sub basin s long term hydrological behaviour to overcome some of the problems of data scarcity these few examples show that uncertainty will always be present in hydrological simulations beven 2006 hughes 2016 uncertainties in water resources estimation can be caused by climate inputs mcmillan et al 2012 westerberg and mcmillan 2015 ehlers et al 2019 streamflow discharge data westerberg et al 2011b mcmahon and peel 2019 model structure gupta and govindaraju 2019 and model parameters mehdi et al 2018 other uncertainty sources include the shortness of available streamflow series and a poor representation of the long term flow regime westerberg et al 2014 lack of spatial representation making it difficult to interpolate to ungauged sub basins undocumented upstream water development infrastructure and the effects of large wetland areas tshimanga and hughes 2014 tumbo and hughes 2015 ndzabandzaba and hughes 2017 methods that quantify the uncertainty directly from the streamflow data are based on either discharge gaugings themselves coxon et al 2015 stage gaugings mcmillan et al 2012 horner et al 2018 or rating curve uncertainty westerberg and mcmillan 2015 kiang et al 2018 and mcmahon and peel 2019 reviewed some of these methods however their application in the context of the congo basin is difficult due to the small amount of streamflow data in the congo basin technical information on rating curves and associated uncertainty are not often available tshimanga and hughes 2014 this makes it impractical to quantify uncertainty from individual data sources and alternative methods are required to realistically quantify the total uncertainty associated with hydrological estimates these alternatives include the use of regionalised hydrological indices to constrain hydrological model simulation uncertainties previously such approaches were focused on the limits of acceptability based on flow duration curves fdcs beven 2006 blazkova and beven 2009 westerberg et al 2011a beven 2012 beven and binley 2014 teweldebrhan et al 2018 and later evolved to include additional signatures to reflect different water balance components yadav et al 2007 zhang et al 2008 westerberg and mcmillan 2015 shafii and tolson 2015 almeida et al 2016 ndzabandzaba and hughes 2017 nijzink et al 2018 such methods have the advantage of assessing the limits of model acceptability uncertainty rather than normal methods of measuring reliability such as objective functions based on comparisons with the measured data westerberg et al 2011a beven 2012 the limits or constraints on model acceptability are also model independent two studies tumbo and hughes 2015 ndzabandzaba and hughes 2017 conducted in the southern africa region used six hydrological indices representing the main water balance components these six indices were used to constrain the pitman model outputs and establish appropriate behavioural parameter sets the parameter sets that generated simulations that met all of the constraint ranges were referred to as behavioural quesada montano et al 2018 used four different constraints based on climate and runoff process characteristics at different time scales to reject hbv light model parameters that failed to represent hydrological process characteristics of a costa rican catchment nijzink et al 2018 constrained the feasible parameter space of conceptual hydrological models using different remote sensing products of soil moisture evaporation and total water storage and snow accumulation for 27 catchments across europe yadav et al 2007 developed prediction limits of hydrological constraint indices with associated confidence intervals for 30 uk catchments such limits were used by both yadav et al 2007 and kapangaziwiri et al 2012 to define regional constraint uncertainty similarly ndzabandzaba and hughes 2017 applied uncertainty bounds around previous simulations to define the constraint ranges and developed regional relationships between the aridity index ratio of the mean annual potential evapotranspiration and the mean annual rainfall and hydrological indices for eswatini formerly swaziland in contrast quesada montano et al 2018 applied a subjective 20 uncertainty to the runoff ratio inspired by uncertainty studies conducted elsewhere westerberg and mcmillan 2015 in another study by tumbo and hughes 2015 where it was difficult to find regional patterns in the relationships between sub basin physical attributes and the hydrological indices the constraint ranges were based on simple index ranges for each identified region in the great ruaha river basin of tanzania these few examples highlight the need for extracting the most possible information from the available data to define realistic constraint ranges in the context of ungauged basins hrachowitz et al 2013 in the congo basin the initial study by tshimanga and hughes 2014 used an a priori estimation approach to estimate uncertainty ranges for the pitman model parameters while the simulations were generally acceptable there remained some unresolved uncertainty issues partly due to the coarse resolution of the physical basin properties used to set the parameter ranges kabuya et al 2020b developed uncertainty ranges of some hydrological indices across different climate and physiographic regions of the congo river basin using confidence intervals of the predictive equations based on the aridity index the present study builds on the latter kabuya et al 2020b and mainly aims at testing the applicability of these index ranges in constraining the simulation uncertainties of a hydrological model of the congo river basin specifically the paper is focussed on applying the constraints for simulations using the pitman model and evaluating the results using the same set of sub basins mainly headwater areas used to develop the regional relationships as well as additional gauged data located downstream of groups of sub basins the validation data the overall objective is to assess the potential value of the approach for constraining hydrological model simulations in all the defined sub basins of the congo river basin and to identify where the likely methodological gaps are and how they might be filled 2 study area and available data the climate of the congo river basin is warm and humid with two distinct wet and dry seasons that vary with distance from the equator bultot 1974 samba et al 2008 land cover varies from tropical evergreen forest with little seasonal variation in the central parts to savannah in the north and south mayaux et al 2000 hansen et al 2008 forest constitutes the primary land cover with an area of 2 3 106 km2 representing about 18 of the world s tropical forests hansen et al 2008 somorin et al 2012 and placing the congo basin second in the world after only the amazon a total of 403 sub basins have been delineated in the congo river basin tshimanga et al 2020 and there are a total of 58 streamflow gauging stations kabuya et al 2020b the monthly streamflow time series fig 1 b and table 1 were obtained from several sources including the global runoff data centre fekete et al 1999 the office national de recherche et du developpement lempicka 1971 hydrosciences montpellier système d informations environnementales sierem http hydrosciences fr sierem and the annuaire hydrologique du congo belge devroey 1951 some of the gauges are on the main river or its main tributaries and represent a large number of upstream sub basins while others are affected by upstream large wetland systems these are not used in this study as it would be difficult to resolve either the upstream heterogeneity or the wetland impacts of the remaining 31 gauges 9 represent headwater sub basins or groups of no more than 6 upstream sub basins 7 and were used to develop initial regional hydrological index constraint ranges indicated by blue symbols in fig 1b based on relationships with the aridity index kabuya et al 2020b these indices consisted of mean monthly flow volume mmq and three non dimensional flow duration curve indices fdc10 mmq fdc50 mmq and fdc90 mmq the remaining 15 gauges represent some headwater sub basins 5 or groups of sub basins and these are used as the validation set in this study indicated by red symbols in fig 1 table 1 lists the stations used in this study while table 2 lists only the non headwater gauges and the number of upstream sub basins the monthly rainfall forcing data used for the model are the climate research unit cru ts 3 10 data for the period of 1901 to 2014 harris et al 2014 at a spatial resolution of 0 5 the unidel university of delaware rainfall dataset covering the same period and spatial resolution was used to check the appropriateness of the cru rainfall data in specific areas sun et al 2018 the cru rainfall data have previously been successfully used for hydrological modelling in the congo basin tshimanga and hughes 2014 however while gridded rainfall data might represent the general characteristics of the real rainfall i e seasonality and frequency characteristics they may not represent individual months very well the monthly distributions of potential evapotranspiration pet required by the model are derived from the international water management institute website http www iwmi org and have been computed using climate information derived from new et al 2002 for the period between 1961 and 1990 these climate data are used to calculate the aridity index using annual means of pet rainfall also the daily mod16a2 006 modis actual evapotranspiration aet estimates running et al 2017 with a spatial resolution of 500 m x 500 m aggregated by year were used to detect potential uncertainties in some of the long term water balance components stream flow rainfall evaporative losses these global climate datasets are used given the lack of adequate ground based information available for long periods and with good spatial coverage however the paucity of rainfall gauges over the congo river basin means that only limited observed records are used to construct and validate the global datasets contributing a source of input uncertainty that cannot be readily quantified tshimanga 2012 maidment et al 2015 sun et al 2018 mean monthly recharge mmr mm index values are available from the global database of annual long term average groundwater recharge döll and fiedler 2008 at a spatial resolution of 0 5 by 0 5 fig 2 but are expected to be very uncertain in the absence of any observed measurements across the basin 3 materials and methods 3 1 hydrological model arguably any single model or group of models could be used to achieve the stated objective of evaluating the usefulness of the regional hydrological indices for constraining the model s outputs largely because the general approach is model independent in this study the monthly time step pitman model pitman 1973 hughes 2013 has been used for two main reasons the first main reason is that it has been previously applied successfully in many parts of the southern africa region including the congo river basin itself kapangaziwiri et al 2012 hughes 2013 tshimanga and hughes 2014 tumbo and hughes 2015 ndzabandzaba and hughes 2017 oosthuizen et al 2018 kabuya 2020 further applications therefore build on the existing experience base of the model while that same experience base is helpful for establishing likely model parameter values the second main reason is that the model is packaged with a freely available model application interface spatsim https www ru ac za iwr research software spatsim that allows the model to be run in different ways that are appropriate to this study see below for more details spatsim consists of a variety of tools to store and manage the required data as well as set up and run the model and analyse the outputs this is not only valuable for this study but also benefits other potential users in the region who may wish to replicate and expand on this study or apply similar methods in other areas but who may not have access to the necessary software development tools or skills to adapt a different model the model consists of storages interception soil moisture and groundwater linked by functions to explicity represent the main runoff generation processes infiltration excess saturation excess and direct overland flow interflow and groundwater flow considered to occur at the sub basin scale fig 3 illustrates the model structure while a brief description of the model parameters is given in table 3 the model components and associated parameters are explained in more detail in previous publications hughes et al 2006 hughes 2013 tumbo and hughes 2015 hughes and mazibuko 2018 while a quite comprehensive guide is available on the website https www ru ac za iwr research software there is little doubt that the model has a relatively high number of parameters and a high level of equifinality compared to many more parsimonious models beven 2006 hughes 2016 quesada montano et al 2018 her and seong 2018 however in the context of this study this is not considered to be a limiting issue because the model outputs are constrained by the regionalised indices of hydrological behaviour and strictly speaking not based on any specific method of parameter calibration there are four main versions of the model as illustrated in fig 4 the first v1 is a simple single run version that uses a single climate input and parameter set to generate a single simulation for each sub basin this is largely used for manual calibration of the model and was not used in this study the second v2 represents stage 1 of a two stage uncertainty approach tumbo and hughes 2015 ndzabandzaba and hughes 2017 the first stage simulates incremental flow contributions from one or more sub basins independently i e no cumulative flow routing the parameter inputs consist of ranges of values for any parameters that are considered uncertain while the uncertainty ranges of a set of hydrological indices also form part of the input the model is run many times with a user selectable option of 10 000 50 000 or 100 000 with all the parameter values being randomly sampled from their ranges i e assuming a uniform distribution if any single model run generates a simulation that has characteristics falling within all of the ranges of a set of hydrological indices multiple constraint filters in fig 4 namely the mean monthly runoff volume mmq in m3 106 mean monthly groundwater recharge depth mmr in mm the 10th 50th and 90th percentiles of the flow duration curve expressed as a fraction of mmq q10 mmq q50 mmq q90 mmq and the percentage of time that zero flows are expected then it is accepted as behavioural and the parameter set is saved for later use in stage 2 v3b the model run stops when the user defined number of behavioural parameter sets has been generated the key issue is that not only must the constraint indices be compatible with each other e g flow duration curve 90th percentile must be compatible with the groundwater recharge constraint but the input parameter ranges must also be compatible with the constraint index ranges e g the groundwater parameters should be compatible with the groundwater recharge constraint index range there are built in facilities to guide users in the calibration of the input parameter ranges to ensure that they are appropriately compatible and to ensure the efficient achievement of the required number of behavioural ensemble outputs given the specified total number of possible model runs the third version of the model runs the model many times typically 10 000 for the whole basin to generate cumulative flows at each sub basin outlet this can be based on independent random sampling of the input parameter ranges v3a unconstrained uncertainty assessment or it can be based on re sampling the complete parameter sets that were saved during the stage 1 model runs referred to above v3b constrained uncertainty assessment in both cases if there are observed data available the outputs include a range of objective functions that can be used to evaluate individual ensemble members against the available observed data the former can be useful to explore parameter equifinality and sensitivity hughes and farinosi 2021 while the latter represents the second stage of the 2 stage uncertainty approach based on hydrological index constraints both of these options have been used in this study the final version is similar to the third except that the input rainfall data consists of ensembles rather than a single time series each rainfall input typically 500 is used in combination with either unconstrained v4a or constrained v4b parameter sampling to generate simulated flow ensembles that represent a combination of climate and parameter uncertainty this version has been used in climate change assessments hughes and farinosi 2020 but is not used in this study these model versions are well suited for the congo basin because it is known as one of the most ungauged tropical basins where the majority of the available gauging stations reflect cumulative flow characteristics making it difficult to distinguish the incremental flow contributions from different upstream sub drainage systems through the regionalised hydrological indices it is possible to identify behavioural parameters that reflect the sub basin s incremental flow contributions the model also provides the possibility of accounting for a sub basin s development conditions such as water abstraction e g reservoirs and different types of regulations e g hydropower dams in the stage 2 v3b of the modelling approach in addition the general model structure fig 3 provides a function that deals with wetlands where they are expected to exert considerable impacts on downstream flow regime 3 2 steps in the analysis in an iterative process kabuya et al 2020b identified the aridity index as the main predictor of the hydrological response across the basin the authors used climate and physiographic attributes topographic wetness index slope fractions of silt sand clay and curve number that are known to have potential relationships with sub basin hydrological response characteristics buchanan et al 2014 beck et al 2015 zeng et al 2017 they indicated that due to the scarcity of available headwater gauging stations it was impractical to develop predictive equations of the hydrological response for each identified physiographic region of the congo basin therefore the alternative approach of developing generic predictive equations for the whole basin was adopted with the aridity index producing the best results for all of the hydrological indices used however the authors did expect that this would pose some problems in areas where there may be additional factors apart from the aridity index that determine differences in hydrological response kabuya et al 2020b this challenge and others related to the temporal scaling of the constraints and identified convergence of the uncertainty bounds at low aridity index values are addressed in this analysis 3 2 1 step 1 temporal scaling of the constraints it is possible that the streamflow constraint indices are not independent of the time period being simulated kabuya et al 2020b indicated that while every attempt was made to adopt a similar period for all the gauges used in the regional analysis of hydrological indices the large differences between the gauges used and the lack of suitable adjacent stations available to extend the series means that quite different periods were used in some cases therefore the initial step in the assessment analysis is to re calculate the hydrological index range for the common simulation period used in this study 1901 to 2014 this involved using the unconstrained uncertainty model version v3a fig 4 and finding the ensemble that most closely matches the observed streamflow data for the common overlap period the hydrological indices mmq q10 mmq q50 mmq and q90 mmq were then calculated for the selected ensemble for the overlap period and for the total period and checked to identify if there were any significant differences 3 2 2 step 2 critical analysis of the constraint predictive equations the uncertainty bounds that were reported in kabuya et al 2020b fig 11 were based on fitting power relationships to the 5 and 95 confidence intervals around the regression relationships however it was subsequently noted that for both mmq and q90 mmq the lower and upper bounds started to converge at low aridity ai values given that a later step in the analysis see the results section uses downward adjustments to the ai values step 5 it was necessary to remove this convergence and new uncertainty bounds were established that were also extended to much lower ai values the results of this analysis as well as the equations for the uncertainty bounds are presented in appendix 1 3 2 3 step 3 constraints compatibility check and establishing behavioural sub basin parameters there is no guarantee that the groundwater recharge values of döll and fiedler 2008 are compatible with the low flow responses of the observed streamflow it was therefore necessary to check these as a first step in the application of model version 2 if they are not compatible then the approach will never find any behavioural simulations regardless of the parameter sets used fortunately the software utilities available see ndzabandzaba and hughes 2017 for further details and examples with the model allow these types of incompatibility to be determined quite efficiently this part of the initial processing therefore established new groundwater recharge constraints where necessary the initial model parameter ranges table 1a were established based on previous modelling experience in the congo river basin tshimanga and hughes 2014 kabuya 2020 in this study only model parameters responsible for a sub basin s natural hydrology 19 are used to simulate behavioural sub basin responses and five were considered as fixed values leaving fourteen being considered as uncertain and sampled using a uniform probability distribution 3 2 4 step 4 generating total cumulative flows model version 3b fig 4 is then run to generate ensembles of total cumulative flow at all of the gauging sites during this process some of the downstream routing parameters can also be considered fixed or uncertain no water use parameters were used in this study as all the gauges are considered to represent largely un developed conditions nilsson et al 2005 santini and caporaso 2018 a further option in versions 3 and 4 a and b of the model allows for the parameter sampling across all sub basins to be totally independent or grouped according to some user defined criteria of sub basin similarity in the former the uncertainty band downstream of a group of sub basins will be generally lower given that all of the upstream sub basins will contribute relatively wet or dry incremental simulations in a random manner in the latter the sampling scheme is such that generally wetter or drier simulations will be linked for all sub basins in the same group suggesting a higher band of uncertainty downstream 3 3 evaluation of model performance an additional utility program can be used to post process the time series ensembles to generate five time series representing the minimum the 5th 50th and 95th percentiles and the maximum simulated flows for each month of the total time series the 5th and 95th percentiles provide useful upper and lower uncertainty bounds covering 90 of all the simulated ensembles and excluding any outliers it should be noted that the simulation uncertainty bounds are a result of the uncertainty bounds derived from the regional analysis of the hydrological indices that are used to constrain the model in both gauged and ungauged basins ndzabandzaba and hughes 2017 kabuya et al 2020 they are therefore not arbitrary but represent the uncertainty in our understanding of regional differences in hydrological response whether or not the final simulation bounds are appropriate for any specific practical use e g the design of reservoir storage or abstraction operating rules is important but out of the scope of this paper the simulated uncertainty bounds can be compared with the observed flows at both headwater and downstream gauging stations using either hydrographs or flow duration curves fdcs but other performance measures nash and sutcliffe 1970 krause et al 2005 moriasi et al 2007 wöhling et al 2013 waseem et al 2016 such as nash sutcliffe coefficient of efficiency and mean monthly runoff bias for both untransformed ne and bias and transformed values ne ln and bias ln can also be used to assess individual ensembles in this study the key performance measures used are based on the extent to which the observed time series or percentage points on the fdc fall within the four quartiles representing the uncertainty band of the simulations for the same month or percentage point values of 0 and 3 for this containment index represent conditions where the observed data lie at the low or high end of the simulated range while 1 and 2 indicate that the observed data lie in the middle of the range similarly values of 1 or 4 indicate that the observed data fall outside the uncertainty range the purpose of the results evaluation is therefore to determine how many of the calibration and validation gauges have a high proportion of observed data that fall outside the simulated uncertainty bounds and to look for any patterns that might point to how the regionalisation can be improved using additional information about the sub basin characteristics the key issue is that the observed data are not used directly to calibrate the model although some of these data are used to develop the hydrological index constraint bounds the observed data are therefore mainly used to assess the extent to which the constraint bounds can be used to generate appropriate simulations in ungauged sub basins 4 results 4 1 assessment of the initial groundwater recharge estimates as mentioned before it is important to ensure that the ranges of the groundwater recharge estimates mmr are compatible with the q90 mmq constraint in many cases the results have shown that the groundwater recharge values of döll and fiedler 2008 were incompatible with the q90 mmq constraint and therefore were revised for consistency in the simulation of low flows fig 5 in stage 1 of the modelling framework since the original mmr values are model dependant it was expected that their use in this modelling exercise would constitute one of the major sources of uncertainty associated with low flows conversely there are also some sub basins in the upper lualaba kasai rift valley and batéké plateaux where the revised mmr values fall within the original range suggesting that this global data do have some value for constraining the groundwater components of a hydrological model 4 2 initial assessment of the results as noted above the first step prior to running the model was to check whether adjusments to the constraint values were required given the longer period of modelling compared to the observed data periods used for developing the regionalisation the large majority of the adjustments required were less than 5 and most are not considered likely to have any real impact on the results table 4 presents the results of the analysis using the output from the constrained version of the model based on identifying the number of months in either the time series or the fdcs where the observed data are bracketed by the simulated uncertainty bounds using the 95 and 5 exceeded values columns 3 to 5 list the number of months in the time series where the observed data are below within or above the simulated bounds while columns 6 to 8 repeat this information but using the fdcs the final three columns list the quartiles of the simulated bounds in which the observed data lie for the three key percentage points values between 0 and 3 indicate that the observed data are within the simulated bounds negative values indicate situations where the observed data are below i e over simulation while positive values indicate where the observed data are above i e under simulation the first observation is that even where the fdc results are acceptable where the last 3 columns of table 4 are all 0 or 3 and a high value for column 7 the of observed data falling within the simulation bounds for the time series column 4 is typically quite low maximum value of 47 for l cb261 fig 6 this is quite a common issue in data scarce regions where even if the input gridded climate data are acceptably representative of the overall seasonality and intra annual variability individual monthly rainfall values might be poorly representative of reality this means that the fdcs of the resulting simulated flows may be acceptable but there may be parts of the time series that are not very well simulated the second observation is that while there are some sites in both the calibration and validation data sets that show good results or at least adequate for parts of the fdc fig 7 a and 7b there are also many that are totally inadequate with extremely high positive quartile index values extreme under simulation fig 7c and some quite high negative values moderate to high over simulation fig 7d the remainder of this results section is therefore focused on attempting to resolve some of these discrepancies by identifying possible reasons why the regionalisation has failed in some areas and using the outcomes of this investigation to revise and improve the regioanlisation approach the order in which the sub basins are discussed is largely determined by the scale of the discrepancies between the observed data and the simulated uncertainty bounds 4 3 reassessment of the results one of the largest discrepancies between the simulations and the observed data occur for l cb191 a total of 12 sub basins lying near the rift valley to the west of rwanda and it is immediately evident that this area has high slopes 10 and some 20 relative to nearly all the rest of the congo river basin this observation prompted the use of a slope correction factor to reduce the aridity index in sub basins with slopes greater than about 7 after some trial and error attempts to find a suitable correction approach eqs 1 and 2 were used for adjusting the aridity index ai that is applied to the regional estimation equations for mmq and q90 mmq with the condition that the adjustment factors are limited to a maximum value of 1 for slopes of 8 or less both adjustment factors are relatively close to 1 while for a slope of 20 the mmq adjustment factor is 0 3 and the q90 factor is 0 7 reference to fig 2 suggests that the effects of reducing the ai value by these amounts will vary with the original ai value and have a large effect for ai values of less than about 0 8 the rationale for a lower q90 correction factor is that the actual q90 value will be affected by both an increase in the mmq constraints as well as in the q90 mmq constraint the adjustment factor required for the ai value used with the q10 mmq and q50 mmq relationships was expected to be less and was set to half way between 1 and the aiadjq90 value the format of eqs 1 and 2 was largely guided by the initial results for l cb191 but c cb138 and c cb169 also included sub basins with quite high slopes and can therefore be used to test the slope adjustments 1 a i adj mmq ln slope 3 8 2 a i adj q 90 ln slope 1 2 1 after applying the slope adjustments to l cb191 the results improved substantially table 4 2nd row for l cb191 but the under simulation remained it was further noted that many of the sub basins in the upper parts of the catchment have lower cru rainfall and higher ai values than the lower areas which appears to be somewhat counter intuitive the unidel rainfall data also show a similar pattern but the rainfall based on a water balance table 5 using modis actual evapotranspiration data observed runoff depth modis aet suggest rainfalls that are much higher for the upper parts of the catchment after the lower rainfall sub basins were adjusted to increase the total basin weighted rainfall by some 15 the results improved substantially table 4 3rd row for l cb191 the rainfall adjustments applied were very simplified given the lack of any detailed evidence that could be used for individual sub basins it is also acknowledged that the evidence for the adjustments is not very precise given the uncertainties inherent in the modis aet estimates however the balance of evidence suggests that they are justified even if the actual adjustments are not likely to be at all accurate for c cb169 batéké plateaux the original results suggest very high levels of under simulation for moderate to low flows and the observed flow duration curve has a very low slope which is inconsistent with the simulated constraint ranges the slopes are generally quite high 9 5 to 13 3 and the slope adjustments certainly improve the simulations table 4 the unidel rainfall is some 14 higher than the cru data table 5 and if the unidel data are used to force the model not only will there be more rainfall available but the ai values also decrease both of which improve the simulations table 4 3rd row for c cb169 but low flows remain under simulated these sub basins are the main ones draining the batéké plateaux and the major river valleys are deeply incised with floodplain wetlands this suggests the possibility of some high flow attenuation which was roughly simulated using uncertain ranges for the channel routing parameter in the second stage run of the model i e not affecting the sub basin incremental flow simulations driven by the estimated constraint ranges but only the routing through the sub basins this improves the results further table 4 4rd row for c cb169 despite the approach being a very simplified way of accounting for possible floodplain and wetland attenuation effects the original results for c cb138 inkisi suggest quite high levels of under simulation notably for low flows and the influence of the slope adjustments is quite small as the slopes are mostly about 8 or less there is some evidence from the water balance calculations table 5 that the rainfall might be slightly under estimated and there is some evidence that the mmq value based on the relatively short observed data period 1951 to 1959 under represents the long term mmq by some 10 applying these adjustments gives slightly better results table 4 but the observed flows remain under simulated the observed flows for k cb259 upper kasai are quite highly under simulated for moderate to low flows table 4 the slopes are all quite low but the basin is long and quite narrow suggesting that channel attenuation may play a role applying the channel routing parameter gives some improvements and this could have implications for other ungauged rivers in the south western partf of the congo river basin many of which have similar basin shape characteristics fig 1 l cb200 201 and 202 are gauged sub basins of lcb18 table 2 while l cb230 is in the same area while the results for the downstream site l cb18 table 4 improved the results for the smaller headwater catchments did not change much with some being under and others being over simulated l cb200 lcb202 and l cb230 remain quite highly under simulated for moderate to low flows and there is no currently available evidence to suggest why this region has an apparently different low flow regime than other parts of the total basin however previous work unpublished but including field observations in these zambian catchments confirm that sustained flows occur throughout the dry season it is possible that there is an influence related to geology but we were unable to identify any data sources that could suggest any unique characteristics of the geology that would contribute to sustaining low flows c cb185 itimbiri is generally over simulated particularly for moderate to low flows while the slope adjustment changes do not affect this set of sub basins the water balance check using modis aet data table 5 suggest that both the cru and unidel rainfalls could tend to over estimate the available moisture and the constraints were re set and the model re run with the cru rainfall data scaled by 94 the results are certainly better with low flows still being somewhat over simulated table 4 the results for the remaining sub basins were generally quite good or only moderate over or under simulated and the revisions did not change the situation very much with some improving slightly and others being somewhat poorer however table 4 indicates that in general terms the revisions have generated improved results s cb236 in the northwestern sub basins represents one of the few sub basins where there is a relatively large difference between the mmq for the short observation period 1951 to 1970 and the longer simulation period however the overall result did not change very much it is also an area that has very high forest cover and one of the changes that was made was based on turning off the surface runoff generation part of the model and simulating all flows as either interflow or groundwater discharge this improved the results table 4 partly because the final simulations had a larger uncertainty range than the original ones based partly on surface runoff generation 5 discussion fig 8 illustrates the frequency distributions of the containment indices for the original and revised simulations it is evident that there are relatively few changes in the q10 and q50 indices apart from the fact that some of the small number of large under simulations have been improved there are also quite a high number 20 gauging stations where the observed data were totally within both the original and revised simulated bounds there are far fewer 15 gauging stations where the low flows q90 are successfully simulated and there remain quite a high number where the low flows are either under simulated mostly or over simulated after the revisions to the constraint values this result could almost have been predicted given the large spread in q90 mmq values shown in fig a1 appendix 1 while some of the identified adjustments have improved the situation there are evidently other factors that have not been accounted for that cause quite large differences in low flow response in different parts of the congo river basin some of the adjustments made have been based on including the channel routing parameter to attenuate high flows and increase lower flows this parameter has the greatest impact on downstream flows from a number of upstream sub basins and has already been justified in some sub basins c cb169 and k cb259 but it may also apply in others where there is expected to be high flow attenuation however it is not a simple matter to identify those areas where the use of the channel routing parameter can be justified based on measurable physical characteristics tshimanga and hughes 2014 differences in land cover have not been taken into account in the regional analysis of the constraint values largely because there were no clear signals in the orginal analysis kabuya et al 2020b possibly because of the relatively small data set there are also no clear signals in the current analysis and therefore the effects of land cover on runoff ratio and the shapes of fdcs remain largely unknown for the congo river basin the effects of increased evapotranspiration losses from forestry areas has largely been accounted for through uncertainty ranges in the annual potential evaporation demand but differences in this range have not been fully related to the area of forest cover the lower value of the range has been set to the iwmi estimates http www iwmi org which could under estimate evapotranspiration losses in densely forested areas however this would mainly increase the simulated range of at least some of the constraint indices during the simulation runs it was noted that some of the simulated ranges were relatively low and certainly lower than the input constraint ranges this has the potential to exacerbate any over or under estimates relative to observed data as the quartiles of the simulated range will be quite small it is therefore considered to be important to ensure that the simulated ensembles cover the range of the input constraints i e are not biased to either extreme or concentrated in a small part of the range to ensure that the results reflect the input constraints rather than any bias in the model simulations within these constraints however this is not always straightforward to achieve given the large parameter space and inherent equifinalities hughes 2016 her and seong 2018 one observation is that it is often better to fix some of the parameters to achieve more clearer control over the uncertainty in the outputs i e reduce the equifinality in the uncertainty the situation for s cb236 including s cb332 illustrates this problem in that the original simulated range of the q10 mmq constraint was always limited to a narrow band within the middle of the input range various combinations of the surface runoff parameters affecting high flows made very little difference to this result while turning off the surface runoff generation parameters and focusing on simulating high flows with the interflow function made a large difference this is a justifiable result for a heavily forested area and it would be worthwhile to assess whether this approach would be beneficial in other heavily forested areas despite the fact that many of these already have acceptable results it should be noted that in the case of s cb236 table 4 all of the observed values for the constraint indices are well within the regionalised uncertainty ranges input to the model it is therefore evident that at least some of the results that show containment indices that are just outside of the ideal range of 0 to 3 are a modelling artefact where the observed data are inside the input constraint ranges but the model has generated an output range that is narrower and biased toward one end of the input range the same principles could be applied to c cb218 ruki ingende which has 10 sub basins table 2 all of which are forested one of the observations is that while the observed data have values for the constraint indices that fall within the input uncertainty range the observed q50 mmq and q90 mmq are close to the upper end of the uncertainty range the unidel rainfall data are some 8 higher than the cru data and using the unidel data has the effect of lowering the aridity index which in turn increases the runoff ratio q50 mmq and q90 mmq while slightly decreasing the q10 mmq constraint this effect places the observed constraint indices more within the input constrain ranges as well as providing more water re running the model with the new constraints and the increased rainfall improved the results with the three key containment indices largely improving q10 3 q50 1 and q90 2 the nash sutcliffe efficiency values also improved from approximately 0 3 for both untransformed and ln transformed data to values of better than 0 55 across the ensemble set this result offers further support for replacing the cru rainfall data with the unidel data for this set of sub basins it was also noted that the short record 97 months of available data creates an observed fdc that is not smooth and with quite large changes within a few percentage points particularly at the extremes making the containment results very sensitive to the exact percentage points chosen for comparison the overall result shows the ensemble of flow duration curves that were very close to the observed data for the most part but this was achieved with a low uncertainty range which meant that even relatively small deviations outside this range by the observed values lead to poor containment index values at some percentage points the conclusion for this site is that possible problems with the rainfall data possibly also the short record of observed flows combined with possible effects of forestry make the original constraint indices inappropriate table 1a one of the issues that is extremely difficult to account for is uncertainties in the observed streamflow input rainfall and evaporation demand data largely because there are not enough alternative datasets to confirm or deny the appropriateness of the data that have been used some attempts were made to use modis aet data and alternative rainfall data sets unidel to assess the validity of the cru data in some cases this analysis pointed to some potential problems in the cru data but the modis data are also very uncertain ruhoff et al 2013 velpuri et al 2013 as evidenced by some very low values in some areas table 5 the effects of all these data uncertainties has a compound effect they not only affect the simulations themselves e g not enough rainfall to force the model to achieve the observed outputs as noted for parts of l cb191 but they also affect the regional relationships that are used to quantify the input constraint values because they impact on the aridity estimates kabuya et al 2020b given that these compound effects could be quite different for each of the sub areas used in this analysis i e the uncertainties are likely to be quite random in their effects it is very difficult to resolve them to improve the results it is important to note that the model can be calibrated to closely reproduce the shapes of all the observed flow duration curves even if the statistics of fit for the time series can frequently be quite poor e g nash sutcliffe efficieny values of less then 0 4 in kabuya 2020 the key issue is therefore not that the model cannot be parameterised to generate appropriate responses but that the constraints which are model independent in combination with the input forcing data used do not generate outputs that are always a match to the observed data there are some situations where the model is not able to generate ensembles with constraint index values that are evenly distributed across the various input constraint ranges this is possibly because some parts of the input constraint ranges are incompatible with each other and the model is not able to generate ensembles that match the full ranges of multiple constraints one of the consequences of this is that the final uncertainty range of ensembles is much narrower than the input range of the constraints and even if the observed data are close but not within the range the containment indices suggest a poor fit notwithstanding these rather negative comments about the results fig 8 suggests that quite for a large proportion of the sub basins the results are quite good while the details for all sub basins in table 4 suggests that there is no real difference between the calibration and validation sites 6 conclusions the overall conclusion is that the orginal regionalised constraint indices based soley on aridity index are appropriate in many sub basins but not all further detailed examination of these results suggested that the effects of high slopes prevelant in a relatively small number of sub basins could increase the runoff ratio and q90 mmq values and that implementing an adjustment factor based on slope did improve some of the very poor results however it was also clear that some of the cru rainfall data under represented the real rainfall in some areas and this also removed some of the gross under simulations it was recognised that there are missing data in the cru dataset at the start and ends of the total record these are represented by mean monthly values in the time series an indication that there are few local data available to generate the gridded values the worst affected areas the most years with mean monthly values stretches across the total basin in a band from the south west to the north east and mainly covers sub basins c cb188 and c cb218 used in this analysis but also covers many ungauged sub basins not included here attempts to apply a water balance approach using observed flows plus modis aet data to compare with the available rainfall data were largely inconclusive because of some clearly incorrect modis values future studies ideally need to more critically assess the rainfall data used to force the model and in the absence of data to validate any rainfall products could consider the use of uncertain rainfall inputs into the model using a range of different rainfall products including satellite derived estimates to quantify the uncertainties multiple information sources of remote sensing products e g satellite water level observations jung et al 2010 may be also useful in the larger rivers to supplement in situ observations some minor improvements were made through the use of the channel routing parameter to reduce high flows and this approach was applied where there is some evidence that upstream high flows could be attenuated however this concept was not applied to all other sub basins partly because it is not always straightforward to identify where attenuation effects might be applicable there is some evidence that land cover and particularly the effects of dense tropical forest should be part of the approach to the regional estimation of the constraint indices however once again this result is far from conclusive as the effects do not appear to apply to all the sub basins that have high proportions of forest one of the recommendations for further work is that this issue should be investigated in more detail both from an empirical i e looking at response differences across all forested areas using the available observed data and conceptual persepective the conceptual perspective should include considerations of the likely runoff generation processes across all forested areas and how these should be represented in the model parameter sets some of the sub basins in the zambian part of the congo river basin appear to have very sustained dry season low flows resulting in higher q90 mmq values than other areas and certainly values that are at the very high end of the regional ranges for this constraint index we could not find any information that would explain this characteristic of the flow regimes and this also requires further investigation there is some evidence to suggest that sites with quite short records less than 10 years and sites with high proportions of missing data can skew the results even though only the simulated values that were matched with available observed data were included in the containment analysis there is very little that can be done to improve this situation although it is possible that some form of observed flow data patching could be attempted this type of approach however might simply end up adding another layer of uncertainty into an analysis that is already very uncertain it should be noted that previous work tshimanga et al 2011 tshimanga and hughes 2014 conducted in the congo basin has demonstrated that the pitman model can be calibrated with acceptable statistics in most gauged basins nash sutcliffe coefficient of efficiency for the majority of the gauging stations range from 0 5 to 0 9 and is therefore considered applicable to the region however this does not help to decide how to set the model up for all the many ungauged sub basins in the remainder of the basin the current paper attempted to address this problem by applying regionalised indices of sub basin hydrological response characteristics and testing the approach using the same gauged basins used in the regionalisation as well as a set of validation gauging stations that were not previously used most of the validation stations are downstream of multiple sub basins and therefore the validations are based on applying the regional constraint indices to sub basins and then assess whether the cumulative simulated flow bounds at the gauges are comparable to the observed data in terms of both fdc characteristics as well as their time series variations this study has not reported on the differences between parameter values across the sub basins partly because this would take up a great deal of space in an already lengthy paper and partly because the main focus of the study was to evaluate the regionalised constraint indices which are model independent however it is recommended that future studies should look at this issue more closely and try to ensure that there is a degree of consistency in the way in which the responses of sub basins with similar characteristics are simulated by the model credit authorship contribution statement pierre m kabuya conceptualization methodology writing original draft writing review editing denis a hughes supervision software writing review editing raphael m tshimanga data curation mark a trigg writing review editing paul bates writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the funding support of the congo river user hydraulics and morphology cruhm project which is wholly funded by the royal society dfid africa capacity building rs dfid under the grant number aq150005 paul bates is supported by a royal society wolfson research merit award the modelling tools spatsim and pitman model used in this study have been developed at the institute for water research rhodes university and can be accessed through the rhodes university website https www ru ac za iwr research software spatsim the model setup for the congo can be accessed by directly contacting the corresponding author appendix 1 re assessment of the constraint index regional relationship uncertainty bounds the runoff ratio rr used to calculate mmq bounds required extending to account for lower aridity index ai values after they have been adjusted downwards by the effect of slope the extensions of the two bounds are based on linear extrapolation of the slopes of the main bound relationships fitted to the 5 and 95 confidence limits of the regression equations eqs a1 and a2 between ai values of 0 75 and 0 65 fig a1 a suggests that this approach may under estimate the upper bound values for low ai for ai values 0 65 a1 rr lower 1 2944 ex p 2 508 ai a2 rr upper 0 2608 a i 0 951 for ai values 0 65 a3 rr lower 0 254 0 5758 0 65 ai a4 rr upper 0 395 0 5 0 65 ai the q90 mmq bounds also needed extending and the same approach was used for ai values 0 65 a5 q 90 mmq lower 0 4975 a i 2 1 4935 ai 1 1334 a6 q 90 mmq upper 0 4077 a i 1 037 for ai values 0 65 a7 q 90 mmq lower 0 373 0 8 0 65 ai a8 q 90 mmq upper 0 637 0 879 0 65 ai there is no need to extend the q10 mmq and q50 mmq bound relationships as the slope adjustments are smaller and the relationships fitted to the confidence limits are smoother without any signs of convergence at low or high ai values a10 q 10 mmq lower 1 635 a i 0 843 a11 q 10 mmq upper 2 4425 a i 0 5614 a12 q 50 mmq lower 0 58 a i 0 695 a13 q 50 mmq upper 0 8383 a i 0 599 
223,the hyporheic zone provides opportunities for the turnover and removal of nutrients such as ammonium and nitrate from stream water hyporheic flow patterns and dynamics govern the transport of nutrients and other solutes through the hyporheic zone and in turn control their transformation and removal to better understand the links between flow and turnover we systematically studied nutrient turnover rates with simulated sets of idealized streambed domains which varied in domain depth hydraulic conductivity its heterogeneity and anisotropy we show that both aerobic e g nitrification and anaerobic e g denitrification turnover rates generally decrease monotonically with decreasing sediment conductivity at sufficiently large hyporheic zone depth however a reduction of the domain depth leads to an optimum of anaerobic turnover rates at intermediate conductivity due to the rate or transit time limitations of the reaction at the far ends of the conductivity range furthermore conductivity heterogeneity generally lowers the turnover rates of both aerobic and anaerobic reactions it is demonstrated how to reproduce this reduced nutrient turnover in heterogeneous sediments via a simplified anisotropy which facilitates the prediction of turnover rates in heterogeneous sediments in certain cases our results foster the understanding of the interplay between hyporheic exchange and nutrient transformations and they aim to facilitate the conceptualization of large scale numerical simulations by demonstrating the effect of study design decisions like domain extent heterogeneity and anisotropy 1 introduction the exchange of water between streams and their hyporheic zones provides essential ecosystem services within fluvial networks such as the provision of habitat and thermal refugia buffering of stream temperatures as well as biogeochemical processing of nutrients boano et al 2014 gooseff 2010 and references therein hyporheic exchange flows are induced by morphological structures covering a variety of spatial scales ranging from meanders to ripples morén et al 2017 s h stonedahl et al 2010 as hyporheic zones are regarded to play an important role for nutrient processing it is essential to understand the factors controlling reactions in the hyporheic zone bardini et al 2012 morén et al 2018 trauth et al 2014 biogeochemical reactions are controlled by hyporheic exchange flows supplying subsurface microbial communities with oxygen organic carbon and nutrients the resulting biogeochemical zonation is related to transit times in the hyporheic zone for example net nitrification dominates along flow paths with short transit times whereas net denitrification dominates along flow paths with long transit times zarnetske et al 2012 the different temporal scales coincide with typical spatial scales large scale hyporheic exchange generates long transit times and vice versa s h stonedahl et al 2013 however most of the hyporheic exchange flux is generated in small scale structures s h stonedahl et al 2013 s h 2010 the transit time controls if the hyporheic flow reaches anoxic conditions and thus facilitates the potential for denitrification zarnetske et al 2012 the relationship between reaction time scales and transit time scales can be described by the damköhler number da oldham et al 2013 zarnetske et al 2011 da of oxygen as inhibitor of denitrification has been applied in hyporheic zone studies to predict whether the hyporheic zone is a net no3 source or sink zarnetske et al 2012 generally damköhler numbers have been demonstrated to be useful for relating transport and reaction times scales in various hydrological systems lewandowski et al 2019 marzadri et al 2012 ocampo et al 2006 oldham et al 2013 the concept of damköhler numbers originates from chemical engineering where the transit time in a reactor needs to be optimized with respect to the reaction time however unlike technical reactors natural systems such as the hyporheic zone usually exhibit broader transit time distributions this is due to naturally non uniform flow paths and due to the fact that natural flow systems are not always constrained to a fixed reaction volume in geological configurations where the impermeable lower boundary is sufficiently deep even flow paths induced by small morphological structures can generate long and deep hyporheic flow paths here we refer to such cases as unconstrained settings these deep flow paths are typically not represented in da calculations of hydrological systems as da is usually calculated based on a single representative transit time value like the mean or median transit time harvey et al 2013 marzadri et al 2012 shelley et al 2017 tonina et al 2016 zarnetske et al 2012 especially for transit time distributions with high variance a summary statistic like the mean or median does not reflect the full complexity of transit times transit times that represent the margins of the distribution may be characterized by damköhler numbers that deviate substantially from those represented by the mean transit time often this simplification is justified because the deep flow paths often contribute only a minor part to the bulk flow increased hydraulic conductivity k results in an overall increase of hyporheic exchange flow as a result deep and long flow paths of unconstrained settings that otherwise carry only low flux can become relevant for the biogeochemical reactivity of the system however only theoretical models employ such an infinite depth of the hyporheic zone bottacin busolin and marion 2010 elliott and brooks 1997 in reality hyporheic flow cells are more or less depth limited by a number of factors such as ambient groundwater flow cardenas and wilson 2007 trauth and fleckenstein 2017 and flow induced by larger scale features azizian et al 2017 boano et al 2008 bottacin busolin and marion 2010 fox et al 2016 tonina et al 2016 or from confining subsurface structures such as bedrock and clay layers gomez velez et al 2014 the shape of the transit time distribution results not only from the combination of hydraulic gradients and patterns of k but also from the spatial constraints of the hyporheic zone a systematic analysis of the interplay between hydraulic conductivity and hyporheic zone volume and its effects on biogeochemical reactions is currently missing in our understanding of the hyporheic zone a consequence of different hyporheic zone volumes is that the shape of the transit time distribution varies particularly in geologically unconstrained settings of hyporheic exchange high variance transit time distributions occur as a consequence da may need to be represented by a distribution rather than a single value in such cases substantial denitrification can occur in the deeper low flux zones even if the mean da would suggest prevailing overall aerobic conditions in this study we systematically analyze the effects of hydraulic conductivity sediment heterogeneity and reaction volume constraints on the potential for denitrification by using a numerical reactive transport model we hypothesize that if the hyporheic reaction volume is strongly restricted the potential for nitrate removal per streambed area via denitrification has its maximum where the ratio between the median transit time and the reaction time da is close to unity in this case the hyporheic zone can be conceptualized as a chemical reactor with a narrow transit time distribution in other words if the sediment k is higher than the optimum rate limitation becomes the controlling factor and the total denitrification rate decreases in contrast if the hyporheic reaction volume is less restricted an increase in k could trigger higher absolute denitrification potential this would hold even if the da based on the median transit time decreases substantially below unity i e one would expect rate limited conditions this is because denitrification predominantly occurs in the deeper low flux zones which are insufficiently represented by a single da based on a mean or median transit time representing the entire system we further hypothesize that heterogeneous sediment generally has a lower denitrification potential than a homogeneous sediment of equal median transit time that is because hyporheic flux in heterogeneous sediments is focused on highly conductive flow paths which typically results in a reduction of the effective volume of the hyporheic zone laube et al 2018 we additionally demonstrate the use of our previously developed method of an anisotropic homogeneous sediment as a representation for a heterogeneous sediment laube et al 2018 to prove its utility in the context of reactive transport simulations 2 methods we designed a set of numerical simulations of a 2d reactive hyporheic zone at ripple scale including homogeneous heterogeneous and anisotropic sediments of different conductivity and three different depth restrictions we simulated the reactive transport in these domains using representative reaction kinetics for denitrification nitrification and aerobic respiration 2 1 simulated scenarios a systematic investigation of the effect of k on denitrification is most interesting where a change in k could shift transit times close to critical time thresholds where e g denitrification might be inhibited by the presence of oxygen those short transit times are typically generated by small scale morphological structures in the stream like ripples and smaller pool riffle sequences azizian et al 2017 trauth et al 2014 as opposed to longer transit times e g in parafluvial flows through inter meander zones as we are interested in the effects of streambed heterogeneity on transitions between oxic and anoxic regimes in the hyporheic zone we focus on the ripple scale to study the effect of k variations on denitrification aerobic respiration and nitrification accordingly we simulated a simplified rectangular 2d representation of a rippled streambed of x 2m length and varying depth for the numerical investigation of hyporheic nutrient turnover the simulations were conducted via min3p the ripples were represented by a sinusoidal head boundary over a flat bed the head variations were calculated as proposed by elliott and brooks 1997 for ripple height of h 1cm stream velocity of u 10cm s stream depth d 20cm and wavelengths of λ 20cm the domain and boundary conditions are equal to the ones in laube et al 2018 except for the slope in the head boundary and the variations in domain depth to test the hypotheses a total of 1600 simulations were carried out the different scenarios of reaction volume constraints heterogeneity and anisotropy can be categorized in seven groups fig 1 the base group hom50cm contained 200 simulations with z 50cm domain depth i e z 2 5 λ and each with one homogeneous k out of a range of 13 5 ln k 1 5 ln m s the other six groups are variations of this base group the simulations in the groups hom20cm and hom10cm were equivalent to the ones in hom50cm but with 20 cm and 10 cm domain depth i e z λ and z λ 2 respectively these two groups aimed at showing the effect of a restricted domain depth which translates to a restricted reaction volume the groups het1 and het2 consisted of 300 simulations each with a heterogeneous k distribution in het1 and het2 heterogeneous sediment was represented by gaussian random fields with randomized correlation lengths and correlation angles and a fixed variance of microscopically isotropic log conductivity σ ln k 2 1 0 and σ ln k 2 2 0 respectively in both heterogeneous groups the median k varied between 13 5 μln k 1 5 ln m s see laube et al 2018 for details with respect to the gaussian random fields finally aniso1 and aniso2 with 200 simulations each varied through an anisotropic homogeneous k tensor the anisotropic simulations aimed to expand the idea of laube et al 2018 that the hyporheic volume reduction and thus the hyporheic transit time and exchange flux of heterogeneous sediment can sufficiently be matched by a homogeneous model with anisotropic k we tested this empirical simplification of the complexity of heterogeneity for its usability in geochemical calculations the according anisotropy ratio was calculated by 1 r k xx k zz exp 1 06 σ ln k 2 where σ ln k 2 is the variance of the hydraulic conductivity of the targeted heterogeneous sediment and kxx and kzz are the horizontal and vertical conductivity of its anisotropic representation see laube et al 2018 for detailed reasoning why this specific anisotropy ratio has been chosen as an equivalent to the heterogeneous domains aniso1 and aniso2 were designed to be the anisotropic equivalents to het1 and het2 with r 1 exp 1 06 i e σ ln k 2 1 moderately heterogeneous and r 2 exp 2 12 i e σ ln k 2 2 strongly heterogeneous just like the other groups the 200 simulations of each group ranged over conductivities of 13 5 ln kxx 1 5 ln m s and kzz kxx r it should be noted that we intentionally chose boundary conditions without a slope a constant head slope leads to an underflow underneath the hyporheic zone this underflow limits the depth of the hyporheic flow cell the effect of a depth limitation however was already investigated with the hom50cm hom20cm and hom10cm cases bottacin busolin and marion 2010 developed a model to calculate the depth limitation of the hyporheic zone caused by underflow based on the underflow velocity our findings could be translated accordingly 2 2 reactions the setup of the reactive transport model for the hyporheic zone was chosen to represent reaction kinetics that are commonly reported in literature for the following reactions aerobic respiration c h 2 o o 2 c o 2 h 2 o nitrification n h 4 2 o 2 n o 3 h 2 o 2 h denitrification 5 c h 2 o 4 n o 3 4 h 5 c o 2 n 2 7 h 2 o we selected concentration boundary conditions table 1 such that hyporheic nitrate concentrations under aerobic conditions were dominated by nitrification whereas denitrification dominated the nitrate concentration in anaerobic conditions fig 2 doc concentrations were chosen high enough to prevent electron donor limitations this is in line with other studies where carbon limitation is often reported to be negligible due to additional carbon sources like particulate organic carbon peyrard et al 2011 trauth et al 2015 zarnetske et al 2012 all reactions follow monod kinetics i e a concentration dependent reaction rate with a maximum reaction rate limit and in the case of denitrification with an inhibition term depending on oxygen concentration 2 r μ max c d c d k d c a c a k a k in c in k in where r is the reaction rate μ max is the maximum reaction rate cd and ca are the concentrations of the electron donor and acceptor kd and ka are the respective half saturation constants and cin and kin are the concentration of the inhibitor and the respective inhibition constant only used for the inhibition of denitrification in the presence of oxygen the reaction parameters reflect the calibrated drift creek model zarnetske et al 2012 2011 which represents an upland agricultural stream the model was chosen because the results of the study are generally well accepted and all relevant reactions aerobic respiration nitrification and denitrification under oxygen inhibition were reported the numerical experiments were carried out via the reactive transport model min3p mayer et al 2002 the resulting concentration progressions over time qualitatively match those reported by gu et al 2007 zarnetske et al 2012 fig 2a we calculate da as the ratio of transit time and depletion time of oxygen given that oxygen is never completely removed from the domain we chose a characteristic oxygen concentration to be the concentration where the particular stream trace changes from a net nitrification to a net denitrification regime marked as red and blue label in fig 2 based on the simulated concentration propagations fig 2a the characteristic oxygen concentration is 23 of the initial concentration and the corresponding characteristic oxygen depletion time is 11301s i e 3 1 h we select the median transit time to be the characteristic transit time for the calculation of da for the 2d simulations of the streambed 3 da τ 11301 s 2 3 analytical solution to better illustrate the effect of domain depth restrictions on the transit time distribution we applied an analytical solution of the homogeneous cases appendix a1 in addition to previous works we included a domain depth restriction in the boundary conditions elliott and brooks 1997 laube et al 2018 marzadri et al 2010 as a result we were able to calculate the velocity ux uz 9 and transit time τ 14 and 15 of individual stream traces with infiltration coordinate x 0 within the dimensionless domain 0 x 2π depending on the domain depth d to derive flux weighted transit time distributions we numerically calculated flux q s t 10 6 π 2 u z x x 0 z 0 and transit times of a set of 106 infiltration points 0 x 0 π 2 the results were doubled to represent the whole symmetric domain 0 x 0 2π of one wavelength 20 cm of which only one half 0 x 0 π acts as infiltration area these flux weighted transit time distributions were calculated for several domain depths two of which are shown in fig 6 and each with two different values for k the height of a bin in the resulting histograms in fig 6 corresponds to the sum of fluxes of all stream traces that fall into the respective bin of transit times integrating over the whole distribution thus yields the total hyporheic flux into the domain this is different to a regular non weighted histogram which would show the number of stream traces that fall into the bin 2 4 analysis and presentation of the results each of the 1600 simulations yielded a velocity field the total change in amount of each substance and spatially resolved reaction rates and substance concentrations transit times have been calculated from the velocity fields using paraview s stream trace functionality with one stream trace seeded per grid element of the uppermost grid layer the resulting n transit times were ordered flux weighted and the median transit time τ was selected to be the transit time where half of the total hyporheic flux q had lower and half of it had higher transit times τ τ i w h e r e i 1 k 1 q i q 2 a n d i k 1 n q i q 2 all results in fig 3 and fig 4 were generated by variations of k instead of comparing the results by their conductivity they are presented in relation to the resulting median hyporheic transit time τ for a more functional comparison of the different results in other words the x axes of fig 3 and fig 4 are median transit time axes and shows high and low k only as qualitative annotation this avoids the unresolved choice of an equivalent k as a representation of heterogeneous sediments durlofsky 1991 laube et al 2018 this way the denitrification of a certain sediment type can be compared to another sediment type of equal median transit time which we believe is more relevant than comparing them by some statistical moment of k depending on the targeted use of the resulting data two different presentations of turnover rates can be considered one might present hyporheic turnover efficiency i e local concentration loss over infiltrating concentration neglecting total substance masses e g pescimoro et al 2019 trauth and fleckenstein 2017 and net nitrate concentrations i e denitrification subtracted from nitrification azizian et al 2017 zarnetske et al 2012 this presentation is useful for comparison with field data where substance concentrations at a certain location are easier to obtain than integral budgets and specific turnover rates in this study however we chose the presentation of absolute losses rather than relative concentrations which allows for easier derivation of conclusions on larger scales and overall substance budgets at the expense of worse comparability to field data therefore we present substance losses per area streamwater sediment interface per time mol d m² which inherently includes the amount of hyporheic exchange further we distinguish between nitrification and denitrification and display them individually instead of calculating the net nitrate concentration which is a result of the two this neglects the fact that the hyporheic zone might locally act as a nitrate source but from a more global point of view following the nitrogen cycle from fixation of reactive nitrogen through anthropogenic and natural deposition to its final release as atmospheric nitrogen both nitrification and denitrification are mandatory parts of the cycle that build on each other 3 results 3 1 aerobic respiration and nitrification we define the change of the amount of a solute over time per unit area of the streamwater sediment interface due to a specific reaction as the area weighted turnover rate mol d m2 the turnover rate is denoted by the loss of ch2o for aerobic respiration and by the gain of no3 for nitrification the area weighted turnover rate of both nitrification and aerobic respiration monotonically decreased with increasing median transit time i e decreasing k fig 3a b for homogenous anisotropic and heterogenous scenarios the reduction of turnover rates with transit time was highest for the homogeneous scenarios the depth z of the domain had minor effects on the turnover rates of nitrification and aerobic respiration specifically a reduction of z from 2 5λ to λ hom50cm to hom20cm caused a reduction in turnover rates of both reactions by 3 15 depending on k compared to the base case hom50cm ratios between the base case hom50cm and all other cases are displayed in fig 3c when reduced to λ 2 hom10cm the domain depth caused stronger deviations of up to 40 reduction of turnover rates at high conductivities i e low median transit times of 100 s and between 17 and 35 reduction of turnover rates compared to hom50cm at more moderate conductivities streambed heterogeneity generally decreased the turnover rates of aerobic respiration and nitrification moderate heterogeneity of σ ln k 2 1 0 het1 reduced the turnover rate of aerobic respiration by 44 sd 15 on average compared to hom50cm stronger heterogeneity of σ ln k 2 2 0 het2 reduced the turnover rate by 75 sd 17 on average but with large variations between different geostatistical realizations of heterogeneity furthermore no distinct trend of the turnover rate loss can be seen with respect to the median transit time in other words the moderate heterogeneity reduced the turnover rate by an average factor of 2 stronger heterogeneity by an average factor of 4 no matter if the compared cases have high or low conductivity fig 3a and b the anisotropic simulations which were originally intended to mimic merely the total hyporheic flux and the median transit time of the heterogeneous simulations laube et al 2018 performed reasonably well in representing also the respective turnover rates of aerobic respiration and nitrification in the heterogeneous sceanrios the similarity between the heterogeneous simulations and their respective anisotropic simulations is most easily compared by their relative turnover rates fig 3c the approximately 44 and 75 reductions of turnover in heterogeneous sediments can also be observed in the results of the respective anisotropic simulations the turnover rates of aniso1 lie well within the bounds of the natural scattering of het1 for moderate conductivities but slightly tend to underestimate the turnover rates for high conductive heterogeneous cases with low median transit times the turnover rates of aniso2 generally tend to overestimate the turnover rates of het2 especially for medium conductivities but still lie within the bounds of its scattering results 3 2 denitrification different to nitrification and aerobic respiration there is not in all cases a monotonic decrease of the turnover rate for denitrification with increasing median transit time fig 4a b the cases with a domain depth of z 2 5λ i e hom50cm het1 het2 aniso1 and aniso2 had strictly decreasing turnover rates with median transit time whereas the cases with shallower simulation domains hom20cm and hom10cm had local maxima of turnover rates with respect to median transit time i e with respect to hydraulic conductivity the deviations between the different depth restrictions can be observed best in fig 4c where they are plotted as relative ratios the denitrification rate for all domain depths is similar for low conductivities that foster median transit times τ 10 4 s i e under conditions that could be considered as transport limited da 1 under consideration of the denitrification rate maximum fig 2 on the contrary if k increases i e median transit time decreases the denitrification of the deeper domains stays high while the denitrification rate of the shallower domains drops denitrification decreases strongly for domains with median transit time around τ 10 3 s when 10 cm deep and around τ 10 2 s when 20 cm deep similar to the results of aerobic respiration and nitrification in the previous section streambed heterogeneity generally decreased the turnover rates for denitrification with a large variation between realizations fig 4b c moderate heterogeneity het1 and strong heterogeneity het2 decreased the denitrification efficiency of the simulated domains by 28 sd 31 and 57 sd 34 on average compared to hom50cm different to aerobic respiration and nitrification there was a clear trend of this average efficiency loss with respect to changes in median transit time the efficiency discrepancy between homogeneous and heterogeneous cases diminished towards higher conductivities and the corresponding lower median transit times to an extent that some heterogeneous cases had even higher denitrification rates than the corresponding homogeneous ones to give an example heterogeneous cases with high conductivities that foster median transit times of τ 10 3 s reduced the denitrification to 97 het1 and 56 het2 on average whereas low conductivity cases with transit times of τ 10 5 s reduced denitrification to 61 and 25 compared to homogeneous cases of equivalent median transit times fig 4c the anisotropic simulations matched the respective heterogeneous simulations well for low conductivities but failed to reproduce the trend of the heterogeneous cases with high k i e low median transit time for transit times τ 10 4 s the anisotropic results of aniso1 and aniso2 lie well within the scattered results of het1 and het2 when increasing k above that point though heterogeneous denitrification rates started to increasingly deviate from their anisotropic counterparts such that the anisotropic results are right on the edge of the scattered heterogeneous results at τ 10 3 s 4 discussion hydraulic conductivity has ambiguous effects on biogeochemical reactions within small scale hyporheic flow cells most of our results indicate that an increase in k fosters higher nutrient turnover this is not surprising for the monod kinetics of nitrification and aerobic respiration because the reaction rates of these reactions decrease with longer transit time see fig 2b here an increase of k simply increases nutrient supply within this highly reactive timeframe and consequently increases total turnover rates the monod limitation of a maximum reaction rate would eventually lead to a linear correlation between flux and turnover but even our lowest k simulations did not reach this point of reaction rate limitation with the full extent of their transit time distribution the simple relationship the higher the conductivity the higher the turnover holds for all heterogeneities anisotropies and depth restrictions the more complex results will be discussed in subsections for changes in domain depth heterogeneity and anisotropy 4 1 domain depth denitrification is inhibited by oxygen and thus requires a minimum transit time until most of the oxygen is depleted within the typical shallow hyporheic flow cell hom20cm hom10cm dashed and dash dotted lines of fig 4a this transit time threshold is usually not reached for high k fig 5 i in these cases da 1 a typical e g azizian et al 2017 lewandowski et al 2019 and references therein transit time limitation for denitrification can be observed there is an optimal k for denitrification which promotes median transit times that are similar to the depletion times of oxygen i e da 1 this has also been observed in other studies harvey et al 2013 marzadri et al 2012 shelley et al 2017 zarnetske et al 2012 however the notion that optimal k occurs roughly at da 1 may substantially depend on the depth constraints of the hyporheic zone the least depth constrained scenario fig 4b hom50cm het1 2 is characterized by a strict increase of the total denitrification rate with increasing k similar results can be found in zheng et al 2019 this implies that transit time limitations of highly conductive sediments are compensated by the relatively high flux occurring along long and deep flow paths and thus at the extreme long end of the transit time distribution fig 5c if only a limited number of stream traces is applied they often don t even capture these deep zones as part of the hyporheic zone because of its little contribution to the total hyporheic exchange flow the effect of domain depth restrictions on the transit times can also be described by the analytical solution the flux is proportional to k eq 9 flux equals the area under curve of fig 6 the transit time is inversely proportional to k eq 14 x axis of fig 6 an increase in k thus shifts the transit time distribution to the upper left higher flux shorter transit time in fig 6 the steepness of the tail of the distribution distinguishes if such an increase in k leads to a gain green area or loss red area of flux for a certain transit time bin the shallow domain results in a truncation of flow paths with long transit time accordingly shallower domains show a steeper drop of the tail of the distribution fig 6b leading to a reduction of hyporheic exchange flux with long transit times from an increase in k shorter median transit times this leads to the transit time limitation of denitrification in shallow domains for high conductivities short median transit times fig 4 in deeper domains however the slope of the tail of the distribution is sufficiently low to avoid a truncation of long residence times fig 6a fig 6 shows this for a distinct k 0 10 3 m s however changes in k by a certain factor affect all stream traces equally with an increase in flux and a decrease in transit time by that factor hence changes in k do not alter the shape of the distribution but merely its position on the time axis and its height as a measure of flux consequently our observations should be valid for all conductivities not only for the one we chose to generate the results in fig 6 based on the transit time distributions we found a domain depth of 1 1λ to be the threshold that determines if denitrification can become transit time limited with increasing k this is in good agreement with the simulation results fig 4a where a domain depth of 1 0λ led to transit time limitations for very high conductivities both methods involve numeric methods with limited precision at some point e g finite number of bins of the histograms for practical purposes domain depth must be larger than feature wavelength to prevent transit time limitation should be an appropriate rule of thumb the overall benefits of increased k and the resulting higher hyporheic exchange fluxes for nutrient turnover have been reported before for large scale hyporheic exchange gomez et al 2012 hester et al 2016 as larger structures and meanders usually generate transport limited reactions in the hyporheic zone an increase in k will often lead to an increase in denitrification this simple relationship higher conductivity higher nutrient turnover seems to apply for small feature generated hyporheic exchange as well if certain boundary conditions are met this is related to the fact that even small scale features might foster large scale flow cells this is in good agreement with bardini et al 2012 who stated that conductivity strongly correlates with nitrification and aerobic respiration and weakly but still positively correlates with denitrification this finding has been extended here to a broader range of conductivities to assure that this assumption is not due to a local conductivity optimum another hint for deep reaching hyporheic exchange may be seen in restoration projects like kaushal et al 2008 where significant amounts of coarse material was added to a streambed this measure successfully lowered the overall in stream nitrate concentration in comparison the simple addition of a thin layer of gravel onto fine grained sediment has little effect on solute concentrations sarriquet et al 2007 in cases of upwelling groundwater the effect of conductivity is less clear as upwelling groundwater limits the extent of the hyporheic zone fox et al 2016 denitrification might show a similar behavior as for the shallow cases hom20cm hom10cm at the same time conductivity strongly correlates with the mixing of surface water and groundwater hester et al 2013 which again might be beneficial to denitrification to evaluate the effect of streambed conductivity on hyporheic denitrification it is important to distinguish between a few general configurations of the system namely if the streambed is not affected by ambient groundwater flow or large scale flow cells but deep enough to foster deep flow cells an increase in k will increase denitrification rates as the denitrification process is translocated into deep sediments if under the same general configuration the sediment depth is strongly restricted denitrification is maximized where k fosters median transit times that are in the same order of magnitude of oxygen consumption times if on the contrary the streambed sediment is strongly affected by ambient groundwater flow or large scale flow cells the effects on denitrification can only be hypothesized about combining our results with well known denitrification behavior at other scales if for example large scale hyporheic flow cells limit the depth of the small hyporheic flow cells from ripples we suspect that an increase in k will still foster higher denitrification rates that is because large flow cells potentially behave similarly to the deep flow paths that we saw in our simulations little exchange flux and long transit times as in our simulations the denitrification of such transport limited flow cells strongly benefited from higher conductivity groundwater connection either losing or gaining strongly limits the extent of the hyporheic zone azizian et al 2017 fox et al 2014 the remaining flow cell is likely to behave similar to the depth restricted case of hom10cm i e with an optimal k that generates transit times similar to oxygen consumption times however if strong connectivity with the ambient groundwater system is the major control of flow in shallow sediments hyporheic exchange might play only a minor role in stream water quality in these cases other factors like shallow groundwater mixing hester et al 2013 and denitrification in a narrow mixing zone between groundwater and hyporheic water trauth et al 2015 2014 might be more important than denitrification in the main hyporheic flow cell domain depth had a minor effect on the non inhibited reactions nitrification and aerobic respiration fig 3 the non inhibited reactions are more influenced by flux i e solute supply hence long transit times are not necessary as reaction rates decline over time fig 2 turnover for the non inhibited reactions predominantly occurs in the short transit time range domain depth however mostly affects the long tail of the transit time distribution fig 6 but not the total hyporheic flux which can be derived from the analytical solution of the respective homogeneous domain the hyporheic flux is proportional to the vertical flow velocity uz eq 9 at the interface z 0 the vertical flow velocity of an isotropic r 1 domain is proportional to 4 u z x 0 r 1 sinh d cosh d tanh d where d is the dimensionless domain depth d 2 π λ d d is the domain depth evaluated in the simulations 10 to 50 cm and λ 20 cm is the wavelength of the sinusoidal head boundary the tangens hyperbolicus can be approximated to be constantly 1 if d 2 i e for domain depths larger than d λ π in this case d 6 4 cm in other words domain depth has no effect on the hyporheic exchange flux if the domain depth is larger than one third of the wavelength of the morphological structure driving the hyporheic exchange as a consequence it has no effect on nitrification and aerobic respiration the fact that fig 3 does show some effect of the domain depth is merely an effect of the shift of the calculated median transit time to shorter times due to the deformation of the transit time distribution this effect can be seen in the median transit times shown in fig 6 the shift of median transit times of the depth restricted cases hom20cm hom10cm leads to a shift of the results to shorter times in fig 3 and thus seemingly to a reduction in reaction rates which would not be present if compared in terms of hyporheic flux or k rather than median transit time 4 2 heterogeneity in comparison to the homogeneous cases conductivity heterogeneity generally decreased turnover rates of all investigated reactions if compared in terms of median transit time this is due to a generally lower product of hyporheic exchange flux and median transit time compared to a homogeneous streambed laube et al 2018 in our previous study we referred to this product as equivalent volume because it is equal to the volume of a one dimensional stream tube that carries the total hyporheic exchange flux with only the median transit time as transit time for all particles we found this equivalent volume to be constant with changes in homogeneous k i e flux was inversely proportional to transit time in contrast the equivalent volume decreased with increasing heterogeneity which is why we assumed that heterogeneous sediment would provide a lower equivalent volume available for nutrient turnover in other words heterogeneity decreases the transit time more strongly than it increases the flux consequently an increase in heterogeneity limits reaction times without sufficiently increasing substance transport this leads to the observed general reduction of turnover rates for almost all heterogeneous cases fig 3 and fig 4 an extensive discussion of the effect of conductivity heterogeneity on transit time distribution and hyporheic flux can be found in our previous study laube et al 2018 another way of looking at this phenomenon is that in heterogeneous sediments hyporheic flow concentrates along high conductive flow paths this decreases the volume available for nutrient turnover because low conductive areas away from those flow paths contribute little to overall hyporheic turnover this effect can be seen in fig 7 b and c where those parts of the uppermost layer with conductivities significantly below median k blue contour lines k k 50 10 10 6 m s in c k k 50 10 10 4 m s in b do not contribute to denitrification the fact that reductions in denitrification rates for heterogeneous sediments are smaller for higher conductivity compared to low conductivities is likely caused by these low conductive areas just like denitrification is translocated into deeper parts of the sediment in highly conductive homogeneous sediments it might also be translocated to comparably low conductive areas in highly conductive heterogeneous sediments this effect can be seen in fig 7a where also those parts of the domain with k below median k blue lines k k 50 10 10 2 m s significantly contribute to the domains total denitrification rate in both cases deep domain and heterogeneous conductivity the variance of the transit time distribution will be higher i e calculations based on the median transit time will underestimate the reactive potential of the longer flow paths at the end of the distribution 4 3 anisotropy the reasoning for the choice of a representative anisotropic conductivity tensor was that anisotropy just like heterogeneity reduces the equivalent volume total flux times median transit time of the hyporheic flow cell laube et al 2018 if chosen correctly these anisotropic domains yield similar results in hyporheic flux median transit time and turnover as heterogeneous domains specifically the horizontal and vertical k of such a simplified domain is laube et al 2018 5 k x x e q exp μ l n k a σ l n k 2 k zz eq exp μ lnk 2 b a σ lnk 2 with the mean and standard deviation of the logarithm of the targeted heterogeneous conductivity μ lnk and σ l n k 2 and the coefficients a 0 89 or a 0 47 and b 0 36 or b 0 24 depending on whether the targeted heterogeneity is gaussian smooth or binary with sharp transitions between the different sediment types the anisotropic domains were able to reproduce the decrease in nutrient turnover from the respective heterogeneous domains with varying quality depending on the specific reaction type and transit time regime we calculated the coefficients of determination r² using hom50cm aniso1 and aniso2 as predictors for the heterogeneous results to judge if nutrient turnover of heterogeneous domains can sufficiently be predicted from homogeneous simulations and especially if the introduced anisotropy improves the isotropic base case table 2 we found that the anisotropic simulations generally improved the prediction of nutrient turnover of heterogeneous domains compared to the isotropic base case hom50cm with one exception denitri het1 whole dataset especially the stronger het2 cases could only insufficiently be represented by an isotropic homogeneous domain so that even the null hypothesis a transit time independent average turnover rate r 2 0 would have been an improvement the aniso2 domain improves the prediction of aerobic respiration nitrification and denitrification significantly although especially for denitrification further improvements were desirable the nutrient turnover of the mildly heterogeneous het1 cases was generally well predicted by both isotropic and anisotropic domains of equal median transit time anisotropy improved the prediction of aerobic respiration and nitrification but failed to improve the prediction of denitrification over the whole range of transit times the weaker prediction quality of denitrification is most likely caused by the fact that the anisotropy was originally designed to mimic the mean logarithmic transit time and hyporheic flux of a heterogeneous domain laube et al 2018 however for the prediction of denitrification rates knowledge of the tailing of the residence time distributions is crucial especially when median transit times are below the necessary reaction times that provide anaerobic conditions i e da 1 it can be seen that the prediction quality of the anisotropic model is significantly better when only low conductive heterogeneous cases with high median transit times da 1 are considered in conclusion the replacement of heterogeneous domains with anisotropic domains yields reasonable predictions of non inhibited reaction rates the anisotropic domains also improve the prediction of the inhibited denitrification rate in heterogeneous sediments however for strongly heterogeneous and or highly conductive sediments the choice of a representative homogeneous conductivity needs a refinement such a refinement is beyond the scope of this paper because a finer grained stream trace analysis would be necessary to investigate the tailing of transit time distributions of heterogeneous sediments with sufficient precision with the limitations described above the method cannot be seen as a universal solution but only as one step towards the goal to simplify heterogeneity by the use of some sort of homogeneous domain such a substitution would allow for simplification of future large scale or spectral models without the need to spatially map the heterogeneity of the targeted domain with complex measurement setups e g earon et al 2020 however our solution could provide such a simplification only for certain cases and more work is necessary to improve the model especially the representation of the long tail of the transit time distribution we tested this simplification only for small scale hyporheic exchange but due to the linearity of darcy s law we believe this substitution of heterogeneity by anisotropy to be somewhat universal in scale a model of multispectral hydraulic heads lee et al 2020 could be used to test this assumption 4 4 summary and further discussion sediment heterogeneity and conductivity can both affect turnover rates significantly in comparison domain depth had a minor effect on aerobic respiration and nitrification denitrification in turn was strongly controlled by domain depth especially if streambed conductivity is high we expect the highest overall nutrient turnover to be realized in high conductive homogeneous deep sediments another aspect when discussing conductivity effects on nutrient turnover is the dependency of microbial habitation and sediment grain size distribution our models didn t include any such conductivity turnover rate dependency mendoza lera and datry 2017 suggest that area available for colonization decreases with increasing sediment grain size and thus expect an optimal hyporheic biogeochemical processing around k values of 10 4 10 7 m s in contrast a laboratory experiment by perujo et al 2017 could not show such a grain size to turnover rate dependency apart from hydraulic controls of nutrient transport further experiments are needed to clarify if microbial habitation and turnover depends on sediment grain size beyond the pure effect of changes in nutrient transport from changes in k 5 conclusions if hyporheic flow cells are not or hardly depth constrained by geological structures or ambient groundwater flow also small scale bedforms can induce long and deep flow paths the long flow paths can be characterized by travel times that are sufficiently long to deplete oxygen which in turn facilitates oxygen inhibited reactions like denitrification in settings with high hydraulic conductivity and consequently more hyporheic exchange flux a sufficiently deep domain still facilitates those long transit times where denitrification can occur within the limits of our investigations we could not find a transit time limitation caused by high hydraulic conductivity and high hyporheic exchange flux in deep domains denitrification was always positively correlated with k reactions like aerobic respiration or nitrification always benefit from the higher transport in highly conductive sediments therefore high conductivity is in many cases beneficial to the overall nutrient turnover in the streambed if geological structures or ambient groundwater flow limit the depth of hyporheic exchange highly conductive sediments provoke reaction limitations for denitrification in these cases denitrification is highest if the streambed conductivity fosters median transit times that are in the same range as oxygen depletion times streambed conductivity heterogeneity concentrates hyporheic exchange flux along highly conductive flow paths this limits the volume of sediment that the bulk of the hyporheic flux flows through and in turn the sediment volume available for microbial turnover hence streambed heterogeneity generally limits nutrient turnover per area of the streambed we tested the substitution of heterogeneous domains by anisotropic homogeneous fields this anisotropic substitution improved the prediction of heterogeneous nutrient turnover compared to a substitution with isotropic homogeneous fields however the predictive power is not sufficient in all cases so that such a substitution is only advisable in certain cases e g for the prediction of uninhibited reactions in weakly heterogeneous sediments analytical and large scale models would benefit from such a simplification through easier mathematical descriptions of domain conductivity and lower computational costs but further work is required to elaborate a more generalizable substitution model credit authorship contribution statement gerrit laube conceptualization methodology software validation formal analysis investigation resources data curation writing original draft visualization christian schmidt conceptualization supervision writing review editing project administration funding acquisition jan h fleckenstein supervision writing review editing project administration funding acquisition declaration of competing interest there are no conflicts to declare acknowledgements we thank the two anonymous reviewers whose comments significantly helped to improve the quality of this article this research was supported by a grant nr 1158 132 8 2011 from the gif the german israeli foundation for scientific research and development appendix a1 analytical solution of the hyporheic exchange flow in a homogeneous domain with finite depth the simple design of the simulated domain and boundary conditions allow an analytical solution of the flow field and thus the transit time of the hyporheic exchange flow this has been done in a similar fashion as elliott and brooks 1997 laube et al 2018 marzadri et al 2010 the domain of dimensionless coordinates x 2 π λ x z 2 π λ z a n d d 2 π λ d where x and z are the simulation coordinates d is the simulation domain depth and λ is the wavelength of the head fluctuation is defined by its boundary conditions h z 0 h 0 sin x h z z d 0 6 h x h x 2 π with the head field h i e the ripple induced head fluctuations are represented by a sinusoidal head boundary with maximum head h 0 the field infinitely repeats in x direction after a full wavelength and a no flow boundary condition at depth d limits the depth of the domain on this domain the anisotropic laplace equation 7 k xx 2 h x 2 k zz 2 h z 2 0 is solved by 8 h x z h 0 cosh r d cosh r z d sin x with the anisotropy ratio r k x x k z z accordingly darcy s law u ux uz t k h with a diagonal k tensor results in the seepage velocities u x φ x t k x x h x k x x h 0 cosh r d cosh r z d cos x 9 u z φ z t k zz h z k zz h 0 r cosh r d sinh r z d sin x with porosity φ in this velocity field stream traces can be defined as the set of points x z that follow the velocity field 10 dz dx u z u x 1 r tanh r z x d tan x this nonlinear differential equation was solved by wolfram research inc 2020 11 z x 1 r sinh 1 c sec x d where c can be found by defining the infiltration point x x 0 z 0 12 z x 1 r sinh 1 cos x 0 sinh d r sec x d with this we can solve the velocity field for this specific stream trace with infiltration point x 0 for its transit time based on the x coordinate of the stream trace 13 u x φ x t k xx h 0 cosh r d cosh sinh 1 cos x 0 sinh d r sec x cos x 14 k xx h 0 φ cosh d r t c sec x 2 cos 2 x 0 sinh 2 d r cos 2 x 1 cos 2 x 0 sinh 2 d r 1 f x 1 cos 2 x 0 sinh 2 d r 1 2 sinh 2 d r 2 wolfram research inc 2020 where f x m is the elliptic integral of the first kind with parameter m k 2 the constant c can be found by defining t 0 x x 0 0 15 c sec x 0 2 cos 2 x 0 sinh 2 d r cos 2 x 0 1 cos 2 x 0 sinh 2 d r 1 f x 0 1 cos 2 x 0 sinh 2 d r 1 2 sinh 2 d r 2 the known symmetry of the flow cell ux x z ux x z uz x z uz x z allows us to calculate the exfiltration time for one specific stream trace that infiltrates at x0 z 0 and exfiltrates at x0 z 0 by numerically solving 14 and 15 for texf t x 0 
223,the hyporheic zone provides opportunities for the turnover and removal of nutrients such as ammonium and nitrate from stream water hyporheic flow patterns and dynamics govern the transport of nutrients and other solutes through the hyporheic zone and in turn control their transformation and removal to better understand the links between flow and turnover we systematically studied nutrient turnover rates with simulated sets of idealized streambed domains which varied in domain depth hydraulic conductivity its heterogeneity and anisotropy we show that both aerobic e g nitrification and anaerobic e g denitrification turnover rates generally decrease monotonically with decreasing sediment conductivity at sufficiently large hyporheic zone depth however a reduction of the domain depth leads to an optimum of anaerobic turnover rates at intermediate conductivity due to the rate or transit time limitations of the reaction at the far ends of the conductivity range furthermore conductivity heterogeneity generally lowers the turnover rates of both aerobic and anaerobic reactions it is demonstrated how to reproduce this reduced nutrient turnover in heterogeneous sediments via a simplified anisotropy which facilitates the prediction of turnover rates in heterogeneous sediments in certain cases our results foster the understanding of the interplay between hyporheic exchange and nutrient transformations and they aim to facilitate the conceptualization of large scale numerical simulations by demonstrating the effect of study design decisions like domain extent heterogeneity and anisotropy 1 introduction the exchange of water between streams and their hyporheic zones provides essential ecosystem services within fluvial networks such as the provision of habitat and thermal refugia buffering of stream temperatures as well as biogeochemical processing of nutrients boano et al 2014 gooseff 2010 and references therein hyporheic exchange flows are induced by morphological structures covering a variety of spatial scales ranging from meanders to ripples morén et al 2017 s h stonedahl et al 2010 as hyporheic zones are regarded to play an important role for nutrient processing it is essential to understand the factors controlling reactions in the hyporheic zone bardini et al 2012 morén et al 2018 trauth et al 2014 biogeochemical reactions are controlled by hyporheic exchange flows supplying subsurface microbial communities with oxygen organic carbon and nutrients the resulting biogeochemical zonation is related to transit times in the hyporheic zone for example net nitrification dominates along flow paths with short transit times whereas net denitrification dominates along flow paths with long transit times zarnetske et al 2012 the different temporal scales coincide with typical spatial scales large scale hyporheic exchange generates long transit times and vice versa s h stonedahl et al 2013 however most of the hyporheic exchange flux is generated in small scale structures s h stonedahl et al 2013 s h 2010 the transit time controls if the hyporheic flow reaches anoxic conditions and thus facilitates the potential for denitrification zarnetske et al 2012 the relationship between reaction time scales and transit time scales can be described by the damköhler number da oldham et al 2013 zarnetske et al 2011 da of oxygen as inhibitor of denitrification has been applied in hyporheic zone studies to predict whether the hyporheic zone is a net no3 source or sink zarnetske et al 2012 generally damköhler numbers have been demonstrated to be useful for relating transport and reaction times scales in various hydrological systems lewandowski et al 2019 marzadri et al 2012 ocampo et al 2006 oldham et al 2013 the concept of damköhler numbers originates from chemical engineering where the transit time in a reactor needs to be optimized with respect to the reaction time however unlike technical reactors natural systems such as the hyporheic zone usually exhibit broader transit time distributions this is due to naturally non uniform flow paths and due to the fact that natural flow systems are not always constrained to a fixed reaction volume in geological configurations where the impermeable lower boundary is sufficiently deep even flow paths induced by small morphological structures can generate long and deep hyporheic flow paths here we refer to such cases as unconstrained settings these deep flow paths are typically not represented in da calculations of hydrological systems as da is usually calculated based on a single representative transit time value like the mean or median transit time harvey et al 2013 marzadri et al 2012 shelley et al 2017 tonina et al 2016 zarnetske et al 2012 especially for transit time distributions with high variance a summary statistic like the mean or median does not reflect the full complexity of transit times transit times that represent the margins of the distribution may be characterized by damköhler numbers that deviate substantially from those represented by the mean transit time often this simplification is justified because the deep flow paths often contribute only a minor part to the bulk flow increased hydraulic conductivity k results in an overall increase of hyporheic exchange flow as a result deep and long flow paths of unconstrained settings that otherwise carry only low flux can become relevant for the biogeochemical reactivity of the system however only theoretical models employ such an infinite depth of the hyporheic zone bottacin busolin and marion 2010 elliott and brooks 1997 in reality hyporheic flow cells are more or less depth limited by a number of factors such as ambient groundwater flow cardenas and wilson 2007 trauth and fleckenstein 2017 and flow induced by larger scale features azizian et al 2017 boano et al 2008 bottacin busolin and marion 2010 fox et al 2016 tonina et al 2016 or from confining subsurface structures such as bedrock and clay layers gomez velez et al 2014 the shape of the transit time distribution results not only from the combination of hydraulic gradients and patterns of k but also from the spatial constraints of the hyporheic zone a systematic analysis of the interplay between hydraulic conductivity and hyporheic zone volume and its effects on biogeochemical reactions is currently missing in our understanding of the hyporheic zone a consequence of different hyporheic zone volumes is that the shape of the transit time distribution varies particularly in geologically unconstrained settings of hyporheic exchange high variance transit time distributions occur as a consequence da may need to be represented by a distribution rather than a single value in such cases substantial denitrification can occur in the deeper low flux zones even if the mean da would suggest prevailing overall aerobic conditions in this study we systematically analyze the effects of hydraulic conductivity sediment heterogeneity and reaction volume constraints on the potential for denitrification by using a numerical reactive transport model we hypothesize that if the hyporheic reaction volume is strongly restricted the potential for nitrate removal per streambed area via denitrification has its maximum where the ratio between the median transit time and the reaction time da is close to unity in this case the hyporheic zone can be conceptualized as a chemical reactor with a narrow transit time distribution in other words if the sediment k is higher than the optimum rate limitation becomes the controlling factor and the total denitrification rate decreases in contrast if the hyporheic reaction volume is less restricted an increase in k could trigger higher absolute denitrification potential this would hold even if the da based on the median transit time decreases substantially below unity i e one would expect rate limited conditions this is because denitrification predominantly occurs in the deeper low flux zones which are insufficiently represented by a single da based on a mean or median transit time representing the entire system we further hypothesize that heterogeneous sediment generally has a lower denitrification potential than a homogeneous sediment of equal median transit time that is because hyporheic flux in heterogeneous sediments is focused on highly conductive flow paths which typically results in a reduction of the effective volume of the hyporheic zone laube et al 2018 we additionally demonstrate the use of our previously developed method of an anisotropic homogeneous sediment as a representation for a heterogeneous sediment laube et al 2018 to prove its utility in the context of reactive transport simulations 2 methods we designed a set of numerical simulations of a 2d reactive hyporheic zone at ripple scale including homogeneous heterogeneous and anisotropic sediments of different conductivity and three different depth restrictions we simulated the reactive transport in these domains using representative reaction kinetics for denitrification nitrification and aerobic respiration 2 1 simulated scenarios a systematic investigation of the effect of k on denitrification is most interesting where a change in k could shift transit times close to critical time thresholds where e g denitrification might be inhibited by the presence of oxygen those short transit times are typically generated by small scale morphological structures in the stream like ripples and smaller pool riffle sequences azizian et al 2017 trauth et al 2014 as opposed to longer transit times e g in parafluvial flows through inter meander zones as we are interested in the effects of streambed heterogeneity on transitions between oxic and anoxic regimes in the hyporheic zone we focus on the ripple scale to study the effect of k variations on denitrification aerobic respiration and nitrification accordingly we simulated a simplified rectangular 2d representation of a rippled streambed of x 2m length and varying depth for the numerical investigation of hyporheic nutrient turnover the simulations were conducted via min3p the ripples were represented by a sinusoidal head boundary over a flat bed the head variations were calculated as proposed by elliott and brooks 1997 for ripple height of h 1cm stream velocity of u 10cm s stream depth d 20cm and wavelengths of λ 20cm the domain and boundary conditions are equal to the ones in laube et al 2018 except for the slope in the head boundary and the variations in domain depth to test the hypotheses a total of 1600 simulations were carried out the different scenarios of reaction volume constraints heterogeneity and anisotropy can be categorized in seven groups fig 1 the base group hom50cm contained 200 simulations with z 50cm domain depth i e z 2 5 λ and each with one homogeneous k out of a range of 13 5 ln k 1 5 ln m s the other six groups are variations of this base group the simulations in the groups hom20cm and hom10cm were equivalent to the ones in hom50cm but with 20 cm and 10 cm domain depth i e z λ and z λ 2 respectively these two groups aimed at showing the effect of a restricted domain depth which translates to a restricted reaction volume the groups het1 and het2 consisted of 300 simulations each with a heterogeneous k distribution in het1 and het2 heterogeneous sediment was represented by gaussian random fields with randomized correlation lengths and correlation angles and a fixed variance of microscopically isotropic log conductivity σ ln k 2 1 0 and σ ln k 2 2 0 respectively in both heterogeneous groups the median k varied between 13 5 μln k 1 5 ln m s see laube et al 2018 for details with respect to the gaussian random fields finally aniso1 and aniso2 with 200 simulations each varied through an anisotropic homogeneous k tensor the anisotropic simulations aimed to expand the idea of laube et al 2018 that the hyporheic volume reduction and thus the hyporheic transit time and exchange flux of heterogeneous sediment can sufficiently be matched by a homogeneous model with anisotropic k we tested this empirical simplification of the complexity of heterogeneity for its usability in geochemical calculations the according anisotropy ratio was calculated by 1 r k xx k zz exp 1 06 σ ln k 2 where σ ln k 2 is the variance of the hydraulic conductivity of the targeted heterogeneous sediment and kxx and kzz are the horizontal and vertical conductivity of its anisotropic representation see laube et al 2018 for detailed reasoning why this specific anisotropy ratio has been chosen as an equivalent to the heterogeneous domains aniso1 and aniso2 were designed to be the anisotropic equivalents to het1 and het2 with r 1 exp 1 06 i e σ ln k 2 1 moderately heterogeneous and r 2 exp 2 12 i e σ ln k 2 2 strongly heterogeneous just like the other groups the 200 simulations of each group ranged over conductivities of 13 5 ln kxx 1 5 ln m s and kzz kxx r it should be noted that we intentionally chose boundary conditions without a slope a constant head slope leads to an underflow underneath the hyporheic zone this underflow limits the depth of the hyporheic flow cell the effect of a depth limitation however was already investigated with the hom50cm hom20cm and hom10cm cases bottacin busolin and marion 2010 developed a model to calculate the depth limitation of the hyporheic zone caused by underflow based on the underflow velocity our findings could be translated accordingly 2 2 reactions the setup of the reactive transport model for the hyporheic zone was chosen to represent reaction kinetics that are commonly reported in literature for the following reactions aerobic respiration c h 2 o o 2 c o 2 h 2 o nitrification n h 4 2 o 2 n o 3 h 2 o 2 h denitrification 5 c h 2 o 4 n o 3 4 h 5 c o 2 n 2 7 h 2 o we selected concentration boundary conditions table 1 such that hyporheic nitrate concentrations under aerobic conditions were dominated by nitrification whereas denitrification dominated the nitrate concentration in anaerobic conditions fig 2 doc concentrations were chosen high enough to prevent electron donor limitations this is in line with other studies where carbon limitation is often reported to be negligible due to additional carbon sources like particulate organic carbon peyrard et al 2011 trauth et al 2015 zarnetske et al 2012 all reactions follow monod kinetics i e a concentration dependent reaction rate with a maximum reaction rate limit and in the case of denitrification with an inhibition term depending on oxygen concentration 2 r μ max c d c d k d c a c a k a k in c in k in where r is the reaction rate μ max is the maximum reaction rate cd and ca are the concentrations of the electron donor and acceptor kd and ka are the respective half saturation constants and cin and kin are the concentration of the inhibitor and the respective inhibition constant only used for the inhibition of denitrification in the presence of oxygen the reaction parameters reflect the calibrated drift creek model zarnetske et al 2012 2011 which represents an upland agricultural stream the model was chosen because the results of the study are generally well accepted and all relevant reactions aerobic respiration nitrification and denitrification under oxygen inhibition were reported the numerical experiments were carried out via the reactive transport model min3p mayer et al 2002 the resulting concentration progressions over time qualitatively match those reported by gu et al 2007 zarnetske et al 2012 fig 2a we calculate da as the ratio of transit time and depletion time of oxygen given that oxygen is never completely removed from the domain we chose a characteristic oxygen concentration to be the concentration where the particular stream trace changes from a net nitrification to a net denitrification regime marked as red and blue label in fig 2 based on the simulated concentration propagations fig 2a the characteristic oxygen concentration is 23 of the initial concentration and the corresponding characteristic oxygen depletion time is 11301s i e 3 1 h we select the median transit time to be the characteristic transit time for the calculation of da for the 2d simulations of the streambed 3 da τ 11301 s 2 3 analytical solution to better illustrate the effect of domain depth restrictions on the transit time distribution we applied an analytical solution of the homogeneous cases appendix a1 in addition to previous works we included a domain depth restriction in the boundary conditions elliott and brooks 1997 laube et al 2018 marzadri et al 2010 as a result we were able to calculate the velocity ux uz 9 and transit time τ 14 and 15 of individual stream traces with infiltration coordinate x 0 within the dimensionless domain 0 x 2π depending on the domain depth d to derive flux weighted transit time distributions we numerically calculated flux q s t 10 6 π 2 u z x x 0 z 0 and transit times of a set of 106 infiltration points 0 x 0 π 2 the results were doubled to represent the whole symmetric domain 0 x 0 2π of one wavelength 20 cm of which only one half 0 x 0 π acts as infiltration area these flux weighted transit time distributions were calculated for several domain depths two of which are shown in fig 6 and each with two different values for k the height of a bin in the resulting histograms in fig 6 corresponds to the sum of fluxes of all stream traces that fall into the respective bin of transit times integrating over the whole distribution thus yields the total hyporheic flux into the domain this is different to a regular non weighted histogram which would show the number of stream traces that fall into the bin 2 4 analysis and presentation of the results each of the 1600 simulations yielded a velocity field the total change in amount of each substance and spatially resolved reaction rates and substance concentrations transit times have been calculated from the velocity fields using paraview s stream trace functionality with one stream trace seeded per grid element of the uppermost grid layer the resulting n transit times were ordered flux weighted and the median transit time τ was selected to be the transit time where half of the total hyporheic flux q had lower and half of it had higher transit times τ τ i w h e r e i 1 k 1 q i q 2 a n d i k 1 n q i q 2 all results in fig 3 and fig 4 were generated by variations of k instead of comparing the results by their conductivity they are presented in relation to the resulting median hyporheic transit time τ for a more functional comparison of the different results in other words the x axes of fig 3 and fig 4 are median transit time axes and shows high and low k only as qualitative annotation this avoids the unresolved choice of an equivalent k as a representation of heterogeneous sediments durlofsky 1991 laube et al 2018 this way the denitrification of a certain sediment type can be compared to another sediment type of equal median transit time which we believe is more relevant than comparing them by some statistical moment of k depending on the targeted use of the resulting data two different presentations of turnover rates can be considered one might present hyporheic turnover efficiency i e local concentration loss over infiltrating concentration neglecting total substance masses e g pescimoro et al 2019 trauth and fleckenstein 2017 and net nitrate concentrations i e denitrification subtracted from nitrification azizian et al 2017 zarnetske et al 2012 this presentation is useful for comparison with field data where substance concentrations at a certain location are easier to obtain than integral budgets and specific turnover rates in this study however we chose the presentation of absolute losses rather than relative concentrations which allows for easier derivation of conclusions on larger scales and overall substance budgets at the expense of worse comparability to field data therefore we present substance losses per area streamwater sediment interface per time mol d m² which inherently includes the amount of hyporheic exchange further we distinguish between nitrification and denitrification and display them individually instead of calculating the net nitrate concentration which is a result of the two this neglects the fact that the hyporheic zone might locally act as a nitrate source but from a more global point of view following the nitrogen cycle from fixation of reactive nitrogen through anthropogenic and natural deposition to its final release as atmospheric nitrogen both nitrification and denitrification are mandatory parts of the cycle that build on each other 3 results 3 1 aerobic respiration and nitrification we define the change of the amount of a solute over time per unit area of the streamwater sediment interface due to a specific reaction as the area weighted turnover rate mol d m2 the turnover rate is denoted by the loss of ch2o for aerobic respiration and by the gain of no3 for nitrification the area weighted turnover rate of both nitrification and aerobic respiration monotonically decreased with increasing median transit time i e decreasing k fig 3a b for homogenous anisotropic and heterogenous scenarios the reduction of turnover rates with transit time was highest for the homogeneous scenarios the depth z of the domain had minor effects on the turnover rates of nitrification and aerobic respiration specifically a reduction of z from 2 5λ to λ hom50cm to hom20cm caused a reduction in turnover rates of both reactions by 3 15 depending on k compared to the base case hom50cm ratios between the base case hom50cm and all other cases are displayed in fig 3c when reduced to λ 2 hom10cm the domain depth caused stronger deviations of up to 40 reduction of turnover rates at high conductivities i e low median transit times of 100 s and between 17 and 35 reduction of turnover rates compared to hom50cm at more moderate conductivities streambed heterogeneity generally decreased the turnover rates of aerobic respiration and nitrification moderate heterogeneity of σ ln k 2 1 0 het1 reduced the turnover rate of aerobic respiration by 44 sd 15 on average compared to hom50cm stronger heterogeneity of σ ln k 2 2 0 het2 reduced the turnover rate by 75 sd 17 on average but with large variations between different geostatistical realizations of heterogeneity furthermore no distinct trend of the turnover rate loss can be seen with respect to the median transit time in other words the moderate heterogeneity reduced the turnover rate by an average factor of 2 stronger heterogeneity by an average factor of 4 no matter if the compared cases have high or low conductivity fig 3a and b the anisotropic simulations which were originally intended to mimic merely the total hyporheic flux and the median transit time of the heterogeneous simulations laube et al 2018 performed reasonably well in representing also the respective turnover rates of aerobic respiration and nitrification in the heterogeneous sceanrios the similarity between the heterogeneous simulations and their respective anisotropic simulations is most easily compared by their relative turnover rates fig 3c the approximately 44 and 75 reductions of turnover in heterogeneous sediments can also be observed in the results of the respective anisotropic simulations the turnover rates of aniso1 lie well within the bounds of the natural scattering of het1 for moderate conductivities but slightly tend to underestimate the turnover rates for high conductive heterogeneous cases with low median transit times the turnover rates of aniso2 generally tend to overestimate the turnover rates of het2 especially for medium conductivities but still lie within the bounds of its scattering results 3 2 denitrification different to nitrification and aerobic respiration there is not in all cases a monotonic decrease of the turnover rate for denitrification with increasing median transit time fig 4a b the cases with a domain depth of z 2 5λ i e hom50cm het1 het2 aniso1 and aniso2 had strictly decreasing turnover rates with median transit time whereas the cases with shallower simulation domains hom20cm and hom10cm had local maxima of turnover rates with respect to median transit time i e with respect to hydraulic conductivity the deviations between the different depth restrictions can be observed best in fig 4c where they are plotted as relative ratios the denitrification rate for all domain depths is similar for low conductivities that foster median transit times τ 10 4 s i e under conditions that could be considered as transport limited da 1 under consideration of the denitrification rate maximum fig 2 on the contrary if k increases i e median transit time decreases the denitrification of the deeper domains stays high while the denitrification rate of the shallower domains drops denitrification decreases strongly for domains with median transit time around τ 10 3 s when 10 cm deep and around τ 10 2 s when 20 cm deep similar to the results of aerobic respiration and nitrification in the previous section streambed heterogeneity generally decreased the turnover rates for denitrification with a large variation between realizations fig 4b c moderate heterogeneity het1 and strong heterogeneity het2 decreased the denitrification efficiency of the simulated domains by 28 sd 31 and 57 sd 34 on average compared to hom50cm different to aerobic respiration and nitrification there was a clear trend of this average efficiency loss with respect to changes in median transit time the efficiency discrepancy between homogeneous and heterogeneous cases diminished towards higher conductivities and the corresponding lower median transit times to an extent that some heterogeneous cases had even higher denitrification rates than the corresponding homogeneous ones to give an example heterogeneous cases with high conductivities that foster median transit times of τ 10 3 s reduced the denitrification to 97 het1 and 56 het2 on average whereas low conductivity cases with transit times of τ 10 5 s reduced denitrification to 61 and 25 compared to homogeneous cases of equivalent median transit times fig 4c the anisotropic simulations matched the respective heterogeneous simulations well for low conductivities but failed to reproduce the trend of the heterogeneous cases with high k i e low median transit time for transit times τ 10 4 s the anisotropic results of aniso1 and aniso2 lie well within the scattered results of het1 and het2 when increasing k above that point though heterogeneous denitrification rates started to increasingly deviate from their anisotropic counterparts such that the anisotropic results are right on the edge of the scattered heterogeneous results at τ 10 3 s 4 discussion hydraulic conductivity has ambiguous effects on biogeochemical reactions within small scale hyporheic flow cells most of our results indicate that an increase in k fosters higher nutrient turnover this is not surprising for the monod kinetics of nitrification and aerobic respiration because the reaction rates of these reactions decrease with longer transit time see fig 2b here an increase of k simply increases nutrient supply within this highly reactive timeframe and consequently increases total turnover rates the monod limitation of a maximum reaction rate would eventually lead to a linear correlation between flux and turnover but even our lowest k simulations did not reach this point of reaction rate limitation with the full extent of their transit time distribution the simple relationship the higher the conductivity the higher the turnover holds for all heterogeneities anisotropies and depth restrictions the more complex results will be discussed in subsections for changes in domain depth heterogeneity and anisotropy 4 1 domain depth denitrification is inhibited by oxygen and thus requires a minimum transit time until most of the oxygen is depleted within the typical shallow hyporheic flow cell hom20cm hom10cm dashed and dash dotted lines of fig 4a this transit time threshold is usually not reached for high k fig 5 i in these cases da 1 a typical e g azizian et al 2017 lewandowski et al 2019 and references therein transit time limitation for denitrification can be observed there is an optimal k for denitrification which promotes median transit times that are similar to the depletion times of oxygen i e da 1 this has also been observed in other studies harvey et al 2013 marzadri et al 2012 shelley et al 2017 zarnetske et al 2012 however the notion that optimal k occurs roughly at da 1 may substantially depend on the depth constraints of the hyporheic zone the least depth constrained scenario fig 4b hom50cm het1 2 is characterized by a strict increase of the total denitrification rate with increasing k similar results can be found in zheng et al 2019 this implies that transit time limitations of highly conductive sediments are compensated by the relatively high flux occurring along long and deep flow paths and thus at the extreme long end of the transit time distribution fig 5c if only a limited number of stream traces is applied they often don t even capture these deep zones as part of the hyporheic zone because of its little contribution to the total hyporheic exchange flow the effect of domain depth restrictions on the transit times can also be described by the analytical solution the flux is proportional to k eq 9 flux equals the area under curve of fig 6 the transit time is inversely proportional to k eq 14 x axis of fig 6 an increase in k thus shifts the transit time distribution to the upper left higher flux shorter transit time in fig 6 the steepness of the tail of the distribution distinguishes if such an increase in k leads to a gain green area or loss red area of flux for a certain transit time bin the shallow domain results in a truncation of flow paths with long transit time accordingly shallower domains show a steeper drop of the tail of the distribution fig 6b leading to a reduction of hyporheic exchange flux with long transit times from an increase in k shorter median transit times this leads to the transit time limitation of denitrification in shallow domains for high conductivities short median transit times fig 4 in deeper domains however the slope of the tail of the distribution is sufficiently low to avoid a truncation of long residence times fig 6a fig 6 shows this for a distinct k 0 10 3 m s however changes in k by a certain factor affect all stream traces equally with an increase in flux and a decrease in transit time by that factor hence changes in k do not alter the shape of the distribution but merely its position on the time axis and its height as a measure of flux consequently our observations should be valid for all conductivities not only for the one we chose to generate the results in fig 6 based on the transit time distributions we found a domain depth of 1 1λ to be the threshold that determines if denitrification can become transit time limited with increasing k this is in good agreement with the simulation results fig 4a where a domain depth of 1 0λ led to transit time limitations for very high conductivities both methods involve numeric methods with limited precision at some point e g finite number of bins of the histograms for practical purposes domain depth must be larger than feature wavelength to prevent transit time limitation should be an appropriate rule of thumb the overall benefits of increased k and the resulting higher hyporheic exchange fluxes for nutrient turnover have been reported before for large scale hyporheic exchange gomez et al 2012 hester et al 2016 as larger structures and meanders usually generate transport limited reactions in the hyporheic zone an increase in k will often lead to an increase in denitrification this simple relationship higher conductivity higher nutrient turnover seems to apply for small feature generated hyporheic exchange as well if certain boundary conditions are met this is related to the fact that even small scale features might foster large scale flow cells this is in good agreement with bardini et al 2012 who stated that conductivity strongly correlates with nitrification and aerobic respiration and weakly but still positively correlates with denitrification this finding has been extended here to a broader range of conductivities to assure that this assumption is not due to a local conductivity optimum another hint for deep reaching hyporheic exchange may be seen in restoration projects like kaushal et al 2008 where significant amounts of coarse material was added to a streambed this measure successfully lowered the overall in stream nitrate concentration in comparison the simple addition of a thin layer of gravel onto fine grained sediment has little effect on solute concentrations sarriquet et al 2007 in cases of upwelling groundwater the effect of conductivity is less clear as upwelling groundwater limits the extent of the hyporheic zone fox et al 2016 denitrification might show a similar behavior as for the shallow cases hom20cm hom10cm at the same time conductivity strongly correlates with the mixing of surface water and groundwater hester et al 2013 which again might be beneficial to denitrification to evaluate the effect of streambed conductivity on hyporheic denitrification it is important to distinguish between a few general configurations of the system namely if the streambed is not affected by ambient groundwater flow or large scale flow cells but deep enough to foster deep flow cells an increase in k will increase denitrification rates as the denitrification process is translocated into deep sediments if under the same general configuration the sediment depth is strongly restricted denitrification is maximized where k fosters median transit times that are in the same order of magnitude of oxygen consumption times if on the contrary the streambed sediment is strongly affected by ambient groundwater flow or large scale flow cells the effects on denitrification can only be hypothesized about combining our results with well known denitrification behavior at other scales if for example large scale hyporheic flow cells limit the depth of the small hyporheic flow cells from ripples we suspect that an increase in k will still foster higher denitrification rates that is because large flow cells potentially behave similarly to the deep flow paths that we saw in our simulations little exchange flux and long transit times as in our simulations the denitrification of such transport limited flow cells strongly benefited from higher conductivity groundwater connection either losing or gaining strongly limits the extent of the hyporheic zone azizian et al 2017 fox et al 2014 the remaining flow cell is likely to behave similar to the depth restricted case of hom10cm i e with an optimal k that generates transit times similar to oxygen consumption times however if strong connectivity with the ambient groundwater system is the major control of flow in shallow sediments hyporheic exchange might play only a minor role in stream water quality in these cases other factors like shallow groundwater mixing hester et al 2013 and denitrification in a narrow mixing zone between groundwater and hyporheic water trauth et al 2015 2014 might be more important than denitrification in the main hyporheic flow cell domain depth had a minor effect on the non inhibited reactions nitrification and aerobic respiration fig 3 the non inhibited reactions are more influenced by flux i e solute supply hence long transit times are not necessary as reaction rates decline over time fig 2 turnover for the non inhibited reactions predominantly occurs in the short transit time range domain depth however mostly affects the long tail of the transit time distribution fig 6 but not the total hyporheic flux which can be derived from the analytical solution of the respective homogeneous domain the hyporheic flux is proportional to the vertical flow velocity uz eq 9 at the interface z 0 the vertical flow velocity of an isotropic r 1 domain is proportional to 4 u z x 0 r 1 sinh d cosh d tanh d where d is the dimensionless domain depth d 2 π λ d d is the domain depth evaluated in the simulations 10 to 50 cm and λ 20 cm is the wavelength of the sinusoidal head boundary the tangens hyperbolicus can be approximated to be constantly 1 if d 2 i e for domain depths larger than d λ π in this case d 6 4 cm in other words domain depth has no effect on the hyporheic exchange flux if the domain depth is larger than one third of the wavelength of the morphological structure driving the hyporheic exchange as a consequence it has no effect on nitrification and aerobic respiration the fact that fig 3 does show some effect of the domain depth is merely an effect of the shift of the calculated median transit time to shorter times due to the deformation of the transit time distribution this effect can be seen in the median transit times shown in fig 6 the shift of median transit times of the depth restricted cases hom20cm hom10cm leads to a shift of the results to shorter times in fig 3 and thus seemingly to a reduction in reaction rates which would not be present if compared in terms of hyporheic flux or k rather than median transit time 4 2 heterogeneity in comparison to the homogeneous cases conductivity heterogeneity generally decreased turnover rates of all investigated reactions if compared in terms of median transit time this is due to a generally lower product of hyporheic exchange flux and median transit time compared to a homogeneous streambed laube et al 2018 in our previous study we referred to this product as equivalent volume because it is equal to the volume of a one dimensional stream tube that carries the total hyporheic exchange flux with only the median transit time as transit time for all particles we found this equivalent volume to be constant with changes in homogeneous k i e flux was inversely proportional to transit time in contrast the equivalent volume decreased with increasing heterogeneity which is why we assumed that heterogeneous sediment would provide a lower equivalent volume available for nutrient turnover in other words heterogeneity decreases the transit time more strongly than it increases the flux consequently an increase in heterogeneity limits reaction times without sufficiently increasing substance transport this leads to the observed general reduction of turnover rates for almost all heterogeneous cases fig 3 and fig 4 an extensive discussion of the effect of conductivity heterogeneity on transit time distribution and hyporheic flux can be found in our previous study laube et al 2018 another way of looking at this phenomenon is that in heterogeneous sediments hyporheic flow concentrates along high conductive flow paths this decreases the volume available for nutrient turnover because low conductive areas away from those flow paths contribute little to overall hyporheic turnover this effect can be seen in fig 7 b and c where those parts of the uppermost layer with conductivities significantly below median k blue contour lines k k 50 10 10 6 m s in c k k 50 10 10 4 m s in b do not contribute to denitrification the fact that reductions in denitrification rates for heterogeneous sediments are smaller for higher conductivity compared to low conductivities is likely caused by these low conductive areas just like denitrification is translocated into deeper parts of the sediment in highly conductive homogeneous sediments it might also be translocated to comparably low conductive areas in highly conductive heterogeneous sediments this effect can be seen in fig 7a where also those parts of the domain with k below median k blue lines k k 50 10 10 2 m s significantly contribute to the domains total denitrification rate in both cases deep domain and heterogeneous conductivity the variance of the transit time distribution will be higher i e calculations based on the median transit time will underestimate the reactive potential of the longer flow paths at the end of the distribution 4 3 anisotropy the reasoning for the choice of a representative anisotropic conductivity tensor was that anisotropy just like heterogeneity reduces the equivalent volume total flux times median transit time of the hyporheic flow cell laube et al 2018 if chosen correctly these anisotropic domains yield similar results in hyporheic flux median transit time and turnover as heterogeneous domains specifically the horizontal and vertical k of such a simplified domain is laube et al 2018 5 k x x e q exp μ l n k a σ l n k 2 k zz eq exp μ lnk 2 b a σ lnk 2 with the mean and standard deviation of the logarithm of the targeted heterogeneous conductivity μ lnk and σ l n k 2 and the coefficients a 0 89 or a 0 47 and b 0 36 or b 0 24 depending on whether the targeted heterogeneity is gaussian smooth or binary with sharp transitions between the different sediment types the anisotropic domains were able to reproduce the decrease in nutrient turnover from the respective heterogeneous domains with varying quality depending on the specific reaction type and transit time regime we calculated the coefficients of determination r² using hom50cm aniso1 and aniso2 as predictors for the heterogeneous results to judge if nutrient turnover of heterogeneous domains can sufficiently be predicted from homogeneous simulations and especially if the introduced anisotropy improves the isotropic base case table 2 we found that the anisotropic simulations generally improved the prediction of nutrient turnover of heterogeneous domains compared to the isotropic base case hom50cm with one exception denitri het1 whole dataset especially the stronger het2 cases could only insufficiently be represented by an isotropic homogeneous domain so that even the null hypothesis a transit time independent average turnover rate r 2 0 would have been an improvement the aniso2 domain improves the prediction of aerobic respiration nitrification and denitrification significantly although especially for denitrification further improvements were desirable the nutrient turnover of the mildly heterogeneous het1 cases was generally well predicted by both isotropic and anisotropic domains of equal median transit time anisotropy improved the prediction of aerobic respiration and nitrification but failed to improve the prediction of denitrification over the whole range of transit times the weaker prediction quality of denitrification is most likely caused by the fact that the anisotropy was originally designed to mimic the mean logarithmic transit time and hyporheic flux of a heterogeneous domain laube et al 2018 however for the prediction of denitrification rates knowledge of the tailing of the residence time distributions is crucial especially when median transit times are below the necessary reaction times that provide anaerobic conditions i e da 1 it can be seen that the prediction quality of the anisotropic model is significantly better when only low conductive heterogeneous cases with high median transit times da 1 are considered in conclusion the replacement of heterogeneous domains with anisotropic domains yields reasonable predictions of non inhibited reaction rates the anisotropic domains also improve the prediction of the inhibited denitrification rate in heterogeneous sediments however for strongly heterogeneous and or highly conductive sediments the choice of a representative homogeneous conductivity needs a refinement such a refinement is beyond the scope of this paper because a finer grained stream trace analysis would be necessary to investigate the tailing of transit time distributions of heterogeneous sediments with sufficient precision with the limitations described above the method cannot be seen as a universal solution but only as one step towards the goal to simplify heterogeneity by the use of some sort of homogeneous domain such a substitution would allow for simplification of future large scale or spectral models without the need to spatially map the heterogeneity of the targeted domain with complex measurement setups e g earon et al 2020 however our solution could provide such a simplification only for certain cases and more work is necessary to improve the model especially the representation of the long tail of the transit time distribution we tested this simplification only for small scale hyporheic exchange but due to the linearity of darcy s law we believe this substitution of heterogeneity by anisotropy to be somewhat universal in scale a model of multispectral hydraulic heads lee et al 2020 could be used to test this assumption 4 4 summary and further discussion sediment heterogeneity and conductivity can both affect turnover rates significantly in comparison domain depth had a minor effect on aerobic respiration and nitrification denitrification in turn was strongly controlled by domain depth especially if streambed conductivity is high we expect the highest overall nutrient turnover to be realized in high conductive homogeneous deep sediments another aspect when discussing conductivity effects on nutrient turnover is the dependency of microbial habitation and sediment grain size distribution our models didn t include any such conductivity turnover rate dependency mendoza lera and datry 2017 suggest that area available for colonization decreases with increasing sediment grain size and thus expect an optimal hyporheic biogeochemical processing around k values of 10 4 10 7 m s in contrast a laboratory experiment by perujo et al 2017 could not show such a grain size to turnover rate dependency apart from hydraulic controls of nutrient transport further experiments are needed to clarify if microbial habitation and turnover depends on sediment grain size beyond the pure effect of changes in nutrient transport from changes in k 5 conclusions if hyporheic flow cells are not or hardly depth constrained by geological structures or ambient groundwater flow also small scale bedforms can induce long and deep flow paths the long flow paths can be characterized by travel times that are sufficiently long to deplete oxygen which in turn facilitates oxygen inhibited reactions like denitrification in settings with high hydraulic conductivity and consequently more hyporheic exchange flux a sufficiently deep domain still facilitates those long transit times where denitrification can occur within the limits of our investigations we could not find a transit time limitation caused by high hydraulic conductivity and high hyporheic exchange flux in deep domains denitrification was always positively correlated with k reactions like aerobic respiration or nitrification always benefit from the higher transport in highly conductive sediments therefore high conductivity is in many cases beneficial to the overall nutrient turnover in the streambed if geological structures or ambient groundwater flow limit the depth of hyporheic exchange highly conductive sediments provoke reaction limitations for denitrification in these cases denitrification is highest if the streambed conductivity fosters median transit times that are in the same range as oxygen depletion times streambed conductivity heterogeneity concentrates hyporheic exchange flux along highly conductive flow paths this limits the volume of sediment that the bulk of the hyporheic flux flows through and in turn the sediment volume available for microbial turnover hence streambed heterogeneity generally limits nutrient turnover per area of the streambed we tested the substitution of heterogeneous domains by anisotropic homogeneous fields this anisotropic substitution improved the prediction of heterogeneous nutrient turnover compared to a substitution with isotropic homogeneous fields however the predictive power is not sufficient in all cases so that such a substitution is only advisable in certain cases e g for the prediction of uninhibited reactions in weakly heterogeneous sediments analytical and large scale models would benefit from such a simplification through easier mathematical descriptions of domain conductivity and lower computational costs but further work is required to elaborate a more generalizable substitution model credit authorship contribution statement gerrit laube conceptualization methodology software validation formal analysis investigation resources data curation writing original draft visualization christian schmidt conceptualization supervision writing review editing project administration funding acquisition jan h fleckenstein supervision writing review editing project administration funding acquisition declaration of competing interest there are no conflicts to declare acknowledgements we thank the two anonymous reviewers whose comments significantly helped to improve the quality of this article this research was supported by a grant nr 1158 132 8 2011 from the gif the german israeli foundation for scientific research and development appendix a1 analytical solution of the hyporheic exchange flow in a homogeneous domain with finite depth the simple design of the simulated domain and boundary conditions allow an analytical solution of the flow field and thus the transit time of the hyporheic exchange flow this has been done in a similar fashion as elliott and brooks 1997 laube et al 2018 marzadri et al 2010 the domain of dimensionless coordinates x 2 π λ x z 2 π λ z a n d d 2 π λ d where x and z are the simulation coordinates d is the simulation domain depth and λ is the wavelength of the head fluctuation is defined by its boundary conditions h z 0 h 0 sin x h z z d 0 6 h x h x 2 π with the head field h i e the ripple induced head fluctuations are represented by a sinusoidal head boundary with maximum head h 0 the field infinitely repeats in x direction after a full wavelength and a no flow boundary condition at depth d limits the depth of the domain on this domain the anisotropic laplace equation 7 k xx 2 h x 2 k zz 2 h z 2 0 is solved by 8 h x z h 0 cosh r d cosh r z d sin x with the anisotropy ratio r k x x k z z accordingly darcy s law u ux uz t k h with a diagonal k tensor results in the seepage velocities u x φ x t k x x h x k x x h 0 cosh r d cosh r z d cos x 9 u z φ z t k zz h z k zz h 0 r cosh r d sinh r z d sin x with porosity φ in this velocity field stream traces can be defined as the set of points x z that follow the velocity field 10 dz dx u z u x 1 r tanh r z x d tan x this nonlinear differential equation was solved by wolfram research inc 2020 11 z x 1 r sinh 1 c sec x d where c can be found by defining the infiltration point x x 0 z 0 12 z x 1 r sinh 1 cos x 0 sinh d r sec x d with this we can solve the velocity field for this specific stream trace with infiltration point x 0 for its transit time based on the x coordinate of the stream trace 13 u x φ x t k xx h 0 cosh r d cosh sinh 1 cos x 0 sinh d r sec x cos x 14 k xx h 0 φ cosh d r t c sec x 2 cos 2 x 0 sinh 2 d r cos 2 x 1 cos 2 x 0 sinh 2 d r 1 f x 1 cos 2 x 0 sinh 2 d r 1 2 sinh 2 d r 2 wolfram research inc 2020 where f x m is the elliptic integral of the first kind with parameter m k 2 the constant c can be found by defining t 0 x x 0 0 15 c sec x 0 2 cos 2 x 0 sinh 2 d r cos 2 x 0 1 cos 2 x 0 sinh 2 d r 1 f x 0 1 cos 2 x 0 sinh 2 d r 1 2 sinh 2 d r 2 the known symmetry of the flow cell ux x z ux x z uz x z uz x z allows us to calculate the exfiltration time for one specific stream trace that infiltrates at x0 z 0 and exfiltrates at x0 z 0 by numerically solving 14 and 15 for texf t x 0 
224,in the present study we numerically focus on the vorticity generation mechanism in a scour hole developed downstream of a grade control structure in sand bed channels the liquid granular flow has been simulated through a symplectic weakly compressible sph scheme with a two equation turbulence model where the two phases are treated as continua with different rheological properties the equilibrium configuration of flow field and bed topography is reached after a transient period in which the system oscillates between two flow patterns i the scour hole shows a relatively steep hump downstream of it increasing the free surface elevation and generating a b jump type with a counterclockwise rotating macro vortex structure which pushes the main flow towards the bed where strong erosive action is observed ii the scour shows a relatively modest inclination of the scour cavity leading to the formation of a wave jump dominated by a clockwise rotating macro vortex structure keywords smoothed particle hydrodynamics flow patterns scour holes hydraulic jump local scouring processes 1 introduction local scour in the vicinity of hydraulic structures is an important phenomenon which may endanger their stability therefore the prediction of the maximum scour depth downstream of hydraulic structures has been widely studied relevant references can be found for instance in carstens 1966 bormann and julien 1991 balachandar and kells 1997 gaudio et al 2000 lenzi et al 2002 d agostino and ferro 2004 ben meftah and mossa 2006 martín vide and andreatta 2006 espa and sibilla 2014 manes and brocchini 2015 papanicolaou et al 2018 wang et al 2018 most of these studies propose prediction formulae for both scour depth and length which are calibrated on experimental and field data and are made available to designers the experiments by ben meftah and mossa 2006 tregnaghi et al 2007 and lu et al 2013 showed that the scour downstream of a grade control structure evolves into three distinct phases including an initial phase a developing phase and an equilibrium phase experiments by ben meftah and mossa 2006 showed that the extent of the scour hole was strongly dependent on time and observed an initial rapid stage a progressive stage and a final decelerated stage the initial high rate of solid transport was due to the high shear stresses exerted over the sand bed at the initial time the second stage was characterized by an increased rate of scour development much slower than the first stage the final slow stage was when the scour achieves equilibrium after a long period of time experiments by tregnaghi et al 2007 showed that the scour process usually reaches its equilibrium condition rapidly in live bed conditions and rather slowly in clear water conditions lu et al 2013 indicated that the scour hole in non cohesive sediments depends on the channel bed slope on the flow conditions on the densimetric froude number and on the sediment median size however the complex nature of the local scouring process shows that current knowledge is far from a full understanding of the phenomenon whereas most experiments provide measurements at a point or on a plane the complete flow field supplied by a computational fluid dynamics cfd simulation enables the reasearchers to have a deeper understanding of the scouring process therefore cfd methods have become a useful tool to study complex environmental fluid mechanics problems the estimation of erosion rates is a key issue for management and long term operation plans of many hydraulic structures in a management context modeling supports the prediction of changes in sediment balance upstream and downstream of a hydraulic structure with relatively low cost in this context the use of lagrangian meshless methods appears in general to be particularly suitable for dealing efficiently with the presence of two phases the combination of interfacial and free surface flows in addition to particle entrainment of sediments by the fluid among mesh free methods smoothed particle hydrodynamics sph has gained a widespread popularity in the last decades although it had been initially developed to study astrophysical problems gingold and monaghan 1977 lucy 1997 it has since then been extended to a wide range of engineering applications such as the breaking and impact of waves di monaco et al 2011 lin et al 2015 makris et al 2016 xia and liang 2016 de padova et al 2018a 2020a hydraulic jumps lópez et al 2010 federico et al 2012 de padova et al 2017 2018b c jonsson et al 2016 multi phase flows and fluid structure interaction fsi problems pu et al 2013 xie and jin 2016 de padova and mossa 2020 2020b 2021 calderon sanchez et al 2021 oscillating jets that induce breaking waves espa et al 2008 de padova and mossa 2019 2020b barile et al 2020 wastewater treatment meister and rauch 2016 simulation of landslides manenti et al 2016 ran et al 2015 during the last decade multi phase sph numerical studies on sediment transport have been carried out by manenti et al 2012 zanganeh et al 2012 ran et al 2015 fourtakas and rogers 2016 fu and jin 2016 khanpour et al 2016 pahar and dhar 2017 shi et al 2017 ulrich et al 2013 wang et al 2018 zubeldia et al 2018 bertevas et al 2019 zheng et al 2019 in manenti et al 2012 both liquid and granular materials were modelled as weakly compressible viscous fluids whose motion results from the numerical solution of the continuity and momentum equations discretized according to a standard sph formulation comparison with experimental results showed that the eroded volume and the profile evolution were better reproduced by the shields criterion zanganeh et al 2012 applied a two phase sph method for simulating scour processes beneath a marine pipeline with respect to the sediment and fluid phase interactions here the sediment and fluid phases were described as a non newtonian and newtonian fluid respectively and a sub particle scale sps model was used to represent turbulent stresses ulrich et al 2013 applied a two phase sph method to complex full scale marine engineering problems including the scouring of sea port bottom soil due to ship propeller induced flows here the soil phase was treated as a viscous material with a variable viscosity adhering to the mohr coulomb yield stress criterion for granular materials and the constitutive model was supplemented by a suspension treatment to capture the viscosity transition along the water soil interface in ran et al 2015 an incompressible sph isph erosion model was developed to investigate the sediment bed scour and grain movement under a dam break flow the sediment bed erosion model was based on the concept of pick up flow velocity and the sediment was initiated when the local flow velocity exceeded a critical value in fourtakas and rogers 2016 the numerical sph scheme was based on the bingham type herschel bulkley papanastasiou hbp model that allows simulating the rheology of the un yielded and the yielded material without needing to define a maximum value for viscosity the multi phase model was calibrated with experimental and 2 d reference numerical models for scour following a dry bed dam break in fu and jin 2016 a two phase sph method based on a rheology model and a higher order viscosity smoothening scheme was used to reproduce the open channel flow scouring and water sediment dam break flow in khanpour et al 2016 a two phase sph based on mohr coulomb and shields yielding criteria was used to reproduce the scouring downstream of a wall jet and a reservoir sediment flushing pahar and dhar 2017 developed a coupled solenoidal isph model for simulation of sediment displacement in erodible bed in wang et al 2018b a 3d isph sediment erosion model was proposed to simulate the scouring process around a large vertical cylinder the model was based on the twp concept wang et al 2016 and the sediment motion was initiated when the fluid bottom shear stress exceeded the critical value in zubeldia et al 2018 a two phase sph method based on the shields criterion and applied to the flow of a two phase liquid sediment mixture was employed to model the scouring flows with large deformations in luo and kazemi 2019 a sph sediment model was used to study the dynamic hydraulic jump in steep open channels in bertevas et al 2019 a sph formulation of the classical two phase mixture model was used to study the turbulent sediment transport and the sediment disturbances generated by moving equipment operating near or on the seabed the rheological behavior of clay sediment water mixtures was modelled using a volume fraction shear rate dependent viscosity which accounts for the existence of a yield stress in general some sph approaches consider the sediment as a single phase moving mass other approaches model the sediment as a two phase mixture where the voids of the solid matrix are filled by a liquid phase in order to account for the pressure effect however in all these approaches the basic idea is to model the sediment dynamics like a pseudo fluid one once the onset of sediment particle motion is attained as a result a criterion that represents the critical condition for the incipient motion of sediment must be defined this can be done in terms of the critical velocity hayashi et al 2003 ran et al 2015 or the critical shear stress manenti et al 2012 in some of the considered works a numerical threshold was used for this purpose and therefore it is evident that the prediction capability of the model depends on the calibration made to overcome this limitation a wcsph formulation of a mixture model consistent with the kinetic theory of dense granular flows ktgf was introduced by amicarelli et al 2017 showing a suitable degree of accuracy the reader can refer to manenti et al 2019 for a comprehensive review of the studies on multi phase sph erosion models starting from the research experiences described above the main aim of this study is to exploit the features of the sph method i e its inherent ease in the treatment of different rheologies as well as of rapidly varying free surfaces and interfaces to investigate the effect of sediment movement under the action of rapid flows such as the ones occurring downstream of a bed sill which lead to the formation of unsteady hydraulic jumps and evolving scour holes to reach this goal an existing sph model which has proven to be highly effective in the description of unsteady free surface flows dominated by turbulence and wave breaking see e g espa et al 2008 de padova et al 2013 2018b and 2020a was extended to include the treatment of soil water interaction among the different available models the one developed by ulrich et al 2013 has been considered suitable because of its peculiar two phase approach which takes into account the granular bed as a separate granular phase but treats the water sediment suspension as a single fluid phase with variable viscosity the calibration of the sph model has been performed by comparing experimental and numerical observations of the local scour holes downstream of a hydraulic jump finally sph simulations have been used i to inspect and detail the vorticity field evaluating in particular its temporal evolution ii to relate the vorticity field and the scour process iii to relate the vorticity field and the free surface dynamics in particular to the flow surface parallel deceleration and iv to study the temporal evolution of the dominance of vorticity and strain 2 sph numerical method the liquid granular flow has been simulated through a sph approach where the two phases treated as continua with different physical and rheological properties are represented by different sets of particles and no transfer of mass is allowed from one phase to the other time advancement is obtained through a symplectic weakly compressible sph wcsph scheme where artificial compressibility is introduced to solve explicitly in time the equations of motion of the two incompressible fluids the motion of both continuum phases is represented by the navier stokes equations which take the following sph semi discrete form 1 d ρ i d t j 1 n i m j v i v j w i j d v i d t j 1 n i m j p i ρ i 2 p j ρ j 2 w i j j 1 n i m j ρ j t i t j w i j g p i p 0 c i 2 ϱ i ρ 0 t i η i s i where wij represents the c2 wendland kernel function wendland 1995 evaluated at the interparticle distance and defined over a circle having a radius double than the smoothing length h sph particle approximation is indicated by angled brackets and is written for each particle i having mass mi the summations in 1 are extended to all the ni particles j located at a distance smaller than 2 h from particle i irrespective of the material characterizing the particles in eq 1 v u w is the velocity vector p is pressure p is density g is the gravity acceleration vector t is the shear stress tensor c is the speed of sound in the weakly compressible fluid η is a suitable viscosity coefficient s is the rate of strain tensor and the subscript 0 denotes a reference state for pressure computation the way in which the viscosity coefficient is evaluated defines the different models which represent the flow of the two phases the tilde notation w i j indicates that the gradient of wij is renormalized by enforcing 1st order consistency on the 1st derivatives sibilla 2015 leading to a 2nd order accurate discretization scheme in space the kernel renormalization is applied to all of the terms in 1 apart from the pressure gradient term where the form originally proposed by monaghan 1992 is retained to guarantee momentum conservation 2 1 turbulent liquid flow in the case of a turbulent flow of the liquid phase all variables in 1 are assumed to be reynolds averaged and the equations of motion become the reynolds averaged rans equations in this case η represents the kinematic eddy viscosity which is evaluated through a standard k ε turbulence model launder and spalding 1974 as η c μ k 2 ε where k is the turbulent kinetic energy and ε the turbulent dissipation rate in the same sph semi discrete form as 1 the equations for the turbulence model are de padova et al 2016 2 d k i d t p k i 1 σ k j 1 n i m j η i η j ρ i ρ j k i k j r i j 2 0 01 h 2 r i j w i j ε i d ε i d t c ε 1 ε i k i p k i 1 σ ε j 1 n i m j η i η j ρ i ρ j ε i ε j r i j 2 0 01 h 2 r i j w i j c ε 2 ε i k i j 1 n i m j ρ j ε j w i j where pk is the production of turbulent kinetic energy depending on the local rate of deformation and the model constants have the following values σk 1 σε 1 3 cε 1 1 44 ce 2 1 92 2 2 granular and suspension flow following ulrich et al 2013 the granular phase is treated as a viscous material with a variable viscosity which takes into account also the viscosity transition in the layer where the granular material is found in suspension inside the liquid flow the concentration of the suspension is estimated through sph interpolation as 3 c i j 1 n g i m j ρ j w i j k 1 n i m k ρ k w i k where ng i are the particles of granular material surrounding particle i for a concentration ci 1 the viscosity of the granular material is computed according to the mohr coulomb yield stress criterion 4 η i m c min η m a x χ cos ϕ p i sin ϕ ρ g s i where χ is the cohesion φ the friction angle and ηmax an upper threshold for viscosity to avoid the singularity which occurs when the strain rate vanishes the viscosity of the suspension is derived from the assumption of a constant friction coefficient which yields 5 η i s min η m a x c f v i 2 s i a constant value cf 0 01 is assumed for the friction coefficient within the range suggested by fraccarollo and capart 2002 to smooth the transition between the different layers the viscosity values are piecewise linearly interpolated between the turbulent eddy viscosity the suspension viscosity ηs and the granular viscosity ηmc according to the local value of the concentration 3 6 η i c μ k i 2 ε i η i s c μ k i 2 ε i c 1 c i for 0 c i c 1 η i s for c 1 c i c 2 η i s η i m c η i s c 3 c 2 c i c 2 for c 2 c i c 3 η i m c for c 3 c i 1 for the boundary values between the different viscosity regions the same values suggested by ulrich et al 2013 were adopted i e c 1 0 3 c 2 0 6 and c 3 0 99 it must be noted that the model by ulrich et al 2013 is essentially a single phase model for the suspension which is treated as a fluid with varying rheological properties dependent on the local suspended solid concentration as such the model does not take into account explicitly the mass fluxes between the bed granular material and the suspended sediment in the water flow in this sense it is an approximate model which holds in the hypotheses of solid transport mainly occurring as bed transport and of non negligible values of the mixture viscosity only occurring in the near bed layer given the fact that the bed material here analysed is a coarse sand as explained in section 3 these hypotheses can be accepted the semi discrete system 1 and 2 is integrated in time by a 2nd order two stage xsph explicit algorithm with a pressure smoothing procedure specifically designed for free surface flows more details on the adopted sph scheme can be found in de padova et al 2013 de padova et al 2016 inflow boundary conditions are assigned by introducing a 2h wide buffer layer upstream of the computational domain where the required conditions are imposed to particles located between the bed and the water surface each inflow particle is then moved at a constant velocity uc for a time ti 2 h uc and with constant values of turbulent energy and dissipation until it enters the computational domain where its properties evolve according to eqs 1 and 2 the number of entering particles is determined by the inlet water depth h 1 and is regulated in time in order to guarantee the exact mass flow rate at the inlet k and ε at the inlet are computed according to an average initial turbulence intensity of 1 zero gradient outflow boundary conditions are imposed to all the quantities but pressure by introducing a second 2h wide buffer layer downstream of the computational domain where the particle velocity k and ε are kept unchanged pressure is instead imposed according to the hydrostatic pressure gradient resulting from the outlet water depth h 2 3 numerical test 3 1 numerical parameters and validation of the sph results the numerical scheme described above was used to reproduce the local scouring process experimentally observed downstream of the first bed sill located 2 m downstream of the wooden ramp fig 1 the experimental flume bottom is covered with uniform sand particles with a nominal diameter d50 1 8 mm and density ρ 2650 kg m3 the sill height decreases progressively downstream of the wooden ramp respecting an assigned initial slope s0 0 0086 table 1 lists the main experimental parameters of the investigated scour process l is the distance between sills hc is the flow depth over the crest of the sill downstream of which the scour hole is measured u c is the flow velocity over the sill zs is the maximum equilibrium scour depth from the original bed profile h s is the flow depth at the position of maximum equilibrium scour depth fdc u c δgd 50 0 5 is the densimetric froude number for the approaching flow over the sill further details and discussion of the results of the experiments can be found in ben meftah and mossa 2006 and in ben meftah et al 2020 2021 the numerical domain is 1 2 m long and 0 6 m high shorter than the laboratory channel such a shorter domain was chosen to reduce the computational cost without influencing the quality of the numerical solution as shown by de padova et al 2014 an upstream flow depth h 1 hc 0 048 m was therefore chosen while a flow depth h 2 0 056 m was imposed downstream a sketch of the problem setup and of the initial conditions of the sph simulation can be seen in fig 2 the efficiency of the sph kernel function depends also on the choice of the h δ ratio where δ is the particle spacing de padova et al 2014 showed that a value h δ 1 2 should be preferred here the initial particle spacing was taken to be δ 0 002 m and a ratio h δ 1 5 was used the resulting initial number of sph particles in the simulation was approximately 60 000 a thorough sensitivity analysis was already performed by the authors in the application of the same sph numerical method to hydraulic jumps and breaking wave flows de padova et al 2018c 2019 according to this analysis the sph simulations of the cases here studied were performed by adopting a velocity smoothing coefficient in the xsph scheme φv 0 01 the simulations were performed with χ 10 pa φ 41 and ηmax 0 01 m2 s in eq 4 the validity of the numerical scheme adopted here was checked against the experimental observations of the local scour holes downstream of hydraulic jumps reported by ben meftah and mossa 2006 the evolution of the scour hole during the sph simulation is shown at various time instants in fig 3 fig 4 shows the resulting sph and experimental velocity fields superimposed in a vector plot inside the scour hole downstream of the first bed sill located 2 m downstream of the wooden ramp the obtained results highlight that the final model proves to be capable of reproducing the experimental bed evolution the flow velocity and turbulence intensity through the scour hole actually the three regions which characterize the flow according to the experiments are clearly reproduced in particular the flow in region 1 plays a very important role in the initial phase of the scour development this is due to its high velocity which leads to an increase of the jet potential erosive action on the bed channel region 2 is dominated by a clockwise local vortex at the position of maximum scour depth in region 3 the velocity vectors tend to be more horizontal the measured black dots and simulated blue dots bed profiles at equilibrium are also compared and show a substantial agreement fig 5 shows the streamwise u and the vertical turbulence w intensities u is defined as the ratio of the standard deviation of the streamwise flow velocity component fluctuations to the average velocity uc w is defined as the ratio of the standard deviation of the vertical flow velocity component fluctuation to the average velocity uc in the discussion the fluctuations u and w can be considered to be referred to the large scale fluctuations which are resolved and directly computed by the lagrangian time dependent sph while the k ε turbulence model takes into account also the effect of the modelled small scale turbulent eddies in a global way averaging the information on the microscopic turbulence anisotropy the numerical results show that the behavior of the simulated liquid granular flow is consistent with the experiments of ben meftah and mossa 2006 in particular the results show that i the vertical turbulence intensities w are smaller than the streamwise ones u ii the maximum streamwise u and vertical w turbulence intensities take place at the regions 1 due to the more intermittent behavior of the jet flow iii the minimum streamwise u and vertical w turbulence intensities take place at the region 3 due to the steadier flow velocity distribution iv in region 2 the streamwise u and vertical w turbulence intensities show the smallest values comparable to those occurred in region 1 due to the flow velocity reduction v at the different downstream positions x xs the streamwise u and vertical w turbulence intensities decrease with decreasing z zs i e approaching the equilibrium scour bed fig 6 shows the vertical profiles of the time averaged turbulent kinetic energy k u 2 w 2 2 normalized by uc herein the angle brackets indicate the average over the length of the time series the agreement between the numerical results and laboratory measurements is satisfactory these results highlight that i at all vertical profiles except the one at x xs 1 33 the time averaged turbulent kinetic energy k decreases when z zs decreases i e going down to the equilibrium scour bed ii at x xs 1 33 the time averaged turbulent kinetic energy k increases when z zs decreases due to the effect of the transition between regions 1 and 3 to evaluate the model performance table 2 shows the statistical analysis of the comparison between the numerical model and the experimental results in terms of the wilmott index wilmott 1981 i w 1 k 1 n x c k x m k 2 k 1 n x c k x m x m k x m 2 7 where x c and x m are the modelled and measured values of the variable x respectively while the bar denotes the average of the modelled and measured values a perfect agreement between the measured and modelled values is reached when i w is equal to 1 while a complete discrepancy between numerical and experimental results is observed when iw tends to 0 therefore the sph model provides a satisfactory prediction in terms of the flow velocity field and the turbulence intensity in the scour holes 3 2 flow characterization since turbulence is the most important mechanism of sediment entrainment causing a significant increase in the shear stress around the base of a hydraulic structure the flow velocity field in the scour holes was analysed therefore in this section we provide a simple characterization of the flow based both on the vorticity ω and on the okubo weiss parameter w okubo 1970 weiss 1991 vorticity is defined as 8 ω u z w x and is computed using instantaneous values of the horizontal and vertical velocity the w parameter is defined as 9 w s n 2 s s 2 ω 2 where ω is the vorticity defined by 8 while s n u x w z and s s w x u z respectively are the normal and shear components of strain rate the vorticity maps shown in fig 7 were computed from the sph vector fields furthermore the flow behavior is well described by the instantaneous streamlines representing a single snapshot obtained from the instantaneous velocity field calculated on a regular grid fig 7 analyzing the results the equilibrium configuration of flow field and bed topography is reached after a transitory period in which the system oscillates between two flow patterns i at first fig 7 a the presence of a scour hole with a relatively steep hump downstream of it leads to an increase of the free surface elevation and to the generation of a b jump type with a counterclockwise rotating macro vortex structure negative vorticity which pushes the main flow towards the bed where a strong erosive action is observed and sediments are forced to move downstream this behavior of the liquid flow is clearly observed by looking at the streamlines which show that the majority of the flow is oriented parallel to the bed in the downstream direction however over the scour hole the streamlines clearly show the flow recirculation and the fluid moving in the upstream direction near the free surface ii later when the scour hole shows a milder inclination fig 7 b the formation of a wave jump is observed this wave jump is dominated by a clockwise rotating macro vortex structure positive vorticity here the clockwise circular motion over the scour hole is clearly shown by the streamlines the surface boundary layer near the free surface with positive vorticity grows in the downstream direction furthermore there is a concentrated region of negative vorticity near the bed the analysis of the vorticity maps alone is not sufficient to identify vortices since they are masked by background shear thus considering that turbulent structures essentially evolve from interactions between vorticity and strain rate the maps of the okubo weiss parameter w have been also used to detect coherent structures mattioli et al 2012 hilt et al 2020 using the local value of w the flow domain can be partitioned in three distinct types of regions i vorticity dominated regions or elliptic regions w 0 ii strain dominated regions or hyperbolic regions w 0 iii intermediate regions w 0 figs 8 and 9 show the comparison between the instantaneous map of ω and of w rated by w 0 0 2σw with σw being the standard deviation of w in the whole domain at beginning of erosive action t 2 s and when the stable configuration has been reached t 165 s respectively the map of w w 0 shown in fig 8 b highlights the presence of coherent eddies w 0 in the near surface region which is characterized by negative vorticity fig 8 a a strain dominated region is instead observed in the scour hole the dominance of strain rate is observed until the scour hole shows relatively steep walls and where a strong erosive action is observed instead when the scour hole shows a relatively mild inclination and a stable formation of a wave jump has been observed fig 9 a the dominance of the strain rate terms is greatly reduced fig 9 b in order to better understand the behavior of the vorticity field at equilibrium configuration fig 9 a the flow deceleration due to the convective term u s u s s has been studied as shown by misra et al 2008 the mean surface parallel velocities have been calculated as 10 u s u cos θ v sin θ where θ is the inclination of the mean surface on the horizontal fig 10 shows the instantaneous map of the surface parallel convective acceleration when the stable configuration has been reached we observe that a flow deceleration occurs in the same location where a strong positive vorticity appears this is consistent with the observations made by dabiri and gharib 1997 that theoretically derived that near surface vorticity increases with increasing deceleration term 3 3 local scouring process characterization some experimental studies noticed a cyclic variation of jump types under specific flow conditions ohtsu and yasuda 1991 mossa 2002mossa et al 2002 chanson and toombes 1998 mossa 1999 mossa et al 2003 the experiments by abdel ghafaret al 1995 on local scour in sand bed channel due to hydraulic jump showed that the hydraulic jump tended to repeat itself in a periodic form from clockwise to anti clockwise rotation of the vortex these results confirm the experimental findings by mossa 1999 who showed that the oscillations of the hydraulic jump depended on the shape of the bed and on the hydrodynamic characteristics of the channel flow in agreement with these observations fig 11 highlights that the configurations in which the oscillation between b and wave jump appears occur along a boundary between the two regions of occurrence of each type this boundary is represented by a log relation between the upstream froude number f r 1 u 1 g h 1 and the water depth ratio h 2 h 1 to understand the effect of oscillating hydraulic jumps on the scouring profiles the calculated scouring profiles at different times are plotted in fig 12 the results obtained by the numerical model indicate that the maximum scour depth is almost constant after 160 s run time the results show that a strong horizontal erosive action tends to rapidly intensify when the system shifts from b to wave jump analyzing the instantaneous vorticity fields the transition between the two jump types starts at t 63 s and clearly ends at t 65 s in fact from t 63 s fig 12 shows a reduction in the vertical scour depth and a rapid increase in the horizontal scour depth fig 13 reveals that three different phases of the scour process can be identified phase i where the flow is characterized by a b jump shows a rapid increase of the scour to a depth which is more than 60 of the final depth while the scour length increases at a much slower rate phase ii when the transition between the two jump types has been observed is dominated by a strong and fast increase of the horizontal dimension of the scour hole while its depth decreases owing to the collapse of the upstream side finally during phase iii a stable wave jump is observed and the scour depth length and volume all increase until equilibrium is reached 4 conclusions the objective of the present work was to investigate the vorticity generation mechanism in a scour hole developed downstream of a grade control structure in sand bed channels providing a full hydrodynamic picture of the scouring process the liquid granular flow has been simulated through a symplectic weakly compressible sph wcsph scheme with a two equation turbulence model where the two phases are treated as continua with different physical and rheological properties in the hypothesis of solid transport mainly occurring as bed transport and of suspended solids only influencing the apparent viscosity of the liquid flow the sph model was validated by comparing the simulated results with the experiments on the local scour holes downstream of hydraulic jump showing that the simulations were consistent with experimental data as experimentally observed our results indicate that three regions can be identified the first is dominated by a jet like flow characterized by high speed and plays a very important role in the downstream movement of sediments the second is dominated by a clockwise local vortex at the position of maximum scour depth third is dominated by a relatively aligned horizontal flow the detailed analysis of the turbulence characteristics in the scour hole at equilibrium conditions shows that both the maximum value of the streamwise and of the vertical turbulence intensities occur in the first region due to the jet flow in the third region there is a sharp reduction in turbulence intensity at equilibrium conditions the stability of sediment particles is due to a significant decrease of turbulent energy production at the bed flow interface the equilibrium configuration of flow field and bed topography is reached after a transitory period in which the system oscillates between two flow patterns i the presence of a scour hole with a relatively steep hump downstream of it increases the free surface elevation and generates a b jump type characterized by a counterclockwise rotating macro vortex structure negative vorticity which pushes the main flow towards the bed where a strong erosive action is observed ii the scour with a relatively modest inclination of the scour cavity leads to the formation of a wave jump dominated by a clockwise rotating macro vortex structure positive vorticity furthermore a cause effect relation between near surface flow deceleration and vorticity fluxes is detected similarly to what observed in dabiry and gharib 1997 the maps of the relative okubo weiss parameter w w0 highlights the presence of coherent eddies w 0 in the region which exhibits negative vorticity near the surface instead a strain dominated region is observed in the scour hole the dominance of strain rate is observed until the scour hole shows relatively steep walls and where a strong erosive action occurs instead when the scour shows a relatively mild inclination and a stable wave jump forms the dominance of the strain rate terms is greatly reduced finally the calculated scouring profiles at different times have been plotted to understand the effect of oscillating hydraulic jumps these profiles show that the scour process evolves in three distinct phases phase i when the flow is characterized by a b jump shows a rapid increase of the scour to a depth which is more than 60 of the final depth while the scour length increases at a much slower rate phase ii when the transition between the two jump types takes place is dominated by a strong and fast increase of the horizontal dimension of the scour hole while its depth decreases owing to the collapse of the upstream side phase iii when the flow is characterized by a stable wave jump and the scour depth length and volume all increase until equilibrium is reached author contributions d d p and s s performed the numerical modeling m m and m b m performed the experiments d d p m b m m m and s s analyzed the data d d p wrote the paper m b m m m and s s contributed suggestions discussions and reviewed the manuscript all authors have read and agreed to the published version of the manuscript declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the experiments were carried out at the hydraulic laboratory of the mediterranean agronomic institute of bari italy 
224,in the present study we numerically focus on the vorticity generation mechanism in a scour hole developed downstream of a grade control structure in sand bed channels the liquid granular flow has been simulated through a symplectic weakly compressible sph scheme with a two equation turbulence model where the two phases are treated as continua with different rheological properties the equilibrium configuration of flow field and bed topography is reached after a transient period in which the system oscillates between two flow patterns i the scour hole shows a relatively steep hump downstream of it increasing the free surface elevation and generating a b jump type with a counterclockwise rotating macro vortex structure which pushes the main flow towards the bed where strong erosive action is observed ii the scour shows a relatively modest inclination of the scour cavity leading to the formation of a wave jump dominated by a clockwise rotating macro vortex structure keywords smoothed particle hydrodynamics flow patterns scour holes hydraulic jump local scouring processes 1 introduction local scour in the vicinity of hydraulic structures is an important phenomenon which may endanger their stability therefore the prediction of the maximum scour depth downstream of hydraulic structures has been widely studied relevant references can be found for instance in carstens 1966 bormann and julien 1991 balachandar and kells 1997 gaudio et al 2000 lenzi et al 2002 d agostino and ferro 2004 ben meftah and mossa 2006 martín vide and andreatta 2006 espa and sibilla 2014 manes and brocchini 2015 papanicolaou et al 2018 wang et al 2018 most of these studies propose prediction formulae for both scour depth and length which are calibrated on experimental and field data and are made available to designers the experiments by ben meftah and mossa 2006 tregnaghi et al 2007 and lu et al 2013 showed that the scour downstream of a grade control structure evolves into three distinct phases including an initial phase a developing phase and an equilibrium phase experiments by ben meftah and mossa 2006 showed that the extent of the scour hole was strongly dependent on time and observed an initial rapid stage a progressive stage and a final decelerated stage the initial high rate of solid transport was due to the high shear stresses exerted over the sand bed at the initial time the second stage was characterized by an increased rate of scour development much slower than the first stage the final slow stage was when the scour achieves equilibrium after a long period of time experiments by tregnaghi et al 2007 showed that the scour process usually reaches its equilibrium condition rapidly in live bed conditions and rather slowly in clear water conditions lu et al 2013 indicated that the scour hole in non cohesive sediments depends on the channel bed slope on the flow conditions on the densimetric froude number and on the sediment median size however the complex nature of the local scouring process shows that current knowledge is far from a full understanding of the phenomenon whereas most experiments provide measurements at a point or on a plane the complete flow field supplied by a computational fluid dynamics cfd simulation enables the reasearchers to have a deeper understanding of the scouring process therefore cfd methods have become a useful tool to study complex environmental fluid mechanics problems the estimation of erosion rates is a key issue for management and long term operation plans of many hydraulic structures in a management context modeling supports the prediction of changes in sediment balance upstream and downstream of a hydraulic structure with relatively low cost in this context the use of lagrangian meshless methods appears in general to be particularly suitable for dealing efficiently with the presence of two phases the combination of interfacial and free surface flows in addition to particle entrainment of sediments by the fluid among mesh free methods smoothed particle hydrodynamics sph has gained a widespread popularity in the last decades although it had been initially developed to study astrophysical problems gingold and monaghan 1977 lucy 1997 it has since then been extended to a wide range of engineering applications such as the breaking and impact of waves di monaco et al 2011 lin et al 2015 makris et al 2016 xia and liang 2016 de padova et al 2018a 2020a hydraulic jumps lópez et al 2010 federico et al 2012 de padova et al 2017 2018b c jonsson et al 2016 multi phase flows and fluid structure interaction fsi problems pu et al 2013 xie and jin 2016 de padova and mossa 2020 2020b 2021 calderon sanchez et al 2021 oscillating jets that induce breaking waves espa et al 2008 de padova and mossa 2019 2020b barile et al 2020 wastewater treatment meister and rauch 2016 simulation of landslides manenti et al 2016 ran et al 2015 during the last decade multi phase sph numerical studies on sediment transport have been carried out by manenti et al 2012 zanganeh et al 2012 ran et al 2015 fourtakas and rogers 2016 fu and jin 2016 khanpour et al 2016 pahar and dhar 2017 shi et al 2017 ulrich et al 2013 wang et al 2018 zubeldia et al 2018 bertevas et al 2019 zheng et al 2019 in manenti et al 2012 both liquid and granular materials were modelled as weakly compressible viscous fluids whose motion results from the numerical solution of the continuity and momentum equations discretized according to a standard sph formulation comparison with experimental results showed that the eroded volume and the profile evolution were better reproduced by the shields criterion zanganeh et al 2012 applied a two phase sph method for simulating scour processes beneath a marine pipeline with respect to the sediment and fluid phase interactions here the sediment and fluid phases were described as a non newtonian and newtonian fluid respectively and a sub particle scale sps model was used to represent turbulent stresses ulrich et al 2013 applied a two phase sph method to complex full scale marine engineering problems including the scouring of sea port bottom soil due to ship propeller induced flows here the soil phase was treated as a viscous material with a variable viscosity adhering to the mohr coulomb yield stress criterion for granular materials and the constitutive model was supplemented by a suspension treatment to capture the viscosity transition along the water soil interface in ran et al 2015 an incompressible sph isph erosion model was developed to investigate the sediment bed scour and grain movement under a dam break flow the sediment bed erosion model was based on the concept of pick up flow velocity and the sediment was initiated when the local flow velocity exceeded a critical value in fourtakas and rogers 2016 the numerical sph scheme was based on the bingham type herschel bulkley papanastasiou hbp model that allows simulating the rheology of the un yielded and the yielded material without needing to define a maximum value for viscosity the multi phase model was calibrated with experimental and 2 d reference numerical models for scour following a dry bed dam break in fu and jin 2016 a two phase sph method based on a rheology model and a higher order viscosity smoothening scheme was used to reproduce the open channel flow scouring and water sediment dam break flow in khanpour et al 2016 a two phase sph based on mohr coulomb and shields yielding criteria was used to reproduce the scouring downstream of a wall jet and a reservoir sediment flushing pahar and dhar 2017 developed a coupled solenoidal isph model for simulation of sediment displacement in erodible bed in wang et al 2018b a 3d isph sediment erosion model was proposed to simulate the scouring process around a large vertical cylinder the model was based on the twp concept wang et al 2016 and the sediment motion was initiated when the fluid bottom shear stress exceeded the critical value in zubeldia et al 2018 a two phase sph method based on the shields criterion and applied to the flow of a two phase liquid sediment mixture was employed to model the scouring flows with large deformations in luo and kazemi 2019 a sph sediment model was used to study the dynamic hydraulic jump in steep open channels in bertevas et al 2019 a sph formulation of the classical two phase mixture model was used to study the turbulent sediment transport and the sediment disturbances generated by moving equipment operating near or on the seabed the rheological behavior of clay sediment water mixtures was modelled using a volume fraction shear rate dependent viscosity which accounts for the existence of a yield stress in general some sph approaches consider the sediment as a single phase moving mass other approaches model the sediment as a two phase mixture where the voids of the solid matrix are filled by a liquid phase in order to account for the pressure effect however in all these approaches the basic idea is to model the sediment dynamics like a pseudo fluid one once the onset of sediment particle motion is attained as a result a criterion that represents the critical condition for the incipient motion of sediment must be defined this can be done in terms of the critical velocity hayashi et al 2003 ran et al 2015 or the critical shear stress manenti et al 2012 in some of the considered works a numerical threshold was used for this purpose and therefore it is evident that the prediction capability of the model depends on the calibration made to overcome this limitation a wcsph formulation of a mixture model consistent with the kinetic theory of dense granular flows ktgf was introduced by amicarelli et al 2017 showing a suitable degree of accuracy the reader can refer to manenti et al 2019 for a comprehensive review of the studies on multi phase sph erosion models starting from the research experiences described above the main aim of this study is to exploit the features of the sph method i e its inherent ease in the treatment of different rheologies as well as of rapidly varying free surfaces and interfaces to investigate the effect of sediment movement under the action of rapid flows such as the ones occurring downstream of a bed sill which lead to the formation of unsteady hydraulic jumps and evolving scour holes to reach this goal an existing sph model which has proven to be highly effective in the description of unsteady free surface flows dominated by turbulence and wave breaking see e g espa et al 2008 de padova et al 2013 2018b and 2020a was extended to include the treatment of soil water interaction among the different available models the one developed by ulrich et al 2013 has been considered suitable because of its peculiar two phase approach which takes into account the granular bed as a separate granular phase but treats the water sediment suspension as a single fluid phase with variable viscosity the calibration of the sph model has been performed by comparing experimental and numerical observations of the local scour holes downstream of a hydraulic jump finally sph simulations have been used i to inspect and detail the vorticity field evaluating in particular its temporal evolution ii to relate the vorticity field and the scour process iii to relate the vorticity field and the free surface dynamics in particular to the flow surface parallel deceleration and iv to study the temporal evolution of the dominance of vorticity and strain 2 sph numerical method the liquid granular flow has been simulated through a sph approach where the two phases treated as continua with different physical and rheological properties are represented by different sets of particles and no transfer of mass is allowed from one phase to the other time advancement is obtained through a symplectic weakly compressible sph wcsph scheme where artificial compressibility is introduced to solve explicitly in time the equations of motion of the two incompressible fluids the motion of both continuum phases is represented by the navier stokes equations which take the following sph semi discrete form 1 d ρ i d t j 1 n i m j v i v j w i j d v i d t j 1 n i m j p i ρ i 2 p j ρ j 2 w i j j 1 n i m j ρ j t i t j w i j g p i p 0 c i 2 ϱ i ρ 0 t i η i s i where wij represents the c2 wendland kernel function wendland 1995 evaluated at the interparticle distance and defined over a circle having a radius double than the smoothing length h sph particle approximation is indicated by angled brackets and is written for each particle i having mass mi the summations in 1 are extended to all the ni particles j located at a distance smaller than 2 h from particle i irrespective of the material characterizing the particles in eq 1 v u w is the velocity vector p is pressure p is density g is the gravity acceleration vector t is the shear stress tensor c is the speed of sound in the weakly compressible fluid η is a suitable viscosity coefficient s is the rate of strain tensor and the subscript 0 denotes a reference state for pressure computation the way in which the viscosity coefficient is evaluated defines the different models which represent the flow of the two phases the tilde notation w i j indicates that the gradient of wij is renormalized by enforcing 1st order consistency on the 1st derivatives sibilla 2015 leading to a 2nd order accurate discretization scheme in space the kernel renormalization is applied to all of the terms in 1 apart from the pressure gradient term where the form originally proposed by monaghan 1992 is retained to guarantee momentum conservation 2 1 turbulent liquid flow in the case of a turbulent flow of the liquid phase all variables in 1 are assumed to be reynolds averaged and the equations of motion become the reynolds averaged rans equations in this case η represents the kinematic eddy viscosity which is evaluated through a standard k ε turbulence model launder and spalding 1974 as η c μ k 2 ε where k is the turbulent kinetic energy and ε the turbulent dissipation rate in the same sph semi discrete form as 1 the equations for the turbulence model are de padova et al 2016 2 d k i d t p k i 1 σ k j 1 n i m j η i η j ρ i ρ j k i k j r i j 2 0 01 h 2 r i j w i j ε i d ε i d t c ε 1 ε i k i p k i 1 σ ε j 1 n i m j η i η j ρ i ρ j ε i ε j r i j 2 0 01 h 2 r i j w i j c ε 2 ε i k i j 1 n i m j ρ j ε j w i j where pk is the production of turbulent kinetic energy depending on the local rate of deformation and the model constants have the following values σk 1 σε 1 3 cε 1 1 44 ce 2 1 92 2 2 granular and suspension flow following ulrich et al 2013 the granular phase is treated as a viscous material with a variable viscosity which takes into account also the viscosity transition in the layer where the granular material is found in suspension inside the liquid flow the concentration of the suspension is estimated through sph interpolation as 3 c i j 1 n g i m j ρ j w i j k 1 n i m k ρ k w i k where ng i are the particles of granular material surrounding particle i for a concentration ci 1 the viscosity of the granular material is computed according to the mohr coulomb yield stress criterion 4 η i m c min η m a x χ cos ϕ p i sin ϕ ρ g s i where χ is the cohesion φ the friction angle and ηmax an upper threshold for viscosity to avoid the singularity which occurs when the strain rate vanishes the viscosity of the suspension is derived from the assumption of a constant friction coefficient which yields 5 η i s min η m a x c f v i 2 s i a constant value cf 0 01 is assumed for the friction coefficient within the range suggested by fraccarollo and capart 2002 to smooth the transition between the different layers the viscosity values are piecewise linearly interpolated between the turbulent eddy viscosity the suspension viscosity ηs and the granular viscosity ηmc according to the local value of the concentration 3 6 η i c μ k i 2 ε i η i s c μ k i 2 ε i c 1 c i for 0 c i c 1 η i s for c 1 c i c 2 η i s η i m c η i s c 3 c 2 c i c 2 for c 2 c i c 3 η i m c for c 3 c i 1 for the boundary values between the different viscosity regions the same values suggested by ulrich et al 2013 were adopted i e c 1 0 3 c 2 0 6 and c 3 0 99 it must be noted that the model by ulrich et al 2013 is essentially a single phase model for the suspension which is treated as a fluid with varying rheological properties dependent on the local suspended solid concentration as such the model does not take into account explicitly the mass fluxes between the bed granular material and the suspended sediment in the water flow in this sense it is an approximate model which holds in the hypotheses of solid transport mainly occurring as bed transport and of non negligible values of the mixture viscosity only occurring in the near bed layer given the fact that the bed material here analysed is a coarse sand as explained in section 3 these hypotheses can be accepted the semi discrete system 1 and 2 is integrated in time by a 2nd order two stage xsph explicit algorithm with a pressure smoothing procedure specifically designed for free surface flows more details on the adopted sph scheme can be found in de padova et al 2013 de padova et al 2016 inflow boundary conditions are assigned by introducing a 2h wide buffer layer upstream of the computational domain where the required conditions are imposed to particles located between the bed and the water surface each inflow particle is then moved at a constant velocity uc for a time ti 2 h uc and with constant values of turbulent energy and dissipation until it enters the computational domain where its properties evolve according to eqs 1 and 2 the number of entering particles is determined by the inlet water depth h 1 and is regulated in time in order to guarantee the exact mass flow rate at the inlet k and ε at the inlet are computed according to an average initial turbulence intensity of 1 zero gradient outflow boundary conditions are imposed to all the quantities but pressure by introducing a second 2h wide buffer layer downstream of the computational domain where the particle velocity k and ε are kept unchanged pressure is instead imposed according to the hydrostatic pressure gradient resulting from the outlet water depth h 2 3 numerical test 3 1 numerical parameters and validation of the sph results the numerical scheme described above was used to reproduce the local scouring process experimentally observed downstream of the first bed sill located 2 m downstream of the wooden ramp fig 1 the experimental flume bottom is covered with uniform sand particles with a nominal diameter d50 1 8 mm and density ρ 2650 kg m3 the sill height decreases progressively downstream of the wooden ramp respecting an assigned initial slope s0 0 0086 table 1 lists the main experimental parameters of the investigated scour process l is the distance between sills hc is the flow depth over the crest of the sill downstream of which the scour hole is measured u c is the flow velocity over the sill zs is the maximum equilibrium scour depth from the original bed profile h s is the flow depth at the position of maximum equilibrium scour depth fdc u c δgd 50 0 5 is the densimetric froude number for the approaching flow over the sill further details and discussion of the results of the experiments can be found in ben meftah and mossa 2006 and in ben meftah et al 2020 2021 the numerical domain is 1 2 m long and 0 6 m high shorter than the laboratory channel such a shorter domain was chosen to reduce the computational cost without influencing the quality of the numerical solution as shown by de padova et al 2014 an upstream flow depth h 1 hc 0 048 m was therefore chosen while a flow depth h 2 0 056 m was imposed downstream a sketch of the problem setup and of the initial conditions of the sph simulation can be seen in fig 2 the efficiency of the sph kernel function depends also on the choice of the h δ ratio where δ is the particle spacing de padova et al 2014 showed that a value h δ 1 2 should be preferred here the initial particle spacing was taken to be δ 0 002 m and a ratio h δ 1 5 was used the resulting initial number of sph particles in the simulation was approximately 60 000 a thorough sensitivity analysis was already performed by the authors in the application of the same sph numerical method to hydraulic jumps and breaking wave flows de padova et al 2018c 2019 according to this analysis the sph simulations of the cases here studied were performed by adopting a velocity smoothing coefficient in the xsph scheme φv 0 01 the simulations were performed with χ 10 pa φ 41 and ηmax 0 01 m2 s in eq 4 the validity of the numerical scheme adopted here was checked against the experimental observations of the local scour holes downstream of hydraulic jumps reported by ben meftah and mossa 2006 the evolution of the scour hole during the sph simulation is shown at various time instants in fig 3 fig 4 shows the resulting sph and experimental velocity fields superimposed in a vector plot inside the scour hole downstream of the first bed sill located 2 m downstream of the wooden ramp the obtained results highlight that the final model proves to be capable of reproducing the experimental bed evolution the flow velocity and turbulence intensity through the scour hole actually the three regions which characterize the flow according to the experiments are clearly reproduced in particular the flow in region 1 plays a very important role in the initial phase of the scour development this is due to its high velocity which leads to an increase of the jet potential erosive action on the bed channel region 2 is dominated by a clockwise local vortex at the position of maximum scour depth in region 3 the velocity vectors tend to be more horizontal the measured black dots and simulated blue dots bed profiles at equilibrium are also compared and show a substantial agreement fig 5 shows the streamwise u and the vertical turbulence w intensities u is defined as the ratio of the standard deviation of the streamwise flow velocity component fluctuations to the average velocity uc w is defined as the ratio of the standard deviation of the vertical flow velocity component fluctuation to the average velocity uc in the discussion the fluctuations u and w can be considered to be referred to the large scale fluctuations which are resolved and directly computed by the lagrangian time dependent sph while the k ε turbulence model takes into account also the effect of the modelled small scale turbulent eddies in a global way averaging the information on the microscopic turbulence anisotropy the numerical results show that the behavior of the simulated liquid granular flow is consistent with the experiments of ben meftah and mossa 2006 in particular the results show that i the vertical turbulence intensities w are smaller than the streamwise ones u ii the maximum streamwise u and vertical w turbulence intensities take place at the regions 1 due to the more intermittent behavior of the jet flow iii the minimum streamwise u and vertical w turbulence intensities take place at the region 3 due to the steadier flow velocity distribution iv in region 2 the streamwise u and vertical w turbulence intensities show the smallest values comparable to those occurred in region 1 due to the flow velocity reduction v at the different downstream positions x xs the streamwise u and vertical w turbulence intensities decrease with decreasing z zs i e approaching the equilibrium scour bed fig 6 shows the vertical profiles of the time averaged turbulent kinetic energy k u 2 w 2 2 normalized by uc herein the angle brackets indicate the average over the length of the time series the agreement between the numerical results and laboratory measurements is satisfactory these results highlight that i at all vertical profiles except the one at x xs 1 33 the time averaged turbulent kinetic energy k decreases when z zs decreases i e going down to the equilibrium scour bed ii at x xs 1 33 the time averaged turbulent kinetic energy k increases when z zs decreases due to the effect of the transition between regions 1 and 3 to evaluate the model performance table 2 shows the statistical analysis of the comparison between the numerical model and the experimental results in terms of the wilmott index wilmott 1981 i w 1 k 1 n x c k x m k 2 k 1 n x c k x m x m k x m 2 7 where x c and x m are the modelled and measured values of the variable x respectively while the bar denotes the average of the modelled and measured values a perfect agreement between the measured and modelled values is reached when i w is equal to 1 while a complete discrepancy between numerical and experimental results is observed when iw tends to 0 therefore the sph model provides a satisfactory prediction in terms of the flow velocity field and the turbulence intensity in the scour holes 3 2 flow characterization since turbulence is the most important mechanism of sediment entrainment causing a significant increase in the shear stress around the base of a hydraulic structure the flow velocity field in the scour holes was analysed therefore in this section we provide a simple characterization of the flow based both on the vorticity ω and on the okubo weiss parameter w okubo 1970 weiss 1991 vorticity is defined as 8 ω u z w x and is computed using instantaneous values of the horizontal and vertical velocity the w parameter is defined as 9 w s n 2 s s 2 ω 2 where ω is the vorticity defined by 8 while s n u x w z and s s w x u z respectively are the normal and shear components of strain rate the vorticity maps shown in fig 7 were computed from the sph vector fields furthermore the flow behavior is well described by the instantaneous streamlines representing a single snapshot obtained from the instantaneous velocity field calculated on a regular grid fig 7 analyzing the results the equilibrium configuration of flow field and bed topography is reached after a transitory period in which the system oscillates between two flow patterns i at first fig 7 a the presence of a scour hole with a relatively steep hump downstream of it leads to an increase of the free surface elevation and to the generation of a b jump type with a counterclockwise rotating macro vortex structure negative vorticity which pushes the main flow towards the bed where a strong erosive action is observed and sediments are forced to move downstream this behavior of the liquid flow is clearly observed by looking at the streamlines which show that the majority of the flow is oriented parallel to the bed in the downstream direction however over the scour hole the streamlines clearly show the flow recirculation and the fluid moving in the upstream direction near the free surface ii later when the scour hole shows a milder inclination fig 7 b the formation of a wave jump is observed this wave jump is dominated by a clockwise rotating macro vortex structure positive vorticity here the clockwise circular motion over the scour hole is clearly shown by the streamlines the surface boundary layer near the free surface with positive vorticity grows in the downstream direction furthermore there is a concentrated region of negative vorticity near the bed the analysis of the vorticity maps alone is not sufficient to identify vortices since they are masked by background shear thus considering that turbulent structures essentially evolve from interactions between vorticity and strain rate the maps of the okubo weiss parameter w have been also used to detect coherent structures mattioli et al 2012 hilt et al 2020 using the local value of w the flow domain can be partitioned in three distinct types of regions i vorticity dominated regions or elliptic regions w 0 ii strain dominated regions or hyperbolic regions w 0 iii intermediate regions w 0 figs 8 and 9 show the comparison between the instantaneous map of ω and of w rated by w 0 0 2σw with σw being the standard deviation of w in the whole domain at beginning of erosive action t 2 s and when the stable configuration has been reached t 165 s respectively the map of w w 0 shown in fig 8 b highlights the presence of coherent eddies w 0 in the near surface region which is characterized by negative vorticity fig 8 a a strain dominated region is instead observed in the scour hole the dominance of strain rate is observed until the scour hole shows relatively steep walls and where a strong erosive action is observed instead when the scour hole shows a relatively mild inclination and a stable formation of a wave jump has been observed fig 9 a the dominance of the strain rate terms is greatly reduced fig 9 b in order to better understand the behavior of the vorticity field at equilibrium configuration fig 9 a the flow deceleration due to the convective term u s u s s has been studied as shown by misra et al 2008 the mean surface parallel velocities have been calculated as 10 u s u cos θ v sin θ where θ is the inclination of the mean surface on the horizontal fig 10 shows the instantaneous map of the surface parallel convective acceleration when the stable configuration has been reached we observe that a flow deceleration occurs in the same location where a strong positive vorticity appears this is consistent with the observations made by dabiri and gharib 1997 that theoretically derived that near surface vorticity increases with increasing deceleration term 3 3 local scouring process characterization some experimental studies noticed a cyclic variation of jump types under specific flow conditions ohtsu and yasuda 1991 mossa 2002mossa et al 2002 chanson and toombes 1998 mossa 1999 mossa et al 2003 the experiments by abdel ghafaret al 1995 on local scour in sand bed channel due to hydraulic jump showed that the hydraulic jump tended to repeat itself in a periodic form from clockwise to anti clockwise rotation of the vortex these results confirm the experimental findings by mossa 1999 who showed that the oscillations of the hydraulic jump depended on the shape of the bed and on the hydrodynamic characteristics of the channel flow in agreement with these observations fig 11 highlights that the configurations in which the oscillation between b and wave jump appears occur along a boundary between the two regions of occurrence of each type this boundary is represented by a log relation between the upstream froude number f r 1 u 1 g h 1 and the water depth ratio h 2 h 1 to understand the effect of oscillating hydraulic jumps on the scouring profiles the calculated scouring profiles at different times are plotted in fig 12 the results obtained by the numerical model indicate that the maximum scour depth is almost constant after 160 s run time the results show that a strong horizontal erosive action tends to rapidly intensify when the system shifts from b to wave jump analyzing the instantaneous vorticity fields the transition between the two jump types starts at t 63 s and clearly ends at t 65 s in fact from t 63 s fig 12 shows a reduction in the vertical scour depth and a rapid increase in the horizontal scour depth fig 13 reveals that three different phases of the scour process can be identified phase i where the flow is characterized by a b jump shows a rapid increase of the scour to a depth which is more than 60 of the final depth while the scour length increases at a much slower rate phase ii when the transition between the two jump types has been observed is dominated by a strong and fast increase of the horizontal dimension of the scour hole while its depth decreases owing to the collapse of the upstream side finally during phase iii a stable wave jump is observed and the scour depth length and volume all increase until equilibrium is reached 4 conclusions the objective of the present work was to investigate the vorticity generation mechanism in a scour hole developed downstream of a grade control structure in sand bed channels providing a full hydrodynamic picture of the scouring process the liquid granular flow has been simulated through a symplectic weakly compressible sph wcsph scheme with a two equation turbulence model where the two phases are treated as continua with different physical and rheological properties in the hypothesis of solid transport mainly occurring as bed transport and of suspended solids only influencing the apparent viscosity of the liquid flow the sph model was validated by comparing the simulated results with the experiments on the local scour holes downstream of hydraulic jump showing that the simulations were consistent with experimental data as experimentally observed our results indicate that three regions can be identified the first is dominated by a jet like flow characterized by high speed and plays a very important role in the downstream movement of sediments the second is dominated by a clockwise local vortex at the position of maximum scour depth third is dominated by a relatively aligned horizontal flow the detailed analysis of the turbulence characteristics in the scour hole at equilibrium conditions shows that both the maximum value of the streamwise and of the vertical turbulence intensities occur in the first region due to the jet flow in the third region there is a sharp reduction in turbulence intensity at equilibrium conditions the stability of sediment particles is due to a significant decrease of turbulent energy production at the bed flow interface the equilibrium configuration of flow field and bed topography is reached after a transitory period in which the system oscillates between two flow patterns i the presence of a scour hole with a relatively steep hump downstream of it increases the free surface elevation and generates a b jump type characterized by a counterclockwise rotating macro vortex structure negative vorticity which pushes the main flow towards the bed where a strong erosive action is observed ii the scour with a relatively modest inclination of the scour cavity leads to the formation of a wave jump dominated by a clockwise rotating macro vortex structure positive vorticity furthermore a cause effect relation between near surface flow deceleration and vorticity fluxes is detected similarly to what observed in dabiry and gharib 1997 the maps of the relative okubo weiss parameter w w0 highlights the presence of coherent eddies w 0 in the region which exhibits negative vorticity near the surface instead a strain dominated region is observed in the scour hole the dominance of strain rate is observed until the scour hole shows relatively steep walls and where a strong erosive action occurs instead when the scour shows a relatively mild inclination and a stable wave jump forms the dominance of the strain rate terms is greatly reduced finally the calculated scouring profiles at different times have been plotted to understand the effect of oscillating hydraulic jumps these profiles show that the scour process evolves in three distinct phases phase i when the flow is characterized by a b jump shows a rapid increase of the scour to a depth which is more than 60 of the final depth while the scour length increases at a much slower rate phase ii when the transition between the two jump types takes place is dominated by a strong and fast increase of the horizontal dimension of the scour hole while its depth decreases owing to the collapse of the upstream side phase iii when the flow is characterized by a stable wave jump and the scour depth length and volume all increase until equilibrium is reached author contributions d d p and s s performed the numerical modeling m m and m b m performed the experiments d d p m b m m m and s s analyzed the data d d p wrote the paper m b m m m and s s contributed suggestions discussions and reviewed the manuscript all authors have read and agreed to the published version of the manuscript declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the experiments were carried out at the hydraulic laboratory of the mediterranean agronomic institute of bari italy 
