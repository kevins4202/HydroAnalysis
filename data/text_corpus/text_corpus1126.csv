index,text
5630,the flow and chemistry of groundwater in agricultural riparian zones are highly heterogeneous due to the human impacts as well as convergent flow conditions and variable stream aquifer interactions to evaluate impact of seasonal heavy pumping on the aquifers in agricultural riparian zones we investigated groundwater and stream water using a multi parameter approach integrating continuous monitoring of water level and temperature and periodic measurements of hydrogeochemical parameters water stable isotopes and microbial communities in agricultural riparian zones with contrasting patterns of land use and water use across the third order stream for two years in the mid western south korea intense groundwater use for warming of greenhouses in dry farmland during winter induced groundwater drawdown of up to 5 m resulting in losing stream condition and decreased groundwater temperature with considerable spatial variability groundwater contamination was clearly identified based on elevated concentrations of agriculture derived solutes such as ca2 and so4 2 despite the negligible no3 content under reducing conditions three component mixing of groundwater based on δ18o and dissolved silica revealed major water sources of regional recharge paddy soil water and winter stream water with considerable differences in their contributions between the riparian zones the fraction of winter stream water in groundwater showed different temporal variability depending on aquifer connectivity with the stream as well as groundwater use principal component analysis of hydrogeochemical and isotopic parameters revealed the major processes of agricultural contamination water rock interactions and the contribution of paddy impounded water which varied significantly with the extent of stream water infiltration these results suggest that seasonal pumping substantially affect groundwater flow and its relationship to stream with considerable horizontal and vertical variability in riparian aquifers this study highlights spatial and temporal variations of groundwater flow dynamics in riparian areas are effectively delineated by a multi parameter approach which can contribute to better understanding of stream aquifer interactions and implementation of integrated water management in the areas with agricultural land uses and water uses keywords riparian zone multi level well temporal variation stable isotope multivariate statistical analysis 1 introduction riparian zones are transitional areas between terrestrial and aquatic ecosystems which connect water bodies to their adjacent uplands via surface and subsurface hydrological processes gregory et al 1991 nrc 2002 convergent groundwater flow is dominant in riparian aquifers where variable interactions with surface water depend on the connectivity between streams and aquifers toth 1963 brodie et al 2008 li et al 2016 in riparian zones surface water and groundwater interact according to the spatial and temporal hydrological conditions considerably affecting the fate of nutrients in surface water and groundwater hill 1996 roy and bickerton 2014 dwivedi et al 2018 human activities including agriculture are increasingly affecting hydrological and ecological systems in riparian areas as well as adverse impacts on groundwater and surface water interactions such as depletion of surface water and introduction of contaminants in those areas watson et al 2010 zeng et al 2016 in particular agricultural land uses in riparian zones play an important role in controlling contaminant transport by increasing the complexity of groundwater flow and its interaction with surface water through intense groundwater use and irrigation in riparian zones krause et al 2008 menció et al 2016 most agricultural activities in riparian zones rely on both riparian groundwater and surface water schilling et al 2006 watson et al 2010 mcdonald et al 2013 continued pumping lowers the groundwater level and surface water infiltrates into the aquifers inducing recharge when the zone of contribution reaches the stream winter et al 1998 chen and yin 2001 one of the factors controlling the amount and flow path of water to be infiltrated is the connectivity between the stream and adjacent aquifers which is mainly determined by the distance from the stream hydraulic conditions and hydrogeological properties of the aquifer and streambed stanford and ward 1993 western et al 2001 chen and shu 2002 li et al 2016 in korea groundwater has been used since late 1980s to aid in heating greenhouses during winter by either spraying water between two layers of the greenhouses or allowing to flow into an open waterway inside the greenhouse when the air temperature drops below zero in celsius which is known as water curtain cultivation wcc facilities park et al 1988 maf 2014 this agricultural practice results in heavy withdrawal of groundwater from the riparian aquifer with groundwater use reaching up to 1 55 billion m3 y 1 in korea nihhs 2007 some studies investigated the effects of wcc on the decline of groundwater levels of alluvial aquifers and the depletion of flow in adjacent streams kim et al 2012 lee et al 2017 however few studies were done for the spatial and temporal responses of aquifers to intense seasonal groundwater withdrawal using multi level monitoring wells in agricultural riparian zones many previous studies have attempted to identify interactions between streams and groundwater by monitoring water levels and temperatures sophocleous et al 1988 zume and tarhule 2008 yang et al 2017 el zehairy et al 2018 to combine various monitoring data pertaining to the water level temperature and ec multivariate analyses have been used to identify the key factors determining the interaction between groundwater and surface water page et al 2012 mixing analyses using relevant hydrogeochemical and isotopic parameters have been applied in riparian zones to evaluate stream aquifer interactions nakaya et al 2007 neumann and curtis 2016 temporal variation in hydrogeochemical parameters has also been used to identify contaminant sources and evaluate groundwater and surface water interactions as well as geochemical processes controlling the fate of contaminants menció and mas pla 2008 king et al 2014 recent studies have revealed that microbial community structures in aquifers are strongly related to redox conditions and human impacts suggesting that these are good indicators of changes in groundwater systems flynn et al 2013 sirisena et al 2013 we constructed a test site to investigate stream aquifer interactions with several multi level wells in two riparian zones of a stream with different degrees of wcc activities heavy groundwater withdrawal in this area results in strong seasonal changes in groundwater levels and streamflow discharge cho et al 2012 lee et al 2015 groundwater withdrawal and irrigation in the test area are highly variable both in temporal and spatial terms which may cause complicated responses in the riparian aquifers and stream aquifer interactions kwon et al 2017 difference in agricultural activity on the riparian zone can be judged to be an important factor in the interaction between stream and aquifer we evaluated impact of seasonal heavy pumping on the aquifers in riparian zones through an integrative approach using continuous monitoring of water levels and seasonal investigation of hydrogeochemical parameters water stable isotopes and microbial community structures and identified stream water infiltration into the aquifer using water temperature and a three component mixing model we also investigated the responses of hydrogeological and hydrogeochemical parameters of aquifers to infiltration of stream water 2 study area 2 1 hydrogeological setting the study area is 50 km away from the geum river estuary which is located in the mid western part of the republic of south korea fig 1 and riparian zones near noseongcheon stream ns a third order stream which is a tributary to the geum river one of the four major rivers in the republic of south korea the noseongchen stream is 27 7 km long and its catchment area is 202 5 km2 the northern riparian zone nrz and southern riparian zone srz were divided by levees into stream side areas and plain side areas making up the four main hydrogeological divisions of the study area the difference in elevation between the stream bed and stream side areas was 4 to 5 m alluvium in the area is 4 5 m to 8 3 m thick and overlies weathered zones of jurassic granodiorite kigam 2011 clay embedded layers were found at depths between 3 8 and 8 3 m in most of the study area as identified by neutron logging which measures total porosity in the unit of limestone porosity unit lpu won et al 2017 in the nearby riparian zone of the main stream of the geum river sediment layers intercalated with clay and sand with thicknesses of 3 m were found at a depth of approximately 5 m with considerable horizontal continuity these were deposited in back marshes formed by flooding in later stages of the last interglacial period park 2014 a weathered zone with an average thickness of 20 m underlies the alluvial sediments identified using a two dimensional resistivity survey with dipole array and modified pole pole array won et al 2013 the bedrock is jurassic granodiorite containing quartz plagioclase microcline orthoclase biotite chlorite and minor minerals including muscovite pyroxene and apatite kigam 2011 the study area has a monsoonal climate with hot and humid summers between june and august and cold and dry winters from november to january the average precipitation is 1244 4 mm and the average annual temperature is 12 2 c according to measurements taken from nonsan automatic weather station between 1998 and 2017 which is 2 2 km away from the study area and operated by the korea meteorological administration kma in total 67 of the annual precipitation is concentrated between june and september the monthly average temperature from november 2014 to november 2016 was lowest in january at 1 1 c and highest in august at 26 4 c at the watershed of the ns the average groundwater recharge rate was determined to be 15 9 of precipitation molit 2015 in the study area according to pumping and slug tests the hydraulic conductivity of the alluvial sediment and fractured zone is 55 3 and 5 1 m d 1 respectively the storage coefficient of the aquifer ranges from 1 5 10 4 to 5 5 10 4 cho et al 2012 2 2 agricultural activities land uses in the study area are rice paddy and vegetable producing dry farmland in the plains area while orchards and residential areas are present in the hilly terrain fig 1 annual use of nitrogen chemical fertilizers averaged 201 kg ha 1 yr 1 for the period between 1995 and 2005 nonsan si 2007 which is close to the average use in south korea of 218 kg ha 1 yr 1 maf 2014 the total number of wells in the watershed is 6056 and the withdrawal rate is 6 459 000 m3 y 1 molit 2015 in the past the agricultural areas in this region were mainly rice paddies since 2003 strawberry cultivation has become widespread in nonsan the region is now one of the most famous strawberry growing areas in korea kigam 2010 in the study area considerable portions of rice paddies have been converted into dry farmland for strawberry cultivation fig 1 the air temperature in nonsan is lower than 0 c at night in winter which is far lower than the temperature required for strawberry cultivation which is about 10 c jeong et al 2011 the air temperature in the strawberry growing greenhouses are maintained by wcc facilities which spray groundwater with a temperature of approximately 13 c as a source of heat these usually operate from mid november to early march strawberry cultivation using wcc is widespread within the nrz the groundwater levels of the wells for agriculture use were between 4 6 5 2 m asl and 3 8 to 0 5 m asl with drawdowns of up to 8 m in the watershed including the nrz which was attributed to intense groundwater pumping during wcc kwon et al 2017 the average groundwater withdrawal in the nrz was estimated to be 420 m3 d 1 ha 1 for this area the annual total groundwater withdrawal is 1 310 400 m3 y 1 based on the number of wcc days 120 d y 1 and areas 26 ha lee et al 2015 groundwater used for wcc is discharged to the noseongcheon stream along the impermeable concrete ditch whose outlet is located at the downstream site of the groundwater monitoring wells fig 1 by contrast the southern part of the stream the srz is still mainly composed of rice paddies groundwater withdrawals in the srz are much smaller than in the nrz because the water sources for rice paddies are mainly surface water from reservoirs and weirs nam et al 2017 rice paddies are irrigated with upstream reservoir water through the impermeable irrigation channels from may to august rice growing season and no water is flowing in the channels during other season 3 methods 3 1 water level and temperature monitoring total 12 monitoring points including four multi level wells and one single point well were installed for monitoring groundwater levels and temperature and for sampling fig 1 each monitoring well had a diameter of 35 mm and a 1 m long screened interval near the bottom and more detail specifications are in table 1 multi level groundwater monitoring is commonly used for observation of multiple parameters to properly understand the highly heterogeneous flow systems and chemical characteristics of groundwater in riparian zones choi et al 2009 sharma et al 2012 bailey et al 2015 rønde et al 2017 we installed a standpipe with a screen in the streambed to monitor the level and temperature of the stream water the water level and temperature were measured at 5 min intervals using micro diver eijkelkamp soil water giesbeek the netherlands with measurement errors in pressure and temperature of 1 cm h2o and 0 1 c respectively data on the stream water level and temperature were missing from 17th april 2016 to 24th may 2017 due to stream maintenance operations which were carried out by the local municipality 3 2 sampling and measurement in total we carried out 12 sampling campaigns to obtain samples to assess chemical and physical parameters and water stable isotopes from october 2014 to april 2017 we collected 127 groundwater and stream water samples for groundwater sampling we used a peristaltic pump to purge three times the volume of groundwater in the individual wells to remove the well bore effect prior to sampling occasionally groundwater samples could not be taken from the shallowest wells where the water level had decreased to near the bottom of the well and the well had been consequently dried field parameters such as temperature ph ec and dissolved oxygen do were monitored during purging and water samples were taken after these parameters were stabilized soil water in paddy fields near the nrz was also collected four times in winter of 2018 using a suction lysimeter sks20 ums corp münchen germany at a depth of 80 cm for measurements of stable isotopes and selected chemical parameters all of the water samples were filtered using 0 45 μm membrane filters and we acidified the aliquots for cation analyses to ph 2 in the field using concentrated nitric acid anions including cl so4 2 no3 and f were measured using ion exchange chromatography with conductivity detection ics 1500 dionex sunnyvale ca usa ca2 mg2 na k and sio2 aq were measured using inductively coupled plasma optical emission spectrometry optima 7300 dv icp oes spectrometer perkin elmer shelton ct usa the alkalinity was evaluated as the total alkalinity using an automatic titrator t50 titrator mettler toledo columbus oh usa with acidimetric titration to the end point of ph 4 5 the charge balance errors of all samples were less than 8 water stable isotopes were analyzed by wavelength scanned cavity ring down spectroscopy l1102 i picarro sunnyvale ca usa with typical precision of 0 1 and 0 5 for δ18o and δ2h respectively jung et al 2013 3 3 multivariate statistical analyses msa principal component analyses pcas were used to identify major geochemical processes controlling the flow system and chemistry of groundwater schot and van der wal 1992 thyne et al 2004 principal components pcs were extracted from a correlation matrix of 16 hydrogeochemical variables temperature measured at sampling ph total dissolved solids tds do ca2 mg2 na k hco3 cl so4 2 no3 f sio2 aq δ18o and δ2h for 127 groundwater samples concentrations below the detection limit were assumed half of the detection limit the variables were logarithmically transformed due to their log normal distributions except for ph δ18o and δ2h pcs with eigenvalues larger than 1 were selected and rotated iteratively using the varimax method varimax rotation reduces the overlap between the original variables and is useful for finding factors that can be readily explained by hydrogeochemical processes helena et al 2000 3 4 microbial community analyses every 2 l of groundwater and stream water samples was passed through a 0 2 μm membrane filter advantec mfs dublin ca usa in the field and the filters were stored at 70 c until deoxyribonucleic acid dna extraction genomic dna was extracted from the filters using the dneasy powerwater kit qiagen hilden germany following the manufacturer s protocol and stored at 20 c until further analysis the genomic dna extracted from the groundwater samples were amplified in the v3 v4 region of the 16s ribosomal ribonucleic acid 16s rrna gene using the miseq platform illumina san diego ca usa at macrogen seoul south korea the raw sequence data were analyzed using mothur v 1 38 schloss et al 2009 and standard miseq sequence operating procedures kozich et al 2013 4 results 4 1 spatial and temporal variation in water level and temperature groundwater levels in the study area increase in the humid summer when heavy rainfall occurs and decrease in the dry winter which is typical in the monsoon climate of korea moon et al 2004 additional drawdown was observed in winter due to intense pumping for wcc in the nrz which was smaller in the srz where paddy fields are dominant cho et al 2012 meanwhile the stream water level remained constant despite peaks in runoff from rainfall events because it is artificially controlled with a weir and large reservoir located upstream of the monitoring site fig 2 stream water temperature exhibited typical fluctuations similar to those of atmospheric temperature while groundwater temperature in the plain side area was nearly constant with lower temperatures in nrz than in srz fig 2 groundwater temperature in the nrz stream side area was as low as 11 4 c on average with the largest variation of 8 4 c by contrast deeper wells in the srz plain side area had a higher average temperature of 15 0 c with the lowest variation of 1 3 c the unusually high variability of groundwater temperature indicates the effects of stream water with seasonally variable temperature best exemplified by the lowest groundwater temperature being observed in the nrz stream side area due to infiltration of winter stream water such changes in groundwater temperature induced by anthropogenic activities have been reported in alluvial aquifers connected to losing streams duque et al 2010 kigam 2011 lee et al 2017 to clarify the relationship between stream water and groundwater pca was performed using water level and temperature monitoring data collected in 6 h intervals page et al 2012 fig 3 principal component loadings of the groundwater level were similar while those of groundwater temperature were highly varied the groundwater level measured in the nrz plain side area which was most strongly affected by intense pumping of groundwater in winter had the weakest correlation with stream water level while the groundwater level in the stream side area had the strongest correlation with the stream water level by contrast groundwater temperature appears to be controlled by spatial heterogeneity such as the distinctively lower temperature in the nrz stream side area due to infiltration of winter stream water silliman et al 1995 groundwater temperature in the nrz stream side area had the strongest correlation with stream water temperature which was observed to a lesser extent in the srz stream side area meanwhile groundwater temperature in the srz plain side area had the weakest correlation with stream water temperature 4 2 hydrogeochemical parameters and water stable isotopes the observed nitrate concentration was surprisingly low and was near the detection limit 0 05 mg l 1 in many groundwater samples despite annual application of a considerable amount of nitrogenous chemical fertilizers however elevated concentrations of ca2 and so4 2 are indicative of agricultural contamination kelly 1997 nikolaidis et al 2008 puig et al 2013 sulfate concentration was higher with a large variation and in the range defined by two regional studies near the study site choi et al 2008 koh et al 2009 which focused on typical riparian zones with agricultural activities spatially the shallow wells in the nrz had much higher sulfate concentration whereas some wells in the srz had relatively lower sulfate concentration fig 4 a bicarbonate concentration in groundwater was much higher in the srz than that in the nrz and stream water fig 4b sio2 aq is mostly derived from weathering of silicate minerals and its concentrations clearly differed between stream water and groundwater fig 4b most of the groundwater had a narrow range of sio2 concentrations around 30 mg l 1 and between 20 and 40 mg l 1 while stream water had 10 mg l 1 on average and less than 20 mg l 1 table 2 lower concentrations in a few groundwater samples seem to have been linked to infiltration of stream water due to wcc activities while higher sio2 aq concentrations in that area resulted from accelerated weathering caused by acidity from heavy application of chemical fertilizers koh et al 2009 kim et al 2019 anthropogenically accelerated weathering of silicate minerals due to soil acidification caused by fertilizer use has also been reported in other countries perrin et al 2008 pierson wickmann et al 2009 groundwater in the study area seem to have different degree of water rock interactions depending on the depth fig 4c the deepest well at each well cluster was located at the top of the weathering zone of granitic rocks where strong positive correlation between na and f was often observed chae et al 2006 kim et al 2014 on a horizontal basis degree of water rock interactions was stronger in the stream side area than that in the plain side area various groundwater flow paths are converged near the stream in the riparian zone and groundwater is likely to be older and to have higher degree of water rock interactions in deeper wells and wells closer to the stream szabo et al 1996 it is noteworthy that this spatial trend was maintained in the srz while it was highly variable in the nrz on a seasonal basis particularly for the deepest wells of well clusters n2 and n1 fig 4c the temporal changes in measured parameters in groundwater showed distinctive patterns according to the four divided regions groundwater in the nrz plain side area with the largest drawdown during the wcc period had lower sio2 aq concentration fig 5 a by contrast groundwater in the srz plain side area which was less connected to the stream had relatively constant values of δ18o and sio2 aq large seasonal variability of δ18o in groundwater was observed in the areas of high connectivity with the stream especially in the stream side areas where sio2 aq concentration in groundwater decreased during the wcc period fig 5b however significant nitrate concentration was observed in stream water and groundwater of some wells n1 6 m had temporarily higher nitrate concentration of 25 mg l 1 in november 2015 corresponding to the wcc period and strawberry growing season n3 14 m also had higher nitrate concentration of up to 6 mg l 1 fig 5c stable isotopic compositions of groundwater mostly vary between the local meteoric water line lmwl in summer which is defined regionally lee and lee 1999 fig 6 a the isotopic composition is mainly affected by seasonal variation in precipitation and evaporation because the effects of altitude on stable isotopes can be ignored due to the terrain of the study area table 2 the δ18o and δ2h values of groundwater with regional recharge sources in the study area were 7 4 to 5 8 and 48 6 to 40 5 designated as regional groundwater in the northern nrgw and southern srgw areas based on the measurements of koh et al 2010 which are present in the nrz and srz respectively denoting significantly greater enrichment than the values of 9 and 62 of the high altitude recharge in the nearby area koh et al 2010 this indicates that recharge in the plain area is dominant in the study area the groundwater in srz had an enriched isotopic composition fig 6b by contrast the stable isotopic composition in the groundwater of nrz was less enriched and closer to that of summer lmwl fig 6a the isotopic composition of groundwater in the nrz was close to the mean for stream water in winter compared with the srz 4 3 contributions of three water sources to groundwater hydrological hydrogeochemical and isotopic indicators showed that groundwater in the study area derives from three water sources regional recharge paddy soil water and infiltration of stream water during winter fig 7 considering these water sources we established three component mixing models for groundwater in the nrz and srz using sio2 aq and δ18o to evaluate the spatial and temporal variability of each contributing water source barthold et al 2011 liu and yamanaka 2012 the mass balance equations for three component mixing using the two tracers and the three end members are 1 1 f r f w f p 2 s i o 2 a q s f r s i o 2 a q r f w s i o 2 a q w f p s i o 2 a q p 3 δ 18 o s f r δ 18 o r f w δ 18 o w f p δ 18 o p where f fraction of each component s water sample r regional recharge end member p paddy soil water end member and w winter stream water end member using parameters with different characteristics it is possible to elucidate the contributions of various end members to groundwater doctor et al 2006 iwasaki yoshioka et al 2016 the end member composition of paddy soil water was determined from the measurements for soil water in paddy fields near nrz plain side area in the nrz groundwater contributions were widely scattered regardless of well depth and distance from the stream and the contribution of paddy soil water was lower than those of the other two components fig 7a strong seasonal variability in both dissolved silica and δ18o was observed for most of the wells table 3 some nrz groundwater samples collected outside the wcc period fell outside of the mixing domain due to abnormally high sio2 aq concentrations but a contribution of winter stream water was observed in those wells during or after the pumping season from november to april by contrast dissolved silica in groundwater of the srz increased systematically with increasing well depth and showed no seasonal variation except at s2 9 m indicating a larger contribution of regional groundwater fig 7b the contribution of paddy soil water in srz varied seasonally and was higher than that in nrz in srz groundwater is controlled mainly by flow systems in the discharge zone with a seasonally variable contribution of paddy soil water and a limited input of stream water to identify the seasonal variation in the contribution of winter stream water its fraction was compared over time for each monitoring well and then the wells were divided into three groups according to the degree and timing of their temporal changes fig 8 the first group wells in the srz plain side area such as s1 15 m and s2 21 m showed small stream water fractions with minor seasonal changes indicating negligible interactions with the stream fig 8a the second group includes the wells with the highest stream water fraction during the wcc period such as n1 20 m and s2 9 m fig 8b these wells appear to respond to drawdown of the groundwater level in february during wcc pumping without considerable delay which is consistent with the pca results for water level and temperature the last group is made up of wells that show a peak in the stream water fraction in april after the wcc period has ended such as n1 8 m and n1 12 m fig 8c compared to the timing of peak drawdown infiltration of winter stream water was delayed by a few months due to poor connectivity with the stream these diverse seasonal variation patterns of the fraction of winter stream water clearly show that stream water infiltration is driven by intense pumping during winter and stream aquifer connectivity in the study area 4 4 multivariate statistical analyses of measured parameters principal component analysis of measured hydrogeochemical parameters and water stable isotopes produced four principal components pc representing major geochemical and recharge processes in the riparian aquifers of the study area fig 9 pc1 accounts for 26 of the total variance and stands for agricultural contamination having positive correlation with mg2 sio2 aq so4 2 lower ph and tds and anoxic processes such as denitrification having negative correlation with no3 and do table 4 the anoxic processes to the extent of nitrate reduction conditions were well identified in the previous regional studies on groundwater in floodplain areas including the study site koh et al 2009 koh et al 2010 pc2 accounted for 15 of the total variance water rock interactions were positively correlated with the concentrations of na f hco3 and tds typical of granitic aquifers chae et al 2006 kim et al 2014 pc3 also represents agricultural contamination accounting for 14 of the total variance similar to pc1 however pc3 is highly positively correlated with ca2 and k and do and no3 in a lesser extent indicating presence of oxic conditions though the study area is predominantly suboxic to anoxic pc4 is related to recharge with an evaporation signature which is correlated with enriched stable isotopic compositions and elevated temperature the relative influence of the major processes on each sample was assessed by comparison of pc scores and mixing fractions of the selected end members fig 9 pc1 represents anoxic groundwater which makes up the majority of groundwater in the study area pc1 is highly correlated with the shallow wells of n1 which can be attributed to accelerated weathering of silicate minerals due to soil acidification some samples collected in stream side areas had negative scores for pc1 similar to ns pc1 scores had negative correlation with mixing fraction of winter stream water fig 9a groundwater samples highly connected with the stream and those affected by intense groundwater pumping had negative pc1 scores and higher mixing fraction of winter stream water pc2 scores increased with increasing well depth in both srz and nrz representing bedrock groundwater despite the sampling depths being considerably shallower than those of typical bedrock wells in korea which are generally 50 m to 150 m however this trend is much weaker for the wells in nrz where pc2 scores were more negative and seasonally variable than those in the srz with the exception of samples affected by agriculturally accelerated weathering the fraction of regional groundwater and pc2 scores representing granitic rock water interactions were positively correlated fig 9b pc3 scores were higher for shallow oxic groundwater affected by agricultural contamination and were generally higher in srz than in nrz except for shallow wells of n1 which had higher pc1 scores these results show that the impact of agricultural contamination is greater in srz than in nrz overall aside from shallow wells in the plain side area of nrz the unexpectedly low impact of agricultural contamination on groundwater deeper than 10 m in the nrz can be attributed to the greater degree of stream water infiltration which was also observed in hydrological and hydrogeochemical indicators based on the seasonality of groundwater withdrawal we compared the spatial distributions of water level and pc scores and the contribution of winter stream water determined from hydrogeochemical and isotopic parameters between two representative periods fig 10 at the end of pumping season pc1 scores decreased to zero or negative values in the wells in nrz which is consistent with the increase in the fraction of winter stream water for example in well n1 20 m the pc1 score decreased from 0 03 to 0 23 indicating stream water infiltration and the pc2 score decreased from 1 25 to 0 66 indicating loss of the bedrock groundwater signature when the fraction of stream water increased by 0 3 the wells located in the region affected by intense pumping showed seasonal variation in pc scores and mixing fractions as well as considerable temporal changes in groundwater level and temperature by contrast pc scores were relatively constant in the deepest point of each well except n1 20 m which showed little variation in the fraction of stream water indicating a lack of connectivity to the stream 4 5 bacterial community structure we analyzed seasonal changes in the bacterial community structure of the groundwater and stream water samples from the greenhouse agricultural area based on 16s rrna gene sequencing the two most dominant phyla were proteobacteria and firmicutes which represented 7 1 71 7 and 0 9 61 9 respectively of the total 16 s rdna gene sequences in the samples fig 11 the majority of communities were assigned to the class betaproteobacteria which constituted 4 2 85 6 of the proteobacteria data not shown in summer july 2016 although each sample had a different community structure the stream water sample was clearly distinguished from the other groundwater samples due to the high abundance of actinobacteria 23 6 and cyanobacteria 30 3 the microbial community structures of the groundwater were spatially and temporally distinct the plain side n1 and s1 communities were mainly composed of proteobacteria and firmicutes while proteobacteria dominated the stream side samples n2 and s2 at the end of the heavy groundwater extraction season february 2017 the bacterial community structures were significantly altered with respect to the season with no extraction july 2016 generally the firmicute ratio increased across all samples including the stream water except for samples from wells s1 15 m and s1 10 m in addition the proportion of proteobacteria decreased significantly in all samples by 10 9 on average except the s1 15 m samples in which the proteobacteria proportion increased by 37 1 on average 5 discussion groundwater in riparian zones with active agricultural activities is considerably affected by both land uses and water uses in terms of the processes of recharge flow and solute transport which determine responses of the aquifers to pumping irrigation and contamination walker et al 2002 andrade and stigter 2009 koh et al 2010 pulido velazquez et al 2015 the nrz with mixed land uses and intense seasonal pumping had lower groundwater levels and more variable temperatures than the srz which is mostly rice paddies and undergoes less pumping land use in the study area can be a critical factor in the infiltration of irrigation water and agricultural contaminants due to the significantly different infiltration rates of rice paddies and vegetable producing dry farmland ritter et al 2007 matiatos 2016 wang et al 2017 greater impacts of agricultural contamination were observed in deeper wells in nrz and in shallower wells in srz fig 4a likely resulting from the higher infiltration rate of dry farmland which covers a considerable portion of nrz compared to rice paddies in srz different stable isotopic compositions of groundwater in srz and nrz can be attributed to differences in both land use and water use liu and yamanaka 2012 darling and bowes 2016 séraphin et al 2016 jung et al 2019 in addition to land use stable isotopic composition indicated a smaller effect of evaporation when a preferential flow path was formed gazis and feng 2004 contribution of paddy impounded water to recharge in srz is readily discernible by more enriched isotopic composition with stronger evaporation signature compared with that in nrz where precipitation and irrigated water in dry farmland mainly contribute to recharge fig 6a three component mixing based on dissolved silica and δ18o revealed three recharge sources of regional groundwater paddy impounded water and winter stream water and their contributions at each monitoring point pca of hydrogeochemical parameters and stable isotopes in groundwater allowed identification of hydrological processes as well as water rock interactions redox processes and the impacts of agricultural contamination the intense seasonal pumping in riparian zones induced groundwater drawdowns of up to 5 m and losing stream conditions during winter otherwise gaining stream conditions would have maintained martin et al 2004 bastola and peterson 2016 lee et al 2017 various properties of water flow including infiltration of stream water were indicated by hydrogeochemical parameters which corroborates monitoring results of groundwater level and temperature groundwater with a large contribution from winter stream water was consistently identified in temperature monitoring three component mixing and pca results fig 10 based on the variation in microbial community structure it is likely that groundwater near the stream was influenced by infiltration of stream water ben maamar et al 2015 lee et al 2018 which is more pronounced in the nrz than in the srz these results show that stream aquifer interactions can be significantly perturbed by human interventions in riparian zones resulting in significant changes to the physical and chemical conditions of groundwater with high spatial and temporal variability that depend on connectivity between aquifers and the stream stanford and ward 1993 menció and mas pla 2010 yang et al 2017 for example the distinctive response of plain side deeper wells in the nrz to losing stream condition suggests the presence of layers with higher permeability such as paleo channel sediments resulting in higher connectivity to the stream revil et al 2005 choi et al 2016 lee et al 2018 agricultural land uses significantly affect recharge processes groundwater flow and contaminant transport in the aquifers in riparian areas watson et al 2010 zeng et al 2016 in addition groundwater uses such as intense pumping strongly control hydraulic conditions in the aquifers which in turn induces changes in stream aquifer interactions chen and shu 2002 zume and tarhule 2008 these factors need to be properly addressed for effective management of surface water and groundwater in riparian zones schilling and zhang 2006 menció et al 2016 in this study the complicated nature of flow processes in the riparian aquifers and stream aquifer interactions were successfully revealed by employing multi parameters which is more effective than a single or limited parameter approach andrade and stigter 2009 each measured or monitored parameter provided information on the different flow processes particularly temperature monitoring and sio2 aq concentration were identified as good indicators for stream water infiltration and water stable isotopes well represented contribution of paddy impounded water to recharge demonstrating usefulness of the multi parameter approach for evaluation of highly heterogeneous systems such as the riparian zones it is also noteworthy that multi level monitoring wells were effective to delineate spatiotemporal variation of flow processes in the study site implementing the multi parameter approach this study revealed the impacts of seasonal pumping and irrigation on the riparian aquifers and stream aquifer interactions resulting in complicated spatiotemporal changes in flow and chemistry of groundwater and the variably gaining and losing conditions of the adjoining stream these findings can contribute to establishment and implementation of effective integrated management plans for groundwater and surface water in the riparian areas with diverse agricultural land uses and water uses and ecosystems related to groundwater 6 summary and conclusions we evaluated flow and hydrogeochemical processes in agricultural riparian zones with contrasting land and groundwater uses based on measurements from multi level monitoring wells and the stream using an integrative approach groundwater levels and temperatures in the study area showed sinusoidal variation due to intense groundwater use in winter from december to february the drawdown was considerably larger in dry farmland area with higher groundwater use water table drawdown was reduced due to the infiltration of stream water under losing stream conditions occurring in winter temporal variation in groundwater temperature indicated infiltration of winter stream water corroborating the losing condition of the stream in the dry farmland and stream side areas deeper infiltration of agriculturally derived solutes such as ca2 and so4 2 was observed in the dry farmland area compared to the paddy area recharge from paddy impounded water was identified by evaporation signatures of water stable isotopes these observations clearly indicate that differences in land use and water use had variable effects on the groundwater flow in the agricultural riparian zones in terms of flow paths recharge and stream aquifer interactions in agricultural activity riparian zones temporal and spatial distribution of recharge sources obtained by three component mixing analysis temporal variation in the winter stream contribution of each well indicated that connectivity between the aquifer and the stream determined the aquifer s response to intense seasonal pumping principal component analysis of hydrogeochemical and isotopic parameters showed major geochemical processes of agricultural contamination water rock interactions and infiltration of paddy impounded water with the increase in infiltration of winter stream water into the aquifers the effects of the geochemical processes changed significantly in the monitoring wells with higher connectivity to the stream indicating that human induced stream aquifer interactions significantly affect hydrological and geochemical processes in riparian zones this study clearly shows that continuous monitoring and seasonal investigation of multiple parameters using multi level monitoring wells can be quite useful for evaluating the highly variable responses of riparian groundwater to the impacts of agricultural activities as well as groundwater stream interactions these efforts can aid the establishment of effective solutions to stream depletion and infiltration of stream water contaminants into aquifers as well as groundwater management in riparian zones our results revealed main drivers for hydrological processes in the riparian zone of the study area are seasonal pumping and irrigation in paddy fields and regulated stream water level as well as regional groundwater which were variably modulated by stream aquifer connectivity and land uses these findings suggest that better land management and water withdrawal are needed to support the natural hydrological and ecological processes in riparian areas credit authorship contribution statement hong il kwon investigation formal analysis data curation writing original draft dong chan koh conceptualization methodology writing review editing youn young jung investigation resources dong hun kim investigation writing original draft kyoochul ha project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the basic research project 18 3411 of the korea institute of geoscience and mineral resources kigam funded by the ministry of science and ict we thank korea rural community corporation krc and local farmers for permission of installation of groundwater monitoring wells in the study site kyoung ho kim provided insightful comments on multivariate statistical analysis which is also appreciated 
5630,the flow and chemistry of groundwater in agricultural riparian zones are highly heterogeneous due to the human impacts as well as convergent flow conditions and variable stream aquifer interactions to evaluate impact of seasonal heavy pumping on the aquifers in agricultural riparian zones we investigated groundwater and stream water using a multi parameter approach integrating continuous monitoring of water level and temperature and periodic measurements of hydrogeochemical parameters water stable isotopes and microbial communities in agricultural riparian zones with contrasting patterns of land use and water use across the third order stream for two years in the mid western south korea intense groundwater use for warming of greenhouses in dry farmland during winter induced groundwater drawdown of up to 5 m resulting in losing stream condition and decreased groundwater temperature with considerable spatial variability groundwater contamination was clearly identified based on elevated concentrations of agriculture derived solutes such as ca2 and so4 2 despite the negligible no3 content under reducing conditions three component mixing of groundwater based on δ18o and dissolved silica revealed major water sources of regional recharge paddy soil water and winter stream water with considerable differences in their contributions between the riparian zones the fraction of winter stream water in groundwater showed different temporal variability depending on aquifer connectivity with the stream as well as groundwater use principal component analysis of hydrogeochemical and isotopic parameters revealed the major processes of agricultural contamination water rock interactions and the contribution of paddy impounded water which varied significantly with the extent of stream water infiltration these results suggest that seasonal pumping substantially affect groundwater flow and its relationship to stream with considerable horizontal and vertical variability in riparian aquifers this study highlights spatial and temporal variations of groundwater flow dynamics in riparian areas are effectively delineated by a multi parameter approach which can contribute to better understanding of stream aquifer interactions and implementation of integrated water management in the areas with agricultural land uses and water uses keywords riparian zone multi level well temporal variation stable isotope multivariate statistical analysis 1 introduction riparian zones are transitional areas between terrestrial and aquatic ecosystems which connect water bodies to their adjacent uplands via surface and subsurface hydrological processes gregory et al 1991 nrc 2002 convergent groundwater flow is dominant in riparian aquifers where variable interactions with surface water depend on the connectivity between streams and aquifers toth 1963 brodie et al 2008 li et al 2016 in riparian zones surface water and groundwater interact according to the spatial and temporal hydrological conditions considerably affecting the fate of nutrients in surface water and groundwater hill 1996 roy and bickerton 2014 dwivedi et al 2018 human activities including agriculture are increasingly affecting hydrological and ecological systems in riparian areas as well as adverse impacts on groundwater and surface water interactions such as depletion of surface water and introduction of contaminants in those areas watson et al 2010 zeng et al 2016 in particular agricultural land uses in riparian zones play an important role in controlling contaminant transport by increasing the complexity of groundwater flow and its interaction with surface water through intense groundwater use and irrigation in riparian zones krause et al 2008 menció et al 2016 most agricultural activities in riparian zones rely on both riparian groundwater and surface water schilling et al 2006 watson et al 2010 mcdonald et al 2013 continued pumping lowers the groundwater level and surface water infiltrates into the aquifers inducing recharge when the zone of contribution reaches the stream winter et al 1998 chen and yin 2001 one of the factors controlling the amount and flow path of water to be infiltrated is the connectivity between the stream and adjacent aquifers which is mainly determined by the distance from the stream hydraulic conditions and hydrogeological properties of the aquifer and streambed stanford and ward 1993 western et al 2001 chen and shu 2002 li et al 2016 in korea groundwater has been used since late 1980s to aid in heating greenhouses during winter by either spraying water between two layers of the greenhouses or allowing to flow into an open waterway inside the greenhouse when the air temperature drops below zero in celsius which is known as water curtain cultivation wcc facilities park et al 1988 maf 2014 this agricultural practice results in heavy withdrawal of groundwater from the riparian aquifer with groundwater use reaching up to 1 55 billion m3 y 1 in korea nihhs 2007 some studies investigated the effects of wcc on the decline of groundwater levels of alluvial aquifers and the depletion of flow in adjacent streams kim et al 2012 lee et al 2017 however few studies were done for the spatial and temporal responses of aquifers to intense seasonal groundwater withdrawal using multi level monitoring wells in agricultural riparian zones many previous studies have attempted to identify interactions between streams and groundwater by monitoring water levels and temperatures sophocleous et al 1988 zume and tarhule 2008 yang et al 2017 el zehairy et al 2018 to combine various monitoring data pertaining to the water level temperature and ec multivariate analyses have been used to identify the key factors determining the interaction between groundwater and surface water page et al 2012 mixing analyses using relevant hydrogeochemical and isotopic parameters have been applied in riparian zones to evaluate stream aquifer interactions nakaya et al 2007 neumann and curtis 2016 temporal variation in hydrogeochemical parameters has also been used to identify contaminant sources and evaluate groundwater and surface water interactions as well as geochemical processes controlling the fate of contaminants menció and mas pla 2008 king et al 2014 recent studies have revealed that microbial community structures in aquifers are strongly related to redox conditions and human impacts suggesting that these are good indicators of changes in groundwater systems flynn et al 2013 sirisena et al 2013 we constructed a test site to investigate stream aquifer interactions with several multi level wells in two riparian zones of a stream with different degrees of wcc activities heavy groundwater withdrawal in this area results in strong seasonal changes in groundwater levels and streamflow discharge cho et al 2012 lee et al 2015 groundwater withdrawal and irrigation in the test area are highly variable both in temporal and spatial terms which may cause complicated responses in the riparian aquifers and stream aquifer interactions kwon et al 2017 difference in agricultural activity on the riparian zone can be judged to be an important factor in the interaction between stream and aquifer we evaluated impact of seasonal heavy pumping on the aquifers in riparian zones through an integrative approach using continuous monitoring of water levels and seasonal investigation of hydrogeochemical parameters water stable isotopes and microbial community structures and identified stream water infiltration into the aquifer using water temperature and a three component mixing model we also investigated the responses of hydrogeological and hydrogeochemical parameters of aquifers to infiltration of stream water 2 study area 2 1 hydrogeological setting the study area is 50 km away from the geum river estuary which is located in the mid western part of the republic of south korea fig 1 and riparian zones near noseongcheon stream ns a third order stream which is a tributary to the geum river one of the four major rivers in the republic of south korea the noseongchen stream is 27 7 km long and its catchment area is 202 5 km2 the northern riparian zone nrz and southern riparian zone srz were divided by levees into stream side areas and plain side areas making up the four main hydrogeological divisions of the study area the difference in elevation between the stream bed and stream side areas was 4 to 5 m alluvium in the area is 4 5 m to 8 3 m thick and overlies weathered zones of jurassic granodiorite kigam 2011 clay embedded layers were found at depths between 3 8 and 8 3 m in most of the study area as identified by neutron logging which measures total porosity in the unit of limestone porosity unit lpu won et al 2017 in the nearby riparian zone of the main stream of the geum river sediment layers intercalated with clay and sand with thicknesses of 3 m were found at a depth of approximately 5 m with considerable horizontal continuity these were deposited in back marshes formed by flooding in later stages of the last interglacial period park 2014 a weathered zone with an average thickness of 20 m underlies the alluvial sediments identified using a two dimensional resistivity survey with dipole array and modified pole pole array won et al 2013 the bedrock is jurassic granodiorite containing quartz plagioclase microcline orthoclase biotite chlorite and minor minerals including muscovite pyroxene and apatite kigam 2011 the study area has a monsoonal climate with hot and humid summers between june and august and cold and dry winters from november to january the average precipitation is 1244 4 mm and the average annual temperature is 12 2 c according to measurements taken from nonsan automatic weather station between 1998 and 2017 which is 2 2 km away from the study area and operated by the korea meteorological administration kma in total 67 of the annual precipitation is concentrated between june and september the monthly average temperature from november 2014 to november 2016 was lowest in january at 1 1 c and highest in august at 26 4 c at the watershed of the ns the average groundwater recharge rate was determined to be 15 9 of precipitation molit 2015 in the study area according to pumping and slug tests the hydraulic conductivity of the alluvial sediment and fractured zone is 55 3 and 5 1 m d 1 respectively the storage coefficient of the aquifer ranges from 1 5 10 4 to 5 5 10 4 cho et al 2012 2 2 agricultural activities land uses in the study area are rice paddy and vegetable producing dry farmland in the plains area while orchards and residential areas are present in the hilly terrain fig 1 annual use of nitrogen chemical fertilizers averaged 201 kg ha 1 yr 1 for the period between 1995 and 2005 nonsan si 2007 which is close to the average use in south korea of 218 kg ha 1 yr 1 maf 2014 the total number of wells in the watershed is 6056 and the withdrawal rate is 6 459 000 m3 y 1 molit 2015 in the past the agricultural areas in this region were mainly rice paddies since 2003 strawberry cultivation has become widespread in nonsan the region is now one of the most famous strawberry growing areas in korea kigam 2010 in the study area considerable portions of rice paddies have been converted into dry farmland for strawberry cultivation fig 1 the air temperature in nonsan is lower than 0 c at night in winter which is far lower than the temperature required for strawberry cultivation which is about 10 c jeong et al 2011 the air temperature in the strawberry growing greenhouses are maintained by wcc facilities which spray groundwater with a temperature of approximately 13 c as a source of heat these usually operate from mid november to early march strawberry cultivation using wcc is widespread within the nrz the groundwater levels of the wells for agriculture use were between 4 6 5 2 m asl and 3 8 to 0 5 m asl with drawdowns of up to 8 m in the watershed including the nrz which was attributed to intense groundwater pumping during wcc kwon et al 2017 the average groundwater withdrawal in the nrz was estimated to be 420 m3 d 1 ha 1 for this area the annual total groundwater withdrawal is 1 310 400 m3 y 1 based on the number of wcc days 120 d y 1 and areas 26 ha lee et al 2015 groundwater used for wcc is discharged to the noseongcheon stream along the impermeable concrete ditch whose outlet is located at the downstream site of the groundwater monitoring wells fig 1 by contrast the southern part of the stream the srz is still mainly composed of rice paddies groundwater withdrawals in the srz are much smaller than in the nrz because the water sources for rice paddies are mainly surface water from reservoirs and weirs nam et al 2017 rice paddies are irrigated with upstream reservoir water through the impermeable irrigation channels from may to august rice growing season and no water is flowing in the channels during other season 3 methods 3 1 water level and temperature monitoring total 12 monitoring points including four multi level wells and one single point well were installed for monitoring groundwater levels and temperature and for sampling fig 1 each monitoring well had a diameter of 35 mm and a 1 m long screened interval near the bottom and more detail specifications are in table 1 multi level groundwater monitoring is commonly used for observation of multiple parameters to properly understand the highly heterogeneous flow systems and chemical characteristics of groundwater in riparian zones choi et al 2009 sharma et al 2012 bailey et al 2015 rønde et al 2017 we installed a standpipe with a screen in the streambed to monitor the level and temperature of the stream water the water level and temperature were measured at 5 min intervals using micro diver eijkelkamp soil water giesbeek the netherlands with measurement errors in pressure and temperature of 1 cm h2o and 0 1 c respectively data on the stream water level and temperature were missing from 17th april 2016 to 24th may 2017 due to stream maintenance operations which were carried out by the local municipality 3 2 sampling and measurement in total we carried out 12 sampling campaigns to obtain samples to assess chemical and physical parameters and water stable isotopes from october 2014 to april 2017 we collected 127 groundwater and stream water samples for groundwater sampling we used a peristaltic pump to purge three times the volume of groundwater in the individual wells to remove the well bore effect prior to sampling occasionally groundwater samples could not be taken from the shallowest wells where the water level had decreased to near the bottom of the well and the well had been consequently dried field parameters such as temperature ph ec and dissolved oxygen do were monitored during purging and water samples were taken after these parameters were stabilized soil water in paddy fields near the nrz was also collected four times in winter of 2018 using a suction lysimeter sks20 ums corp münchen germany at a depth of 80 cm for measurements of stable isotopes and selected chemical parameters all of the water samples were filtered using 0 45 μm membrane filters and we acidified the aliquots for cation analyses to ph 2 in the field using concentrated nitric acid anions including cl so4 2 no3 and f were measured using ion exchange chromatography with conductivity detection ics 1500 dionex sunnyvale ca usa ca2 mg2 na k and sio2 aq were measured using inductively coupled plasma optical emission spectrometry optima 7300 dv icp oes spectrometer perkin elmer shelton ct usa the alkalinity was evaluated as the total alkalinity using an automatic titrator t50 titrator mettler toledo columbus oh usa with acidimetric titration to the end point of ph 4 5 the charge balance errors of all samples were less than 8 water stable isotopes were analyzed by wavelength scanned cavity ring down spectroscopy l1102 i picarro sunnyvale ca usa with typical precision of 0 1 and 0 5 for δ18o and δ2h respectively jung et al 2013 3 3 multivariate statistical analyses msa principal component analyses pcas were used to identify major geochemical processes controlling the flow system and chemistry of groundwater schot and van der wal 1992 thyne et al 2004 principal components pcs were extracted from a correlation matrix of 16 hydrogeochemical variables temperature measured at sampling ph total dissolved solids tds do ca2 mg2 na k hco3 cl so4 2 no3 f sio2 aq δ18o and δ2h for 127 groundwater samples concentrations below the detection limit were assumed half of the detection limit the variables were logarithmically transformed due to their log normal distributions except for ph δ18o and δ2h pcs with eigenvalues larger than 1 were selected and rotated iteratively using the varimax method varimax rotation reduces the overlap between the original variables and is useful for finding factors that can be readily explained by hydrogeochemical processes helena et al 2000 3 4 microbial community analyses every 2 l of groundwater and stream water samples was passed through a 0 2 μm membrane filter advantec mfs dublin ca usa in the field and the filters were stored at 70 c until deoxyribonucleic acid dna extraction genomic dna was extracted from the filters using the dneasy powerwater kit qiagen hilden germany following the manufacturer s protocol and stored at 20 c until further analysis the genomic dna extracted from the groundwater samples were amplified in the v3 v4 region of the 16s ribosomal ribonucleic acid 16s rrna gene using the miseq platform illumina san diego ca usa at macrogen seoul south korea the raw sequence data were analyzed using mothur v 1 38 schloss et al 2009 and standard miseq sequence operating procedures kozich et al 2013 4 results 4 1 spatial and temporal variation in water level and temperature groundwater levels in the study area increase in the humid summer when heavy rainfall occurs and decrease in the dry winter which is typical in the monsoon climate of korea moon et al 2004 additional drawdown was observed in winter due to intense pumping for wcc in the nrz which was smaller in the srz where paddy fields are dominant cho et al 2012 meanwhile the stream water level remained constant despite peaks in runoff from rainfall events because it is artificially controlled with a weir and large reservoir located upstream of the monitoring site fig 2 stream water temperature exhibited typical fluctuations similar to those of atmospheric temperature while groundwater temperature in the plain side area was nearly constant with lower temperatures in nrz than in srz fig 2 groundwater temperature in the nrz stream side area was as low as 11 4 c on average with the largest variation of 8 4 c by contrast deeper wells in the srz plain side area had a higher average temperature of 15 0 c with the lowest variation of 1 3 c the unusually high variability of groundwater temperature indicates the effects of stream water with seasonally variable temperature best exemplified by the lowest groundwater temperature being observed in the nrz stream side area due to infiltration of winter stream water such changes in groundwater temperature induced by anthropogenic activities have been reported in alluvial aquifers connected to losing streams duque et al 2010 kigam 2011 lee et al 2017 to clarify the relationship between stream water and groundwater pca was performed using water level and temperature monitoring data collected in 6 h intervals page et al 2012 fig 3 principal component loadings of the groundwater level were similar while those of groundwater temperature were highly varied the groundwater level measured in the nrz plain side area which was most strongly affected by intense pumping of groundwater in winter had the weakest correlation with stream water level while the groundwater level in the stream side area had the strongest correlation with the stream water level by contrast groundwater temperature appears to be controlled by spatial heterogeneity such as the distinctively lower temperature in the nrz stream side area due to infiltration of winter stream water silliman et al 1995 groundwater temperature in the nrz stream side area had the strongest correlation with stream water temperature which was observed to a lesser extent in the srz stream side area meanwhile groundwater temperature in the srz plain side area had the weakest correlation with stream water temperature 4 2 hydrogeochemical parameters and water stable isotopes the observed nitrate concentration was surprisingly low and was near the detection limit 0 05 mg l 1 in many groundwater samples despite annual application of a considerable amount of nitrogenous chemical fertilizers however elevated concentrations of ca2 and so4 2 are indicative of agricultural contamination kelly 1997 nikolaidis et al 2008 puig et al 2013 sulfate concentration was higher with a large variation and in the range defined by two regional studies near the study site choi et al 2008 koh et al 2009 which focused on typical riparian zones with agricultural activities spatially the shallow wells in the nrz had much higher sulfate concentration whereas some wells in the srz had relatively lower sulfate concentration fig 4 a bicarbonate concentration in groundwater was much higher in the srz than that in the nrz and stream water fig 4b sio2 aq is mostly derived from weathering of silicate minerals and its concentrations clearly differed between stream water and groundwater fig 4b most of the groundwater had a narrow range of sio2 concentrations around 30 mg l 1 and between 20 and 40 mg l 1 while stream water had 10 mg l 1 on average and less than 20 mg l 1 table 2 lower concentrations in a few groundwater samples seem to have been linked to infiltration of stream water due to wcc activities while higher sio2 aq concentrations in that area resulted from accelerated weathering caused by acidity from heavy application of chemical fertilizers koh et al 2009 kim et al 2019 anthropogenically accelerated weathering of silicate minerals due to soil acidification caused by fertilizer use has also been reported in other countries perrin et al 2008 pierson wickmann et al 2009 groundwater in the study area seem to have different degree of water rock interactions depending on the depth fig 4c the deepest well at each well cluster was located at the top of the weathering zone of granitic rocks where strong positive correlation between na and f was often observed chae et al 2006 kim et al 2014 on a horizontal basis degree of water rock interactions was stronger in the stream side area than that in the plain side area various groundwater flow paths are converged near the stream in the riparian zone and groundwater is likely to be older and to have higher degree of water rock interactions in deeper wells and wells closer to the stream szabo et al 1996 it is noteworthy that this spatial trend was maintained in the srz while it was highly variable in the nrz on a seasonal basis particularly for the deepest wells of well clusters n2 and n1 fig 4c the temporal changes in measured parameters in groundwater showed distinctive patterns according to the four divided regions groundwater in the nrz plain side area with the largest drawdown during the wcc period had lower sio2 aq concentration fig 5 a by contrast groundwater in the srz plain side area which was less connected to the stream had relatively constant values of δ18o and sio2 aq large seasonal variability of δ18o in groundwater was observed in the areas of high connectivity with the stream especially in the stream side areas where sio2 aq concentration in groundwater decreased during the wcc period fig 5b however significant nitrate concentration was observed in stream water and groundwater of some wells n1 6 m had temporarily higher nitrate concentration of 25 mg l 1 in november 2015 corresponding to the wcc period and strawberry growing season n3 14 m also had higher nitrate concentration of up to 6 mg l 1 fig 5c stable isotopic compositions of groundwater mostly vary between the local meteoric water line lmwl in summer which is defined regionally lee and lee 1999 fig 6 a the isotopic composition is mainly affected by seasonal variation in precipitation and evaporation because the effects of altitude on stable isotopes can be ignored due to the terrain of the study area table 2 the δ18o and δ2h values of groundwater with regional recharge sources in the study area were 7 4 to 5 8 and 48 6 to 40 5 designated as regional groundwater in the northern nrgw and southern srgw areas based on the measurements of koh et al 2010 which are present in the nrz and srz respectively denoting significantly greater enrichment than the values of 9 and 62 of the high altitude recharge in the nearby area koh et al 2010 this indicates that recharge in the plain area is dominant in the study area the groundwater in srz had an enriched isotopic composition fig 6b by contrast the stable isotopic composition in the groundwater of nrz was less enriched and closer to that of summer lmwl fig 6a the isotopic composition of groundwater in the nrz was close to the mean for stream water in winter compared with the srz 4 3 contributions of three water sources to groundwater hydrological hydrogeochemical and isotopic indicators showed that groundwater in the study area derives from three water sources regional recharge paddy soil water and infiltration of stream water during winter fig 7 considering these water sources we established three component mixing models for groundwater in the nrz and srz using sio2 aq and δ18o to evaluate the spatial and temporal variability of each contributing water source barthold et al 2011 liu and yamanaka 2012 the mass balance equations for three component mixing using the two tracers and the three end members are 1 1 f r f w f p 2 s i o 2 a q s f r s i o 2 a q r f w s i o 2 a q w f p s i o 2 a q p 3 δ 18 o s f r δ 18 o r f w δ 18 o w f p δ 18 o p where f fraction of each component s water sample r regional recharge end member p paddy soil water end member and w winter stream water end member using parameters with different characteristics it is possible to elucidate the contributions of various end members to groundwater doctor et al 2006 iwasaki yoshioka et al 2016 the end member composition of paddy soil water was determined from the measurements for soil water in paddy fields near nrz plain side area in the nrz groundwater contributions were widely scattered regardless of well depth and distance from the stream and the contribution of paddy soil water was lower than those of the other two components fig 7a strong seasonal variability in both dissolved silica and δ18o was observed for most of the wells table 3 some nrz groundwater samples collected outside the wcc period fell outside of the mixing domain due to abnormally high sio2 aq concentrations but a contribution of winter stream water was observed in those wells during or after the pumping season from november to april by contrast dissolved silica in groundwater of the srz increased systematically with increasing well depth and showed no seasonal variation except at s2 9 m indicating a larger contribution of regional groundwater fig 7b the contribution of paddy soil water in srz varied seasonally and was higher than that in nrz in srz groundwater is controlled mainly by flow systems in the discharge zone with a seasonally variable contribution of paddy soil water and a limited input of stream water to identify the seasonal variation in the contribution of winter stream water its fraction was compared over time for each monitoring well and then the wells were divided into three groups according to the degree and timing of their temporal changes fig 8 the first group wells in the srz plain side area such as s1 15 m and s2 21 m showed small stream water fractions with minor seasonal changes indicating negligible interactions with the stream fig 8a the second group includes the wells with the highest stream water fraction during the wcc period such as n1 20 m and s2 9 m fig 8b these wells appear to respond to drawdown of the groundwater level in february during wcc pumping without considerable delay which is consistent with the pca results for water level and temperature the last group is made up of wells that show a peak in the stream water fraction in april after the wcc period has ended such as n1 8 m and n1 12 m fig 8c compared to the timing of peak drawdown infiltration of winter stream water was delayed by a few months due to poor connectivity with the stream these diverse seasonal variation patterns of the fraction of winter stream water clearly show that stream water infiltration is driven by intense pumping during winter and stream aquifer connectivity in the study area 4 4 multivariate statistical analyses of measured parameters principal component analysis of measured hydrogeochemical parameters and water stable isotopes produced four principal components pc representing major geochemical and recharge processes in the riparian aquifers of the study area fig 9 pc1 accounts for 26 of the total variance and stands for agricultural contamination having positive correlation with mg2 sio2 aq so4 2 lower ph and tds and anoxic processes such as denitrification having negative correlation with no3 and do table 4 the anoxic processes to the extent of nitrate reduction conditions were well identified in the previous regional studies on groundwater in floodplain areas including the study site koh et al 2009 koh et al 2010 pc2 accounted for 15 of the total variance water rock interactions were positively correlated with the concentrations of na f hco3 and tds typical of granitic aquifers chae et al 2006 kim et al 2014 pc3 also represents agricultural contamination accounting for 14 of the total variance similar to pc1 however pc3 is highly positively correlated with ca2 and k and do and no3 in a lesser extent indicating presence of oxic conditions though the study area is predominantly suboxic to anoxic pc4 is related to recharge with an evaporation signature which is correlated with enriched stable isotopic compositions and elevated temperature the relative influence of the major processes on each sample was assessed by comparison of pc scores and mixing fractions of the selected end members fig 9 pc1 represents anoxic groundwater which makes up the majority of groundwater in the study area pc1 is highly correlated with the shallow wells of n1 which can be attributed to accelerated weathering of silicate minerals due to soil acidification some samples collected in stream side areas had negative scores for pc1 similar to ns pc1 scores had negative correlation with mixing fraction of winter stream water fig 9a groundwater samples highly connected with the stream and those affected by intense groundwater pumping had negative pc1 scores and higher mixing fraction of winter stream water pc2 scores increased with increasing well depth in both srz and nrz representing bedrock groundwater despite the sampling depths being considerably shallower than those of typical bedrock wells in korea which are generally 50 m to 150 m however this trend is much weaker for the wells in nrz where pc2 scores were more negative and seasonally variable than those in the srz with the exception of samples affected by agriculturally accelerated weathering the fraction of regional groundwater and pc2 scores representing granitic rock water interactions were positively correlated fig 9b pc3 scores were higher for shallow oxic groundwater affected by agricultural contamination and were generally higher in srz than in nrz except for shallow wells of n1 which had higher pc1 scores these results show that the impact of agricultural contamination is greater in srz than in nrz overall aside from shallow wells in the plain side area of nrz the unexpectedly low impact of agricultural contamination on groundwater deeper than 10 m in the nrz can be attributed to the greater degree of stream water infiltration which was also observed in hydrological and hydrogeochemical indicators based on the seasonality of groundwater withdrawal we compared the spatial distributions of water level and pc scores and the contribution of winter stream water determined from hydrogeochemical and isotopic parameters between two representative periods fig 10 at the end of pumping season pc1 scores decreased to zero or negative values in the wells in nrz which is consistent with the increase in the fraction of winter stream water for example in well n1 20 m the pc1 score decreased from 0 03 to 0 23 indicating stream water infiltration and the pc2 score decreased from 1 25 to 0 66 indicating loss of the bedrock groundwater signature when the fraction of stream water increased by 0 3 the wells located in the region affected by intense pumping showed seasonal variation in pc scores and mixing fractions as well as considerable temporal changes in groundwater level and temperature by contrast pc scores were relatively constant in the deepest point of each well except n1 20 m which showed little variation in the fraction of stream water indicating a lack of connectivity to the stream 4 5 bacterial community structure we analyzed seasonal changes in the bacterial community structure of the groundwater and stream water samples from the greenhouse agricultural area based on 16s rrna gene sequencing the two most dominant phyla were proteobacteria and firmicutes which represented 7 1 71 7 and 0 9 61 9 respectively of the total 16 s rdna gene sequences in the samples fig 11 the majority of communities were assigned to the class betaproteobacteria which constituted 4 2 85 6 of the proteobacteria data not shown in summer july 2016 although each sample had a different community structure the stream water sample was clearly distinguished from the other groundwater samples due to the high abundance of actinobacteria 23 6 and cyanobacteria 30 3 the microbial community structures of the groundwater were spatially and temporally distinct the plain side n1 and s1 communities were mainly composed of proteobacteria and firmicutes while proteobacteria dominated the stream side samples n2 and s2 at the end of the heavy groundwater extraction season february 2017 the bacterial community structures were significantly altered with respect to the season with no extraction july 2016 generally the firmicute ratio increased across all samples including the stream water except for samples from wells s1 15 m and s1 10 m in addition the proportion of proteobacteria decreased significantly in all samples by 10 9 on average except the s1 15 m samples in which the proteobacteria proportion increased by 37 1 on average 5 discussion groundwater in riparian zones with active agricultural activities is considerably affected by both land uses and water uses in terms of the processes of recharge flow and solute transport which determine responses of the aquifers to pumping irrigation and contamination walker et al 2002 andrade and stigter 2009 koh et al 2010 pulido velazquez et al 2015 the nrz with mixed land uses and intense seasonal pumping had lower groundwater levels and more variable temperatures than the srz which is mostly rice paddies and undergoes less pumping land use in the study area can be a critical factor in the infiltration of irrigation water and agricultural contaminants due to the significantly different infiltration rates of rice paddies and vegetable producing dry farmland ritter et al 2007 matiatos 2016 wang et al 2017 greater impacts of agricultural contamination were observed in deeper wells in nrz and in shallower wells in srz fig 4a likely resulting from the higher infiltration rate of dry farmland which covers a considerable portion of nrz compared to rice paddies in srz different stable isotopic compositions of groundwater in srz and nrz can be attributed to differences in both land use and water use liu and yamanaka 2012 darling and bowes 2016 séraphin et al 2016 jung et al 2019 in addition to land use stable isotopic composition indicated a smaller effect of evaporation when a preferential flow path was formed gazis and feng 2004 contribution of paddy impounded water to recharge in srz is readily discernible by more enriched isotopic composition with stronger evaporation signature compared with that in nrz where precipitation and irrigated water in dry farmland mainly contribute to recharge fig 6a three component mixing based on dissolved silica and δ18o revealed three recharge sources of regional groundwater paddy impounded water and winter stream water and their contributions at each monitoring point pca of hydrogeochemical parameters and stable isotopes in groundwater allowed identification of hydrological processes as well as water rock interactions redox processes and the impacts of agricultural contamination the intense seasonal pumping in riparian zones induced groundwater drawdowns of up to 5 m and losing stream conditions during winter otherwise gaining stream conditions would have maintained martin et al 2004 bastola and peterson 2016 lee et al 2017 various properties of water flow including infiltration of stream water were indicated by hydrogeochemical parameters which corroborates monitoring results of groundwater level and temperature groundwater with a large contribution from winter stream water was consistently identified in temperature monitoring three component mixing and pca results fig 10 based on the variation in microbial community structure it is likely that groundwater near the stream was influenced by infiltration of stream water ben maamar et al 2015 lee et al 2018 which is more pronounced in the nrz than in the srz these results show that stream aquifer interactions can be significantly perturbed by human interventions in riparian zones resulting in significant changes to the physical and chemical conditions of groundwater with high spatial and temporal variability that depend on connectivity between aquifers and the stream stanford and ward 1993 menció and mas pla 2010 yang et al 2017 for example the distinctive response of plain side deeper wells in the nrz to losing stream condition suggests the presence of layers with higher permeability such as paleo channel sediments resulting in higher connectivity to the stream revil et al 2005 choi et al 2016 lee et al 2018 agricultural land uses significantly affect recharge processes groundwater flow and contaminant transport in the aquifers in riparian areas watson et al 2010 zeng et al 2016 in addition groundwater uses such as intense pumping strongly control hydraulic conditions in the aquifers which in turn induces changes in stream aquifer interactions chen and shu 2002 zume and tarhule 2008 these factors need to be properly addressed for effective management of surface water and groundwater in riparian zones schilling and zhang 2006 menció et al 2016 in this study the complicated nature of flow processes in the riparian aquifers and stream aquifer interactions were successfully revealed by employing multi parameters which is more effective than a single or limited parameter approach andrade and stigter 2009 each measured or monitored parameter provided information on the different flow processes particularly temperature monitoring and sio2 aq concentration were identified as good indicators for stream water infiltration and water stable isotopes well represented contribution of paddy impounded water to recharge demonstrating usefulness of the multi parameter approach for evaluation of highly heterogeneous systems such as the riparian zones it is also noteworthy that multi level monitoring wells were effective to delineate spatiotemporal variation of flow processes in the study site implementing the multi parameter approach this study revealed the impacts of seasonal pumping and irrigation on the riparian aquifers and stream aquifer interactions resulting in complicated spatiotemporal changes in flow and chemistry of groundwater and the variably gaining and losing conditions of the adjoining stream these findings can contribute to establishment and implementation of effective integrated management plans for groundwater and surface water in the riparian areas with diverse agricultural land uses and water uses and ecosystems related to groundwater 6 summary and conclusions we evaluated flow and hydrogeochemical processes in agricultural riparian zones with contrasting land and groundwater uses based on measurements from multi level monitoring wells and the stream using an integrative approach groundwater levels and temperatures in the study area showed sinusoidal variation due to intense groundwater use in winter from december to february the drawdown was considerably larger in dry farmland area with higher groundwater use water table drawdown was reduced due to the infiltration of stream water under losing stream conditions occurring in winter temporal variation in groundwater temperature indicated infiltration of winter stream water corroborating the losing condition of the stream in the dry farmland and stream side areas deeper infiltration of agriculturally derived solutes such as ca2 and so4 2 was observed in the dry farmland area compared to the paddy area recharge from paddy impounded water was identified by evaporation signatures of water stable isotopes these observations clearly indicate that differences in land use and water use had variable effects on the groundwater flow in the agricultural riparian zones in terms of flow paths recharge and stream aquifer interactions in agricultural activity riparian zones temporal and spatial distribution of recharge sources obtained by three component mixing analysis temporal variation in the winter stream contribution of each well indicated that connectivity between the aquifer and the stream determined the aquifer s response to intense seasonal pumping principal component analysis of hydrogeochemical and isotopic parameters showed major geochemical processes of agricultural contamination water rock interactions and infiltration of paddy impounded water with the increase in infiltration of winter stream water into the aquifers the effects of the geochemical processes changed significantly in the monitoring wells with higher connectivity to the stream indicating that human induced stream aquifer interactions significantly affect hydrological and geochemical processes in riparian zones this study clearly shows that continuous monitoring and seasonal investigation of multiple parameters using multi level monitoring wells can be quite useful for evaluating the highly variable responses of riparian groundwater to the impacts of agricultural activities as well as groundwater stream interactions these efforts can aid the establishment of effective solutions to stream depletion and infiltration of stream water contaminants into aquifers as well as groundwater management in riparian zones our results revealed main drivers for hydrological processes in the riparian zone of the study area are seasonal pumping and irrigation in paddy fields and regulated stream water level as well as regional groundwater which were variably modulated by stream aquifer connectivity and land uses these findings suggest that better land management and water withdrawal are needed to support the natural hydrological and ecological processes in riparian areas credit authorship contribution statement hong il kwon investigation formal analysis data curation writing original draft dong chan koh conceptualization methodology writing review editing youn young jung investigation resources dong hun kim investigation writing original draft kyoochul ha project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the basic research project 18 3411 of the korea institute of geoscience and mineral resources kigam funded by the ministry of science and ict we thank korea rural community corporation krc and local farmers for permission of installation of groundwater monitoring wells in the study site kyoung ho kim provided insightful comments on multivariate statistical analysis which is also appreciated 
5631,copula based statistical model has been extensively used to characterize the joint probability behaviors of extreme hydro climatic design events such as bivariate design floods however parameter uncertainty not desirably but inevitably accompanies the copula based design flood estimation cdfe model which makes the inference results of design flood ambiguous in this paper we develop a bayesian information theoretic bit approach to disclose design flood uncertainty arising from parameter uncertainty in cdfe model and furthermore examine how the parameter uncertainty is propagated to design flood estimation two catchments located in the yellow river basin china are selected as study regions the research we have done indicates that design flood uncertainty is considerably large under parameter uncertainty worse still the uncertainty in design flood increases along with the return period thus making the design flood inference more ambiguous specifically shape and scale parameters of marginal distributions have the largest contribution to the design flood uncertainty followed by copula parameter finally the location parameter of marginal distribution furthermore the interaction between some parameters has dominant effect on design flood uncertainty compared with the individual effect of these parameters these findings will enable better understanding the design flood uncertainty under parameter uncertainty moreover the proposed bit approach also offers a promising technical reference for design estimation of other types of extreme hydrological events not limited to the design flood keywords bayesian information theoretic approach uncertainty quantification and propagation bivariate design flood 1 introduction estimation of design flood under specific return period is of significant concern for flood management such as developing flood control and mitigation scheme designing hydraulic engineering parkes and demeritt 2016 nakamura and oki 2018 it is noteworthy that design flood is multivariate in nature and generally defined by several correlated flood features such as flood peak and volume dung et al 2015 daneshkhah et al 2016 moreover in practice flood peak and volume both are tightly correlated with flood management requena et al 2013 therefore estimating bivariate design flood characterized by correlated flood peak and volume shows its desirability and indispensability compared with traditional univariate design flood estimation over the past years numerous studies have been carried out to estimate bivariate design flood using bivariate probability distributions among them copula based bivariate distributions have received widespread attention within the hydrologic community zhang and singh 2006 karmakar and simonovic 2009 reddy and ganguli 2012 serinaldi 2013 dung et al 2015 fan et al 2016 2017 ozga zielinski et al 2016 guo et al 2017 2018 yin et al 2018 compared with traditional bivariate distributions the copulas allow modeling joint dependence structure of variables without any restrictions on marginal distributions bárdossy and li 2008 nonetheless it is worth noting that uncertainties e g sampling uncertainty parameter uncertainty model uncertainty are inevitably in copula based design flood estimation cdfe serinaldi 2013 dung et al 2015 michailidi and bacchi 2017 these uncertainties make the inference results of design flood ambiguous and seriously affects the accuracy and reliability of design flood consequently the uncertainty problem hinders the application of design flood to flood control in the real world therefore taking the uncertainty of copula based design flood estimation into account in design applications is extremely indispensable however this issue as serinaldi 2013 highlighted has often been overlooked in spite of its widely recognized importance in practical flood management therefore serinaldi 2013 proposed three monte carlo based algorithms to disclose the distribution of copula based design flood under sampling uncertainty following his work there have been a few studies focusing on quantifying impacts of sampling uncertainty on extreme hydro meteorological events to date dung et al 2015 serinaldi 2016 zhang et al 2015 michailidi and bacchi 2017 guo et al 2017 2018 yin et al 2018 for example dung et al 2015 developed bootstrapping based uncertainty estimation method to disclose the influence of different uncertainties on cdfe their results indicate that the sampling uncertainty caused by limited hydrological observations should arise considerable concern compared with model selection uncertainty and parameter estimation method uncertainty similarly michailidi and bacchi 2017 and yin et al 2018 underlined that overlooking sampling uncertainty in cdfe easily results in deceiving results in flood management as inferred by aforementioned works sampling uncertainty is quite high in cdfe from a statistical point of view the small sample i e the limited hydro meteorological records includes insufficient or incomplete information which is hard to characterize the statistical features of the whole population of interest accurately chowdhary and singh 2010 as a result the estimated parameters in copula based bivariate statistical model based on the limited hydrological records are uncertain therefore this paper is designed to disclose parameter uncertainty in copula based bivariate statistical model from a bayesian perspective and then investigate how the parameter uncertainty is propagated to model output uncertainty i e design flood in this paper to sum up this paper focuses on 1 quantifying uncertainties in cdfe model parameters and corresponding model output i e design flood and 2 disclosing the propagation of parameter uncertainty to model output as for the first focus from our knowledge studies investigating design flood uncertainty have not yet received widespread attention among them monte carlo sampling based methods are generally adopted dung et al 2015 guo et al 2017 20188 yin et al 2018 liu et al 2020 in terms of the second one there have been just a few studies discussing this topic serinaldi 2013 zhang et al 2015 serinaldi 2013 and zhang et al 2015 firstly analyzed parameters effects on design flood drought through observing variability of design flood drought under different parameter combinations statistical method for objectively quantifying parameters effects on the output of copula based statistical model is still scarce therefore in this paper we propose a general bayesian information theoretic bit approach to disclose uncertainty in copula based design flood estimation the bit approach integrates bayesian inference based dream approach differential evolution adaptive metropolis algorithm and information theoretic approach specifically the bayesian inference based dream algorithm focuses on disclosing uncertainties in cdfe model parameters and design flood based on the bayesian inference results the mutual information partitioning approach is utilized to quantify parameters individual and interactive effects on design flood uncertainty and thus identify parameters with largest contribution on design flood uncertainty the remainder of the paper is organized as follows section 2 describes the study area and data section 3 introduces the methods used in this study the results and discussion are presented in section 4 section 6 summarizes the main conclusions drawn from the study 2 description of the study region and data the yellow river also known as mother river of china is the second largest river in china the yellow river basin contributes 13 of the cultivated area in china but holds only 3 of the country s water resources cai et al 2011 it is one of the most economically politically and culturally important basins in china lu et al 2019 in present study we select two important catchments lying in the upper and middle yellow river basin as study regions shown in fig 1 i e the upper yellow river basin and jinghe river basin respectively the upper yellow river basin fig 1 is an important area of flood source of the yellow river basin it is situated between 95 50 103 30 e and 32 30 35 00 n from the source of the yellow river to tangnaihe station with an area of 121 792 km2 it is known as water tower of the yellow river basin which contributes 35 of total water resources of this basin but has an area that is only 16 of the whole basin lan et al 2006 brierley et al 2016 wei et al 2016 the upper yellow river basin is crucial for the water resources of the whole basin in northwest china the mean annual runoff observed at the gauge station tangnaihe is 202 33 108 m3 1960 2010 mean annual precipitation varies between 250 and 810 mm of which approximately 75 falls between june and september therefore the warm and wet summer season is the principal flood season of the upper yellow river basin the jinghe river fig 1 is one of 10 principal tributaries of the yellow river it lies in the middle and upper reaches of yellow river the length of mainstream reaches to 455 km with drainage area of approximately 45421 km2 the jinghe river basin characterized with extensive soil erosion area accounting for nearly 73 of the total land cover is one of the most soil eroded areas of the loess plateau china therefore the jinghe river basin is one important source of coarse sediment in the yellow river basin he et al 2015 it should be noted that sediment yield is primarily driven by hyperconcentrated floods annual precipitation in this basin ranges from 350 to 600 mm which is generally deficient in spring and early summer about 36 44 of which falls between july and august the emergence frequency of rainstorm is higher during summer and autumn floods occur frequently after rainstorms and flood peak discharge larger than 1000 m3 s often occur li and wei 2013 annual maximum flood discharge and annual maxima 15 day flood volume observed at tangnaihe 1957 2013 station are utilized to represent the flood characterization in the upper yellow river basin as for the jinghe river basin annual maximum flood discharge and annual maxima 3 day flood volume observed at zhangjiashan station 1960 2010 are collected locations of these stations are displayed in fig 1 the data are provided by the hydrology bureau of the yellow river conservancy commission which takes the main responsibility of monitoring collecting and disposing hydrological information in the yellow river basin 3 methodology in this section the outline of bit approach proposed in this study is briefly described the bit approach is composed of three parts i cdfe model section 3 1 ii bayesian inference based dream algorithm section 3 2 and iii mutual information partitioning approach section 3 3 the cdfe model is embedded into the bayesian inference framework as shown in step 1 in fig 2 with the aid of the bayesian inference framework the posterior distributions of parameters and related design flood can be obtained after the convergence of the dream algorithm step 2 in fig 2 here mutual information is used to measure the strength of the association between posterior parameters the joint entropy is employed to quantify the uncertainty of bivariate design flood with different return periods based on the bayesian inference results the mutual information partitioning approach is performed to identify parameters that contribute the most to the design flood uncertainty step 3 in fig 2 all the methods mentioned above will be described in detail below 3 1 copula based design flood estimation model 3 1 1 copula based joint distribution for describing dependence structure between variables the copula as introduced by sklar 1959 is a powerful tool for modeling the joint dependence structures of individual variables without any restrictions on marginal distributions according to sklar s theorem one d dimensional multivariate joint distribution function hc for random variables x 1 x 2 x d with marginal distribution of f 1 f 2 fd can be expressed as 1 h c x 1 x d θ c f 1 x 1 α 1 f d x d α d θ c u 1 u d θ where θ denotes parameter of copula function c u 1 u d θ θ α 1 α d θ is the parameter vector of joint distribution hc f d x d α d u d f x x x f x t α d dt represents the marginal distribution of x d with parameter α d assuming that joint distribution h c x 1 x d θ is continuous then the joint probability density h c x 1 x d θ can be written as 2 h c x 1 x d θ d h c x 1 x d θ x 1 x d c f 1 x 1 α 1 f d x d α d θ f x 1 x 1 α 1 f x d x d α d c u 1 u d θ i 1 d f x d x d α d where c u 1 u d θ represents the copula probability density function expressed as c u 1 u d θ d c u 1 u d θ u 1 u d noteworthy is that there exist enormous copula functions for modeling dependence structures between variables of interest among them archimedean copulas are widely used ones in hydrological field which including frank clayton and gumbel copulas each of them fits for different types of dependence structures for example the frank copula exhibits no tail dependence the clayton copula which is an asymmetric copula exhibits greater dependence in the negative tail than in the positive in contrast to the clayton copula the gumbel copula can capture the greater positive tail dependence than the negative tail dependence as poulin et al 2007 highlighted taking into account the tail dependence in copula function selection is of great importance for giving the best fit to data samples in this study we focus on estimating the design flood peak and volume with a certain return period due to the positive dependence between flood peak and volume we select the bivariate gumbel copula to characterize their dependence structure in this paper the distribution function of gumbel copula is defined as follows 3 c gumbel u 1 u 2 θ exp ln u 1 θ ln u 2 θ 1 θ θ 0 the density function of gumbel copula is given by 4 c gumbel u 1 u 2 θ ln u 1 θ ln u 2 θ 1 θ θ 2 θ 1 ln u 1 θ ln u 2 θ 1 2 θ θ ln u 1 ln u 2 θ 1 u 1 u 2 exp ln u 1 θ ln u 2 θ 1 θ prior to the copula construction selecting appropriate marginal distribution should be done in this paper five popularly used distributions in hydrology namely the generalized extreme value distribution gev pearson type iii distribution p3 lognormal distribution logn normal distribution norm and gamma distribution gam are selected as candidates for flood peak and volume the kolmogorov smirnov k s test for goodness of fit is conducted for evaluating the validity of these candidate distributions then we use the corrected akaike information criterion aicc to select the most appropriate distribution compared to the classical aic the aicc is much stricter particularly when the sample size is limited tables s1 lists the corresponding results for the marginal distributions selection results indicate that logn distribution is the most appropriate one to model the flood peak and volume series at tangnaihe station gev and gam distributions are suitable for fitting the distributions of flood peak and volume series at zhangjiashan station respectively the probability density functions of logn gev and gam distributions are abbreviated as f logn x μ σ f gev x k μ σ and f gam x a b respectively the logn distribution comprises the scale parameter μ μ r and parameter σ σ 0 that controls the shape and behavior of the tail in terms of gev distribution k k 0 σ σ 0 and μ μ r represent the shape scale and location parameters respectively a a 0 and b b 0 denote shape and scale parameters of gam distribution respectively by substituting c gumbel eq 4 f logn x μ σ f gev x k μ σ and f gam x a b into eq 2 we can obtain the following joint distributions to model the dependence structure between flood peak x 1 and volume x 2 at tangnaihe and zhangjiashan stations tangnaihe 5a h c x 1 x 2 θ h c x 1 x 2 μ 1 σ 1 μ 2 σ 2 θ c gumbel x f x 1 logn t μ 1 σ 1 dt x f x 2 logn t μ 2 σ 2 dt θ f x 1 logn x 1 μ 1 σ 1 f x 2 logn x 2 μ 2 σ 2 zhangjiashan 5b h c x 1 x 2 θ h c x 1 x 2 k μ σ a b θ c gumbel x f x 1 gev t k μ σ dt x f x 2 gam t a b dt θ f x 1 gev x 1 k μ σ f x 2 gam x 2 a b 3 1 2 most likely design flood estimation model in the multivariate case appropriate multivariate design event for a given return period is extremely needed for the design of hydraulic structures however there exists a problem of inherent ambiguity whereby an ensemble of multivariate events shares the same return period focusing on this issue salvadori et al 2011 proposed a most likely design event estimation approach and applied it to determine the multivariate design flood the essence of the method is to select the multivariate design event with largest joint probability density which lies on critical layers l t f for a critical level t the most likely design realization δ ml can be written as 6 δ ml arg max x y l t f h c x y θ t 0 1 where h indicates the density of copula based joint distribution l t f is defined as l t f x y h c x y θ t for computing most likely design realizations for tangnaihe and zhangjiashan stations we can obtain the corresponding equations through substituting h c from eqs 5a 5b into eq 6 design event δ ml can be identified by determining the largest joint probability density eq 6 in the logarithmic domain on the critical layers l t f with the corresponding x y as the design realization with the joint return period t in this study two widely used approaches to compute the joint return period t are used i e the so called or and and approaches the joint probability behaviors for the two types of joint return period are defined in terms of variables x and y with thresholds x and y respectively 1 x x or y y 2 x x and y y accordingly the joint return periods also called primary return periods can be written as 7a t or μ t 1 c f x x α x f y y α y θ 7b t and μ t 1 f x x α x f y y α y c f x x α x f y y α y θ here μ t indicates the average inter arrival time between two successive events μ t 1 for maximum annual events 3 2 bayesian parameter inference for the copula based bivariate statistical model 3 2 1 bayes theorem the bayes theorem provides an elegant approach to quantify model parameters denoted as φ uncertainty and posterior distributions denoted as p φ x on the basis of real world observations x x 1 x 2 xn li et al 2010 mondal et al 2010 cheung et al 2011 zeng et al 2016 jia et al 2018 sethurajan et al 2019 mathematically 8 p φ x f x φ π φ f x φ π φ d φ f x φ π φ where f x φ denotes the likelihood function that quantifies the probability of observations x x 1 x 2 xn given different φ values π φ represents the prior probability distributions of model parameters φ the denominator represents normalizing constant signifying the sum of conditional probabilities f x φ weighted by the joint prior probability distribution π φ here the denominator ensures that the posterior probability density distribution integrates to unity thus the relationship equal in eq 8 can be changed to proportional in the context of copula based bivariate statistical model the likelihood functions f x φ for the tangnaihe and zhangjiashan stations can be expressed as tangnaihe 9a f x φ h c x 1 x 2 μ 1 σ 1 μ 2 σ 2 θ i 1 n h c x i y i μ 1 σ 1 μ 2 σ 2 θ zhangjiashan 9b f x φ h c x 1 x 2 k μ σ a b θ i 1 n h c x i y i k μ σ a b θ additionally to derive the posterior distribution of the parameters in copula based bivariate statistical models the prior distributions are assumed to follow normal distribution and uniform distribution in this paper the details are shown in table 1 3 2 2 differential evolution adaptive metropolis dream algorithm once the likelihood function and prior distribution are defined the posterior parameter probability distributions can be derived through the differential evolution adaptive metropolis dream algorithm vrugt et al 2009 as an adaptation of traditional markov chain monte carlo mcmc algorithm marshall et al 2004 ruggeri et al 2015 kennedy et al 2015 sethuraman and hey 2016 the dream algorithm is an adaptive multiple chain mcmc sampler in which runs multiple chains simultaneously for exploring the entire parameter space and employs one discrete proposal distribution to evolve the sampler to the posterior distribution liu et al 2017 to explore the posterior distributions the metropolis hasting inference is employed in the dream algorithm specifically a candidate parameter set θ k at the current state is generated from a proposal distribution q θ k θ k 1 which only depends on the previous accepted parameter set θ k 1 then the new candidate θ k is accepted or rejected based on the associated hasting ratio expressed as 10 β min p θ k x y q θ k θ k 1 p θ k 1 x y q θ k 1 θ k 1 in the context of cdfe model the accepted candidate θ k parameter will be substituted to eqs 5a 5b then through calculating eqs 6 7a 7b we can obtain the bivariate design flood realizations under different types of return periods repeated application of these steps will result in the so called markov chain for cdfe model parameters and related bivariate design flood realizations in this work the dream convergence is diagnosed by the r metric gelman and rubin 1992 as well as 3 chains for each parameter r value less than 1 2 is regarded as a convergence of the algorithm the reported posterior distributions of parameters are obtained on the basis of 10 000 samples sampled after r convergence 3 3 information theory 3 3 1 entropy based measure for bivariate design flood uncertainty quantification entropy shannon 1948 is the fundamental concept of information theory which is generally used as a way of measuring uncertainty of random variable liu et al 2016 xu et al 2017 let x x 1 x 2 xn be a continuous random variable the entropy of variable x h x is defined as h x f x log f x d x here the base of the logarithm log is 2 f x represents the probability density function of variable x in the case of discrete variables the is replaced by the definition of entropy can be extended to two or more variables for of a pair of continuous variables x y the joint entropy h x y is given by 11 h x y f x y log f x y d x d y h c x y log h c x y d x d y c f x f y f x f y log c f x f y f x f y d x d y here the f x y represents the joint probability density function of variable x and y in the context of cdfe model eq 2 f x y h c x y c f x f y f x f y substituting h c from eq 5a and eq 5b into eq 11 yields the specific formulas of joint entropy for measuring bivariate design flood uncertainty in tangnaihe and zhangjiashan stations 3 3 2 mutual information partitioning approach for disclosing effects of parameters on design flood uncertainty mutual information measures the amount of information that both variables share in other words it indicates the reduction in the uncertainty of one random variable due to the knowledge of the other variable s compared with traditional correlation coefficient the mutual information is more general since it doesn t assume any property of the dependence between variables such as the linearity or continuity the univariate mutual information denoted as umi between a continuous input x and output y is defined by 12 u m i x y p x y log p x y p x p y d x d y it is directly related to shannon s entropy through the following equations 13 u m i x y h x h y h x y umi is always non negative which is zero if variables x and y are statistically independent additionally umi is symmetric so u m i x y u m i y x in present study the umi is used to identify parameters that contribute the most to the design flood uncertainty additionally the strength between cdfe model parameters is also measured by the umi worthy of note is that umi focuses on revealing the contribution of individual model parameter on design flood while disregarding the interaction information stored in two or more parameters in this paper we consider the simplest case which concerns the multivariate mutual information mmi hereafter between a pair of model inputs x 1 x 2 on model output y in addition to using the concept of mmi simply and directly present paper employs the perspective on the structure of mmi williams and beer 2010 to disclose how the total information is distributed amongst the variables specifically the mmi between model inputs x 1 x 2 and output y is partitioned into the unique u redundant r and synergistic s information components the partitioning is defined as 14 m m i x 1 x 2 y p x 1 x 2 y log p x 1 x 2 y p x 1 x 2 p y d x 1 d x 2 d y u 1 x 1 y u 2 x 2 y r x 1 x 2 y s x 1 x 2 y where u 1 u 2 r and s are always nonnegative u 1 and u 2 represent the information component that only variables x 1 and x 2 share with variable y uniquely r indicates the information that variables x 1 and x 2 both share with variable y redundantly i e the overlapping shared information s denotes the information that is provided to variable y only when both variables x 1 and x 2 are known together in other words s represents the cooperative provision of shared information that causes the mmi x 1 x 2 y to be larger than the umi x 1 y and umi x 2 y umi x 1 y and umi x 2 y can be decomposed as williams and beer 2010 15 u m i x 1 y u 1 x 1 y r x 1 x 2 y u m i x 2 y u 2 x 1 y r x 1 x 2 y the difference between r and s is called the interaction information ii 16 i i x 1 x 2 y s x 1 x 2 y r x 1 x 2 y ii can be negative or positive ii 0 denotes the dominance of synergistic relationship among variables while ii 0 denotes the dominance of redundant relationship among variables ii also can be interpreted as the difference between the total information mmi x 1 x 2 y and the sum of univariate mutual information umi x 1 y umi x 2 y i e ii mmi x 1 x 2 y umi x 1 y umi x 2 y hence ii 0 indicates the total information mmi x 1 x 2 y is smaller than the sum of umi i e the dominantly synergistic relationship ii 0 indicates the total information mmi x 1 x 2 y is larger than the sum of umi i e the dominantly redundant relationship from eqs 12 15 16 it can be found that estimating the r value is the core part for computing the information components mentioned in eq 14 in this paper we follow the proposal by goodwell and kumar 2017a b which employs one rescaled redundancy measure rs to represent redundancy r i e rs r 17 r s r r min i s r mmi r min where is represents the normalized source dependency rmmi and r min denote the upper and lower bounds of redundancy respectively specific formulas for is rmmi and r min are shown as follows 18 i s u m i x 1 x 2 min h x 1 h x 2 r mmi min u m i x 1 y u m i x 2 y r min max 0 i i x 1 x 2 y 4 results and discussion 4 1 parameter uncertainty of cdfe model posterior distributions of cdfe model parameters for the tangnaihe and zhangjiashan stations are shown in fig 3 the on diagonal graphs exhibit the posterior distributions of parameters in cdfe model x axis represents posterior range of individual parameter the larger the range the greater the parameter uncertainty in terms of tangnaihe station the posterior distributions of mup muv and siv are close to normal distribution indicating that the posterior distributions of these parameters are well defined in comparison the posterior distribution of sip presents positive skewness which indicates most of sip samples tend to cluster toward the right side of the x axis i e the upper bound the posterior distribution of θ seems flatter not a sharp and peak distribution in other words parameter θ is not well particularly identifiable compared with other parameters as for zhangjiashan station the posterior distributions of almost all of the parameters in cdfe model are normally distributed except for parameter shv which presents positive skewness the off diagonal graphs in fig 3 display the bivariate scatter plots of these posterior samples these graphs highlight the non negligible presence of correlations between cdfe model parameters take tangnaihe station as an example it can be easily found that there exist strongly positive linear relationships in parameter combinations mup muv and sip siv in terms of zhangjiashan station visual inspection of fig 3 reveals the negative non linear relationship between shv and scv in addition to the visual inspection method we employ mutual information to measure the strength of the relationship between parameters compared to the traditional correlation coefficients the mutual information allows for capturing both linear and non linear interdependencies in time series corresponding results are displayed in fig 4 the larger mutual information value means the stronger strength of the relationship between variables from fig 4 it can be easily found that the stronger relationship in parameter combinations mup muv and sip siv in the cdfe model of tangnaihe station shv scv in the cdfe model of zhangjiashan station this conclusion is in agreement with that drawn from fig 3 additionally the strong relationship between shp and scv also should receive remarkable attention in the cdfe model of zhangjiashan station moreover from fig 4 it can be found that parameters of marginal distributions in the cdfe model are tightly correlated with each other by contrast the so called copula parameter θ in the cdfe model presents a relatively weaker relationship with other parameters here worthy of note is that the strength between copula parameter and other parameters is not the weakest while some parameters of marginal distributions in the cdfe model present the weakest relationship specifically in the cdfe model of tangnaihe station mup and siv have the minimum mutual information value indicating the weakest relationship between them in terms of the cdfe model of zhangjiashan station the strength of the relationship between shp and lop is the weakest 4 2 design flood uncertainty under parameter uncertainty in order to disclose the uncertainty of design flood under parameter uncertainty fig 5 exemplarily displays the joint confidence regions of the most likely design flood events with tor tand tsec 20 years through the r package ks the highest density regions under 75 90 and 95 confidence level are displayed as a two dimensional irregular plane it can be found from fig 5 that from a bayesian perspective parameter uncertainty of the cdfe model results in considerably large uncertainty in ascertaining design flood in the 95 confidence region values of bivariate design flood with a return period of 20 years exhibit substantial variations which varies between flood values with return periods of at least 10 and 50 years take the tangnaihe station as example the peak discharge with tor 20 years in 95 confidence region spans from 3 36 103 m3 s to 5 02 103 m3 s while flood volume spans from 36 8 108 m3 to 54 2 108 m3 upper left panel of fig 5 design flood displays enormous difference in the context of parameter uncertainty this result is in accordance with recent studies serinaldi 2013 2016 dung et al 2015 zhang et al 2015 michailidi and bacchi 2017 worthy of note is that the considerable difference of design flood would inevitably pose great challenges for developing flood control and mitigation schemes obscuring the design flood uncertainty would produce incomplete or even misleading conclusions in the practice of flood control therefore as suggested by guo et al 2018 with assist of above uncertainty evaluation results management departments can improve the design standard of flood control engineering and increase water release from reservoirs although it would increase the cost and decrease economic profit additionally another noteworthy point is that how the uncertainty of design flood varies with return periods under parameter uncertainty this study employs the joint entropy to quantitatively measure the uncertainty of bivariate design flood with different return periods the greater the joint entropy the higher uncertainty of design flood fig 6 displays the joint entropy of bivariate design flood under different return periods here for reducing computation burden we set the return period to the range of 20 200 years with step length 15 years it can be easily found from fig 6 that the joint entropy gradually increases with return period increasing it implies that uncertainty of design flood would be larger with higher return period therefore ascertaining design flood becomes particularly harder under higher return period the primary reason behind the considerable uncertainty of design flood is the posterior distributions of model parameters derived from limited hydrological observations from eq 8 we can know that the derived posterior distributions of cdfe model parameters reflect statistical characteristics of hydrological observations therefore the longer length of hydrological observations is more beneficial to improve the accuracy of the posterior distributions of model parameters however in practice only finite hydrological observations can be obtained such as the 57 and 51 observations in tangnaihe and zhangjiashan stations respectively the limited hydrological observations fail to fully characterize the posterior distributions of model parameters thus inducing the uncertainty of design flood under various return periods as highlighted by serinaldi and kilsby 2015 we can only say that there is a 95 probability that the interval between about fourteen and two thousand years contains the true return period of our observed 50 year event anything beyond this kind of specification is speculation therefore to enable a more reliable estimation of design flood expanding the temporal spatial or causal flood data as much as possible is extremely desirable 4 3 effects of parameters on design flood uncertainty 4 3 1 effects of individual parameter on design flood uncertainty to identify the effects of cdfe model parameters on design flood uncertainty we calculate the umi between individual parameter and design flood parameter with highest umi value contributes most to design flood uncertainty fig 7 presents the related results for tangnaihe and zhangjiashan stations it can be easily found from fig 7 that umi values exhibit quite similar variations under three types of joint return periods i e or and and sec for each station compared with copula parameter θ shape and scale parameters of marginal distributions contribute relatively more to design flood uncertainty in terms of the cdfe model for the tangnaihe station upper panel of fig 7 sip and siv have larger contribution to the uncertainty of design flood compared to the other parameters in terms of the cdfe model for zhangjiashan station lower panel of fig 7 shp and scv contribute more to design flood uncertainty above results indicate that in the context of cdfe model paying more attention to the shape and scale parameters of marginal distributions seems more desirable in design flood estimation compared with the copula parameter θ therefore selecting marginal distribution with better fit still be of great concern for design flood estimation moreover we can easily find from lower panel of fig 7 that location parameter has the smallest contribution to design flood uncertainty among the cdfe model parameters more specifically contributions from cdfe model parameters to design flood change with return period take the tangnaihe station as example upper panel of fig 7 umi value between sip siv and or type design flood increases with the increasing return period while umi value between mup muv and or type design flood exhibits opposite trend by contrast contributions from parameter θ to design flood uncertainty show little change with the increasing of return period 4 3 2 effects of multiple parameters on design flood in this section we further examine effects of multiple parameters on design flood uncertainty through calculating mmi between a pair of cdfe model parameters and design flood variations of mmi under changing return periods are shown in figs s1 s2 supplemental material for simplicity these figures are not analysed here alternatively we display the average of mmi for the two stations in fig 8 from the upper panel of fig 8 we can find that parameter combinations mup sip muv siv contribute most to the uncertainty of design flood peak and volume in tangnaihe station respectively as for the zhangjiashan station lower panel of fig 8 parameter combinations shp scp shv scv have the largest contribution to the uncertainty of design flood peak and volume respectively individual parameter with highest umi value shown in fig 7 is contained in the parameter combination with considerably large contribution such as sip in mup sip siv in muv siv for the cdfe model in tangnaihe station here worthy of note is that parameter combination with most contribution doesn t contain both individual parameters with umi ranking the first and second for example contributions from sip and siv to design flood uncertainty rank the top two positions in the cdfe model for tangnaihe station as shown in upper panel of fig 7 whereas the mmi between parameter combination sip siv and design flood ranks the last but one from the information perspective it means that mmi sip siv design flood is smaller than the sum of umi sip design flood and umi siv design flood indicating the presence of negative interaction information between sip siv and design flood this finding indicates the necessity of examine the interaction information between cdfe model parameters and design flood in light of above fig 9 displays exemplarily the decomposition results of mmi i e the so called unique u redundant r and synergistic s information components between cdfe model parameters and and type design flood under tand 200 years figs s3 s4 exhibit corresponding results for or type design flood from upper panel of fig 9 and fig s3 it can be found that except for the parameter combination sip siv other parameter combinations provide higher s than r to design flood in tangnaihe station moreover amount of u information provided from sip siv to design flood peak design flood volume is higher than the other parameter in each sip contained siv contained parameter combination note that sip and siv are also the most sensitive parameters to design flood peak and volume respectively as shown in upper panel of fig 9 as for the zhangjiashan station all parameter combinations except for shp scv provide higher s than r to design flood similar to the tangnaihe station sensitivities of shp and scv rank in the top three positions lower panel of fig 9 while the negative interaction information i e s r between them makes that the multivariate mi shp scv design flood is not the largest above results demonstrate again the necessity of considering the interaction between cdfe model parameters parameter combinations mup sip and muv siv have the strongest influence on design flood peak and volume in tangnaihe station respectively in terms of the zhangjiashan station parameter combinations shp scp and shv scv provide the highest explanatory information to design flood peak and volume respectively fig 10 and figs s5 s6 exhibit the trends in total information and all information decomposition components between these parameter combinations and design flood over different return periods it can be found from fig 10 and figs s5 s6 that variations of total information and related information components between selected parameter combination and design flood exhibit negligible difference specifically as for the tangnaihe station total information of mup sip and muv siv on design flood peak and volume both have gradual decreasing trend with increasing return periods proportion of s information component is largest among the four components which presents a decreasing trend by contrast influence of u information from sip and siv to design flood is increasing gradually in terms of zhangjiashan station the proportion of the sum of u information is higher than the other information content and increases with increasing return periods here u information from shp is larger than that from scp on design flood peak while u information from scv is larger than that from shv on design flood volume it indicates that the shp and scv are primary sources influencing design flood peak and volume in the context of cdfe model respectively 5 summary and conclusions in this study a bayesian information theoretic bit framework is developed to evaluate uncertainty in copula based design flood estimation cdfe in bit framework the bayesian inference based differential evolution adaptive metropolis dream algorithm is employed to disclose uncertainty of design flood moreover with the aid of mutual information partitioning approach in bit framework parameters effects on design flood are quantified in addition to above joint entropy is suggested to quantify the uncertainty of bivariate design flood two important catchments in the yellow river basin are selected as study regions the general conclusions and specific inferences are drawn as follows uncertainties of bivariate design flood for the two catchments are considerably large fig 5 for example the 95 confidence region of bivariate design flood with 20 year return period exhibit substantial variations the corresponding design flood reaches between flood values with return periods of at least 10 and 50 years the large uncertainty of design flood poses great challenges for developing flood control and mitigation schemes worse still the uncertainty of design flood increases with return period increasing fig 6 consequently the related challenges would inevitably be more and more prominent therefore great attention should be paid to the design flood estimation particularly when developing policies for flood control and mitigation furthermore different individual parameters present noticeably different effects on design flood uncertainty fig 7 to be specific the so called shape and scale parameters of marginal distributions contribute relatively more to design flood uncertainty compared with the parameter of copula function location parameter of marginal distribution has the minimum contribution to design flood uncertainty moreover the contribution from shape and scale parameters increase with return periods increasing while that from other parameters of marginal distributions exhibit decreasing trend contribution of copula parameter changes slightly with return periods increasing similarly contributions of different parameter combinations on design flood uncertainty are noticeably different fig 8 worthy of note is that parameter combination with highest contribution doesn t contain both individual parameters with contribution ranking the first and second the phenomenon infers the presence of dominantly redundant information between parameters which is also confirmed by the decomposition of multivariate mutual information fig 9 moreover the synergistic unique and redundant components of multivariate mutual information between parameter combination and design flood are not fixed but monotonically increase or decrease with return period increasing fig 10 above findings enhance understanding the uncertainty in cdfe moreover the developed bit framework is also promising for use in examining uncertainty in the design estimation of other types of extreme hydrological events not restricted to the design flood in addition to above it should be noted that the bit framework under study is only applied to uncover effects of uncertainty arising from a pair of parameters on design flood uncertainty however how the three or more parameters simultaneously influence the design flood uncertainty is not considered therefore improving the mutual information partitioning approach used in this study to enlarge its application scope deserves to be studied in the future work credit authorship contribution statement aijun guo conceptualization methodology writing original draft resources jianxia chang writing review editing resources yimin wang writing review editing investigation resources qiang huang resources yunyun li visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the national natural science foundation of china granted no 51679187 51879214 51909207 key laboratory of science and technology innovation project of shaanxi province 2013szs02 z02 teachers doctoral research initiation fund in xi an university of technology 104 256081916 data associated with this work can be obtained by contacting chxiang xaut edu cn the authors extend special thanks to editors and numerous anonymous reviewers appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124677 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5631,copula based statistical model has been extensively used to characterize the joint probability behaviors of extreme hydro climatic design events such as bivariate design floods however parameter uncertainty not desirably but inevitably accompanies the copula based design flood estimation cdfe model which makes the inference results of design flood ambiguous in this paper we develop a bayesian information theoretic bit approach to disclose design flood uncertainty arising from parameter uncertainty in cdfe model and furthermore examine how the parameter uncertainty is propagated to design flood estimation two catchments located in the yellow river basin china are selected as study regions the research we have done indicates that design flood uncertainty is considerably large under parameter uncertainty worse still the uncertainty in design flood increases along with the return period thus making the design flood inference more ambiguous specifically shape and scale parameters of marginal distributions have the largest contribution to the design flood uncertainty followed by copula parameter finally the location parameter of marginal distribution furthermore the interaction between some parameters has dominant effect on design flood uncertainty compared with the individual effect of these parameters these findings will enable better understanding the design flood uncertainty under parameter uncertainty moreover the proposed bit approach also offers a promising technical reference for design estimation of other types of extreme hydrological events not limited to the design flood keywords bayesian information theoretic approach uncertainty quantification and propagation bivariate design flood 1 introduction estimation of design flood under specific return period is of significant concern for flood management such as developing flood control and mitigation scheme designing hydraulic engineering parkes and demeritt 2016 nakamura and oki 2018 it is noteworthy that design flood is multivariate in nature and generally defined by several correlated flood features such as flood peak and volume dung et al 2015 daneshkhah et al 2016 moreover in practice flood peak and volume both are tightly correlated with flood management requena et al 2013 therefore estimating bivariate design flood characterized by correlated flood peak and volume shows its desirability and indispensability compared with traditional univariate design flood estimation over the past years numerous studies have been carried out to estimate bivariate design flood using bivariate probability distributions among them copula based bivariate distributions have received widespread attention within the hydrologic community zhang and singh 2006 karmakar and simonovic 2009 reddy and ganguli 2012 serinaldi 2013 dung et al 2015 fan et al 2016 2017 ozga zielinski et al 2016 guo et al 2017 2018 yin et al 2018 compared with traditional bivariate distributions the copulas allow modeling joint dependence structure of variables without any restrictions on marginal distributions bárdossy and li 2008 nonetheless it is worth noting that uncertainties e g sampling uncertainty parameter uncertainty model uncertainty are inevitably in copula based design flood estimation cdfe serinaldi 2013 dung et al 2015 michailidi and bacchi 2017 these uncertainties make the inference results of design flood ambiguous and seriously affects the accuracy and reliability of design flood consequently the uncertainty problem hinders the application of design flood to flood control in the real world therefore taking the uncertainty of copula based design flood estimation into account in design applications is extremely indispensable however this issue as serinaldi 2013 highlighted has often been overlooked in spite of its widely recognized importance in practical flood management therefore serinaldi 2013 proposed three monte carlo based algorithms to disclose the distribution of copula based design flood under sampling uncertainty following his work there have been a few studies focusing on quantifying impacts of sampling uncertainty on extreme hydro meteorological events to date dung et al 2015 serinaldi 2016 zhang et al 2015 michailidi and bacchi 2017 guo et al 2017 2018 yin et al 2018 for example dung et al 2015 developed bootstrapping based uncertainty estimation method to disclose the influence of different uncertainties on cdfe their results indicate that the sampling uncertainty caused by limited hydrological observations should arise considerable concern compared with model selection uncertainty and parameter estimation method uncertainty similarly michailidi and bacchi 2017 and yin et al 2018 underlined that overlooking sampling uncertainty in cdfe easily results in deceiving results in flood management as inferred by aforementioned works sampling uncertainty is quite high in cdfe from a statistical point of view the small sample i e the limited hydro meteorological records includes insufficient or incomplete information which is hard to characterize the statistical features of the whole population of interest accurately chowdhary and singh 2010 as a result the estimated parameters in copula based bivariate statistical model based on the limited hydrological records are uncertain therefore this paper is designed to disclose parameter uncertainty in copula based bivariate statistical model from a bayesian perspective and then investigate how the parameter uncertainty is propagated to model output uncertainty i e design flood in this paper to sum up this paper focuses on 1 quantifying uncertainties in cdfe model parameters and corresponding model output i e design flood and 2 disclosing the propagation of parameter uncertainty to model output as for the first focus from our knowledge studies investigating design flood uncertainty have not yet received widespread attention among them monte carlo sampling based methods are generally adopted dung et al 2015 guo et al 2017 20188 yin et al 2018 liu et al 2020 in terms of the second one there have been just a few studies discussing this topic serinaldi 2013 zhang et al 2015 serinaldi 2013 and zhang et al 2015 firstly analyzed parameters effects on design flood drought through observing variability of design flood drought under different parameter combinations statistical method for objectively quantifying parameters effects on the output of copula based statistical model is still scarce therefore in this paper we propose a general bayesian information theoretic bit approach to disclose uncertainty in copula based design flood estimation the bit approach integrates bayesian inference based dream approach differential evolution adaptive metropolis algorithm and information theoretic approach specifically the bayesian inference based dream algorithm focuses on disclosing uncertainties in cdfe model parameters and design flood based on the bayesian inference results the mutual information partitioning approach is utilized to quantify parameters individual and interactive effects on design flood uncertainty and thus identify parameters with largest contribution on design flood uncertainty the remainder of the paper is organized as follows section 2 describes the study area and data section 3 introduces the methods used in this study the results and discussion are presented in section 4 section 6 summarizes the main conclusions drawn from the study 2 description of the study region and data the yellow river also known as mother river of china is the second largest river in china the yellow river basin contributes 13 of the cultivated area in china but holds only 3 of the country s water resources cai et al 2011 it is one of the most economically politically and culturally important basins in china lu et al 2019 in present study we select two important catchments lying in the upper and middle yellow river basin as study regions shown in fig 1 i e the upper yellow river basin and jinghe river basin respectively the upper yellow river basin fig 1 is an important area of flood source of the yellow river basin it is situated between 95 50 103 30 e and 32 30 35 00 n from the source of the yellow river to tangnaihe station with an area of 121 792 km2 it is known as water tower of the yellow river basin which contributes 35 of total water resources of this basin but has an area that is only 16 of the whole basin lan et al 2006 brierley et al 2016 wei et al 2016 the upper yellow river basin is crucial for the water resources of the whole basin in northwest china the mean annual runoff observed at the gauge station tangnaihe is 202 33 108 m3 1960 2010 mean annual precipitation varies between 250 and 810 mm of which approximately 75 falls between june and september therefore the warm and wet summer season is the principal flood season of the upper yellow river basin the jinghe river fig 1 is one of 10 principal tributaries of the yellow river it lies in the middle and upper reaches of yellow river the length of mainstream reaches to 455 km with drainage area of approximately 45421 km2 the jinghe river basin characterized with extensive soil erosion area accounting for nearly 73 of the total land cover is one of the most soil eroded areas of the loess plateau china therefore the jinghe river basin is one important source of coarse sediment in the yellow river basin he et al 2015 it should be noted that sediment yield is primarily driven by hyperconcentrated floods annual precipitation in this basin ranges from 350 to 600 mm which is generally deficient in spring and early summer about 36 44 of which falls between july and august the emergence frequency of rainstorm is higher during summer and autumn floods occur frequently after rainstorms and flood peak discharge larger than 1000 m3 s often occur li and wei 2013 annual maximum flood discharge and annual maxima 15 day flood volume observed at tangnaihe 1957 2013 station are utilized to represent the flood characterization in the upper yellow river basin as for the jinghe river basin annual maximum flood discharge and annual maxima 3 day flood volume observed at zhangjiashan station 1960 2010 are collected locations of these stations are displayed in fig 1 the data are provided by the hydrology bureau of the yellow river conservancy commission which takes the main responsibility of monitoring collecting and disposing hydrological information in the yellow river basin 3 methodology in this section the outline of bit approach proposed in this study is briefly described the bit approach is composed of three parts i cdfe model section 3 1 ii bayesian inference based dream algorithm section 3 2 and iii mutual information partitioning approach section 3 3 the cdfe model is embedded into the bayesian inference framework as shown in step 1 in fig 2 with the aid of the bayesian inference framework the posterior distributions of parameters and related design flood can be obtained after the convergence of the dream algorithm step 2 in fig 2 here mutual information is used to measure the strength of the association between posterior parameters the joint entropy is employed to quantify the uncertainty of bivariate design flood with different return periods based on the bayesian inference results the mutual information partitioning approach is performed to identify parameters that contribute the most to the design flood uncertainty step 3 in fig 2 all the methods mentioned above will be described in detail below 3 1 copula based design flood estimation model 3 1 1 copula based joint distribution for describing dependence structure between variables the copula as introduced by sklar 1959 is a powerful tool for modeling the joint dependence structures of individual variables without any restrictions on marginal distributions according to sklar s theorem one d dimensional multivariate joint distribution function hc for random variables x 1 x 2 x d with marginal distribution of f 1 f 2 fd can be expressed as 1 h c x 1 x d θ c f 1 x 1 α 1 f d x d α d θ c u 1 u d θ where θ denotes parameter of copula function c u 1 u d θ θ α 1 α d θ is the parameter vector of joint distribution hc f d x d α d u d f x x x f x t α d dt represents the marginal distribution of x d with parameter α d assuming that joint distribution h c x 1 x d θ is continuous then the joint probability density h c x 1 x d θ can be written as 2 h c x 1 x d θ d h c x 1 x d θ x 1 x d c f 1 x 1 α 1 f d x d α d θ f x 1 x 1 α 1 f x d x d α d c u 1 u d θ i 1 d f x d x d α d where c u 1 u d θ represents the copula probability density function expressed as c u 1 u d θ d c u 1 u d θ u 1 u d noteworthy is that there exist enormous copula functions for modeling dependence structures between variables of interest among them archimedean copulas are widely used ones in hydrological field which including frank clayton and gumbel copulas each of them fits for different types of dependence structures for example the frank copula exhibits no tail dependence the clayton copula which is an asymmetric copula exhibits greater dependence in the negative tail than in the positive in contrast to the clayton copula the gumbel copula can capture the greater positive tail dependence than the negative tail dependence as poulin et al 2007 highlighted taking into account the tail dependence in copula function selection is of great importance for giving the best fit to data samples in this study we focus on estimating the design flood peak and volume with a certain return period due to the positive dependence between flood peak and volume we select the bivariate gumbel copula to characterize their dependence structure in this paper the distribution function of gumbel copula is defined as follows 3 c gumbel u 1 u 2 θ exp ln u 1 θ ln u 2 θ 1 θ θ 0 the density function of gumbel copula is given by 4 c gumbel u 1 u 2 θ ln u 1 θ ln u 2 θ 1 θ θ 2 θ 1 ln u 1 θ ln u 2 θ 1 2 θ θ ln u 1 ln u 2 θ 1 u 1 u 2 exp ln u 1 θ ln u 2 θ 1 θ prior to the copula construction selecting appropriate marginal distribution should be done in this paper five popularly used distributions in hydrology namely the generalized extreme value distribution gev pearson type iii distribution p3 lognormal distribution logn normal distribution norm and gamma distribution gam are selected as candidates for flood peak and volume the kolmogorov smirnov k s test for goodness of fit is conducted for evaluating the validity of these candidate distributions then we use the corrected akaike information criterion aicc to select the most appropriate distribution compared to the classical aic the aicc is much stricter particularly when the sample size is limited tables s1 lists the corresponding results for the marginal distributions selection results indicate that logn distribution is the most appropriate one to model the flood peak and volume series at tangnaihe station gev and gam distributions are suitable for fitting the distributions of flood peak and volume series at zhangjiashan station respectively the probability density functions of logn gev and gam distributions are abbreviated as f logn x μ σ f gev x k μ σ and f gam x a b respectively the logn distribution comprises the scale parameter μ μ r and parameter σ σ 0 that controls the shape and behavior of the tail in terms of gev distribution k k 0 σ σ 0 and μ μ r represent the shape scale and location parameters respectively a a 0 and b b 0 denote shape and scale parameters of gam distribution respectively by substituting c gumbel eq 4 f logn x μ σ f gev x k μ σ and f gam x a b into eq 2 we can obtain the following joint distributions to model the dependence structure between flood peak x 1 and volume x 2 at tangnaihe and zhangjiashan stations tangnaihe 5a h c x 1 x 2 θ h c x 1 x 2 μ 1 σ 1 μ 2 σ 2 θ c gumbel x f x 1 logn t μ 1 σ 1 dt x f x 2 logn t μ 2 σ 2 dt θ f x 1 logn x 1 μ 1 σ 1 f x 2 logn x 2 μ 2 σ 2 zhangjiashan 5b h c x 1 x 2 θ h c x 1 x 2 k μ σ a b θ c gumbel x f x 1 gev t k μ σ dt x f x 2 gam t a b dt θ f x 1 gev x 1 k μ σ f x 2 gam x 2 a b 3 1 2 most likely design flood estimation model in the multivariate case appropriate multivariate design event for a given return period is extremely needed for the design of hydraulic structures however there exists a problem of inherent ambiguity whereby an ensemble of multivariate events shares the same return period focusing on this issue salvadori et al 2011 proposed a most likely design event estimation approach and applied it to determine the multivariate design flood the essence of the method is to select the multivariate design event with largest joint probability density which lies on critical layers l t f for a critical level t the most likely design realization δ ml can be written as 6 δ ml arg max x y l t f h c x y θ t 0 1 where h indicates the density of copula based joint distribution l t f is defined as l t f x y h c x y θ t for computing most likely design realizations for tangnaihe and zhangjiashan stations we can obtain the corresponding equations through substituting h c from eqs 5a 5b into eq 6 design event δ ml can be identified by determining the largest joint probability density eq 6 in the logarithmic domain on the critical layers l t f with the corresponding x y as the design realization with the joint return period t in this study two widely used approaches to compute the joint return period t are used i e the so called or and and approaches the joint probability behaviors for the two types of joint return period are defined in terms of variables x and y with thresholds x and y respectively 1 x x or y y 2 x x and y y accordingly the joint return periods also called primary return periods can be written as 7a t or μ t 1 c f x x α x f y y α y θ 7b t and μ t 1 f x x α x f y y α y c f x x α x f y y α y θ here μ t indicates the average inter arrival time between two successive events μ t 1 for maximum annual events 3 2 bayesian parameter inference for the copula based bivariate statistical model 3 2 1 bayes theorem the bayes theorem provides an elegant approach to quantify model parameters denoted as φ uncertainty and posterior distributions denoted as p φ x on the basis of real world observations x x 1 x 2 xn li et al 2010 mondal et al 2010 cheung et al 2011 zeng et al 2016 jia et al 2018 sethurajan et al 2019 mathematically 8 p φ x f x φ π φ f x φ π φ d φ f x φ π φ where f x φ denotes the likelihood function that quantifies the probability of observations x x 1 x 2 xn given different φ values π φ represents the prior probability distributions of model parameters φ the denominator represents normalizing constant signifying the sum of conditional probabilities f x φ weighted by the joint prior probability distribution π φ here the denominator ensures that the posterior probability density distribution integrates to unity thus the relationship equal in eq 8 can be changed to proportional in the context of copula based bivariate statistical model the likelihood functions f x φ for the tangnaihe and zhangjiashan stations can be expressed as tangnaihe 9a f x φ h c x 1 x 2 μ 1 σ 1 μ 2 σ 2 θ i 1 n h c x i y i μ 1 σ 1 μ 2 σ 2 θ zhangjiashan 9b f x φ h c x 1 x 2 k μ σ a b θ i 1 n h c x i y i k μ σ a b θ additionally to derive the posterior distribution of the parameters in copula based bivariate statistical models the prior distributions are assumed to follow normal distribution and uniform distribution in this paper the details are shown in table 1 3 2 2 differential evolution adaptive metropolis dream algorithm once the likelihood function and prior distribution are defined the posterior parameter probability distributions can be derived through the differential evolution adaptive metropolis dream algorithm vrugt et al 2009 as an adaptation of traditional markov chain monte carlo mcmc algorithm marshall et al 2004 ruggeri et al 2015 kennedy et al 2015 sethuraman and hey 2016 the dream algorithm is an adaptive multiple chain mcmc sampler in which runs multiple chains simultaneously for exploring the entire parameter space and employs one discrete proposal distribution to evolve the sampler to the posterior distribution liu et al 2017 to explore the posterior distributions the metropolis hasting inference is employed in the dream algorithm specifically a candidate parameter set θ k at the current state is generated from a proposal distribution q θ k θ k 1 which only depends on the previous accepted parameter set θ k 1 then the new candidate θ k is accepted or rejected based on the associated hasting ratio expressed as 10 β min p θ k x y q θ k θ k 1 p θ k 1 x y q θ k 1 θ k 1 in the context of cdfe model the accepted candidate θ k parameter will be substituted to eqs 5a 5b then through calculating eqs 6 7a 7b we can obtain the bivariate design flood realizations under different types of return periods repeated application of these steps will result in the so called markov chain for cdfe model parameters and related bivariate design flood realizations in this work the dream convergence is diagnosed by the r metric gelman and rubin 1992 as well as 3 chains for each parameter r value less than 1 2 is regarded as a convergence of the algorithm the reported posterior distributions of parameters are obtained on the basis of 10 000 samples sampled after r convergence 3 3 information theory 3 3 1 entropy based measure for bivariate design flood uncertainty quantification entropy shannon 1948 is the fundamental concept of information theory which is generally used as a way of measuring uncertainty of random variable liu et al 2016 xu et al 2017 let x x 1 x 2 xn be a continuous random variable the entropy of variable x h x is defined as h x f x log f x d x here the base of the logarithm log is 2 f x represents the probability density function of variable x in the case of discrete variables the is replaced by the definition of entropy can be extended to two or more variables for of a pair of continuous variables x y the joint entropy h x y is given by 11 h x y f x y log f x y d x d y h c x y log h c x y d x d y c f x f y f x f y log c f x f y f x f y d x d y here the f x y represents the joint probability density function of variable x and y in the context of cdfe model eq 2 f x y h c x y c f x f y f x f y substituting h c from eq 5a and eq 5b into eq 11 yields the specific formulas of joint entropy for measuring bivariate design flood uncertainty in tangnaihe and zhangjiashan stations 3 3 2 mutual information partitioning approach for disclosing effects of parameters on design flood uncertainty mutual information measures the amount of information that both variables share in other words it indicates the reduction in the uncertainty of one random variable due to the knowledge of the other variable s compared with traditional correlation coefficient the mutual information is more general since it doesn t assume any property of the dependence between variables such as the linearity or continuity the univariate mutual information denoted as umi between a continuous input x and output y is defined by 12 u m i x y p x y log p x y p x p y d x d y it is directly related to shannon s entropy through the following equations 13 u m i x y h x h y h x y umi is always non negative which is zero if variables x and y are statistically independent additionally umi is symmetric so u m i x y u m i y x in present study the umi is used to identify parameters that contribute the most to the design flood uncertainty additionally the strength between cdfe model parameters is also measured by the umi worthy of note is that umi focuses on revealing the contribution of individual model parameter on design flood while disregarding the interaction information stored in two or more parameters in this paper we consider the simplest case which concerns the multivariate mutual information mmi hereafter between a pair of model inputs x 1 x 2 on model output y in addition to using the concept of mmi simply and directly present paper employs the perspective on the structure of mmi williams and beer 2010 to disclose how the total information is distributed amongst the variables specifically the mmi between model inputs x 1 x 2 and output y is partitioned into the unique u redundant r and synergistic s information components the partitioning is defined as 14 m m i x 1 x 2 y p x 1 x 2 y log p x 1 x 2 y p x 1 x 2 p y d x 1 d x 2 d y u 1 x 1 y u 2 x 2 y r x 1 x 2 y s x 1 x 2 y where u 1 u 2 r and s are always nonnegative u 1 and u 2 represent the information component that only variables x 1 and x 2 share with variable y uniquely r indicates the information that variables x 1 and x 2 both share with variable y redundantly i e the overlapping shared information s denotes the information that is provided to variable y only when both variables x 1 and x 2 are known together in other words s represents the cooperative provision of shared information that causes the mmi x 1 x 2 y to be larger than the umi x 1 y and umi x 2 y umi x 1 y and umi x 2 y can be decomposed as williams and beer 2010 15 u m i x 1 y u 1 x 1 y r x 1 x 2 y u m i x 2 y u 2 x 1 y r x 1 x 2 y the difference between r and s is called the interaction information ii 16 i i x 1 x 2 y s x 1 x 2 y r x 1 x 2 y ii can be negative or positive ii 0 denotes the dominance of synergistic relationship among variables while ii 0 denotes the dominance of redundant relationship among variables ii also can be interpreted as the difference between the total information mmi x 1 x 2 y and the sum of univariate mutual information umi x 1 y umi x 2 y i e ii mmi x 1 x 2 y umi x 1 y umi x 2 y hence ii 0 indicates the total information mmi x 1 x 2 y is smaller than the sum of umi i e the dominantly synergistic relationship ii 0 indicates the total information mmi x 1 x 2 y is larger than the sum of umi i e the dominantly redundant relationship from eqs 12 15 16 it can be found that estimating the r value is the core part for computing the information components mentioned in eq 14 in this paper we follow the proposal by goodwell and kumar 2017a b which employs one rescaled redundancy measure rs to represent redundancy r i e rs r 17 r s r r min i s r mmi r min where is represents the normalized source dependency rmmi and r min denote the upper and lower bounds of redundancy respectively specific formulas for is rmmi and r min are shown as follows 18 i s u m i x 1 x 2 min h x 1 h x 2 r mmi min u m i x 1 y u m i x 2 y r min max 0 i i x 1 x 2 y 4 results and discussion 4 1 parameter uncertainty of cdfe model posterior distributions of cdfe model parameters for the tangnaihe and zhangjiashan stations are shown in fig 3 the on diagonal graphs exhibit the posterior distributions of parameters in cdfe model x axis represents posterior range of individual parameter the larger the range the greater the parameter uncertainty in terms of tangnaihe station the posterior distributions of mup muv and siv are close to normal distribution indicating that the posterior distributions of these parameters are well defined in comparison the posterior distribution of sip presents positive skewness which indicates most of sip samples tend to cluster toward the right side of the x axis i e the upper bound the posterior distribution of θ seems flatter not a sharp and peak distribution in other words parameter θ is not well particularly identifiable compared with other parameters as for zhangjiashan station the posterior distributions of almost all of the parameters in cdfe model are normally distributed except for parameter shv which presents positive skewness the off diagonal graphs in fig 3 display the bivariate scatter plots of these posterior samples these graphs highlight the non negligible presence of correlations between cdfe model parameters take tangnaihe station as an example it can be easily found that there exist strongly positive linear relationships in parameter combinations mup muv and sip siv in terms of zhangjiashan station visual inspection of fig 3 reveals the negative non linear relationship between shv and scv in addition to the visual inspection method we employ mutual information to measure the strength of the relationship between parameters compared to the traditional correlation coefficients the mutual information allows for capturing both linear and non linear interdependencies in time series corresponding results are displayed in fig 4 the larger mutual information value means the stronger strength of the relationship between variables from fig 4 it can be easily found that the stronger relationship in parameter combinations mup muv and sip siv in the cdfe model of tangnaihe station shv scv in the cdfe model of zhangjiashan station this conclusion is in agreement with that drawn from fig 3 additionally the strong relationship between shp and scv also should receive remarkable attention in the cdfe model of zhangjiashan station moreover from fig 4 it can be found that parameters of marginal distributions in the cdfe model are tightly correlated with each other by contrast the so called copula parameter θ in the cdfe model presents a relatively weaker relationship with other parameters here worthy of note is that the strength between copula parameter and other parameters is not the weakest while some parameters of marginal distributions in the cdfe model present the weakest relationship specifically in the cdfe model of tangnaihe station mup and siv have the minimum mutual information value indicating the weakest relationship between them in terms of the cdfe model of zhangjiashan station the strength of the relationship between shp and lop is the weakest 4 2 design flood uncertainty under parameter uncertainty in order to disclose the uncertainty of design flood under parameter uncertainty fig 5 exemplarily displays the joint confidence regions of the most likely design flood events with tor tand tsec 20 years through the r package ks the highest density regions under 75 90 and 95 confidence level are displayed as a two dimensional irregular plane it can be found from fig 5 that from a bayesian perspective parameter uncertainty of the cdfe model results in considerably large uncertainty in ascertaining design flood in the 95 confidence region values of bivariate design flood with a return period of 20 years exhibit substantial variations which varies between flood values with return periods of at least 10 and 50 years take the tangnaihe station as example the peak discharge with tor 20 years in 95 confidence region spans from 3 36 103 m3 s to 5 02 103 m3 s while flood volume spans from 36 8 108 m3 to 54 2 108 m3 upper left panel of fig 5 design flood displays enormous difference in the context of parameter uncertainty this result is in accordance with recent studies serinaldi 2013 2016 dung et al 2015 zhang et al 2015 michailidi and bacchi 2017 worthy of note is that the considerable difference of design flood would inevitably pose great challenges for developing flood control and mitigation schemes obscuring the design flood uncertainty would produce incomplete or even misleading conclusions in the practice of flood control therefore as suggested by guo et al 2018 with assist of above uncertainty evaluation results management departments can improve the design standard of flood control engineering and increase water release from reservoirs although it would increase the cost and decrease economic profit additionally another noteworthy point is that how the uncertainty of design flood varies with return periods under parameter uncertainty this study employs the joint entropy to quantitatively measure the uncertainty of bivariate design flood with different return periods the greater the joint entropy the higher uncertainty of design flood fig 6 displays the joint entropy of bivariate design flood under different return periods here for reducing computation burden we set the return period to the range of 20 200 years with step length 15 years it can be easily found from fig 6 that the joint entropy gradually increases with return period increasing it implies that uncertainty of design flood would be larger with higher return period therefore ascertaining design flood becomes particularly harder under higher return period the primary reason behind the considerable uncertainty of design flood is the posterior distributions of model parameters derived from limited hydrological observations from eq 8 we can know that the derived posterior distributions of cdfe model parameters reflect statistical characteristics of hydrological observations therefore the longer length of hydrological observations is more beneficial to improve the accuracy of the posterior distributions of model parameters however in practice only finite hydrological observations can be obtained such as the 57 and 51 observations in tangnaihe and zhangjiashan stations respectively the limited hydrological observations fail to fully characterize the posterior distributions of model parameters thus inducing the uncertainty of design flood under various return periods as highlighted by serinaldi and kilsby 2015 we can only say that there is a 95 probability that the interval between about fourteen and two thousand years contains the true return period of our observed 50 year event anything beyond this kind of specification is speculation therefore to enable a more reliable estimation of design flood expanding the temporal spatial or causal flood data as much as possible is extremely desirable 4 3 effects of parameters on design flood uncertainty 4 3 1 effects of individual parameter on design flood uncertainty to identify the effects of cdfe model parameters on design flood uncertainty we calculate the umi between individual parameter and design flood parameter with highest umi value contributes most to design flood uncertainty fig 7 presents the related results for tangnaihe and zhangjiashan stations it can be easily found from fig 7 that umi values exhibit quite similar variations under three types of joint return periods i e or and and sec for each station compared with copula parameter θ shape and scale parameters of marginal distributions contribute relatively more to design flood uncertainty in terms of the cdfe model for the tangnaihe station upper panel of fig 7 sip and siv have larger contribution to the uncertainty of design flood compared to the other parameters in terms of the cdfe model for zhangjiashan station lower panel of fig 7 shp and scv contribute more to design flood uncertainty above results indicate that in the context of cdfe model paying more attention to the shape and scale parameters of marginal distributions seems more desirable in design flood estimation compared with the copula parameter θ therefore selecting marginal distribution with better fit still be of great concern for design flood estimation moreover we can easily find from lower panel of fig 7 that location parameter has the smallest contribution to design flood uncertainty among the cdfe model parameters more specifically contributions from cdfe model parameters to design flood change with return period take the tangnaihe station as example upper panel of fig 7 umi value between sip siv and or type design flood increases with the increasing return period while umi value between mup muv and or type design flood exhibits opposite trend by contrast contributions from parameter θ to design flood uncertainty show little change with the increasing of return period 4 3 2 effects of multiple parameters on design flood in this section we further examine effects of multiple parameters on design flood uncertainty through calculating mmi between a pair of cdfe model parameters and design flood variations of mmi under changing return periods are shown in figs s1 s2 supplemental material for simplicity these figures are not analysed here alternatively we display the average of mmi for the two stations in fig 8 from the upper panel of fig 8 we can find that parameter combinations mup sip muv siv contribute most to the uncertainty of design flood peak and volume in tangnaihe station respectively as for the zhangjiashan station lower panel of fig 8 parameter combinations shp scp shv scv have the largest contribution to the uncertainty of design flood peak and volume respectively individual parameter with highest umi value shown in fig 7 is contained in the parameter combination with considerably large contribution such as sip in mup sip siv in muv siv for the cdfe model in tangnaihe station here worthy of note is that parameter combination with most contribution doesn t contain both individual parameters with umi ranking the first and second for example contributions from sip and siv to design flood uncertainty rank the top two positions in the cdfe model for tangnaihe station as shown in upper panel of fig 7 whereas the mmi between parameter combination sip siv and design flood ranks the last but one from the information perspective it means that mmi sip siv design flood is smaller than the sum of umi sip design flood and umi siv design flood indicating the presence of negative interaction information between sip siv and design flood this finding indicates the necessity of examine the interaction information between cdfe model parameters and design flood in light of above fig 9 displays exemplarily the decomposition results of mmi i e the so called unique u redundant r and synergistic s information components between cdfe model parameters and and type design flood under tand 200 years figs s3 s4 exhibit corresponding results for or type design flood from upper panel of fig 9 and fig s3 it can be found that except for the parameter combination sip siv other parameter combinations provide higher s than r to design flood in tangnaihe station moreover amount of u information provided from sip siv to design flood peak design flood volume is higher than the other parameter in each sip contained siv contained parameter combination note that sip and siv are also the most sensitive parameters to design flood peak and volume respectively as shown in upper panel of fig 9 as for the zhangjiashan station all parameter combinations except for shp scv provide higher s than r to design flood similar to the tangnaihe station sensitivities of shp and scv rank in the top three positions lower panel of fig 9 while the negative interaction information i e s r between them makes that the multivariate mi shp scv design flood is not the largest above results demonstrate again the necessity of considering the interaction between cdfe model parameters parameter combinations mup sip and muv siv have the strongest influence on design flood peak and volume in tangnaihe station respectively in terms of the zhangjiashan station parameter combinations shp scp and shv scv provide the highest explanatory information to design flood peak and volume respectively fig 10 and figs s5 s6 exhibit the trends in total information and all information decomposition components between these parameter combinations and design flood over different return periods it can be found from fig 10 and figs s5 s6 that variations of total information and related information components between selected parameter combination and design flood exhibit negligible difference specifically as for the tangnaihe station total information of mup sip and muv siv on design flood peak and volume both have gradual decreasing trend with increasing return periods proportion of s information component is largest among the four components which presents a decreasing trend by contrast influence of u information from sip and siv to design flood is increasing gradually in terms of zhangjiashan station the proportion of the sum of u information is higher than the other information content and increases with increasing return periods here u information from shp is larger than that from scp on design flood peak while u information from scv is larger than that from shv on design flood volume it indicates that the shp and scv are primary sources influencing design flood peak and volume in the context of cdfe model respectively 5 summary and conclusions in this study a bayesian information theoretic bit framework is developed to evaluate uncertainty in copula based design flood estimation cdfe in bit framework the bayesian inference based differential evolution adaptive metropolis dream algorithm is employed to disclose uncertainty of design flood moreover with the aid of mutual information partitioning approach in bit framework parameters effects on design flood are quantified in addition to above joint entropy is suggested to quantify the uncertainty of bivariate design flood two important catchments in the yellow river basin are selected as study regions the general conclusions and specific inferences are drawn as follows uncertainties of bivariate design flood for the two catchments are considerably large fig 5 for example the 95 confidence region of bivariate design flood with 20 year return period exhibit substantial variations the corresponding design flood reaches between flood values with return periods of at least 10 and 50 years the large uncertainty of design flood poses great challenges for developing flood control and mitigation schemes worse still the uncertainty of design flood increases with return period increasing fig 6 consequently the related challenges would inevitably be more and more prominent therefore great attention should be paid to the design flood estimation particularly when developing policies for flood control and mitigation furthermore different individual parameters present noticeably different effects on design flood uncertainty fig 7 to be specific the so called shape and scale parameters of marginal distributions contribute relatively more to design flood uncertainty compared with the parameter of copula function location parameter of marginal distribution has the minimum contribution to design flood uncertainty moreover the contribution from shape and scale parameters increase with return periods increasing while that from other parameters of marginal distributions exhibit decreasing trend contribution of copula parameter changes slightly with return periods increasing similarly contributions of different parameter combinations on design flood uncertainty are noticeably different fig 8 worthy of note is that parameter combination with highest contribution doesn t contain both individual parameters with contribution ranking the first and second the phenomenon infers the presence of dominantly redundant information between parameters which is also confirmed by the decomposition of multivariate mutual information fig 9 moreover the synergistic unique and redundant components of multivariate mutual information between parameter combination and design flood are not fixed but monotonically increase or decrease with return period increasing fig 10 above findings enhance understanding the uncertainty in cdfe moreover the developed bit framework is also promising for use in examining uncertainty in the design estimation of other types of extreme hydrological events not restricted to the design flood in addition to above it should be noted that the bit framework under study is only applied to uncover effects of uncertainty arising from a pair of parameters on design flood uncertainty however how the three or more parameters simultaneously influence the design flood uncertainty is not considered therefore improving the mutual information partitioning approach used in this study to enlarge its application scope deserves to be studied in the future work credit authorship contribution statement aijun guo conceptualization methodology writing original draft resources jianxia chang writing review editing resources yimin wang writing review editing investigation resources qiang huang resources yunyun li visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the national natural science foundation of china granted no 51679187 51879214 51909207 key laboratory of science and technology innovation project of shaanxi province 2013szs02 z02 teachers doctoral research initiation fund in xi an university of technology 104 256081916 data associated with this work can be obtained by contacting chxiang xaut edu cn the authors extend special thanks to editors and numerous anonymous reviewers appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124677 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5632,this study evaluates the univariate and bivariate characteristics of five gridded products with respect to the adjusted and homogenized canadian climate data for 1980 2010 spatial variations of temperature and precipitation biases including the ones corresponding to the magnitude and frequency of extremes are assessed over canada the dependence structure between the two variables is analysed across each dataset using a goodness of fit test based on copulas the propagation of univariate and bivariate biases into streamflow simulations is then investigated by driving a semi distributed hydrological model for three watersheds with distinct characteristics in western canada the input data include original unadjusted and bias corrected climate data based on the univariate quantile delta mapping and multivariate bias correction approaches the univariate analyses show that all datasets have relatively significant cold and wet biases to the west of the rocky mountains and hot and dry biases over the prairies bivariate evaluations using copulas show that all products fail to capture the dependence structure between temperature and precipitation at the majority of the locations which can undermine their suitability for compound event assessments the differences between univariate and multivariate bias correction approaches are highlighted by the significant differences in the interrelationships between precipitation and temperature hydrological modelling results show major improvements in the detection of extremes after correcting the bivariate biases of the input datasets keywords gridded climate datasets bivariate comparison compound events multivariate bias correction hydrological modelling precipitation temperature 1 introduction extreme weather events commonly occur because of the interactions between temperature and precipitation for example precipitation on an unusually warm winter day will likely increase the chances of flooding in snow packed regions similarly extended periods of low precipitation along with high temperatures in the summer give rise to heatwaves droughts and wildfires according to the intergovernmental panel on climate change ipcc special report seneviratne et al 2012 compound events can be defined as two or more extreme events occurring simultaneously or successively or combinations of events that are not themselves extremes but lead to an extreme event or impact when combined the increasing frequency of extremes and their catastrophic effects on human life and infrastructure have resulted in peaked interest in identification prediction and mitigation of compound events highlighting shortcomings of the definition of compound events in the ipcc report leonard et al 2014 proposed a more general definition a compound event is an extreme impact that depends on multiple statistically dependent variables or events and laid out a framework for analysing modeling and communicating the risks associated with such events whereas earlier most studies performed univariate analysis of extremes the focus has now shifted towards multivariate analyses considering the joint behaviour of multiple factors this has been made possible by advances in modeling tools and methodologies for studying multivariate data such as copulas introduced by sklar 1959 copulas are a set of functions that can bind individual marginals with their dependence structure to create multivariate distributions which allow for easy interpretation of joint return periods and exceedance probabilities singh et al 2019 the efficacy of applying copulas to meteorology and climate research was presented by schoelzel and friederichs 2008 aghakouchak et al 2014 used copulas to show that univariate methods underestimate or overestimate drought return periods as compared to the bivariate study of temperature and precipitation zscheischler and seneviratne 2017 analysed joint quantiles of temperature and precipitation and reported that the likelihood of a hot and dry summer in russia increased by a factor of 5 when both variables were considered as compared to their individual analysis although advances have been made in tools to analyse multivariate data for example the development of the multivariate copula analysis toolbox by sadegh et al 2017 the availability and reliability of climate data is still a limiting factor hutchinson et al 2009 provide extensive details about the availability of station data in canada obtained from the national climate data archive ncda they report the presence of 2000 3000 stations measuring precipitation and 1500 2200 stations measuring temperature from 1961 to 2003 over 95 of these stations lie in the southern half of canada however the density of weather stations in this region is 1 per 2500 km2 which is quite low to represent high resolution spatial variabilities hutchinson et al 2009 report several other problems with the data such as missing or incorrect coordinates and elevation along with large temporal gaps in the measurements this gap in climate data is filled by temporally and spatially continuous models created using different interpolation techniques on existing station data or through reanalysis products despite their advantages and widespread use gridded datasets are only estimates of the truth that are required to be validated makshtas et al 2007 compared five variables sea level pressure air temperature at 2 m winds at 10 m specific humidity at 2 m and total cloudiness from ncep reanalysis 1 dataset to station observations over the north pole drifting stations for 1954 2006 they reported their results based on seasonal mean error me standard deviation std and correlation coefficient cor decker et al 2012 compared multiple gridded datasets against observations and reported ecmwf interim re analysis era interim as the best product for surface air temperature and global land data assimilation system gldas from the goddard space flight center gsfc for precipitation they used measures such as mean squared error mse root mean squared error rmse along with a performance ranking system as proposed by brunke et al 2003 the following metrics are the most widely used criteria for performance evaluation of gridded datasets me mean absolute error mae rmse mse cor parametric distributions and extreme climate indices climdex among few others balmaseda et al 2013 bao and zhang 2013 bosilovich et al 2008 henn et al 2018 janowiak et al 1998 werner et al 2019 zhang et al 2011 wong et al 2017 compared precipitation from 7 datasets ground based reanalysis statistically and dynamically downscaled products across canada using similar metrics mentioned previously several studies have been performed in other regions of the world as well such as china yin et al 2015 tibetan plateau you et al 2015 west africa lamptey 2008 iran javanmard et al 2010 among others most of these studies in canada and around the world have been limited to the univariate analysis of climate variables eum et al 2014 islam and déry 2017 werner et al 2019 and analyses based on the multivariate behaviour of climate variables are lacking a few studies have compared outputs from hydrological models forced with gridded datasets essou et al 2016 compared three gridded products over 424 basins in the continental united states they concluded that even though there were significant differences in temperature and precipitation biases the overall difference in simulated streamflow was not significant for lumped hydrological modeling raimonet et al 2017 calibrated and compared the génie rural à 4 paramètres journalier gr4j perrin et al 2003 conceptual hydrological model combined with the cemaneige snow routine over france using four temperature and precipitation datasets they concluded that high resolution datasets and reanalysis products perform better than low resolution and interpolated data respectively a global study was conducted using the variable infiltration capacity vic model by voisin et al 2008 using the 40 yr ecmwf re analysis era 40 uppala et al 2005 and the global precipitation climatology project one degree daily gpcp 1dd huffman et al 2001 the effects of topography on the performance of gridded products were assessed by yang et al 2014 they compared ncep cfsr asian precipitation highly resolved observational data integration towards evaluation aphrodite and china trend surface reanalysis data over the three gorges reservoir in china concluding that the datasets were able to perform satisfactorily only in a relatively flat basin other studies have also been conducted on bias correction of climate inputs to hydrological modeling berg et al 2003 terink et al 2010 however explored the differences between univariate and multivariate sources of bias in input data and their implications for hydrologic modeling the implications of the lack of understanding of compound events can be understood in the context of historical disasters across canada in 2017 british columbia spent almost 649 million suppressing wildfires which also lead to the evacuation of 65 000 people from the fire affected area a record 1 2 million hectares bc wildfire service 2019 in july 2018 heatwave caused over 90 deaths in quebec with temperatures consistently peaking over 35 c for over a week pelmorex weather networks inc 2018 in april 2017 the highest water levels in the last 50 years were recorded in the ottawa river basin which lead to flooding in southern quebec the flooding damaged 5371 residences and cost upwards of 228 million philips 2018 recently the 2019 spring flood in quebec proved to be even more disastrous leaving over 10 000 people homeless haines 2019 fig 1 shows some of the extreme events that can be directly attributed to the covariability of temperature and precipitation since 2015 based on canada s top 10 weather stories environment and climate change canada 2018 in this study the univariate and bivariate characteristics of temperature and precipitation from five gridded datasets are evaluated over canada the datasets include nrcanmet ncep cfsr ncep narr grasp and s14fd results are presented in the form of bias error metrics for temperature and precipitation along with bivariate evaluation results in the form of formal goodness of fit test for all datasets under the assumption of a true underlying copula represented by the observation dataset additionally a semi distributed hydrological model is forced with the respective unadjusted and univariate and multivariate bias corrected climate data to characterize the propagation of different sources of bias in input data to streamflow simulations 2 study area and data the study compares temperature and precipitation covariability from five gridded datasets over canada table 1 hydrological modelling is performed over three watersheds with distinct characteristics in western canada fig 2 the kootenay watershed is predominantly mountainous with elevation ranging from 2130 m in the south to 3700 m in northern parts most of the precipitation in the region takes place in winter and fall with the highest annual magnitude of up to 1000 mm and the lowest up to 200 mm quesnel and thiessen 1993 streamflow is dominated by snowmelt from snow deposits and glaciers at high elevations in the north causing relatively low flows in winter and peak flows in the months of may or june the comox lake watershed lies in north eastern part of vancouver island bc covering an area of 600 km2 the comox glacier is the primary source of water into the comox lake the average temperature in the summer is around 22 c and the average low temperatures rarely drop below freezing most of the 1200 mm of the average annual rainfall occurs in the fall and winter seasons resulting in dry summers and warm wet winters environment canada 2014 the coquitlam watershed covers an area of 261 km2 consisting of low level flood plain areas to mountainous areas with the lowest and highest elevation at 0 4 m and 1584 m above sea level respectively whereas summers are usually dry winters tend to be relatively wet with the average annual precipitation ranging from 1869 mm at lower elevations to 3468 mm at higher elevations falling mostly between november march mcphee 2003 the adjusted and homogenized canadian climate data ahccd is used as a reference for the evaluation of the gridded products the dataset provides the temperature at 338 locations across canada which were adjusted for multiple factors including non climatic shifts discontinuities and errors arising from a nation wide change in time observation in july 1961 vincent et al 2012 precipitation data are available at 464 locations and are adjusted for common gauge related issues like wind undercatch evaporation and wetting losses mekis and vincent 2011 discontinuities in both datasets were removed by combining data from nearby gauging locations the data were also corrected for non climatic factors like instrument changes and station relocation given the bivariate focus of the study 160 stations that provide both temperature and precipitation measurements are selected the data records are further filtered based on at least 80 data availability from 1980 01 01 to 2010 12 31 resulting in 113 stations retained for the analysis fig 2 shows the selected ahccd stations used in this study 2 1 nrcanmet nrcanmet is a gridded product based on station data from national climate data archive ncda environment and climate change canada which is available at a resolution of 30 arc second 1 12 or 10 km for 1950 2013 updated from the original time span of 1961 2003 quality controlled but not adjusted as in ahccd station data were interpolated using the australian national university splines anusplin package hutchinson et al 2009 a trivariate thin plate splines interpolation method that considers the latitude longitude and elevation of each site the dataset is often used as a source of truth and has been extensively used in hydrological studies in canada some notable examples include works done by chen et al 2011a and 2011b and wehner et al 2011 2 2 ncep climate forecast system reanalysis cfsr cfsr saha et al 2010 is a global reanalysis product available from 1979 to present at a horizontal resolution of about 35 km the product is a successor to the extensively used reanalysis 1 dataset produced jointly by national centers for environmental prediction ncep and the national center for atmospheric research ncar kalnay et al 1996 as described by saha et al 2010 the novelties of this product include a coupled ocean model an interactive sea ice model and assimilation of radiances the dataset has been used in hydrological studies as well as evaluation studies daggupati et al 2018 faramarzi et al 2015 rapaić et al 2015 2 3 global risk assessment toward stable production of food grasp the grasp dataset iizumi et al 2014 is created using two different reanalysis products era 40 uppala et al 2005 and jra 25 onogi et al 2007 it is a global dataset excluding antarctica available at a resolution of 1 125 in both dimensions from 1961 to 2010 era 40 is used to generate the new dataset from 1961 to 1978 while jra 25 is used from 1979 to 2010 before merging the two datasets to create the new product the authors match the biases of era 40 to jra 25 followed by the calculation of monthly correction factors based on the corrected era 40 dataset finally they apply the correction factors to the two reanalysis products in the respective time periods as mentioned above the data was bias corrected using cumulative distribution function based downscaling grasp was created with the objective of providing a meteorological forcing dataset for crop modelling 2 4 ncep north american regional reanalysis narr mesinger et al 2006 describe narr as long term dynamically consistent high resolution high frequency atmospheric and land surface hydrology dataset for the north american domain the dataset is available at a resolution of approximately 32 km at the lowest latitude from 1979 to present at 3 hourly intervals the product is a regional extension of the ncep global reanalysis created using the ncep eta model and the regional data assimilation system rdas several studies over canada have used narr for evaluation comparison purposes and as forcing to drive hydrological models choi et al 2009 eum et al 2014 woo and thorne 2006 2 5 s14 global meteorological forcing dataset s14fd the s14fd dataset iizumi et al 2017 is created by downscaling and bias correcting the jra 55 reanalysis available from 1958 to 2013 at a resolution of 55 km kobayashi et al 2015 jra 55 is downscaled to a resolution of 0 5 in both dimensions over the 55 year span to obtain s14fd the 2 m air temperature was corrected using the cru ts3 22 data harris et al 2014 monthly precipitation data and dry wet day frequency were corrected using gpccv7 and data provided by motaya et al 2002 respectively the proposed framework can be extended to the analysis of other climate products including merra and era interim among others 3 methods all gridded products are evaluated against the ahccd dataset by comparing the grid records with the closest ahccd station record from each gridded product one grid closest to each of the ahccd sites is chosen using a nearest neighbour algorithm mean bias error mbe is used to evaluate the temperature and precipitation separately we assess the frequency and magnitude of extreme temperature and precipitation events across each dataset in addition to the individual analysis of temperature and precipitation copulas are used to evaluate how well the gridded products mimic the dependence structure of the ground based data furthermore a hydrological model is forced with temperature and precipitation data from all six datasets to evaluate how the uncertainties from both univariate and multivariate biases propagate through the model into the simulated streamflow the hydrological model is driven under three scenarios 1 the model is forced with original data from all products 2 all gridded products are bias corrected using a univariate bias correction method and 3 the gridded products are bias corrected using a multivariate bias correction algorithm that corrects for marginal biases as well as the bias in the dependence structure the comparison across all scenarios reveals the importance of maintaining the covariability of temperature and precipitation from a hydrological perspective the following section describes the metrics used in the validation and comparison process 3 1 univariate validation metrics mean bias error mbe is used to assess the direction and magnitude of biases in temperature and precipitation respectively 1 mbe i 1 n g i o i n where o i represents the observation ahccd g i represents the gridded data and n is the total number of data records analyses are performed for each season separately i e winter djf spring mam summer jja and fall son the magnitude of extreme precipitation is compared by taking the accumulated precipitation of all days exceeding the 95th quantile of wet days pr 1 mm within each year and then averaging it across the 31 year period this approach is similar to the definition of r95p annual total precipitation when rr 95th percentile by the expert team on climate change detection and indices etccdi which is part of the extreme climate indices zhang et al 2011 the magnitude of extreme temperature is analysed by comparing the annual average of 95th quantiles of daily temperature across all datasets to evaluate the frequency of extremes in each dataset we followed the approach proposed by papalexiou and montanari 2019 the method involves extracting n highest precipitation extremes from a data record of n years a discrete data series is then created by counting the number of extremes that occurred within each year this method results in a frequency series of length n where some years have multiple extremes and some years may have none the frequency series corresponding to gridded datasets are compared to the one from ahccd using pearson correlation coefficient this method is applied to both temperature and precipitation extremes in this study 3 2 bivariate validation copulas stem from sklar s theorem sklar 1959 which states that the joint cumulative density function cdf of two continuous random variables x and y can be written as 2 h x y c f x g y where h x y is the cdf of the bivariate distribution of the marginals x and y and f x and g y are the respective univariate cdfs c is a copula function that binds the two marginal cdfs copulas provide a flexible approach to model the dependence structure of two or more variables the primary strength of the method is that each variable can have its own independent form i e distribution and yet they can still be bound together into a multivariate structure using copulas given that temperature and precipitation come from different populations mostly normal and gamma distributions respectively this method proves useful in characterizing their dependence structure copulas are used for comparing the full dependence structure instead of other measures such as correlation coefficients this provides a robust assessment of the dependence between precipitation and temperature since two pairs of data with similar correlation might exhibit different dependence structure especially in their tails or extreme values embrechts et al 2002 in this study we use the archimedean family of copulas which are the most widely used class of copulas in hydrological studies grimaldi and serinaldi 2006 zhang and singh 2006 this family of copulas consist of clayton frank joe and gumbel copula the copula model selection for each site is performed based on the akaike information criterion aic akaike 1974 aic stems from the field of information theory given two candidate models and one true unknown model aic attempts to minimize the kullback leibler divergence kullback and leibler 1951 of the candidate model to the true model thus in turn minimizing the information loss when the candidate model is used instead of the true model burnham and anderson 2003 the model that leads to the least loss of information i e lowest aic score is selected aic is calculated by taking into consideration the residual sum of squares rss and the number of parameters of the copula function as a penalising factor 3 aic n log rss n 2 p where n is the number of samples and p is the number of copula parameters the fitted model is further evaluated using a formal goodness of fit test for copulas proposed by genest et al 2006 the goodness of fit gof test is based on calculating two variants of the cramér von mises statistic genest and favre 2007 4 s n 0 1 k n t 2 k θ n t d t 5 t n 0 t 1 sup k n t where k n t n k n t k θ n t kn and kθn refer to the empirical distribution of the data and the distribution of the samples taken from the theoretical copula respectively the p values of the respective statistics are calculated using a bootstrapping procedure of wang wells 2000 which involves creating a distribution of s n and t n by repeated sampling from the copula according to genest and rémillard 2008 under the assumption of a large number of iterations and the null hypothesis h 0 c c where c is the empirical copula and c is a parametric family of copula the population of the statistics should converge to mutually independent and identically distributed random variables deviation from this behavior leads to rejection of the null hypothesis thus stating that the empirical copula under consideration does not follow the parametric family of copula to identify whether a particular dataset captures the true dependence between temperature and precipitation we perform the following procedure using aic and gof test a parametric copula c p from the archimedean family of copulas is fitted to the reference data ahccd it is assumed that the copula c p represents true dependence structure between temperature and precipitation because the observed data are indeed considered the ground truth then the fit of the selected copula is tested on the other datasets and a p value is calculated based on the null hypothesis h 0 c c p where c is the empirical copula of the gridded dataset under evaluation based on a 5 significance level the gridded dataset at a particular location is assigned a binary value of 1 success if the null hypothesis is accepted i e the gridded dataset is able to capture the true dependence structure or 0 failure if the null hypothesis is rejected 3 3 propagation of univariate and bivariate climate biases to hydrological simulations the covariability between climate variables can have important implications for extreme events such as rain on snow multivariate droughts hao and aghakouchak 2014 and fire weather indices vicente serrano et al 2010 among others evidence for the variability and trends of compound events such as extreme warm wet or extreme warm dry periods might be misrepresented if the data does not capture such behaviour in this study we use the raven hydrological model craig 2019 to explore how the univariate and multivariate biases can affect model outputs i e streamflow and quantify the corresponding uncertainties over the kootenay comox and coquitlam watersheds in western canada 3 4 raven hydrological framework raven is a flexible hydrological modeling framework that allows for the development of lumped and semi distributed models some of the features of raven include discretization of land into hydrological response units hrus and flexibility of using empirical models or physical systems to represent hydrological processes shafii 2017 raven is capable of emulating a number of hydrologic models including the ubc watershed model ubcwm quick 1995 environment canada s hbv model bergstrom 1995 and hmets martel et al 2017 among others in this study the ubcwm emulation setup by bc hydro is adopted in all three watersheds the hydrological model is used as a framework to characterize the propagation of biases in climate inputs to streamflow simulations to assess the effectiveness of the univariate and multivariate bias correction methods and avoid the influence of model parameterization we consider the streamflow simulations generated using the ahccd input data as the truth temperature and precipitation from gridded products which are bias corrected based on ahccd are then used to drive the same model structure with similar parameterization the resulting simulations are compared considering the ahccd driven model output as the baseline the qdm and mbc corrected data are expected to show similar univariate distributions for temperature and precipitation because the mbc method uses qdm to bias correct the marginal distributions the difference between the two approaches is in adjusting the bivariate structure of the data which has important implications for hydrological simulations for example the total precipitation provided as an input to the raven hydrologic model is partitioned into rain and snow based on the corresponding temperature using the following linear transition approach craig 2019 6 α s 0 5 t trans t ave δ t where α s is the snow fraction t ave is the average daily temperature t trans and δ t are global parameters defined within the model structure t trans 1 0 δ t 2 0 α s is further used to calculate rainfall r from total precipitation p using r 1 α s p and snowfall s using s α s p eq 6 is only used when the temperature ranges between t trans δ t 2 to t trans δ t 2 when the average daily temperature is outside this range total precipitation is considered as all snow or all rain accordingly changes in the co occurrence of precipitation and temperature can affect the precipitation regime snowpack snowmelt rain on snow processes among others gridded records corresponding to each dataset that fall within each watershed are spatially averaged to create a single 31 year time series of temperature and precipitation then the hydrologic models are forced with all six datasets ahccd and five gridded products and the simulated streamflow is compared using annual hydrographs and the modified kling gupta efficiency kling et al 2012 a performance metric proposed in an earlier study by gupta et al 2009 7 k g e 1 r 1 2 β 1 2 γ 1 2 kge combines the pearson correlation coefficient r the bias ratio β and the variability ratio γ into one quantifiable value that ranges from to 1 with 1 being the ideal score finally to validate the frequency of extreme flows probability of detection pod of extreme flows is calculated to calculate pod a particular day is identified in the observed flow time series when an extreme event happens i e q 95th percentile then we check whether the corresponding simulated streamflow also exceeds its 95th percentile or not the principal being whether simulated streamflow is able to capture the occurrence of a high flow irrespective of bias in its magnitude we classify the input data bias into two categories univariate bias that represents the biases in temperature and precipitation individually and the multivariate bias that is the bias in their dependence structure first the gridded products are bias corrected using the quantile delta mapping qdm a univariate bias correction method cannon et al 2015 next the gridded products are bias corrected using the multivariate bias correction method mbc proposed by cannon 2016 the qdm bias correction approach preserves relative changes in quantiles of the variable being corrected the approach builds upon previous approaches such as quantile mapping qm and detrended quantile mapping dqm cannon et al 2015 show how their approach accounts for relative changes in all modeled quantiles where earlier approaches i e dqm only accounts for relative changes in the modeled mean the mbc approach is a further development of the qdm bias correction method combined with a multivariate linear bias correction algorithm proposed by bürger et al 2011 while qdm only corrects for univariate biases the multivariate bias correction algorithm corrects the multivariate structure but not the univariate structure unless it is strictly multivariate gaussian mbc combines the two methods using an iterative process correcting both univariate and preserving the dependence structure at the same time the mbc algorithm has two variants mbcp which relies on the pearson correlation coefficient and mbcr which relies on the spearman rank correlation coefficient in this study mbcr is used for bias correction of temperature and precipitation since the bivariate structure of the two variables is not necessarily gaussian therefore rank correlation is the ideal choice to represent their dependence consequently three scenarios of simulated streamflow are considered based on the gridded product inputs fig 3 streamflow generated using original gridded products q o streamflow generated after univariate bias correction of gridded products q u and streamflow generated after multivariate bias correction of gridded products q m this allows for investigating the propagation of biases in both univariate and multivariate structure of the input data into hydrological model predictions 4 results and discussion 4 1 univariate analysis majority of the 113 locations have cold biases across all products in all seasons fig 4 the magnitude of the cold bias is maximum in winter at 10 c as an outlier on the eastern coast if the outlier is excluded then all seasons show a similar pattern where maximum cold biases around 8 c occur over the rockies in the west whereas maximum warm biases around 5 c occur over the canadian prairies there are significant spatial similarities among the datasets in terms of where warm and cold biases are observed all products have the highest accuracy in southeastern canada southern ontario in capturing temperature with the region having the lowest bias on average on average both ncep products cfsr and narr have the highest warm and cold biases across seasons with narr being predominantly warmer in all seasons except winter nrcanmet and s14fd have very similar biases in each case but nrcanmet on the whole performs better than every other dataset similar patterns are observed for precipitation biases as well fig 5 nrcanmet and s14fd tend to be the most accurate products across all seasons however s14fd proves marginally better than nrcanmet on average grasp has some extreme outliers in all seasons except summer with biases reaching over 4 mm day in winter and spring and 6 mm day in fall observed at a couple of location on the western coast in all seasons ncep products display opposite behavior to each other with cfsr predominantly wet and narr predominantly dry maximum wet biases in cfsr are observed over the western mountains while maximum dry biases in narr are observed over the canadian prairies and southern ontario the 95th quantile of temperature t95 is underestimated by all gridded datasets fig 6 a with narr being the closest to the observation and grasp being the farthest nrcanmet and s14fd again exhibit very similar results with the average t95 at just over 20 c while grasp estimates the average t95 across the 113 locations at 19 1 c regarding the frequency of temperature extremes nrcanmet has the highest correlation with the observed dataset with 47 locations having correlations above 0 8 while for all other products the number of sites is below 15 with the lowest in narr the magnitude of extreme precipitation is best captured by narr followed by nrcanmet and s14fd fig 6b it is evident from the results that the biases observed in daily time step in precipitation do not play a large role in extremes the consistent wet bias in cfsr and dry bias in narr is not evident in r95p in fact cfsr slightly underestimates the annual sum of extreme precipitation grasp shows a very narrow distribution of extremes across all sites with a few outliers at both ends regarding the frequency of extreme precipitation events nrcanmet outperforms other products followed by s14fd but the overall value of correlation is much lower than observed for temperature extremes only one site across all products shows a correlation above 0 8 while 50 of locations across all products show correlations of less than 0 5 indicating that even though the magnitude of extreme events might be captured satisfactorily their temporal occurrence is not according to the univariate analyses nrcanmet and s14fd can represent temperature and precipitation better than other gridded datasets with nrcanmet performing marginally better for temperature and s14fd marginally better for precipitation the ability of nrcanmet to capture both temperature and precipitation better can be associated with the direct interpolation of 3000 ground based stations across canada while taking elevation into account this makes the dataset much closer to the ground truth as compared to the other four reanalysis products and thus are more dependent on the modeling framework and data assimilation processes undertaken in their development 4 2 bivariate analysis across all gridded products and four seasons the number of sites that match the dependence of ground based observation data is below 50 except for s14fd in winter at 67 sites fig 7 there is hardly any homogeneity between the datasets in different seasons and the number of common sites across all products where dependence is captured or not captured is less than 15 these sites are located in the southwest southern ontario and east of the rockies all datasets struggle the most in capturing dependence between temperature and precipitation in spring the following are some of the significant dependence features of the ground based data that gridded products do not capture well 1 the observed data shows significant dependency between warm and wet events upper tail in spring in the north and southwestern regions of canada windward side of the rockies which the gridded datasets fail to capture 2 the observed data shows significant dependency between hot and dry events in the prairies in both spring and summer which the gridded datasets do not capture these dependencies have important hydrologic implications the northern regions of canada have warmed by over 2 3 c according to canada s changing climate report released by environment and climate change canada which is almost 4 times the global average bush lemmen 2019 the positive dependence between temperature and precipitation in the north indicates that the region can get wetter as it gets warmer something that the gridded products fail to capture in addition the western coast of canada is impacted by numerous snowmelt and rain on snow floods in late spring and early winter when precipitation occurs on unusually warm days with snow on the ground the positive dependence implies that with temperature increases the amount of precipitation is expected to rise which can further worsen these conditions tencer et al 2014 gridded datasets however fail to capture such warm wet dependency in southwest canada further the prairies has experienced dramatic droughts amounting to billions of dollars in damages garnett 2002 the strong overall negative dependence between temperature and precipitation suggests that as the area gets hotter it can get drier thus exacerbating the occurrence and severity of droughts aghakouchak et al 2014 zscheischler and seneviratne 2017 this phenomenon is not captured well by gridded datasets which can lead to an underestimation of the risks associated with these extreme events while nrcanmet characterizes the univariate behaviour of temperature and precipitation relatively well results suggest that it does not represent the dependency any better than the other datasets this brings into question the use of nrcanmet as observation in numerous hydrologic applications and in bias correction of other products such as global climate models there is a growing interest in developing multivariate bias correction methods which correct the dependence between variables along with their univariate characteristics however as shown in this study this true dataset may not be capable of capturing the dependence structure correctly which can undermine the accuracy of bias corrected products and further inferences drawn from them 4 3 hydrological model assessments we compare the simulated streamflow across different scenarios for each watershed to quantify improvements in model accuracy associated with the univariate and multivariate bias correction of the input data to better understand the differences we scrutinize the co occurrence of temperature and precipitation and the corresponding precipitation regime in the hydrological model 4 4 partitioning of total precipitation as expected the distributions of univariate temperature and precipitation from both mbcr and qdm corrections are identical fig 8 the effect of multivariate bias correction only becomes apparent when the input data is discretized into precipitation occurring above and below a certain threshold as described in section 3 3 table 2 shows the average annual precipitation falling below 0 c corresponding to t trans δ t 2 in section 3 3 indicating that precipitation falls as snow and above 2 c corresponding to t trans δ t 2 indicating that precipitation falls as rain for unadjusted and bias corrected gridded datasets compared to the ahccd observation at kootenay comox and coquitlam watersheds there are significant differences in the partitioning of total precipitation between qdm and mbcr data even though the underlying univariate distributions are identical 4 5 comparison of simulated streamflow as discussed previously hydrological models are not calibrated to the individual datasets as the focus is not on how well they perform with respect to their original inputs we investigate differences between the qdm and mbcr input scenarios to quantify the added benefits of correcting the bivariate structure of the input data fig 9 shows the comparison of annual streamflow from october 1990 to september 1991 for qdm and mbcr input scenarios across the study regions in all three watersheds the seasonality of streamflow i e peak flows occurring in kootenay and comox watersheds in spring and in coquitlam in late winter are captured in both scenarios further the influence of hot and dry conditions in the summer are also evident in all datasets showing the occurrence of low flows during late summer smaller differences are evident however using the kge metric for this particular year where in almost all datasets marginal improvements are seen for the mbcr inputs further the overall kge metric across 31 years also shows that in all cases except for narr in winter kge of mbcr driven model output improves over the qdm driven output fig 10 the highest kge values between multiple datasets correspond to nrcanmet followed by narr the superiority of nrcanmet again hints towards the elevation based interpolation conducted over a vast array of station records which makes it more robust as compared to the other datasets the largest differences between qdm and mbcr are observed in the pod of extreme flows fig 11 in most cases the pod values corresponding to mbcr are approximately double the ones from the qdm scenario these differences highlight the importance of maintaining the dependence structure of temperature and precipitation input datasets for hydrological modelling particularly in forecasting extremes while extreme flows are directly related to high precipitation rates the effects of temperature and the co occurrence of the two variables are also significant especially in high elevation areas this study characterizes the propagation of biases in the dependence structure of these input variables that can result in the misrepresentation of critical conditions such as warm and wet events and subsequent high flows 5 conclusions the goal of the study is to evaluate the performance of gridded products in representing the covariability between temperature and precipitation over canada with the point of view of using these datasets for identifying and modelling compound events five gridded datasets are compared with ground based observations considering both univariate and bivariate behaviours the analysis is performed using daily temperature and precipitation data spanning over 31 years 1980 2010 at 113 station locations the overall characteristics of temperature and precipitation of each gridded dataset are assessed using mbe in addition the corresponding frequency and magnitude of extreme precipitation are compared to the observed extremes the bivariate performance is evaluated based on a formal goodness of fit test for copulas that verifies how well the gridded datasets represent the dependence between temperature and precipitation with respect to the dependence structure of the ground based observation to demonstrate the importance of bivariate bias correction a semi distributed hydrological model is forced with three sets of input data for three watersheds with distinct characteristics in western canada the input scenarios include the original datasets unadjusted data bias corrected using qdm a univariate bias correction method and input data bias corrected using mbcr a multivariate bias correction method the hydrographs of the three sets of streamflow scenarios are then compared and the overall performance of the models are evaluated using kge and probability of detection pod of extremes the minimum and maximum temperature biases across all gridded products are 7 9 c in fall excluding the outlier to 7 6 c in winter cold bias exists at the majority of the 113 locations for all datasets the bias is strongest over western rockies where all gridded products show colder conditions than ground based observation while warm bias is strongest over the prairies overall nrcanmet shows the closest temperature variability compared with the ground based observation one of the strengths of nrcanmet is its use of elevation as a predictor in thin plate spline interpolation however no clear relation is found between the observed bias and station elevations the minimum and maximum biases for precipitation across all datasets are 3 8 mm day to 6 2 mm day in fall in all datasets sites with high wet biases are located on the windward side of the rocky mountains whereas the location of sites with dry biases varies between each dataset there are significant biases in nrcanmet in several locations however along with s14fd it outperforms the other products in representing precipitation the performance of the gridded products in representing the dependence structures is evaluated using copulas the results show that in almost all cases across seasons and datasets the correct dependence structure is identified at less than 50 of the sites critical bivariate characteristics such as the upper tail dependencies between temperature and precipitation warm wet conditions in the north and southwest regions of canada are not captured by gridded datasets which has important implications for water availability and flood risk especially in southwestern canada najafi and moradkhani 2014 najafi et al 2017a najafi et al 2017b similarly hot dry dependencies in the prairies are not represented in gridded datasets which can lead to drought underestimations in this region notably the capability of nrcanmet to capture the individual characteristics of temperature and precipitation does not transfer over to the bivariate behaviour using a hydrological model we showed how the biases in individual precipitation and temperature variability and their dependence structure propagates into streamflow simulations there are significant differences between the bivariate structure of data adjusted by the mbcr approach as compared to the ones bias corrected by qdm even though the underlying univariate distributions remain identical the partitioning of total precipitation into rain and snow is significantly more accurate in mbcr compared to qdm with respect to the observed ahccd data these differences are further highlighted in streamflow simulations where mbcr improves upon qdm inputs in almost all cases while marginal improvements are noticed in the overall kge metric the greatest change is observed in the probability of detection of extreme flows this can be directly attributed to the underlying bivariate structure since extreme flows are affected by precipitation temperature and their covariability especially in mountainous regions such as the three watersheds considered in this study in the future the proposed evaluation framework can be extended to characterize the propagation of dependence biases at large scales this study calls for a deeper analysis of existing datasets to verify their capabilities to characterize compound events without this verification inferences based on such datasets particularly in the multivariate conditions are unreliable as the uncertainty increases with the addition of data and the covariability between different factors credit authorship contribution statement harsimrenjit singh conceptualization methodology software writing original draft mohammad reza najafi conceptualization methodology writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the raven hydrological model was setup by bc hydro for the three watersheds we thank georg jost for providing access to this model this project was funded by an nserc discovery grant 
5632,this study evaluates the univariate and bivariate characteristics of five gridded products with respect to the adjusted and homogenized canadian climate data for 1980 2010 spatial variations of temperature and precipitation biases including the ones corresponding to the magnitude and frequency of extremes are assessed over canada the dependence structure between the two variables is analysed across each dataset using a goodness of fit test based on copulas the propagation of univariate and bivariate biases into streamflow simulations is then investigated by driving a semi distributed hydrological model for three watersheds with distinct characteristics in western canada the input data include original unadjusted and bias corrected climate data based on the univariate quantile delta mapping and multivariate bias correction approaches the univariate analyses show that all datasets have relatively significant cold and wet biases to the west of the rocky mountains and hot and dry biases over the prairies bivariate evaluations using copulas show that all products fail to capture the dependence structure between temperature and precipitation at the majority of the locations which can undermine their suitability for compound event assessments the differences between univariate and multivariate bias correction approaches are highlighted by the significant differences in the interrelationships between precipitation and temperature hydrological modelling results show major improvements in the detection of extremes after correcting the bivariate biases of the input datasets keywords gridded climate datasets bivariate comparison compound events multivariate bias correction hydrological modelling precipitation temperature 1 introduction extreme weather events commonly occur because of the interactions between temperature and precipitation for example precipitation on an unusually warm winter day will likely increase the chances of flooding in snow packed regions similarly extended periods of low precipitation along with high temperatures in the summer give rise to heatwaves droughts and wildfires according to the intergovernmental panel on climate change ipcc special report seneviratne et al 2012 compound events can be defined as two or more extreme events occurring simultaneously or successively or combinations of events that are not themselves extremes but lead to an extreme event or impact when combined the increasing frequency of extremes and their catastrophic effects on human life and infrastructure have resulted in peaked interest in identification prediction and mitigation of compound events highlighting shortcomings of the definition of compound events in the ipcc report leonard et al 2014 proposed a more general definition a compound event is an extreme impact that depends on multiple statistically dependent variables or events and laid out a framework for analysing modeling and communicating the risks associated with such events whereas earlier most studies performed univariate analysis of extremes the focus has now shifted towards multivariate analyses considering the joint behaviour of multiple factors this has been made possible by advances in modeling tools and methodologies for studying multivariate data such as copulas introduced by sklar 1959 copulas are a set of functions that can bind individual marginals with their dependence structure to create multivariate distributions which allow for easy interpretation of joint return periods and exceedance probabilities singh et al 2019 the efficacy of applying copulas to meteorology and climate research was presented by schoelzel and friederichs 2008 aghakouchak et al 2014 used copulas to show that univariate methods underestimate or overestimate drought return periods as compared to the bivariate study of temperature and precipitation zscheischler and seneviratne 2017 analysed joint quantiles of temperature and precipitation and reported that the likelihood of a hot and dry summer in russia increased by a factor of 5 when both variables were considered as compared to their individual analysis although advances have been made in tools to analyse multivariate data for example the development of the multivariate copula analysis toolbox by sadegh et al 2017 the availability and reliability of climate data is still a limiting factor hutchinson et al 2009 provide extensive details about the availability of station data in canada obtained from the national climate data archive ncda they report the presence of 2000 3000 stations measuring precipitation and 1500 2200 stations measuring temperature from 1961 to 2003 over 95 of these stations lie in the southern half of canada however the density of weather stations in this region is 1 per 2500 km2 which is quite low to represent high resolution spatial variabilities hutchinson et al 2009 report several other problems with the data such as missing or incorrect coordinates and elevation along with large temporal gaps in the measurements this gap in climate data is filled by temporally and spatially continuous models created using different interpolation techniques on existing station data or through reanalysis products despite their advantages and widespread use gridded datasets are only estimates of the truth that are required to be validated makshtas et al 2007 compared five variables sea level pressure air temperature at 2 m winds at 10 m specific humidity at 2 m and total cloudiness from ncep reanalysis 1 dataset to station observations over the north pole drifting stations for 1954 2006 they reported their results based on seasonal mean error me standard deviation std and correlation coefficient cor decker et al 2012 compared multiple gridded datasets against observations and reported ecmwf interim re analysis era interim as the best product for surface air temperature and global land data assimilation system gldas from the goddard space flight center gsfc for precipitation they used measures such as mean squared error mse root mean squared error rmse along with a performance ranking system as proposed by brunke et al 2003 the following metrics are the most widely used criteria for performance evaluation of gridded datasets me mean absolute error mae rmse mse cor parametric distributions and extreme climate indices climdex among few others balmaseda et al 2013 bao and zhang 2013 bosilovich et al 2008 henn et al 2018 janowiak et al 1998 werner et al 2019 zhang et al 2011 wong et al 2017 compared precipitation from 7 datasets ground based reanalysis statistically and dynamically downscaled products across canada using similar metrics mentioned previously several studies have been performed in other regions of the world as well such as china yin et al 2015 tibetan plateau you et al 2015 west africa lamptey 2008 iran javanmard et al 2010 among others most of these studies in canada and around the world have been limited to the univariate analysis of climate variables eum et al 2014 islam and déry 2017 werner et al 2019 and analyses based on the multivariate behaviour of climate variables are lacking a few studies have compared outputs from hydrological models forced with gridded datasets essou et al 2016 compared three gridded products over 424 basins in the continental united states they concluded that even though there were significant differences in temperature and precipitation biases the overall difference in simulated streamflow was not significant for lumped hydrological modeling raimonet et al 2017 calibrated and compared the génie rural à 4 paramètres journalier gr4j perrin et al 2003 conceptual hydrological model combined with the cemaneige snow routine over france using four temperature and precipitation datasets they concluded that high resolution datasets and reanalysis products perform better than low resolution and interpolated data respectively a global study was conducted using the variable infiltration capacity vic model by voisin et al 2008 using the 40 yr ecmwf re analysis era 40 uppala et al 2005 and the global precipitation climatology project one degree daily gpcp 1dd huffman et al 2001 the effects of topography on the performance of gridded products were assessed by yang et al 2014 they compared ncep cfsr asian precipitation highly resolved observational data integration towards evaluation aphrodite and china trend surface reanalysis data over the three gorges reservoir in china concluding that the datasets were able to perform satisfactorily only in a relatively flat basin other studies have also been conducted on bias correction of climate inputs to hydrological modeling berg et al 2003 terink et al 2010 however explored the differences between univariate and multivariate sources of bias in input data and their implications for hydrologic modeling the implications of the lack of understanding of compound events can be understood in the context of historical disasters across canada in 2017 british columbia spent almost 649 million suppressing wildfires which also lead to the evacuation of 65 000 people from the fire affected area a record 1 2 million hectares bc wildfire service 2019 in july 2018 heatwave caused over 90 deaths in quebec with temperatures consistently peaking over 35 c for over a week pelmorex weather networks inc 2018 in april 2017 the highest water levels in the last 50 years were recorded in the ottawa river basin which lead to flooding in southern quebec the flooding damaged 5371 residences and cost upwards of 228 million philips 2018 recently the 2019 spring flood in quebec proved to be even more disastrous leaving over 10 000 people homeless haines 2019 fig 1 shows some of the extreme events that can be directly attributed to the covariability of temperature and precipitation since 2015 based on canada s top 10 weather stories environment and climate change canada 2018 in this study the univariate and bivariate characteristics of temperature and precipitation from five gridded datasets are evaluated over canada the datasets include nrcanmet ncep cfsr ncep narr grasp and s14fd results are presented in the form of bias error metrics for temperature and precipitation along with bivariate evaluation results in the form of formal goodness of fit test for all datasets under the assumption of a true underlying copula represented by the observation dataset additionally a semi distributed hydrological model is forced with the respective unadjusted and univariate and multivariate bias corrected climate data to characterize the propagation of different sources of bias in input data to streamflow simulations 2 study area and data the study compares temperature and precipitation covariability from five gridded datasets over canada table 1 hydrological modelling is performed over three watersheds with distinct characteristics in western canada fig 2 the kootenay watershed is predominantly mountainous with elevation ranging from 2130 m in the south to 3700 m in northern parts most of the precipitation in the region takes place in winter and fall with the highest annual magnitude of up to 1000 mm and the lowest up to 200 mm quesnel and thiessen 1993 streamflow is dominated by snowmelt from snow deposits and glaciers at high elevations in the north causing relatively low flows in winter and peak flows in the months of may or june the comox lake watershed lies in north eastern part of vancouver island bc covering an area of 600 km2 the comox glacier is the primary source of water into the comox lake the average temperature in the summer is around 22 c and the average low temperatures rarely drop below freezing most of the 1200 mm of the average annual rainfall occurs in the fall and winter seasons resulting in dry summers and warm wet winters environment canada 2014 the coquitlam watershed covers an area of 261 km2 consisting of low level flood plain areas to mountainous areas with the lowest and highest elevation at 0 4 m and 1584 m above sea level respectively whereas summers are usually dry winters tend to be relatively wet with the average annual precipitation ranging from 1869 mm at lower elevations to 3468 mm at higher elevations falling mostly between november march mcphee 2003 the adjusted and homogenized canadian climate data ahccd is used as a reference for the evaluation of the gridded products the dataset provides the temperature at 338 locations across canada which were adjusted for multiple factors including non climatic shifts discontinuities and errors arising from a nation wide change in time observation in july 1961 vincent et al 2012 precipitation data are available at 464 locations and are adjusted for common gauge related issues like wind undercatch evaporation and wetting losses mekis and vincent 2011 discontinuities in both datasets were removed by combining data from nearby gauging locations the data were also corrected for non climatic factors like instrument changes and station relocation given the bivariate focus of the study 160 stations that provide both temperature and precipitation measurements are selected the data records are further filtered based on at least 80 data availability from 1980 01 01 to 2010 12 31 resulting in 113 stations retained for the analysis fig 2 shows the selected ahccd stations used in this study 2 1 nrcanmet nrcanmet is a gridded product based on station data from national climate data archive ncda environment and climate change canada which is available at a resolution of 30 arc second 1 12 or 10 km for 1950 2013 updated from the original time span of 1961 2003 quality controlled but not adjusted as in ahccd station data were interpolated using the australian national university splines anusplin package hutchinson et al 2009 a trivariate thin plate splines interpolation method that considers the latitude longitude and elevation of each site the dataset is often used as a source of truth and has been extensively used in hydrological studies in canada some notable examples include works done by chen et al 2011a and 2011b and wehner et al 2011 2 2 ncep climate forecast system reanalysis cfsr cfsr saha et al 2010 is a global reanalysis product available from 1979 to present at a horizontal resolution of about 35 km the product is a successor to the extensively used reanalysis 1 dataset produced jointly by national centers for environmental prediction ncep and the national center for atmospheric research ncar kalnay et al 1996 as described by saha et al 2010 the novelties of this product include a coupled ocean model an interactive sea ice model and assimilation of radiances the dataset has been used in hydrological studies as well as evaluation studies daggupati et al 2018 faramarzi et al 2015 rapaić et al 2015 2 3 global risk assessment toward stable production of food grasp the grasp dataset iizumi et al 2014 is created using two different reanalysis products era 40 uppala et al 2005 and jra 25 onogi et al 2007 it is a global dataset excluding antarctica available at a resolution of 1 125 in both dimensions from 1961 to 2010 era 40 is used to generate the new dataset from 1961 to 1978 while jra 25 is used from 1979 to 2010 before merging the two datasets to create the new product the authors match the biases of era 40 to jra 25 followed by the calculation of monthly correction factors based on the corrected era 40 dataset finally they apply the correction factors to the two reanalysis products in the respective time periods as mentioned above the data was bias corrected using cumulative distribution function based downscaling grasp was created with the objective of providing a meteorological forcing dataset for crop modelling 2 4 ncep north american regional reanalysis narr mesinger et al 2006 describe narr as long term dynamically consistent high resolution high frequency atmospheric and land surface hydrology dataset for the north american domain the dataset is available at a resolution of approximately 32 km at the lowest latitude from 1979 to present at 3 hourly intervals the product is a regional extension of the ncep global reanalysis created using the ncep eta model and the regional data assimilation system rdas several studies over canada have used narr for evaluation comparison purposes and as forcing to drive hydrological models choi et al 2009 eum et al 2014 woo and thorne 2006 2 5 s14 global meteorological forcing dataset s14fd the s14fd dataset iizumi et al 2017 is created by downscaling and bias correcting the jra 55 reanalysis available from 1958 to 2013 at a resolution of 55 km kobayashi et al 2015 jra 55 is downscaled to a resolution of 0 5 in both dimensions over the 55 year span to obtain s14fd the 2 m air temperature was corrected using the cru ts3 22 data harris et al 2014 monthly precipitation data and dry wet day frequency were corrected using gpccv7 and data provided by motaya et al 2002 respectively the proposed framework can be extended to the analysis of other climate products including merra and era interim among others 3 methods all gridded products are evaluated against the ahccd dataset by comparing the grid records with the closest ahccd station record from each gridded product one grid closest to each of the ahccd sites is chosen using a nearest neighbour algorithm mean bias error mbe is used to evaluate the temperature and precipitation separately we assess the frequency and magnitude of extreme temperature and precipitation events across each dataset in addition to the individual analysis of temperature and precipitation copulas are used to evaluate how well the gridded products mimic the dependence structure of the ground based data furthermore a hydrological model is forced with temperature and precipitation data from all six datasets to evaluate how the uncertainties from both univariate and multivariate biases propagate through the model into the simulated streamflow the hydrological model is driven under three scenarios 1 the model is forced with original data from all products 2 all gridded products are bias corrected using a univariate bias correction method and 3 the gridded products are bias corrected using a multivariate bias correction algorithm that corrects for marginal biases as well as the bias in the dependence structure the comparison across all scenarios reveals the importance of maintaining the covariability of temperature and precipitation from a hydrological perspective the following section describes the metrics used in the validation and comparison process 3 1 univariate validation metrics mean bias error mbe is used to assess the direction and magnitude of biases in temperature and precipitation respectively 1 mbe i 1 n g i o i n where o i represents the observation ahccd g i represents the gridded data and n is the total number of data records analyses are performed for each season separately i e winter djf spring mam summer jja and fall son the magnitude of extreme precipitation is compared by taking the accumulated precipitation of all days exceeding the 95th quantile of wet days pr 1 mm within each year and then averaging it across the 31 year period this approach is similar to the definition of r95p annual total precipitation when rr 95th percentile by the expert team on climate change detection and indices etccdi which is part of the extreme climate indices zhang et al 2011 the magnitude of extreme temperature is analysed by comparing the annual average of 95th quantiles of daily temperature across all datasets to evaluate the frequency of extremes in each dataset we followed the approach proposed by papalexiou and montanari 2019 the method involves extracting n highest precipitation extremes from a data record of n years a discrete data series is then created by counting the number of extremes that occurred within each year this method results in a frequency series of length n where some years have multiple extremes and some years may have none the frequency series corresponding to gridded datasets are compared to the one from ahccd using pearson correlation coefficient this method is applied to both temperature and precipitation extremes in this study 3 2 bivariate validation copulas stem from sklar s theorem sklar 1959 which states that the joint cumulative density function cdf of two continuous random variables x and y can be written as 2 h x y c f x g y where h x y is the cdf of the bivariate distribution of the marginals x and y and f x and g y are the respective univariate cdfs c is a copula function that binds the two marginal cdfs copulas provide a flexible approach to model the dependence structure of two or more variables the primary strength of the method is that each variable can have its own independent form i e distribution and yet they can still be bound together into a multivariate structure using copulas given that temperature and precipitation come from different populations mostly normal and gamma distributions respectively this method proves useful in characterizing their dependence structure copulas are used for comparing the full dependence structure instead of other measures such as correlation coefficients this provides a robust assessment of the dependence between precipitation and temperature since two pairs of data with similar correlation might exhibit different dependence structure especially in their tails or extreme values embrechts et al 2002 in this study we use the archimedean family of copulas which are the most widely used class of copulas in hydrological studies grimaldi and serinaldi 2006 zhang and singh 2006 this family of copulas consist of clayton frank joe and gumbel copula the copula model selection for each site is performed based on the akaike information criterion aic akaike 1974 aic stems from the field of information theory given two candidate models and one true unknown model aic attempts to minimize the kullback leibler divergence kullback and leibler 1951 of the candidate model to the true model thus in turn minimizing the information loss when the candidate model is used instead of the true model burnham and anderson 2003 the model that leads to the least loss of information i e lowest aic score is selected aic is calculated by taking into consideration the residual sum of squares rss and the number of parameters of the copula function as a penalising factor 3 aic n log rss n 2 p where n is the number of samples and p is the number of copula parameters the fitted model is further evaluated using a formal goodness of fit test for copulas proposed by genest et al 2006 the goodness of fit gof test is based on calculating two variants of the cramér von mises statistic genest and favre 2007 4 s n 0 1 k n t 2 k θ n t d t 5 t n 0 t 1 sup k n t where k n t n k n t k θ n t kn and kθn refer to the empirical distribution of the data and the distribution of the samples taken from the theoretical copula respectively the p values of the respective statistics are calculated using a bootstrapping procedure of wang wells 2000 which involves creating a distribution of s n and t n by repeated sampling from the copula according to genest and rémillard 2008 under the assumption of a large number of iterations and the null hypothesis h 0 c c where c is the empirical copula and c is a parametric family of copula the population of the statistics should converge to mutually independent and identically distributed random variables deviation from this behavior leads to rejection of the null hypothesis thus stating that the empirical copula under consideration does not follow the parametric family of copula to identify whether a particular dataset captures the true dependence between temperature and precipitation we perform the following procedure using aic and gof test a parametric copula c p from the archimedean family of copulas is fitted to the reference data ahccd it is assumed that the copula c p represents true dependence structure between temperature and precipitation because the observed data are indeed considered the ground truth then the fit of the selected copula is tested on the other datasets and a p value is calculated based on the null hypothesis h 0 c c p where c is the empirical copula of the gridded dataset under evaluation based on a 5 significance level the gridded dataset at a particular location is assigned a binary value of 1 success if the null hypothesis is accepted i e the gridded dataset is able to capture the true dependence structure or 0 failure if the null hypothesis is rejected 3 3 propagation of univariate and bivariate climate biases to hydrological simulations the covariability between climate variables can have important implications for extreme events such as rain on snow multivariate droughts hao and aghakouchak 2014 and fire weather indices vicente serrano et al 2010 among others evidence for the variability and trends of compound events such as extreme warm wet or extreme warm dry periods might be misrepresented if the data does not capture such behaviour in this study we use the raven hydrological model craig 2019 to explore how the univariate and multivariate biases can affect model outputs i e streamflow and quantify the corresponding uncertainties over the kootenay comox and coquitlam watersheds in western canada 3 4 raven hydrological framework raven is a flexible hydrological modeling framework that allows for the development of lumped and semi distributed models some of the features of raven include discretization of land into hydrological response units hrus and flexibility of using empirical models or physical systems to represent hydrological processes shafii 2017 raven is capable of emulating a number of hydrologic models including the ubc watershed model ubcwm quick 1995 environment canada s hbv model bergstrom 1995 and hmets martel et al 2017 among others in this study the ubcwm emulation setup by bc hydro is adopted in all three watersheds the hydrological model is used as a framework to characterize the propagation of biases in climate inputs to streamflow simulations to assess the effectiveness of the univariate and multivariate bias correction methods and avoid the influence of model parameterization we consider the streamflow simulations generated using the ahccd input data as the truth temperature and precipitation from gridded products which are bias corrected based on ahccd are then used to drive the same model structure with similar parameterization the resulting simulations are compared considering the ahccd driven model output as the baseline the qdm and mbc corrected data are expected to show similar univariate distributions for temperature and precipitation because the mbc method uses qdm to bias correct the marginal distributions the difference between the two approaches is in adjusting the bivariate structure of the data which has important implications for hydrological simulations for example the total precipitation provided as an input to the raven hydrologic model is partitioned into rain and snow based on the corresponding temperature using the following linear transition approach craig 2019 6 α s 0 5 t trans t ave δ t where α s is the snow fraction t ave is the average daily temperature t trans and δ t are global parameters defined within the model structure t trans 1 0 δ t 2 0 α s is further used to calculate rainfall r from total precipitation p using r 1 α s p and snowfall s using s α s p eq 6 is only used when the temperature ranges between t trans δ t 2 to t trans δ t 2 when the average daily temperature is outside this range total precipitation is considered as all snow or all rain accordingly changes in the co occurrence of precipitation and temperature can affect the precipitation regime snowpack snowmelt rain on snow processes among others gridded records corresponding to each dataset that fall within each watershed are spatially averaged to create a single 31 year time series of temperature and precipitation then the hydrologic models are forced with all six datasets ahccd and five gridded products and the simulated streamflow is compared using annual hydrographs and the modified kling gupta efficiency kling et al 2012 a performance metric proposed in an earlier study by gupta et al 2009 7 k g e 1 r 1 2 β 1 2 γ 1 2 kge combines the pearson correlation coefficient r the bias ratio β and the variability ratio γ into one quantifiable value that ranges from to 1 with 1 being the ideal score finally to validate the frequency of extreme flows probability of detection pod of extreme flows is calculated to calculate pod a particular day is identified in the observed flow time series when an extreme event happens i e q 95th percentile then we check whether the corresponding simulated streamflow also exceeds its 95th percentile or not the principal being whether simulated streamflow is able to capture the occurrence of a high flow irrespective of bias in its magnitude we classify the input data bias into two categories univariate bias that represents the biases in temperature and precipitation individually and the multivariate bias that is the bias in their dependence structure first the gridded products are bias corrected using the quantile delta mapping qdm a univariate bias correction method cannon et al 2015 next the gridded products are bias corrected using the multivariate bias correction method mbc proposed by cannon 2016 the qdm bias correction approach preserves relative changes in quantiles of the variable being corrected the approach builds upon previous approaches such as quantile mapping qm and detrended quantile mapping dqm cannon et al 2015 show how their approach accounts for relative changes in all modeled quantiles where earlier approaches i e dqm only accounts for relative changes in the modeled mean the mbc approach is a further development of the qdm bias correction method combined with a multivariate linear bias correction algorithm proposed by bürger et al 2011 while qdm only corrects for univariate biases the multivariate bias correction algorithm corrects the multivariate structure but not the univariate structure unless it is strictly multivariate gaussian mbc combines the two methods using an iterative process correcting both univariate and preserving the dependence structure at the same time the mbc algorithm has two variants mbcp which relies on the pearson correlation coefficient and mbcr which relies on the spearman rank correlation coefficient in this study mbcr is used for bias correction of temperature and precipitation since the bivariate structure of the two variables is not necessarily gaussian therefore rank correlation is the ideal choice to represent their dependence consequently three scenarios of simulated streamflow are considered based on the gridded product inputs fig 3 streamflow generated using original gridded products q o streamflow generated after univariate bias correction of gridded products q u and streamflow generated after multivariate bias correction of gridded products q m this allows for investigating the propagation of biases in both univariate and multivariate structure of the input data into hydrological model predictions 4 results and discussion 4 1 univariate analysis majority of the 113 locations have cold biases across all products in all seasons fig 4 the magnitude of the cold bias is maximum in winter at 10 c as an outlier on the eastern coast if the outlier is excluded then all seasons show a similar pattern where maximum cold biases around 8 c occur over the rockies in the west whereas maximum warm biases around 5 c occur over the canadian prairies there are significant spatial similarities among the datasets in terms of where warm and cold biases are observed all products have the highest accuracy in southeastern canada southern ontario in capturing temperature with the region having the lowest bias on average on average both ncep products cfsr and narr have the highest warm and cold biases across seasons with narr being predominantly warmer in all seasons except winter nrcanmet and s14fd have very similar biases in each case but nrcanmet on the whole performs better than every other dataset similar patterns are observed for precipitation biases as well fig 5 nrcanmet and s14fd tend to be the most accurate products across all seasons however s14fd proves marginally better than nrcanmet on average grasp has some extreme outliers in all seasons except summer with biases reaching over 4 mm day in winter and spring and 6 mm day in fall observed at a couple of location on the western coast in all seasons ncep products display opposite behavior to each other with cfsr predominantly wet and narr predominantly dry maximum wet biases in cfsr are observed over the western mountains while maximum dry biases in narr are observed over the canadian prairies and southern ontario the 95th quantile of temperature t95 is underestimated by all gridded datasets fig 6 a with narr being the closest to the observation and grasp being the farthest nrcanmet and s14fd again exhibit very similar results with the average t95 at just over 20 c while grasp estimates the average t95 across the 113 locations at 19 1 c regarding the frequency of temperature extremes nrcanmet has the highest correlation with the observed dataset with 47 locations having correlations above 0 8 while for all other products the number of sites is below 15 with the lowest in narr the magnitude of extreme precipitation is best captured by narr followed by nrcanmet and s14fd fig 6b it is evident from the results that the biases observed in daily time step in precipitation do not play a large role in extremes the consistent wet bias in cfsr and dry bias in narr is not evident in r95p in fact cfsr slightly underestimates the annual sum of extreme precipitation grasp shows a very narrow distribution of extremes across all sites with a few outliers at both ends regarding the frequency of extreme precipitation events nrcanmet outperforms other products followed by s14fd but the overall value of correlation is much lower than observed for temperature extremes only one site across all products shows a correlation above 0 8 while 50 of locations across all products show correlations of less than 0 5 indicating that even though the magnitude of extreme events might be captured satisfactorily their temporal occurrence is not according to the univariate analyses nrcanmet and s14fd can represent temperature and precipitation better than other gridded datasets with nrcanmet performing marginally better for temperature and s14fd marginally better for precipitation the ability of nrcanmet to capture both temperature and precipitation better can be associated with the direct interpolation of 3000 ground based stations across canada while taking elevation into account this makes the dataset much closer to the ground truth as compared to the other four reanalysis products and thus are more dependent on the modeling framework and data assimilation processes undertaken in their development 4 2 bivariate analysis across all gridded products and four seasons the number of sites that match the dependence of ground based observation data is below 50 except for s14fd in winter at 67 sites fig 7 there is hardly any homogeneity between the datasets in different seasons and the number of common sites across all products where dependence is captured or not captured is less than 15 these sites are located in the southwest southern ontario and east of the rockies all datasets struggle the most in capturing dependence between temperature and precipitation in spring the following are some of the significant dependence features of the ground based data that gridded products do not capture well 1 the observed data shows significant dependency between warm and wet events upper tail in spring in the north and southwestern regions of canada windward side of the rockies which the gridded datasets fail to capture 2 the observed data shows significant dependency between hot and dry events in the prairies in both spring and summer which the gridded datasets do not capture these dependencies have important hydrologic implications the northern regions of canada have warmed by over 2 3 c according to canada s changing climate report released by environment and climate change canada which is almost 4 times the global average bush lemmen 2019 the positive dependence between temperature and precipitation in the north indicates that the region can get wetter as it gets warmer something that the gridded products fail to capture in addition the western coast of canada is impacted by numerous snowmelt and rain on snow floods in late spring and early winter when precipitation occurs on unusually warm days with snow on the ground the positive dependence implies that with temperature increases the amount of precipitation is expected to rise which can further worsen these conditions tencer et al 2014 gridded datasets however fail to capture such warm wet dependency in southwest canada further the prairies has experienced dramatic droughts amounting to billions of dollars in damages garnett 2002 the strong overall negative dependence between temperature and precipitation suggests that as the area gets hotter it can get drier thus exacerbating the occurrence and severity of droughts aghakouchak et al 2014 zscheischler and seneviratne 2017 this phenomenon is not captured well by gridded datasets which can lead to an underestimation of the risks associated with these extreme events while nrcanmet characterizes the univariate behaviour of temperature and precipitation relatively well results suggest that it does not represent the dependency any better than the other datasets this brings into question the use of nrcanmet as observation in numerous hydrologic applications and in bias correction of other products such as global climate models there is a growing interest in developing multivariate bias correction methods which correct the dependence between variables along with their univariate characteristics however as shown in this study this true dataset may not be capable of capturing the dependence structure correctly which can undermine the accuracy of bias corrected products and further inferences drawn from them 4 3 hydrological model assessments we compare the simulated streamflow across different scenarios for each watershed to quantify improvements in model accuracy associated with the univariate and multivariate bias correction of the input data to better understand the differences we scrutinize the co occurrence of temperature and precipitation and the corresponding precipitation regime in the hydrological model 4 4 partitioning of total precipitation as expected the distributions of univariate temperature and precipitation from both mbcr and qdm corrections are identical fig 8 the effect of multivariate bias correction only becomes apparent when the input data is discretized into precipitation occurring above and below a certain threshold as described in section 3 3 table 2 shows the average annual precipitation falling below 0 c corresponding to t trans δ t 2 in section 3 3 indicating that precipitation falls as snow and above 2 c corresponding to t trans δ t 2 indicating that precipitation falls as rain for unadjusted and bias corrected gridded datasets compared to the ahccd observation at kootenay comox and coquitlam watersheds there are significant differences in the partitioning of total precipitation between qdm and mbcr data even though the underlying univariate distributions are identical 4 5 comparison of simulated streamflow as discussed previously hydrological models are not calibrated to the individual datasets as the focus is not on how well they perform with respect to their original inputs we investigate differences between the qdm and mbcr input scenarios to quantify the added benefits of correcting the bivariate structure of the input data fig 9 shows the comparison of annual streamflow from october 1990 to september 1991 for qdm and mbcr input scenarios across the study regions in all three watersheds the seasonality of streamflow i e peak flows occurring in kootenay and comox watersheds in spring and in coquitlam in late winter are captured in both scenarios further the influence of hot and dry conditions in the summer are also evident in all datasets showing the occurrence of low flows during late summer smaller differences are evident however using the kge metric for this particular year where in almost all datasets marginal improvements are seen for the mbcr inputs further the overall kge metric across 31 years also shows that in all cases except for narr in winter kge of mbcr driven model output improves over the qdm driven output fig 10 the highest kge values between multiple datasets correspond to nrcanmet followed by narr the superiority of nrcanmet again hints towards the elevation based interpolation conducted over a vast array of station records which makes it more robust as compared to the other datasets the largest differences between qdm and mbcr are observed in the pod of extreme flows fig 11 in most cases the pod values corresponding to mbcr are approximately double the ones from the qdm scenario these differences highlight the importance of maintaining the dependence structure of temperature and precipitation input datasets for hydrological modelling particularly in forecasting extremes while extreme flows are directly related to high precipitation rates the effects of temperature and the co occurrence of the two variables are also significant especially in high elevation areas this study characterizes the propagation of biases in the dependence structure of these input variables that can result in the misrepresentation of critical conditions such as warm and wet events and subsequent high flows 5 conclusions the goal of the study is to evaluate the performance of gridded products in representing the covariability between temperature and precipitation over canada with the point of view of using these datasets for identifying and modelling compound events five gridded datasets are compared with ground based observations considering both univariate and bivariate behaviours the analysis is performed using daily temperature and precipitation data spanning over 31 years 1980 2010 at 113 station locations the overall characteristics of temperature and precipitation of each gridded dataset are assessed using mbe in addition the corresponding frequency and magnitude of extreme precipitation are compared to the observed extremes the bivariate performance is evaluated based on a formal goodness of fit test for copulas that verifies how well the gridded datasets represent the dependence between temperature and precipitation with respect to the dependence structure of the ground based observation to demonstrate the importance of bivariate bias correction a semi distributed hydrological model is forced with three sets of input data for three watersheds with distinct characteristics in western canada the input scenarios include the original datasets unadjusted data bias corrected using qdm a univariate bias correction method and input data bias corrected using mbcr a multivariate bias correction method the hydrographs of the three sets of streamflow scenarios are then compared and the overall performance of the models are evaluated using kge and probability of detection pod of extremes the minimum and maximum temperature biases across all gridded products are 7 9 c in fall excluding the outlier to 7 6 c in winter cold bias exists at the majority of the 113 locations for all datasets the bias is strongest over western rockies where all gridded products show colder conditions than ground based observation while warm bias is strongest over the prairies overall nrcanmet shows the closest temperature variability compared with the ground based observation one of the strengths of nrcanmet is its use of elevation as a predictor in thin plate spline interpolation however no clear relation is found between the observed bias and station elevations the minimum and maximum biases for precipitation across all datasets are 3 8 mm day to 6 2 mm day in fall in all datasets sites with high wet biases are located on the windward side of the rocky mountains whereas the location of sites with dry biases varies between each dataset there are significant biases in nrcanmet in several locations however along with s14fd it outperforms the other products in representing precipitation the performance of the gridded products in representing the dependence structures is evaluated using copulas the results show that in almost all cases across seasons and datasets the correct dependence structure is identified at less than 50 of the sites critical bivariate characteristics such as the upper tail dependencies between temperature and precipitation warm wet conditions in the north and southwest regions of canada are not captured by gridded datasets which has important implications for water availability and flood risk especially in southwestern canada najafi and moradkhani 2014 najafi et al 2017a najafi et al 2017b similarly hot dry dependencies in the prairies are not represented in gridded datasets which can lead to drought underestimations in this region notably the capability of nrcanmet to capture the individual characteristics of temperature and precipitation does not transfer over to the bivariate behaviour using a hydrological model we showed how the biases in individual precipitation and temperature variability and their dependence structure propagates into streamflow simulations there are significant differences between the bivariate structure of data adjusted by the mbcr approach as compared to the ones bias corrected by qdm even though the underlying univariate distributions remain identical the partitioning of total precipitation into rain and snow is significantly more accurate in mbcr compared to qdm with respect to the observed ahccd data these differences are further highlighted in streamflow simulations where mbcr improves upon qdm inputs in almost all cases while marginal improvements are noticed in the overall kge metric the greatest change is observed in the probability of detection of extreme flows this can be directly attributed to the underlying bivariate structure since extreme flows are affected by precipitation temperature and their covariability especially in mountainous regions such as the three watersheds considered in this study in the future the proposed evaluation framework can be extended to characterize the propagation of dependence biases at large scales this study calls for a deeper analysis of existing datasets to verify their capabilities to characterize compound events without this verification inferences based on such datasets particularly in the multivariate conditions are unreliable as the uncertainty increases with the addition of data and the covariability between different factors credit authorship contribution statement harsimrenjit singh conceptualization methodology software writing original draft mohammad reza najafi conceptualization methodology writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the raven hydrological model was setup by bc hydro for the three watersheds we thank georg jost for providing access to this model this project was funded by an nserc discovery grant 
5633,when the simulation optimization method is applied to groundwater contamination source identification gcsi the numerical simulation model is usually embedded in the optimization model as a constraint condition hundreds and thousands of simulation model calls while solving the optimization model often lead to computational disaster establishing a surrogate model for the simulation model can effectively alleviate this drawback when using extreme learning machine elm to establish a surrogate model for a simulation model the output weights are calculated using randomly given input weights and hidden layer deviations which may lead to inadequate accuracy of the surrogate model and insufficient generalization ability to samples not appearing in the training set however by combining the elm with particle swarm optimization pso the pso can be used to optimize the selection of the input weights and hidden layer deviations of the elm thus calculating the output weights and establishing a surrogate model based on the pso elm instead of the simulation model embedded in the optimization model to complete the gcsi the uncertainty of the parameters is rarely considered when the simulation optimization method is applied to gcsi thus the uncertainty of the parameters is considered in gcsi based on the pso elm the results show that compared with the elm the pso elm can establish the surrogate model with higher accuracy the surrogate model based on pso elm can be embedded in the optimization model to effectively solve gcsi problems the predictive model based on pso elm can predict the release histories of contamination sources corresponding to different random parameters keywords groundwater contamination pso elm uncertainty surrogate model simulation optimization 1 introduction the reasonable design of groundwater contamination remediation schemes the accurate identification of contamination liability and the assessment of contamination risk need to be supported by relevant information about groundwater contamination source characteristics including the number location and release history release intensity of release period of contamination sources khan et al 2004 lapworth et al 2012 however unlike air and surface water contamination which can be easily detected in a timely manner after contamination occurs groundwater contamination sources are hidden underground and thus they are characterized by concealment and delayed discovery which makes it difficult for people to obtain relevant information about groundwater contamination source characteristics therefore it is particularly important to identify this relevant information gcsi has a development history of about 40 years many theories and methods have been applied to gcsi including geophysical detection methods geochemical fingerprinting methods isotope methods and mathematical equation inverse methods milnes and perrochet 2007 among these the simulation optimization method which is a type of mathematical equation inverse method has been widely used in gcsi ayvaz and karahan 2008 mirghani et al 2009 ayvaz 2010 datta et al 2011 a numerical simulation model can describe the functional transformation relationship between a contamination source sink term and contaminant concentrations in observation wells xing et al 2019 therefore use of the simulation optimization method in gcsi requires embedding the numerical simulation model as an equality constraint in the optimization model during optimization model solution the characteristics of contamination sources are identified by minimizing the difference between the simulated concentration and the measured value zhao et al 2016 however solving the optimization model often requires hundreds of iterative calculations in this iterative calculation process it is necessary to call the numerical simulation model repeatedly to perform numerical calculations which entails a huge computational load and lengthy calculation time hou et al 2016 this problem seriously restricts the feasibility of the simulation optimization method in gcsi establishing a surrogate model for the numerical simulation model can effectively solve this problem the surrogate model not only functionally approximates the simulation model but also significantly reduces the computational load when the surrogate model is used for gcsi the approximation accuracy of the surrogate model with respect to the simulation model is very important because it has a great impact on the solution results of the optimization model hou and lu 2018 if the approximation accuracy of the surrogate model with respect to the simulation model is not high the solution of the optimization model will deviate from the true characteristics of the groundwater contamination sources making the inverse result meaningless therefore a method for constructing high accuracy surrogate models is urgently needed current methods for building surrogate models include artificial neural network techniques singh et al 2004 behzadian et al 2009 farzaneh et al 2018 kriging methods simpson et al 2001 zhao et al 2016 support vector machines svm zhang et al 2009 hou et al 2015 diaz alcaide and martinez santos 2019 radial basis functions rbf mullur and messac 2006 regis and shoemaker 2007 bagtzoglou and hossain 2009 luo et al 2013 polynomials wang 2003 he et al 2008 fen et al 2009 multivariate adaptive regression splines buja et al 1991 jin et al 2001 extreme learning machines jiang et al 2015 hou et al 2019 and many others elm is a machine learning method that has been developed in recent years huang et al 2004 2066 elm is a new type of feedforward neural network compared with the traditional single hidden layer feedforward neural network elm has the advantages of fast learning speed and good generalization performance huang et al 2015 ding et al 2015 alade et al 2017 therefore the elm method has been widely used in various fields liu et al 2018 however this method still has its own shortcomings because the elm is randomly given input weights and hidden layer deviations elm usually requires more hidden layer neurons to achieve the desired accuracy moreover sometimes its generalization ability is weak however using pso to select the input weights and hidden layer deviations of the elm and then calculating the output weights can avoid the above shortcomings to some extent and improve the generalization ability of the elm the pso elm algorithm has been applied in many fields but not gcsi in particular yadav et al 2016 employed pso elm to estimate the cost of an in situ bioremediation system xu et al 2017 used pso elm to predict the porosity of a tuffaceous sandstone reservoir kaloop et al 2019 applied pso elm to predict the resilient modulus of stabilized aggregate bases as well as comparing the accuracy of the predictions obtained by pso elm and an artificial neural network ann algorithm where the results showed that the accuracy was higher with pso elm this study utilizes pso elm to gcsi firstly the pso was used to improve the elm and then the pso elm was used to establish a surrogate model for the simulation model in order to compare the generalization performance of the pso elm and other methods when establish surrogate model the accuracies of the surrogate models established by the artificial neural network ann generalized regression neural network grnn elm and pso elm were compared and the surrogate model with its greater generalization ability was selected for embedding in the optimization model from where it is called during solving the optimization model few studies have considered the uncertainty of the parameters when applying simulation optimization to solve gcsi problems singh and datta 2006 guo et al 2018 zhen et al 2019 although uncertainties clearly exist and they could affect the gcsi results therefore the uncertainty of the parameters is considered in gcsi based on the pso elm in the present study a predictive model which could predict the relationship between the random parameters and the release histories was established by applying pso elm method 2 methodology 2 1 extreme learning machine elm is a kind of machine learning method based on a feedforward neural network huang et al 2015 huang et al 2004 the single hidden layer feedforward neural network in elm consists of an input layer a hidden layer and an output layer the neurons of the input layer and the hidden layer and those of the hidden layer and the output layer are fully connected the input layer has n input variables which are equivalent to n neurons the hidden layer has l neurons the output layer has m output variables which are equivalent to m neurons if there are m arbitrarily different samples x i y i xi xi1 xi2 xin yi yi1 yi2 yin then the output of the feedforward neural network with l neurons and hidden layer excitation function g x can be expressed as 1 f l x i 1 l β i g a i x i b i where a i a i 1 a i 2 a in is the connection input weight between the input layer and the i th neuron of the hidden layer β i β i 1 β i 2 β im is the connection output weight between the output layer and the i th neuron of the hidden layer and b i is the threshold of the i th neuron in the hidden layer if the feedforward neural network with l hidden layer neurons can approximate the m samples with zero error then there exist a i β i b i that satisfy eq 2 and eq 2 can be converted to eq 3 2 f l x y i 3 h β y where h is the output matrix of the hidden layer as given by eq 4 in the elm algorithm the input weight and the thresholds of the hidden layer are randomly determined before training and remain unchanged during the training process so that h is uniquely determined thus the training of the elm network can be transformed into a linear system optimization problem to solve for the connection output weights β as given by eq 5 by solving the optimization problem the connection output weights β can be calculated as given by eq 6 4 h g ω 1 x 1 b 1 g ω l x 1 b l g ω 1 x m b 1 g ω l x m b l m l 5 min β h β y 6 β h y t where h is the moore penrose generalized inverse matrix of the output matrix h after calculating the connection output weights the output corresponding to any different input can be predicted 2 2 particle swarm optimization pso is an optimization method based on swarm intelligence proposed by kennedy and eberhart 1995 the algorithm originates from the study of bird prey behavior the basic idea of pso is to search for the optimal solution to the problem through cooperation and information sharing among individuals in the group in pso each bird is regarded as a particle with a memory function which can remember the best position for which it has searched the characteristics of each particle can be expressed by position fitness and velocity the position of the particle corresponds to the solution of the optimization problem the fitness value of a particle is the value calculated by bringing the current position of the particle into the objective function the velocity of the particles determines the next flight direction and distance of the particles themselves swathi and elwha 2018 mategaonkar et al 2018 the optimal solution to the problem is the optimal position of all the particles after a number of iterations in the solution space the updated position of each particle after each iteration could be the optimal solution of the problem during each iteration update process the particle updates its position by tracking two extreme values one is the optimal solution found by the particle itself this solution is called the individual extremum pbest the other extremum is the optimal solution currently found by the entire population this extremum is the global extremum gbest in d dimensional space consider a population of n particles x x 1 x 2 x n where the position of the i th particle is x i x i 1 x i 2 x id t bring x i into the fitness function f x i to calculate the fitness value of the particle position the velocity of the i th particle is v i v i 1 v i 2 v id t where the pbest of the i th particle is p i p i 1 p i 2 p id t and the gbest of the population is p g p g 1 p g 2 p gd t during the iterative optimization process the particle updates its velocity and position through pbest and gbest 7 v id k 1 ω v id k c 1 r 1 p id k x id k c 2 r 2 p gd k x gd k 8 x id x id v id where ω is the inertial weight which controls how much of the current velocity the i th particle inherits d is the dimension of the solution to be optimized n is the population size k is the current iteration number v id is the particle velocity and c 1 c 2 are acceleration factors which control the velocity calculation to pay more attention to particle experience or group experience r 1 and r 2 are two random numbers with the value range of 0 1 that can increase the degree of search randomness to prevent a blind search by particles the position and velocity are generally limited to x max x max v max v max 2 3 pso elm it is known from eqs 1 to 6 that the output weights are calculated using the input weights and the hidden layer deviations because the elm randomly assigns the input weights and the hidden layer deviations there may be some cases where the deviation of input weight and the hidden layer deviation are 0 this causes some hidden layer neurons to be invalid which makes the elm unable to achieve the ideal accuracy due to insufficient generalization of samples that are not present in the training set to solve these problems pso and elm are combined the pso is used to optimize the input weight and hidden layer deviations of the elm and an optimal elm network is obtained the input weights and hidden layer deviations of the elm are regarded as the particles in the pso and the root mean square error of each individual of the initialized population calculated by the training sample is used as the fitness of the pso han et al 2013 zhang and li 2016 the specific implementation steps are as follows 1 prepare the training samples and determine the dimensions of the input and output i e the number of neurons in the input and output layers of the elm and the number of neurons in the hidden layer 2 generate the initial population produce the appropriate number of particles form the initial population and determine the appropriate acceleration factor and the maximum number of iterations 3 for each individual particle in the population the elm is used to calculate the output weights the fitness value of each particle in the initial population the pbest of the individual particles and the gbest of all particles from the training sample if the conditions for stopping the iterations are not met maximum number of iterations or error less than the threshold then the velocity and position of all particles are updated using eqs 7 and 8 4 when the conditions for stopping the iterations are reached the pso optimized elm network has been obtained 2 4 artificial neural network artificial neural network ann have been used for gcsi for many years singh et al 2004 an ann comprises an input layer hidden layer and output layer anns are regarded as approximators of nonlinear systems and their detailed principles were described by zurada 1992 the newff function in matlab r2014b was used to conduct the feedforward backpropagation ann training process in the present study yadav et al 2016 2 5 generalized regression neural network a generalized regression neural network grnn can approximate the implicit mapping relationship based on the sample data grnn have a high capacity for nonlinear mapping where the number of samples required and the number of artificially controlled parameters for modeling are low the principle of the grnn is described as follows the joint probability density function between the random variables x and y can be expressed as f x y if the measured value of x is x then the relative regression predictive value for x is y 9 y yf x y dy f x y dy f x y can be estimated from the training samples further details of the principles of grnn were described by cigizoglu and alp 2006 2 6 optimization model establishing an optimization model is an essential part of identifying the characteristics of groundwater contamination sources in general an optimization model consists of three parts the objective function the decision variable and the constraints building an optimization model involves three steps 1 determine optimization goals and decision variables 2 determine the objective function expression of the optimization target 3 determine constraints including equality and inequality constraints the optimization goal refers to the purpose of solving the optimization problem decision variables are control variables that have an impact on the optimization goal the optimization goal can be achieved by making changes and designing the decision variables after determining the decision variables and optimization goals the optimization goals must be expressed in the form of objective functions the objective function is the form of the desired goal expressed in terms of the decision variables and it is a criterion for evaluating whether the obtained values of the decision variables meet the specified requirements in the optimization problem the constraint conditions are restrictions on the decision variables often appearing in the form of inequalities or equations the objective function often needs to find the maximum value or minimum value under certain constraints in the optimization problem if the objective function or constraint of the optimization model is a nonlinear system the model is called a nonlinear optimization model the optimization model is presented as follows 10 min f x α g i x σ i 1 2 n h j x 0 j 1 2 m where min f x is the objective function and α and σ are upper and lower bounds of inequality constraints respectively x x 1 x 2 x 3 x t is the vector of decision variables t is the dimension of the decision variables g i x is the inequality constraints β j x is the equality constraints and n and m are the total number of inequality and inequality constraints respectively 3 case study 3 1 site overview in this study a hypothetical groundwater contamination site was used to verify the effectiveness of the research methods described above when applied to gcsi the contaminant at the hypothetical sites is a conservative contaminant that does not undergo biological transformation or chemical changes see fig 1 the case study area was a two dimensional heterogeneous isotropic aquifer with irregular boundaries with three parameter zones and the groundwater flow was transient flow the southeastern and northwest boundaries of the case study area were specified head boundaries the southwestern and northeast boundaries of the case study area were no flow boundaries shown in fig 2 the vertical direction of the case study area received uniform recharge through atmospheric rainfall the initial concentration of contaminant in the case study area was 0 mg l the total simulated time of contamination transport was 12 months with a total of six simulation periods every two months was one simulation period contaminant was released to the aquifer during the first three simulation periods of the simulation and then stopped there were seven observation wells in the case study area distribution of three parameter zones in aquifer locations of observation wells and potential contamination sources are shown in fig 2 the actual contamination source information under two situations in the study area was separately identified the actual parameters of the aquifer are listed in table 1 and the true contamination source information in both situations is shown in table 2 the locations and release histories of contamination sources were regarded as unknown variables and some parameters were regarded as random variables during the process of gcsi 3 2 numerical simulation model a numerical simulation model of groundwater flow and contaminant transport was constructed to describe groundwater and contaminant transport in the groundwater system in the aquifer the governing partial differential equations of groundwater flow and contaminant transport for transient flow in a two dimensional aquifer system are given below singh and datta 2006 zhao et al 2016 the governing partial differential equation of groundwater flow is as follows x i k ij h x j w μ h t x y ω i j 1 2 t 0 where kij is hydraulic conductivity h is hydraulic head μ is specific yield ω is the simulated area range and w is volumetric flux per unit volume the governing partial differential equation of groundwater contaminant transport is as follows c t x i d ij c x j x i u i c r θ x y ω i j 1 2 t 0 u i k ij θ h x i i j 1 2 where θ is porosity c is contaminant concentration dij is the dispersion coefficient ui is the average linear velocity of the groundwater flow and r is a source or sink term the modflow and mt3dms toolboxes of the gms software were used to carry out numerical calculations for groundwater flow and contamination transport numerical simulation models unlike actual research examples hypothetical research cases have no measured value therefore after the numerical simulation model of contamination transport was constructed it was necessary to run this model in the forward direction the simulated contamination concentration of all observation wells at each simulation period was obtained as the measured value in the inverse identification process of groundwater contamination sources and the locations and release histories of contamination sources were regarded as unknown variables to be identified the measured values of the observation wells were obtained by the forward running contamination transport numerical simulation model when actual contamination sources information shown in table 2 were input simulation model shown in fig 3 3 3 sensitivity analysis the gcsi process was performed after obtaining all of the measured values for the observation wells the objective uncertainty in the parameters could have affected the gcsi results so the local sensitivity analysis method was conducted where the two parameters with greater impacts on the model output were selected as random variables for the model and the other parameters were treated as deterministic variables the sensitivity of each parameter was calculated using the following formula 14 s k y α k y i α k δ α k y i α k 1 δ α k α k 1 where s k is the sensitivity α k is one of the input model parameter values δ α k is the variation in α k y i α k is the output of the model when the parameter is α k and y i α k δ α k is the output of the model when the parameter is α k δ α k sensitivity analysis showed that the two most sensitive parameters were the hydraulic conductivity and longitudinal dispersivity fig 4 therefore eighty groups of hydraulic conductivity and longitudinal dispersivity a total of four parameters for each group were sampled using the latin hypercube method a common sampling method detailed principle of the latin hypercube method can be found in parnianifard et al 2020 the first group of random parameters and other deterministic parameters the deterministic parameters remained unchanged throughout the study as shown in table 1 were used as inputs for the numerical simulation model the distributions of the random parameters are shown in table 3 the current numerical simulation model was then employed to perform the operations described in sections 3 4 and 3 5 3 4 surrogate models of the numerical simulation model the numerical simulation model was embedded in the optimization model as an equality constraint to ensure that contaminant transport obeyed the groundwater contaminant transport law during the optimization model solving process however during iterative calculations of the optimization model the numerical simulation model had to be called hundreds and thousands of times which would generate a large computational load and take an excessive amount of time hou and lu 2018 luo et al 2013 to avoid this shortcoming a surrogate model of the numerical simulation model was constructed a surrogate model with satisfactory accuracy has almost the same inputs and outputs as the simulation model it is a good choice to use the surrogate model instead of the simulation model as the optimization model to embed for calculation in this study the concentrations of each observation well in each simulation period were taken as the output variables of the surrogate model and the release intensities of each potential contamination source were regarded as the input variables for the surrogate model a total of nine input release intensity variables the release intensities of each potential contamination source were sampled by using the latin hypercube method in their feasible domains the feasible domain range of release intensity was 0 400 mg l release intensity values for 100 groups were sampled and were sequentially input into the simulation model and the corresponding output concentrations of all observation wells in each period were obtained by running the simulation model eighty groups of input output data pairs were selected as training samples for the surrogate model and the remaining twenty groups of input output data were used as test samples for the surrogate model based on the training samples ann grnn elm and pso elm were used to establish surrogate models the established surrogate models could be used to predict the output corresponding to any input the accuracy of the surrogate models were tested using three statistics including the mean relative error mre the root mean square error rmsr and the coefficient of determination r2 mre rmsr and r2 were calculated respectively as follows mre 1 n i 1 n y i y i y i 100 16 rmsr i 1 n y i y i 2 n 17 r 2 1 i 1 n y i y i 2 i 1 n y i y i 2 where y i is the output value of the i th sample in the contaminant transport numerical simulation model y i is the output value of the i th sample in the surrogate model and y i is the average value of n samples output from the simulation model the smaller the mre the smaller the rmse and the closer r 2 is to 1 the higher is the approximation accuracy of the surrogate model in simulating the output of the simulation model 3 5 nonlinear optimization model the locations and release histories of contamination sources were identified in this study the release history refers to the contaminant release intensity at each simulation period atmadja and bagtzoglou 2001 sun et al 2006 the release histories of the contamination sources were decision variables of the optimization model the fitting error between the measured and simulated concentrations of contaminant in the observation wells at each simulation period was minimized as the objective function the contaminant transport numerical simulation model was embedded in the optimization model as an equality constraint replacing the simulation model by the surrogate model the feasible domains of release histories of the contamination sources were inequality constraints the specific expression of the nonlinear optimization model used to identify the characteristics of contamination sources is 18 min z q 1 q 2 q 3 t 1 6 k 1 7 c k t t c k t 0 2 0 q m 400 m 1 2 3 q m q 1 m q 2 m q im i c k t t f q m 1 2 3 where q m is the release intensity of contamination sources during each release period c k t t is the simulated concentration of the contaminant at the observation point and c k t 0 is the measured contaminant concentration at the observation point c k t t f q m is the surrogate model of the simulation model the optimization model was solved to identify the location and release history of the contamination sources 3 6 establishment of predictive model after performing the procedures described in sections 3 4 and 3 5 based on the numerical simulation model corresponding to the first group of random parameters the same process was conducted based on the numerical simulation model corresponding to the second group of random parameters until the 80th group of random parameters the release histories of the contamination sources corresponding to eighty groups of random parameters were then obtained in this manner based on these eighty groups of random parameters and release histories a predictive model representing the relationships between the random parameters and release histories was established with the pso elm method the first sixty groups were used for training the predictive model the last twenty groups were used to test the accuracy of the predictive model 4 results 4 1 comparative analysis of the accuracy of the surrogate models ann grnn elm and pso elm were all used to establish surrogate models for the simulation model e g for the simulation model corresponding to one group of random parameters a total of eighty groups of simulation models were generated the accuracies of the ann surrogate model grnn surrogate model elm surrogate model and pso elm surrogate model were compared and analyzed using mre rmsr and r2 then the surrogate model with higher accuracy was selected for embedding in the optimization model twenty groups of input samples were input into the simulation model ann surrogate model grnn surrogate model elm surrogate model and pso elm surrogate model respectively and then twenty groups of output data corresponding to the input of the simulation model and the four surrogate models were obtained the next step was to test and compare the accuracy of the four surrogate models table 4 shows mre r2 and rmse for the seven observation wells from the ann grnn elm and pso elm surrogate models to clarify the accuracy comparison of the four surrogate models contrast histograms of mre fig 5 rmse fig 6 and r2 fig 7 were plotted in order to intuitively demonstrate the improvements twenty groups of output data related to the seven observation wells obtained from the simulation model elm surrogate model and pso elm surrogate model were plotted as scatter graphs for a total of six simulation periods taking sp4 as an example table 4 and fig 8 show that the performance of elm was improved by pso table 4 and figs 5 8 show that the pso elm surrogate model has a higher coefficient of determination than the other four surrogate models the minimum coefficient of determination for pso elm was 0 9988 which is very close to 1 compared with the other surrogate model the mre and rmse of the pso elm surrogate model were smaller therefore the pso elm surrogate model provided a better approximation to the simulation model and had higher accuracy therefore the pso elm surrogate model was selected for embedding in the optimization model to identify the location and release history of groundwater contamination sources 4 2 results of solving the optimization model the pso elm surrogate model with its higher accuracy was embedded into the optimization model and a genetic algorithm zwickl 2008 guo et al 2018 was used to solve the optimization model to identify the true locations and release histories of contamination sources the locations of contamination sources was determined by the release intensity when the release intensity of one of the three locations was zero at each simulation period it indicated that no actual contamination source was present the contamination source characteristics were then identified in the two situations described above and the identification results were as follows e g for the optimization model solution corresponding to one group of random parameters a total of eighty groups of optimization models were generated it required about 7 3 min to solving the optimization model 1000 iterations when the surrogate model was embedded in optimization model but it required about 166 7 min to solving the optimization model when the simulation model was embedded in optimization model thus the calculation time saved by applying the surrogate model was about 95 6 situation 1 table 5 show that the contaminant release intensity in each release period of s2 is close to zero it indicated two of the three potential contamination source locations were actual contamination sources which were s1 and s3 their release intensity were shown in table 5 situation 2 table 6 show that all three potential contamination source locations were actual contamination sources and their release intensity were shown in table 6 the locations and release histories of contamination sources were identified by solving the optimization model applying the same method the eighty optimization models were solved successively until release histories corresponding to the eighty groups of random parameters were obtained 4 3 accuracy analysis of predictive model pso elm has good generalization performance therefore pso elm was applied to establish a predictive model that reflected the relationship between the random parameters and the contamination sources release histories twenty groups of release histories and their corresponding random parameters test samples were used to calculate mre rmsr and r2 in order to test the accuracy of the predictive model table 7 and fig 9 show that both mre and rmsr were very small and r2 was 0 99 thereby indicating that the predictive model obtained high accuracy and it could predict the release histories corresponding to different random parameters see table 8 4 4 analysis of contamination source identification results after establishing the predictive model 10 000 groups of hydraulic conductivity and longitudinal dispersivity data were sampled again and used as inputs for the predictive model the predictive model generated 10 000 groups of release histories for each contamination source statistical analyses were conducted based on the 10 000 groups of release histories for each contamination source establishing 10 000 optimization models and then solving them in turn required 73 000 min by contrast applying the predictive model to predict the outputs corresponding to 10 000 groups of inputs required about 5 s thus the savings in terms of the computational time and human resources were considerable situation 1 using the 10 000 groups of release histories histograms and probability density maps were generated for each contamination source the distributions of the release histories considering the uncertainty of the parameters are shown in fig 10 the probability densities corresponding to each of the release histories are shown in fig 11 where the point with the highest probability density in the release history for each contamination source was calculated as the identification result decision makers can also select the mean median and maximum values according to their requirements as the basis for decisions table 9 and figs 10 and 11 show that compared with s1 and s3 very little of the contaminant was released at s2 therefore the contamination sources were located at s1 and s3 when the release histories corresponding to the highest probability density were used as the identification results the relative error between the identification results and the actual values was less than 5 situation 2 10 000 groups of release histories for each contamination source were treated in the same manner as in situation 1 table 10 and figs 12 and 13 show that the contaminant was released from all three sources when the release histories corresponding to the highest probability density were regarded as the identification results the relative error between the identification results and the actual values did not exceed 9 5 discussion the uncertainty of the parameters can affect the gcsi results however this problem was not considered in many previous gcsi studies based on the simulation optimization method and thus the gcsi identification results were not necessarily reliable considering uncertainty associated with the parameters in gcsi the identification results must include a variety of possibilities to cover as many of the actual contamination sources as possible and provide decision makers with suitable options applying pso to improve elm can improve the generalization performance of elm to some extent and obtain the optimal training network while maintaining stability if the nonlinearity of the site simulation model increases significantly or the input dimensions of the surrogate model increase significantly the accuracy of the surrogate model established using the pso elm method may be reduced the accuracy may be reduced further with the traditional ann therefore although the pso elm method can obtain good results the next improvement should involve the application of deep learning neural network to perform gcsi 6 conclusions a new method is proposed in this paper to establish surrogate models and a predictive model by combining particle swarm optimization pso with an extreme learning machine elm the optimization model based on the pso elm surrogate model was used to identify the locations and release histories of contamination sources the predictive model based on pso elm was used to predict the release histories corresponding to thousands of random parameters the following three conclusions can be made based on the results obtained in this study 1 in the past the input weights and hidden layer deviations of elm were assigned randomly when using the elm to set up a surrogate model for the simulation model whereas the output weights of elm were calculated using the input weights and hidden layer deviations during the calculations some cases may occur where the input weights and the hidden layer deviations are zero resulting in some hidden layer neurons being ineffective and having insufficient generalization ability for samples not appearing in the training set in this study a pso elm model was proposed pso was used to optimize the selection of input weights and hidden layer deviations for elm based on this method a surrogate model of a simulation model and a predictive model which reflected the relationship between the random parameters and the contamination sources release history were established 2 the pso elm surrogate model with its high degree of approximation accuracy to the simulation model was embedded in the optimization model when the simulation optimization method was used for gcsi this approach can alleviate computational disaster by reducing computational load and saving calculation time in the process of solving the optimization model by solving the nonlinear optimization model the locations and release histories of contamination sources can be identified 3 in order to consider the uncertainty of the parameters a predictive model reflecting the relationships between the random parameters and the release histories of the contamination sources was established based on pso elm the predictive model considers the impact of the uncertainty of the parameters on the gcsi identification results as well as reducing the computational time and human resources required credit authorship contribution statement jiuhui li conceptualization methodology software writing original draft wenxi lu conceptualization writing review editing supervision project administration han wang validation formal analysis yue fan validation data curation zhenbo chang software validation data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to acknowledge the support provided by the national natural science foundation of china 41672232 and the jilin province science and technology development project grant no 20170101066jc special gratitude is given to the journal editors for their efforts to evaluate the work and the valuable comments of the anonymous reviewers are also greatly acknowledged 
5633,when the simulation optimization method is applied to groundwater contamination source identification gcsi the numerical simulation model is usually embedded in the optimization model as a constraint condition hundreds and thousands of simulation model calls while solving the optimization model often lead to computational disaster establishing a surrogate model for the simulation model can effectively alleviate this drawback when using extreme learning machine elm to establish a surrogate model for a simulation model the output weights are calculated using randomly given input weights and hidden layer deviations which may lead to inadequate accuracy of the surrogate model and insufficient generalization ability to samples not appearing in the training set however by combining the elm with particle swarm optimization pso the pso can be used to optimize the selection of the input weights and hidden layer deviations of the elm thus calculating the output weights and establishing a surrogate model based on the pso elm instead of the simulation model embedded in the optimization model to complete the gcsi the uncertainty of the parameters is rarely considered when the simulation optimization method is applied to gcsi thus the uncertainty of the parameters is considered in gcsi based on the pso elm the results show that compared with the elm the pso elm can establish the surrogate model with higher accuracy the surrogate model based on pso elm can be embedded in the optimization model to effectively solve gcsi problems the predictive model based on pso elm can predict the release histories of contamination sources corresponding to different random parameters keywords groundwater contamination pso elm uncertainty surrogate model simulation optimization 1 introduction the reasonable design of groundwater contamination remediation schemes the accurate identification of contamination liability and the assessment of contamination risk need to be supported by relevant information about groundwater contamination source characteristics including the number location and release history release intensity of release period of contamination sources khan et al 2004 lapworth et al 2012 however unlike air and surface water contamination which can be easily detected in a timely manner after contamination occurs groundwater contamination sources are hidden underground and thus they are characterized by concealment and delayed discovery which makes it difficult for people to obtain relevant information about groundwater contamination source characteristics therefore it is particularly important to identify this relevant information gcsi has a development history of about 40 years many theories and methods have been applied to gcsi including geophysical detection methods geochemical fingerprinting methods isotope methods and mathematical equation inverse methods milnes and perrochet 2007 among these the simulation optimization method which is a type of mathematical equation inverse method has been widely used in gcsi ayvaz and karahan 2008 mirghani et al 2009 ayvaz 2010 datta et al 2011 a numerical simulation model can describe the functional transformation relationship between a contamination source sink term and contaminant concentrations in observation wells xing et al 2019 therefore use of the simulation optimization method in gcsi requires embedding the numerical simulation model as an equality constraint in the optimization model during optimization model solution the characteristics of contamination sources are identified by minimizing the difference between the simulated concentration and the measured value zhao et al 2016 however solving the optimization model often requires hundreds of iterative calculations in this iterative calculation process it is necessary to call the numerical simulation model repeatedly to perform numerical calculations which entails a huge computational load and lengthy calculation time hou et al 2016 this problem seriously restricts the feasibility of the simulation optimization method in gcsi establishing a surrogate model for the numerical simulation model can effectively solve this problem the surrogate model not only functionally approximates the simulation model but also significantly reduces the computational load when the surrogate model is used for gcsi the approximation accuracy of the surrogate model with respect to the simulation model is very important because it has a great impact on the solution results of the optimization model hou and lu 2018 if the approximation accuracy of the surrogate model with respect to the simulation model is not high the solution of the optimization model will deviate from the true characteristics of the groundwater contamination sources making the inverse result meaningless therefore a method for constructing high accuracy surrogate models is urgently needed current methods for building surrogate models include artificial neural network techniques singh et al 2004 behzadian et al 2009 farzaneh et al 2018 kriging methods simpson et al 2001 zhao et al 2016 support vector machines svm zhang et al 2009 hou et al 2015 diaz alcaide and martinez santos 2019 radial basis functions rbf mullur and messac 2006 regis and shoemaker 2007 bagtzoglou and hossain 2009 luo et al 2013 polynomials wang 2003 he et al 2008 fen et al 2009 multivariate adaptive regression splines buja et al 1991 jin et al 2001 extreme learning machines jiang et al 2015 hou et al 2019 and many others elm is a machine learning method that has been developed in recent years huang et al 2004 2066 elm is a new type of feedforward neural network compared with the traditional single hidden layer feedforward neural network elm has the advantages of fast learning speed and good generalization performance huang et al 2015 ding et al 2015 alade et al 2017 therefore the elm method has been widely used in various fields liu et al 2018 however this method still has its own shortcomings because the elm is randomly given input weights and hidden layer deviations elm usually requires more hidden layer neurons to achieve the desired accuracy moreover sometimes its generalization ability is weak however using pso to select the input weights and hidden layer deviations of the elm and then calculating the output weights can avoid the above shortcomings to some extent and improve the generalization ability of the elm the pso elm algorithm has been applied in many fields but not gcsi in particular yadav et al 2016 employed pso elm to estimate the cost of an in situ bioremediation system xu et al 2017 used pso elm to predict the porosity of a tuffaceous sandstone reservoir kaloop et al 2019 applied pso elm to predict the resilient modulus of stabilized aggregate bases as well as comparing the accuracy of the predictions obtained by pso elm and an artificial neural network ann algorithm where the results showed that the accuracy was higher with pso elm this study utilizes pso elm to gcsi firstly the pso was used to improve the elm and then the pso elm was used to establish a surrogate model for the simulation model in order to compare the generalization performance of the pso elm and other methods when establish surrogate model the accuracies of the surrogate models established by the artificial neural network ann generalized regression neural network grnn elm and pso elm were compared and the surrogate model with its greater generalization ability was selected for embedding in the optimization model from where it is called during solving the optimization model few studies have considered the uncertainty of the parameters when applying simulation optimization to solve gcsi problems singh and datta 2006 guo et al 2018 zhen et al 2019 although uncertainties clearly exist and they could affect the gcsi results therefore the uncertainty of the parameters is considered in gcsi based on the pso elm in the present study a predictive model which could predict the relationship between the random parameters and the release histories was established by applying pso elm method 2 methodology 2 1 extreme learning machine elm is a kind of machine learning method based on a feedforward neural network huang et al 2015 huang et al 2004 the single hidden layer feedforward neural network in elm consists of an input layer a hidden layer and an output layer the neurons of the input layer and the hidden layer and those of the hidden layer and the output layer are fully connected the input layer has n input variables which are equivalent to n neurons the hidden layer has l neurons the output layer has m output variables which are equivalent to m neurons if there are m arbitrarily different samples x i y i xi xi1 xi2 xin yi yi1 yi2 yin then the output of the feedforward neural network with l neurons and hidden layer excitation function g x can be expressed as 1 f l x i 1 l β i g a i x i b i where a i a i 1 a i 2 a in is the connection input weight between the input layer and the i th neuron of the hidden layer β i β i 1 β i 2 β im is the connection output weight between the output layer and the i th neuron of the hidden layer and b i is the threshold of the i th neuron in the hidden layer if the feedforward neural network with l hidden layer neurons can approximate the m samples with zero error then there exist a i β i b i that satisfy eq 2 and eq 2 can be converted to eq 3 2 f l x y i 3 h β y where h is the output matrix of the hidden layer as given by eq 4 in the elm algorithm the input weight and the thresholds of the hidden layer are randomly determined before training and remain unchanged during the training process so that h is uniquely determined thus the training of the elm network can be transformed into a linear system optimization problem to solve for the connection output weights β as given by eq 5 by solving the optimization problem the connection output weights β can be calculated as given by eq 6 4 h g ω 1 x 1 b 1 g ω l x 1 b l g ω 1 x m b 1 g ω l x m b l m l 5 min β h β y 6 β h y t where h is the moore penrose generalized inverse matrix of the output matrix h after calculating the connection output weights the output corresponding to any different input can be predicted 2 2 particle swarm optimization pso is an optimization method based on swarm intelligence proposed by kennedy and eberhart 1995 the algorithm originates from the study of bird prey behavior the basic idea of pso is to search for the optimal solution to the problem through cooperation and information sharing among individuals in the group in pso each bird is regarded as a particle with a memory function which can remember the best position for which it has searched the characteristics of each particle can be expressed by position fitness and velocity the position of the particle corresponds to the solution of the optimization problem the fitness value of a particle is the value calculated by bringing the current position of the particle into the objective function the velocity of the particles determines the next flight direction and distance of the particles themselves swathi and elwha 2018 mategaonkar et al 2018 the optimal solution to the problem is the optimal position of all the particles after a number of iterations in the solution space the updated position of each particle after each iteration could be the optimal solution of the problem during each iteration update process the particle updates its position by tracking two extreme values one is the optimal solution found by the particle itself this solution is called the individual extremum pbest the other extremum is the optimal solution currently found by the entire population this extremum is the global extremum gbest in d dimensional space consider a population of n particles x x 1 x 2 x n where the position of the i th particle is x i x i 1 x i 2 x id t bring x i into the fitness function f x i to calculate the fitness value of the particle position the velocity of the i th particle is v i v i 1 v i 2 v id t where the pbest of the i th particle is p i p i 1 p i 2 p id t and the gbest of the population is p g p g 1 p g 2 p gd t during the iterative optimization process the particle updates its velocity and position through pbest and gbest 7 v id k 1 ω v id k c 1 r 1 p id k x id k c 2 r 2 p gd k x gd k 8 x id x id v id where ω is the inertial weight which controls how much of the current velocity the i th particle inherits d is the dimension of the solution to be optimized n is the population size k is the current iteration number v id is the particle velocity and c 1 c 2 are acceleration factors which control the velocity calculation to pay more attention to particle experience or group experience r 1 and r 2 are two random numbers with the value range of 0 1 that can increase the degree of search randomness to prevent a blind search by particles the position and velocity are generally limited to x max x max v max v max 2 3 pso elm it is known from eqs 1 to 6 that the output weights are calculated using the input weights and the hidden layer deviations because the elm randomly assigns the input weights and the hidden layer deviations there may be some cases where the deviation of input weight and the hidden layer deviation are 0 this causes some hidden layer neurons to be invalid which makes the elm unable to achieve the ideal accuracy due to insufficient generalization of samples that are not present in the training set to solve these problems pso and elm are combined the pso is used to optimize the input weight and hidden layer deviations of the elm and an optimal elm network is obtained the input weights and hidden layer deviations of the elm are regarded as the particles in the pso and the root mean square error of each individual of the initialized population calculated by the training sample is used as the fitness of the pso han et al 2013 zhang and li 2016 the specific implementation steps are as follows 1 prepare the training samples and determine the dimensions of the input and output i e the number of neurons in the input and output layers of the elm and the number of neurons in the hidden layer 2 generate the initial population produce the appropriate number of particles form the initial population and determine the appropriate acceleration factor and the maximum number of iterations 3 for each individual particle in the population the elm is used to calculate the output weights the fitness value of each particle in the initial population the pbest of the individual particles and the gbest of all particles from the training sample if the conditions for stopping the iterations are not met maximum number of iterations or error less than the threshold then the velocity and position of all particles are updated using eqs 7 and 8 4 when the conditions for stopping the iterations are reached the pso optimized elm network has been obtained 2 4 artificial neural network artificial neural network ann have been used for gcsi for many years singh et al 2004 an ann comprises an input layer hidden layer and output layer anns are regarded as approximators of nonlinear systems and their detailed principles were described by zurada 1992 the newff function in matlab r2014b was used to conduct the feedforward backpropagation ann training process in the present study yadav et al 2016 2 5 generalized regression neural network a generalized regression neural network grnn can approximate the implicit mapping relationship based on the sample data grnn have a high capacity for nonlinear mapping where the number of samples required and the number of artificially controlled parameters for modeling are low the principle of the grnn is described as follows the joint probability density function between the random variables x and y can be expressed as f x y if the measured value of x is x then the relative regression predictive value for x is y 9 y yf x y dy f x y dy f x y can be estimated from the training samples further details of the principles of grnn were described by cigizoglu and alp 2006 2 6 optimization model establishing an optimization model is an essential part of identifying the characteristics of groundwater contamination sources in general an optimization model consists of three parts the objective function the decision variable and the constraints building an optimization model involves three steps 1 determine optimization goals and decision variables 2 determine the objective function expression of the optimization target 3 determine constraints including equality and inequality constraints the optimization goal refers to the purpose of solving the optimization problem decision variables are control variables that have an impact on the optimization goal the optimization goal can be achieved by making changes and designing the decision variables after determining the decision variables and optimization goals the optimization goals must be expressed in the form of objective functions the objective function is the form of the desired goal expressed in terms of the decision variables and it is a criterion for evaluating whether the obtained values of the decision variables meet the specified requirements in the optimization problem the constraint conditions are restrictions on the decision variables often appearing in the form of inequalities or equations the objective function often needs to find the maximum value or minimum value under certain constraints in the optimization problem if the objective function or constraint of the optimization model is a nonlinear system the model is called a nonlinear optimization model the optimization model is presented as follows 10 min f x α g i x σ i 1 2 n h j x 0 j 1 2 m where min f x is the objective function and α and σ are upper and lower bounds of inequality constraints respectively x x 1 x 2 x 3 x t is the vector of decision variables t is the dimension of the decision variables g i x is the inequality constraints β j x is the equality constraints and n and m are the total number of inequality and inequality constraints respectively 3 case study 3 1 site overview in this study a hypothetical groundwater contamination site was used to verify the effectiveness of the research methods described above when applied to gcsi the contaminant at the hypothetical sites is a conservative contaminant that does not undergo biological transformation or chemical changes see fig 1 the case study area was a two dimensional heterogeneous isotropic aquifer with irregular boundaries with three parameter zones and the groundwater flow was transient flow the southeastern and northwest boundaries of the case study area were specified head boundaries the southwestern and northeast boundaries of the case study area were no flow boundaries shown in fig 2 the vertical direction of the case study area received uniform recharge through atmospheric rainfall the initial concentration of contaminant in the case study area was 0 mg l the total simulated time of contamination transport was 12 months with a total of six simulation periods every two months was one simulation period contaminant was released to the aquifer during the first three simulation periods of the simulation and then stopped there were seven observation wells in the case study area distribution of three parameter zones in aquifer locations of observation wells and potential contamination sources are shown in fig 2 the actual contamination source information under two situations in the study area was separately identified the actual parameters of the aquifer are listed in table 1 and the true contamination source information in both situations is shown in table 2 the locations and release histories of contamination sources were regarded as unknown variables and some parameters were regarded as random variables during the process of gcsi 3 2 numerical simulation model a numerical simulation model of groundwater flow and contaminant transport was constructed to describe groundwater and contaminant transport in the groundwater system in the aquifer the governing partial differential equations of groundwater flow and contaminant transport for transient flow in a two dimensional aquifer system are given below singh and datta 2006 zhao et al 2016 the governing partial differential equation of groundwater flow is as follows x i k ij h x j w μ h t x y ω i j 1 2 t 0 where kij is hydraulic conductivity h is hydraulic head μ is specific yield ω is the simulated area range and w is volumetric flux per unit volume the governing partial differential equation of groundwater contaminant transport is as follows c t x i d ij c x j x i u i c r θ x y ω i j 1 2 t 0 u i k ij θ h x i i j 1 2 where θ is porosity c is contaminant concentration dij is the dispersion coefficient ui is the average linear velocity of the groundwater flow and r is a source or sink term the modflow and mt3dms toolboxes of the gms software were used to carry out numerical calculations for groundwater flow and contamination transport numerical simulation models unlike actual research examples hypothetical research cases have no measured value therefore after the numerical simulation model of contamination transport was constructed it was necessary to run this model in the forward direction the simulated contamination concentration of all observation wells at each simulation period was obtained as the measured value in the inverse identification process of groundwater contamination sources and the locations and release histories of contamination sources were regarded as unknown variables to be identified the measured values of the observation wells were obtained by the forward running contamination transport numerical simulation model when actual contamination sources information shown in table 2 were input simulation model shown in fig 3 3 3 sensitivity analysis the gcsi process was performed after obtaining all of the measured values for the observation wells the objective uncertainty in the parameters could have affected the gcsi results so the local sensitivity analysis method was conducted where the two parameters with greater impacts on the model output were selected as random variables for the model and the other parameters were treated as deterministic variables the sensitivity of each parameter was calculated using the following formula 14 s k y α k y i α k δ α k y i α k 1 δ α k α k 1 where s k is the sensitivity α k is one of the input model parameter values δ α k is the variation in α k y i α k is the output of the model when the parameter is α k and y i α k δ α k is the output of the model when the parameter is α k δ α k sensitivity analysis showed that the two most sensitive parameters were the hydraulic conductivity and longitudinal dispersivity fig 4 therefore eighty groups of hydraulic conductivity and longitudinal dispersivity a total of four parameters for each group were sampled using the latin hypercube method a common sampling method detailed principle of the latin hypercube method can be found in parnianifard et al 2020 the first group of random parameters and other deterministic parameters the deterministic parameters remained unchanged throughout the study as shown in table 1 were used as inputs for the numerical simulation model the distributions of the random parameters are shown in table 3 the current numerical simulation model was then employed to perform the operations described in sections 3 4 and 3 5 3 4 surrogate models of the numerical simulation model the numerical simulation model was embedded in the optimization model as an equality constraint to ensure that contaminant transport obeyed the groundwater contaminant transport law during the optimization model solving process however during iterative calculations of the optimization model the numerical simulation model had to be called hundreds and thousands of times which would generate a large computational load and take an excessive amount of time hou and lu 2018 luo et al 2013 to avoid this shortcoming a surrogate model of the numerical simulation model was constructed a surrogate model with satisfactory accuracy has almost the same inputs and outputs as the simulation model it is a good choice to use the surrogate model instead of the simulation model as the optimization model to embed for calculation in this study the concentrations of each observation well in each simulation period were taken as the output variables of the surrogate model and the release intensities of each potential contamination source were regarded as the input variables for the surrogate model a total of nine input release intensity variables the release intensities of each potential contamination source were sampled by using the latin hypercube method in their feasible domains the feasible domain range of release intensity was 0 400 mg l release intensity values for 100 groups were sampled and were sequentially input into the simulation model and the corresponding output concentrations of all observation wells in each period were obtained by running the simulation model eighty groups of input output data pairs were selected as training samples for the surrogate model and the remaining twenty groups of input output data were used as test samples for the surrogate model based on the training samples ann grnn elm and pso elm were used to establish surrogate models the established surrogate models could be used to predict the output corresponding to any input the accuracy of the surrogate models were tested using three statistics including the mean relative error mre the root mean square error rmsr and the coefficient of determination r2 mre rmsr and r2 were calculated respectively as follows mre 1 n i 1 n y i y i y i 100 16 rmsr i 1 n y i y i 2 n 17 r 2 1 i 1 n y i y i 2 i 1 n y i y i 2 where y i is the output value of the i th sample in the contaminant transport numerical simulation model y i is the output value of the i th sample in the surrogate model and y i is the average value of n samples output from the simulation model the smaller the mre the smaller the rmse and the closer r 2 is to 1 the higher is the approximation accuracy of the surrogate model in simulating the output of the simulation model 3 5 nonlinear optimization model the locations and release histories of contamination sources were identified in this study the release history refers to the contaminant release intensity at each simulation period atmadja and bagtzoglou 2001 sun et al 2006 the release histories of the contamination sources were decision variables of the optimization model the fitting error between the measured and simulated concentrations of contaminant in the observation wells at each simulation period was minimized as the objective function the contaminant transport numerical simulation model was embedded in the optimization model as an equality constraint replacing the simulation model by the surrogate model the feasible domains of release histories of the contamination sources were inequality constraints the specific expression of the nonlinear optimization model used to identify the characteristics of contamination sources is 18 min z q 1 q 2 q 3 t 1 6 k 1 7 c k t t c k t 0 2 0 q m 400 m 1 2 3 q m q 1 m q 2 m q im i c k t t f q m 1 2 3 where q m is the release intensity of contamination sources during each release period c k t t is the simulated concentration of the contaminant at the observation point and c k t 0 is the measured contaminant concentration at the observation point c k t t f q m is the surrogate model of the simulation model the optimization model was solved to identify the location and release history of the contamination sources 3 6 establishment of predictive model after performing the procedures described in sections 3 4 and 3 5 based on the numerical simulation model corresponding to the first group of random parameters the same process was conducted based on the numerical simulation model corresponding to the second group of random parameters until the 80th group of random parameters the release histories of the contamination sources corresponding to eighty groups of random parameters were then obtained in this manner based on these eighty groups of random parameters and release histories a predictive model representing the relationships between the random parameters and release histories was established with the pso elm method the first sixty groups were used for training the predictive model the last twenty groups were used to test the accuracy of the predictive model 4 results 4 1 comparative analysis of the accuracy of the surrogate models ann grnn elm and pso elm were all used to establish surrogate models for the simulation model e g for the simulation model corresponding to one group of random parameters a total of eighty groups of simulation models were generated the accuracies of the ann surrogate model grnn surrogate model elm surrogate model and pso elm surrogate model were compared and analyzed using mre rmsr and r2 then the surrogate model with higher accuracy was selected for embedding in the optimization model twenty groups of input samples were input into the simulation model ann surrogate model grnn surrogate model elm surrogate model and pso elm surrogate model respectively and then twenty groups of output data corresponding to the input of the simulation model and the four surrogate models were obtained the next step was to test and compare the accuracy of the four surrogate models table 4 shows mre r2 and rmse for the seven observation wells from the ann grnn elm and pso elm surrogate models to clarify the accuracy comparison of the four surrogate models contrast histograms of mre fig 5 rmse fig 6 and r2 fig 7 were plotted in order to intuitively demonstrate the improvements twenty groups of output data related to the seven observation wells obtained from the simulation model elm surrogate model and pso elm surrogate model were plotted as scatter graphs for a total of six simulation periods taking sp4 as an example table 4 and fig 8 show that the performance of elm was improved by pso table 4 and figs 5 8 show that the pso elm surrogate model has a higher coefficient of determination than the other four surrogate models the minimum coefficient of determination for pso elm was 0 9988 which is very close to 1 compared with the other surrogate model the mre and rmse of the pso elm surrogate model were smaller therefore the pso elm surrogate model provided a better approximation to the simulation model and had higher accuracy therefore the pso elm surrogate model was selected for embedding in the optimization model to identify the location and release history of groundwater contamination sources 4 2 results of solving the optimization model the pso elm surrogate model with its higher accuracy was embedded into the optimization model and a genetic algorithm zwickl 2008 guo et al 2018 was used to solve the optimization model to identify the true locations and release histories of contamination sources the locations of contamination sources was determined by the release intensity when the release intensity of one of the three locations was zero at each simulation period it indicated that no actual contamination source was present the contamination source characteristics were then identified in the two situations described above and the identification results were as follows e g for the optimization model solution corresponding to one group of random parameters a total of eighty groups of optimization models were generated it required about 7 3 min to solving the optimization model 1000 iterations when the surrogate model was embedded in optimization model but it required about 166 7 min to solving the optimization model when the simulation model was embedded in optimization model thus the calculation time saved by applying the surrogate model was about 95 6 situation 1 table 5 show that the contaminant release intensity in each release period of s2 is close to zero it indicated two of the three potential contamination source locations were actual contamination sources which were s1 and s3 their release intensity were shown in table 5 situation 2 table 6 show that all three potential contamination source locations were actual contamination sources and their release intensity were shown in table 6 the locations and release histories of contamination sources were identified by solving the optimization model applying the same method the eighty optimization models were solved successively until release histories corresponding to the eighty groups of random parameters were obtained 4 3 accuracy analysis of predictive model pso elm has good generalization performance therefore pso elm was applied to establish a predictive model that reflected the relationship between the random parameters and the contamination sources release histories twenty groups of release histories and their corresponding random parameters test samples were used to calculate mre rmsr and r2 in order to test the accuracy of the predictive model table 7 and fig 9 show that both mre and rmsr were very small and r2 was 0 99 thereby indicating that the predictive model obtained high accuracy and it could predict the release histories corresponding to different random parameters see table 8 4 4 analysis of contamination source identification results after establishing the predictive model 10 000 groups of hydraulic conductivity and longitudinal dispersivity data were sampled again and used as inputs for the predictive model the predictive model generated 10 000 groups of release histories for each contamination source statistical analyses were conducted based on the 10 000 groups of release histories for each contamination source establishing 10 000 optimization models and then solving them in turn required 73 000 min by contrast applying the predictive model to predict the outputs corresponding to 10 000 groups of inputs required about 5 s thus the savings in terms of the computational time and human resources were considerable situation 1 using the 10 000 groups of release histories histograms and probability density maps were generated for each contamination source the distributions of the release histories considering the uncertainty of the parameters are shown in fig 10 the probability densities corresponding to each of the release histories are shown in fig 11 where the point with the highest probability density in the release history for each contamination source was calculated as the identification result decision makers can also select the mean median and maximum values according to their requirements as the basis for decisions table 9 and figs 10 and 11 show that compared with s1 and s3 very little of the contaminant was released at s2 therefore the contamination sources were located at s1 and s3 when the release histories corresponding to the highest probability density were used as the identification results the relative error between the identification results and the actual values was less than 5 situation 2 10 000 groups of release histories for each contamination source were treated in the same manner as in situation 1 table 10 and figs 12 and 13 show that the contaminant was released from all three sources when the release histories corresponding to the highest probability density were regarded as the identification results the relative error between the identification results and the actual values did not exceed 9 5 discussion the uncertainty of the parameters can affect the gcsi results however this problem was not considered in many previous gcsi studies based on the simulation optimization method and thus the gcsi identification results were not necessarily reliable considering uncertainty associated with the parameters in gcsi the identification results must include a variety of possibilities to cover as many of the actual contamination sources as possible and provide decision makers with suitable options applying pso to improve elm can improve the generalization performance of elm to some extent and obtain the optimal training network while maintaining stability if the nonlinearity of the site simulation model increases significantly or the input dimensions of the surrogate model increase significantly the accuracy of the surrogate model established using the pso elm method may be reduced the accuracy may be reduced further with the traditional ann therefore although the pso elm method can obtain good results the next improvement should involve the application of deep learning neural network to perform gcsi 6 conclusions a new method is proposed in this paper to establish surrogate models and a predictive model by combining particle swarm optimization pso with an extreme learning machine elm the optimization model based on the pso elm surrogate model was used to identify the locations and release histories of contamination sources the predictive model based on pso elm was used to predict the release histories corresponding to thousands of random parameters the following three conclusions can be made based on the results obtained in this study 1 in the past the input weights and hidden layer deviations of elm were assigned randomly when using the elm to set up a surrogate model for the simulation model whereas the output weights of elm were calculated using the input weights and hidden layer deviations during the calculations some cases may occur where the input weights and the hidden layer deviations are zero resulting in some hidden layer neurons being ineffective and having insufficient generalization ability for samples not appearing in the training set in this study a pso elm model was proposed pso was used to optimize the selection of input weights and hidden layer deviations for elm based on this method a surrogate model of a simulation model and a predictive model which reflected the relationship between the random parameters and the contamination sources release history were established 2 the pso elm surrogate model with its high degree of approximation accuracy to the simulation model was embedded in the optimization model when the simulation optimization method was used for gcsi this approach can alleviate computational disaster by reducing computational load and saving calculation time in the process of solving the optimization model by solving the nonlinear optimization model the locations and release histories of contamination sources can be identified 3 in order to consider the uncertainty of the parameters a predictive model reflecting the relationships between the random parameters and the release histories of the contamination sources was established based on pso elm the predictive model considers the impact of the uncertainty of the parameters on the gcsi identification results as well as reducing the computational time and human resources required credit authorship contribution statement jiuhui li conceptualization methodology software writing original draft wenxi lu conceptualization writing review editing supervision project administration han wang validation formal analysis yue fan validation data curation zhenbo chang software validation data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to acknowledge the support provided by the national natural science foundation of china 41672232 and the jilin province science and technology development project grant no 20170101066jc special gratitude is given to the journal editors for their efforts to evaluate the work and the valuable comments of the anonymous reviewers are also greatly acknowledged 
5634,laboratory measurements to derive the soil water retention curve θ ψ are time consuming and expensive we present a cost effective alternative using particle size distribution psd and saturated water content we propose a novel physical conceptual intergranular mixing psd model imp model which derives θ ψ from psd exploiting the relation between particle size and pore size distributions and the intergranular arrangement of the soil particles the imp model successfully predicts θ ψ for fine texture soil which is the most challenging soil texture to be modelled with our novel model reliable θ ψ can be obtained using only three general fitting parameters without needing to assume any particular type of soil particle packing with mean nash sutcliffe efficiency coefficient of 0 92 for 259 soils the imp model can accurately predict θ ψ for fine texture soils because a it implements an intergranular mixing function that accounts for soil pores not all being perfectly spherical and takes into consideration the intergranular rearrangement mixing of the particles which allows neighbouring particles to have different sizes resulting in variations in pore radius and pore shape of the corresponding pore fraction b it overcomes the absence of psd data for sizes smaller than the clay fraction by developing a normalised form of the young laplace capillary equation and c the residual pore volume accounting for water strongly bound to solid particles or in very small pores is incorporated as a function of the clay fraction keywords particle size distribution pore size distribution water retention curve intergranular mixing kosugi model 1 introduction the soil water retention curve θ ψ is fundamental in describing the storage and transmission of water in the soil the θ ψ relates the soil water content θ l3 l 3 to the soil matric potential or suction ψ l in a distinct relationship for different soils the θ ψ is experimentally determined by measuring the amount of water that remains in the soil at a certain suction measurements normally range between saturation and permanent wilting point 1500 kpa because laboratory measurements are time consuming and expensive estimations of the θ ψ can alternatively be derived from soil physical properties different approaches include directly estimating points from the θ ψ e g balland and pollacco 2008 pollacco 2008 or estimating the whole θ ψ curve using empirical pedotransfer functions mcneill et al 2018 van looy et al 2017 derived from surrogate soil measurements one promising approach is to derive the θ ψ curve from the soil particle size distribution psd based on the similarity between the cumulative particle size distribution p s d and the cumulative pore size distribution p o r e s d the latter corresponds to θ ψ e g arya and paris 1981 chang et al 2019 mohammadi and vanclooster 2011 nasta et al 2013 psd is a fundamental soil physical characteristic used for soil classification and for the estimation of other physical properties such as hydraulic and thermal characteristics yang et al 2019 the routinely used sieve and sediment method for measuring psd separates larger particle fractions by wet sieving then smaller particle fractions by sedimentation klute 1986 and assumes sphericity of the individual soil particles and a constant particle density for all size ranges arya and paris 1981 developed the first conceptual model to derive θ ψ from psd using a semi physical approach in which pore size was associated with pore volume and determined by scaling the pore length pore lengths based on spherical particles were scaled using an empirical scaling parameter further formulations of this empirical scaling parameter have been proposed to improve the prediction of the θ ψ arya et al 2008 alternative semi physical models have been proposed using empirical parameters and specific assumptions relating to the relationship between particle size and pore size nevertheless these approaches fail to predict θ ψ from psd for loamy and fine texture soils e g haverkamp and parlange 1986 zhuang et al 2001 nimmo et al 2007 mohammadi and vanclooster 2011 chang et al 2019 to relate p s d to p o r e s d and its corresponding θ ψ mohammadi and vanclooster 2011 presented a simple physical empirical conceptual model to retrieve the θ ψ from psd the soil is described as an ensemble of particles of different sizes where for each particle size the void ratio the ratio of volume of voids to the volume of solids is related to particle size and the type of packing of the soil particles the size of the particle is related to the effective pore size that forms between the particles and the integration over all particle sizes then allows calculation of p o r e s d as a function of p s d several types of packing were considered including close packed cubic cubical tetrahedral tetragonal spheroidal pyramidal tetrahedral and body centred cubic finally pore size is related to ψ through the young laplace capillary equation to provide θ ψ however in their approach mohammadi and vanclooster 2011 assumed the same type of packing for all particle sizes making the void ratio constant regardless of particle size this is a common assumption e g arya and paris 1981 that simplifies the derivation of the θ ψ when linking p s d to the equivalent p o r e s d since the ratio between particle size and pore size is constant when the geometry of the pores is considered similar to the geometry of the particles however in a soil the geometry of the pores can vary with the size of the particles leading to a variable relationship between the particle radius and pore radius the purpose of this study is to develop a model that can account for the possibility of a pore system formed by neighbours particles of different sizes in this study we hypothesize that the geometry of the pores depends on the size of the soil particles and the intergranular mixing between particles of different sizes the intergranular mixing accounts for the organisation of neighbouring soil particles of different sizes we therefore propose an intergranular mixing psd imp model we revisit the conceptual model of mohammadi and vanclooster 2011 considering the intergranular mixing of particle sizes and propose an expression to account for it the predicted θ ψ from a set of psd data points using the traditional sieve and sediment method is compared to the θ ψ from laboratory data using the drying curve the proposed model is compared with the recent chang et al 2019 model which is currently one the models providing better agreement between θ ψ from laboratory data and predicted θ ψ from psd this model outperforms that of meskini vishkaee et al 2014 a modification of the mohammadi and vanclooster 2011 model that improved it by including a soil particle scaling factor the manuscript is organised as follows section 2 outlines the theory behind the proposed model briefly describes the model used for comparison and the fundamental physical approach on which our intergranular mixing approach is based section 3 presents the experimental data and the numerical computations used to derive θ ψ from the laboratory measurements and from the imp model section 4 evaluates the model performance and illustrates the relevance of the processes considered and section 5 summarises the key conclusions 2 theory the p s d is divided into m fractions depending on the measurement method or available data the mass ratio and the representative particle radius for the i th fraction are w i m m 1 and r i l respectively i m solid particles within each fraction are packed considering uniform sized spherical particles with the same bulk density as the soil as proposed by arya and paris 1981 the volumetric water content θ i l3 l 3 is obtained by summation of pore volumes that progressively fill up with water from the smallest fraction to the corresponding soil water content the p s d is used to compute θ i by multiplying the saturated soil water content θ s l3 l 3 by the cumulative mass ratio of particles up to the i th fraction 1 θ i θ s j 1 i w j where θ s is the saturated soil water content and w i is the mass ratio which represents the particle radius for the i th fraction r i i m the determination of the θ ψ relies on the fact that for a given matric potential ψ i l only part of the pore fractions are activated this activation is ruled by the young laplace capillary equation which takes the following general form tuller et al 1999 2 ψ i c i a i γ cos θ ρ w g where ρ w m l 3 is the density of water g l t 2 is the acceleration due to gravity c i l and a i l2 correspond respectively to the circumference and the cross sectional area of the narrowest part of the pore for the corresponding fraction γ m t 2 is the surface tension at the air water interface and θ is the contact angle between the soil particle and the water the ratio a i c i has the dimension of a length and equals r i 2 for a perfectly cylindrical pore of radius r i l therefore the young laplace capillary equation is written as 3 ψ i 2 γ cos θ ρ w g r i y r i where y equals 14 9 mm2 for pure water at 20 c and a contact angle of 0 γ 0 0728 kg s 2 ρ w 998 2067 kg m 3 and g 9 8067 m s 2 2 1 chang et al 2019 model when eq 1 is used to compute the cumulative pore volume the residual pore fraction is greater than the corresponding clay fraction this is notable for small particle sizes that become embedded within the pores formed by the larger particles increasing the pore volume formed by the smaller particles which are protected from compaction and reducing the pore volume fraction associated with large particles filling up the space of bigger pores by small particles fernández gálvez and barahona 2005 to account for the increase in the pore volume by the smallest particle size corresponding to the clay fraction chang et al 2019 introduced an empirical relationship derived for a range of contrasting soil textures taken from the unsoda database 4 θ 1 θ s c l a y η with η optimised θ i θ 1 θ s j 2 i w i cla y η c l a y w i j 2 m w j for i 1 where η is a fitting parameter found equal to 0 516 θ 1 l3 l 3 is the residual pore fraction and clay m m 1 refers to the percentage of the clay fraction to relate pore radius r to ψ chang et al 2019 used a linear relationship between r and associated particle radius r using the scale factor of 0 3 as indicated here 5 ψ i y 0 3 r i although chang et al 2019 improved estimates of θ ψ compared to the mohammadi and vanclooster 2011 model and its scaled version meskini vishkaee et al 2014 specifically developed for the van genuchten 1980 hydraulic model it still shows poor predictions for silty soils which we will address in this paper 2 2 mohammadi and vanclooster 2011 model for each particle fraction w i with a representative particle radius r i the assemblage of these particles forms a pore fraction for which the pore radius r i can be geometrically related to the particle radius in a close packed cubic assemblage for a particle radius r i where eight spherical particles contribute to each assembly the pore volume for a single assembly is the total volume of the assembly 4 r i 3 minus the solid volume of the corresponding spherical particles 8 4 π r i 3 3 this assumption implies that neighbouring particles are of similar size within each particle fraction to account for alternative structures where the number of spherical particles contributing to a single assembly differs from eight mohammadi and vanclooster 2011 introduced a coefficient that depends on the state of packing p state therefore the void ratio e of the assemblage takes the following form 6 e 4 r i 3 8 p state 4 π r i 3 3 8 p state 4 π r i 3 3 6 π p state π p state then 7 p state 6 π 1 e 6 π 1 ϕ where ϕ is the total porosity and e is the void ratio which relates to the solid particle density ρ s m l 3 and the soil bulk density ρ b m l 3 by 8 e ρ s ρ b ρ b mohammadi and vanclooster 2011 assumed that for soil particles in the i th size fraction particularly for a close packed cubic assemblage with uniform size spherical particles of radius r i the ratio c i a i is 9 c i a i 2 π r i p state 2 r i 2 π r i 2 2 π p state 4 π r i for other types of soil particle packing the ratio can be written in its general form as 10 c i a i p type p state r i where p type describes the packing type which mohammadi and vanclooster 2011 found to have an average value of 7 3 corresponding to close packed cubic packing p type can vary between 2 866 and 19 470 depending on the geometric characteristics of the packing of the soil particles which are assumed to be spherical different particle size fractions may have different types of packing which then modifies the number of spherical particles devoted to each assemblage mohammadi and vanclooster 2011 compute ψ for a general pore with cross section shape in the soil by 11 ψ i p state p type r i γ cos θ ρ w g p state p type y 2 r i 3 1 ϕ p type y π r i considering eq 3 this leads to the following relation between particle radius r i and pore radius r i 12 r i 2 r i p state p type π r i 3 1 ϕ p type eq 5 is similar to eq 11 with similar scale factors when p type corresponds to the close packed cubic packing 2 3 novel model to predict θ ψ from psd using principles of soil physics the uncertainty associated with the packing type is eliminated by constraining the total volume of spherical pores to the soil water content at saturation θ s the maximum amount of water in the soil system for perfectly spherical pores ξ 0 can be calculated from the sum of all pore volumes up to the maximum pore size using the following expression 13 θ s 4 π 3 j 1 m n j r j 3 ξ where n j m 1 is the number of spherical pores for each fraction of the pore size distribution and ξ with values in the range 0 3 accounts for soil pores not all being perfectly spherical ξ is further discussed in section 2 3 1 for the limiting case when ξ 0 the pores are perfectly spherical pollacco et al 2017 2013 and neighbouring particles are of similar size mohammadi and vanclooster 2011 the number of spherical pores for each pore fraction is assumed to be equal to the number of spherical particles for each fraction which is corrected by ξ and therefore calculated dividing the mass ratio by the total mass of the corresponding fraction 14 n j 3 w j 4 π ρ s r j 3 where for the calculation of n j for each r j it is assumed that ρ s is equal for all particle sizes combining eq 13 with 12 and 14 gives 15 θ s 1 ρ s π 3 1 ϕ p type 3 ξ j 1 m w j r j ξ from where p type can be isolated 16 p type π 3 1 ϕ 1 θ s ρ s j 1 m w j r j ξ 1 3 ξ the soil water content of the i th fraction θ i can be obtained from successive summations corresponding to particle radius up to i th as for the total volume of pores in eq 13 17 θ i 4 π 3 j 1 i n j r j 3 ξ replacing r i by r i using eq 12 substituting n i from eq 14 and p type from eq 16 leads to 18 θ i θ s j 1 i w j r j ξ j 1 m w j r j ξ when ξ 0 this expression reduces to eq 1 standard psd measurements lack data below 0 001 mm effective radius limiting the practicality of deriving θ in dry conditions high ψ the residual particle size fraction that accounts for the contribution of the residual soil water content θ r psd l3 l 3 is limited by the smallest measured particle fraction which can be related to the clay fraction e g pollacco et al 2008b chang et al 2019 therefore for a better estimation of the soil water content the expression is modified to 19 θ i θ s θ r p s d j 1 i w j r j ξ j 1 m w j r j ξ θ r p s d the relationship between θ r psd and the soil clay fraction is described in section 2 3 2 the soil matric potential corresponding to particle radius up to the i th fraction ψ i is described by chang et al 2019 and mohammadi and vanclooster 2011 in the form of the young laplace capillary equation using quite similar scale factors as those in eqs 5 and 11 respectively because routine methods cannot measure particle sizes smaller than the clay fraction expressions based on the young laplace capillary equation fail to describe ψ for pore fractions corresponding to smaller particles assemblages as shown in fig 1 for example for r min 0 001 mm gives ψ 500 kpa which does not take into account the large suction corresponding to the very small pores therefore an alternative normalized expression of the young laplace capillary equation is proposed in which a linear relation between pore radius and particle radius is considered 20 ψ i ψ max y r i y r max y r min y r max λ ψ max 3 1 ϕ p type y π r i 3 1 ϕ p type y π r max 3 1 ϕ p type y π r min 3 1 ϕ p type y π r max λ ψ max 1 r i 1 r max 1 r min 1 r max λ where ψ max represents the maximum value of the matric potential which corresponds to a value marginally larger than wilting point and is set to 1600 kpa to account for the feasible range of matric potential y from eq 3 corresponds to the constant in the young laplace capillary equation 14 9 mm2 r max and r min are the maximum and minimum pore radius r max and r min are the maximum and minimum particle radius determined experimentally and λ is a shape parameter to account for the fact that the correction for ψ only applies for the smaller particles fig 1 compares different expressions that relate ψ to r based on the young laplace capillary equation used by chang et al 2019 eq 5 and the normalized form eq 20 for cases when λ equals 1 and 2 r min corresponds to the clay particle size with an effective radius below 0 001 mm the proposed normalized expression differs from the classic approximation at smaller particle sizes for λ 1 differences can be seen from the very fine sand fraction particle radius below 0 1 mm while for λ 2 the curves start to diverge from the very fine silt fraction particle radius below 0 003 mm which gives a better physical description of ψ such that at r min 0 001 mm then ψ 1500 kpa 2 3 1 novel intergranular mixing function from psd as previously indicated ξ in eq 19 is interpreted as a correction to account for the fact that not all soil pores are perfectly spherical we modify ξ such that it could be interpreted as an intergranular mixing function that accounts not only for the non spherical shape of the soil pores but also for the intergranular rearrangement mixing of the particles in a soil therefore we hypothesise that ξ could be expressed as a function of effective r i using the following expression which is introduced into eq 19 21 ξ r i ξ 1 exp r i ξ 2 where ξ 1 and ξ 2 are intergranular mixing parameters to account for intergranular mixing of the particles depending on their effective size pores formed between particles may be of different sizes we consider that small pores are surrounded by small particles and larger pores are surrounded by large particles while medium size pores consist of a mixture of small and large particles to illustrate this concept fig 2 plots r i ξ r i as a function of r i where r i ξ r i is the weighting function applied to w i in eq 19 as a function of r i for optimal values of ξ 1 and ξ 2 the bell shape results in larger corrections for moderate particle sizes in fig 2 at around 0 02 mm moderate sized particles result from a mixed size range of particles polydisperse decreasing the passages of the pore system pollacco et al 2013 2017 and therefore requiring a higher suction for the water to be drained with a consequent higher correction the arrangement of the soil particles in a unit volume can have neighbouring particles of different sizes which results in variations in pore radius and pore shape of the corresponding pore fraction the bell shape can be shifted depending on the degree of mixing fig 2 where increasing smaller particles in a polydisperse soil results in higher mixing when the amount of smaller particles increases the correction spreads to a wider range of larger particles that is the width of the bell increases in order to take this effect into account we vary ξ 2 based on the psd using the following proposed expression 22 ξ 2 β 1 exp β 2 i 1 p w i where β 1 and β 2 are two additional fitting parameters and p is a particle distribution fraction that is selected such that ξ 2 is correlated to the optimal ξ 2 derived for individual soils 2 3 2 deriving θ r from psd the residual soil water content θ r l3l 3 is a parameter indicating the amount of water left in the soil at relatively high suction it can be derived as a fitting parameter from the θ ψ fixing θ r to a constant value close to zero results in significant errors in the estimation of θ ψ especially for soils with significant clay fraction e g lee and ro 2014 mohammadi and meskini vishkaee 2013 therefore predicting θ r from psd is required for the estimation of θ r and subsequently a better prediction of the θ ψ a relationship between the residual pore fraction and clay content is derived as follows 23 θ r p s d θ r m a x 1 exp α 1 c l a y α 2 where θ r m a x is the maximum value allowed for θ r that was found to be satisfactory when set at 0 25 and α 1 and α 2 are two empirical parameters this is described in fig 3 3 material and methods 3 1 experimental data 3 1 1 sites soils and profiles description soil samples n 259 corresponding to 46 soil profiles were collected in canterbury new zealand sampled sites included irrigated and non irrigated pastoral farming land mostly grazed by dairy cattle but including mixed sheep and cattle grazed pastures rainfall across the sites varied from 550 to 800 mm per year soil parent material was sediments derived from quartzo feldspathic hard sandstone deposited as either river alluvium or windblown loess landcare research 2019 schmidt et al 2005 previous research has shown these sediments to have a relatively consistent mineralogy across the region with the sand fraction dominated by quartz and feldspar and the clay fraction by mica and chlorite bruce 1984 rijkse 1985 this relatively consistent parent material across the sample set is an advantage for develop the theory underpinning the imp model because it minimizes the possible complex effects of contrasting mineralogy on the soil hydraulic functions as well the effects of more complex mineralogy on the reliability of laboratory measurements such as shrink swell clays or amorphous volcanic minerals allbrook 1993 mcneill et al 2018 although beyond the scope of this paper the imp approach taken here should be adaptable to account for the effects of different mineralogy on pore geometry because it explicitly incorporates the effects of intergranular mixing of particles of different sizes all soils in this study had at least 60 cm depth of fine earth soil material with most sites classifying to the pallic soil order in the new zealand soil classification hewitt 2010 correlating in soil taxonomy to haplusteps and humustepts great groups fourteen sites had younger soils that classified to the recent soil order hewitt 2010 correlating to haplusteps and ustifluvent great groups variation of particle size occurs in these soils due to factors such as the distance from the river source coarser textures near source nature of deposition loess soils often have a higher silt content and degree of weathering with older soils having more compact subsoils and sometimes greater clay content due to argillisation processes soil was sampled in 10 cm increments to 60 cm depth at each increment two soil cores were collected a large core of 589 cm3 10 cm diameter by 7 5 cm depth used for unsaturated hydraulic conductivity measurements and a small core of 59 cm3 5 cm diameter by 3 cm depth used for water retention measurements at the same depth increments and immediately beside the soil cores a bulk sample was collected for particle size and chemistry measurement to ensure consistent soil moisture conditions at all sites water was infiltrated two days prior to sampling for each core that was sampled a column of soil was created by sitting a core liner on the soil surface and carefully carving down around the core with a sharp knife leaving the core sitting on a pedestal a few mm wider than itself soil core liners were slowly and carefully pushed down into the soil while trimming the sides of the pedestal this process prevented any disturbance or damage to the soil structure ensuring that the properties of the cores that were analysed were the same as the soil in situ at the sampling site all cores were immediately wrapped in plastic film packed into crates with foam lining and stored at 4 c until laboratory measurement could occur 3 1 2 soil physical measurements soil core preparation bulk density particle density water retention and unsaturated hydraulic conductivity were measured at the manaaki whenua national soil physics laboratory following the standard methods used in new zealand gradwell 1972 gradwell and birrell 1979 claydon 1989 these methods are summarised below particle density was determined for each depth increment as described in gradwell and birrell 1979 particle density values ranged from 2 52 g cm3 to 2 75 g cm3 standard deviation of 0 05 g cm3 with topsoil values slightly lower than that found in subsoil bulk density was measured for both large and small cores following the water release and unsaturated conductivity measurements dry soil weight was measured after oven drying at 105 c for 24 h despite the differences in sample volume the correlation between large cores and small core bulk density measurements shows a coefficient of determination of 0 842 with a deviation from the 1 1 line lower than 0 5 slope 0 995 the particle size distribution of the soil fine earth fraction 2 00 mm was measured by wet sieving and the pipette method as described in claydon 1989 samples were pre treated to remove organic matter and calcium carbonate if necessary and then dispersed by ultrasonic vibration and a chemical dispersant agent the coarser fraction 0 063 mm was wet sieved dried and shaken through a stack of sieves between sizes 2 00 mm and 0 063 mm the remaining soil 0 063 mm was suspended in a column and after initial shaking pipette samples are drawn at various times from a set depth to determine the concentration of particles following stokes equation the soils collected had loamy silt sandy loam silt loam and silty clay texture classes according to new zealand soil classification milne et al 1995 fig 4 presents the textural triangle corresponding to the collected samples water retention values were measured at 0 4 0 7 1 5 10 20 40 100 and 1500 kpa for the small cores measurements 10 kpa suction were on high flow ceramic plates with suction applied by a hanging water column measurements above 10 kpa suction were made using pressure chambers gradwell and birrell 1979 additional measurements taken on large cores at 5 and 10 kpa showed high correlation with values obtained for the small cores with coefficients of determinations of 0 883 slope 1 007 and 0 892 slope 1 001 respectively for representativeness and to better capture the soil structure the large core bulk density data were used to convert gravimetric soil water content into the corresponding volumetric values saturated water content θ s was obtained from the soil porosity ϕ derived for the large cores using the soil particle density and bulk density the θ s is related to ϕ by a multiplying factor representing the ratio of measured saturated water content to calculated porosity out of the measured bulk density θ s ε ϕ where ε is set to 0 95 slightly increasing the goodness of the fit of the hydraulic parameters for a limited number of samples with water retention value at 0 4 kpa higher than porosity the small core bulk density was used instead to measure unsaturated hydraulic conductivity the large cores were trimmed saturated and then equilibrated to 0 1 0 4 0 7 and 1 kpa suction with a buchner funnel apparatus as described in cook et al 1993 unsaturated hydraulic conductivity was then measured using disc permeameters set to equivalent suctions for each measurement cook et al 1993 3 2 kosugi hydraulic model the θ ψ is often expressed as a close form unimodal function representing the relationship between θ and ψ e g brooks and corey 1964 clapp and hornberger 1978 van genuchten 1980 among these functions the one proposed by kosugi 1996 has the advantage of having parameters with a direct physical meaning in relation to the soil pore size distribution e g hayashi et al 2009 pollacco et al 2013 2017 the unimodal lognormal distribution of pores in the soil matrix leads to the kosugi model for the θ ψ 24 θ 1 2 θ s θ r erfc ln ψ ln ψ m σ 2 θ r where θ r is the residual volumetric water content e r f c is the complementary error function while ψ m l and σ are the shape parameters of the water retention curve in a physical sense ln ψ m refers to the median of the lognormal distribution of the matric potential which corresponds to the logarithmic median of the effective soil pore radius through the young laplace capillary equation ln r m and σ is the standard deviation of the log transformed soil pore radius the unsaturated hydraulic conductivity function for the kosugi model can be written as 25 k s e k s s e e r f c 1 2 erfc 1 2 s e σ 2 2 where k s l t 1 is the saturated hydraulic conductivity and s e refers to the effective saturation 26 s e θ θ r θ s θ r values derived from the fit of the experimental data to the kosugi hydraulic model for the individual soils are considered as observed data for the fitting of the psd models 3 3 objective function and goodness of fit the fitting process used to estimate the parameters used a robust global optimizer blackboxoptim https github com robertfeldt blackboxoptim jl written in the julia language bezanson et al 2017 this procedure used an objective function and goodness of fit defined in the following sections 3 3 1 inverting procedure to derive θ ψ from experimental data the minimization process between the observed and the fitted values used an objective function o f kg see below that includes information from both the water retention θ ψ and hydraulic conductivity k ψ data in order to avoid problems of non uniqueness the ln transformation in the second term of the o f kg puts relatively more weight on the lower values of k θ to minimize the bias toward high conductivity and also takes into account the larger uncertainties in measuring k θ as it increases pollacco et al 2013 the feasible range of parameters used for the fit is set according to fernández gálvez et al 2019 the o f kg is computed as follows 27 o f kg i 1 l θ ψ ob s i θ ψ k g i 2 i 1 l θ ψ ob s i θ ψ obs 2 i 1 k ln 1 k θ ob s i ln 1 k θ k g i 2 i 1 k ln 1 k θ ob s i ln 1 k θ obs 2 where l and k refer to the total number of experimentally measured data for the water retention and the unsaturated hydraulic conductivity curves respectively θ ψ ob s i and k θ ob s i correspond to the experimental values measured for the θ ψ and hydraulic conductivity function respectively and θ ψ k g i and k θ k g i correspond to fitted values of the kosugi model the fitted soil hydraulic parameters are therefore ψ m σ θ r and k s θ s is obtained experimentally from bulk density the goodness of fit of the measured water retention data to the θ ψ using the kosugi model was assessed using the nash sutcliffe efficiency coefficient ns e θ ψ as follows 28 ns e θ ψ 1 i 1 l θ ψ ob s i θ ψ k g i 2 i 1 l θ ψ ob s i θ ψ obs 2 where l corresponds to the total number of data points experimentally measured in the θ ψ θ ψ ob s i corresponds to the experimental values measured to derive the θ ψ and θ ψ k g i corresponds to the values derived from the fitted kosugi model a similar approach is used to quantify the goodness of the fit for k θ using the corresponding ns e k θ with the hydraulic conductivity values 3 3 2 inverting procedure to derive ψ θ from psd the minimization process between the observed θ ψ k g i derived from the fitted kosugi model and the fitted psd models described in table 2 used the following objective function o f psd 29 o f psd i 1 m θ ψ ps d i θ ψ k g i 2 where m refers to the total number of data points of the psd data the capability of the different particle size distribution models to predict the experimentally determined θ ψ is also evaluated using the nash sutcliffe efficiency coefficient ns e θ ψ psd defined as follows 30 ns e θ ψ psd 1 i 1 m θ ψ k g i θ r ps d i 2 i 1 m θ ψ k g i θ ψ kg 2 where m corresponds to the total number of data points in the θ ψ θ ψ k g i corresponds to the laboratory values fitted to the θ ψ using the kosugi model and θ r ps d i corresponds to the estimated value of the θ ψ from the corresponding particle size distribution model described in table 2 4 results and discussion 4 1 experimental data and fitting of the laboratory θ ψ table 1 summarises the statistics of the prominent measured soil physical properties ρ s ρ b and θ s and fitted kosugi hydraulic parameters k s ψ m σ and θ r derived by minimizing o f kg eq 27 using laboratory measurements the highest variability occurs for ln k s indicating the wide range of permeability of the studied soils the variability of ln ψ m and σ close to 20 illustrates the range of the hydraulic properties of the studied soils the goodness of fit of the observed data to the kosugi hydraulic model eq 28 is equally good for θ ψ eq 24 and k ψ eq 25 with mean nse values of 0 92 sd 0 09 and 0 94 sd 0 10 respectively 4 2 derive θr from psd fig 5 left shows the relationship between the estimated θ r values derived from the fit of the experimental data to the kosugi hydraulic model observed θ r k g for the individual soils as a function of the clay content and the estimated θ r values predicted with eq 23 from clay predicted θ r p s d the nse coefficient between the observed and predicted values is 0 60 with optimal α 1 and α 2 parameters equal to 16 02 and 2 01 respectively for the studied soils fig 5 right shows θ r observed and predicted values closely align to the 1 1 line predicted values from eq 23 slightly overestimate θ r compared to the fitted values with a slope equal to 0 98 4 3 intergranular mixing function from psd the fitting parameters ξ 1 and ξ 2 describing the bell shape of r i ξ r i fig 2 when ξ is described by eq 21 were found to be highly correlated ξ 1 is less sensitive than ξ 2 to both the amplitude and the location of the maxima in the weighting applied to the p s d therefore ξ 1 was kept constant at an optimal value for all soils while ξ 2 was derived for every soil sample from eq 22 table 2 step 4 for the soils studied ξ 2 was highly correlated with p s d 0 003 mm particle radius p 2 in eq 22 corresponding to particle sizes up to the very fine silt fraction the nse coefficient between ξ 2 values obtained for individual soils table 2 step 3 and predicted values of ξ 2 derived from eq 22 is 0 49 with optimal values of β 1 0 09 and β 2 0 95 and an associated ξ 1 9 04 table 2 step 4 these three parameters are the optimised imp model parameters obtained for the soils studied for illustration purposes fig 6 left shows p s d for two soils with contrasting texture fine and coarse texture soils fig 6 right relates p s d at 0 003 mm particle radius marked with a vertical dashed line in fig 6 left to ξ 2 eq 22 as expected the slope of p s d up to the fine silt fraction increases with the amount of clay and fine silt this results in a decrease in the general slope of p s d when passing from fine texture to coarse texture soils which is directly related to the shape of the θ ψ for sandy soil the θ ψ is steeper than for a clay soil computed values of ξ 2 for the individual soils as a function of the p s d up to the 0 003 mm particle radius are plotted together with the fitting corresponding to eq 22 fig 6 right 4 4 physical processes to derive θ ψ from psd for each progressive step of the model ns e θ ψ psd steadily increases and sd decreases table 2 showing that taking into account further processes improves model performance the processes taken into account at each model development step are outlined below step 1 normalised young laplace capillary equation for ψ due to limited range of the smallest psd and normalised θ from psd corrected for non sphericity of soil particles the first step derives the θ ψ from psd data by calculating θ from a normalised expression of the p s d scaled by θ s and corrected for the non sphericity of the soil particles eq 18 through ξ optimised for all soils the simplification of the soil pore system to perfectly spherical pores ξ 0 reduces the performance of derivation of θ ψ from psd since soil pores are not perfectly spherical ψ is computed from r using the normalised expression of the young laplace capillary equation eq 20 resulting in a significant improvement when increasing λ from 1 to 2 to account for the larger suction corresponding to the small pores this correction considers the limitation in describing the smallest pore sizes from the smallest particle size fraction clay when assuming similarity between p s d and θ ψ the corresponding optimal values are ξ 0 79 for λ 1 ns e θ ψ psd 0 48 and ξ 0 08 for λ 2 ns e θ ψ psd 0 85 the improvement in the model when λ 2 with ξ 0 08 suggests that pores are almost spherical these results already outperform alternative attempts presented in the literature e g mohammadi and vanclooster 2011 meskini vishkaee et al 2014 chang et al 2019 step 2 residual pore volume for θ due to limited range of the smallest psd the soil porous media is able to retain water that is strongly bound to solid particles or in very small pores that remain in the soil at a suction higher than 1500 kpa therefore introducing a residual pore volume considered as a residual soil water content slightly increases the model performance sd reduced from 0 22 to 0 17 the improvement by using a residual pore volume considered as a residual soil water content and related to the clay fraction by eq 23 is not reflected in the mean value of the ns e θ ψ psd because it is more sensitive to errors in large pores than in small pores step 3 intergranular mixing of soil particles depending on their size the mixing of soil particles is affected by the particle size this is considered in eq 21 where optimizing ξ 1 and ξ 2 for all soils improves the prediction of the θ ψ from psd this confirms that soil particle arrangements in the soil can have neighbouring particles of different sizes which results in variations in pore radius and pore shape of the corresponding pore fraction in fact the particle radius represents an effective mean radius for each of the particle fractions the optimal values for ξ 1 and ξ 2 are 11 07 and 0 12 respectively the weighting applied to the p s d to translate it into the θ ψ has the form of a bell shape with larger corrections applied in the middle range of the particle sizes because statistically higher mixing occurs for effective mid sized particles step 4 intergranular mixing of soil particles depending on their size as a function of psd it was found that ξ 1 and ξ 2 in eq 21 are highly correlated with ξ 2 showing higher sensitivity to r i ξ r i than ξ 1 additionally ξ 2 is correlated to the amount of particles below 0 003 mm radius allowing ξ 2 to be derived from psd using eq 22 this improves the estimates of θ ψ from psd using only 3 parameters β 1 β 2 to derive ξ 2 and ξ 1 therefore the imp model can accurately predict θ ψ from experimental measurements of psd and θ s 4 5 model performance to derive θ ψ from psd the proposed imp model table 2 step 4 is compared to the chang et al 2019 model the residual pore fraction used in chang et al 2019 is related to the clay fraction by a power function for which they obtained a fitting value of η equal to 0 52 for a data set including clay to sandy soil textures optimising this fitting parameter for our studied soils gave η 0 55 which slightly increased the model performance nevertheless the chang et al 2019 model gave considerably less robust agreement between the observed and predicted θ ψ ns e θ ψ psd 0 53 and sd 0 32 compared to our novel model with optimized β 1 β 2 and ξ 1 ns e θ ψ psd 0 92 and sd 0 08 chang et al 2019 pointed out the limitations of their model for silty soils and therefore the significant amount of silt in the soils in this study will have contributed to the poorer agreement of their model increasing silt content contributes to more intergranular mixing of soil particles which results in wider variations in corresponding pore shapes and sizes therefore a stronger correction needs to be applied at this particle size range to derive θ ψ from psd for silty soils the imp model performs very well for all soil groups table 3 with marginally worse performance for sandy loam ns e θ ψ psd 0 87 which may be due to the small sample size the imp model was remarkably successful making predictions for loamy and silty soils which are considered to be the most difficult soils to be modelled chang et al 2019 fernández gálvez et al 2019 haverkamp and parlange 1986 mohammadi and vanclooster 2011 nimmo et al 2007 zhuang et al 2001 although we were able to successfully model θ ψ we were not able to directly compare the optimal hydraulic parameters from the kosugi model or any other hydraulic model derived from the θ ψ derived from laboratory measurements with the hydraulic parameters derived from the imp model this limitation arises because equally good combinations of hydraulic parameters could be derived which are sets of truly linked parameters pollacco et al 2008a 2008b pollacco and angulo jaramillo 2009 fernández gálvez et al 2019 this is because the imp model derives θ ψ but no estimate is provided for k θ to act as a constraint for the resolution of non uniqueness this issue will be the subject of further investigation examples for each of the soil texture groups fig 7 show the imp model predicts similar θ ψ to those derived from laboratory measurements in general the deviations between observed and predicted θ ψ are random and small fig 7d the bell shape of the weighting function fig 7c accounts for the intergranular mixing of particles the location of the mode depends on soil texture and shifts within the silt particle size range as indicated in section 2 3 1 the displacement of the mode is related to the degree of intergranular mixing of the soil particles increasing smaller particles in a polydisperse soil results in higher intergranular mixing and therefore the correction spreads to a wider range of larger particles the width of the bell increases as expected for sandy loam soils the mode shifts towards the smaller silt sizes while for silty clay soils the mode shifts towards the larger silt sizes 5 conclusions this paper develops a novel physically based intergranular mixing psd model imp which derives θ ψ from traditional psd data the model exploits the relationship between particle size and pore size distributions and the intergranular arrangement of the soil particles the imp model successfully predicts θ ψ for fine texture soils which are the most challenging soil textures to be modelled reliable estimates of θ ψ can be obtained in a cost effective way from psd and θ s using only three general fitting parameters mean nash sutcliffe efficiency coefficient 0 92 for 259 soils without requiring an assumption of soil particle packing type the imp model can accurately predict θ ψ for fine texture soils because a it implements an intergranular mixing function that accounts for soil pores not all being perfectly spherical and takes into consideration the intergranular rearrangement mixing of the particles which allows neighbouring particles to have different sizes resulting in variations in pore radius and pore shape of the corresponding pore fraction b it overcomes the absence of psd data below the clay fraction by developing a normalised form of the young laplace capillary equation and c the residual pore volume accounting for water strongly bound to the solid particles or in very small pores is incorporated as a function of the clay fraction this leads to the conclusion that to compute θ ψ from psd the proposed model only requires ρ b to calculate θ s and three general fitting parameters β 1 β 2 to compute ξ 2 and ξ 1 despite of the excellent agreement between the water retention curve derived from laboratory measurements and from the imp model it was not possible to compare the derived hydraulic parameters due to the problem of non uniqueness this issue needs be the subject to further investigation by the hydrological community further work is also recommended to test and calibrate the imp model on a wider range of soils with different parent material and mineralogy declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements funding provided by the new zealand ministry for business innovation and employment under the mbie s map next generation research programme and the mbie winning against wildings john dando for the laboratory physical determinations veronica penny for collecting soil cores and samples laurent lassabatere and rafael angulo jaramillo for helpful discussion on soil pore medium and stephen mcneill and leah kearns for reviewing and improving the manuscript 
5634,laboratory measurements to derive the soil water retention curve θ ψ are time consuming and expensive we present a cost effective alternative using particle size distribution psd and saturated water content we propose a novel physical conceptual intergranular mixing psd model imp model which derives θ ψ from psd exploiting the relation between particle size and pore size distributions and the intergranular arrangement of the soil particles the imp model successfully predicts θ ψ for fine texture soil which is the most challenging soil texture to be modelled with our novel model reliable θ ψ can be obtained using only three general fitting parameters without needing to assume any particular type of soil particle packing with mean nash sutcliffe efficiency coefficient of 0 92 for 259 soils the imp model can accurately predict θ ψ for fine texture soils because a it implements an intergranular mixing function that accounts for soil pores not all being perfectly spherical and takes into consideration the intergranular rearrangement mixing of the particles which allows neighbouring particles to have different sizes resulting in variations in pore radius and pore shape of the corresponding pore fraction b it overcomes the absence of psd data for sizes smaller than the clay fraction by developing a normalised form of the young laplace capillary equation and c the residual pore volume accounting for water strongly bound to solid particles or in very small pores is incorporated as a function of the clay fraction keywords particle size distribution pore size distribution water retention curve intergranular mixing kosugi model 1 introduction the soil water retention curve θ ψ is fundamental in describing the storage and transmission of water in the soil the θ ψ relates the soil water content θ l3 l 3 to the soil matric potential or suction ψ l in a distinct relationship for different soils the θ ψ is experimentally determined by measuring the amount of water that remains in the soil at a certain suction measurements normally range between saturation and permanent wilting point 1500 kpa because laboratory measurements are time consuming and expensive estimations of the θ ψ can alternatively be derived from soil physical properties different approaches include directly estimating points from the θ ψ e g balland and pollacco 2008 pollacco 2008 or estimating the whole θ ψ curve using empirical pedotransfer functions mcneill et al 2018 van looy et al 2017 derived from surrogate soil measurements one promising approach is to derive the θ ψ curve from the soil particle size distribution psd based on the similarity between the cumulative particle size distribution p s d and the cumulative pore size distribution p o r e s d the latter corresponds to θ ψ e g arya and paris 1981 chang et al 2019 mohammadi and vanclooster 2011 nasta et al 2013 psd is a fundamental soil physical characteristic used for soil classification and for the estimation of other physical properties such as hydraulic and thermal characteristics yang et al 2019 the routinely used sieve and sediment method for measuring psd separates larger particle fractions by wet sieving then smaller particle fractions by sedimentation klute 1986 and assumes sphericity of the individual soil particles and a constant particle density for all size ranges arya and paris 1981 developed the first conceptual model to derive θ ψ from psd using a semi physical approach in which pore size was associated with pore volume and determined by scaling the pore length pore lengths based on spherical particles were scaled using an empirical scaling parameter further formulations of this empirical scaling parameter have been proposed to improve the prediction of the θ ψ arya et al 2008 alternative semi physical models have been proposed using empirical parameters and specific assumptions relating to the relationship between particle size and pore size nevertheless these approaches fail to predict θ ψ from psd for loamy and fine texture soils e g haverkamp and parlange 1986 zhuang et al 2001 nimmo et al 2007 mohammadi and vanclooster 2011 chang et al 2019 to relate p s d to p o r e s d and its corresponding θ ψ mohammadi and vanclooster 2011 presented a simple physical empirical conceptual model to retrieve the θ ψ from psd the soil is described as an ensemble of particles of different sizes where for each particle size the void ratio the ratio of volume of voids to the volume of solids is related to particle size and the type of packing of the soil particles the size of the particle is related to the effective pore size that forms between the particles and the integration over all particle sizes then allows calculation of p o r e s d as a function of p s d several types of packing were considered including close packed cubic cubical tetrahedral tetragonal spheroidal pyramidal tetrahedral and body centred cubic finally pore size is related to ψ through the young laplace capillary equation to provide θ ψ however in their approach mohammadi and vanclooster 2011 assumed the same type of packing for all particle sizes making the void ratio constant regardless of particle size this is a common assumption e g arya and paris 1981 that simplifies the derivation of the θ ψ when linking p s d to the equivalent p o r e s d since the ratio between particle size and pore size is constant when the geometry of the pores is considered similar to the geometry of the particles however in a soil the geometry of the pores can vary with the size of the particles leading to a variable relationship between the particle radius and pore radius the purpose of this study is to develop a model that can account for the possibility of a pore system formed by neighbours particles of different sizes in this study we hypothesize that the geometry of the pores depends on the size of the soil particles and the intergranular mixing between particles of different sizes the intergranular mixing accounts for the organisation of neighbouring soil particles of different sizes we therefore propose an intergranular mixing psd imp model we revisit the conceptual model of mohammadi and vanclooster 2011 considering the intergranular mixing of particle sizes and propose an expression to account for it the predicted θ ψ from a set of psd data points using the traditional sieve and sediment method is compared to the θ ψ from laboratory data using the drying curve the proposed model is compared with the recent chang et al 2019 model which is currently one the models providing better agreement between θ ψ from laboratory data and predicted θ ψ from psd this model outperforms that of meskini vishkaee et al 2014 a modification of the mohammadi and vanclooster 2011 model that improved it by including a soil particle scaling factor the manuscript is organised as follows section 2 outlines the theory behind the proposed model briefly describes the model used for comparison and the fundamental physical approach on which our intergranular mixing approach is based section 3 presents the experimental data and the numerical computations used to derive θ ψ from the laboratory measurements and from the imp model section 4 evaluates the model performance and illustrates the relevance of the processes considered and section 5 summarises the key conclusions 2 theory the p s d is divided into m fractions depending on the measurement method or available data the mass ratio and the representative particle radius for the i th fraction are w i m m 1 and r i l respectively i m solid particles within each fraction are packed considering uniform sized spherical particles with the same bulk density as the soil as proposed by arya and paris 1981 the volumetric water content θ i l3 l 3 is obtained by summation of pore volumes that progressively fill up with water from the smallest fraction to the corresponding soil water content the p s d is used to compute θ i by multiplying the saturated soil water content θ s l3 l 3 by the cumulative mass ratio of particles up to the i th fraction 1 θ i θ s j 1 i w j where θ s is the saturated soil water content and w i is the mass ratio which represents the particle radius for the i th fraction r i i m the determination of the θ ψ relies on the fact that for a given matric potential ψ i l only part of the pore fractions are activated this activation is ruled by the young laplace capillary equation which takes the following general form tuller et al 1999 2 ψ i c i a i γ cos θ ρ w g where ρ w m l 3 is the density of water g l t 2 is the acceleration due to gravity c i l and a i l2 correspond respectively to the circumference and the cross sectional area of the narrowest part of the pore for the corresponding fraction γ m t 2 is the surface tension at the air water interface and θ is the contact angle between the soil particle and the water the ratio a i c i has the dimension of a length and equals r i 2 for a perfectly cylindrical pore of radius r i l therefore the young laplace capillary equation is written as 3 ψ i 2 γ cos θ ρ w g r i y r i where y equals 14 9 mm2 for pure water at 20 c and a contact angle of 0 γ 0 0728 kg s 2 ρ w 998 2067 kg m 3 and g 9 8067 m s 2 2 1 chang et al 2019 model when eq 1 is used to compute the cumulative pore volume the residual pore fraction is greater than the corresponding clay fraction this is notable for small particle sizes that become embedded within the pores formed by the larger particles increasing the pore volume formed by the smaller particles which are protected from compaction and reducing the pore volume fraction associated with large particles filling up the space of bigger pores by small particles fernández gálvez and barahona 2005 to account for the increase in the pore volume by the smallest particle size corresponding to the clay fraction chang et al 2019 introduced an empirical relationship derived for a range of contrasting soil textures taken from the unsoda database 4 θ 1 θ s c l a y η with η optimised θ i θ 1 θ s j 2 i w i cla y η c l a y w i j 2 m w j for i 1 where η is a fitting parameter found equal to 0 516 θ 1 l3 l 3 is the residual pore fraction and clay m m 1 refers to the percentage of the clay fraction to relate pore radius r to ψ chang et al 2019 used a linear relationship between r and associated particle radius r using the scale factor of 0 3 as indicated here 5 ψ i y 0 3 r i although chang et al 2019 improved estimates of θ ψ compared to the mohammadi and vanclooster 2011 model and its scaled version meskini vishkaee et al 2014 specifically developed for the van genuchten 1980 hydraulic model it still shows poor predictions for silty soils which we will address in this paper 2 2 mohammadi and vanclooster 2011 model for each particle fraction w i with a representative particle radius r i the assemblage of these particles forms a pore fraction for which the pore radius r i can be geometrically related to the particle radius in a close packed cubic assemblage for a particle radius r i where eight spherical particles contribute to each assembly the pore volume for a single assembly is the total volume of the assembly 4 r i 3 minus the solid volume of the corresponding spherical particles 8 4 π r i 3 3 this assumption implies that neighbouring particles are of similar size within each particle fraction to account for alternative structures where the number of spherical particles contributing to a single assembly differs from eight mohammadi and vanclooster 2011 introduced a coefficient that depends on the state of packing p state therefore the void ratio e of the assemblage takes the following form 6 e 4 r i 3 8 p state 4 π r i 3 3 8 p state 4 π r i 3 3 6 π p state π p state then 7 p state 6 π 1 e 6 π 1 ϕ where ϕ is the total porosity and e is the void ratio which relates to the solid particle density ρ s m l 3 and the soil bulk density ρ b m l 3 by 8 e ρ s ρ b ρ b mohammadi and vanclooster 2011 assumed that for soil particles in the i th size fraction particularly for a close packed cubic assemblage with uniform size spherical particles of radius r i the ratio c i a i is 9 c i a i 2 π r i p state 2 r i 2 π r i 2 2 π p state 4 π r i for other types of soil particle packing the ratio can be written in its general form as 10 c i a i p type p state r i where p type describes the packing type which mohammadi and vanclooster 2011 found to have an average value of 7 3 corresponding to close packed cubic packing p type can vary between 2 866 and 19 470 depending on the geometric characteristics of the packing of the soil particles which are assumed to be spherical different particle size fractions may have different types of packing which then modifies the number of spherical particles devoted to each assemblage mohammadi and vanclooster 2011 compute ψ for a general pore with cross section shape in the soil by 11 ψ i p state p type r i γ cos θ ρ w g p state p type y 2 r i 3 1 ϕ p type y π r i considering eq 3 this leads to the following relation between particle radius r i and pore radius r i 12 r i 2 r i p state p type π r i 3 1 ϕ p type eq 5 is similar to eq 11 with similar scale factors when p type corresponds to the close packed cubic packing 2 3 novel model to predict θ ψ from psd using principles of soil physics the uncertainty associated with the packing type is eliminated by constraining the total volume of spherical pores to the soil water content at saturation θ s the maximum amount of water in the soil system for perfectly spherical pores ξ 0 can be calculated from the sum of all pore volumes up to the maximum pore size using the following expression 13 θ s 4 π 3 j 1 m n j r j 3 ξ where n j m 1 is the number of spherical pores for each fraction of the pore size distribution and ξ with values in the range 0 3 accounts for soil pores not all being perfectly spherical ξ is further discussed in section 2 3 1 for the limiting case when ξ 0 the pores are perfectly spherical pollacco et al 2017 2013 and neighbouring particles are of similar size mohammadi and vanclooster 2011 the number of spherical pores for each pore fraction is assumed to be equal to the number of spherical particles for each fraction which is corrected by ξ and therefore calculated dividing the mass ratio by the total mass of the corresponding fraction 14 n j 3 w j 4 π ρ s r j 3 where for the calculation of n j for each r j it is assumed that ρ s is equal for all particle sizes combining eq 13 with 12 and 14 gives 15 θ s 1 ρ s π 3 1 ϕ p type 3 ξ j 1 m w j r j ξ from where p type can be isolated 16 p type π 3 1 ϕ 1 θ s ρ s j 1 m w j r j ξ 1 3 ξ the soil water content of the i th fraction θ i can be obtained from successive summations corresponding to particle radius up to i th as for the total volume of pores in eq 13 17 θ i 4 π 3 j 1 i n j r j 3 ξ replacing r i by r i using eq 12 substituting n i from eq 14 and p type from eq 16 leads to 18 θ i θ s j 1 i w j r j ξ j 1 m w j r j ξ when ξ 0 this expression reduces to eq 1 standard psd measurements lack data below 0 001 mm effective radius limiting the practicality of deriving θ in dry conditions high ψ the residual particle size fraction that accounts for the contribution of the residual soil water content θ r psd l3 l 3 is limited by the smallest measured particle fraction which can be related to the clay fraction e g pollacco et al 2008b chang et al 2019 therefore for a better estimation of the soil water content the expression is modified to 19 θ i θ s θ r p s d j 1 i w j r j ξ j 1 m w j r j ξ θ r p s d the relationship between θ r psd and the soil clay fraction is described in section 2 3 2 the soil matric potential corresponding to particle radius up to the i th fraction ψ i is described by chang et al 2019 and mohammadi and vanclooster 2011 in the form of the young laplace capillary equation using quite similar scale factors as those in eqs 5 and 11 respectively because routine methods cannot measure particle sizes smaller than the clay fraction expressions based on the young laplace capillary equation fail to describe ψ for pore fractions corresponding to smaller particles assemblages as shown in fig 1 for example for r min 0 001 mm gives ψ 500 kpa which does not take into account the large suction corresponding to the very small pores therefore an alternative normalized expression of the young laplace capillary equation is proposed in which a linear relation between pore radius and particle radius is considered 20 ψ i ψ max y r i y r max y r min y r max λ ψ max 3 1 ϕ p type y π r i 3 1 ϕ p type y π r max 3 1 ϕ p type y π r min 3 1 ϕ p type y π r max λ ψ max 1 r i 1 r max 1 r min 1 r max λ where ψ max represents the maximum value of the matric potential which corresponds to a value marginally larger than wilting point and is set to 1600 kpa to account for the feasible range of matric potential y from eq 3 corresponds to the constant in the young laplace capillary equation 14 9 mm2 r max and r min are the maximum and minimum pore radius r max and r min are the maximum and minimum particle radius determined experimentally and λ is a shape parameter to account for the fact that the correction for ψ only applies for the smaller particles fig 1 compares different expressions that relate ψ to r based on the young laplace capillary equation used by chang et al 2019 eq 5 and the normalized form eq 20 for cases when λ equals 1 and 2 r min corresponds to the clay particle size with an effective radius below 0 001 mm the proposed normalized expression differs from the classic approximation at smaller particle sizes for λ 1 differences can be seen from the very fine sand fraction particle radius below 0 1 mm while for λ 2 the curves start to diverge from the very fine silt fraction particle radius below 0 003 mm which gives a better physical description of ψ such that at r min 0 001 mm then ψ 1500 kpa 2 3 1 novel intergranular mixing function from psd as previously indicated ξ in eq 19 is interpreted as a correction to account for the fact that not all soil pores are perfectly spherical we modify ξ such that it could be interpreted as an intergranular mixing function that accounts not only for the non spherical shape of the soil pores but also for the intergranular rearrangement mixing of the particles in a soil therefore we hypothesise that ξ could be expressed as a function of effective r i using the following expression which is introduced into eq 19 21 ξ r i ξ 1 exp r i ξ 2 where ξ 1 and ξ 2 are intergranular mixing parameters to account for intergranular mixing of the particles depending on their effective size pores formed between particles may be of different sizes we consider that small pores are surrounded by small particles and larger pores are surrounded by large particles while medium size pores consist of a mixture of small and large particles to illustrate this concept fig 2 plots r i ξ r i as a function of r i where r i ξ r i is the weighting function applied to w i in eq 19 as a function of r i for optimal values of ξ 1 and ξ 2 the bell shape results in larger corrections for moderate particle sizes in fig 2 at around 0 02 mm moderate sized particles result from a mixed size range of particles polydisperse decreasing the passages of the pore system pollacco et al 2013 2017 and therefore requiring a higher suction for the water to be drained with a consequent higher correction the arrangement of the soil particles in a unit volume can have neighbouring particles of different sizes which results in variations in pore radius and pore shape of the corresponding pore fraction the bell shape can be shifted depending on the degree of mixing fig 2 where increasing smaller particles in a polydisperse soil results in higher mixing when the amount of smaller particles increases the correction spreads to a wider range of larger particles that is the width of the bell increases in order to take this effect into account we vary ξ 2 based on the psd using the following proposed expression 22 ξ 2 β 1 exp β 2 i 1 p w i where β 1 and β 2 are two additional fitting parameters and p is a particle distribution fraction that is selected such that ξ 2 is correlated to the optimal ξ 2 derived for individual soils 2 3 2 deriving θ r from psd the residual soil water content θ r l3l 3 is a parameter indicating the amount of water left in the soil at relatively high suction it can be derived as a fitting parameter from the θ ψ fixing θ r to a constant value close to zero results in significant errors in the estimation of θ ψ especially for soils with significant clay fraction e g lee and ro 2014 mohammadi and meskini vishkaee 2013 therefore predicting θ r from psd is required for the estimation of θ r and subsequently a better prediction of the θ ψ a relationship between the residual pore fraction and clay content is derived as follows 23 θ r p s d θ r m a x 1 exp α 1 c l a y α 2 where θ r m a x is the maximum value allowed for θ r that was found to be satisfactory when set at 0 25 and α 1 and α 2 are two empirical parameters this is described in fig 3 3 material and methods 3 1 experimental data 3 1 1 sites soils and profiles description soil samples n 259 corresponding to 46 soil profiles were collected in canterbury new zealand sampled sites included irrigated and non irrigated pastoral farming land mostly grazed by dairy cattle but including mixed sheep and cattle grazed pastures rainfall across the sites varied from 550 to 800 mm per year soil parent material was sediments derived from quartzo feldspathic hard sandstone deposited as either river alluvium or windblown loess landcare research 2019 schmidt et al 2005 previous research has shown these sediments to have a relatively consistent mineralogy across the region with the sand fraction dominated by quartz and feldspar and the clay fraction by mica and chlorite bruce 1984 rijkse 1985 this relatively consistent parent material across the sample set is an advantage for develop the theory underpinning the imp model because it minimizes the possible complex effects of contrasting mineralogy on the soil hydraulic functions as well the effects of more complex mineralogy on the reliability of laboratory measurements such as shrink swell clays or amorphous volcanic minerals allbrook 1993 mcneill et al 2018 although beyond the scope of this paper the imp approach taken here should be adaptable to account for the effects of different mineralogy on pore geometry because it explicitly incorporates the effects of intergranular mixing of particles of different sizes all soils in this study had at least 60 cm depth of fine earth soil material with most sites classifying to the pallic soil order in the new zealand soil classification hewitt 2010 correlating in soil taxonomy to haplusteps and humustepts great groups fourteen sites had younger soils that classified to the recent soil order hewitt 2010 correlating to haplusteps and ustifluvent great groups variation of particle size occurs in these soils due to factors such as the distance from the river source coarser textures near source nature of deposition loess soils often have a higher silt content and degree of weathering with older soils having more compact subsoils and sometimes greater clay content due to argillisation processes soil was sampled in 10 cm increments to 60 cm depth at each increment two soil cores were collected a large core of 589 cm3 10 cm diameter by 7 5 cm depth used for unsaturated hydraulic conductivity measurements and a small core of 59 cm3 5 cm diameter by 3 cm depth used for water retention measurements at the same depth increments and immediately beside the soil cores a bulk sample was collected for particle size and chemistry measurement to ensure consistent soil moisture conditions at all sites water was infiltrated two days prior to sampling for each core that was sampled a column of soil was created by sitting a core liner on the soil surface and carefully carving down around the core with a sharp knife leaving the core sitting on a pedestal a few mm wider than itself soil core liners were slowly and carefully pushed down into the soil while trimming the sides of the pedestal this process prevented any disturbance or damage to the soil structure ensuring that the properties of the cores that were analysed were the same as the soil in situ at the sampling site all cores were immediately wrapped in plastic film packed into crates with foam lining and stored at 4 c until laboratory measurement could occur 3 1 2 soil physical measurements soil core preparation bulk density particle density water retention and unsaturated hydraulic conductivity were measured at the manaaki whenua national soil physics laboratory following the standard methods used in new zealand gradwell 1972 gradwell and birrell 1979 claydon 1989 these methods are summarised below particle density was determined for each depth increment as described in gradwell and birrell 1979 particle density values ranged from 2 52 g cm3 to 2 75 g cm3 standard deviation of 0 05 g cm3 with topsoil values slightly lower than that found in subsoil bulk density was measured for both large and small cores following the water release and unsaturated conductivity measurements dry soil weight was measured after oven drying at 105 c for 24 h despite the differences in sample volume the correlation between large cores and small core bulk density measurements shows a coefficient of determination of 0 842 with a deviation from the 1 1 line lower than 0 5 slope 0 995 the particle size distribution of the soil fine earth fraction 2 00 mm was measured by wet sieving and the pipette method as described in claydon 1989 samples were pre treated to remove organic matter and calcium carbonate if necessary and then dispersed by ultrasonic vibration and a chemical dispersant agent the coarser fraction 0 063 mm was wet sieved dried and shaken through a stack of sieves between sizes 2 00 mm and 0 063 mm the remaining soil 0 063 mm was suspended in a column and after initial shaking pipette samples are drawn at various times from a set depth to determine the concentration of particles following stokes equation the soils collected had loamy silt sandy loam silt loam and silty clay texture classes according to new zealand soil classification milne et al 1995 fig 4 presents the textural triangle corresponding to the collected samples water retention values were measured at 0 4 0 7 1 5 10 20 40 100 and 1500 kpa for the small cores measurements 10 kpa suction were on high flow ceramic plates with suction applied by a hanging water column measurements above 10 kpa suction were made using pressure chambers gradwell and birrell 1979 additional measurements taken on large cores at 5 and 10 kpa showed high correlation with values obtained for the small cores with coefficients of determinations of 0 883 slope 1 007 and 0 892 slope 1 001 respectively for representativeness and to better capture the soil structure the large core bulk density data were used to convert gravimetric soil water content into the corresponding volumetric values saturated water content θ s was obtained from the soil porosity ϕ derived for the large cores using the soil particle density and bulk density the θ s is related to ϕ by a multiplying factor representing the ratio of measured saturated water content to calculated porosity out of the measured bulk density θ s ε ϕ where ε is set to 0 95 slightly increasing the goodness of the fit of the hydraulic parameters for a limited number of samples with water retention value at 0 4 kpa higher than porosity the small core bulk density was used instead to measure unsaturated hydraulic conductivity the large cores were trimmed saturated and then equilibrated to 0 1 0 4 0 7 and 1 kpa suction with a buchner funnel apparatus as described in cook et al 1993 unsaturated hydraulic conductivity was then measured using disc permeameters set to equivalent suctions for each measurement cook et al 1993 3 2 kosugi hydraulic model the θ ψ is often expressed as a close form unimodal function representing the relationship between θ and ψ e g brooks and corey 1964 clapp and hornberger 1978 van genuchten 1980 among these functions the one proposed by kosugi 1996 has the advantage of having parameters with a direct physical meaning in relation to the soil pore size distribution e g hayashi et al 2009 pollacco et al 2013 2017 the unimodal lognormal distribution of pores in the soil matrix leads to the kosugi model for the θ ψ 24 θ 1 2 θ s θ r erfc ln ψ ln ψ m σ 2 θ r where θ r is the residual volumetric water content e r f c is the complementary error function while ψ m l and σ are the shape parameters of the water retention curve in a physical sense ln ψ m refers to the median of the lognormal distribution of the matric potential which corresponds to the logarithmic median of the effective soil pore radius through the young laplace capillary equation ln r m and σ is the standard deviation of the log transformed soil pore radius the unsaturated hydraulic conductivity function for the kosugi model can be written as 25 k s e k s s e e r f c 1 2 erfc 1 2 s e σ 2 2 where k s l t 1 is the saturated hydraulic conductivity and s e refers to the effective saturation 26 s e θ θ r θ s θ r values derived from the fit of the experimental data to the kosugi hydraulic model for the individual soils are considered as observed data for the fitting of the psd models 3 3 objective function and goodness of fit the fitting process used to estimate the parameters used a robust global optimizer blackboxoptim https github com robertfeldt blackboxoptim jl written in the julia language bezanson et al 2017 this procedure used an objective function and goodness of fit defined in the following sections 3 3 1 inverting procedure to derive θ ψ from experimental data the minimization process between the observed and the fitted values used an objective function o f kg see below that includes information from both the water retention θ ψ and hydraulic conductivity k ψ data in order to avoid problems of non uniqueness the ln transformation in the second term of the o f kg puts relatively more weight on the lower values of k θ to minimize the bias toward high conductivity and also takes into account the larger uncertainties in measuring k θ as it increases pollacco et al 2013 the feasible range of parameters used for the fit is set according to fernández gálvez et al 2019 the o f kg is computed as follows 27 o f kg i 1 l θ ψ ob s i θ ψ k g i 2 i 1 l θ ψ ob s i θ ψ obs 2 i 1 k ln 1 k θ ob s i ln 1 k θ k g i 2 i 1 k ln 1 k θ ob s i ln 1 k θ obs 2 where l and k refer to the total number of experimentally measured data for the water retention and the unsaturated hydraulic conductivity curves respectively θ ψ ob s i and k θ ob s i correspond to the experimental values measured for the θ ψ and hydraulic conductivity function respectively and θ ψ k g i and k θ k g i correspond to fitted values of the kosugi model the fitted soil hydraulic parameters are therefore ψ m σ θ r and k s θ s is obtained experimentally from bulk density the goodness of fit of the measured water retention data to the θ ψ using the kosugi model was assessed using the nash sutcliffe efficiency coefficient ns e θ ψ as follows 28 ns e θ ψ 1 i 1 l θ ψ ob s i θ ψ k g i 2 i 1 l θ ψ ob s i θ ψ obs 2 where l corresponds to the total number of data points experimentally measured in the θ ψ θ ψ ob s i corresponds to the experimental values measured to derive the θ ψ and θ ψ k g i corresponds to the values derived from the fitted kosugi model a similar approach is used to quantify the goodness of the fit for k θ using the corresponding ns e k θ with the hydraulic conductivity values 3 3 2 inverting procedure to derive ψ θ from psd the minimization process between the observed θ ψ k g i derived from the fitted kosugi model and the fitted psd models described in table 2 used the following objective function o f psd 29 o f psd i 1 m θ ψ ps d i θ ψ k g i 2 where m refers to the total number of data points of the psd data the capability of the different particle size distribution models to predict the experimentally determined θ ψ is also evaluated using the nash sutcliffe efficiency coefficient ns e θ ψ psd defined as follows 30 ns e θ ψ psd 1 i 1 m θ ψ k g i θ r ps d i 2 i 1 m θ ψ k g i θ ψ kg 2 where m corresponds to the total number of data points in the θ ψ θ ψ k g i corresponds to the laboratory values fitted to the θ ψ using the kosugi model and θ r ps d i corresponds to the estimated value of the θ ψ from the corresponding particle size distribution model described in table 2 4 results and discussion 4 1 experimental data and fitting of the laboratory θ ψ table 1 summarises the statistics of the prominent measured soil physical properties ρ s ρ b and θ s and fitted kosugi hydraulic parameters k s ψ m σ and θ r derived by minimizing o f kg eq 27 using laboratory measurements the highest variability occurs for ln k s indicating the wide range of permeability of the studied soils the variability of ln ψ m and σ close to 20 illustrates the range of the hydraulic properties of the studied soils the goodness of fit of the observed data to the kosugi hydraulic model eq 28 is equally good for θ ψ eq 24 and k ψ eq 25 with mean nse values of 0 92 sd 0 09 and 0 94 sd 0 10 respectively 4 2 derive θr from psd fig 5 left shows the relationship between the estimated θ r values derived from the fit of the experimental data to the kosugi hydraulic model observed θ r k g for the individual soils as a function of the clay content and the estimated θ r values predicted with eq 23 from clay predicted θ r p s d the nse coefficient between the observed and predicted values is 0 60 with optimal α 1 and α 2 parameters equal to 16 02 and 2 01 respectively for the studied soils fig 5 right shows θ r observed and predicted values closely align to the 1 1 line predicted values from eq 23 slightly overestimate θ r compared to the fitted values with a slope equal to 0 98 4 3 intergranular mixing function from psd the fitting parameters ξ 1 and ξ 2 describing the bell shape of r i ξ r i fig 2 when ξ is described by eq 21 were found to be highly correlated ξ 1 is less sensitive than ξ 2 to both the amplitude and the location of the maxima in the weighting applied to the p s d therefore ξ 1 was kept constant at an optimal value for all soils while ξ 2 was derived for every soil sample from eq 22 table 2 step 4 for the soils studied ξ 2 was highly correlated with p s d 0 003 mm particle radius p 2 in eq 22 corresponding to particle sizes up to the very fine silt fraction the nse coefficient between ξ 2 values obtained for individual soils table 2 step 3 and predicted values of ξ 2 derived from eq 22 is 0 49 with optimal values of β 1 0 09 and β 2 0 95 and an associated ξ 1 9 04 table 2 step 4 these three parameters are the optimised imp model parameters obtained for the soils studied for illustration purposes fig 6 left shows p s d for two soils with contrasting texture fine and coarse texture soils fig 6 right relates p s d at 0 003 mm particle radius marked with a vertical dashed line in fig 6 left to ξ 2 eq 22 as expected the slope of p s d up to the fine silt fraction increases with the amount of clay and fine silt this results in a decrease in the general slope of p s d when passing from fine texture to coarse texture soils which is directly related to the shape of the θ ψ for sandy soil the θ ψ is steeper than for a clay soil computed values of ξ 2 for the individual soils as a function of the p s d up to the 0 003 mm particle radius are plotted together with the fitting corresponding to eq 22 fig 6 right 4 4 physical processes to derive θ ψ from psd for each progressive step of the model ns e θ ψ psd steadily increases and sd decreases table 2 showing that taking into account further processes improves model performance the processes taken into account at each model development step are outlined below step 1 normalised young laplace capillary equation for ψ due to limited range of the smallest psd and normalised θ from psd corrected for non sphericity of soil particles the first step derives the θ ψ from psd data by calculating θ from a normalised expression of the p s d scaled by θ s and corrected for the non sphericity of the soil particles eq 18 through ξ optimised for all soils the simplification of the soil pore system to perfectly spherical pores ξ 0 reduces the performance of derivation of θ ψ from psd since soil pores are not perfectly spherical ψ is computed from r using the normalised expression of the young laplace capillary equation eq 20 resulting in a significant improvement when increasing λ from 1 to 2 to account for the larger suction corresponding to the small pores this correction considers the limitation in describing the smallest pore sizes from the smallest particle size fraction clay when assuming similarity between p s d and θ ψ the corresponding optimal values are ξ 0 79 for λ 1 ns e θ ψ psd 0 48 and ξ 0 08 for λ 2 ns e θ ψ psd 0 85 the improvement in the model when λ 2 with ξ 0 08 suggests that pores are almost spherical these results already outperform alternative attempts presented in the literature e g mohammadi and vanclooster 2011 meskini vishkaee et al 2014 chang et al 2019 step 2 residual pore volume for θ due to limited range of the smallest psd the soil porous media is able to retain water that is strongly bound to solid particles or in very small pores that remain in the soil at a suction higher than 1500 kpa therefore introducing a residual pore volume considered as a residual soil water content slightly increases the model performance sd reduced from 0 22 to 0 17 the improvement by using a residual pore volume considered as a residual soil water content and related to the clay fraction by eq 23 is not reflected in the mean value of the ns e θ ψ psd because it is more sensitive to errors in large pores than in small pores step 3 intergranular mixing of soil particles depending on their size the mixing of soil particles is affected by the particle size this is considered in eq 21 where optimizing ξ 1 and ξ 2 for all soils improves the prediction of the θ ψ from psd this confirms that soil particle arrangements in the soil can have neighbouring particles of different sizes which results in variations in pore radius and pore shape of the corresponding pore fraction in fact the particle radius represents an effective mean radius for each of the particle fractions the optimal values for ξ 1 and ξ 2 are 11 07 and 0 12 respectively the weighting applied to the p s d to translate it into the θ ψ has the form of a bell shape with larger corrections applied in the middle range of the particle sizes because statistically higher mixing occurs for effective mid sized particles step 4 intergranular mixing of soil particles depending on their size as a function of psd it was found that ξ 1 and ξ 2 in eq 21 are highly correlated with ξ 2 showing higher sensitivity to r i ξ r i than ξ 1 additionally ξ 2 is correlated to the amount of particles below 0 003 mm radius allowing ξ 2 to be derived from psd using eq 22 this improves the estimates of θ ψ from psd using only 3 parameters β 1 β 2 to derive ξ 2 and ξ 1 therefore the imp model can accurately predict θ ψ from experimental measurements of psd and θ s 4 5 model performance to derive θ ψ from psd the proposed imp model table 2 step 4 is compared to the chang et al 2019 model the residual pore fraction used in chang et al 2019 is related to the clay fraction by a power function for which they obtained a fitting value of η equal to 0 52 for a data set including clay to sandy soil textures optimising this fitting parameter for our studied soils gave η 0 55 which slightly increased the model performance nevertheless the chang et al 2019 model gave considerably less robust agreement between the observed and predicted θ ψ ns e θ ψ psd 0 53 and sd 0 32 compared to our novel model with optimized β 1 β 2 and ξ 1 ns e θ ψ psd 0 92 and sd 0 08 chang et al 2019 pointed out the limitations of their model for silty soils and therefore the significant amount of silt in the soils in this study will have contributed to the poorer agreement of their model increasing silt content contributes to more intergranular mixing of soil particles which results in wider variations in corresponding pore shapes and sizes therefore a stronger correction needs to be applied at this particle size range to derive θ ψ from psd for silty soils the imp model performs very well for all soil groups table 3 with marginally worse performance for sandy loam ns e θ ψ psd 0 87 which may be due to the small sample size the imp model was remarkably successful making predictions for loamy and silty soils which are considered to be the most difficult soils to be modelled chang et al 2019 fernández gálvez et al 2019 haverkamp and parlange 1986 mohammadi and vanclooster 2011 nimmo et al 2007 zhuang et al 2001 although we were able to successfully model θ ψ we were not able to directly compare the optimal hydraulic parameters from the kosugi model or any other hydraulic model derived from the θ ψ derived from laboratory measurements with the hydraulic parameters derived from the imp model this limitation arises because equally good combinations of hydraulic parameters could be derived which are sets of truly linked parameters pollacco et al 2008a 2008b pollacco and angulo jaramillo 2009 fernández gálvez et al 2019 this is because the imp model derives θ ψ but no estimate is provided for k θ to act as a constraint for the resolution of non uniqueness this issue will be the subject of further investigation examples for each of the soil texture groups fig 7 show the imp model predicts similar θ ψ to those derived from laboratory measurements in general the deviations between observed and predicted θ ψ are random and small fig 7d the bell shape of the weighting function fig 7c accounts for the intergranular mixing of particles the location of the mode depends on soil texture and shifts within the silt particle size range as indicated in section 2 3 1 the displacement of the mode is related to the degree of intergranular mixing of the soil particles increasing smaller particles in a polydisperse soil results in higher intergranular mixing and therefore the correction spreads to a wider range of larger particles the width of the bell increases as expected for sandy loam soils the mode shifts towards the smaller silt sizes while for silty clay soils the mode shifts towards the larger silt sizes 5 conclusions this paper develops a novel physically based intergranular mixing psd model imp which derives θ ψ from traditional psd data the model exploits the relationship between particle size and pore size distributions and the intergranular arrangement of the soil particles the imp model successfully predicts θ ψ for fine texture soils which are the most challenging soil textures to be modelled reliable estimates of θ ψ can be obtained in a cost effective way from psd and θ s using only three general fitting parameters mean nash sutcliffe efficiency coefficient 0 92 for 259 soils without requiring an assumption of soil particle packing type the imp model can accurately predict θ ψ for fine texture soils because a it implements an intergranular mixing function that accounts for soil pores not all being perfectly spherical and takes into consideration the intergranular rearrangement mixing of the particles which allows neighbouring particles to have different sizes resulting in variations in pore radius and pore shape of the corresponding pore fraction b it overcomes the absence of psd data below the clay fraction by developing a normalised form of the young laplace capillary equation and c the residual pore volume accounting for water strongly bound to the solid particles or in very small pores is incorporated as a function of the clay fraction this leads to the conclusion that to compute θ ψ from psd the proposed model only requires ρ b to calculate θ s and three general fitting parameters β 1 β 2 to compute ξ 2 and ξ 1 despite of the excellent agreement between the water retention curve derived from laboratory measurements and from the imp model it was not possible to compare the derived hydraulic parameters due to the problem of non uniqueness this issue needs be the subject to further investigation by the hydrological community further work is also recommended to test and calibrate the imp model on a wider range of soils with different parent material and mineralogy declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements funding provided by the new zealand ministry for business innovation and employment under the mbie s map next generation research programme and the mbie winning against wildings john dando for the laboratory physical determinations veronica penny for collecting soil cores and samples laurent lassabatere and rafael angulo jaramillo for helpful discussion on soil pore medium and stephen mcneill and leah kearns for reviewing and improving the manuscript 
