index,text
7165,rapid urbanization is considered to be an important factor that contributes to flood risk therefore flood prediction in urban watersheds using appropriate runoff models is essential to avoid the harmful effects of floods there are various storage function sf models such as kimura prasad hoshi and urban storage function usf models that have been widely used in different parts of the world as rainfall runoff models in which the usf model was recently developed in japan for the specific application in urban watersheds however the identification of an appropriate model remains challenging in the field of hydrology therefore this study aims to identify an effective sf model for an urban watershed in terms of hydrograph reproducibility and from an akaike information criterion aic perspective the sce ua global optimization method was used for the parameter optimization of each model with root mean square error rmse as the objective function the reproducibility of the hydrograph was evaluated using the performance evaluation criteria of rmse nash sutcliffe efficiency nse and other error functions of peak volume time to peak lag time and runoff coefficient the results revealed that the higher values of nse coupled with the lower values of rmse and other error functions indicated that the hydrograph reproducibility of usf is the highest among the sf models furthermore aic and akaike weight aw were used to identify the most effective model among all those based on the information criteria perspective the usf model received the lowest aic score and the highest aw during most of the events which indicates that it is the most parsimonious model compared to the other sf models moreover uncertainty characterization of the sf model parameters was also conducted to analyze the effect of each parameter on model performance keywords urban storage function model hoshi s model prasad s model kimura s model performance evaluation parameter uncertainty 1 introduction flooding is a crucial issue in both rural and urban areas but the severity level of floods is greater in urban areas because most of the population is concentrated near floodplains mason et al 2007 urban areas are characterized by high population concentrated human activities presence of sewer systems and impervious surfaces zoppou 2001 in which the latter two features will accelerate the rainfall runoff transformation process and flood flows are therefore higher and more rapid than is the case in rural catchments hollis 1975 these flash floods cause damage to human life properties different crops etc and have a negative impact padiyedath et al 2017b sahoo and saritha 2015 in urban watersheds therefore it is very important to detect urban floods compared to those in rural areas because of the increased risks and costs associated with them mason et al 2012 the modeling of the rainfall runoff transformation process in an urban watershed is essential not only for flash flood estimation but also for flood control by the drainage optimization using the pumping systems flood mitigation is one of the water management strategies that can control the excessive damage caused by floods bubeck et al 2012 hence the accurate prediction of the hydrograph in advance which includes the estimation of flood peak time to peak volume lag time etc is important in order to avoid losses due to floodplain inundation with the increasing population and urbanization prediction of the urban flash flood is becoming an important problem to mitigate their impacts for this purpose the rainfall runoff models are important tools and they play a central role especially in urban watersheds there is no universally accepted rainfall runoff model classification as of now and there exist different ways of classifications depending on the criteria of interest dawdy 1969 singh 1995 sivakumar 2017 snyder and stall 1965 according to sivakumar 2017 based on simplicity and convenience the models can be grouped into two categories namely physical models and abstract models the physical models can represent the processes of a watershed in a physically realistic manner on a reduced size such as open channel hydrologic model of the river the hydraulic model of dam spillway etc the abstract model is the representation of the system using mathematical equations which links the input to the output and it is also called as a mathematical model sivakumar 2017 the abstract model can be further divided into empirical models theoretical models and conceptual models dooge 1977 the empirical models extract information only from the existing data without considering the hydrological characteristics and highly depends on the boundary conditions unit hydrograph rational method least square method etc are the examples of this method devi et al 2015 sivakumar 2017 the theoretical model is based on physical laws governing the hydrological process and it includes mikeshe swat etc abbott et al 1986 the conceptual model is an intermediary between the empirical and theoretical models generally conceptual models consider physical laws but in highly simplified form the examples of conceptual models include tank model sugawara 1974 and the models based on the spatially lumped form of continuity equation and the storage discharge relationship dooge 1959 nash 1958 sivakumar 2017 the rainfall runoff models can also be divided as a function of their process description lumped and distributed time variability event based continuous time and large time scale and technique of solution numerical analog and analytical amaguchi et al 2012 singh 1995 singh and woolhiser 2002 the selection of appropriate models for the intended purpose is very important most of the conceptual rainfall runoff models have been concerned with lumping up the dominant sub watershed processes that contribute to the overall watershed response boyle et al 2001 the lumped models are easy to use as they generally do not account for the spatial distribution of the input compared to the distributed models even though spatially lumped models also exist carpenter and georgakakos 2006 among the different conceptual lumped rainfall runoff models storage function sf models have been widely used in many parts of the world especially in japan not only because of their ease of use in computation and handling but also the ease by which they express the nonlinear relationship of the rainfall runoff process using simple equations kawamura et al 2004 extensive studies have been conducted using sf models in order to analyze the rainfall runoff transformation process kimura 1961 proposed the first sf model in japan with two parameters and delay time this nonlinear lumped model is still widely used in japan for flood prediction later laurenson 1964 developed a procedure to reproduce the surface runoff hydrograph of a catchment from the effective rainfall using a different two parameter sf model and tested the method in south creek australia subsequently prasad 1967 presented a three parameter sf model that had an additional term for the inclusion of the loop effect between storage and discharge as well as a parameter for the representation of wedge storage compared to that of kimura s model he considered the relationship between the effective rainfall and surface runoff in the model soon after kuribayashi and sadamichi 1969 evaluated the characteristics of the kinematic wave and kimura s sf model parameters they compared the characteristics of both models and developed theoretical relationships under an assumption of constant rainfall later hoshihata 1972 examined the applicability of the sf model as a distributed model he described a practical method for the estimation of the sf model parameters using the watershed slope but had insufficient data to conclude the results mein et al 1974 extended the work of laurenson 1965 by developing a nonlinear method for estimating surface runoff hydrographs by representing the basin as a series of conceptual reservoirs aoki et al 1976 compared hydrograph estimates for a channel using the sf model and kinematic wave model and related their parameters subsequently hoshi and yamaoka 1982 added another parameter and improved the robustness of sf model nagai et al 1982 examined the physical significance of the sf model parameters obtained by applying a mathematical optimization technique thereafter sugiyama et al 1997 theoretically analyzed the sf model parameters by comparing the sf and kinematic wave models and then evaluated sf model characteristics sugiyama et al 1999 however all the aforementioned models require effective rainfall as their input for the prediction of direct runoff hence they involve the separation of baseflow and effective rainfall components from total discharge and total rainfall respectively there was no adequate method of objectively quantifying effective rainfall after deducing losses until recently perumal and sahoo 2007 also numerous baseflow separation techniques are currently in use and thereby the baseflow separation will be a subjective process padiyedath et al 2017a this subsequently may further affect the value of parameters to be estimated and their relative stability later in order to overcome these problems baba et al 1999 introduced an sf model with the loss mechanism that uses the observed rainfall and total runoff directly and applied to a mountainous river basin in hokkaido japan the incorporated loss mechanisms infiltration and all other outflow components avoided the need for effective rainfall estimation and baseflow separation the use of the sf model of baba for the prediction of runoff in urban areas may be difficult because urban areas differ completely from mountainous areas in terms of their imperviousness absence of vegetation presence of sewer systems etc therefore takasaki et al 2009 developed a new urban sf usf model considering the urban runoff process it uses the observed rainfall and runoff directly without effective rainfall estimation and baseflow separation for flood prediction and compared with baba s sf model the model considers all possible inflow and outflow components including groundwater inflow as an outflow from the basin however all the studies in the literature have mainly focused on the theoretical significance of the parameters involved and the modification of existing models there was a need for the comparative studies of rainfall runoff models due to the existence of a variety of models which was identified quite early by the wmo 1975 in order to evaluate the ability of models to predict discharge and to provide information and guidelines for end users on the use of such models with regard to specific conditions and accuracy requirements also the comparative assessments of models serve to highlight strengths and weaknesses of modeling approaches of various complexity perrin et al 2001 the inferences of comparative assessments may be different from study to study based on the calibration methodology model structure study area and the model performance evaluation criteria there are several studies which compared the performance of different rainfall runoff models for instance michaud and sorooshian 1994 compared the discharge simulation accuracy of three models such as a complex distributed model a simple distributed model and a simple lumped model using root mean square error rmse and average bias as the evaluation criteria subsequently refsgaard and knudsen 1996 inter compared the lumped conceptual distributed physically based and intermediate models using evaluation criteria of nash sutcliffe efficiency nse and other index based on flow duration curve later perrin et al 2001 examined the role of complexity in hydrological models by relating the number of optimized parameters with their model performance using four different criteria in 19 models whose number of parameters ranges from three to nine he concluded that very simple models can achieve a level of performance almost as high as models with more parameters and the complexity alone cannot guarantee good and reliable performances this is because the over parameterization will add complexity and sometimes face the problem of equifinality beven 1993 during calibration therefore it is essential to address this issue through assessing the performance of different rainfall runoff models with different complexity to identify an effective one for urban watersheds that have a promising future scope despite the progress in the aforementioned direction none of the studies have evaluated the various sf models not only in terms of the prediction accuracy but also the information criteria point of view as far as the authors know specifically there are no studies that describe the performance evaluation of different sf models for an urban area including the usf model hence this study aims to identify an effective sf model among those selected for an urban watershed in terms of hydrograph reproducibility and from an akaike information criterion aic perspective for this purpose we have selected the relatively new usf model and four conventional sf models of hoshi prasad kimura and the linear model in order to conduct the performance evaluation the kanda river basin a typical small to medium sized urban watershed in tokyo was selected as the target basin and the five sf models were applied to five selected flood events in order to assess the performance in terms of the reproducibility of the hydrograph we first formulated the sf models with optimal parameters identified using the shuffled complex evolution university of arizona sce ua global optimization method duan et al 1992 1993 the rmse was chosen as the objective function for optimization these sf models with optimal parameters were further assessed for reproducibility of the hydrograph with minimum rmse and maximum nse and other error functions of peak volume time to peak lag time and runoff coefficient also for the first time in sf model research the authors have utilized aic and akaike weight aw to identify the most effective sf model for an urban watershed based on the information criteria perspective akaike 1998 in light of the aforementioned discussions the main objectives of this study were conducted in four steps as follows 1 the selection of different existing sf models and modification of the framework in order to consider the total rainfall and discharge directly and thereby reduce the associated errors of separation 2 the estimation of parameters for the selected models in each selected event using the sce ua global optimization method 3 the evaluation of the performance of the different sf models in terms of hydrograph reproducibility and from an aic perspective 4 the characterization of the uncertainty of parameter values for each model due to their variability in values during each event 2 methodology 2 1 conventional sf models sf models are flood event based lumped models used as short term models for simulating a few or individual flood events they are characterized by the relationship between storage and discharge they have different degrees of simplification that affect the input output transformation takasao and takara 1988 the four conventional sf models are linear kimura prasad and hoshi models and are shown in table 1 with their associated continuity equations where s is the storage mm q is the observed river discharge mm min t is the time min and k 1 k 2 p 1 p 2 are model parameters among the models hoshi s model has been found to be superior in terms of an additional parameter p 2 which was quantified by numerical experiments and can well define the flow characteristics based on kinematic wave theory hoshi and yamaoka 1982 some simplifications of hoshi s storage model can lead to prasad s storage model if p 2 1 in hoshi s model we obtain prasad s storage model in a similar fashion if we set k 2 0 in prasad s model the model can be transformed into kimura s model furthermore the most simplified linear model can be obtained by maintaining p 1 1 in kimura s model in this study the authors used kimura s sf model with one storage tank which is widely used as a special case of kimura s original model with the delay time third parameter equal to zero takasao and takara 1988 because delay time is a function of effective rainfall and basin characteristics its estimation becomes a difficult process especially for small watersheds where small stream channels are not printed on a map sugiyama et al 1997 also the linear model considered herein is used to check how efficiently a model can reproduce the hydrograph with a limited number of parameters 2 2 usf model in order to develop an sf model for an urban watershed without the separation of effective rainfall and baseflow components from total rainfall and discharge respectively it is essential to consider all inflow and outflow components of the watershed fig 1 shows the schematic diagram of all the possible inflow and outflow components of an urban watershed with the combined sewer system we are considering the combined sewer system because many older cities in different parts of the world continue to operate combined sewers with a high installed rate instead of the separate system due to the high cost involved metcalf and eddy 1972 us epa 1999 the model is a lumped one based on the relationship between the rainfall over the basin and the runoff at the outlet point the runoff at the outlet point is the river discharge although both pluvial and fluvial floods occur within the basin which have a delayed effect in the river discharge at the outlet point during light rain only the pluvial flood occurs but finally discharging to the river and contributing to the river discharge during heavy rain both pluvial and fluvial floods occur and the fluvial flood causes more damage than the pluvial flood by overflowing the river therefore the usf model measures the combined effect of both the floods at the outlet point the basin storage is mainly composed of river storage surface and sub surface storage and the sewer system storage the storage has been considered as just one independent cell for the entire basin there is no other inflows from other basins but an outflow from the basin to the treatment plant through the combined sewer system rather than discharging into the river as lateral inflow the inflow components in fig 1 are represented by rainfall r mm min and urban specific and groundwater inflows from other basins i mm min urban specific inflows include leakage from water distribution pipes irrigational flow etc the outflow components are constituted by the river discharge q mm min evapotranspiration e mm min storm drainage from the basin through the combined sewer system q r mm min water intake from the basin for intended purposes such as water supply agricultural needs etc o mm min and groundwater related loss q l mm min in addition domestic sewage q w has also been depicted in fig 1 even though it does not contribute to the watershed storage s mm the usf model is the empirical representation of hoshi s sf model shown in table 1 in which the river discharge q is replaced by the discharge including the storm drainage q q r combining the expression of storage for usf model with the associated continuity equation given in table 1 yields the nonlinear expression of the usf model takasaki et al 2009 groundwater related loss q l was defined by considering the infiltration hole height z and is given by the following equation takasaki et al 2009 1 q l k 3 s z s z 0 s z where k 3 and z are the parameters the expression for storm drainage q r from the combined sewer system discharged out of the basin is developed by assuming a linear relationship between total discharge q q r and the storm drainage q r immediately after the rainfall the q r is defined takasaki et al 2009 as follows 2 q r α q q r q 0 α q q r q 0 q r m a x q r m a x α q q r q 0 q r m a x where α is the slope of the linear relationship between total discharge q q r and the drainage q r and q 0 is the initial river discharge just before the rain starts takasaki et al 2009 the maximum volume of q r cannot exceed the sewer maximum carrying capacity q rmax substituting the storage equation into the continuity equation will lead to a second order ordinary differential equation ode as follows 3 k 2 d 2 d t 2 q q r p 2 k 1 d dt q q r p 1 r i e o q q r q l in order to solve the second order ode the change of variables is performed as follows 4 x 1 q q r p 2 5 x 2 d x 1 dt d dt q q r p 2 substituting eq 1 into eq 3 and performing the change of variables will lead to the emergence of two first order odes concerning two conditions as shown in eq 1 when s z the first order ode is as follows 6a d x 2 dt k 1 k 2 p 1 p 2 x 1 p 1 p 2 1 x 2 1 k 2 x 1 1 p 2 k 1 k 3 k 2 x 1 p 1 p 2 k 3 x 2 1 k 2 r i e o k 3 z in the case of s z the first order ode concerning the same processes are given by the following 6b d x 2 dt k 1 k 2 p 1 p 2 x 1 p 1 p 2 1 x 2 1 k 2 x 1 1 p 2 1 k 2 r i e o by solving the two simultaneous non linear odes of d x 1 dt eq 5 and d x 2 dt eqs 6a 6b numerically we obtain the total discharge q q r in order to solve the two first order simultaneous odes we used the runge kuta gill method the river discharge q is obtained as the solution after subtracting the q r which is calculated using eq 2 from the total discharge the usf model is a seven parameter model with parameters k 1 k 2 k 3 p 1 p 2 z α used in the rainfall runoff modeling generally the conventional hoshi sf is a four parameter model with parameters k 1 k 2 p 1 p 2 used for the transformation of effective rainfall into direct runoff however the separation techniques involved result in uncertainties and erroneous estimation of runoff hence in order to incorporate the loss related to groundwater q l and to consider the observed discharge as a whole in urban watersheds we added the term q l eq 1 with the addition of two more parameters k 3 and z and modified the framework therefore now hoshi s sf model can be designated as a 6 parameter model in a similar way the prasad kimura and linear models were transformed into 5 4 and 3 parameter models respectively for this present study the usf hoshi prasad kimura and the linear models will be the 7 6 5 4 and 3 parameter models respectively 2 3 parameter estimation the sce ua method proposed by duan et al 1992 was used to estimate the optimum parameter values of all the aforementioned models it is a well known global optimization strategy developed for effective and efficient optimization for calibrating the watershed models the sce ua method has been found to be a useful technique for complex parameter identification problems in hydrologic modeling canfield and lopes 2004 canfield et al 2002 eckhardt and arnold 2001 kawamura et al 2004 this method is based on the synthesis of four concepts competitive evolution controlled random search simplex method and complex shuffling the algorithmic parameters of sce ua were selected as per the recommendations of duan et al 1993 the population is partitioned into several complexes each of which is permitted to evolve independently the number of complexes c was set equal to 20 and the number of populations in each complex r 2 k 1 where k is the number of parameters to be estimated the objective function to be minimized using the sce ua method was selected as the rmse between the observed and computed using the estimated parameters the search range of parameters for sce ua was set as k 1 10 500 k 2 100 5000 k 3 0 001 0 05 p 1 0 1 1 p 2 0 1 1 z 1 50 and α 0 1 1 takasaki et al 2009 2 4 performance evaluation the river discharge computed for each event using the different sf models was compared in order to assess the reproducibility of the observed hydrographs using seven performance evaluation criteria 1 rmse 2 nse nash and sutcliffe 1970 asce 1993 3 percentage error in peak discharge pep pep 1 computed peak discharge observed peak discharge 100 4 percentage error in volume pev pev 1 computed volume of discharge observed volume of discharge 100 5 percentage error in time to peak discharge petp petp 1 computed time to peak observed time to peak 100 6 percentage error in lag time pelt pelt 1 computed lag time observed lag time 100 and 7 percentage error in runoff coefficient perc perc 1 computed runoff coefficient observed runoff coefficient 100 further aic was also used in order to identify the most effective model by comparing the different models for each event the most effective model is then the model with the lowest aic score and is given by the following expression akaike 1981 1998 7 aic 2 k 2 log l θ y where k is the number of parameters to be estimated and log l θ y is the log likelihood at its maximum likelihood estimator θ based on y observations later this concept was refined to correct for small data samples hurvich and tsai 1989 as follows 8 ai c c a i c 2 k k 1 n k 1 where n is the sample size a better way of interpreting the ai c c score is to normalize the relative likelihood values as aw the weight of all models summed together equals one and the model with the highest aw is considered to be the most effective the aw is considered as the weight of evidence that the model i is the best approximating model for the given data and candidate models the aw for the ith model a w i is as follows 9 a w i exp 0 5 δ a i c c i m 1 m exp 0 5 δ a i c c m where the δ a i c c i is calculated as follows 10 δ a i c c i a i c c i a i c c m i n where ai c c i is the individual ai c c score for the ith model ai c c m i n is the minimum ai c c i score among m models and m is the number of models 2 5 uncertainty characterization for the target watershed optimal parameter sets were obtained for each event using all the models however the obtained parameter values were different for each event corresponding to each model the variability in the model parameters induced due to the spatial averaging of rainfall received at different gauging points is termed as the parameter uncertainty chaubey et al 1999 and is quantitatively assessed using relative error re and coefficient of variation cv the different errors for the ith model and pth parameter are as follows 11 r e i p 1 n j 1 n p i j p i p i 12 c v i p σ i p p i 100 where n is the number of target events p i j is the estimated parameter value for the ith model and jth event p i is the average parameter value from all the events and σ i p is the standard deviation for the ith model and the pth parameter value 3 study area and data used the selected urban watershed for the particular study was the upper kanda river basin and is shown in fig 2 the different sf models were applied in the target basin having an area of 7 7 km2 at koyo bridge in order to determine the effective model the kanda river basin lies between latitudes 35 70 n and 35 64 n and longitudes 139 56 e and 139 64 e in tokyo japan with an urbanization rate of more than 95 the source of the river is the inokashira pond and it joins the zenpukuji river and flows east ando and takahasi 1997 the drainage pattern follows the combined sewer system and the sewer installed population rate is 100 the main flow path length of the river sewer density of pipes having a diameter greater than 25 cm and the average slope of the watershed are 6 017 km 22 76 km 1 and 0 025 radians respectively the computed time of concentration of surface runoff from the upstream reaches to the watershed outlet was about 30 min the impervious area percentage was precisely estimated as 68 using the urban landscape gis delineation koga et al 2016 that further reduced the water retention capacity of the basin significantly there is a wide variety of land cover features with different impermeable properties within all land use classifications koga et al 2016 the smaller time of concentration indicated that the river discharge will occur immediately after the rainfall within a short period and it is desirable to use hydrological data at very short time intervals for the rainfall runoff analysis therefore the rainfall and water level data were collected at one minute intervals from the bureau of construction tokyo metropolitan government tmg from 2003 to 2006 for the present study the average rainfall of the basin was determined using the thiessen polygon method from the eight rain gauges scattered over the basin as shown in fig 2 five target events were selected from the data whose 60 minute maximum rainfall r60 is greater than 30 mm and is capable of producing flash floods table 2 shows the characteristics of the five selected rainfall events the inflow component i in the continuity equation was fixed at 0 0012 mm min based on the annual report of the bureau of construction tmg the water intake o from the basin and evapotranspiration e were set at 0 as there is no intake from the target basin and the evapotranspiration during heavy rainfall is insignificant the maximum storm drainage q rmax was estimated as 0 033 mm min using manning s equation 4 results and discussion 4 1 parameter estimation the sce ua method was applied for parameter estimation of the five sf models for the five selected flood events in the target watershed with rmse as the objective function the model parameters are estimated by calibration using the average watershed rainfall and the observed river discharge the convergence of parameters was also checked and it was found that the parameters converged before the 50th generation in each sce ua application run the total population generated was different from model to model based on the number of parameters in each model the best parameter set among the total population at the 50th generation with the minimum rmse was used for further hydrograph reproduction table 3 shows the elapsed time for calibration of models using sce ua and the computational time of each model for each event using the estimated parameters all the model simulations carried out in this study were run on windows 10 with intel core i7 6700 cpu as the processor and 16 gb ram the parameter calibration and evaluation were conducted on matlab it is clear from the table that the usf has taken the longest time for computation because it has the most number of parameters on the other hand the 3 parameter model has received the least time for simulations fig 3 shows the estimated model parameters for each selected event and sf model fig 3 a c show the k 1 k 3 z parameters respectively and these are associated with all of the five models the k 1 values are quite close for all the models except for the 3 parameter model during events 4 and 5 parameter k 3 was found to be similar for the usf 7 parameter and 6 parameter models during all the events even though it varies among events the k 3 value for the other models was also found to be similar and they were close to zero the z parameter for the usf 6 and 5 parameter models varies among events while the 4 and 3 parameter models have quite similar values close to zero during all the events fig 3 d exhibits parameter p 1 which is common for all the models except the 3 parameter model the p 1 values are sufficiently close for the 6 5 and 4 parameter models during all the events however the usf model has the highest p 1 value among all the models even though the value is closer to the other models during events 1 and 3 fig 3 e demonstrates parameter k 2 which is present in the usf 6 and 5 parameter models while fig 3 f shows the parameter p 2 which forms a part of the usf and 6 parameter models only we observed a high level of agreement between the usf and 6 parameter models in the k 2 value from fig 3 e on the other hand the 5 parameter model shows small disparities in the values as compared to those of the usf and 6 parameter models however the parameter fluctuates substantially during all the events for all the models the parameter values of p 2 in fig 3 f for the usf and 6 parameter models are identical during all the events although it varies among the events fig 3 g depicts parameter α which is associated with the usf model only the α values were found to be consistent during all the events for the usf model it is evident from the above discussion that the usf and 6 parameter model parameters values are identical in all the events except for the parameters z and p 1 in events 2 4 and 5 during these events the z and p 1 parameters of both the models lie farther from each other and the 6 parameter model lies close to the values of 5 parameter model generally during the parameter estimation each model attempts to either reduce or increase each parameter in association with the other parameters based on their model structure in order to get the best combination which will lead to the better performance therefore this could be a reason for the differences in values of parameters z and p 1 in association with other parameters in usf and other models during events 2 4 and 5 whose climatic factor is frontal rainfall as shown in table 2 the effect of parameter uncertainty and variability based on the model structure are discussed in more detail in section 4 4 4 2 hydrograph reproducibility the sf models with these identified parameters were used to estimate river discharge in order to evaluate hydrograph reproducibility from the observed rainfall as input fig 4 shows the reproduced hydrograph using the different sf models with the parameters shown in fig 3 in fig 4 the x axis and y axis increments are different from event to event it can be seen from fig 4 that the 7 parameter usf model nearly overlaps with the observed river discharge and precisely reproduces the shape of the observed hydrograph it is also capable of accurate reproduction of the peak during all the events even though it shows slight deviations during events 4 and 5 during events 4 and 5 it was most close to the observed peak compared with the peaks estimated by other sf models therefore the usf model can most exactly reproduce the shape of the observed hydrograph as well as the peak discharge compared to that of the other sf models irrespective of the number of peaks even though the 6 parameter model shows a slight deviation in the reproduced hydrograph on the rising and recession limbs during all the events the model accurately reproduces the peak discharge which is slightly less than that estimated by the usf model the model does not preserve the shape of the hydrograph particularly well in the multi peak event 3 although it estimates the peak accurately the 5 parameter model underestimated the peak discharge during all the events except for event 1 the model failed to reproduce not only the shape of the hydrograph but also the peak particularly in the multi peak event both the 4 and 3 parameter models especially the 3 parameter model were unable to reproduce the observed hydrograph they underestimated and early estimated the peak discharge during all the events the models failed to conserve the shape as well as the peak discharge regardless of the number of peaks fig 5 shows the values of various error functions i e rmse nse pep pev petp pelt and perc as described in section 2 4 for the five events using the five models from fig 5 a and b we can see that the usf model generates the lowest rmse close to zero and highest nse close to 100 among the five sf models followed by the 6 5 4 and 3 parameter models during all the events it is evident that the model with a large number of parameters will have the lowest rmse and highest nse which further reveals that the sce ua method has successfully identified the optimal parameters for each model during each event the low rmse and high nse can be interpreted as high hydrograph reproducibility however the 4 and 3 parameter models have high rmse and low nse values as compared to those of the other models this is because of the absence of parameters that describe the loop effect between storage and discharge during the rising and recession limbs fig 5 c depicts that the pep estimated using the usf and 6 parameter models are very low and not greater than 10 during any of the events even though the 6 parameter model shows pep 10 during event 5 both the models estimated a pep close to zero during the first three events while they slightly underestimated positive pep the peak during events 4 and 5 in contrast the 5 4 and 3 parameter models largely vary in their pep values and always underestimate the peak discharge like the pep the usf and 6 parameter models show the best performance in pev and petp values as shown in fig 5 d and e respectively which is close to zero as compared to that of the other models simultaneously the 5 4 and 3 parameter models generate higher values of pev and petp they overestimated the volume negative pev and early estimated the peak discharge fig 5 f demonstrates the pelt generated by different models for the selected events the usf model has values of either zero or close to zero which was immediately followed by the 6 and 5 parameter models respectively the 4 and 3 parameter models have similar pelt values among themselves and are far from those of the other sf model values fig 5 g additionally shows the perc and we can see that the perc value of the usf 6 and 5 parameter models are very close to zero except for the 5 parameter model during event 2 and 6 parameter model during event 5 the high perc value of the 5 parameter model during event 2 indicates a low volume of runoff estimated by the model as well as high pev as shown in fig 5 d in the same way the negative perc values generated by the 6 parameter model during event 5 can be interpreted as a high volume of runoff estimated by the model the 4 and 3 parameter models exhibit greater discrepancies compared to those of the other models during all events the higher values of nse coupled with the lower values of rmse pep pev petp pelp and perc for the usf model indicate that the hydrograph reproducibility of the usf model is the highest among the sf models the 6 parameter model was also found to be good for urban discharge estimation just after the usf model the 5 parameter model can be used as a substitute for the usf and 6 parameter models in urban rainfall runoff transformation process with little deviation to some extent however the 4 and 3 parameter models were found to be inappropriate for hydrograph reproducibility 4 3 aic aspect in addition to hydrograph reproducibility aic aspect was also used in order to determine the effectiveness of the models for each selected event fig 6 a shows the ai c c values eq 8 for each model during each event it can be seen from the figure that the 6 parameter model has the lowest ai c c during event 1 and event 2 however the usf had the lowest ai c c during events 3 4 and 5 even though the usf model did not receive the lowest ai c c during the first two events it was very close to the lowest value of the 6 parameter model there is nearly no support for 4 and 3 parameter models from fig 6 a because they generate a far higher ai c c score which indicates the necessity of more parameters in order to describe the storage characteristics of the urban watershed more accurately the exclusion of the delay time parameter in kimura s 4 parameter model could also be a reason for this high ai c c score from fig 6 a it is not easy to clearly distinguish the difference between the ai c c values of the usf 6 and 5 parameter models hence we analyzed the ai c c values using an associated statistic known as aw eq 9 to depict the differences distinctly as a general rule of thumb the aw of the candidate models during each event should be higher than 10 of the highest aw of that event royall 1997 so that we can easily exclude models with a weight lower than 10 of the highest aw model based on this rule we can exclude the 4 and 3 parameter models fig 6 b shows the aw for each event using the different sf models the weight exhibits an opposite trend to that of the ai c c values and the model with the highest weight is the best hurvich and tsai 1989 like the ai c c score the 6 parameter model received the highest weights during events 1 and 2 during the remaining events the usf model has the highest weight followed by the 6 parameter model even though the 6 parameter is followed by the usf model the difference between the aw values of these models is quite large significantly greater for events 3 and 5 therefore the usf model is much more effective than the 6 parameter model during such multi peak event 3 and single peak event 5 based on the aw values during event 1 the 6 parameter model was followed by the usf model and during event 2 it was followed by the 5 parameter model the difference in aw values between the 6 parameter and usf models are not as great as compared to that during events 3 and 5 consequently the usf model can be more suitable for multi peak events as compared to the other models as per the aic aspect 4 4 parameter uncertainty fig 7 shows the parameter variability of five sf models represented by two statistical indices eqs 11 and 12 the seven symbols in the figure represent the different parameters of each sf model fig 7 a demonstrates the re values of each parameter and are entirely different for each model the re of parameter k 1 which is used to represent the physical watershed characteristics such as watershed area land use etc is small compared to that of the other parameters for all the sf models except for the 3 parameter model in which it is the parameter with the highest re the parameters k 3 and z are used to depict the groundwater related loss from fig 7 a we can see that the re of parameter k 3 is quite high in all models and the parameter z received the highest re for the usf and 5 parameter models the high re of these two parameters plays an important role in hydrograph reproducibility of the sf models the re of z in the 4 and 3 parameter models is very low and the models are least affected by this parameter the p 1 parameter is controlled by the flow regime sugiyama et al 1997 it has higher re values in the 6 5 and 4 parameter models it was found to be one among other parameters with a low re in the usf model the parameter k 2 is a complicated function of several variables that can affect the wedge storage as well as the storage discharge relationship prasad 1967 this parameter was included only in the usf 6 and 5 parameter models and had a medium level of re values the parameter p 2 is incorporated in the usf and 6 parameter models and had quite high re values in both models the parameter α is associated only with the usf model to represent the effect of storm drainage and is that with the least variability in the usf model fig 7 b shows the cv values for the estimated parameters cv is the numerical representation of variability in data the parameter pattern in cv values is quite similar to that in re values even though it shows slight deviations the observed deviations are i the parameter order changed for some models and ii the cv values of parameters were more closely located or sometimes overlapped the parameter z had higher variability in its values for the usf and 5 parameter models on the other hand p 2 was more uncertain in nature for the 6 parameter model k 3 and k 1 are the parameters with the highest cv value for the 4 and 3 parameter models respectively in general a higher variability in rainfall resulted a higher variability in the parameters a larger variation in rainfall values within a single event will result in a higher variation in all estimated parameters the parameter estimates for each event may be quite inconsistent and this uncertainty in the model parameters can be attributed to the spatial variability in rainfall change in watershed characteristics etc it cannot be argued that the better performance of usf model over the other four models is essentially due to the additional parameter α it is not because of just one additional parameter but a combination of all the parameters if the number of parameters was the criteria for model performance the 3 parameter model should have comparable performance at least with the 4 parameter model however the 4 parameter model exhibits substantial improvement in performance compared with the 3 parameter model as shown in fig 5 the addition of parameter p 1 transformed the linear storage model into a non linear sf model and improved its structure however the 4 and 3 parameter models depicted a non linear and linear monovalent storage discharge relationship respectively on the other hand the usf 6 and 5 parameter models considered the looped storage discharge relationship and hence asserted that the inclusion of loop effect can considerably enhance the performance the 6 parameter model revealed an improved performance than the 5 parameter model even though both the model take care of the loop effect this can be attributed to the representation of non linear unsteady flow in 6 parameter model while the 5 parameter model constituted only the linear unsteady flow effects therefore it can be deduced that the introduction of non linear wedge storage can additionally increase the model performance the difference in performance between the usf and 6 parameter models can be ascribed to the effect of storm drainage diverting to the treatment plant through the combined sewer system instead of going to the river in the usf model according to the above discussion it was noted that the models with a different number of optimized parameters produced quite different results especially for 4 and 3 parameter models with a difference of one parameter each this strengthens the argument raised by gan et al 1997 in which the structure of the model is of critical importance for the model performance rather than the number of optimized parameters also the effectiveness of a model cannot be defined in terms of the individual additional parameters alone but should be considered as a combination of parameters which describe different watershed and flow attributes steefel and van cappellen 1998 commented that an effective model is determined based on its simplicity relative to its performance for a given number of observations but the simple 4 and 3 parameter models were not capable of reproducing the observed hydrographs and could not demonstrate an equivalent performance of that produced by the other sf models therefore simplicity alone cannot be used as a valid criterion for how effective a model is perrin et al 2001 suggested that the number of free parameters might be restricted between three and five in lumped rainfall runoff models however even the 5 parameter model failed to exactly reproduce the hydrograph and peak therefore the number of free parameters from three to five is not sufficient to clearly represent urban discharge at least in this particular study 5 conclusions the five sf models with optimal parameters identified using the sce ua method were applied to five flood events in an urban watershed in tokyo to evaluate performance with minimum rmse first the models were assessed for their hydrograph reproducibility using the seven error functions of rmse nse pep pev petp pelt and perc the results revealed that the usf model had the lowest rmse high nse among all the models for all the events which implies that the sce ua method successfully identified the optimal parameters the lower values of pep pev petp pelt and perc of the usf model further indicate that the hydrograph reproducibility of usf model is the highest among the studied sf models in addition the summary of aic results shows that the usf received the highest aw during most of the events compared to that of the other sf models which makes it the most effective model the other sf models have lower aw scores indicating the necessity of the addition of more parameters that describe the storage characteristics of an urban watershed in conclusion the usf model can be considered as the best model not only for hydrograph reproducibility but also the most parsimonious based on the aic perspective during most of the flood events in an urban watershed when compared to the conventional models if the optimal parameters are successfully identified for the events the uncertainty characteristics reveal that it is necessary to investigate the aspect of uncertainty of the parameters in more detail to identify the key parameters of runoff response in an urban basin the validation process of the models is very crucial with an ultimate goal of producing an accurate and credible model and it involves parameter uncertainty however in this study we are mainly concerned with the calibration of the selected sf models and their associated performance therefore our future work will mainly cover the detailed uncertainty analysis of parameters and their relative stability acknowledgements this study was carried out as a part of the research project entitled study on guerrilla rainstorm flood and water pollution in megacity urban watersheds countermeasures against megacity urban water related disasters bipolarized by climate change supported by tokyo metropolitan government japan represented by prof akira kawamura 
7165,rapid urbanization is considered to be an important factor that contributes to flood risk therefore flood prediction in urban watersheds using appropriate runoff models is essential to avoid the harmful effects of floods there are various storage function sf models such as kimura prasad hoshi and urban storage function usf models that have been widely used in different parts of the world as rainfall runoff models in which the usf model was recently developed in japan for the specific application in urban watersheds however the identification of an appropriate model remains challenging in the field of hydrology therefore this study aims to identify an effective sf model for an urban watershed in terms of hydrograph reproducibility and from an akaike information criterion aic perspective the sce ua global optimization method was used for the parameter optimization of each model with root mean square error rmse as the objective function the reproducibility of the hydrograph was evaluated using the performance evaluation criteria of rmse nash sutcliffe efficiency nse and other error functions of peak volume time to peak lag time and runoff coefficient the results revealed that the higher values of nse coupled with the lower values of rmse and other error functions indicated that the hydrograph reproducibility of usf is the highest among the sf models furthermore aic and akaike weight aw were used to identify the most effective model among all those based on the information criteria perspective the usf model received the lowest aic score and the highest aw during most of the events which indicates that it is the most parsimonious model compared to the other sf models moreover uncertainty characterization of the sf model parameters was also conducted to analyze the effect of each parameter on model performance keywords urban storage function model hoshi s model prasad s model kimura s model performance evaluation parameter uncertainty 1 introduction flooding is a crucial issue in both rural and urban areas but the severity level of floods is greater in urban areas because most of the population is concentrated near floodplains mason et al 2007 urban areas are characterized by high population concentrated human activities presence of sewer systems and impervious surfaces zoppou 2001 in which the latter two features will accelerate the rainfall runoff transformation process and flood flows are therefore higher and more rapid than is the case in rural catchments hollis 1975 these flash floods cause damage to human life properties different crops etc and have a negative impact padiyedath et al 2017b sahoo and saritha 2015 in urban watersheds therefore it is very important to detect urban floods compared to those in rural areas because of the increased risks and costs associated with them mason et al 2012 the modeling of the rainfall runoff transformation process in an urban watershed is essential not only for flash flood estimation but also for flood control by the drainage optimization using the pumping systems flood mitigation is one of the water management strategies that can control the excessive damage caused by floods bubeck et al 2012 hence the accurate prediction of the hydrograph in advance which includes the estimation of flood peak time to peak volume lag time etc is important in order to avoid losses due to floodplain inundation with the increasing population and urbanization prediction of the urban flash flood is becoming an important problem to mitigate their impacts for this purpose the rainfall runoff models are important tools and they play a central role especially in urban watersheds there is no universally accepted rainfall runoff model classification as of now and there exist different ways of classifications depending on the criteria of interest dawdy 1969 singh 1995 sivakumar 2017 snyder and stall 1965 according to sivakumar 2017 based on simplicity and convenience the models can be grouped into two categories namely physical models and abstract models the physical models can represent the processes of a watershed in a physically realistic manner on a reduced size such as open channel hydrologic model of the river the hydraulic model of dam spillway etc the abstract model is the representation of the system using mathematical equations which links the input to the output and it is also called as a mathematical model sivakumar 2017 the abstract model can be further divided into empirical models theoretical models and conceptual models dooge 1977 the empirical models extract information only from the existing data without considering the hydrological characteristics and highly depends on the boundary conditions unit hydrograph rational method least square method etc are the examples of this method devi et al 2015 sivakumar 2017 the theoretical model is based on physical laws governing the hydrological process and it includes mikeshe swat etc abbott et al 1986 the conceptual model is an intermediary between the empirical and theoretical models generally conceptual models consider physical laws but in highly simplified form the examples of conceptual models include tank model sugawara 1974 and the models based on the spatially lumped form of continuity equation and the storage discharge relationship dooge 1959 nash 1958 sivakumar 2017 the rainfall runoff models can also be divided as a function of their process description lumped and distributed time variability event based continuous time and large time scale and technique of solution numerical analog and analytical amaguchi et al 2012 singh 1995 singh and woolhiser 2002 the selection of appropriate models for the intended purpose is very important most of the conceptual rainfall runoff models have been concerned with lumping up the dominant sub watershed processes that contribute to the overall watershed response boyle et al 2001 the lumped models are easy to use as they generally do not account for the spatial distribution of the input compared to the distributed models even though spatially lumped models also exist carpenter and georgakakos 2006 among the different conceptual lumped rainfall runoff models storage function sf models have been widely used in many parts of the world especially in japan not only because of their ease of use in computation and handling but also the ease by which they express the nonlinear relationship of the rainfall runoff process using simple equations kawamura et al 2004 extensive studies have been conducted using sf models in order to analyze the rainfall runoff transformation process kimura 1961 proposed the first sf model in japan with two parameters and delay time this nonlinear lumped model is still widely used in japan for flood prediction later laurenson 1964 developed a procedure to reproduce the surface runoff hydrograph of a catchment from the effective rainfall using a different two parameter sf model and tested the method in south creek australia subsequently prasad 1967 presented a three parameter sf model that had an additional term for the inclusion of the loop effect between storage and discharge as well as a parameter for the representation of wedge storage compared to that of kimura s model he considered the relationship between the effective rainfall and surface runoff in the model soon after kuribayashi and sadamichi 1969 evaluated the characteristics of the kinematic wave and kimura s sf model parameters they compared the characteristics of both models and developed theoretical relationships under an assumption of constant rainfall later hoshihata 1972 examined the applicability of the sf model as a distributed model he described a practical method for the estimation of the sf model parameters using the watershed slope but had insufficient data to conclude the results mein et al 1974 extended the work of laurenson 1965 by developing a nonlinear method for estimating surface runoff hydrographs by representing the basin as a series of conceptual reservoirs aoki et al 1976 compared hydrograph estimates for a channel using the sf model and kinematic wave model and related their parameters subsequently hoshi and yamaoka 1982 added another parameter and improved the robustness of sf model nagai et al 1982 examined the physical significance of the sf model parameters obtained by applying a mathematical optimization technique thereafter sugiyama et al 1997 theoretically analyzed the sf model parameters by comparing the sf and kinematic wave models and then evaluated sf model characteristics sugiyama et al 1999 however all the aforementioned models require effective rainfall as their input for the prediction of direct runoff hence they involve the separation of baseflow and effective rainfall components from total discharge and total rainfall respectively there was no adequate method of objectively quantifying effective rainfall after deducing losses until recently perumal and sahoo 2007 also numerous baseflow separation techniques are currently in use and thereby the baseflow separation will be a subjective process padiyedath et al 2017a this subsequently may further affect the value of parameters to be estimated and their relative stability later in order to overcome these problems baba et al 1999 introduced an sf model with the loss mechanism that uses the observed rainfall and total runoff directly and applied to a mountainous river basin in hokkaido japan the incorporated loss mechanisms infiltration and all other outflow components avoided the need for effective rainfall estimation and baseflow separation the use of the sf model of baba for the prediction of runoff in urban areas may be difficult because urban areas differ completely from mountainous areas in terms of their imperviousness absence of vegetation presence of sewer systems etc therefore takasaki et al 2009 developed a new urban sf usf model considering the urban runoff process it uses the observed rainfall and runoff directly without effective rainfall estimation and baseflow separation for flood prediction and compared with baba s sf model the model considers all possible inflow and outflow components including groundwater inflow as an outflow from the basin however all the studies in the literature have mainly focused on the theoretical significance of the parameters involved and the modification of existing models there was a need for the comparative studies of rainfall runoff models due to the existence of a variety of models which was identified quite early by the wmo 1975 in order to evaluate the ability of models to predict discharge and to provide information and guidelines for end users on the use of such models with regard to specific conditions and accuracy requirements also the comparative assessments of models serve to highlight strengths and weaknesses of modeling approaches of various complexity perrin et al 2001 the inferences of comparative assessments may be different from study to study based on the calibration methodology model structure study area and the model performance evaluation criteria there are several studies which compared the performance of different rainfall runoff models for instance michaud and sorooshian 1994 compared the discharge simulation accuracy of three models such as a complex distributed model a simple distributed model and a simple lumped model using root mean square error rmse and average bias as the evaluation criteria subsequently refsgaard and knudsen 1996 inter compared the lumped conceptual distributed physically based and intermediate models using evaluation criteria of nash sutcliffe efficiency nse and other index based on flow duration curve later perrin et al 2001 examined the role of complexity in hydrological models by relating the number of optimized parameters with their model performance using four different criteria in 19 models whose number of parameters ranges from three to nine he concluded that very simple models can achieve a level of performance almost as high as models with more parameters and the complexity alone cannot guarantee good and reliable performances this is because the over parameterization will add complexity and sometimes face the problem of equifinality beven 1993 during calibration therefore it is essential to address this issue through assessing the performance of different rainfall runoff models with different complexity to identify an effective one for urban watersheds that have a promising future scope despite the progress in the aforementioned direction none of the studies have evaluated the various sf models not only in terms of the prediction accuracy but also the information criteria point of view as far as the authors know specifically there are no studies that describe the performance evaluation of different sf models for an urban area including the usf model hence this study aims to identify an effective sf model among those selected for an urban watershed in terms of hydrograph reproducibility and from an akaike information criterion aic perspective for this purpose we have selected the relatively new usf model and four conventional sf models of hoshi prasad kimura and the linear model in order to conduct the performance evaluation the kanda river basin a typical small to medium sized urban watershed in tokyo was selected as the target basin and the five sf models were applied to five selected flood events in order to assess the performance in terms of the reproducibility of the hydrograph we first formulated the sf models with optimal parameters identified using the shuffled complex evolution university of arizona sce ua global optimization method duan et al 1992 1993 the rmse was chosen as the objective function for optimization these sf models with optimal parameters were further assessed for reproducibility of the hydrograph with minimum rmse and maximum nse and other error functions of peak volume time to peak lag time and runoff coefficient also for the first time in sf model research the authors have utilized aic and akaike weight aw to identify the most effective sf model for an urban watershed based on the information criteria perspective akaike 1998 in light of the aforementioned discussions the main objectives of this study were conducted in four steps as follows 1 the selection of different existing sf models and modification of the framework in order to consider the total rainfall and discharge directly and thereby reduce the associated errors of separation 2 the estimation of parameters for the selected models in each selected event using the sce ua global optimization method 3 the evaluation of the performance of the different sf models in terms of hydrograph reproducibility and from an aic perspective 4 the characterization of the uncertainty of parameter values for each model due to their variability in values during each event 2 methodology 2 1 conventional sf models sf models are flood event based lumped models used as short term models for simulating a few or individual flood events they are characterized by the relationship between storage and discharge they have different degrees of simplification that affect the input output transformation takasao and takara 1988 the four conventional sf models are linear kimura prasad and hoshi models and are shown in table 1 with their associated continuity equations where s is the storage mm q is the observed river discharge mm min t is the time min and k 1 k 2 p 1 p 2 are model parameters among the models hoshi s model has been found to be superior in terms of an additional parameter p 2 which was quantified by numerical experiments and can well define the flow characteristics based on kinematic wave theory hoshi and yamaoka 1982 some simplifications of hoshi s storage model can lead to prasad s storage model if p 2 1 in hoshi s model we obtain prasad s storage model in a similar fashion if we set k 2 0 in prasad s model the model can be transformed into kimura s model furthermore the most simplified linear model can be obtained by maintaining p 1 1 in kimura s model in this study the authors used kimura s sf model with one storage tank which is widely used as a special case of kimura s original model with the delay time third parameter equal to zero takasao and takara 1988 because delay time is a function of effective rainfall and basin characteristics its estimation becomes a difficult process especially for small watersheds where small stream channels are not printed on a map sugiyama et al 1997 also the linear model considered herein is used to check how efficiently a model can reproduce the hydrograph with a limited number of parameters 2 2 usf model in order to develop an sf model for an urban watershed without the separation of effective rainfall and baseflow components from total rainfall and discharge respectively it is essential to consider all inflow and outflow components of the watershed fig 1 shows the schematic diagram of all the possible inflow and outflow components of an urban watershed with the combined sewer system we are considering the combined sewer system because many older cities in different parts of the world continue to operate combined sewers with a high installed rate instead of the separate system due to the high cost involved metcalf and eddy 1972 us epa 1999 the model is a lumped one based on the relationship between the rainfall over the basin and the runoff at the outlet point the runoff at the outlet point is the river discharge although both pluvial and fluvial floods occur within the basin which have a delayed effect in the river discharge at the outlet point during light rain only the pluvial flood occurs but finally discharging to the river and contributing to the river discharge during heavy rain both pluvial and fluvial floods occur and the fluvial flood causes more damage than the pluvial flood by overflowing the river therefore the usf model measures the combined effect of both the floods at the outlet point the basin storage is mainly composed of river storage surface and sub surface storage and the sewer system storage the storage has been considered as just one independent cell for the entire basin there is no other inflows from other basins but an outflow from the basin to the treatment plant through the combined sewer system rather than discharging into the river as lateral inflow the inflow components in fig 1 are represented by rainfall r mm min and urban specific and groundwater inflows from other basins i mm min urban specific inflows include leakage from water distribution pipes irrigational flow etc the outflow components are constituted by the river discharge q mm min evapotranspiration e mm min storm drainage from the basin through the combined sewer system q r mm min water intake from the basin for intended purposes such as water supply agricultural needs etc o mm min and groundwater related loss q l mm min in addition domestic sewage q w has also been depicted in fig 1 even though it does not contribute to the watershed storage s mm the usf model is the empirical representation of hoshi s sf model shown in table 1 in which the river discharge q is replaced by the discharge including the storm drainage q q r combining the expression of storage for usf model with the associated continuity equation given in table 1 yields the nonlinear expression of the usf model takasaki et al 2009 groundwater related loss q l was defined by considering the infiltration hole height z and is given by the following equation takasaki et al 2009 1 q l k 3 s z s z 0 s z where k 3 and z are the parameters the expression for storm drainage q r from the combined sewer system discharged out of the basin is developed by assuming a linear relationship between total discharge q q r and the storm drainage q r immediately after the rainfall the q r is defined takasaki et al 2009 as follows 2 q r α q q r q 0 α q q r q 0 q r m a x q r m a x α q q r q 0 q r m a x where α is the slope of the linear relationship between total discharge q q r and the drainage q r and q 0 is the initial river discharge just before the rain starts takasaki et al 2009 the maximum volume of q r cannot exceed the sewer maximum carrying capacity q rmax substituting the storage equation into the continuity equation will lead to a second order ordinary differential equation ode as follows 3 k 2 d 2 d t 2 q q r p 2 k 1 d dt q q r p 1 r i e o q q r q l in order to solve the second order ode the change of variables is performed as follows 4 x 1 q q r p 2 5 x 2 d x 1 dt d dt q q r p 2 substituting eq 1 into eq 3 and performing the change of variables will lead to the emergence of two first order odes concerning two conditions as shown in eq 1 when s z the first order ode is as follows 6a d x 2 dt k 1 k 2 p 1 p 2 x 1 p 1 p 2 1 x 2 1 k 2 x 1 1 p 2 k 1 k 3 k 2 x 1 p 1 p 2 k 3 x 2 1 k 2 r i e o k 3 z in the case of s z the first order ode concerning the same processes are given by the following 6b d x 2 dt k 1 k 2 p 1 p 2 x 1 p 1 p 2 1 x 2 1 k 2 x 1 1 p 2 1 k 2 r i e o by solving the two simultaneous non linear odes of d x 1 dt eq 5 and d x 2 dt eqs 6a 6b numerically we obtain the total discharge q q r in order to solve the two first order simultaneous odes we used the runge kuta gill method the river discharge q is obtained as the solution after subtracting the q r which is calculated using eq 2 from the total discharge the usf model is a seven parameter model with parameters k 1 k 2 k 3 p 1 p 2 z α used in the rainfall runoff modeling generally the conventional hoshi sf is a four parameter model with parameters k 1 k 2 p 1 p 2 used for the transformation of effective rainfall into direct runoff however the separation techniques involved result in uncertainties and erroneous estimation of runoff hence in order to incorporate the loss related to groundwater q l and to consider the observed discharge as a whole in urban watersheds we added the term q l eq 1 with the addition of two more parameters k 3 and z and modified the framework therefore now hoshi s sf model can be designated as a 6 parameter model in a similar way the prasad kimura and linear models were transformed into 5 4 and 3 parameter models respectively for this present study the usf hoshi prasad kimura and the linear models will be the 7 6 5 4 and 3 parameter models respectively 2 3 parameter estimation the sce ua method proposed by duan et al 1992 was used to estimate the optimum parameter values of all the aforementioned models it is a well known global optimization strategy developed for effective and efficient optimization for calibrating the watershed models the sce ua method has been found to be a useful technique for complex parameter identification problems in hydrologic modeling canfield and lopes 2004 canfield et al 2002 eckhardt and arnold 2001 kawamura et al 2004 this method is based on the synthesis of four concepts competitive evolution controlled random search simplex method and complex shuffling the algorithmic parameters of sce ua were selected as per the recommendations of duan et al 1993 the population is partitioned into several complexes each of which is permitted to evolve independently the number of complexes c was set equal to 20 and the number of populations in each complex r 2 k 1 where k is the number of parameters to be estimated the objective function to be minimized using the sce ua method was selected as the rmse between the observed and computed using the estimated parameters the search range of parameters for sce ua was set as k 1 10 500 k 2 100 5000 k 3 0 001 0 05 p 1 0 1 1 p 2 0 1 1 z 1 50 and α 0 1 1 takasaki et al 2009 2 4 performance evaluation the river discharge computed for each event using the different sf models was compared in order to assess the reproducibility of the observed hydrographs using seven performance evaluation criteria 1 rmse 2 nse nash and sutcliffe 1970 asce 1993 3 percentage error in peak discharge pep pep 1 computed peak discharge observed peak discharge 100 4 percentage error in volume pev pev 1 computed volume of discharge observed volume of discharge 100 5 percentage error in time to peak discharge petp petp 1 computed time to peak observed time to peak 100 6 percentage error in lag time pelt pelt 1 computed lag time observed lag time 100 and 7 percentage error in runoff coefficient perc perc 1 computed runoff coefficient observed runoff coefficient 100 further aic was also used in order to identify the most effective model by comparing the different models for each event the most effective model is then the model with the lowest aic score and is given by the following expression akaike 1981 1998 7 aic 2 k 2 log l θ y where k is the number of parameters to be estimated and log l θ y is the log likelihood at its maximum likelihood estimator θ based on y observations later this concept was refined to correct for small data samples hurvich and tsai 1989 as follows 8 ai c c a i c 2 k k 1 n k 1 where n is the sample size a better way of interpreting the ai c c score is to normalize the relative likelihood values as aw the weight of all models summed together equals one and the model with the highest aw is considered to be the most effective the aw is considered as the weight of evidence that the model i is the best approximating model for the given data and candidate models the aw for the ith model a w i is as follows 9 a w i exp 0 5 δ a i c c i m 1 m exp 0 5 δ a i c c m where the δ a i c c i is calculated as follows 10 δ a i c c i a i c c i a i c c m i n where ai c c i is the individual ai c c score for the ith model ai c c m i n is the minimum ai c c i score among m models and m is the number of models 2 5 uncertainty characterization for the target watershed optimal parameter sets were obtained for each event using all the models however the obtained parameter values were different for each event corresponding to each model the variability in the model parameters induced due to the spatial averaging of rainfall received at different gauging points is termed as the parameter uncertainty chaubey et al 1999 and is quantitatively assessed using relative error re and coefficient of variation cv the different errors for the ith model and pth parameter are as follows 11 r e i p 1 n j 1 n p i j p i p i 12 c v i p σ i p p i 100 where n is the number of target events p i j is the estimated parameter value for the ith model and jth event p i is the average parameter value from all the events and σ i p is the standard deviation for the ith model and the pth parameter value 3 study area and data used the selected urban watershed for the particular study was the upper kanda river basin and is shown in fig 2 the different sf models were applied in the target basin having an area of 7 7 km2 at koyo bridge in order to determine the effective model the kanda river basin lies between latitudes 35 70 n and 35 64 n and longitudes 139 56 e and 139 64 e in tokyo japan with an urbanization rate of more than 95 the source of the river is the inokashira pond and it joins the zenpukuji river and flows east ando and takahasi 1997 the drainage pattern follows the combined sewer system and the sewer installed population rate is 100 the main flow path length of the river sewer density of pipes having a diameter greater than 25 cm and the average slope of the watershed are 6 017 km 22 76 km 1 and 0 025 radians respectively the computed time of concentration of surface runoff from the upstream reaches to the watershed outlet was about 30 min the impervious area percentage was precisely estimated as 68 using the urban landscape gis delineation koga et al 2016 that further reduced the water retention capacity of the basin significantly there is a wide variety of land cover features with different impermeable properties within all land use classifications koga et al 2016 the smaller time of concentration indicated that the river discharge will occur immediately after the rainfall within a short period and it is desirable to use hydrological data at very short time intervals for the rainfall runoff analysis therefore the rainfall and water level data were collected at one minute intervals from the bureau of construction tokyo metropolitan government tmg from 2003 to 2006 for the present study the average rainfall of the basin was determined using the thiessen polygon method from the eight rain gauges scattered over the basin as shown in fig 2 five target events were selected from the data whose 60 minute maximum rainfall r60 is greater than 30 mm and is capable of producing flash floods table 2 shows the characteristics of the five selected rainfall events the inflow component i in the continuity equation was fixed at 0 0012 mm min based on the annual report of the bureau of construction tmg the water intake o from the basin and evapotranspiration e were set at 0 as there is no intake from the target basin and the evapotranspiration during heavy rainfall is insignificant the maximum storm drainage q rmax was estimated as 0 033 mm min using manning s equation 4 results and discussion 4 1 parameter estimation the sce ua method was applied for parameter estimation of the five sf models for the five selected flood events in the target watershed with rmse as the objective function the model parameters are estimated by calibration using the average watershed rainfall and the observed river discharge the convergence of parameters was also checked and it was found that the parameters converged before the 50th generation in each sce ua application run the total population generated was different from model to model based on the number of parameters in each model the best parameter set among the total population at the 50th generation with the minimum rmse was used for further hydrograph reproduction table 3 shows the elapsed time for calibration of models using sce ua and the computational time of each model for each event using the estimated parameters all the model simulations carried out in this study were run on windows 10 with intel core i7 6700 cpu as the processor and 16 gb ram the parameter calibration and evaluation were conducted on matlab it is clear from the table that the usf has taken the longest time for computation because it has the most number of parameters on the other hand the 3 parameter model has received the least time for simulations fig 3 shows the estimated model parameters for each selected event and sf model fig 3 a c show the k 1 k 3 z parameters respectively and these are associated with all of the five models the k 1 values are quite close for all the models except for the 3 parameter model during events 4 and 5 parameter k 3 was found to be similar for the usf 7 parameter and 6 parameter models during all the events even though it varies among events the k 3 value for the other models was also found to be similar and they were close to zero the z parameter for the usf 6 and 5 parameter models varies among events while the 4 and 3 parameter models have quite similar values close to zero during all the events fig 3 d exhibits parameter p 1 which is common for all the models except the 3 parameter model the p 1 values are sufficiently close for the 6 5 and 4 parameter models during all the events however the usf model has the highest p 1 value among all the models even though the value is closer to the other models during events 1 and 3 fig 3 e demonstrates parameter k 2 which is present in the usf 6 and 5 parameter models while fig 3 f shows the parameter p 2 which forms a part of the usf and 6 parameter models only we observed a high level of agreement between the usf and 6 parameter models in the k 2 value from fig 3 e on the other hand the 5 parameter model shows small disparities in the values as compared to those of the usf and 6 parameter models however the parameter fluctuates substantially during all the events for all the models the parameter values of p 2 in fig 3 f for the usf and 6 parameter models are identical during all the events although it varies among the events fig 3 g depicts parameter α which is associated with the usf model only the α values were found to be consistent during all the events for the usf model it is evident from the above discussion that the usf and 6 parameter model parameters values are identical in all the events except for the parameters z and p 1 in events 2 4 and 5 during these events the z and p 1 parameters of both the models lie farther from each other and the 6 parameter model lies close to the values of 5 parameter model generally during the parameter estimation each model attempts to either reduce or increase each parameter in association with the other parameters based on their model structure in order to get the best combination which will lead to the better performance therefore this could be a reason for the differences in values of parameters z and p 1 in association with other parameters in usf and other models during events 2 4 and 5 whose climatic factor is frontal rainfall as shown in table 2 the effect of parameter uncertainty and variability based on the model structure are discussed in more detail in section 4 4 4 2 hydrograph reproducibility the sf models with these identified parameters were used to estimate river discharge in order to evaluate hydrograph reproducibility from the observed rainfall as input fig 4 shows the reproduced hydrograph using the different sf models with the parameters shown in fig 3 in fig 4 the x axis and y axis increments are different from event to event it can be seen from fig 4 that the 7 parameter usf model nearly overlaps with the observed river discharge and precisely reproduces the shape of the observed hydrograph it is also capable of accurate reproduction of the peak during all the events even though it shows slight deviations during events 4 and 5 during events 4 and 5 it was most close to the observed peak compared with the peaks estimated by other sf models therefore the usf model can most exactly reproduce the shape of the observed hydrograph as well as the peak discharge compared to that of the other sf models irrespective of the number of peaks even though the 6 parameter model shows a slight deviation in the reproduced hydrograph on the rising and recession limbs during all the events the model accurately reproduces the peak discharge which is slightly less than that estimated by the usf model the model does not preserve the shape of the hydrograph particularly well in the multi peak event 3 although it estimates the peak accurately the 5 parameter model underestimated the peak discharge during all the events except for event 1 the model failed to reproduce not only the shape of the hydrograph but also the peak particularly in the multi peak event both the 4 and 3 parameter models especially the 3 parameter model were unable to reproduce the observed hydrograph they underestimated and early estimated the peak discharge during all the events the models failed to conserve the shape as well as the peak discharge regardless of the number of peaks fig 5 shows the values of various error functions i e rmse nse pep pev petp pelt and perc as described in section 2 4 for the five events using the five models from fig 5 a and b we can see that the usf model generates the lowest rmse close to zero and highest nse close to 100 among the five sf models followed by the 6 5 4 and 3 parameter models during all the events it is evident that the model with a large number of parameters will have the lowest rmse and highest nse which further reveals that the sce ua method has successfully identified the optimal parameters for each model during each event the low rmse and high nse can be interpreted as high hydrograph reproducibility however the 4 and 3 parameter models have high rmse and low nse values as compared to those of the other models this is because of the absence of parameters that describe the loop effect between storage and discharge during the rising and recession limbs fig 5 c depicts that the pep estimated using the usf and 6 parameter models are very low and not greater than 10 during any of the events even though the 6 parameter model shows pep 10 during event 5 both the models estimated a pep close to zero during the first three events while they slightly underestimated positive pep the peak during events 4 and 5 in contrast the 5 4 and 3 parameter models largely vary in their pep values and always underestimate the peak discharge like the pep the usf and 6 parameter models show the best performance in pev and petp values as shown in fig 5 d and e respectively which is close to zero as compared to that of the other models simultaneously the 5 4 and 3 parameter models generate higher values of pev and petp they overestimated the volume negative pev and early estimated the peak discharge fig 5 f demonstrates the pelt generated by different models for the selected events the usf model has values of either zero or close to zero which was immediately followed by the 6 and 5 parameter models respectively the 4 and 3 parameter models have similar pelt values among themselves and are far from those of the other sf model values fig 5 g additionally shows the perc and we can see that the perc value of the usf 6 and 5 parameter models are very close to zero except for the 5 parameter model during event 2 and 6 parameter model during event 5 the high perc value of the 5 parameter model during event 2 indicates a low volume of runoff estimated by the model as well as high pev as shown in fig 5 d in the same way the negative perc values generated by the 6 parameter model during event 5 can be interpreted as a high volume of runoff estimated by the model the 4 and 3 parameter models exhibit greater discrepancies compared to those of the other models during all events the higher values of nse coupled with the lower values of rmse pep pev petp pelp and perc for the usf model indicate that the hydrograph reproducibility of the usf model is the highest among the sf models the 6 parameter model was also found to be good for urban discharge estimation just after the usf model the 5 parameter model can be used as a substitute for the usf and 6 parameter models in urban rainfall runoff transformation process with little deviation to some extent however the 4 and 3 parameter models were found to be inappropriate for hydrograph reproducibility 4 3 aic aspect in addition to hydrograph reproducibility aic aspect was also used in order to determine the effectiveness of the models for each selected event fig 6 a shows the ai c c values eq 8 for each model during each event it can be seen from the figure that the 6 parameter model has the lowest ai c c during event 1 and event 2 however the usf had the lowest ai c c during events 3 4 and 5 even though the usf model did not receive the lowest ai c c during the first two events it was very close to the lowest value of the 6 parameter model there is nearly no support for 4 and 3 parameter models from fig 6 a because they generate a far higher ai c c score which indicates the necessity of more parameters in order to describe the storage characteristics of the urban watershed more accurately the exclusion of the delay time parameter in kimura s 4 parameter model could also be a reason for this high ai c c score from fig 6 a it is not easy to clearly distinguish the difference between the ai c c values of the usf 6 and 5 parameter models hence we analyzed the ai c c values using an associated statistic known as aw eq 9 to depict the differences distinctly as a general rule of thumb the aw of the candidate models during each event should be higher than 10 of the highest aw of that event royall 1997 so that we can easily exclude models with a weight lower than 10 of the highest aw model based on this rule we can exclude the 4 and 3 parameter models fig 6 b shows the aw for each event using the different sf models the weight exhibits an opposite trend to that of the ai c c values and the model with the highest weight is the best hurvich and tsai 1989 like the ai c c score the 6 parameter model received the highest weights during events 1 and 2 during the remaining events the usf model has the highest weight followed by the 6 parameter model even though the 6 parameter is followed by the usf model the difference between the aw values of these models is quite large significantly greater for events 3 and 5 therefore the usf model is much more effective than the 6 parameter model during such multi peak event 3 and single peak event 5 based on the aw values during event 1 the 6 parameter model was followed by the usf model and during event 2 it was followed by the 5 parameter model the difference in aw values between the 6 parameter and usf models are not as great as compared to that during events 3 and 5 consequently the usf model can be more suitable for multi peak events as compared to the other models as per the aic aspect 4 4 parameter uncertainty fig 7 shows the parameter variability of five sf models represented by two statistical indices eqs 11 and 12 the seven symbols in the figure represent the different parameters of each sf model fig 7 a demonstrates the re values of each parameter and are entirely different for each model the re of parameter k 1 which is used to represent the physical watershed characteristics such as watershed area land use etc is small compared to that of the other parameters for all the sf models except for the 3 parameter model in which it is the parameter with the highest re the parameters k 3 and z are used to depict the groundwater related loss from fig 7 a we can see that the re of parameter k 3 is quite high in all models and the parameter z received the highest re for the usf and 5 parameter models the high re of these two parameters plays an important role in hydrograph reproducibility of the sf models the re of z in the 4 and 3 parameter models is very low and the models are least affected by this parameter the p 1 parameter is controlled by the flow regime sugiyama et al 1997 it has higher re values in the 6 5 and 4 parameter models it was found to be one among other parameters with a low re in the usf model the parameter k 2 is a complicated function of several variables that can affect the wedge storage as well as the storage discharge relationship prasad 1967 this parameter was included only in the usf 6 and 5 parameter models and had a medium level of re values the parameter p 2 is incorporated in the usf and 6 parameter models and had quite high re values in both models the parameter α is associated only with the usf model to represent the effect of storm drainage and is that with the least variability in the usf model fig 7 b shows the cv values for the estimated parameters cv is the numerical representation of variability in data the parameter pattern in cv values is quite similar to that in re values even though it shows slight deviations the observed deviations are i the parameter order changed for some models and ii the cv values of parameters were more closely located or sometimes overlapped the parameter z had higher variability in its values for the usf and 5 parameter models on the other hand p 2 was more uncertain in nature for the 6 parameter model k 3 and k 1 are the parameters with the highest cv value for the 4 and 3 parameter models respectively in general a higher variability in rainfall resulted a higher variability in the parameters a larger variation in rainfall values within a single event will result in a higher variation in all estimated parameters the parameter estimates for each event may be quite inconsistent and this uncertainty in the model parameters can be attributed to the spatial variability in rainfall change in watershed characteristics etc it cannot be argued that the better performance of usf model over the other four models is essentially due to the additional parameter α it is not because of just one additional parameter but a combination of all the parameters if the number of parameters was the criteria for model performance the 3 parameter model should have comparable performance at least with the 4 parameter model however the 4 parameter model exhibits substantial improvement in performance compared with the 3 parameter model as shown in fig 5 the addition of parameter p 1 transformed the linear storage model into a non linear sf model and improved its structure however the 4 and 3 parameter models depicted a non linear and linear monovalent storage discharge relationship respectively on the other hand the usf 6 and 5 parameter models considered the looped storage discharge relationship and hence asserted that the inclusion of loop effect can considerably enhance the performance the 6 parameter model revealed an improved performance than the 5 parameter model even though both the model take care of the loop effect this can be attributed to the representation of non linear unsteady flow in 6 parameter model while the 5 parameter model constituted only the linear unsteady flow effects therefore it can be deduced that the introduction of non linear wedge storage can additionally increase the model performance the difference in performance between the usf and 6 parameter models can be ascribed to the effect of storm drainage diverting to the treatment plant through the combined sewer system instead of going to the river in the usf model according to the above discussion it was noted that the models with a different number of optimized parameters produced quite different results especially for 4 and 3 parameter models with a difference of one parameter each this strengthens the argument raised by gan et al 1997 in which the structure of the model is of critical importance for the model performance rather than the number of optimized parameters also the effectiveness of a model cannot be defined in terms of the individual additional parameters alone but should be considered as a combination of parameters which describe different watershed and flow attributes steefel and van cappellen 1998 commented that an effective model is determined based on its simplicity relative to its performance for a given number of observations but the simple 4 and 3 parameter models were not capable of reproducing the observed hydrographs and could not demonstrate an equivalent performance of that produced by the other sf models therefore simplicity alone cannot be used as a valid criterion for how effective a model is perrin et al 2001 suggested that the number of free parameters might be restricted between three and five in lumped rainfall runoff models however even the 5 parameter model failed to exactly reproduce the hydrograph and peak therefore the number of free parameters from three to five is not sufficient to clearly represent urban discharge at least in this particular study 5 conclusions the five sf models with optimal parameters identified using the sce ua method were applied to five flood events in an urban watershed in tokyo to evaluate performance with minimum rmse first the models were assessed for their hydrograph reproducibility using the seven error functions of rmse nse pep pev petp pelt and perc the results revealed that the usf model had the lowest rmse high nse among all the models for all the events which implies that the sce ua method successfully identified the optimal parameters the lower values of pep pev petp pelt and perc of the usf model further indicate that the hydrograph reproducibility of usf model is the highest among the studied sf models in addition the summary of aic results shows that the usf received the highest aw during most of the events compared to that of the other sf models which makes it the most effective model the other sf models have lower aw scores indicating the necessity of the addition of more parameters that describe the storage characteristics of an urban watershed in conclusion the usf model can be considered as the best model not only for hydrograph reproducibility but also the most parsimonious based on the aic perspective during most of the flood events in an urban watershed when compared to the conventional models if the optimal parameters are successfully identified for the events the uncertainty characteristics reveal that it is necessary to investigate the aspect of uncertainty of the parameters in more detail to identify the key parameters of runoff response in an urban basin the validation process of the models is very crucial with an ultimate goal of producing an accurate and credible model and it involves parameter uncertainty however in this study we are mainly concerned with the calibration of the selected sf models and their associated performance therefore our future work will mainly cover the detailed uncertainty analysis of parameters and their relative stability acknowledgements this study was carried out as a part of the research project entitled study on guerrilla rainstorm flood and water pollution in megacity urban watersheds countermeasures against megacity urban water related disasters bipolarized by climate change supported by tokyo metropolitan government japan represented by prof akira kawamura 
7166,skilful forecasting of monthly streamflow in intermittent rivers is a challenging task in stochastic hydrology in this study genetic algorithm ga was combined with gene expression programming gep as a new hybrid model for month ahead streamflow forecasting in an intermittent stream the hybrid model was named gep ga in which sub expression trees of the best evolved gep model were rescaled by appropriate weighting coefficients through the use of ga optimizer auto correlation and partial auto correlation functions of the streamflow records as well as evolutionary search of gep were used to identify the optimum predictors i e number of lags for the model the proposed methodology was demonstrated using monthly streamflow data from the shavir creek in iran performance of the gep ga was compared to that of classic genetic programming gp gep multiple linear regression and gep linear regression models developed in the present study as the benchmarks the results showed that the gep ga outperforms all the benchmarks and motivated to be used in practice keywords streamflow forecasting gene expression programming genetic algorithm evolutionary optimization intermittent streams 1 introduction accurate streamflow forecasting is an important task for variety of issues in basin hydrology including but not limited to reservoir operation irrigation planning food production flood damage mitigation and environmental protection a number of models have been suggested to simulate this complex process either conceptually or through data driven methods aksoy and bayazit 2000 wang et al 2009 yaseen et al 2017 intermittent streams are those that may experience dry spells occasionally this is often the case in arid and semi arid regions salas 1993 particularly in the tributaries of mountainous rivers or snow fed streams because of the paucity of gauging stations in mountainous regions the commonly used rainfall runoff approaches may not be applicable to forecast streamflow in intermittent streams in such situations data driven techniques could be implemented to model streamflow time series if a continuous set of streamflow measurements is available then the evolved model could be applied for neighbouring tributaries using regionalization techniques in recent literature due to the advances in data driven techniques a number of cross station single station and successive station monthly streamflow forecasting models have been developed and their successful results have been reported danandeh mehr et al 2013 gene expression programming gep is relatively a new data driven method that uses population of individuals programs improves according to fitness and obtains the best solution using one or more genetic operators ferreira 2001 however there is foremost differences between genetic programming gp and gep algorithms mainly reside in the nature of their programs in both programs are nonlinear entities with different size and shape while programs are encoded as parse tree in gp they are encoded as linear strings of fixed length in gep which are afterwards expressed as the chromosomes details about gp and gep are provided in section 2 in recent years different variants of gp such as gep multigene gp mggp and linear gp lgp have been used for streamflow prediction babovic and keijzer 2002 meshgi et al 2015 ravansalar et al 2017 for example guven 2009 compared lgp with two versions of artificial neural networks anns to predict daily streamflow of schuylkill river in the usa the author demonstrated that the performance of lgp is higher than anns danandeh mehr et al 2013 used lgp for monthly streamflow prediction between successive stations at çoruh river a perennial river in turkey and showed that lgp is superior to neuro wavelet model shoaib et al 2015 integrated gep model with discrete wavelet transform pre processing approach to predict streamflow using rainfall data the main contribution of the study was the introducing a novel wavelet gep model applicable over four watersheds worth to mention the aim of applying wavelet transform on the streamflow time series was to extract their temporal and spectral information the authors used the sequential time series approach to determine the input vector matrix that built the predictive model the proposed wavelet gep model outperformed the individual gep model in all case study catchments during both training and testing phases using rainfall potential evapotranspiration and streamflow from moselle river basin in france danandeh mehr and demirel 2016 showed that mggp can be satisfactorily used for one day ahead low flow prediction more recently danandeh mehr and kahya 2017 developed a pareto optimal moving mggp model for daily streamflow prediction and demonstrate that their hybrid model can overcome the timing error in time series analysing of daily streamflow models focusing on the implementation of gp gep in wider range of hydrological studies the author s review showed that they have been frequently used to distil knowledge from natural or experimental observations e g khu et al 2001 kisi et al 2012b meshgi et al 2014 johari and nejad 2015 danandeh mehr 2018 these are techniques which generate symbolic expressions that can be interpreted and combined with domain knowledge babovic 2005 and 2009 thus motivating to be used in practice until recently only a few studies focused on the application of gep for monthly streamflow forecasting for example karimi et al 2016 forecasted river flow for both daily and monthly time scales using gep model integrated with wavelet data pre processing approach at filyos river which is a perennial river in mediterranean region of turkey for comparison purpose traditional auto regressive moving average model together with two other soft computing methods anns and adaptive neuro fuzzy inference system were used in the study the authors showed that wavelet gep was superior to its counterparts al juboori and guven 2016 developed a gep based stepwise monthly streamflow prediction model and demonstrated that their model precisely forecasts monthly flows at the perennial hurman river in turkey as well as diyalah and lesser zab rivers in iraq table 1 has listed some of the studies that implemented at least one gp variant for time series modelling of streamflow data as shown in the table karimi et al 2016 as well as al juboori and guven s 2016 papers are dealing with generating gep based monthly streamflow forecasting model for perennial rivers whereas the present study focuses on the calibrating gep for intermittent rivers the main difference between the methodology of this study and those of karimi et al 2016 and al juboori and guven 2016 is the inclusion of seasonality effect in the selection of potential predictors which is the major pattern in the intermittent streamflow series moreover the present study puts forward a new strategy to enhance the accuracy of gep forecasts on the other hand the documented studies related to the streamflow forecasting in intermittent rivers are quite limited owing to the complexity of time series modelling of intermittent flows kisi et al 2012b although one might find a few studies that suggest the implementation of soft computing methods for intermittent streamflow forecasting e g cigizoglu 2005 kişi 2009 kisi et al 2012b to the best of the author s knowledge the present study is the first study in the literature that applies gep for monthly streamflow forecasting in an intermittent stream under the lights of the abovementioned literature a new hybridization procedure is suggested in order to augment gep prediction accuracy this is a new procedure by which the coefficients of the best gep induced expression are optimized through genetic algorithm ga the proposed hybrid gep ga methodology is applied for single station monthly streamflow forecasting at shavir creek an intermittent stream located at north west of iran the efficiency results of the new model are compared with those of classic gp standalone gep as well as multi linear regression mlr and hybrid gep linear regression gep lr models developed in the present study as the benchmarks 2 materials and methods 2 1 study area and data the task of intermittent streamflow forecasting in arid and semi arid regions is more complicated than in moist tropical and subtropical climates a first order tributary of shavir stream an intermittent stream in sefidrood river basin located in a semi arid region in north west of iran was selected as the case study in the present study fig 1 the stream catchment covers an area of approximately 55 5 km2 which is about 0 03 territory of ardabil province iran the stream springs from shavirdagh mountains in ardabil and reaches to caspian sea in kiashahr city of gilan province after a course of 300 km location of the stream gauge station givi hydrometric station used in the present study was also shown in fig 1 and the historical monthly streamflow measurements at the station were depicted in fig 2 fig 2a shows 30 year mean monthly streamflow time series during the 1978 2008 period local water year the first 20 years fig 2b and the remaining 10 years fig 2c of the observations were respectively used to train and validate the standalone models i e gp gep and mlr the statistical characteristics of the entire data as well as the training and validation sub series were presented in table 2 2 2 performance evaluation there are several ways to assess the performance of a model some of which are i line plot to visually inspect the trend between measured data and model output ii scatter plot of measured data versus model output and iii error measures such as mean absolute error root mean square error rmse mean absolute relative error nash sutcliffe coefficient of efficiency nse discrepancy ratio and others tayfur 2012 in this study performance of the proposed model and benchmarks are evaluated on the basis of line plots of trends between measured data and the models output together with two error measures including nse and rmse the former equation 1 is a normalized statistic that shows how well the scatter plot of observed and modeled data lie around the 1 1 perfect model straight line the higher nse one for the perfect model the better the model the latter eq 2 is the conventional quantitative goodness of fit indicator that measures the average magnitude of the error with the same dimension of the predictand variable the lower rmse zero for the perfect model the better the model 1 nse 1 i 1 n x i obs x i pre 2 i 1 n x i obs x mean obs 2 2 rmse i 1 n x i obs x i pre 2 n where and and arethepredictedobservedvaluesofx h e r e m o n t h l y s t r e a m f l o w r e s p e c t i v e l y are the predicted observed values of x here monthly streamflow respectively ismeanamountofobserveddata a n d n d e n o t e s t h e n u m b e r o f o b s e r v a t i o n s is mean amount of observed data and n denotes the number of observations 2 3 overview of ga gp and gep ga holland 1975 goldberg 1989 is an evolutionally optimization technique that frequently used in hydrology e g mckinney and lin 1994 babovic et al 1994 wu and chau 2006 rodríguez vázquez et al 2012 the main points of a ga procedure that have been used in this study to optimize the gep model parameters are shown in fig 3 as illustrated in the figure the best solution i e the parameters of the gep model is obtained through an iterative search method including i generation of a set of candidate solutions p ii fitness evaluation and iii and application of genetic operators crossover mutation and reproduction until a number of generations previously established is achieved for the details of the evolution process in ga the readers are referred to goldberg 1989 gp koza 1992 inspired by biological evolution embedded in ga is one of the most popular data driven techniques widely used in water resources engineering detailed description of gp in hydrology literature can be found in a seminal book by babovic 1996 and pioneer research papers e g babovic and abbot 1997a b savic et al 1999 babovic and keijzer 2000 only a brief introduction is given here in order to help readers to realize the proposed methodology in this article similar to ga each chromosomes in initial population is a potential solution for a given problem however chromosomes in gp are represented by tree shaped structure of a computer program that contains nodes of functions and terminals with connecting branches for example structure of a 3 level gp chromosome a computer program was shown in fig 4 a this is a simple chromosome represents equation 3 using the root node inner nodes sin cos and outer nodes x1 x2 3 x 1 sin x 2 x 2 cos x 1 to solve any problem gp starts with the identification of the chromosomes that are more fitted to the given training data they are considered as parents for creation of offspring via the genetic operators crossover mutation and reproduction reproduction is an operation in which only one chromosome is selected to produce a single offspring which is a pure copy of the parent crossover is the operation that produces two offspring consisting of genetic material of their parents by selecting a crossover point each parent is divided into two parts where the second part represents the subtree structure with crossover point as root node then the subtrees are exchanged between the parents in order to produce two new offspring mutation is another genetic operation in which a subtree from one parent is replaced with a new typically random subtree structure the evolution process in gp is terminated when the gp algorithm finds the perfect solution the fitness of best chromosome reaches specified value or the specific number of generation is reached regardless of the quality of the solution gep ferreira 2001 is an advanced gp method that creates expression trees ets chromosome to solve a specific problem each chromosome comprises one or more genes known as sub expression tree sub et in gep the best solution is constructed by linking the sub ets through algebraic or boolean and or not functions for instance the gep chromosome shown in fig 4d represents a model i e et as a combination of three sub ets i e sub et 1 sub et 2 and sub et 3 linked by addition function hrnjica and danandeh mehr 2018 mathematically the model is presented as follows 4 x 1 sin x 2 x 2 cos x 1 x 1 x 2 log x 2 c 1 x 2 x 1 x 2 where x 1 and x 2 are the input variables vectors and the addition function between the parenthesis i e sub ets is the linking function each sub et is a part of a solution having less complexity and typically provides information about the given process less than the corresponding et thus it can be concluded that gep employs the power of small gp blocks i e genes to capture nonlinear behaviour of a complex system through a multigene structure but there are fundamental differences between gep and gp reside in the creation and combination of their genes in gp computer programs genes follow the lisp language and are expressed as parse trees with different sizes and shapes the genetic operators act on the tree shaped genes whereas the computer programs are considered as linear strings with fixed length composed of one or more genes in gep each gene is composed of a head and tail for a given number of genes and specified length of head the initial population of gep chromosomes are created through filling the head and tail domains in regard to the coding sequence of the genes known as open reading frame readers are referred to ferreira 2006 for details about evolution process in gep to apply gp and gep for predictive modelling gpdotnet v5 0 and genexprotool v5 0 software frameworks were used in the present study respectively main features of the software together with some other available gp gep software frameworks were provided in table 3 hrnjica and danandeh mehr 2018 2 4 the proposed gep ga model despite being efficient for streamflow forecasting standalone artificial intelligence ai techniques are typically not accurate enough to model the nonlinear behaviour between successive flows in intermittent rivers kisi et al 2012b to improve model accuracy hybrid ai models that are benefited from data pre post processing danandeh mehr and nourani 2018 ghorbani et al 2018 or external optimization techniques chau 2007 chen et al 2015 have been suggested in recent studies see fotovatikhah et al 2018 for a survey of some hybrid model the gep ga model fig 5 is a hybrid evolutionary algorithm that intended for fine tuning of the constants of the expressions attained from the standalone gep first predictors lags are selected auto correlation function acf or partial auto correlation function pacf are typically used to identify the optimal lag for time series modelling the other alternatives may include partial mutual information e g tran et al 2015 and nonlinear regression using gp e g uyumaz et al 2014 a certain type of standardization is used to remove nonstationary feature from predictors this is a procedure by which streamflow series are square root transformed and then standardized so that they have zero mean and unit variance delleur and kavvas 1978 showed that subtracting the monthly means essentially removes the trend in the mean and variance and yields a time series having weak stationary states which is satisfied for practical purposes in the next step the standalone gep is used to drive a parsimonious multigene solution with the specified number of expressions in this phase the initially selected predictors and constants are optimized through evolutionary search algorithm as discussed earlier then a ga optimizer is used to optimize coefficients of sub ets this improves gep accuracy if the initial model was trapped into a local optimum solution parsimony of the gep ga model and the number of constants that are subjected to external optimization depend on the number of expressions specified by the modeller during a run setup if an expression does not contain any constants further optimization is still possible as gep algorithm assumes expression coefficients equal to one by default note that gep and ga are trained and validated by different inputs but identical output vector while gep uses antecedent series of normalized observed streamflow the ga is trained using the sub ets hereafter gene vectors of the best gep solution to ascertain optimal gene coefficients i e parameters so that accumulative error between measured data and gep simulations are minimal therefore the objective function for ga is developed as follows 5 min e a i 1 m y i j 1 n a i j g e n e j 2 where yi is ith target variable genei denotes the gep induced jth gene vector and ai j is gene weight the m and n represent total number of training data pairs and gene vectors respectively in the gep ga model the complexity program size with given number of sub ets of the evolved gep model is maintained and yet more accurate solution in terms of rmse are introduced coupled use of gep and ga poses a risk of over fitting thus generalization ability of optimum solution must be carefully controlled by means of unseen validation data set both gep and ga are well stablished evolutionary techniques thus the proposed gep ga model falls within the category of metaheuristic models chau 2017 despite being hybrid the model is explicit so motivating to be used in practice 3 results 3 1 prediction scenario fig 6 shows the acf and pacf of the streamflow time series for a lag range of 0 60 months the figure includes the corresponding 95 confidence levels and exhibits a pronounced annual oscillating pattern almost 12 month periodicity at acf diagram this means that monthly streamflow at the gauging station is more correlated to its previous year amount than that of previous month in addition the pacf graph shows that the serial correlation is strongly weak after two years therefore 1 11 12 23 and 24 month lag were selected as the extent of informative lags necessary for an autoregressive monthly streamflow forecasting model in the station as shown in eq 6 this is a comprehensive combination in which all the inputs are more or less informative inasmuch as the combination is formulated by gp gep and both have the capability of finding the inputs that contribute effectively in the process any other combination scenario with fewer input variables does not included in the present study 6 q t f q t 1 q t 11 q t 12 q t 23 q t 24 where qt represents the normalized monthly discharge at the present time month t the indices t 1 and t 11 respectively refer to 1 month and 11 month lags and so on 3 2 benchmarks the mlr model eq 7 which is taught as an ideal benchmark for comparison with all other sophisticated models in streamflow forecasting was created by fitting a regression line to the training set of normalized input output vectors to this end the method of least squares under the assumption of uncorrelated noise term was used 7 q t 0 3197 q t 1 0 0007 q t 11 0 3329 q t 12 0 2182 q t 23 0 2068 q t 24 0 01055 to formulate the aforementioned combination using the evolutionary methods of gp and gep a set of random floating points i e rk k 1 2 10 in the range 1 1 were considered as the members of the terminals in addition to the training set of input vectors two different setups for gp gep runs were considered to address the risks of complexity and overfitting in the evolutionary models in the first setup hereafter gp1 gep1 only the basic arithmetic operations addition subtraction multiplication and protected division were considered as potential functions for both gp and gep runs the maximum number of gene vectors was also limited to three sub ets in gep the second setup hereafter gp2 gep2 allows the algorithms to use more complex functions such trigonometric square root and exponential for creating the best solution maximum allowed gene vector was set to four sub ets in this setup in both gp1 and gep1 gp2 and gep2 the maximum tree depth was limited to five six levels similar to the most of gep applications in hydrological modelling the addition function was considered as the linking function in both gep1 and gep2 setup e g kisi et al 2012a sabouri et al 2016 regarding the evolutionary parameters such as crossover rate mutation rate and reproduction a number of trials have been performed to figure out the best evolutionary setup the rmse was used as the fitness function to train the both gp and gep algorithms and eventually the average fitness simulation during each generation up to 3000 generations was monitored to stop the run in order to avoid potential overfitting problem for each setup three trials i e separate runs were accomplished and the trial which provided the lowest rmse at training period was selected as the best trial in the present study the algebraic expressions of the best performed gp1 gp2 gep1 and gep2 models were presented in eqs 8 11 respectively it is worth to remind that these are dimensionless equation as they were derived using normalized input vectors 8 q t q t 12 q t 23 q t 1 0 7354 q t 12 0 0037 q t 24 q t 1 q t 1 q t 23 0 0037 q t 24 9 q t 0 2747 0 5293 q t 23 0 9893 q t 1 0 9893 q t 23 e q t 12 q t 1 q t 12 q t 24 10 q t q t 24 q t 1 q t 11 q t 23 q t 1 2 q t 11 q t 23 2 0231 q t 1 2 q t 24 q t 12 4 7685 11 q t 0 327 q t 1 q t 23 q t 24 q t 1 q t 12 q t 23 q t 23 q t 1 q t 1 q t 1 0 2377 q t 1 e 1 727 q t 12 q t 23 q t 23 2 q t 11 q t 24 q t 23 in general gp gep runs for both kind of setups indicated that the best performed model was created during the first 100 generations and extra generations yielded to over fitted models with less generalization ability moreover adding more complex functions into the function set not only increased the complexity of the solutions but also led the gp gep to be over trained at initial generations and consequently the induced models were inefficient at the validation periods comparative analysis among the efficiency of the standalone benchmark models has been presented in table 4 according to the results the highest performance at the unseen validation period 1996 10 2006 09 belongs to the gep1 the model provides the greatest nse measure 0 395 and the least forecasting error 281 6 l s among evolutionary models although the other models showed higher efficiency at the training period these are inefficient models at validation period particularly when the nse criterion is taken into account consequently the gep1 model was selected as the best standalone model and the associated genes are selected to be rescaled by ga parameter optimizer fig 7 illustrates the sub et representation of the gep1 in the figure the parameter ri denotes a random constant and the variables x1 x2 x3 x4 and x5 given in the terminal nodes are the normalized values of qt 24 qt 23 qt 12 qt 11 and qt 1 respectively it is apparent from the figure that the best gep model has three gene vectors with the identical gene weights equal to one it includes all the specified input vectors which implies they are more or less informative to model the process therefore application of acf pacf to select effective input vectors even for nonlinear modelling is suggested the last benchmark model in the present study is the hybrid gep lr model eq 12 that uses the power of linear regression to reformulate the relationship between the gene vectors and the normalized output data the model uses the same approach of mlr but the gene vectors see fig 8 are the input variables in the gep lr 12 q t 0 957 q t 24 1 277 q t 1 q t 11 q t 23 q t 1 2 q t 11 q t 23 0 886 2 0231 q t 1 2 q t 24 q t 12 4 7685 0 0152 3 3 generation of the gep ga model fig 8 demonstrates the time series of the best evolved gep model as well as the associated gene vectors i e gene1 gene2 and gene3 at training period as previously described ga must be applied on the gene vectors to attain optimal weights so that the accumulative error between normalized measured data and scaled simulated data is minimal according to the figure the total number of gene vectors n is three therefore every ga chromosome is composed of three parameters i e a1 a2 and a3 to determine the optimal set of the parameters that holds for good generalization the ga solver in matlab was trained a number of times under a trial and error procedure in a way that the objective function eq 5 was tried to be minimized given an extra degree of freedom to ga the noise parameter b was also considered in the objective function of some of the trials which allows the gep ga to be fairly comparable with gep lr model as both uses four parameters to superpose the rescaled gene vectors among various selection functions stochastic uniform algorithm which lays out a line in which each parent corresponds to a section of the line of length proportional to its expectation was found superior to other commonly used alternatives such as roulette and tournament selection methods table 5 summarize the optimum gene coefficients together with the corresponding objective function value for the top 12 ga trials using the parameters 12 gep ga model were produced and their performance at the validation period were compared with the gep lr model as illustrated in fig 9 the figure reveals that the best gep ga models having three parameters see fig 9a are superior to those having four parameters and also to the gep lr accordingly the best model was selected from these set eq 13 represents the best gep ga model found in this study which is correspond to the 4th trial in table 5 13 q t 0 96 q t 24 1 32 q t 1 q t 11 q t 23 q t 1 2 q t 11 q t 23 0 861 2 0231 q t 1 2 q t 24 q t 12 4 7685 3 4 discussion the abovementioned results indicate that the influence of the first sub et which represent streamflow value at the same month but two years earlier has been decreased in the gep ga model by contrast significant increase in the coefficients of the second sub ets augmented the initial model performance the qualitative and quantitative performance results of the best gep ga model were compared with its original gep and the gep lr models in table 6 according to the results the gep ga provides better fit than the benchmarks from the test results in the table it is apparent that the ga induced improvement in gep predictions was matched by an approximately 15 30 decrease increase in regards to rmse nse however such improvement does not reached by the integration of lr with gep to provide further discussion on the models performance against peak flow estimation the forecasting results obtained by the gep ga were plotted and compared to those of the observed and gep1 at the validation period fig 10 in the figure two of the quasi periodic annual peaks see fig 10a have been magnified in general the figure displays that both the models are capable of capturing the strong periodicity of the observed flow but gep suffers from insufficient accuracy at peak flows the gep ga estimates both local and global maxima better than the gep this result is consistent with previous study of wu and chau 2006 that justifies the importance of ga optimization in providing a better calibration for ann in streamflow forecasting although the proposed gep ga model improved gep forecasts considerably and the results are better than those of the other benchmarks the figure illustrates that the estimated peak values are not at the desired level of accuracy such weakness might be relevant to the intermittent structure of the streamflow sequences as well as the existence of strong deviation at the streamflow records in the range 0 1380 that makes the predictability of the peaks too difficult returning to the goodness of fit results see table 6 and comparing to the results of similar studies available in the literature e g cigizoglu 2005 kişi 2009 it should be noted that such level of accuracy was considered promising in the context of monthly flow forecast in intermittent rivers however there is still room for further research to develop more accurate streamflow forecasting models in intermittent rivers 4 conclusions classic gp and gep have difficulty creating appropriate model for intermittent streamflow forecast using more complicated functions increasing runtime number of expressions or depth of genes could not necessarily augment their performance by contrast they may lead gp gep to over trained models only after a few generations this paper proposed a novel hybrid method gep ga which embeds ga into gep to enhance gep performance through creating the new gene weights that meet the gep expressions the gep ga model was trained and validated using intermittent monthly streamflow time series from shavir stream iran the original streamflow observations were transformed into weak stationary time series and the subsequent autocorrelation analysis was used to select the effective input vectors performance of the hybrid model was cross validated in comparison to the classic gp gep mlr and the hybrid gep lr models the results revealed that the gep ga model provides up to 30 improvements over the baseline model indeed application of ga as an add in optimizer into the gep model led to a higher predictive accuracy owing to rescaling gene coefficients this is in accord with some earlier researches that demonstrate external optimization can improve feature extraction capability of gep e g xu et al 2008 alizadeh et al 2017 the present study was limited to the implementation of i streamflow as a sole predictor and ii a single optimization algorithm to modify gep one way to produce more efficient models might be the use of other exogenous variables such as rainfall and streamflow from nearby stations in addition examining the performance of other types of hybrid gep models that integrate different optimization algorithms could be investigated the methodology proposed here was root in post processing concept future studies may consider both pre and post processing techniques to increase the level of accuracy of the gep forecasts acknowledgments the streamflow data used in this research was provided by iran water resource management company www wrm ir the author also would like to thank the reviewers for their constructive comment on the manuscript 
7166,skilful forecasting of monthly streamflow in intermittent rivers is a challenging task in stochastic hydrology in this study genetic algorithm ga was combined with gene expression programming gep as a new hybrid model for month ahead streamflow forecasting in an intermittent stream the hybrid model was named gep ga in which sub expression trees of the best evolved gep model were rescaled by appropriate weighting coefficients through the use of ga optimizer auto correlation and partial auto correlation functions of the streamflow records as well as evolutionary search of gep were used to identify the optimum predictors i e number of lags for the model the proposed methodology was demonstrated using monthly streamflow data from the shavir creek in iran performance of the gep ga was compared to that of classic genetic programming gp gep multiple linear regression and gep linear regression models developed in the present study as the benchmarks the results showed that the gep ga outperforms all the benchmarks and motivated to be used in practice keywords streamflow forecasting gene expression programming genetic algorithm evolutionary optimization intermittent streams 1 introduction accurate streamflow forecasting is an important task for variety of issues in basin hydrology including but not limited to reservoir operation irrigation planning food production flood damage mitigation and environmental protection a number of models have been suggested to simulate this complex process either conceptually or through data driven methods aksoy and bayazit 2000 wang et al 2009 yaseen et al 2017 intermittent streams are those that may experience dry spells occasionally this is often the case in arid and semi arid regions salas 1993 particularly in the tributaries of mountainous rivers or snow fed streams because of the paucity of gauging stations in mountainous regions the commonly used rainfall runoff approaches may not be applicable to forecast streamflow in intermittent streams in such situations data driven techniques could be implemented to model streamflow time series if a continuous set of streamflow measurements is available then the evolved model could be applied for neighbouring tributaries using regionalization techniques in recent literature due to the advances in data driven techniques a number of cross station single station and successive station monthly streamflow forecasting models have been developed and their successful results have been reported danandeh mehr et al 2013 gene expression programming gep is relatively a new data driven method that uses population of individuals programs improves according to fitness and obtains the best solution using one or more genetic operators ferreira 2001 however there is foremost differences between genetic programming gp and gep algorithms mainly reside in the nature of their programs in both programs are nonlinear entities with different size and shape while programs are encoded as parse tree in gp they are encoded as linear strings of fixed length in gep which are afterwards expressed as the chromosomes details about gp and gep are provided in section 2 in recent years different variants of gp such as gep multigene gp mggp and linear gp lgp have been used for streamflow prediction babovic and keijzer 2002 meshgi et al 2015 ravansalar et al 2017 for example guven 2009 compared lgp with two versions of artificial neural networks anns to predict daily streamflow of schuylkill river in the usa the author demonstrated that the performance of lgp is higher than anns danandeh mehr et al 2013 used lgp for monthly streamflow prediction between successive stations at çoruh river a perennial river in turkey and showed that lgp is superior to neuro wavelet model shoaib et al 2015 integrated gep model with discrete wavelet transform pre processing approach to predict streamflow using rainfall data the main contribution of the study was the introducing a novel wavelet gep model applicable over four watersheds worth to mention the aim of applying wavelet transform on the streamflow time series was to extract their temporal and spectral information the authors used the sequential time series approach to determine the input vector matrix that built the predictive model the proposed wavelet gep model outperformed the individual gep model in all case study catchments during both training and testing phases using rainfall potential evapotranspiration and streamflow from moselle river basin in france danandeh mehr and demirel 2016 showed that mggp can be satisfactorily used for one day ahead low flow prediction more recently danandeh mehr and kahya 2017 developed a pareto optimal moving mggp model for daily streamflow prediction and demonstrate that their hybrid model can overcome the timing error in time series analysing of daily streamflow models focusing on the implementation of gp gep in wider range of hydrological studies the author s review showed that they have been frequently used to distil knowledge from natural or experimental observations e g khu et al 2001 kisi et al 2012b meshgi et al 2014 johari and nejad 2015 danandeh mehr 2018 these are techniques which generate symbolic expressions that can be interpreted and combined with domain knowledge babovic 2005 and 2009 thus motivating to be used in practice until recently only a few studies focused on the application of gep for monthly streamflow forecasting for example karimi et al 2016 forecasted river flow for both daily and monthly time scales using gep model integrated with wavelet data pre processing approach at filyos river which is a perennial river in mediterranean region of turkey for comparison purpose traditional auto regressive moving average model together with two other soft computing methods anns and adaptive neuro fuzzy inference system were used in the study the authors showed that wavelet gep was superior to its counterparts al juboori and guven 2016 developed a gep based stepwise monthly streamflow prediction model and demonstrated that their model precisely forecasts monthly flows at the perennial hurman river in turkey as well as diyalah and lesser zab rivers in iraq table 1 has listed some of the studies that implemented at least one gp variant for time series modelling of streamflow data as shown in the table karimi et al 2016 as well as al juboori and guven s 2016 papers are dealing with generating gep based monthly streamflow forecasting model for perennial rivers whereas the present study focuses on the calibrating gep for intermittent rivers the main difference between the methodology of this study and those of karimi et al 2016 and al juboori and guven 2016 is the inclusion of seasonality effect in the selection of potential predictors which is the major pattern in the intermittent streamflow series moreover the present study puts forward a new strategy to enhance the accuracy of gep forecasts on the other hand the documented studies related to the streamflow forecasting in intermittent rivers are quite limited owing to the complexity of time series modelling of intermittent flows kisi et al 2012b although one might find a few studies that suggest the implementation of soft computing methods for intermittent streamflow forecasting e g cigizoglu 2005 kişi 2009 kisi et al 2012b to the best of the author s knowledge the present study is the first study in the literature that applies gep for monthly streamflow forecasting in an intermittent stream under the lights of the abovementioned literature a new hybridization procedure is suggested in order to augment gep prediction accuracy this is a new procedure by which the coefficients of the best gep induced expression are optimized through genetic algorithm ga the proposed hybrid gep ga methodology is applied for single station monthly streamflow forecasting at shavir creek an intermittent stream located at north west of iran the efficiency results of the new model are compared with those of classic gp standalone gep as well as multi linear regression mlr and hybrid gep linear regression gep lr models developed in the present study as the benchmarks 2 materials and methods 2 1 study area and data the task of intermittent streamflow forecasting in arid and semi arid regions is more complicated than in moist tropical and subtropical climates a first order tributary of shavir stream an intermittent stream in sefidrood river basin located in a semi arid region in north west of iran was selected as the case study in the present study fig 1 the stream catchment covers an area of approximately 55 5 km2 which is about 0 03 territory of ardabil province iran the stream springs from shavirdagh mountains in ardabil and reaches to caspian sea in kiashahr city of gilan province after a course of 300 km location of the stream gauge station givi hydrometric station used in the present study was also shown in fig 1 and the historical monthly streamflow measurements at the station were depicted in fig 2 fig 2a shows 30 year mean monthly streamflow time series during the 1978 2008 period local water year the first 20 years fig 2b and the remaining 10 years fig 2c of the observations were respectively used to train and validate the standalone models i e gp gep and mlr the statistical characteristics of the entire data as well as the training and validation sub series were presented in table 2 2 2 performance evaluation there are several ways to assess the performance of a model some of which are i line plot to visually inspect the trend between measured data and model output ii scatter plot of measured data versus model output and iii error measures such as mean absolute error root mean square error rmse mean absolute relative error nash sutcliffe coefficient of efficiency nse discrepancy ratio and others tayfur 2012 in this study performance of the proposed model and benchmarks are evaluated on the basis of line plots of trends between measured data and the models output together with two error measures including nse and rmse the former equation 1 is a normalized statistic that shows how well the scatter plot of observed and modeled data lie around the 1 1 perfect model straight line the higher nse one for the perfect model the better the model the latter eq 2 is the conventional quantitative goodness of fit indicator that measures the average magnitude of the error with the same dimension of the predictand variable the lower rmse zero for the perfect model the better the model 1 nse 1 i 1 n x i obs x i pre 2 i 1 n x i obs x mean obs 2 2 rmse i 1 n x i obs x i pre 2 n where and and arethepredictedobservedvaluesofx h e r e m o n t h l y s t r e a m f l o w r e s p e c t i v e l y are the predicted observed values of x here monthly streamflow respectively ismeanamountofobserveddata a n d n d e n o t e s t h e n u m b e r o f o b s e r v a t i o n s is mean amount of observed data and n denotes the number of observations 2 3 overview of ga gp and gep ga holland 1975 goldberg 1989 is an evolutionally optimization technique that frequently used in hydrology e g mckinney and lin 1994 babovic et al 1994 wu and chau 2006 rodríguez vázquez et al 2012 the main points of a ga procedure that have been used in this study to optimize the gep model parameters are shown in fig 3 as illustrated in the figure the best solution i e the parameters of the gep model is obtained through an iterative search method including i generation of a set of candidate solutions p ii fitness evaluation and iii and application of genetic operators crossover mutation and reproduction until a number of generations previously established is achieved for the details of the evolution process in ga the readers are referred to goldberg 1989 gp koza 1992 inspired by biological evolution embedded in ga is one of the most popular data driven techniques widely used in water resources engineering detailed description of gp in hydrology literature can be found in a seminal book by babovic 1996 and pioneer research papers e g babovic and abbot 1997a b savic et al 1999 babovic and keijzer 2000 only a brief introduction is given here in order to help readers to realize the proposed methodology in this article similar to ga each chromosomes in initial population is a potential solution for a given problem however chromosomes in gp are represented by tree shaped structure of a computer program that contains nodes of functions and terminals with connecting branches for example structure of a 3 level gp chromosome a computer program was shown in fig 4 a this is a simple chromosome represents equation 3 using the root node inner nodes sin cos and outer nodes x1 x2 3 x 1 sin x 2 x 2 cos x 1 to solve any problem gp starts with the identification of the chromosomes that are more fitted to the given training data they are considered as parents for creation of offspring via the genetic operators crossover mutation and reproduction reproduction is an operation in which only one chromosome is selected to produce a single offspring which is a pure copy of the parent crossover is the operation that produces two offspring consisting of genetic material of their parents by selecting a crossover point each parent is divided into two parts where the second part represents the subtree structure with crossover point as root node then the subtrees are exchanged between the parents in order to produce two new offspring mutation is another genetic operation in which a subtree from one parent is replaced with a new typically random subtree structure the evolution process in gp is terminated when the gp algorithm finds the perfect solution the fitness of best chromosome reaches specified value or the specific number of generation is reached regardless of the quality of the solution gep ferreira 2001 is an advanced gp method that creates expression trees ets chromosome to solve a specific problem each chromosome comprises one or more genes known as sub expression tree sub et in gep the best solution is constructed by linking the sub ets through algebraic or boolean and or not functions for instance the gep chromosome shown in fig 4d represents a model i e et as a combination of three sub ets i e sub et 1 sub et 2 and sub et 3 linked by addition function hrnjica and danandeh mehr 2018 mathematically the model is presented as follows 4 x 1 sin x 2 x 2 cos x 1 x 1 x 2 log x 2 c 1 x 2 x 1 x 2 where x 1 and x 2 are the input variables vectors and the addition function between the parenthesis i e sub ets is the linking function each sub et is a part of a solution having less complexity and typically provides information about the given process less than the corresponding et thus it can be concluded that gep employs the power of small gp blocks i e genes to capture nonlinear behaviour of a complex system through a multigene structure but there are fundamental differences between gep and gp reside in the creation and combination of their genes in gp computer programs genes follow the lisp language and are expressed as parse trees with different sizes and shapes the genetic operators act on the tree shaped genes whereas the computer programs are considered as linear strings with fixed length composed of one or more genes in gep each gene is composed of a head and tail for a given number of genes and specified length of head the initial population of gep chromosomes are created through filling the head and tail domains in regard to the coding sequence of the genes known as open reading frame readers are referred to ferreira 2006 for details about evolution process in gep to apply gp and gep for predictive modelling gpdotnet v5 0 and genexprotool v5 0 software frameworks were used in the present study respectively main features of the software together with some other available gp gep software frameworks were provided in table 3 hrnjica and danandeh mehr 2018 2 4 the proposed gep ga model despite being efficient for streamflow forecasting standalone artificial intelligence ai techniques are typically not accurate enough to model the nonlinear behaviour between successive flows in intermittent rivers kisi et al 2012b to improve model accuracy hybrid ai models that are benefited from data pre post processing danandeh mehr and nourani 2018 ghorbani et al 2018 or external optimization techniques chau 2007 chen et al 2015 have been suggested in recent studies see fotovatikhah et al 2018 for a survey of some hybrid model the gep ga model fig 5 is a hybrid evolutionary algorithm that intended for fine tuning of the constants of the expressions attained from the standalone gep first predictors lags are selected auto correlation function acf or partial auto correlation function pacf are typically used to identify the optimal lag for time series modelling the other alternatives may include partial mutual information e g tran et al 2015 and nonlinear regression using gp e g uyumaz et al 2014 a certain type of standardization is used to remove nonstationary feature from predictors this is a procedure by which streamflow series are square root transformed and then standardized so that they have zero mean and unit variance delleur and kavvas 1978 showed that subtracting the monthly means essentially removes the trend in the mean and variance and yields a time series having weak stationary states which is satisfied for practical purposes in the next step the standalone gep is used to drive a parsimonious multigene solution with the specified number of expressions in this phase the initially selected predictors and constants are optimized through evolutionary search algorithm as discussed earlier then a ga optimizer is used to optimize coefficients of sub ets this improves gep accuracy if the initial model was trapped into a local optimum solution parsimony of the gep ga model and the number of constants that are subjected to external optimization depend on the number of expressions specified by the modeller during a run setup if an expression does not contain any constants further optimization is still possible as gep algorithm assumes expression coefficients equal to one by default note that gep and ga are trained and validated by different inputs but identical output vector while gep uses antecedent series of normalized observed streamflow the ga is trained using the sub ets hereafter gene vectors of the best gep solution to ascertain optimal gene coefficients i e parameters so that accumulative error between measured data and gep simulations are minimal therefore the objective function for ga is developed as follows 5 min e a i 1 m y i j 1 n a i j g e n e j 2 where yi is ith target variable genei denotes the gep induced jth gene vector and ai j is gene weight the m and n represent total number of training data pairs and gene vectors respectively in the gep ga model the complexity program size with given number of sub ets of the evolved gep model is maintained and yet more accurate solution in terms of rmse are introduced coupled use of gep and ga poses a risk of over fitting thus generalization ability of optimum solution must be carefully controlled by means of unseen validation data set both gep and ga are well stablished evolutionary techniques thus the proposed gep ga model falls within the category of metaheuristic models chau 2017 despite being hybrid the model is explicit so motivating to be used in practice 3 results 3 1 prediction scenario fig 6 shows the acf and pacf of the streamflow time series for a lag range of 0 60 months the figure includes the corresponding 95 confidence levels and exhibits a pronounced annual oscillating pattern almost 12 month periodicity at acf diagram this means that monthly streamflow at the gauging station is more correlated to its previous year amount than that of previous month in addition the pacf graph shows that the serial correlation is strongly weak after two years therefore 1 11 12 23 and 24 month lag were selected as the extent of informative lags necessary for an autoregressive monthly streamflow forecasting model in the station as shown in eq 6 this is a comprehensive combination in which all the inputs are more or less informative inasmuch as the combination is formulated by gp gep and both have the capability of finding the inputs that contribute effectively in the process any other combination scenario with fewer input variables does not included in the present study 6 q t f q t 1 q t 11 q t 12 q t 23 q t 24 where qt represents the normalized monthly discharge at the present time month t the indices t 1 and t 11 respectively refer to 1 month and 11 month lags and so on 3 2 benchmarks the mlr model eq 7 which is taught as an ideal benchmark for comparison with all other sophisticated models in streamflow forecasting was created by fitting a regression line to the training set of normalized input output vectors to this end the method of least squares under the assumption of uncorrelated noise term was used 7 q t 0 3197 q t 1 0 0007 q t 11 0 3329 q t 12 0 2182 q t 23 0 2068 q t 24 0 01055 to formulate the aforementioned combination using the evolutionary methods of gp and gep a set of random floating points i e rk k 1 2 10 in the range 1 1 were considered as the members of the terminals in addition to the training set of input vectors two different setups for gp gep runs were considered to address the risks of complexity and overfitting in the evolutionary models in the first setup hereafter gp1 gep1 only the basic arithmetic operations addition subtraction multiplication and protected division were considered as potential functions for both gp and gep runs the maximum number of gene vectors was also limited to three sub ets in gep the second setup hereafter gp2 gep2 allows the algorithms to use more complex functions such trigonometric square root and exponential for creating the best solution maximum allowed gene vector was set to four sub ets in this setup in both gp1 and gep1 gp2 and gep2 the maximum tree depth was limited to five six levels similar to the most of gep applications in hydrological modelling the addition function was considered as the linking function in both gep1 and gep2 setup e g kisi et al 2012a sabouri et al 2016 regarding the evolutionary parameters such as crossover rate mutation rate and reproduction a number of trials have been performed to figure out the best evolutionary setup the rmse was used as the fitness function to train the both gp and gep algorithms and eventually the average fitness simulation during each generation up to 3000 generations was monitored to stop the run in order to avoid potential overfitting problem for each setup three trials i e separate runs were accomplished and the trial which provided the lowest rmse at training period was selected as the best trial in the present study the algebraic expressions of the best performed gp1 gp2 gep1 and gep2 models were presented in eqs 8 11 respectively it is worth to remind that these are dimensionless equation as they were derived using normalized input vectors 8 q t q t 12 q t 23 q t 1 0 7354 q t 12 0 0037 q t 24 q t 1 q t 1 q t 23 0 0037 q t 24 9 q t 0 2747 0 5293 q t 23 0 9893 q t 1 0 9893 q t 23 e q t 12 q t 1 q t 12 q t 24 10 q t q t 24 q t 1 q t 11 q t 23 q t 1 2 q t 11 q t 23 2 0231 q t 1 2 q t 24 q t 12 4 7685 11 q t 0 327 q t 1 q t 23 q t 24 q t 1 q t 12 q t 23 q t 23 q t 1 q t 1 q t 1 0 2377 q t 1 e 1 727 q t 12 q t 23 q t 23 2 q t 11 q t 24 q t 23 in general gp gep runs for both kind of setups indicated that the best performed model was created during the first 100 generations and extra generations yielded to over fitted models with less generalization ability moreover adding more complex functions into the function set not only increased the complexity of the solutions but also led the gp gep to be over trained at initial generations and consequently the induced models were inefficient at the validation periods comparative analysis among the efficiency of the standalone benchmark models has been presented in table 4 according to the results the highest performance at the unseen validation period 1996 10 2006 09 belongs to the gep1 the model provides the greatest nse measure 0 395 and the least forecasting error 281 6 l s among evolutionary models although the other models showed higher efficiency at the training period these are inefficient models at validation period particularly when the nse criterion is taken into account consequently the gep1 model was selected as the best standalone model and the associated genes are selected to be rescaled by ga parameter optimizer fig 7 illustrates the sub et representation of the gep1 in the figure the parameter ri denotes a random constant and the variables x1 x2 x3 x4 and x5 given in the terminal nodes are the normalized values of qt 24 qt 23 qt 12 qt 11 and qt 1 respectively it is apparent from the figure that the best gep model has three gene vectors with the identical gene weights equal to one it includes all the specified input vectors which implies they are more or less informative to model the process therefore application of acf pacf to select effective input vectors even for nonlinear modelling is suggested the last benchmark model in the present study is the hybrid gep lr model eq 12 that uses the power of linear regression to reformulate the relationship between the gene vectors and the normalized output data the model uses the same approach of mlr but the gene vectors see fig 8 are the input variables in the gep lr 12 q t 0 957 q t 24 1 277 q t 1 q t 11 q t 23 q t 1 2 q t 11 q t 23 0 886 2 0231 q t 1 2 q t 24 q t 12 4 7685 0 0152 3 3 generation of the gep ga model fig 8 demonstrates the time series of the best evolved gep model as well as the associated gene vectors i e gene1 gene2 and gene3 at training period as previously described ga must be applied on the gene vectors to attain optimal weights so that the accumulative error between normalized measured data and scaled simulated data is minimal according to the figure the total number of gene vectors n is three therefore every ga chromosome is composed of three parameters i e a1 a2 and a3 to determine the optimal set of the parameters that holds for good generalization the ga solver in matlab was trained a number of times under a trial and error procedure in a way that the objective function eq 5 was tried to be minimized given an extra degree of freedom to ga the noise parameter b was also considered in the objective function of some of the trials which allows the gep ga to be fairly comparable with gep lr model as both uses four parameters to superpose the rescaled gene vectors among various selection functions stochastic uniform algorithm which lays out a line in which each parent corresponds to a section of the line of length proportional to its expectation was found superior to other commonly used alternatives such as roulette and tournament selection methods table 5 summarize the optimum gene coefficients together with the corresponding objective function value for the top 12 ga trials using the parameters 12 gep ga model were produced and their performance at the validation period were compared with the gep lr model as illustrated in fig 9 the figure reveals that the best gep ga models having three parameters see fig 9a are superior to those having four parameters and also to the gep lr accordingly the best model was selected from these set eq 13 represents the best gep ga model found in this study which is correspond to the 4th trial in table 5 13 q t 0 96 q t 24 1 32 q t 1 q t 11 q t 23 q t 1 2 q t 11 q t 23 0 861 2 0231 q t 1 2 q t 24 q t 12 4 7685 3 4 discussion the abovementioned results indicate that the influence of the first sub et which represent streamflow value at the same month but two years earlier has been decreased in the gep ga model by contrast significant increase in the coefficients of the second sub ets augmented the initial model performance the qualitative and quantitative performance results of the best gep ga model were compared with its original gep and the gep lr models in table 6 according to the results the gep ga provides better fit than the benchmarks from the test results in the table it is apparent that the ga induced improvement in gep predictions was matched by an approximately 15 30 decrease increase in regards to rmse nse however such improvement does not reached by the integration of lr with gep to provide further discussion on the models performance against peak flow estimation the forecasting results obtained by the gep ga were plotted and compared to those of the observed and gep1 at the validation period fig 10 in the figure two of the quasi periodic annual peaks see fig 10a have been magnified in general the figure displays that both the models are capable of capturing the strong periodicity of the observed flow but gep suffers from insufficient accuracy at peak flows the gep ga estimates both local and global maxima better than the gep this result is consistent with previous study of wu and chau 2006 that justifies the importance of ga optimization in providing a better calibration for ann in streamflow forecasting although the proposed gep ga model improved gep forecasts considerably and the results are better than those of the other benchmarks the figure illustrates that the estimated peak values are not at the desired level of accuracy such weakness might be relevant to the intermittent structure of the streamflow sequences as well as the existence of strong deviation at the streamflow records in the range 0 1380 that makes the predictability of the peaks too difficult returning to the goodness of fit results see table 6 and comparing to the results of similar studies available in the literature e g cigizoglu 2005 kişi 2009 it should be noted that such level of accuracy was considered promising in the context of monthly flow forecast in intermittent rivers however there is still room for further research to develop more accurate streamflow forecasting models in intermittent rivers 4 conclusions classic gp and gep have difficulty creating appropriate model for intermittent streamflow forecast using more complicated functions increasing runtime number of expressions or depth of genes could not necessarily augment their performance by contrast they may lead gp gep to over trained models only after a few generations this paper proposed a novel hybrid method gep ga which embeds ga into gep to enhance gep performance through creating the new gene weights that meet the gep expressions the gep ga model was trained and validated using intermittent monthly streamflow time series from shavir stream iran the original streamflow observations were transformed into weak stationary time series and the subsequent autocorrelation analysis was used to select the effective input vectors performance of the hybrid model was cross validated in comparison to the classic gp gep mlr and the hybrid gep lr models the results revealed that the gep ga model provides up to 30 improvements over the baseline model indeed application of ga as an add in optimizer into the gep model led to a higher predictive accuracy owing to rescaling gene coefficients this is in accord with some earlier researches that demonstrate external optimization can improve feature extraction capability of gep e g xu et al 2008 alizadeh et al 2017 the present study was limited to the implementation of i streamflow as a sole predictor and ii a single optimization algorithm to modify gep one way to produce more efficient models might be the use of other exogenous variables such as rainfall and streamflow from nearby stations in addition examining the performance of other types of hybrid gep models that integrate different optimization algorithms could be investigated the methodology proposed here was root in post processing concept future studies may consider both pre and post processing techniques to increase the level of accuracy of the gep forecasts acknowledgments the streamflow data used in this research was provided by iran water resource management company www wrm ir the author also would like to thank the reviewers for their constructive comment on the manuscript 
7167,velocity distributions for open channel flows have been investigated using deterministic and probabilistic approaches it is well known that the vertical velocity profiles in wide open channels i e aspect ratio width depth 5 can be approximated by logarithmic velocity laws and power laws recently the entropy concept in the forms of shannon entropy and tsallis entropy has been employed to estimate velocity distributions in open channels with different aspect ratios the accuracy of conventional velocity equations is highly dependent on their parameters that can only be estimated by empirical or semi empirical analytical relations which requires either a good knowledge of velocity field and or physical properties of the channel such as topographic conditions sedimentation conditions and boundary roughness in contrast the entropy based velocity distributions derived based on the least biased probability density function pdf by treating time averaged velocities as random variables are resilient regardless of the flow and channel conditions however a comparison of the velocity profiles computed using deterministic approaches and probabilistic approaches has not been rigorously conducted furthermore the accuracy and reliability of associated velocity distribution equations have not been tested thoroughly using data sets collected using advanced techniques this paper presents a comprehensive and comparative study to analyze the distinctions and linkages between four commonly used velocity laws and two entropy based velocity distributions theoretically and quantitatively using selective laboratory and field measurements available in the literature considering typical sedimentation and channel hydraulic conditions amongst all tsallis entropy based velocity distribution developed from a generalized form of informational entropy exhibits universal validity to sediment laden flows in wide alluvial open channels and is found to be superior to others to predict velocity profiles in large waterways with unmanageable rough beds keywords entropy open channel flow probability distribution velocity distribution law of the wall power laws 1 introduction there is a shortage of reliable velocity data in waterway system during storm events in which the discharge varies rapidly and velocity sampling is extremely difficult recently high tech based measuring techniques such as particle image velocimetry piv adrian 1997 hyun et al 2003 acoustic doppler velocimeters adv holmes and garcia 2008 acoustic doppler current profilers adcp gonzalez et al 1996 and previously developed laser doppler velocimetry ldv also known as laser doppler anemometry lda nezu and rodi 1986 have been applied however their implementation is still subject to uncertainties associated with weather and measurement techniques and involve considerable cost furthermore velocities near solid boundaries and free surface cannot be measured with adcp s due to the interference in the acoustic signals caused by boundary reflectance and are extrapolated based on the power law distribution currently incorporated in adcp post processing software thus for these measurements to be efficient a reliable estimation of velocity distribution for the entire flow depth that has wide applicability regardless of channel properties and flow conditions is preferable to sufficiently reduce the number of velocity observations herein the velocity distribution refers to the vertical distribution of time averaged velocity of primary flow in a transverse cross section eliminating the turbulent oscillation component nezu and rodi 1986 found experimentally that the open channel flow velocity distribution is highly dependent on the presence of secondary currents due to the side wall effects they further divided open channels into two categories as narrow or wide channels according to the aspect ratio a r b d for narrow channels with a r 5 the maximum velocity happens beneath the water surface as a result of the momentum exchange between the primary flow and the secondary circulation also known as velocity dip for wide channels with a r 5 the side wall effects are however reduced and become negligible in the center zone of the width b 5 d thus for sufficiently wide channels with a r 5 the velocity distribution in the large portion of the cross section can be considered to follow a 1d type of velocity distribution in which the velocity profile along each vertical is a monotonic increasing function of the vertical distance to the bed the current analysis is confined to wide channels where 1d assumptions are valid in fluid mechanics open channel flows are part of the general class of bounded shear flows with free surface where velocity profiles are obtained by solving navier stokes equations with given boundary conditions usually under steady uniform flow assumptions logarithmic and power laws are two well known forms of such solution family von karman 1921 1930 and prandtl 1925 first investigated flow through pipes theoretically by integrating the experimental studies of nikuradse 1933 and derived a set of rational velocity distributions and hydraulic resistance relations for turbulent flows over flat plates and in circular pipes these have been extended to open channel flow to include free surface effects rouse 1959 sarma et al 1983 furthermore extensive research has been done to extend the logarithmic type velocity or velocity defect law to sediment laden flow by treating the von karman constant and the law of the wake as functions of flow sediment load characteristics vanoni 1946 coles 1956 einstein and chien 1955 chien 1956 yanlin and finlayson 1972 schlichting 1979 coleman 1981 parker and coleman 1986 wang apr 1981 sill 1982 hoffman and mohammadi 1991 chiu and murray 1992 hinze 1959 showed that the logarithmic velocity distribution can be approximated by the power law velocity distribution in most of the boundary layer cross section specially in the overlapping region of the inner law i e the law of the wall and the outer law i e the velocity defect law chen 1991 wooding et al 1973 then theoretically evaluated the differences between the logarithmic velocity distribution and the power velocity distribution and found that the power law with a small exponent cannot be distinguished experimentally from the logarithmic law it was argued that the power law velocity profile was preferable to the logarithmic velocity distribution landweber 1957 rouse 1959 for three reasons 1 the logarithmic velocity distribution should be considered as an asymptotic law valid for very large reynolds numbers schlichting 1968 whereas the power law is less restrictive to the flow regime and is also applicable to smaller reynolds numbers chen 1991 2 the power law appears to be better able to incorporate the effects of sediment on velocity profiles without troublesome singularities near the bed and or derivative discontinuities at axes and planes of symmetry karim and kennedy 1987 chen 1991 3 hinze 1975 and schlichting 1979 showed that the power law conforms better than the logarithmic relation to the pipe flow data of nikuradse 1933 and laufer 1953 however due to the inherent system randomness and incomplete input information there are always uncertainties associated with theoretical predictions or experiment based calculations of variables or parameter estimation involved in the above conventional deterministic approaches thus the time averaged streamwise velocities should rather be statistically regarded as a random variable the informational entropy theory facilitates the application of probabilistic approaches to hydraulics and hydrology as well as environmental engineering by accounting for the associated uncertainties singh 2013 singh 2014 singh 2015 the principle of maximum entropy pome jaynes 1957 jaynes 1957 states that any system in equilibrium state tends to maximize its entropy under universal constraints which is equivalent to the theory of minimum energy dissipation yang 1976 chiu 1987 first applied the probabilistic concept via shannon entropy to describe the vertical distribution of mean velocity shear stress and suspended sediment concentration in open channel flows using shannon entropy subject to pome thus the derived velocity distribution is claimed to be least biased towards the unknowns and most biased towards the constraints marini et al 2011 tsallis entropy a generalized form of informational entropy was also utilized to describe the streamwise velocity in wide open channels singh and luo 2011 cui and singh 2014 singh 2016 besides the difference in mathematical formulations of the numerous developed velocity distribution equations no comprehensive and rigorous analysis has been conducted to compare the goodness of fit of the aforementioned methods using high resolution data measured with advanced tools and techniques thus this paper presents a comparative analysis on the widely accepted forms of 1d logarithm power law velocity distribution and two entropy based velocity distributions both theoretically and quantitatively with the following specific objectives 1 to compare preselected feasible ways that well balance information parsimony and overall accuracy to estimate key parameters involved in logarithmic and power law velocity distributions 2 to identify the differences and linkages between the formulations of different methods and 3 to compare the accuracy and applicability of the velocity distribution laws considered under various flow and channel conditions overall this paper demonstrates the resilience of entropy based velocity distributions in variety of applications and provides auxiliary alternatives for streamflow measurement and numerical validation purposes 2 conventional deterministic 1d velocity distributions 2 1 logarithmic velocity distribution the 1d logarithmic velocity law was developed by assuming a steady uniform in a wide open channel flow having a mean width b and a mean depth d i e aspect ratio defined as a r b d 5 with a mean flow velocity u as shown in fig 1 the flow velocity distribution under consideration was well established both experimentally and from dimensional analysis schlichting 1979 nezu and rodi 1986 as 1 u u κ ln y y 0 eq 1 is considered as the law of the wall since it was considered to strictly apply inherently in a relatively thin layer y d 0 2 near the bed coleman and alonso 1983 nezu and nakagawa 1993 whereas it is commonly used as a reasonable estimation of the entire depth for most of the flow in many streams and rivers with a correction for wake effects coles 1956 coleman 1986 which can be ignored for single phase and uniform flows schlichting 1979 derived the outer form of the law of the wall by manipulating eq 1 based on the assumption that the maximum flow velocity u max takes place at the water surface where y d i e u d u max this alternative formulation of logarithmic velocity law is also known as velocity defect law whereas it does not require as much knowledge of the bed roughness as the law of the wall does 2 u max u u 1 κ ln y d parameter estimation key parameters in eq 1 are shear velocity u von karman constant κ and bed roughness length y 0 which equates to a very small almost unmeasurable value of depth above the bed where the flow velocity goes to zero based on the experimental results by nikuradse 1933 christoffersen and jonsson 1985 developed a generalized formula to estimate y 0 as a function of effective roughness height k s for flows from hydraulic transitional to fully hydraulic rough as 3 y 0 k s 30 1 exp u k s 27 ν ν 9 u where ν is the kinematic viscosity of water the roughness k s reflects both surface roughness and form roughness of the channel bed rouse 1959 hence its complete evaluation is complicated which further limit the accuracy of eq 3 singh 2011 proposed an even more simple algebraic approach by substituting y d in eq 1 given the knowledge of u d u and y 0 can then be simply estimated as the follows 4 y 0 exp κ u d u d the goodness of eqs 3 and 4 were tested and compared using 29 sets of flume data collected by einstein and chien 1955 that contains all information necessary for the calculation fig 2 a showed that eq 4 agrees better with the observations of parameter y 0 than eq 3 the latter tends to underestimate parameter y 0 for different levels of grain induced bed roughness with a root mean square deviation rmsd on the magnitude of 0 0018 whereas the value yielded from eq 4 was only 0 00016 thus eq 4 is more suitable to estimate parameter y 0 given limited information of boundary roughness i e k s parameter κ is known as von karman universal constant and its clear water value κ 0 41 can be considered to be a universal one smith and mclean 1977 coleman 1981 nezu and rodi 1986 soulsby and wainwright 1987 lyn 1988 long et al 1993 wright and parker 2004 however according to the experiments years ago reported by einstein and chien 1955 1975 von karman constant κ can deviate from its clear water value due to the effect of suspended sediment a smaller value of κ results in a less vigorous exchange of motion and a smaller internal friction opposing the flow in the main body of a sediment laden flow κ is found to be reduced from its clear water value with the increasing sediment concentration however κ does not become less than 0 2 except for flows with hyperconcentrations of fine sediment wang apr 1981 as also discussed by vanoni 1975 and summarized by karim and kennedy 1987 herein we adopted a logarithmic relation suggested by einstein and chien 1955 as below 5 κ 0 132 log 10 35 45 k s y 0 from the above relation κ equates its clean water value when y 0 k s 30 for fully rough turbulent flow fig 2a presents the values of κ estimated using eq 5 compared with the values obtained from semi log plotting of velocity measurements by einstein and chien 1955 this formula correlates the ratio of roughness height and length k s y 0 to the parameter κ with a coefficient of determination r 2 0 86 however the accuracy of this formula is subject to the goodness of measurements and estimation of associated interim parameters nezu and nakagawa 1993 analyzed several methods to estimate the shear velocity u in the case of steady uniform flow in wide channels u can be estimated as gds 0 where s 0 is the bed slope however this method requires an accurate measurement of bed slope in the vicinity of measured section which is always difficult in the case of nonuniform flow the energy slope s e should replace s 0 which involves more uncertainties associated with the estimation of energy coefficient and contraction expansion factor and so is inherently non rigorous 2 2 power law velocity distribution the power law is an alternative method to predict the vertical velocity profiles of the time averaged streamwise velocity in open channel flows assuming uniform hydraulic rough flow and neglecting the wake effect eq 1 and keulegan s resistance law for rough flow keulegan 1938 can be approximated by the power law of the manning strickler form garcia 2008 this gives rise to the widely used power law velocity distribution for open channel flows proposed by karim and kennedy 1987 as follows 6 u u max y d 1 n the effect of moving sediment on the velocity profiles is incorporated into the exponent n formulated on the basis of energy dissipation considerations and quantified by means of a fairly large body of laboratory and field measurements chen 1991 derived an alternative form of power law velocity distribution from the logarithmic velocity profile using darcy weisbach friction factor for steady uniform pipe and channel flows as follows 7 u u a y y 0 m p m p 1 n where u and y 0 are essentially the same as defined in the logarithmic law a and m p are parameters with m p and n so related as in eq 7 the power law velocity distribution given by eq 7 is indeterminate because exponent m p and the associated coefficient a vary either with the global reynolds number for hydraulically smooth flows or with the global relative roughness for fully rough flows due to incomplete similarity as shown in fig 3 parameter estimation chen 1988 1989 concluded that the best estimation of parameters m p and a should satisfy in a least squares sense of the logarithmic law within an acceptable tolerance for a certain range of u u or y y values and the m p value should be confined to a range between 0 and 1 a nonlinear regression analysis in fig 3 shows that the larger m p value namely the smaller the depth leads to a greater deviation of power law from the logarithmic law for a range of velocity or depth and vice versa consequently as m p drops to zero the power law virtually overlaps with logarithmic law at the possibly largest value of u u or y y 0 thereafter it was considered that the 1 7 power and 1 6 power velocity distributions are typical choices for hydraulically smooth flows and fully rough flows respectively assuming a perfect agreement with the logarithmic law the product of κ m p a and e the base of the natural logarithm should equate 1 thus parameter a can be estimated as 8 a 1 em p κ given the mean u m and maximum u max velocities n can be solved by taking the depth average of velocity using eq 6 singh 2013 9 n u m u max u m another alternative expression for n was developed by zimmerman and kennedy 1978 for open channel flow in wide rectangular channels as 10 n κ 8 f where f is the darcy weisbach friction factor thus n appears to be correlated with the frictional resistance at the bed garcia 2008 reviewed a number of power and logarithmic expressions to estimate f and to evaluate flow resistance in open channel flows herein f is estimated using the shear stress form of darcy weisbach equation as follows 11 8 f 1 2 u m u n can also be estimated using shannon entropy as singh 1996 singh 2014 12 n 1 ln u d ln u parameter n can also be determined in the least square sense given a fair amount of velocities sampled the values obtained in this approach might be considered as a criterion to justify the goodness of aforementioned analytical and empirical relations i e eqs 9 10 and 12 a total of 40 sets of flume data coleman 1986 were examined for this purpose in fig 4a the least square regression analysis gave an estimation of parameter n in the range from 6 13 to 9 90 whereas eq 10 by zimmerman and kennedy 1978 fluctuated in a relatively narrow range from 7 46 to 8 28 the reason may resides in the facts that the reported κ is indifferent to suspended sediment concentration in coleman s experiment and the friction factor f estimated from eq 11 staying almost constant moreover the goodness of eq 10 and eq 11 is inherently dependent on a good knowledge of the near bed velocity field and channel properties which is generally difficult to measure it also appears that the estimation given by eqs 9 and 12 follows a highly linear relation with the values estimated by the least square method the former requires the least information and the latter appears to give the best estimation thus both eqs 9 and 12 can give an initial estimate and the values can be further adjusted according to the linear correction as annotated in fig 4a accordingly the velocity profiles predicted using eq 6 with n estimated from eqs 9 and 12 result in better agreement with the measurements fig 4b 3 entropy based 1d velocity distribution in probability theory the time averaged velocity u should rather be considered as a random variable with f u as its cumulative distribution function cdf and f u as the associated probability density function pdf as 13 f u 0 y f u y dy y d where y vertical distance from the bed and d the flow depth eq 13 assumes that stream wise velocity monotonically increases with respect to water depth hence a maximum value happens at the surface when the water air interface shear is neglected entropy h u quantifies the uncertainty associated with u or its pdf f u or in general denotes the randomness of the system the derivation of the 1d velocity distribution applying entropy theory follows 1 definition of the continuous form of entropy 2 specification of universal constraints that velocity distribution is subjected to 3 maximization of entropy and derivation of probability distribution of velocity 4 derivation of velocity distribution and 5 specification and estimation of parameters 3 1 tsallis entropy based 1d velocity distribution tsallis 1988 2004 proposed a generalized form of informational entropy h and its continuous form koutsoyiannis 2005a b can be written as 14 h k m 1 1 0 u d f u m du k m 1 0 u d f u 1 f u m 1 du where k is a constant to keep the entropy invariant of the system of measurement while keeping the units of entropy consistent and is often taken as unity and m is an exponent parameter maximization of h is realizable only for equal probability of occurrences when m 0 singh and luo 2011 applied tsallis entropy to derive velocity distributions in wide open channels under the hypothesis defined in eq 13 by means of the principle of maximum entropy pome the least biased pdf f u should also result in maximum entropy subject to constraints c r r 1 2 n defined by universal conservation laws as 15 c r 0 u d g r u f u du g r u r 1 2 n where n denotes the number of constraints and g r u represent r th order moment of u barbe et al 1991 showed that the effects of momentum and energy conservation constraints on velocity profiles were trivial compared to that of the mass continuity constraint hence was neglected for computational efficiency accordingly singh and luo 2011 derived the least biased probability density function as eq 16 16 f u m 1 m λ v λ 1 u 1 m 1 eq 16 defines the generic probability distribution of velocity that satisfies eq 15 following euler lagrange calculus of variation where λ v and λ 1 are lagrange multipliers the 1d velocity distributions u y was derived by substituting eq 16 into eq 13 and applying integration as 17 u m m 1 1 λ 1 λ 1 y d m 1 m λ v m m 1 m 1 m λ v λ 1 parameter estimation the key parameters involved in both f u and u y are m λ v and λ 1 λ v and λ 1 can be determined by solving the following nonlinear system which is obtained by integration of eqs 15 for i 1 2 after plugging in the derived f u as in eq 16 18a m 1 m λ v λ 1 u d m m 1 λ 1 m 1 m λ v m m 1 18b u d λ 1 m 1 m λ v λ 1 u d m m 1 1 λ 1 2 m 2 m 1 m 1 m λ v λ 1 u d 2 m 1 m 1 1 λ 1 2 m 2 m 1 m 1 m λ v 2 m 1 m 1 u m singh and luo 2011 pointed out that the feasible range of m is from 0 to 2 fig 5 shows that the slope of velocity profile u y increases with increasing m for given u m and u max which indicates that m increases with bed roughness and flow resistance thus m is somewhat similar to the exponent parameter m in the power law velocity distribution i e eq 7 relating to the same channel properties while differing in magnitude fig 6 a and b show that the solution of λ 1 and λ v when m 3 4 must have opposite signs to guarantee velocity as a positive quantity i e u 0 more analysis in the following shows that this conclusion applies to other m values it appears that in the inner region u y decreases as the absolute value of λ 1 increases on the contrary u y increases indicating an increase in bed shear as the absolute value of λ v increases these plots also indicate that the larger velocities at the water surface would yield smaller magnitude of λ 1 but larger magnitudes of λ v between the two parameters λ v varies within a relatively smaller range thus the velocity profiles might be more sensitive to the change of λ v the previous numerical experiments showed that m 3 4 yielded the best prediction for open channel flows without strong interference from the beds and suspended sediment hence can be adopted as a first estimation of the 1d velocity distribution singh and luo 2011 the maximum entropy of the dimensionless velocity u u distribution was obtained through the integration as eq 14 with the least biased probability density function derived as eq 16 for m 3 4 and the analytical form is derived as 19 h u u 4 1 27 2 u 1 4 λ 1 1 λ v λ 1 u d 2 1 λ v 2 fig 7 a shows the regression analysis between the maximum entropy calculated using eq 19 and λ 1 that was obtained from the regression analysis using 29 sets of flume data by einstein and chien 1955 at different levels of sediment concentration and bed roughness the lagrange parameter λ 1 may be considered as a hydraulic parameter that relates to bed roughness and sediment concentration chiu 1987 stated that higher entropy in open channel flow was associated with rougher beds and or with higher sediment concentration which resulted in larger system randomness the relatively larger range of λ 1 in the clear water flows emphasizes the noticeable trend of λ 1 to decrease with increased bed roughness while for the sediment laden flows the trend reflects mixed effect of both suspended sediment and bed shear 3 2 shannon entropy based 1d velocity distribution taking the limit of eq 14 as m approaches unit it reduces to the form of shannon entropy 20 h k 0 u d f u ln f u du following the aforementioned procedure chiu 1987 derived a least biased pdf describing the velocity distribution in wide open channels as 21 f u e λ 1 1 e λ 2 u in which λ 1 and λ 2 are parameters lagrangian multipliers a relationship between the two parameters was derived by substituting eq 21 into eq 15 as 22 e λ 1 1 λ 2 e λ 2 u d 1 1 parameter estimation by solving for λ 2 numerically chiu 1987 obtained an expression relating λ 2 to the shear velocity u as 23 λ 2 k 1 u where k 1 is somewhat similar to von karman constant κ hence may be estimated using a similar approach substituting λ 1 and λ 2 with eq 23 the 1d velocity distribution was derived as 24 u u k 1 ln 1 exp k 1 u d u 1 y d eq 24 implies that the accuracy of shannon entropy based velocity distribution is highly dependent on the estimation of shear velocity u and parameter k 1 similar to the logarithmic velocity distribution but without problematic singularities at the bed substituting eqs 22 and 23 into eq 20 one gets the maximum entropy of the dimensionless velocity u u as 25 h u u h u ln u ln e u d k 1 u 1 u d k 1 u 1 1 e u d k 1 u 1 1 ln k 1 utilizing the entropy calculated by eq 25 chiu 1987 found a relation between parameter k 1 and maximum entropy h u u by regression analysis as shown in fig 7b due to their similarity the values of k 1 were taken to be the same as those of κ as reported by einstein and chien 1955 similar to λ 1 in the velocity equation based on tsallis entropy the parameter k 1 may also be considered as an indicator of bed roughness and sediment concentration chiu 1987 the lower values of k 1 in fig 7b was associated with higher values of entropy corresponding to flows over coarser beds and or with higher sediment concentration a linear correlation between k 1 and entropy has been established based on regression with a r 2 value as high as 0 99 in general the values of λ 1 and k 1 for sediment laden flow are lower than their values for clear water flows the comparison shows that the tsallis entropy based velocity with m 3 4 results in a higher value of entropy h u u for the same scenarios according to pome the former might give a better interpretation of the system under given conditions 4 selected field measurements and laboratory data of velocity profiles in sediment laden flows in order to evaluate the performances of the aforementioned 1 d velocity formulations sixteen data sets which were reported by kironoto 1992 hyun et al 2003 gonzalez et al 1996 and guo 1998 were selected to assess the accuracy and applicability of the six velocity equations to typical channel and flow conditions the selected data sets cover laboratory controlled flumes large constructive and natural rivers which diversify in flow conditions boundary roughness and sediment load moreover the selection also reflects various high tech measurement techniques including adcp piv and ldv in addition to traditional ones to assess the goodness of the velocity distributions while excluding the bias due to measurement techniques the point velocity measurements were made along the flume or channel center line where side wall effects on the velocity profile were minimal table 1 summarizes the flow and channel hydraulic parameters and specifies the parameters for each velocity model the roughness reynolds number given by u k s ν calculated for all the selected flows were much larger than 11 6 thus the flows were within the turbulent rough flow regime kironoto 1992 measured the mean velocity profiles using prandtl tubes coupled with a pressure transducer at the swiss federal institute of technology epfl in a 16 8 m long 0 6 m wide and 0 8 m high flume fig 8 the selected four sets of data were for fully developed uniform turbulent flows on rough plate hyun et al 2003 measured the complex flow field over a train of two dimensional dunes attached to the bed of a 10 m long rectangular 610 mm 610 mm open channel flume fig 9 the velocities were measured using a two component fiber optic ldv system and piv in a complementary manner to optimize the accuracy in the near wall region and wake region the flow field was suitable to evaluate the applicability of different velocity models as it contained much of the complexity involved in practical hydraulic engineering applications gonzalez et al 1996 reported two sets of velocity distributions collected by u s geological survey usgs with a fixed adcp at the center of chicago sanitary and ship canal cssc at romeoville illinois usa fig 10 the cssc is an excavated channel of limestone and a rigid bed the channel is about 49 m wide and the flow depth varied between 6 and 8 5 m with hydraulic control works throughout the chicago area waterway system caws and sanitary inflows the cssc is a highly regulated unnatural waterway with continuous perturbations that propagate from lake michigan and influences from the des plaines river that is located just upstream thus continuous and accurate measurement of discharge in the cssc requires an innovative technology to implement repeating high resolution velocity measurement the first data set was collected on august 17 1994 by averaging 70 velocity profiles measured at a time interval of 4 75 s the measurements were confined to the area within 0 27 and 6 27 from the channel bed the second data set was collected on may 12 1995 by averaging 25 velocity profiles measured at a time interval of 4 17 s each profile consists of velocity measurements within 0 41 and 7 16 m above the channel bed guo 1998 reported velocity and sediment concentration profiles measured at feng jie hydrologic station the yangtze river china fig 11 and hua yuan kou hydrologic station the yellow river china fig 12 the four data sets selected from the measurements for the yangtze river were collected in july 1976 and august 1981 with the flow depth varying from 32 3 to 45 9 m the channel width at feng jie hydrologic station is about 1200 m the selected four data sets for the yellow river were collected in august 1983 while the flow depth stabilizes at an average of 2 4 m and the channel width at the station is approximately 825 m 5 results and discussions the error analysis summarized in table 2 uses the root mean square error rmse as a measure to evaluate the deviation between the model predicted and measured values of dimensionless velocity u u max the conventional deterministic velocity distributions appear to perform slightly better in predicting the velocity distribution under experimental conditions than in large natural alluvial waterways in which more complex flow behavior and parameter uncertainties arise amongst all the worst prediction fell in the case of the yellow river with shallower water and high sediment concentration regardless of the inevitable errors tsallis entropy and shannon entropy based velocity equations appeared to be resilient to channel hydraulic properties and flow conditions of which the former yielded on average the best prediction of the velocity profiles over the entire water depth fig 8 illustrates one of the simplest scenario with uniform flow in a wide flume with laboratory controlled rough bed the velocity profiles predicted using conventional power laws and logarithmic velocity laws were comparable to the ones predicted by entropy based distributions overall the clear water value of κ provided acceptable fits to the observations without outstanding presence of sediment in the flow however even for this idealized case the logarithmic law eq 6 and the log defect law eq 2 still resulted in minor deviation in the outer region among which the former tended to underestimate and the latter tended to overestimate fig 8b and d this consistent deviations suggest a constant value of κ that would fit the entire water depth was unrealizable the estimated values of n using eq 9 were close to but smaller than the value of 6 which links to the power law for uniform rough flows in wide open channels shannon entropy based profiles overlapped log defect law profiles when parameter k 1 took essentially the same value as of κ tsallis entropy based method with m 3 4 led to better local accuracy in the wake region and the inner region as can be seen from the comparison with the experimental data series of upa5 and upd5 the local deviation may be minimized by further adjusting the values of parameters λ 1 and λ v according to the sensitivity analysis as presented in fig 6 the local advantage of accuracy in the inner region is more obvious in fig 9a and b as well as their dimensionless counterparts as shown in fig 9c and d while the logarithmic laws tended to overestimate when y d fell below 0 2 this implies that in the lower part of the alluvial channel the increased sediment concentration and the complex internal exchange of sediment between the bed load and suspended sediment leads to a noticeable acceleration of flow velocity vanoni 1946 it further indicates that the logarithmic law with κ of the clear water value tends to underestimate the bed shear stress as well as the boundary shear layer thickness in sediment laden flows similarly as in fig 10 to account for the effect of increasing bed shear exponent m in tsallis entropy is increased to 2 and 5 4 for s1 and s2 respectively which is consistent with the aforementioned argument that m increases with increasing bed roughness as s1 and s2 are measured at the station upstream and downstream of the dune respectively the 1d velocity distributions agree with the velocity field at s1 which was not influenced by the dune downstream fig 10a and c however the two dimensional dune added complexity to the flow field of s2 none of the 1 d velocity models can describe adequately the flow field particularly in the near wall region fig 10b and d this distinction suggests that the bed form induced flow resistance may result in significant disturbance to the flow field as a result of the intensified turbulent shear and secondary circulation associated with resultant flow separation reversal and reattachment the velocity profiles are highly influenced by these three dimensional features and deviate substantially from any type of 1d velocity distributions thus a composite velocity law or a turbulence model is preferable to interpret the stratification of velocity distribution over predominant bed forms similar to the laboratory configurations i e figs 8 and 10 figs 11 and 12 show that the six models are comparable in predicting the velocities in the upper region of flows in large alluvial systems however logarithmic velocity laws and shannon entropy based velocity distributions gradually deviate from the power laws and tsallis entropy based velocity distributions in the lower region when y d 0 2 and result in overestimations the power laws and tsallis entropy based velocity distribution resemble the patterns and magnitudes of measurements in the lower region which can be consistently detected from figs 9 to 12 the similarity in their performance and mathematical formulations suggests that tsallis entropy based velocity distribution may be considered as a generalized form of power laws with additional parameters λ 1 and λ v to strictly satisfy the universal laws of probability and mass which is also consistent with the findings presented by singh 2013 unlike power laws where the exponent parameter n is subject to change with flow conditions e g mean flow velocity and depth as in table 1 the exponent parameter m remains constant within the same channel reach if the channel properties e g aspect ratios bed slope and roughness as in table 1 stay relatively stable with time and hydrologic conditions in the case of laboratory flume with flat and relatively smooth bed such as the experimental apparatus of kironoto 1992 the suggested value of m is 3 4 for excavated channel reaches with manageable roughness such as the cssc and feng jie hydrologic station at the yangtze river the suggested value of m is 5 4 for natural alluvial channels with highly non uniform rough beds e g hua yuan kou hydrologic station on the yellow river the suggested value of m is as high as 2 in which the conventional and shannon entropy based velocity equations consistently underestimate the velocities in the lower 10 of the flow depth to be noticed although all the flows considered here are within the fully hydraulic rough flow regime with u k s ν 11 6 the exponent parameter n can drop to as small as 3 03 as reported in table 1 which contradicts the previous widely accepted value of n 6 for hydraulically rough flows it also shows that κ decreases to 0 210 for the selected station on the yellow river with the average sediment concentration as high as 20 kg m3 which is over four times sediment concentration for the selected station in the yangtze river hence it proves that the clear water value of 0 41 is only applicable as long as the effects of the sediment in suspension and grain particles that re entrain from the bed to the flow remain negligible 6 summary and conclusions to summarize this study demonstrated that for a channel of bed covered with smooth or moderate material conventional logarithm and power velocity laws and entropy based velocity distributions display comparable performance however the deviations of the conventional velocity laws increase with respect to the scale and complexities of channel and flow conditions as more uncertainties and assumptions are involved it is also demonstrated that with the proper estimation of parameters the two forms of power laws and logarithmic laws tend to overlap each other for the main body of flow the logarithmic law results in underestimations in the outer region which agree with the previous findings hence the outer form or the log defect law is preferred between the two as the latter requires less information about the bed roughness despite differences in methodologies the accuracy of log defect law and shannon entropy based velocity distribution resides in the estimation of u κ and k 1 respectively the latter two are virtually the same hence the two velocity distributions resemble in their pattern and accuracy the von karman constant decreases drastically from its clear water value of 0 41 for highly sediment laden flows indicating its value is subject to change with sediment load power law and tsallis entropy based velocity distribution have an exponent parameters n and m respectively which appear to vary with bed roughness in addition to the previously proposed value of 3 4 for channels with smooth or moderate roughness the values of 5 4 and 2 are suggested to be adopted in tsallis entropy based velocity distribution to account for additional roughness in large scale alluvial channels which is consistently underestimated by conventional methods distinct from the previous theories the exponent parameter n of power laws is found to vary from its commonly adopted value of 6 for hydraulically rough flows amongst all velocity distributions based on tsallis entropy as a generalized form of informational entropy is shown to have resiliency to various channel properties and flow conditions and display consistent advantages in the inner region particularly for rough beds covered with nonuniform coarse materials however none of these 1d velocity distributions is applicable to simulate the highly skewed velocity profile due to the 3d effect induced by the channel nonuniformity and additional flow resistance associated with bed forms moreover these 1d type of formulas are only valid for sufficiently wide channels or local regions where the side wall effects are minor and the velocity dip phenomenon is not present despite these limitations our comprehensive comparative study on the 1d velocity distributions may serve as an important reference for numerical modeling of sufficiently wide natural waterways and urban drainage systems notation the following symbols are used in this paper a r width depth aspect ratio b channel width d flow depth h informational entropy y vertical distance to the bed y 0 effective roughness height u time averaged streamwise velocity u shear velocity u d velocity at the water surface u m depth averaged velocity u max maximum velocity m p n exponent parameters in power laws m exponent parameter in tsallis entropy κ von karman constant λ lagrange parameter acknowledgements we gratefully acknowledge the helpful suggestions provided by dr marcelo garcia and dr gary parker for us to carry out the literature review and to articulate the methodology theoretically we thankfully acknowledge the editors and both reviewers for giving constructive comments to improve the overall efficiency of the paper furthermore the laboratory and field data measurements that were collected by different institutions and reported by different authors are gratefully acknowledged 
7167,velocity distributions for open channel flows have been investigated using deterministic and probabilistic approaches it is well known that the vertical velocity profiles in wide open channels i e aspect ratio width depth 5 can be approximated by logarithmic velocity laws and power laws recently the entropy concept in the forms of shannon entropy and tsallis entropy has been employed to estimate velocity distributions in open channels with different aspect ratios the accuracy of conventional velocity equations is highly dependent on their parameters that can only be estimated by empirical or semi empirical analytical relations which requires either a good knowledge of velocity field and or physical properties of the channel such as topographic conditions sedimentation conditions and boundary roughness in contrast the entropy based velocity distributions derived based on the least biased probability density function pdf by treating time averaged velocities as random variables are resilient regardless of the flow and channel conditions however a comparison of the velocity profiles computed using deterministic approaches and probabilistic approaches has not been rigorously conducted furthermore the accuracy and reliability of associated velocity distribution equations have not been tested thoroughly using data sets collected using advanced techniques this paper presents a comprehensive and comparative study to analyze the distinctions and linkages between four commonly used velocity laws and two entropy based velocity distributions theoretically and quantitatively using selective laboratory and field measurements available in the literature considering typical sedimentation and channel hydraulic conditions amongst all tsallis entropy based velocity distribution developed from a generalized form of informational entropy exhibits universal validity to sediment laden flows in wide alluvial open channels and is found to be superior to others to predict velocity profiles in large waterways with unmanageable rough beds keywords entropy open channel flow probability distribution velocity distribution law of the wall power laws 1 introduction there is a shortage of reliable velocity data in waterway system during storm events in which the discharge varies rapidly and velocity sampling is extremely difficult recently high tech based measuring techniques such as particle image velocimetry piv adrian 1997 hyun et al 2003 acoustic doppler velocimeters adv holmes and garcia 2008 acoustic doppler current profilers adcp gonzalez et al 1996 and previously developed laser doppler velocimetry ldv also known as laser doppler anemometry lda nezu and rodi 1986 have been applied however their implementation is still subject to uncertainties associated with weather and measurement techniques and involve considerable cost furthermore velocities near solid boundaries and free surface cannot be measured with adcp s due to the interference in the acoustic signals caused by boundary reflectance and are extrapolated based on the power law distribution currently incorporated in adcp post processing software thus for these measurements to be efficient a reliable estimation of velocity distribution for the entire flow depth that has wide applicability regardless of channel properties and flow conditions is preferable to sufficiently reduce the number of velocity observations herein the velocity distribution refers to the vertical distribution of time averaged velocity of primary flow in a transverse cross section eliminating the turbulent oscillation component nezu and rodi 1986 found experimentally that the open channel flow velocity distribution is highly dependent on the presence of secondary currents due to the side wall effects they further divided open channels into two categories as narrow or wide channels according to the aspect ratio a r b d for narrow channels with a r 5 the maximum velocity happens beneath the water surface as a result of the momentum exchange between the primary flow and the secondary circulation also known as velocity dip for wide channels with a r 5 the side wall effects are however reduced and become negligible in the center zone of the width b 5 d thus for sufficiently wide channels with a r 5 the velocity distribution in the large portion of the cross section can be considered to follow a 1d type of velocity distribution in which the velocity profile along each vertical is a monotonic increasing function of the vertical distance to the bed the current analysis is confined to wide channels where 1d assumptions are valid in fluid mechanics open channel flows are part of the general class of bounded shear flows with free surface where velocity profiles are obtained by solving navier stokes equations with given boundary conditions usually under steady uniform flow assumptions logarithmic and power laws are two well known forms of such solution family von karman 1921 1930 and prandtl 1925 first investigated flow through pipes theoretically by integrating the experimental studies of nikuradse 1933 and derived a set of rational velocity distributions and hydraulic resistance relations for turbulent flows over flat plates and in circular pipes these have been extended to open channel flow to include free surface effects rouse 1959 sarma et al 1983 furthermore extensive research has been done to extend the logarithmic type velocity or velocity defect law to sediment laden flow by treating the von karman constant and the law of the wake as functions of flow sediment load characteristics vanoni 1946 coles 1956 einstein and chien 1955 chien 1956 yanlin and finlayson 1972 schlichting 1979 coleman 1981 parker and coleman 1986 wang apr 1981 sill 1982 hoffman and mohammadi 1991 chiu and murray 1992 hinze 1959 showed that the logarithmic velocity distribution can be approximated by the power law velocity distribution in most of the boundary layer cross section specially in the overlapping region of the inner law i e the law of the wall and the outer law i e the velocity defect law chen 1991 wooding et al 1973 then theoretically evaluated the differences between the logarithmic velocity distribution and the power velocity distribution and found that the power law with a small exponent cannot be distinguished experimentally from the logarithmic law it was argued that the power law velocity profile was preferable to the logarithmic velocity distribution landweber 1957 rouse 1959 for three reasons 1 the logarithmic velocity distribution should be considered as an asymptotic law valid for very large reynolds numbers schlichting 1968 whereas the power law is less restrictive to the flow regime and is also applicable to smaller reynolds numbers chen 1991 2 the power law appears to be better able to incorporate the effects of sediment on velocity profiles without troublesome singularities near the bed and or derivative discontinuities at axes and planes of symmetry karim and kennedy 1987 chen 1991 3 hinze 1975 and schlichting 1979 showed that the power law conforms better than the logarithmic relation to the pipe flow data of nikuradse 1933 and laufer 1953 however due to the inherent system randomness and incomplete input information there are always uncertainties associated with theoretical predictions or experiment based calculations of variables or parameter estimation involved in the above conventional deterministic approaches thus the time averaged streamwise velocities should rather be statistically regarded as a random variable the informational entropy theory facilitates the application of probabilistic approaches to hydraulics and hydrology as well as environmental engineering by accounting for the associated uncertainties singh 2013 singh 2014 singh 2015 the principle of maximum entropy pome jaynes 1957 jaynes 1957 states that any system in equilibrium state tends to maximize its entropy under universal constraints which is equivalent to the theory of minimum energy dissipation yang 1976 chiu 1987 first applied the probabilistic concept via shannon entropy to describe the vertical distribution of mean velocity shear stress and suspended sediment concentration in open channel flows using shannon entropy subject to pome thus the derived velocity distribution is claimed to be least biased towards the unknowns and most biased towards the constraints marini et al 2011 tsallis entropy a generalized form of informational entropy was also utilized to describe the streamwise velocity in wide open channels singh and luo 2011 cui and singh 2014 singh 2016 besides the difference in mathematical formulations of the numerous developed velocity distribution equations no comprehensive and rigorous analysis has been conducted to compare the goodness of fit of the aforementioned methods using high resolution data measured with advanced tools and techniques thus this paper presents a comparative analysis on the widely accepted forms of 1d logarithm power law velocity distribution and two entropy based velocity distributions both theoretically and quantitatively with the following specific objectives 1 to compare preselected feasible ways that well balance information parsimony and overall accuracy to estimate key parameters involved in logarithmic and power law velocity distributions 2 to identify the differences and linkages between the formulations of different methods and 3 to compare the accuracy and applicability of the velocity distribution laws considered under various flow and channel conditions overall this paper demonstrates the resilience of entropy based velocity distributions in variety of applications and provides auxiliary alternatives for streamflow measurement and numerical validation purposes 2 conventional deterministic 1d velocity distributions 2 1 logarithmic velocity distribution the 1d logarithmic velocity law was developed by assuming a steady uniform in a wide open channel flow having a mean width b and a mean depth d i e aspect ratio defined as a r b d 5 with a mean flow velocity u as shown in fig 1 the flow velocity distribution under consideration was well established both experimentally and from dimensional analysis schlichting 1979 nezu and rodi 1986 as 1 u u κ ln y y 0 eq 1 is considered as the law of the wall since it was considered to strictly apply inherently in a relatively thin layer y d 0 2 near the bed coleman and alonso 1983 nezu and nakagawa 1993 whereas it is commonly used as a reasonable estimation of the entire depth for most of the flow in many streams and rivers with a correction for wake effects coles 1956 coleman 1986 which can be ignored for single phase and uniform flows schlichting 1979 derived the outer form of the law of the wall by manipulating eq 1 based on the assumption that the maximum flow velocity u max takes place at the water surface where y d i e u d u max this alternative formulation of logarithmic velocity law is also known as velocity defect law whereas it does not require as much knowledge of the bed roughness as the law of the wall does 2 u max u u 1 κ ln y d parameter estimation key parameters in eq 1 are shear velocity u von karman constant κ and bed roughness length y 0 which equates to a very small almost unmeasurable value of depth above the bed where the flow velocity goes to zero based on the experimental results by nikuradse 1933 christoffersen and jonsson 1985 developed a generalized formula to estimate y 0 as a function of effective roughness height k s for flows from hydraulic transitional to fully hydraulic rough as 3 y 0 k s 30 1 exp u k s 27 ν ν 9 u where ν is the kinematic viscosity of water the roughness k s reflects both surface roughness and form roughness of the channel bed rouse 1959 hence its complete evaluation is complicated which further limit the accuracy of eq 3 singh 2011 proposed an even more simple algebraic approach by substituting y d in eq 1 given the knowledge of u d u and y 0 can then be simply estimated as the follows 4 y 0 exp κ u d u d the goodness of eqs 3 and 4 were tested and compared using 29 sets of flume data collected by einstein and chien 1955 that contains all information necessary for the calculation fig 2 a showed that eq 4 agrees better with the observations of parameter y 0 than eq 3 the latter tends to underestimate parameter y 0 for different levels of grain induced bed roughness with a root mean square deviation rmsd on the magnitude of 0 0018 whereas the value yielded from eq 4 was only 0 00016 thus eq 4 is more suitable to estimate parameter y 0 given limited information of boundary roughness i e k s parameter κ is known as von karman universal constant and its clear water value κ 0 41 can be considered to be a universal one smith and mclean 1977 coleman 1981 nezu and rodi 1986 soulsby and wainwright 1987 lyn 1988 long et al 1993 wright and parker 2004 however according to the experiments years ago reported by einstein and chien 1955 1975 von karman constant κ can deviate from its clear water value due to the effect of suspended sediment a smaller value of κ results in a less vigorous exchange of motion and a smaller internal friction opposing the flow in the main body of a sediment laden flow κ is found to be reduced from its clear water value with the increasing sediment concentration however κ does not become less than 0 2 except for flows with hyperconcentrations of fine sediment wang apr 1981 as also discussed by vanoni 1975 and summarized by karim and kennedy 1987 herein we adopted a logarithmic relation suggested by einstein and chien 1955 as below 5 κ 0 132 log 10 35 45 k s y 0 from the above relation κ equates its clean water value when y 0 k s 30 for fully rough turbulent flow fig 2a presents the values of κ estimated using eq 5 compared with the values obtained from semi log plotting of velocity measurements by einstein and chien 1955 this formula correlates the ratio of roughness height and length k s y 0 to the parameter κ with a coefficient of determination r 2 0 86 however the accuracy of this formula is subject to the goodness of measurements and estimation of associated interim parameters nezu and nakagawa 1993 analyzed several methods to estimate the shear velocity u in the case of steady uniform flow in wide channels u can be estimated as gds 0 where s 0 is the bed slope however this method requires an accurate measurement of bed slope in the vicinity of measured section which is always difficult in the case of nonuniform flow the energy slope s e should replace s 0 which involves more uncertainties associated with the estimation of energy coefficient and contraction expansion factor and so is inherently non rigorous 2 2 power law velocity distribution the power law is an alternative method to predict the vertical velocity profiles of the time averaged streamwise velocity in open channel flows assuming uniform hydraulic rough flow and neglecting the wake effect eq 1 and keulegan s resistance law for rough flow keulegan 1938 can be approximated by the power law of the manning strickler form garcia 2008 this gives rise to the widely used power law velocity distribution for open channel flows proposed by karim and kennedy 1987 as follows 6 u u max y d 1 n the effect of moving sediment on the velocity profiles is incorporated into the exponent n formulated on the basis of energy dissipation considerations and quantified by means of a fairly large body of laboratory and field measurements chen 1991 derived an alternative form of power law velocity distribution from the logarithmic velocity profile using darcy weisbach friction factor for steady uniform pipe and channel flows as follows 7 u u a y y 0 m p m p 1 n where u and y 0 are essentially the same as defined in the logarithmic law a and m p are parameters with m p and n so related as in eq 7 the power law velocity distribution given by eq 7 is indeterminate because exponent m p and the associated coefficient a vary either with the global reynolds number for hydraulically smooth flows or with the global relative roughness for fully rough flows due to incomplete similarity as shown in fig 3 parameter estimation chen 1988 1989 concluded that the best estimation of parameters m p and a should satisfy in a least squares sense of the logarithmic law within an acceptable tolerance for a certain range of u u or y y values and the m p value should be confined to a range between 0 and 1 a nonlinear regression analysis in fig 3 shows that the larger m p value namely the smaller the depth leads to a greater deviation of power law from the logarithmic law for a range of velocity or depth and vice versa consequently as m p drops to zero the power law virtually overlaps with logarithmic law at the possibly largest value of u u or y y 0 thereafter it was considered that the 1 7 power and 1 6 power velocity distributions are typical choices for hydraulically smooth flows and fully rough flows respectively assuming a perfect agreement with the logarithmic law the product of κ m p a and e the base of the natural logarithm should equate 1 thus parameter a can be estimated as 8 a 1 em p κ given the mean u m and maximum u max velocities n can be solved by taking the depth average of velocity using eq 6 singh 2013 9 n u m u max u m another alternative expression for n was developed by zimmerman and kennedy 1978 for open channel flow in wide rectangular channels as 10 n κ 8 f where f is the darcy weisbach friction factor thus n appears to be correlated with the frictional resistance at the bed garcia 2008 reviewed a number of power and logarithmic expressions to estimate f and to evaluate flow resistance in open channel flows herein f is estimated using the shear stress form of darcy weisbach equation as follows 11 8 f 1 2 u m u n can also be estimated using shannon entropy as singh 1996 singh 2014 12 n 1 ln u d ln u parameter n can also be determined in the least square sense given a fair amount of velocities sampled the values obtained in this approach might be considered as a criterion to justify the goodness of aforementioned analytical and empirical relations i e eqs 9 10 and 12 a total of 40 sets of flume data coleman 1986 were examined for this purpose in fig 4a the least square regression analysis gave an estimation of parameter n in the range from 6 13 to 9 90 whereas eq 10 by zimmerman and kennedy 1978 fluctuated in a relatively narrow range from 7 46 to 8 28 the reason may resides in the facts that the reported κ is indifferent to suspended sediment concentration in coleman s experiment and the friction factor f estimated from eq 11 staying almost constant moreover the goodness of eq 10 and eq 11 is inherently dependent on a good knowledge of the near bed velocity field and channel properties which is generally difficult to measure it also appears that the estimation given by eqs 9 and 12 follows a highly linear relation with the values estimated by the least square method the former requires the least information and the latter appears to give the best estimation thus both eqs 9 and 12 can give an initial estimate and the values can be further adjusted according to the linear correction as annotated in fig 4a accordingly the velocity profiles predicted using eq 6 with n estimated from eqs 9 and 12 result in better agreement with the measurements fig 4b 3 entropy based 1d velocity distribution in probability theory the time averaged velocity u should rather be considered as a random variable with f u as its cumulative distribution function cdf and f u as the associated probability density function pdf as 13 f u 0 y f u y dy y d where y vertical distance from the bed and d the flow depth eq 13 assumes that stream wise velocity monotonically increases with respect to water depth hence a maximum value happens at the surface when the water air interface shear is neglected entropy h u quantifies the uncertainty associated with u or its pdf f u or in general denotes the randomness of the system the derivation of the 1d velocity distribution applying entropy theory follows 1 definition of the continuous form of entropy 2 specification of universal constraints that velocity distribution is subjected to 3 maximization of entropy and derivation of probability distribution of velocity 4 derivation of velocity distribution and 5 specification and estimation of parameters 3 1 tsallis entropy based 1d velocity distribution tsallis 1988 2004 proposed a generalized form of informational entropy h and its continuous form koutsoyiannis 2005a b can be written as 14 h k m 1 1 0 u d f u m du k m 1 0 u d f u 1 f u m 1 du where k is a constant to keep the entropy invariant of the system of measurement while keeping the units of entropy consistent and is often taken as unity and m is an exponent parameter maximization of h is realizable only for equal probability of occurrences when m 0 singh and luo 2011 applied tsallis entropy to derive velocity distributions in wide open channels under the hypothesis defined in eq 13 by means of the principle of maximum entropy pome the least biased pdf f u should also result in maximum entropy subject to constraints c r r 1 2 n defined by universal conservation laws as 15 c r 0 u d g r u f u du g r u r 1 2 n where n denotes the number of constraints and g r u represent r th order moment of u barbe et al 1991 showed that the effects of momentum and energy conservation constraints on velocity profiles were trivial compared to that of the mass continuity constraint hence was neglected for computational efficiency accordingly singh and luo 2011 derived the least biased probability density function as eq 16 16 f u m 1 m λ v λ 1 u 1 m 1 eq 16 defines the generic probability distribution of velocity that satisfies eq 15 following euler lagrange calculus of variation where λ v and λ 1 are lagrange multipliers the 1d velocity distributions u y was derived by substituting eq 16 into eq 13 and applying integration as 17 u m m 1 1 λ 1 λ 1 y d m 1 m λ v m m 1 m 1 m λ v λ 1 parameter estimation the key parameters involved in both f u and u y are m λ v and λ 1 λ v and λ 1 can be determined by solving the following nonlinear system which is obtained by integration of eqs 15 for i 1 2 after plugging in the derived f u as in eq 16 18a m 1 m λ v λ 1 u d m m 1 λ 1 m 1 m λ v m m 1 18b u d λ 1 m 1 m λ v λ 1 u d m m 1 1 λ 1 2 m 2 m 1 m 1 m λ v λ 1 u d 2 m 1 m 1 1 λ 1 2 m 2 m 1 m 1 m λ v 2 m 1 m 1 u m singh and luo 2011 pointed out that the feasible range of m is from 0 to 2 fig 5 shows that the slope of velocity profile u y increases with increasing m for given u m and u max which indicates that m increases with bed roughness and flow resistance thus m is somewhat similar to the exponent parameter m in the power law velocity distribution i e eq 7 relating to the same channel properties while differing in magnitude fig 6 a and b show that the solution of λ 1 and λ v when m 3 4 must have opposite signs to guarantee velocity as a positive quantity i e u 0 more analysis in the following shows that this conclusion applies to other m values it appears that in the inner region u y decreases as the absolute value of λ 1 increases on the contrary u y increases indicating an increase in bed shear as the absolute value of λ v increases these plots also indicate that the larger velocities at the water surface would yield smaller magnitude of λ 1 but larger magnitudes of λ v between the two parameters λ v varies within a relatively smaller range thus the velocity profiles might be more sensitive to the change of λ v the previous numerical experiments showed that m 3 4 yielded the best prediction for open channel flows without strong interference from the beds and suspended sediment hence can be adopted as a first estimation of the 1d velocity distribution singh and luo 2011 the maximum entropy of the dimensionless velocity u u distribution was obtained through the integration as eq 14 with the least biased probability density function derived as eq 16 for m 3 4 and the analytical form is derived as 19 h u u 4 1 27 2 u 1 4 λ 1 1 λ v λ 1 u d 2 1 λ v 2 fig 7 a shows the regression analysis between the maximum entropy calculated using eq 19 and λ 1 that was obtained from the regression analysis using 29 sets of flume data by einstein and chien 1955 at different levels of sediment concentration and bed roughness the lagrange parameter λ 1 may be considered as a hydraulic parameter that relates to bed roughness and sediment concentration chiu 1987 stated that higher entropy in open channel flow was associated with rougher beds and or with higher sediment concentration which resulted in larger system randomness the relatively larger range of λ 1 in the clear water flows emphasizes the noticeable trend of λ 1 to decrease with increased bed roughness while for the sediment laden flows the trend reflects mixed effect of both suspended sediment and bed shear 3 2 shannon entropy based 1d velocity distribution taking the limit of eq 14 as m approaches unit it reduces to the form of shannon entropy 20 h k 0 u d f u ln f u du following the aforementioned procedure chiu 1987 derived a least biased pdf describing the velocity distribution in wide open channels as 21 f u e λ 1 1 e λ 2 u in which λ 1 and λ 2 are parameters lagrangian multipliers a relationship between the two parameters was derived by substituting eq 21 into eq 15 as 22 e λ 1 1 λ 2 e λ 2 u d 1 1 parameter estimation by solving for λ 2 numerically chiu 1987 obtained an expression relating λ 2 to the shear velocity u as 23 λ 2 k 1 u where k 1 is somewhat similar to von karman constant κ hence may be estimated using a similar approach substituting λ 1 and λ 2 with eq 23 the 1d velocity distribution was derived as 24 u u k 1 ln 1 exp k 1 u d u 1 y d eq 24 implies that the accuracy of shannon entropy based velocity distribution is highly dependent on the estimation of shear velocity u and parameter k 1 similar to the logarithmic velocity distribution but without problematic singularities at the bed substituting eqs 22 and 23 into eq 20 one gets the maximum entropy of the dimensionless velocity u u as 25 h u u h u ln u ln e u d k 1 u 1 u d k 1 u 1 1 e u d k 1 u 1 1 ln k 1 utilizing the entropy calculated by eq 25 chiu 1987 found a relation between parameter k 1 and maximum entropy h u u by regression analysis as shown in fig 7b due to their similarity the values of k 1 were taken to be the same as those of κ as reported by einstein and chien 1955 similar to λ 1 in the velocity equation based on tsallis entropy the parameter k 1 may also be considered as an indicator of bed roughness and sediment concentration chiu 1987 the lower values of k 1 in fig 7b was associated with higher values of entropy corresponding to flows over coarser beds and or with higher sediment concentration a linear correlation between k 1 and entropy has been established based on regression with a r 2 value as high as 0 99 in general the values of λ 1 and k 1 for sediment laden flow are lower than their values for clear water flows the comparison shows that the tsallis entropy based velocity with m 3 4 results in a higher value of entropy h u u for the same scenarios according to pome the former might give a better interpretation of the system under given conditions 4 selected field measurements and laboratory data of velocity profiles in sediment laden flows in order to evaluate the performances of the aforementioned 1 d velocity formulations sixteen data sets which were reported by kironoto 1992 hyun et al 2003 gonzalez et al 1996 and guo 1998 were selected to assess the accuracy and applicability of the six velocity equations to typical channel and flow conditions the selected data sets cover laboratory controlled flumes large constructive and natural rivers which diversify in flow conditions boundary roughness and sediment load moreover the selection also reflects various high tech measurement techniques including adcp piv and ldv in addition to traditional ones to assess the goodness of the velocity distributions while excluding the bias due to measurement techniques the point velocity measurements were made along the flume or channel center line where side wall effects on the velocity profile were minimal table 1 summarizes the flow and channel hydraulic parameters and specifies the parameters for each velocity model the roughness reynolds number given by u k s ν calculated for all the selected flows were much larger than 11 6 thus the flows were within the turbulent rough flow regime kironoto 1992 measured the mean velocity profiles using prandtl tubes coupled with a pressure transducer at the swiss federal institute of technology epfl in a 16 8 m long 0 6 m wide and 0 8 m high flume fig 8 the selected four sets of data were for fully developed uniform turbulent flows on rough plate hyun et al 2003 measured the complex flow field over a train of two dimensional dunes attached to the bed of a 10 m long rectangular 610 mm 610 mm open channel flume fig 9 the velocities were measured using a two component fiber optic ldv system and piv in a complementary manner to optimize the accuracy in the near wall region and wake region the flow field was suitable to evaluate the applicability of different velocity models as it contained much of the complexity involved in practical hydraulic engineering applications gonzalez et al 1996 reported two sets of velocity distributions collected by u s geological survey usgs with a fixed adcp at the center of chicago sanitary and ship canal cssc at romeoville illinois usa fig 10 the cssc is an excavated channel of limestone and a rigid bed the channel is about 49 m wide and the flow depth varied between 6 and 8 5 m with hydraulic control works throughout the chicago area waterway system caws and sanitary inflows the cssc is a highly regulated unnatural waterway with continuous perturbations that propagate from lake michigan and influences from the des plaines river that is located just upstream thus continuous and accurate measurement of discharge in the cssc requires an innovative technology to implement repeating high resolution velocity measurement the first data set was collected on august 17 1994 by averaging 70 velocity profiles measured at a time interval of 4 75 s the measurements were confined to the area within 0 27 and 6 27 from the channel bed the second data set was collected on may 12 1995 by averaging 25 velocity profiles measured at a time interval of 4 17 s each profile consists of velocity measurements within 0 41 and 7 16 m above the channel bed guo 1998 reported velocity and sediment concentration profiles measured at feng jie hydrologic station the yangtze river china fig 11 and hua yuan kou hydrologic station the yellow river china fig 12 the four data sets selected from the measurements for the yangtze river were collected in july 1976 and august 1981 with the flow depth varying from 32 3 to 45 9 m the channel width at feng jie hydrologic station is about 1200 m the selected four data sets for the yellow river were collected in august 1983 while the flow depth stabilizes at an average of 2 4 m and the channel width at the station is approximately 825 m 5 results and discussions the error analysis summarized in table 2 uses the root mean square error rmse as a measure to evaluate the deviation between the model predicted and measured values of dimensionless velocity u u max the conventional deterministic velocity distributions appear to perform slightly better in predicting the velocity distribution under experimental conditions than in large natural alluvial waterways in which more complex flow behavior and parameter uncertainties arise amongst all the worst prediction fell in the case of the yellow river with shallower water and high sediment concentration regardless of the inevitable errors tsallis entropy and shannon entropy based velocity equations appeared to be resilient to channel hydraulic properties and flow conditions of which the former yielded on average the best prediction of the velocity profiles over the entire water depth fig 8 illustrates one of the simplest scenario with uniform flow in a wide flume with laboratory controlled rough bed the velocity profiles predicted using conventional power laws and logarithmic velocity laws were comparable to the ones predicted by entropy based distributions overall the clear water value of κ provided acceptable fits to the observations without outstanding presence of sediment in the flow however even for this idealized case the logarithmic law eq 6 and the log defect law eq 2 still resulted in minor deviation in the outer region among which the former tended to underestimate and the latter tended to overestimate fig 8b and d this consistent deviations suggest a constant value of κ that would fit the entire water depth was unrealizable the estimated values of n using eq 9 were close to but smaller than the value of 6 which links to the power law for uniform rough flows in wide open channels shannon entropy based profiles overlapped log defect law profiles when parameter k 1 took essentially the same value as of κ tsallis entropy based method with m 3 4 led to better local accuracy in the wake region and the inner region as can be seen from the comparison with the experimental data series of upa5 and upd5 the local deviation may be minimized by further adjusting the values of parameters λ 1 and λ v according to the sensitivity analysis as presented in fig 6 the local advantage of accuracy in the inner region is more obvious in fig 9a and b as well as their dimensionless counterparts as shown in fig 9c and d while the logarithmic laws tended to overestimate when y d fell below 0 2 this implies that in the lower part of the alluvial channel the increased sediment concentration and the complex internal exchange of sediment between the bed load and suspended sediment leads to a noticeable acceleration of flow velocity vanoni 1946 it further indicates that the logarithmic law with κ of the clear water value tends to underestimate the bed shear stress as well as the boundary shear layer thickness in sediment laden flows similarly as in fig 10 to account for the effect of increasing bed shear exponent m in tsallis entropy is increased to 2 and 5 4 for s1 and s2 respectively which is consistent with the aforementioned argument that m increases with increasing bed roughness as s1 and s2 are measured at the station upstream and downstream of the dune respectively the 1d velocity distributions agree with the velocity field at s1 which was not influenced by the dune downstream fig 10a and c however the two dimensional dune added complexity to the flow field of s2 none of the 1 d velocity models can describe adequately the flow field particularly in the near wall region fig 10b and d this distinction suggests that the bed form induced flow resistance may result in significant disturbance to the flow field as a result of the intensified turbulent shear and secondary circulation associated with resultant flow separation reversal and reattachment the velocity profiles are highly influenced by these three dimensional features and deviate substantially from any type of 1d velocity distributions thus a composite velocity law or a turbulence model is preferable to interpret the stratification of velocity distribution over predominant bed forms similar to the laboratory configurations i e figs 8 and 10 figs 11 and 12 show that the six models are comparable in predicting the velocities in the upper region of flows in large alluvial systems however logarithmic velocity laws and shannon entropy based velocity distributions gradually deviate from the power laws and tsallis entropy based velocity distributions in the lower region when y d 0 2 and result in overestimations the power laws and tsallis entropy based velocity distribution resemble the patterns and magnitudes of measurements in the lower region which can be consistently detected from figs 9 to 12 the similarity in their performance and mathematical formulations suggests that tsallis entropy based velocity distribution may be considered as a generalized form of power laws with additional parameters λ 1 and λ v to strictly satisfy the universal laws of probability and mass which is also consistent with the findings presented by singh 2013 unlike power laws where the exponent parameter n is subject to change with flow conditions e g mean flow velocity and depth as in table 1 the exponent parameter m remains constant within the same channel reach if the channel properties e g aspect ratios bed slope and roughness as in table 1 stay relatively stable with time and hydrologic conditions in the case of laboratory flume with flat and relatively smooth bed such as the experimental apparatus of kironoto 1992 the suggested value of m is 3 4 for excavated channel reaches with manageable roughness such as the cssc and feng jie hydrologic station at the yangtze river the suggested value of m is 5 4 for natural alluvial channels with highly non uniform rough beds e g hua yuan kou hydrologic station on the yellow river the suggested value of m is as high as 2 in which the conventional and shannon entropy based velocity equations consistently underestimate the velocities in the lower 10 of the flow depth to be noticed although all the flows considered here are within the fully hydraulic rough flow regime with u k s ν 11 6 the exponent parameter n can drop to as small as 3 03 as reported in table 1 which contradicts the previous widely accepted value of n 6 for hydraulically rough flows it also shows that κ decreases to 0 210 for the selected station on the yellow river with the average sediment concentration as high as 20 kg m3 which is over four times sediment concentration for the selected station in the yangtze river hence it proves that the clear water value of 0 41 is only applicable as long as the effects of the sediment in suspension and grain particles that re entrain from the bed to the flow remain negligible 6 summary and conclusions to summarize this study demonstrated that for a channel of bed covered with smooth or moderate material conventional logarithm and power velocity laws and entropy based velocity distributions display comparable performance however the deviations of the conventional velocity laws increase with respect to the scale and complexities of channel and flow conditions as more uncertainties and assumptions are involved it is also demonstrated that with the proper estimation of parameters the two forms of power laws and logarithmic laws tend to overlap each other for the main body of flow the logarithmic law results in underestimations in the outer region which agree with the previous findings hence the outer form or the log defect law is preferred between the two as the latter requires less information about the bed roughness despite differences in methodologies the accuracy of log defect law and shannon entropy based velocity distribution resides in the estimation of u κ and k 1 respectively the latter two are virtually the same hence the two velocity distributions resemble in their pattern and accuracy the von karman constant decreases drastically from its clear water value of 0 41 for highly sediment laden flows indicating its value is subject to change with sediment load power law and tsallis entropy based velocity distribution have an exponent parameters n and m respectively which appear to vary with bed roughness in addition to the previously proposed value of 3 4 for channels with smooth or moderate roughness the values of 5 4 and 2 are suggested to be adopted in tsallis entropy based velocity distribution to account for additional roughness in large scale alluvial channels which is consistently underestimated by conventional methods distinct from the previous theories the exponent parameter n of power laws is found to vary from its commonly adopted value of 6 for hydraulically rough flows amongst all velocity distributions based on tsallis entropy as a generalized form of informational entropy is shown to have resiliency to various channel properties and flow conditions and display consistent advantages in the inner region particularly for rough beds covered with nonuniform coarse materials however none of these 1d velocity distributions is applicable to simulate the highly skewed velocity profile due to the 3d effect induced by the channel nonuniformity and additional flow resistance associated with bed forms moreover these 1d type of formulas are only valid for sufficiently wide channels or local regions where the side wall effects are minor and the velocity dip phenomenon is not present despite these limitations our comprehensive comparative study on the 1d velocity distributions may serve as an important reference for numerical modeling of sufficiently wide natural waterways and urban drainage systems notation the following symbols are used in this paper a r width depth aspect ratio b channel width d flow depth h informational entropy y vertical distance to the bed y 0 effective roughness height u time averaged streamwise velocity u shear velocity u d velocity at the water surface u m depth averaged velocity u max maximum velocity m p n exponent parameters in power laws m exponent parameter in tsallis entropy κ von karman constant λ lagrange parameter acknowledgements we gratefully acknowledge the helpful suggestions provided by dr marcelo garcia and dr gary parker for us to carry out the literature review and to articulate the methodology theoretically we thankfully acknowledge the editors and both reviewers for giving constructive comments to improve the overall efficiency of the paper furthermore the laboratory and field data measurements that were collected by different institutions and reported by different authors are gratefully acknowledged 
7168,the areas of glacial lakes in the himalayas continue to increase alarmingly due to global warming with consequent risk of glacial lake outburst flood glof the outburst is most common for moraine dammed lakes as a result of a failure of the dam by overtopping and erosion or piping due to seepage in the present context glof events especially for the moraine dam failure process needs to be predicted to assess the drastic and detrimental impacts on the downstream river valley this study focuses on validating an integrated model for simulating the failure of moraine dam by overtopping and erosion using a coupled numerical simulation model the proposed numerical methodology is validated with the data from experiments in laboratory scale physical models the results of the model are compared for both the erosional profiles during collapse of the dam and the resulting outflowing flood hydrograph the primary finding is that the moraine dam height and the volume of the lake upstream of the dam are the most sensitive parameters influencing the glof peak the model is also applied to the field problem of the tangjiashan lake outburst and dam failure and shows reasonably good agreement with observations the validated model is also run for the south lhonak glacial lake in the sikkim himalayas india to obtain the probable flood hydrograph in case of failure of the moraine dam keywords breach morphodynamics erosion glacial lake moraine dam failure open channel flow outflow hydrograph nomenclature b baseline prediction data bss brier skill score c chézy coefficient l1 2t ca reference concentration at a reference level cb sediment concentration in bed load layer ceq equilibrium near bed concentration cz near bed concentration at z elevation of bed d net flux for deposition d dimensionless particle size l d 30 30 finer sediment size l d 50 median sediment size l d 90 90 finer sediment size l e net flux for erosion fr flow froude number g gravitational acceleration l t 2 h flow depth l hd dam height l i number of spatial grid lu s length of dam upstream mse mean square error n total number of the grids or nodes p porosity pi input parameter pim mean input parameter po output parameter pom output parameter for pom pim qb x qb y bed load per unit width and time in x and y direction respectively qp unit peak discharge l2t 1 s relative density sx sy source term in x and y direction respectively lt 2 t time t u shear velocity lt 1 u cr critical shear velocity lt 1 u v depth averaged velocity components in x and y direction respectively lt 1 wd dam crest width l x experimentally observed data x horizontal distance l y numerically simulated data y span wise distance l zb bottom or bed elevation l μ ripple correction factor υ coefficient of kinematic viscosity l2t 1 ρ mass density of water ml 3 τ nondimensional excess bed shear stress θ shields parameter θ nondimensional skin friction δb bed load layer thickness l θc critical shields parameter ρs mass density of sediment ml 3 1 introduction global warming and its impacts have been growing as a grave concern in recent times especially for the snow packs of high mountains like the himalayas melting of permafrost and glaciers has acted as global thermometers haeberli and beniston 1998 ipcc 2001 worldwide the significant increment of glacial lakes both in number and size reflects the effects of global warming mool et al 2001 these glacial lakes pose major hazards in mountainous regions of which the most significant ones being avalanches and glacial floods richardson and reynolds 2000 the latter causing devastating impacts upon the riparian society downstream within a short time span ranging from minutes to hours the glacial floods generally caused by the failure of moraine dams are commonly termed glacial lake outburst flood glof glofs are causes of major concern due to i serious risk of loss of life and ii destruction of valuable infrastructures such as hydropower stations and bridges or roads and buildings located in the river valley and banks downstream in 1971 almost 20 000 lives were lost within five minute of glof initiation at huascaran cordillera blanca mountain region in peru lliboutry et al 1977 the flood debris flow travelled over hills 150 m high and 500 m wide with a speed of almost 80 km h as it destroyed the township of yungay peru another known case of disastrous glof events occurred in 1985 from the dig tsho glacial lake in eastern nepal himalaya which destroyed lives and properties apart from the namche small hydropower plant just a few days after its commissioning the estimated loss was about us 1 5 million icimod and unep 2002 such large glof events have attracted the attention of hydrologists and environmentalists toward the potential consequences of glacier lake failures consequently studies have been undertaken to analyze related phenomena such as growth rates of glacial lakes reason for their outbursts moraine dam failure mechanisms and simulation of moraine dam breach recently researches indicate that the maximum cases of moraine dammed lake outbursts is reported from the himalayas around the mount everest region singh and singh 2001 it has also been established that since moraine dams occur as natural earthen embankments formed from accumulated debris from glacier the moraine which store the glacier melt water behind a trigger event such as landslide and avalanche or earthquake may be sufficient to initiate its failure resulting in a glof event costa and schuster 1988 richardson and reynolds 2000 the research on glof can be categorized under three broad areas i the first relates to the identification of potentially dangerous glacial lakes and their possible degree of risk in causing glof this identification is based mostly on remotely sensed satellite imageries ageta et al 2000 mool et al 2001 komori 2008 bajracharya and mool 2009 kumar and prabhu 2012 luitel et al 2012 a number of glacial lakes have been identified and found to be expanding as a result of climate change and glacier thinning watanabe et al 1994 benn and lehmkuhl 2000 sakai et al 2000 evaluated the rate of glacial lake expansion in rolwaling himalaya nepal by applying the heat balance method while bolch et al 2008 demonstrated an automatic detection method of lake surface using the normalized difference water index ndwi ii the second area of research is focused on the analysis of the causes contributing to glacial lake outburst and techniques to model moraine dam failure richardson and reynolds 2000 studied 26 moraine dammed lakes in the himalayas and identified five motivating factors for an outburst and the degree to which each factor may be considered important ghimire 2004 summarised the generic causes of glacial lake outburst clague and evans 2000 studied the discharge from moraine dammed lakes in british columbia and identified six factors for its initiation in general moraine dams are found to fail mostly by overtopping of the dam by the lake water due to an impulse wave generated by a rock fall or avalanche it could also occur due to the generation of excessive glacial melt water or sudden precipitation awal et al 2010 suggested that the self destruction of a moraine dam can occur due to failure of the dam slopes and melting of ice cores liu et al 2013 focused on specific lakes and investigated the aforementioned facts through a systematic survey while others modeled lake bursts through laboratory experiments shrestha et al 2010 awal et al 2010 iii the third area of research is directed towards glof hazards analysis and risk assessment such studies rely either on remote sensing mckillop and clague 2007 quincey et al 2007 raj et al 2013 or on statistical analysis costa and schuster 1988 walder and o connor 1997 cenderelli and wohl 2001 huggel et al 2004 mckillop and clague 2007 other significant approaches for predicting the outburst flood hydrograph resulting from moraine dam failure employ numerical models based on the governing equations of physics of flow and dam breach these numerical approaches vary with the assumptions for material considerations of the dam for example noncohesive fread 1988 or cohesive and porous yusof et al 2010 takahashi and nakagawa 1993 considered an erosion law depending on the flow generated local shear stress awal et al 2010 included the effect of wind generated impulse wave the use of models like breach fread 1988 xin et al 2008 or basement worni et al 2014 remained popular for glof studies while a few researchers employed precise empirical formulae to obtain the glof generated flood peak costa and schuster 1988 clague and evans 2000 chen et al 2010 xie et al 2013 it may be worth noting that these models assume a dam breach geometry which is made to expand progressively with time following a pre defined relation some researchers analyzed dam break flows resulting from a glof clague and evans 2000 osti and egashira 2009 procter et al 2010 westoby et al 2014 or without a glof fraccarollo and capart 2002 zhou et al 2004 biscarini et al 2010 cantero chinchilla et al 2016a cantero chinchilla et al 2016b relating to glof however no study has apparently been reported on the simulation of the erosional destruction of a moraine dam by overtopping and estimation of resulting flood hydrograph by numerical computation of course numerical simulations of erosional failure have been reported for manmade dams and dykes of these two the failure of the former is similar to that of natural dams like moraine dams wherein the water of the reservoir while overtopping the dam causes it to erode and release the entire water of the reservoir as a flood in this study two methodologies are followed wang and bowles 2006 faeh 2007 and van emelen et al 2015 simulate the erosional failure of homogenous embankment dams by initiating a pilot cut at a given location on the dam crest whereas coleman et al 2002 pontillo et al 2010 schmocker and hager 2012 and müller et al 2016 did not consider any such initial pilot cut for initiation of the erosion the failure of dykes that is embankments that run parallel to a river is more of a breaching process wherein the water flowing at high stage within the dykes finds a way out through a weak spot leading to an initial breach outlet eventually expanding and leading to a complete collapse however this process of failure does not resemble the failure of a moraine dam though some numerical simulations were reported based on the physics of erosion and transportation of sediment which are somewhat similar to moraine dam failure tingsanchali and chinnarasri 2001 wang and bowles 2006 faeh 2007 pontillo et al 2010 further simulation of failure of a dyke or a river embankment essentially requires an imperfection in the geometry for initiation of the failure like a pilot cut or notch on the dyke in the present study an open source two dimensional numerical flow simulation model telemac 2d lang 2010 coupled with the sediment transport simulation model sisyphe villaret 2010 was used for the purpose of the present analysis the dam was modelled as an earthen embankment and the methodology employs the erosion laws relating them to the bed shear stress generated by the flow no pilot cut or notch was required for initiating the erosion process numerically parameters related to dam material properties median size of sediment d 50 and porosity of sediment were varied for ascertaining the validity of the model the simulated results were compared with those obtained from equivalent physical models the combined model was also run for the simulation of the flood wave resulting from the failure of the tangjiashan lake in 2008 on jianjiang river in china and compared with the observed data though the formation of the lake is due to a landslide that blocks the river flow temporarily the failure of the naturally formed dam and the resulting propagation of flows are similar to those resulting from the overtopping of moraine dams sensitivity analysis was also carried out to understand the relative importance of the parameters for resulting flood peak which was probably the first attempt in assessing the most sensitive parameters that were responsible for causing high glof peaks the combination of the telemac 2d model coupled with the model sisyphe was successfully used in simulating river flows and sedimentation by previous researchers hervouet et al 1994 latteux 1995 horritt and bates 2002 liang et al 2008 laroche and alquier 2013 villaret et al 2013 dutta and sen 2016 however the application of this combination in demonstrating the erosional failure of moraine dams and estimating the resulting flood hydrograph is presented for the first time 2 numerical modelling approach the overtopping flow of a moraine dam is similar to the flow over an earthen dam manmade or natural with low or no tail water powledge et al 1989a b reported studies on overtopping of flow over embankment type dams and presented the three erosional zones under two flow regimes as shown in fig 1 erosion zone a lies in the subcritical flow region this zone witnesses the flow proceeding from the static energy head of the lake reservoir towards a combination of dynamic and static head over the upstream part of the dam crest in this zone the hydrodynamic forces and tractive stresses are small due to the small energy gradient and low flow velocity the occurrence of erosion of the bed material is therefore quite less supercritical flow regimes contain two parts of erosion zone erosion zones b and c erosion zone b is the region just after erosion zone a where the critical flow mainly occurs the bed particles are expected to move or erode the downstream crest portion only if the bed shear stress exceeds its critical value for particle motion erosion zone c is the portion where the water flows over the downstream slope of dam and the energy head and velocity of flow significantly increase the tractive stresses are large in erosion zone c leading to high erosion by transporting bed materials when the process of erosion commences and the flow continues the position of the three zones show a significant shift towards the upstream base point of dam 2 1 hydrodynamic model the numerical hydrodynamic model telemac 2d solves the shallow water equations and simulates open channel flow in two dimensions in a horizontal space where the variables are averaged across the flow depth the depth averaged continuity and navier stokes equations are respectively as follows 1 h t h u x h v y 0 2 h u t h u 2 x h u v y g h h x s x 3 h v t h u v x h v 2 y g h h y s y where h flow depth u and v depth averaged velocity components in x and y directions respectively x and y horizontal and spanwise distances respectively g gravitational acceleration t time and sx and sy momentum source terms involving resistance to flow expressed as follows 4 s x g c 2 u u 2 v 2 5 s y g c 2 v u 2 v 2 where c chézy friction coefficient the equations were solved for the three unknowns h u and v using the finite element method for a given set of boundary conditions as provided by the user in case of handling highly unsteady flows at immediate downstream of dam the model employs the time averaged flow concept where no other additional term is considered for supervising the transient turbulent flow actually here after depth averaging the reynolds stress term appears to be as bed shear stress which is reflected as momentum source term sx and sy in the form of friction coefficient c eqs 4 and 5 2 2 sediment transport model the computation of sediment particle transport is based on the active layer concept hirano 1971 which assumes the bed to be composed of many thin layers with the topmost bed layer the active layer being in direct surface contact with the flowing water while the layer below the active layer works as the substrate layer the thickness of the active layer is generally considered to vary with time scale being a function of dam height or sediment size van niekerk et al 1992 cui et al 2010 the active layer thickness is usually measured in terms of bed roughness which is a multiplier of median sediment mean size d 50 for the flat bed case following the literature the present model considered the active layer thickness as 3d 50 moreover einstein 1950 also described the sediment transport in active bed layer as the motion of sediment particles in a thin layer of two particle diameter sizes above the bed as the hiding exposure correction is usually quite less for sand bed materials darby and thorne 1996 no correction was applied and the critical shields parameter was assumed as constant fig 2 illustrates the element wise physical bed elevation change process at the active bed layer the changes in bed elevation was computed using eq 6 considering the threshold condition wherein the erodibility factor was compared with the threshold bed shear stress that is characteristic of the particular material forming the surface of the dam sisyphe the numerical model for sediment transport and erosion simulates the bed topography by calculating the change in bed elevation z using the exner equation which is expressed as follows 6 1 p z b t q b x x q b y y δ b c b t e d 0 where p porosity zb bed elevation qb x and qb y volumetric bed load transport per unit width in x and y direction respectively δb bed load layer thickness cb sediment concentration in bed load layer and e d net sediment flux given by erosion minus deposition flux the net sediment fluxis determined based on the concept of equilibrium concentration as follows celik and rodi 1988 7 e d w s c eq c z where ws settling velocity ceq equilibrium near bed concentration and cz near bed concentration calculated at an elevation z in bed load layer the ceq is calculated according to the zyserman and fredsoe 1994 formulation as 8 c eq 0 331 θ θ c 1 75 1 0 72 θ θ c 1 75 where θc critical shields parameter and θ μθ the nondimensional skin friction which is related to the shields parameter with a ripple correction factor μ the cz can be calculated using the rouse formula rouse 1961 9 c z c a z h z a a h r where r ws κu called the rouse number κ von kármán constant κ 0 4 u shear velocity and ca reference concentration at a reference level z a 0 05 h in sisyphe for predicting bed load the following formulas as proposed by van rijn 1984 are given by 10 q b τ 3 0 053 s 1 g d 50 τ 3 2 d 0 3 11 q b τ 3 0 1 s 1 g d 50 τ 3 2 d 0 3 where 12 d d 50 ρ s ρ g ρ υ 2 τ u 2 u 2 c r u 2 c r in the above qb bed load transport rate s relative density d particle parameter u cr critical shear velocity τ nondimensional excess bed shear stress ρ mass density of water ρs mass density of sediment and υ coefficient of kinematic viscosity the phenomena of sediment transport mainly depends on the interaction between water flow and the sediment bed type sediment bed roughness and sediment size the flow over dam crest and downstream dam slope changes its characteristics from subcritical to supercritical causing a hydraulic jump in the middle the flow just after the hydraulic jump creates some turbulent characteristics the transport of the sediment particles by rolling sliding and saltating modes depends on these characteristics of flow which can be calculated from the bed shear stress if the shear velocity just exceeds its critical value in critical flow depth condition the particle starts to move by rolling or sliding the particles move along the bed by saltation when that excess shear velocity increases this exceedance of shear velocity was taken into account in the eq 6 for calculating the sediment transport rate qb in terms of nondimensional excess bed shear stress τ eqs 10 12 2 3 integrated numerical scheme the numerical flow model telemac 2d provides the user the flexibility to modify the set of fortran sub routines to meet the specific requirements of each different model specification of initial conditions or complex boundary conditions linkups with other modelling systems and introduction of new functions the model accepts input files containing the mesh and bathymetry as binary files the boundary conditions ascii file and the steering parameters ascii file the steering parameters include information on the input output filenames the time step the friction and viscosity formulations adopted and the solver used for the computation the information contained in the different input files is generally produced by using user friendly preprocessors the numerical flow model computations were initiated first which computed the hydrodynamic parameters velocity discharge flow depth assuming a fixed bed over the discretized flow domain unstructured triangular mesh at a set of given initial condition for the first simulation time step the resulting hydrodynamic parameters were then exported to sisyphe where the bed load and bed elevation changes were calculated the new bottom bathymetry so computed was passed back to the flow model as the bottom geometry condition for the next time step and the processes were repeated till the end of the simulation time the results produced by the numerical model were stored in a binary file module named selafin format the final results were treated by the post processing software blue kenue nrc che 2010 which produced the graphical outputs and computation statistics 3 experiments in laboratory flume and numerical simulations in order to validate the erosion process of a dam by overtopping laboratory experiments with physical models were carried out in one of the glass sided hydraulic flumes at the hydraulic and water resources laboratory indian institute of technology kharagpur india the schematic diagram of the full experimental setup is shown in fig 3 the dimensions of the flume are 0 3 m wide and 4 m long with an effective length of 3 5 m the shape of the earthen dam used here to represent a moraine dam was considered trapezoidal with a flat crest the side slopes of the dam were kept as 2 h 1 v on both upstream and downstream while other geometric measurements of dam wdc wdb lu s were kept variable in each experiment as stated in table 1 it may be noted that the volume of lake lv behind the dam is a function of lu s all the experiments were started with a tail water level of 0 04 m with the application of a constant flow from the upstream the dam was placed at a length lu s table 1 from the inlet of the water source which was controlled by a valve uniformly graded sediment of two types s1 and s2 were used to prepare the model dam in the flume another type of dam built with mixed sediments sm was used to achieve the composition of natural moraine dam the case study glacial lakes and glacial lake outburst floods in nepal by icimod based on a field survey to the tsho rolpa moraine dam in nepal reported the following data for the dam d 30 1 4 mm d 90 300 600 mm and d 50 10 mm for the model experiments in the present study the sediment mixture sm was prepared by mixing of three types of sand and the grain size distribution is presented in fig 3 the median size of sediment d 50 mixture sm s1 and s2 type sediments were 1 22 mm 1 7 mm and 1 0 mm respectively in the experiments the water behind the dam was impounded with a constant discharge from the upstream end of flume the inlet discharge was controlled with inlet valve and the discharge was measured using an ultrasound electronic deviceportaflow 330 micronics ltd 2010 having an accuracy 6 during the time of dam failure the outlet discharge was measured with the help of a constant area reservoir at the downstream of flume where the rise in water level was recorded with time one video camera was used to capture the breach or dam failure profiles from right side of the flume table 1 illustrates the details of all the experimental conditions and the composition of the dam body a schematic diagram of the dam section as used in the experimental model is presented in the inset view of fig 4 the experimental flume setup was replicated by a rectangular channel section with horizontal bed 30 cm width and 350 cm length for numerical simulation fig 5 illustrates the bottom bathymetry of the domain for numerical simulation containing 4816 nodes and 9000 elements and constructed with the open source gridding software tool blue kenue all the experiments detailed in table 1 were simulated numerically keeping the same conditions as in experimental cases in case of model calibration different laws of bottom friction chézy and strickler were tested to a range of friction coefficient values found in literature horritt and bates 2002 fernandes et al 2001 and finally the friction coefficient c 40 m1 2s was adopted as it provided the best result only for bottom friction coefficient calibration a set of four simulation runs c 30 40 60 and 80 m1 2s were carried out for each of the different experiment test cases i ii iii and iv the kinematic viscosity of the fluid was considered as 10 6 m2s 1 moreover the model was tested for solver option with six variations of gradient method with finally the conjugate gradient on a normal equation being finalized as it showed an accuracy of 10 4 for this numerical model there was no need to calibrate the threshold shear stress θc in fact in the present study the critical shear stress and critical velocity for erosion and deposition was controlled by the value of the shields parameter θ which was finally set to 0 047 the simulation comprises of the sloping effects on sediment transport and therefore the direct effects of gravity on sediment particles on a sloping channel or riverbed was also considered by using the koch and flokstra s 1981 approach for magnitude and the talmon 1992 approach for direction the optimum time step δt in the numerical simulations for each iteration was found to be δt 0 01 s hydrodynamic model and δt 1 s sediment transport model to maintain the courant condition and considering the grid spacing size 4 results and discussion 4 1 comparison of numerical and physical experimental model results 4 1 1 dam morphology the numerical results are compared with the experimental data discharge recorded at 3 5 m downstream of the flume inlet for evaluating the performance of the numerical model the brier skill score bss was calculated which is defined as sutherland et al 2004 van rijn et al 2003 13 bss 1 mse y x mse b x 14 mse y x 1 i i 1 n y i x i 15 mse b x 1 i i 1 n b i x i where mse mean square error y and x numerically simulated and experimentally observed data respectively i number of spatial grid n total number of the grids or nodes and b baseline prediction data in the present study the baseline prediction for the final bathymetry used in morphological modelling is equal to the initial bathymetry assuming that the bed does not alter the bss score may be treated as a measure of model skill gerritsen et al 2011 ganju et al 2011 dam et al 2015 because it essentially compares the numerical simulation results to a baseline prediction a perfect matching suggests bss 1 whereas modelling the baseline condition gives bss 0 according to sutherland et al 2004 bss value greater than 0 6 can be considered as good and 0 2 bss 0 6 as fair the numerical simulation model reproduced the overall breaching process of all the cases tested and at all times except at the initial moments with a good accuracy overall the bss values were found to improve as the simulation progressed table 2 results at t 8 s showed a slight discrepancy in the dam top retreat and toe erosion but a good estimate of bed evolution was observed at further time steps 4 1 2 comparison of water levels and breach hydrographs fig 6 shows the morphological changes of dam during the breaching process the changes were compared with the experimental data for the test case i here at t 8 s it was observed that the morphological profile of numerical simulation shows a bad matching with the experimental profile which is also reflected by a poor bss value for all other time steps the numerical results were found to provide an overestimation of the bed elevation this observation was directly compared with the experimental data conversely at t 28 s it is observed that both numerically simulated and laboratory experimental results show similar results providing the best accuracy for the model the dam breaching advancements in numerical model for all the nine test cases are presented in fig 7 the effect of dam height in breaching advancement may be clearly seen by comparing test cases v and vi when the dam height was higher than the other the initial erosion or breaching rate was also more in test v than vi similarly in test cases iv and v when the lake volume behind the dam increases test iv the erosion process is found to be faster than the other fig 8 compares the numerically simulated and experimentally measured flow profiles free surface profiles over the dam for test case i at different time instances t 8 s 16 s 28 s 40 s 88 s and 120 s at t 8 s and t 16 s the numerical model appears to slightly overestimate but at t 28 s it matches perfectly with the experimental data whereas at other three time steps it shows a good matching with the experimental results the images of physical experiment at different times are presented in fig 8 b and can be therefore visualized as in the actual dam breach by comparing with the graphical plots fig 8 a the hydrograph resulting from the erosional collapse of the dam for all the nine test cases are shown in fig 9 it is apparent that in all the cases the numerical model results are in a good match with the experimental model results and the most perfect match occurs for the test case iii here the peak unit discharge qp m3 s per m width can be related to the dam breaching process in the comparison for test cases iv and v the former reached a higher peak than the latter the dam erosion advancement process was also faster in test iv than in test v fig 9 similarly while comparing between test cases v and vi it is clearly visible that for a greater dam height test v the peak discharge was also higher than other having a lower height of the dam test vi for some tests e g tests iii and iv the oscillations of the experimental and numerical results are evident to be nearly the same at the time of peak discharge during the time of breaching the entire ponded water gets released due to the erosion of the dam and together with the base flow results in a highly unsteady flow simulation and fluctuations between subcritical and supercritical flow regimes reflecting instabilities of flow after hydraulic jump which too is unsteady to explain further it can be said that when water flows over the downstream slope of the dam and reaches the channel bed the hydraulic jump occurs where it meets the slower moving water on the downstream as the dam erodes the supercritical flow taking place over its eroded surface fluctuates with time resulting in an unsteady hydraulic jump the oscillations were captured by the numerical model due to this fluctuating hydraulic jump at the location of the hydraulic jump the flow characteristics actually do not follow shallow water equations on which the present numerical model calculates the flow parameters the oscillations are also reflected in fig 10 d between time t 17 s and t 40 s for 1 5 fr 2 2 in these test cases tests iii and iv the calibration of model parameters related to flow was carried out somewhat more precisely resulting in nearly perfect matching between the curves of experimental and numerical results in both amplitude and phase 4 1 3 hydrodynamics and erosion phenomena the contour plots of velocity in channel downstream direction bed elevation change bed shear stress and froude number fr at a longitudinal section y 0 05 m for the test case i are presented in fig 10 in this test case the embankment was positioned at a distance from inlet x 2 4 m to x 3 m with the dam crest at x 2 65 m to x 2 75 m the water flow reached a maximum velocity dark red region fig 10 a at the top of the dam and along the downstream slope between times t 10 s and t 30 s the contours of velocity fig 10 a and bed shear stress fig 10 b show similar trends at all time instances along with their different range of values when the flow velocity increases the bed shear stress also becomes greater however when the flow velocity just exceeds its critical value for the sediment motion according to eq 12 it starts to develop an excess bed shear stress τ in eq 12 acting on the sediment particles which acts as the main cause of initiating erosion of the particles thus it is observed that at t 10 s the erosion of dam fig 10 c starts and till t 40 s increases at a rapid rate with the flow velocity and bed shear stress reaching their peaks however at times t 40 s the flow velocity reduces which results not much erosion except some transportation of the eroded sediments the maximum erosion or breaching of the dam occurs before time t 40 s which is also reflected in fig 6 almost 50 of erosion occurs before t 40 s after time t 40 s only when flow velocity values rise to within 0 52 m s and 0 45 m s and the bed shear stress ranges between 0 80 pa and 0 52 pa that the erosion occurs due to supercritical flow condition resulting from the very small flow depths which reflects in the contours of froude number supercritical flow with fr 1 is shown as yellow shaded zone in fig 10 d the green shaded zone in the same figure represents the froude number range between 1 10 and 0 80 which indicate the occurrence of critical flow over the dam crest and along the downstream slope therefore it is observed that the critical flow velocity lies between 0 47 m s and 0 35 m s yellow shaded zone fig 10 a for test case i in fig 10 c the negative values purple blue and green colored zones indicate erosion and the positive values different shades of the red colored zone represent deposition of the eroded sediments at a time t 10 s from the start of overtopping it is observed that the dam located between x 2 70 m and x 2 80 m from the inlet starts eroding and the eroded sediments deposit after some distance ahead at x 2 9 m when the flow continues to increase with time the erosion also grows faster due to the increasing flow velocity and the eroded sediments transport downstream beyond the dam and finally are deposited between x 2 9 m and x 3 3 m as expected the deposition of the eroded sediments occurs when the flow velocity reaches below the critical value immediately after the hydraulic jump as reflected in the green to the blue colored zone of the velocity contour plot fig 10 a for all test cases the results appear to be quite satisfactory with the bss value ranging between 0 75 and 0 98 at t 8 s from the initiation of dam overtopping the sediment erosion rate as computed by numerical simulations observed to be quite high resulting in a low range of bss value 0 3 0 6 table 2 the majority of the erosion occurs just after the initial overtopping and generates a flood peak which is higher than the average steady inflow figs 8 and 9 almost 80 of the total dam erosion and 50 of dam height reduction occurs by about t 40 s fig 8 and beyond t 40 s the flow continues to transport the eroded dam material towards the channel downstream depositing them at some length it is found that the flood peak is almost 150 higher than the steady inflow rate of discharge for all the nine test cases the erosion breaching process of a dam is directly proportional to a function of the flow velocity over the dam being related to the bed shear stress eqs 10 12 and flow characteristics like froude number fig 10 d these parameters viz flow velocity bed shear stress and froude number are inter related and are responsible for causing the change of bed elevation and breaching of the dam fig 10 4 1 4 sensitivity analysis sensitivity analysis of the numerical model was performed for determining the important parameters which need to be precisely estimated for making accurate prediction of breached outflow hydrographs resulting from dam erosion this task was carried out by using the local sensitivity analysis technique one factor at a time ofat oat where the numerical model was run repeatedly by varying each input parameter of the six table 3 one at a time within a prescribed range while keeping the others as constant the resulting hydrograph and peak discharge values were analyzed to determine the absolute sensitivity coefficient sc and normalized sensitivity coefficient sn which provide a measure of the sensitivity table 4 sc and sn for each parameter were calculated as follows sattar and gharabaghi 2015 16 s c 1 p o p i 17 s n s c p im p om where po output parameter pi input parameter pim mean value of pi and pom output parameter when po pim fig 11 shows the effects of these parameters based on the changes of peak value for the outflow flood hydrograph while varying a parameter the others being kept constant it is observed from the analysis that the height of the dam appears to be the most sensitive of all the six parameters in affecting the peak of the resulting flood hydrograph the next two most influential parameters are found to be the lake volume and inlet flows the top width of the dam and the porosity of the dam material are relatively less sensitive while the median size of dam material d 50 is the least sensitive of all this study therefore shows that for predicting a glof hydrograph the most important three parameters to be taken into consideration are moraine dam height volume of lake behind dam and the inflow discharge rate to the lake in comparison it may be noted that dike height was also identified to be a sensitive parameter by schmocker and hager 2012 for the process of a dyke breach evidently dyke breach is not exactly comparable to the present case as a dyke runs parallel to a flowing body of water while a dam as in this case is a barrier across the flow path nevertheless schmocker et al 2014 also identified the median size of sediment d 50 forming the dyke as sensitive 4 2 case studies some researchers simulated the breaching of a moraine dam and lake drainage using numerical models such as bajracharya et al 2007 xin et al 2008 and shrestha et al 2013 who applied the model breach fread 1988 to cases in the himalayan nepal and tibet regions osti and egashira 2009 simulated the outflow glof hydrograph in a lake of himalayan region using hec ras whereas worni et al 2014 simulated the evolution of a moraine dam breach and generation of glof hydrograph using the model basement in a lake of peru in this section the model telemac 2d and sisyphe were employed in modelling the breach evolution of a landslide dam that formed on the jianjiang river in china on 12th may 2008 although such a dam is formed by the sudden deposition of hill slope materials bordering a river valley instigated by a landslide and temporarily blocking the flow of the river its subsequent washout and generation of flood hydrograph is quite similar to that of a moraine dam the particular incident considered here known as the tangjiashan landslide dam failure was reported extensively with well documented data fan et al 2012 bo et al 2015 kidyaeva et al 2017 this case was chosen here to validate the predictive capability of the present numerical model on a field scale further although the numerically coupled model of telemac 2d and sisyphe was validated with two dimensional laboratory experiments it remained to be proved whether the model is capable of simulating a three dimensional phenomena equally well it is unfortunate that observational data of moraine dams especially quantitative measurements of the flood hydrograph resulting from its breaching is not commonly reported in literature of course this may naturally be expected given that most of the moraine dams are in very remote locations and there is virtually no prior indication to the time of a moraine dam collapse hence it is not practically possible to set up a monitoring infrastructure to capture the various flow parameters during the failure of a moraine dam however it is quite possible to pre simulate such a failure given the data on its physical properties and river flow characteristics providing a before hand indication of the localities or infrastructure that may be affected if the dam eventually fails of the several moraine dam lakes in the indian himalayas the lhonak lake is considered to be in a vulnerable state of existence and may collapse if a sufficiently high trigger like a heavy rainfall or a strong earthquake occurs as a second case study a simulated washout of the lhonak dam is presented here with predictions of consequent flood hydrographs which it is hoped would provide a prior cautionary advice to the population of the area in case of the dam breach in fact the hydrograph may be run in conjunction with a flood routing model to predict the possible extents of inundation in case of the dam s failure this would aid the authorities in charge of the safety and security of the local population in planning developments along the river judiciously 4 2 1 tangjiashan landslide dam breaching and flood hydrograph simulation the tangjiashan landslide dam incident occurred at location 31 50 33 n and 104 25 47 e almost 5 km upstream of the town of beichuan in the sichuan province of china the landslide due to the wenchuan earthquake blocked the jianjiang river and formed the tangjiashan barrier lake of about 3 108 m3in volume with flows reaching from the upstream catchment area of around 3550 km2 fan et al 2012 the jianjiang river is mainly rain fed river and according to the records of the hydraulic station at beichuan the average annual flow of the river was 81 m3 s increasing up to167 m3 s at peak monsoon period the wenchuan earthquake was occurred on the 12th may of 2008 and from the historical flood records it is found that the most of the extreme rainstorms hit the region between june to september and caused high floods with peak discharges of 1180 2190 and 3040 m3 s corresponding to 1 5 and 10 years return periods respectively in 2008 the wenchuan and tangjiashan area experienced a heavy rainstorm situation and extreme inflow discharges filled the lake rapidly creating a high risk of overtopping failure of the dam and consequent flooding on the downstream under this situation the chinese government constructed a large emergency spillway in the dam as a mitigation measure from the literature the detailed measurements of spillway fan et al 2012 as well as measurements of dam bo et al 2015 were noted for recreating the surface profile of the dam section in telemac 2d for generating the bathymetry of the lake section which was required as input to the numerical model the topographic information was derived from the satellite digital elevation model dem srtm data set using the gis software arc gis the simulation of the dam breaching process and consequent flood generation were carried out for a 3 day time period from 7th to 10th june 2008 and the peak flood was found to occur on 10th june for the present study the model was tested with 2190 m3 s discharge as the inflow to the lake representing the heavy rainstorm situation the simulation results reflect a satisfactory match of the computed flood hydrograph with the observed and that simulated by fan et al 2012 in order to obtain a good match in the practical case calibrations were done for two parameters in the present study the combination of dam material and porosity of dam in the simulation of telemac 2d the final type of dam material that was considered to comprise of a combination of five classes of sediment 10 having d 50 600 mm 5 having d 50 300 mm 60 having d 50 100 mm 10 having d 50 50 mm and 15 having d 50 5 mm having a combined porosity of 20 all other model parameter values used for this real field case were kept same as those used to simulate the experiments in laboratory scale certainly in the physical laboratory model and numerical model attempts have been made to match the physical phenomena of the dam erosion and failure by considering the flow resistances in cohesion less uniformly and nonuniformly graded sediments even though the laboratory physical model was much smaller than that of the practical case study the flow resistances could be handled only by changing the two parameters the type of dam material combination of mixed type sediment and the porosity of sediment although in practical case the dam material can probably never be absolutely cohesion less such the model was considered here for simplicity in handling the flow resistance terms the resulting hydrograph is illustrated in fig 12 it is observed that telemac 2d simulation overestimates the flood peak almost by 12 from the observed peak whereas in comparison the simulated results of fan et al 2012 using the breach model overestimates the flood peak by around 8 moreover according to the present model the simulated time to peak of the flood hydrograph was also predicted quite early 7 h before than observed besides the flood hydrograph appears to match well with the observed result the reasonably satisfactory results thus obtained may be considered as a satisfactory practical field validation of the numerical simulation model considered for the study 4 2 2 south lhonak lake outburst and glof hydrograph prediction south lhonak lake is located at the toe of south lhonak glacier at 27 54 45 n and 88 11 46 e in the extreme north western corner of the sikkim himalayas of india south lhonak glacier is the main parent glacier of the lake it is also fed by the north lhonak glacier as shown in the fig 13 the lake water level is 5208 m from mean sea level msl and the north face of the lake is extensively nourished by avalanches falling off this rock face the areal expansion process of the south lhonak lake was analyzed based on a series of satellite images fig 14 shows the areal change of the lake with time according to the satellite image landsat 7 of 2005 the area covered by the lake was nearly 0 794 km2 which increased to 1 286 km2 in 2015 computations reveal that the areal expansion rate of the lake was 0 0468 km2 year over the five years of 2005 to 2010 and 0 0516 km2 year for the next five years from 2010 to 2015 indicating high potentiality to cause a glof a field survey was carried out by the national mission for sustaining the himalayan eco system nmshe in 2014 and a bathymetric map for south lhonak glacial lake was prepared as it was not possible to obtain all required data from this report the dem map was derived from srtm data set using the gis software package arc gis the erosional wash out of the moraine dam was simulated with the model combination of telemac 2d and sisyphe considering a constant inflow of 30 m3 s the simulation was initialized with the lake water level assumed at 5208 m msl the bathymetry of the lake is shown in the fig 15 for maintaining the flow resistances the dam material size and porosity were calibrated again for these data and input as a combination of mixed type sediment of four classes with an overall porosity of 30 the hypothetical breaching of the dam and outburst of lhonak lake with geometries of the years 2005 2010 and 2015 were separately simulated and the resulting glof hydrographs are presented in fig 16 it is observed that the initiation of the breach took some time to occur and then the pattern of rising limb of the breach hydrograph was almost the same for each year but the peak discharge of floods differed the peak of the flood hydrograph can be related to the area of the lake because it is observed that when the lake area was the maximum 1 286 km2 in 2015 the flood peak also indicated to be the maximum value 117 m3 s similar results were also reported by worni et al 2014 for glof hydrograph obtained using the model basement from the ventisquero negro lake argentina 5 conclusions this study attempts to analyze the erosion based moraine dam failure caused by overtopping and to estimate the predicted outflow flood hydrograph through simulations with 2d numerically coupled model for flow and sediment motion the results are verified with a series of laboratory flume physical experiments comparisons of the experimental values with the numerical results appear to be reasonably good for the bed elevation changes and the evolution of the flow profiles the physical dam breaching erosion processes are also satisfactorily correlated with the hydrodynamic phenomena when the flow characteristics change from subcritical to supercritical flow resulting in a hydraulic jump at a downstream location this is confirmed with the help of contour plots of velocity bed shear stress froude number and change of bed elevation of the dam section at all times additionally the model was used to assess the sensitivity effects of the various parameters such as particle size of moraine dam porosity of dam material dam crest width dam height and lake volume on the prediction of the outflow hydrograph resulting from the dam erosion process the numerical simulations were also validated with the field data of a failure event of a landslide dam proving the applicability of the 2d model to general 3d phenomena at field scale the model was then used to predict the probable flood hydrograph that may be expected to be generated if lhonak lake one of the most threatened moraine dams of the himalayas fails in the present numerical model however some discrepancies in bed elevation changes were noticed particularly at the location of the top of just downstream the crest it might be attributed to the effects of dam material cohesion and 3d flow structures present for the physical experiments being not considered in the numerical model moreover the transient turbulence effects were not considered in this model though it may not be realistic in dealing with the conditions of the physical experiments a 3d numerical model including sophisticated turbulence models as well as the downstream dam slope effect related to the angle of repose of dam material might provide better results in spite of these limitations it is expected that the methodology as illustrated in this study for numerical simulation of moraine dams may prove to be useful for application to practical field studies in future 
7168,the areas of glacial lakes in the himalayas continue to increase alarmingly due to global warming with consequent risk of glacial lake outburst flood glof the outburst is most common for moraine dammed lakes as a result of a failure of the dam by overtopping and erosion or piping due to seepage in the present context glof events especially for the moraine dam failure process needs to be predicted to assess the drastic and detrimental impacts on the downstream river valley this study focuses on validating an integrated model for simulating the failure of moraine dam by overtopping and erosion using a coupled numerical simulation model the proposed numerical methodology is validated with the data from experiments in laboratory scale physical models the results of the model are compared for both the erosional profiles during collapse of the dam and the resulting outflowing flood hydrograph the primary finding is that the moraine dam height and the volume of the lake upstream of the dam are the most sensitive parameters influencing the glof peak the model is also applied to the field problem of the tangjiashan lake outburst and dam failure and shows reasonably good agreement with observations the validated model is also run for the south lhonak glacial lake in the sikkim himalayas india to obtain the probable flood hydrograph in case of failure of the moraine dam keywords breach morphodynamics erosion glacial lake moraine dam failure open channel flow outflow hydrograph nomenclature b baseline prediction data bss brier skill score c chézy coefficient l1 2t ca reference concentration at a reference level cb sediment concentration in bed load layer ceq equilibrium near bed concentration cz near bed concentration at z elevation of bed d net flux for deposition d dimensionless particle size l d 30 30 finer sediment size l d 50 median sediment size l d 90 90 finer sediment size l e net flux for erosion fr flow froude number g gravitational acceleration l t 2 h flow depth l hd dam height l i number of spatial grid lu s length of dam upstream mse mean square error n total number of the grids or nodes p porosity pi input parameter pim mean input parameter po output parameter pom output parameter for pom pim qb x qb y bed load per unit width and time in x and y direction respectively qp unit peak discharge l2t 1 s relative density sx sy source term in x and y direction respectively lt 2 t time t u shear velocity lt 1 u cr critical shear velocity lt 1 u v depth averaged velocity components in x and y direction respectively lt 1 wd dam crest width l x experimentally observed data x horizontal distance l y numerically simulated data y span wise distance l zb bottom or bed elevation l μ ripple correction factor υ coefficient of kinematic viscosity l2t 1 ρ mass density of water ml 3 τ nondimensional excess bed shear stress θ shields parameter θ nondimensional skin friction δb bed load layer thickness l θc critical shields parameter ρs mass density of sediment ml 3 1 introduction global warming and its impacts have been growing as a grave concern in recent times especially for the snow packs of high mountains like the himalayas melting of permafrost and glaciers has acted as global thermometers haeberli and beniston 1998 ipcc 2001 worldwide the significant increment of glacial lakes both in number and size reflects the effects of global warming mool et al 2001 these glacial lakes pose major hazards in mountainous regions of which the most significant ones being avalanches and glacial floods richardson and reynolds 2000 the latter causing devastating impacts upon the riparian society downstream within a short time span ranging from minutes to hours the glacial floods generally caused by the failure of moraine dams are commonly termed glacial lake outburst flood glof glofs are causes of major concern due to i serious risk of loss of life and ii destruction of valuable infrastructures such as hydropower stations and bridges or roads and buildings located in the river valley and banks downstream in 1971 almost 20 000 lives were lost within five minute of glof initiation at huascaran cordillera blanca mountain region in peru lliboutry et al 1977 the flood debris flow travelled over hills 150 m high and 500 m wide with a speed of almost 80 km h as it destroyed the township of yungay peru another known case of disastrous glof events occurred in 1985 from the dig tsho glacial lake in eastern nepal himalaya which destroyed lives and properties apart from the namche small hydropower plant just a few days after its commissioning the estimated loss was about us 1 5 million icimod and unep 2002 such large glof events have attracted the attention of hydrologists and environmentalists toward the potential consequences of glacier lake failures consequently studies have been undertaken to analyze related phenomena such as growth rates of glacial lakes reason for their outbursts moraine dam failure mechanisms and simulation of moraine dam breach recently researches indicate that the maximum cases of moraine dammed lake outbursts is reported from the himalayas around the mount everest region singh and singh 2001 it has also been established that since moraine dams occur as natural earthen embankments formed from accumulated debris from glacier the moraine which store the glacier melt water behind a trigger event such as landslide and avalanche or earthquake may be sufficient to initiate its failure resulting in a glof event costa and schuster 1988 richardson and reynolds 2000 the research on glof can be categorized under three broad areas i the first relates to the identification of potentially dangerous glacial lakes and their possible degree of risk in causing glof this identification is based mostly on remotely sensed satellite imageries ageta et al 2000 mool et al 2001 komori 2008 bajracharya and mool 2009 kumar and prabhu 2012 luitel et al 2012 a number of glacial lakes have been identified and found to be expanding as a result of climate change and glacier thinning watanabe et al 1994 benn and lehmkuhl 2000 sakai et al 2000 evaluated the rate of glacial lake expansion in rolwaling himalaya nepal by applying the heat balance method while bolch et al 2008 demonstrated an automatic detection method of lake surface using the normalized difference water index ndwi ii the second area of research is focused on the analysis of the causes contributing to glacial lake outburst and techniques to model moraine dam failure richardson and reynolds 2000 studied 26 moraine dammed lakes in the himalayas and identified five motivating factors for an outburst and the degree to which each factor may be considered important ghimire 2004 summarised the generic causes of glacial lake outburst clague and evans 2000 studied the discharge from moraine dammed lakes in british columbia and identified six factors for its initiation in general moraine dams are found to fail mostly by overtopping of the dam by the lake water due to an impulse wave generated by a rock fall or avalanche it could also occur due to the generation of excessive glacial melt water or sudden precipitation awal et al 2010 suggested that the self destruction of a moraine dam can occur due to failure of the dam slopes and melting of ice cores liu et al 2013 focused on specific lakes and investigated the aforementioned facts through a systematic survey while others modeled lake bursts through laboratory experiments shrestha et al 2010 awal et al 2010 iii the third area of research is directed towards glof hazards analysis and risk assessment such studies rely either on remote sensing mckillop and clague 2007 quincey et al 2007 raj et al 2013 or on statistical analysis costa and schuster 1988 walder and o connor 1997 cenderelli and wohl 2001 huggel et al 2004 mckillop and clague 2007 other significant approaches for predicting the outburst flood hydrograph resulting from moraine dam failure employ numerical models based on the governing equations of physics of flow and dam breach these numerical approaches vary with the assumptions for material considerations of the dam for example noncohesive fread 1988 or cohesive and porous yusof et al 2010 takahashi and nakagawa 1993 considered an erosion law depending on the flow generated local shear stress awal et al 2010 included the effect of wind generated impulse wave the use of models like breach fread 1988 xin et al 2008 or basement worni et al 2014 remained popular for glof studies while a few researchers employed precise empirical formulae to obtain the glof generated flood peak costa and schuster 1988 clague and evans 2000 chen et al 2010 xie et al 2013 it may be worth noting that these models assume a dam breach geometry which is made to expand progressively with time following a pre defined relation some researchers analyzed dam break flows resulting from a glof clague and evans 2000 osti and egashira 2009 procter et al 2010 westoby et al 2014 or without a glof fraccarollo and capart 2002 zhou et al 2004 biscarini et al 2010 cantero chinchilla et al 2016a cantero chinchilla et al 2016b relating to glof however no study has apparently been reported on the simulation of the erosional destruction of a moraine dam by overtopping and estimation of resulting flood hydrograph by numerical computation of course numerical simulations of erosional failure have been reported for manmade dams and dykes of these two the failure of the former is similar to that of natural dams like moraine dams wherein the water of the reservoir while overtopping the dam causes it to erode and release the entire water of the reservoir as a flood in this study two methodologies are followed wang and bowles 2006 faeh 2007 and van emelen et al 2015 simulate the erosional failure of homogenous embankment dams by initiating a pilot cut at a given location on the dam crest whereas coleman et al 2002 pontillo et al 2010 schmocker and hager 2012 and müller et al 2016 did not consider any such initial pilot cut for initiation of the erosion the failure of dykes that is embankments that run parallel to a river is more of a breaching process wherein the water flowing at high stage within the dykes finds a way out through a weak spot leading to an initial breach outlet eventually expanding and leading to a complete collapse however this process of failure does not resemble the failure of a moraine dam though some numerical simulations were reported based on the physics of erosion and transportation of sediment which are somewhat similar to moraine dam failure tingsanchali and chinnarasri 2001 wang and bowles 2006 faeh 2007 pontillo et al 2010 further simulation of failure of a dyke or a river embankment essentially requires an imperfection in the geometry for initiation of the failure like a pilot cut or notch on the dyke in the present study an open source two dimensional numerical flow simulation model telemac 2d lang 2010 coupled with the sediment transport simulation model sisyphe villaret 2010 was used for the purpose of the present analysis the dam was modelled as an earthen embankment and the methodology employs the erosion laws relating them to the bed shear stress generated by the flow no pilot cut or notch was required for initiating the erosion process numerically parameters related to dam material properties median size of sediment d 50 and porosity of sediment were varied for ascertaining the validity of the model the simulated results were compared with those obtained from equivalent physical models the combined model was also run for the simulation of the flood wave resulting from the failure of the tangjiashan lake in 2008 on jianjiang river in china and compared with the observed data though the formation of the lake is due to a landslide that blocks the river flow temporarily the failure of the naturally formed dam and the resulting propagation of flows are similar to those resulting from the overtopping of moraine dams sensitivity analysis was also carried out to understand the relative importance of the parameters for resulting flood peak which was probably the first attempt in assessing the most sensitive parameters that were responsible for causing high glof peaks the combination of the telemac 2d model coupled with the model sisyphe was successfully used in simulating river flows and sedimentation by previous researchers hervouet et al 1994 latteux 1995 horritt and bates 2002 liang et al 2008 laroche and alquier 2013 villaret et al 2013 dutta and sen 2016 however the application of this combination in demonstrating the erosional failure of moraine dams and estimating the resulting flood hydrograph is presented for the first time 2 numerical modelling approach the overtopping flow of a moraine dam is similar to the flow over an earthen dam manmade or natural with low or no tail water powledge et al 1989a b reported studies on overtopping of flow over embankment type dams and presented the three erosional zones under two flow regimes as shown in fig 1 erosion zone a lies in the subcritical flow region this zone witnesses the flow proceeding from the static energy head of the lake reservoir towards a combination of dynamic and static head over the upstream part of the dam crest in this zone the hydrodynamic forces and tractive stresses are small due to the small energy gradient and low flow velocity the occurrence of erosion of the bed material is therefore quite less supercritical flow regimes contain two parts of erosion zone erosion zones b and c erosion zone b is the region just after erosion zone a where the critical flow mainly occurs the bed particles are expected to move or erode the downstream crest portion only if the bed shear stress exceeds its critical value for particle motion erosion zone c is the portion where the water flows over the downstream slope of dam and the energy head and velocity of flow significantly increase the tractive stresses are large in erosion zone c leading to high erosion by transporting bed materials when the process of erosion commences and the flow continues the position of the three zones show a significant shift towards the upstream base point of dam 2 1 hydrodynamic model the numerical hydrodynamic model telemac 2d solves the shallow water equations and simulates open channel flow in two dimensions in a horizontal space where the variables are averaged across the flow depth the depth averaged continuity and navier stokes equations are respectively as follows 1 h t h u x h v y 0 2 h u t h u 2 x h u v y g h h x s x 3 h v t h u v x h v 2 y g h h y s y where h flow depth u and v depth averaged velocity components in x and y directions respectively x and y horizontal and spanwise distances respectively g gravitational acceleration t time and sx and sy momentum source terms involving resistance to flow expressed as follows 4 s x g c 2 u u 2 v 2 5 s y g c 2 v u 2 v 2 where c chézy friction coefficient the equations were solved for the three unknowns h u and v using the finite element method for a given set of boundary conditions as provided by the user in case of handling highly unsteady flows at immediate downstream of dam the model employs the time averaged flow concept where no other additional term is considered for supervising the transient turbulent flow actually here after depth averaging the reynolds stress term appears to be as bed shear stress which is reflected as momentum source term sx and sy in the form of friction coefficient c eqs 4 and 5 2 2 sediment transport model the computation of sediment particle transport is based on the active layer concept hirano 1971 which assumes the bed to be composed of many thin layers with the topmost bed layer the active layer being in direct surface contact with the flowing water while the layer below the active layer works as the substrate layer the thickness of the active layer is generally considered to vary with time scale being a function of dam height or sediment size van niekerk et al 1992 cui et al 2010 the active layer thickness is usually measured in terms of bed roughness which is a multiplier of median sediment mean size d 50 for the flat bed case following the literature the present model considered the active layer thickness as 3d 50 moreover einstein 1950 also described the sediment transport in active bed layer as the motion of sediment particles in a thin layer of two particle diameter sizes above the bed as the hiding exposure correction is usually quite less for sand bed materials darby and thorne 1996 no correction was applied and the critical shields parameter was assumed as constant fig 2 illustrates the element wise physical bed elevation change process at the active bed layer the changes in bed elevation was computed using eq 6 considering the threshold condition wherein the erodibility factor was compared with the threshold bed shear stress that is characteristic of the particular material forming the surface of the dam sisyphe the numerical model for sediment transport and erosion simulates the bed topography by calculating the change in bed elevation z using the exner equation which is expressed as follows 6 1 p z b t q b x x q b y y δ b c b t e d 0 where p porosity zb bed elevation qb x and qb y volumetric bed load transport per unit width in x and y direction respectively δb bed load layer thickness cb sediment concentration in bed load layer and e d net sediment flux given by erosion minus deposition flux the net sediment fluxis determined based on the concept of equilibrium concentration as follows celik and rodi 1988 7 e d w s c eq c z where ws settling velocity ceq equilibrium near bed concentration and cz near bed concentration calculated at an elevation z in bed load layer the ceq is calculated according to the zyserman and fredsoe 1994 formulation as 8 c eq 0 331 θ θ c 1 75 1 0 72 θ θ c 1 75 where θc critical shields parameter and θ μθ the nondimensional skin friction which is related to the shields parameter with a ripple correction factor μ the cz can be calculated using the rouse formula rouse 1961 9 c z c a z h z a a h r where r ws κu called the rouse number κ von kármán constant κ 0 4 u shear velocity and ca reference concentration at a reference level z a 0 05 h in sisyphe for predicting bed load the following formulas as proposed by van rijn 1984 are given by 10 q b τ 3 0 053 s 1 g d 50 τ 3 2 d 0 3 11 q b τ 3 0 1 s 1 g d 50 τ 3 2 d 0 3 where 12 d d 50 ρ s ρ g ρ υ 2 τ u 2 u 2 c r u 2 c r in the above qb bed load transport rate s relative density d particle parameter u cr critical shear velocity τ nondimensional excess bed shear stress ρ mass density of water ρs mass density of sediment and υ coefficient of kinematic viscosity the phenomena of sediment transport mainly depends on the interaction between water flow and the sediment bed type sediment bed roughness and sediment size the flow over dam crest and downstream dam slope changes its characteristics from subcritical to supercritical causing a hydraulic jump in the middle the flow just after the hydraulic jump creates some turbulent characteristics the transport of the sediment particles by rolling sliding and saltating modes depends on these characteristics of flow which can be calculated from the bed shear stress if the shear velocity just exceeds its critical value in critical flow depth condition the particle starts to move by rolling or sliding the particles move along the bed by saltation when that excess shear velocity increases this exceedance of shear velocity was taken into account in the eq 6 for calculating the sediment transport rate qb in terms of nondimensional excess bed shear stress τ eqs 10 12 2 3 integrated numerical scheme the numerical flow model telemac 2d provides the user the flexibility to modify the set of fortran sub routines to meet the specific requirements of each different model specification of initial conditions or complex boundary conditions linkups with other modelling systems and introduction of new functions the model accepts input files containing the mesh and bathymetry as binary files the boundary conditions ascii file and the steering parameters ascii file the steering parameters include information on the input output filenames the time step the friction and viscosity formulations adopted and the solver used for the computation the information contained in the different input files is generally produced by using user friendly preprocessors the numerical flow model computations were initiated first which computed the hydrodynamic parameters velocity discharge flow depth assuming a fixed bed over the discretized flow domain unstructured triangular mesh at a set of given initial condition for the first simulation time step the resulting hydrodynamic parameters were then exported to sisyphe where the bed load and bed elevation changes were calculated the new bottom bathymetry so computed was passed back to the flow model as the bottom geometry condition for the next time step and the processes were repeated till the end of the simulation time the results produced by the numerical model were stored in a binary file module named selafin format the final results were treated by the post processing software blue kenue nrc che 2010 which produced the graphical outputs and computation statistics 3 experiments in laboratory flume and numerical simulations in order to validate the erosion process of a dam by overtopping laboratory experiments with physical models were carried out in one of the glass sided hydraulic flumes at the hydraulic and water resources laboratory indian institute of technology kharagpur india the schematic diagram of the full experimental setup is shown in fig 3 the dimensions of the flume are 0 3 m wide and 4 m long with an effective length of 3 5 m the shape of the earthen dam used here to represent a moraine dam was considered trapezoidal with a flat crest the side slopes of the dam were kept as 2 h 1 v on both upstream and downstream while other geometric measurements of dam wdc wdb lu s were kept variable in each experiment as stated in table 1 it may be noted that the volume of lake lv behind the dam is a function of lu s all the experiments were started with a tail water level of 0 04 m with the application of a constant flow from the upstream the dam was placed at a length lu s table 1 from the inlet of the water source which was controlled by a valve uniformly graded sediment of two types s1 and s2 were used to prepare the model dam in the flume another type of dam built with mixed sediments sm was used to achieve the composition of natural moraine dam the case study glacial lakes and glacial lake outburst floods in nepal by icimod based on a field survey to the tsho rolpa moraine dam in nepal reported the following data for the dam d 30 1 4 mm d 90 300 600 mm and d 50 10 mm for the model experiments in the present study the sediment mixture sm was prepared by mixing of three types of sand and the grain size distribution is presented in fig 3 the median size of sediment d 50 mixture sm s1 and s2 type sediments were 1 22 mm 1 7 mm and 1 0 mm respectively in the experiments the water behind the dam was impounded with a constant discharge from the upstream end of flume the inlet discharge was controlled with inlet valve and the discharge was measured using an ultrasound electronic deviceportaflow 330 micronics ltd 2010 having an accuracy 6 during the time of dam failure the outlet discharge was measured with the help of a constant area reservoir at the downstream of flume where the rise in water level was recorded with time one video camera was used to capture the breach or dam failure profiles from right side of the flume table 1 illustrates the details of all the experimental conditions and the composition of the dam body a schematic diagram of the dam section as used in the experimental model is presented in the inset view of fig 4 the experimental flume setup was replicated by a rectangular channel section with horizontal bed 30 cm width and 350 cm length for numerical simulation fig 5 illustrates the bottom bathymetry of the domain for numerical simulation containing 4816 nodes and 9000 elements and constructed with the open source gridding software tool blue kenue all the experiments detailed in table 1 were simulated numerically keeping the same conditions as in experimental cases in case of model calibration different laws of bottom friction chézy and strickler were tested to a range of friction coefficient values found in literature horritt and bates 2002 fernandes et al 2001 and finally the friction coefficient c 40 m1 2s was adopted as it provided the best result only for bottom friction coefficient calibration a set of four simulation runs c 30 40 60 and 80 m1 2s were carried out for each of the different experiment test cases i ii iii and iv the kinematic viscosity of the fluid was considered as 10 6 m2s 1 moreover the model was tested for solver option with six variations of gradient method with finally the conjugate gradient on a normal equation being finalized as it showed an accuracy of 10 4 for this numerical model there was no need to calibrate the threshold shear stress θc in fact in the present study the critical shear stress and critical velocity for erosion and deposition was controlled by the value of the shields parameter θ which was finally set to 0 047 the simulation comprises of the sloping effects on sediment transport and therefore the direct effects of gravity on sediment particles on a sloping channel or riverbed was also considered by using the koch and flokstra s 1981 approach for magnitude and the talmon 1992 approach for direction the optimum time step δt in the numerical simulations for each iteration was found to be δt 0 01 s hydrodynamic model and δt 1 s sediment transport model to maintain the courant condition and considering the grid spacing size 4 results and discussion 4 1 comparison of numerical and physical experimental model results 4 1 1 dam morphology the numerical results are compared with the experimental data discharge recorded at 3 5 m downstream of the flume inlet for evaluating the performance of the numerical model the brier skill score bss was calculated which is defined as sutherland et al 2004 van rijn et al 2003 13 bss 1 mse y x mse b x 14 mse y x 1 i i 1 n y i x i 15 mse b x 1 i i 1 n b i x i where mse mean square error y and x numerically simulated and experimentally observed data respectively i number of spatial grid n total number of the grids or nodes and b baseline prediction data in the present study the baseline prediction for the final bathymetry used in morphological modelling is equal to the initial bathymetry assuming that the bed does not alter the bss score may be treated as a measure of model skill gerritsen et al 2011 ganju et al 2011 dam et al 2015 because it essentially compares the numerical simulation results to a baseline prediction a perfect matching suggests bss 1 whereas modelling the baseline condition gives bss 0 according to sutherland et al 2004 bss value greater than 0 6 can be considered as good and 0 2 bss 0 6 as fair the numerical simulation model reproduced the overall breaching process of all the cases tested and at all times except at the initial moments with a good accuracy overall the bss values were found to improve as the simulation progressed table 2 results at t 8 s showed a slight discrepancy in the dam top retreat and toe erosion but a good estimate of bed evolution was observed at further time steps 4 1 2 comparison of water levels and breach hydrographs fig 6 shows the morphological changes of dam during the breaching process the changes were compared with the experimental data for the test case i here at t 8 s it was observed that the morphological profile of numerical simulation shows a bad matching with the experimental profile which is also reflected by a poor bss value for all other time steps the numerical results were found to provide an overestimation of the bed elevation this observation was directly compared with the experimental data conversely at t 28 s it is observed that both numerically simulated and laboratory experimental results show similar results providing the best accuracy for the model the dam breaching advancements in numerical model for all the nine test cases are presented in fig 7 the effect of dam height in breaching advancement may be clearly seen by comparing test cases v and vi when the dam height was higher than the other the initial erosion or breaching rate was also more in test v than vi similarly in test cases iv and v when the lake volume behind the dam increases test iv the erosion process is found to be faster than the other fig 8 compares the numerically simulated and experimentally measured flow profiles free surface profiles over the dam for test case i at different time instances t 8 s 16 s 28 s 40 s 88 s and 120 s at t 8 s and t 16 s the numerical model appears to slightly overestimate but at t 28 s it matches perfectly with the experimental data whereas at other three time steps it shows a good matching with the experimental results the images of physical experiment at different times are presented in fig 8 b and can be therefore visualized as in the actual dam breach by comparing with the graphical plots fig 8 a the hydrograph resulting from the erosional collapse of the dam for all the nine test cases are shown in fig 9 it is apparent that in all the cases the numerical model results are in a good match with the experimental model results and the most perfect match occurs for the test case iii here the peak unit discharge qp m3 s per m width can be related to the dam breaching process in the comparison for test cases iv and v the former reached a higher peak than the latter the dam erosion advancement process was also faster in test iv than in test v fig 9 similarly while comparing between test cases v and vi it is clearly visible that for a greater dam height test v the peak discharge was also higher than other having a lower height of the dam test vi for some tests e g tests iii and iv the oscillations of the experimental and numerical results are evident to be nearly the same at the time of peak discharge during the time of breaching the entire ponded water gets released due to the erosion of the dam and together with the base flow results in a highly unsteady flow simulation and fluctuations between subcritical and supercritical flow regimes reflecting instabilities of flow after hydraulic jump which too is unsteady to explain further it can be said that when water flows over the downstream slope of the dam and reaches the channel bed the hydraulic jump occurs where it meets the slower moving water on the downstream as the dam erodes the supercritical flow taking place over its eroded surface fluctuates with time resulting in an unsteady hydraulic jump the oscillations were captured by the numerical model due to this fluctuating hydraulic jump at the location of the hydraulic jump the flow characteristics actually do not follow shallow water equations on which the present numerical model calculates the flow parameters the oscillations are also reflected in fig 10 d between time t 17 s and t 40 s for 1 5 fr 2 2 in these test cases tests iii and iv the calibration of model parameters related to flow was carried out somewhat more precisely resulting in nearly perfect matching between the curves of experimental and numerical results in both amplitude and phase 4 1 3 hydrodynamics and erosion phenomena the contour plots of velocity in channel downstream direction bed elevation change bed shear stress and froude number fr at a longitudinal section y 0 05 m for the test case i are presented in fig 10 in this test case the embankment was positioned at a distance from inlet x 2 4 m to x 3 m with the dam crest at x 2 65 m to x 2 75 m the water flow reached a maximum velocity dark red region fig 10 a at the top of the dam and along the downstream slope between times t 10 s and t 30 s the contours of velocity fig 10 a and bed shear stress fig 10 b show similar trends at all time instances along with their different range of values when the flow velocity increases the bed shear stress also becomes greater however when the flow velocity just exceeds its critical value for the sediment motion according to eq 12 it starts to develop an excess bed shear stress τ in eq 12 acting on the sediment particles which acts as the main cause of initiating erosion of the particles thus it is observed that at t 10 s the erosion of dam fig 10 c starts and till t 40 s increases at a rapid rate with the flow velocity and bed shear stress reaching their peaks however at times t 40 s the flow velocity reduces which results not much erosion except some transportation of the eroded sediments the maximum erosion or breaching of the dam occurs before time t 40 s which is also reflected in fig 6 almost 50 of erosion occurs before t 40 s after time t 40 s only when flow velocity values rise to within 0 52 m s and 0 45 m s and the bed shear stress ranges between 0 80 pa and 0 52 pa that the erosion occurs due to supercritical flow condition resulting from the very small flow depths which reflects in the contours of froude number supercritical flow with fr 1 is shown as yellow shaded zone in fig 10 d the green shaded zone in the same figure represents the froude number range between 1 10 and 0 80 which indicate the occurrence of critical flow over the dam crest and along the downstream slope therefore it is observed that the critical flow velocity lies between 0 47 m s and 0 35 m s yellow shaded zone fig 10 a for test case i in fig 10 c the negative values purple blue and green colored zones indicate erosion and the positive values different shades of the red colored zone represent deposition of the eroded sediments at a time t 10 s from the start of overtopping it is observed that the dam located between x 2 70 m and x 2 80 m from the inlet starts eroding and the eroded sediments deposit after some distance ahead at x 2 9 m when the flow continues to increase with time the erosion also grows faster due to the increasing flow velocity and the eroded sediments transport downstream beyond the dam and finally are deposited between x 2 9 m and x 3 3 m as expected the deposition of the eroded sediments occurs when the flow velocity reaches below the critical value immediately after the hydraulic jump as reflected in the green to the blue colored zone of the velocity contour plot fig 10 a for all test cases the results appear to be quite satisfactory with the bss value ranging between 0 75 and 0 98 at t 8 s from the initiation of dam overtopping the sediment erosion rate as computed by numerical simulations observed to be quite high resulting in a low range of bss value 0 3 0 6 table 2 the majority of the erosion occurs just after the initial overtopping and generates a flood peak which is higher than the average steady inflow figs 8 and 9 almost 80 of the total dam erosion and 50 of dam height reduction occurs by about t 40 s fig 8 and beyond t 40 s the flow continues to transport the eroded dam material towards the channel downstream depositing them at some length it is found that the flood peak is almost 150 higher than the steady inflow rate of discharge for all the nine test cases the erosion breaching process of a dam is directly proportional to a function of the flow velocity over the dam being related to the bed shear stress eqs 10 12 and flow characteristics like froude number fig 10 d these parameters viz flow velocity bed shear stress and froude number are inter related and are responsible for causing the change of bed elevation and breaching of the dam fig 10 4 1 4 sensitivity analysis sensitivity analysis of the numerical model was performed for determining the important parameters which need to be precisely estimated for making accurate prediction of breached outflow hydrographs resulting from dam erosion this task was carried out by using the local sensitivity analysis technique one factor at a time ofat oat where the numerical model was run repeatedly by varying each input parameter of the six table 3 one at a time within a prescribed range while keeping the others as constant the resulting hydrograph and peak discharge values were analyzed to determine the absolute sensitivity coefficient sc and normalized sensitivity coefficient sn which provide a measure of the sensitivity table 4 sc and sn for each parameter were calculated as follows sattar and gharabaghi 2015 16 s c 1 p o p i 17 s n s c p im p om where po output parameter pi input parameter pim mean value of pi and pom output parameter when po pim fig 11 shows the effects of these parameters based on the changes of peak value for the outflow flood hydrograph while varying a parameter the others being kept constant it is observed from the analysis that the height of the dam appears to be the most sensitive of all the six parameters in affecting the peak of the resulting flood hydrograph the next two most influential parameters are found to be the lake volume and inlet flows the top width of the dam and the porosity of the dam material are relatively less sensitive while the median size of dam material d 50 is the least sensitive of all this study therefore shows that for predicting a glof hydrograph the most important three parameters to be taken into consideration are moraine dam height volume of lake behind dam and the inflow discharge rate to the lake in comparison it may be noted that dike height was also identified to be a sensitive parameter by schmocker and hager 2012 for the process of a dyke breach evidently dyke breach is not exactly comparable to the present case as a dyke runs parallel to a flowing body of water while a dam as in this case is a barrier across the flow path nevertheless schmocker et al 2014 also identified the median size of sediment d 50 forming the dyke as sensitive 4 2 case studies some researchers simulated the breaching of a moraine dam and lake drainage using numerical models such as bajracharya et al 2007 xin et al 2008 and shrestha et al 2013 who applied the model breach fread 1988 to cases in the himalayan nepal and tibet regions osti and egashira 2009 simulated the outflow glof hydrograph in a lake of himalayan region using hec ras whereas worni et al 2014 simulated the evolution of a moraine dam breach and generation of glof hydrograph using the model basement in a lake of peru in this section the model telemac 2d and sisyphe were employed in modelling the breach evolution of a landslide dam that formed on the jianjiang river in china on 12th may 2008 although such a dam is formed by the sudden deposition of hill slope materials bordering a river valley instigated by a landslide and temporarily blocking the flow of the river its subsequent washout and generation of flood hydrograph is quite similar to that of a moraine dam the particular incident considered here known as the tangjiashan landslide dam failure was reported extensively with well documented data fan et al 2012 bo et al 2015 kidyaeva et al 2017 this case was chosen here to validate the predictive capability of the present numerical model on a field scale further although the numerically coupled model of telemac 2d and sisyphe was validated with two dimensional laboratory experiments it remained to be proved whether the model is capable of simulating a three dimensional phenomena equally well it is unfortunate that observational data of moraine dams especially quantitative measurements of the flood hydrograph resulting from its breaching is not commonly reported in literature of course this may naturally be expected given that most of the moraine dams are in very remote locations and there is virtually no prior indication to the time of a moraine dam collapse hence it is not practically possible to set up a monitoring infrastructure to capture the various flow parameters during the failure of a moraine dam however it is quite possible to pre simulate such a failure given the data on its physical properties and river flow characteristics providing a before hand indication of the localities or infrastructure that may be affected if the dam eventually fails of the several moraine dam lakes in the indian himalayas the lhonak lake is considered to be in a vulnerable state of existence and may collapse if a sufficiently high trigger like a heavy rainfall or a strong earthquake occurs as a second case study a simulated washout of the lhonak dam is presented here with predictions of consequent flood hydrographs which it is hoped would provide a prior cautionary advice to the population of the area in case of the dam breach in fact the hydrograph may be run in conjunction with a flood routing model to predict the possible extents of inundation in case of the dam s failure this would aid the authorities in charge of the safety and security of the local population in planning developments along the river judiciously 4 2 1 tangjiashan landslide dam breaching and flood hydrograph simulation the tangjiashan landslide dam incident occurred at location 31 50 33 n and 104 25 47 e almost 5 km upstream of the town of beichuan in the sichuan province of china the landslide due to the wenchuan earthquake blocked the jianjiang river and formed the tangjiashan barrier lake of about 3 108 m3in volume with flows reaching from the upstream catchment area of around 3550 km2 fan et al 2012 the jianjiang river is mainly rain fed river and according to the records of the hydraulic station at beichuan the average annual flow of the river was 81 m3 s increasing up to167 m3 s at peak monsoon period the wenchuan earthquake was occurred on the 12th may of 2008 and from the historical flood records it is found that the most of the extreme rainstorms hit the region between june to september and caused high floods with peak discharges of 1180 2190 and 3040 m3 s corresponding to 1 5 and 10 years return periods respectively in 2008 the wenchuan and tangjiashan area experienced a heavy rainstorm situation and extreme inflow discharges filled the lake rapidly creating a high risk of overtopping failure of the dam and consequent flooding on the downstream under this situation the chinese government constructed a large emergency spillway in the dam as a mitigation measure from the literature the detailed measurements of spillway fan et al 2012 as well as measurements of dam bo et al 2015 were noted for recreating the surface profile of the dam section in telemac 2d for generating the bathymetry of the lake section which was required as input to the numerical model the topographic information was derived from the satellite digital elevation model dem srtm data set using the gis software arc gis the simulation of the dam breaching process and consequent flood generation were carried out for a 3 day time period from 7th to 10th june 2008 and the peak flood was found to occur on 10th june for the present study the model was tested with 2190 m3 s discharge as the inflow to the lake representing the heavy rainstorm situation the simulation results reflect a satisfactory match of the computed flood hydrograph with the observed and that simulated by fan et al 2012 in order to obtain a good match in the practical case calibrations were done for two parameters in the present study the combination of dam material and porosity of dam in the simulation of telemac 2d the final type of dam material that was considered to comprise of a combination of five classes of sediment 10 having d 50 600 mm 5 having d 50 300 mm 60 having d 50 100 mm 10 having d 50 50 mm and 15 having d 50 5 mm having a combined porosity of 20 all other model parameter values used for this real field case were kept same as those used to simulate the experiments in laboratory scale certainly in the physical laboratory model and numerical model attempts have been made to match the physical phenomena of the dam erosion and failure by considering the flow resistances in cohesion less uniformly and nonuniformly graded sediments even though the laboratory physical model was much smaller than that of the practical case study the flow resistances could be handled only by changing the two parameters the type of dam material combination of mixed type sediment and the porosity of sediment although in practical case the dam material can probably never be absolutely cohesion less such the model was considered here for simplicity in handling the flow resistance terms the resulting hydrograph is illustrated in fig 12 it is observed that telemac 2d simulation overestimates the flood peak almost by 12 from the observed peak whereas in comparison the simulated results of fan et al 2012 using the breach model overestimates the flood peak by around 8 moreover according to the present model the simulated time to peak of the flood hydrograph was also predicted quite early 7 h before than observed besides the flood hydrograph appears to match well with the observed result the reasonably satisfactory results thus obtained may be considered as a satisfactory practical field validation of the numerical simulation model considered for the study 4 2 2 south lhonak lake outburst and glof hydrograph prediction south lhonak lake is located at the toe of south lhonak glacier at 27 54 45 n and 88 11 46 e in the extreme north western corner of the sikkim himalayas of india south lhonak glacier is the main parent glacier of the lake it is also fed by the north lhonak glacier as shown in the fig 13 the lake water level is 5208 m from mean sea level msl and the north face of the lake is extensively nourished by avalanches falling off this rock face the areal expansion process of the south lhonak lake was analyzed based on a series of satellite images fig 14 shows the areal change of the lake with time according to the satellite image landsat 7 of 2005 the area covered by the lake was nearly 0 794 km2 which increased to 1 286 km2 in 2015 computations reveal that the areal expansion rate of the lake was 0 0468 km2 year over the five years of 2005 to 2010 and 0 0516 km2 year for the next five years from 2010 to 2015 indicating high potentiality to cause a glof a field survey was carried out by the national mission for sustaining the himalayan eco system nmshe in 2014 and a bathymetric map for south lhonak glacial lake was prepared as it was not possible to obtain all required data from this report the dem map was derived from srtm data set using the gis software package arc gis the erosional wash out of the moraine dam was simulated with the model combination of telemac 2d and sisyphe considering a constant inflow of 30 m3 s the simulation was initialized with the lake water level assumed at 5208 m msl the bathymetry of the lake is shown in the fig 15 for maintaining the flow resistances the dam material size and porosity were calibrated again for these data and input as a combination of mixed type sediment of four classes with an overall porosity of 30 the hypothetical breaching of the dam and outburst of lhonak lake with geometries of the years 2005 2010 and 2015 were separately simulated and the resulting glof hydrographs are presented in fig 16 it is observed that the initiation of the breach took some time to occur and then the pattern of rising limb of the breach hydrograph was almost the same for each year but the peak discharge of floods differed the peak of the flood hydrograph can be related to the area of the lake because it is observed that when the lake area was the maximum 1 286 km2 in 2015 the flood peak also indicated to be the maximum value 117 m3 s similar results were also reported by worni et al 2014 for glof hydrograph obtained using the model basement from the ventisquero negro lake argentina 5 conclusions this study attempts to analyze the erosion based moraine dam failure caused by overtopping and to estimate the predicted outflow flood hydrograph through simulations with 2d numerically coupled model for flow and sediment motion the results are verified with a series of laboratory flume physical experiments comparisons of the experimental values with the numerical results appear to be reasonably good for the bed elevation changes and the evolution of the flow profiles the physical dam breaching erosion processes are also satisfactorily correlated with the hydrodynamic phenomena when the flow characteristics change from subcritical to supercritical flow resulting in a hydraulic jump at a downstream location this is confirmed with the help of contour plots of velocity bed shear stress froude number and change of bed elevation of the dam section at all times additionally the model was used to assess the sensitivity effects of the various parameters such as particle size of moraine dam porosity of dam material dam crest width dam height and lake volume on the prediction of the outflow hydrograph resulting from the dam erosion process the numerical simulations were also validated with the field data of a failure event of a landslide dam proving the applicability of the 2d model to general 3d phenomena at field scale the model was then used to predict the probable flood hydrograph that may be expected to be generated if lhonak lake one of the most threatened moraine dams of the himalayas fails in the present numerical model however some discrepancies in bed elevation changes were noticed particularly at the location of the top of just downstream the crest it might be attributed to the effects of dam material cohesion and 3d flow structures present for the physical experiments being not considered in the numerical model moreover the transient turbulence effects were not considered in this model though it may not be realistic in dealing with the conditions of the physical experiments a 3d numerical model including sophisticated turbulence models as well as the downstream dam slope effect related to the angle of repose of dam material might provide better results in spite of these limitations it is expected that the methodology as illustrated in this study for numerical simulation of moraine dams may prove to be useful for application to practical field studies in future 
7169,although umpteen studies are available in the hydrologic literature for modeling the contaminant transports under steady flow conditions similar trend is not seen while modeling this process under unsteady flow conditions and thereby limiting their field application for pollution monitoring in semi gauged rivers in this study three simple model variants namely vpmm ad ψdc vpmm ad φdf and vpmm ad dc were developed for unsteady state contaminant routing by tight coupling the physically based variable parameter mccarthy muskingum vpmm flow transport sub model with the advection dispersion ad contaminant transport sub model these model variants were extensively tested under unsteady and steady flow conditions using the numerical experiments and usgs laboratory and real world river application datasets considering the popular mike11 ad model as the benchmark the study results revealed the consistent superior performance of the vpmm ad ψdc and vpmm ad φdf model variants over the benchmark model the developed approach is a novel one as it is fully physically based free from numerical stability problem as the governing equations are solved iteratively can work at meso scale with the same computational space and time steps in the flow and solute routings compatible with the spatiotemporal scales of observation very simple to use and do not compromise with the routing accuracy as encountered in the benchmark hydrodynamic model even with a fully implicit finite difference scheme keywords advection dispersion contaminant transport flow routing pollution river vpmm ad 1 introduction for pollution monitoring at different spatiotemporal scales as well as to dispose wastewater into the river within its self purification capacity level modeling the transport characteristics of the contaminants in the river becomes essential most of the literature deals with the steady state contaminant transports using the advection dispersion ad model komatsu et al 1997 zoppou and knight 1997 koussis and rodriguez mirasol 1998 the ad equation is solved with long tails of concentration time c t curves using the concepts of transient storage chapra and wilcock 2000 lin and medina 2003 gooseff et al 2007 jin et al 2009 jackson et al 2013 dead zone storage czernuszenko et al 1998 one dimensional transport with inflow and storage runkel 1998 hybrid cells in series ghosh et al 2004 and other approaches seo and cheong 1998 koussis and rodriguez mirasol 1998 singh 2003 ramaswami et al 2005 fant and dortch 2007 kazezyilmaz alhan 2008 deng and jung 2009 neumann et al 2011 moghaddam et al 2017 however contaminant transports in nature mostly occur under unsteady flow conditions zhang and aral 2004 which further increase the complexity of numerical solutions of the governing equations gabriele and perkins 1997 runkel et al 1998 camacho 2000 prasad 2002 deng and jung 2009 although the river flow data is generally available relatively at closer spatiotemporal resolutions the availability of corresponding contaminant concentrations is very limited even in the well instrumented river basins with the advent of remote sensing rs based approaches it becomes feasible now a days to assess the daily scale concentrations of the non reactive riverine contaminants at 30 m 1 km spatial resolutions with better accuracy e g swain and sahoo 2017a b similarly rs based discharge measurements are going to be the next generation of research in applied hydrology e g tarpanelli et al 2013 to use these rs data products in the hydrological models there is a need to develop coupled flow and solute routing models operable at meso scale the scale of remote sensing observations in river hydrology dooge 1986 defined meso scale as the spatial resolution of 1 100 km however many of the existing flow and contaminant transport models cannot be used for meso scale river application due to the inherent numerical problems and excess computational load involved with the solutions of the governing equations at larger computational space and time steps further for ungauged or semi gauged rivers and climate change impact assessment studies these existing micro and mini scale models are of limited use due to the large field data requirement and their copious dependency on calibration sivapalan et al 2003 moreover while operating the existing fine scale ad models at meso scales solved with unconditionally stable fully implicit finite difference scheme it may result in inaccurate routing solution therefore the specific research gaps in many of the existing approaches are i lack of clear distinction between different flow and contaminant transport residence times and propagation velocities ii complexity in unifying the governing flow and contaminant transport equations because of the separate numerical schemes involved in solving these two processes iii not dealing with flow and contaminant transports in ungauged or poorly gauged rivers and iv numerical stability problem in modeling the contaminant transport at larger temporal and spatial scales compatible with the solicited information for river water quantity and quality monitoring this necessitates for advocating a simple physically based and embedded flow and contaminant transport model which can be used in ungauged or poorly gauged river basins and could be applied at relatively coarser spatiotemporal scales attuned with the observed scales of remote sensing based flow and contaminant concentrations among the variants of flow transport models amenable to be used at coarser spatiotemporal scales the variable parameter muskingum cunge vpmc model ponce and chaganti 1994 which shows mass conservation problem is extensively used tang et al 1999 perumal and sahoo 2007 2008 subsequently more mass conservative models viz variable parameter muskingum discharge routing method perumal 1994a b sahoo et al 2014 variable parameter muskingum stage routing method perumal et al 2007 2010 muskingum cunge todini method todini 2007 and variable parameter muskingum price method price 2009 have been developed the historical perspective of the physical interpretations of these variants of the muskingum flow transport models are given by perumal et al 2015 conversely the variable parameter mccarthy muskingum vpmm routing model perumal and price 2013 derived from the approximation of the full saint venant equations is a simplified physically distributed and fully mass conservative swain and sahoo 2015 the vpmm model has the ability to route flow in the ungauged or poorly gauged rivers at coarser spatiotemporal scales therefore this study attempts to answer the research questions i can the advection dispersion ad equation be modified suitably to be embedded tightly with the vpmm model derived from the saint venant equations of continuity and momentum for simulating the flow and conservative contaminant transports simultaneously using the same routing space and time steps for both the processes which is compatible with the spatiotemporal resolution of the observed flow and contaminant concentration data ii how does this developed model perform in numerical experiments and the usgs laboratory and real world river applications under both steady and unsteady flow conditions in comparison with the popular mike11 ad model danish hydraulic institute dhi 2014 considered as the benchmark and iii how does the routing accuracy of the vpmm ad model vary if applied at meso scale the paper is organized as follows section 2 presents the development of the vpmm ad embedded model variants accounting for different approaches to estimate the coefficient of longitudinal dispersion section 3 presents the framework of the benchmark mike11 ad model section 4 explains the performance evaluation measures in calibrating and validating the model variants section 5 describes the model verification details and section 6 presents the conclusions of this study 2 development of the vpmm ad embedded model for flow contaminant transports 2 1 vpmm sub model for flow transport the convection diffusion equation hayami 1951 improved by approximately accounting for inertial forces for describing the one dimensional 1 d gradually varied flow transport in prismatic channels dooge 1973 and accounting for lateral flow can be given by 1 q t ε q x d f 2 q x 2 d q l dx where q unsteady discharge ε celerity of unsteady flow dql dx ql lateral flow contribution per unit reach length x space variable t time variable and df diffusion coefficient of flow transport defined as 2 d f q 0 2 s 0 b 1 n v 2 where q 0 reference discharge s 0 river bed slope b top width of flow corresponding to q 0 and nv vedernikov number chow 1959 expressed as 3 n v 2 f 3 p b dr dy 2 3 1 r dp da f in which f froude number a area of flow section p wetted perimeter of flow section r hydraulic mean radius and y unsteady state flow depth the reference discharge q 0 normal velocity vo and normal celerity εo are the unique functions of flow depth y and the corresponding unsteady discharge q unsteady velocity v and unsteady celerity ε are the functions of both y and y x the longitudinal gradient of the water surface using the binomial series expansion one can obtain perumal and price 2013 4 q 0 q v 0 v ε 0 ε s f s 0 0 5 1 1 s 0 y x 1 n v 2 0 5 1 0 5 b ε s 0 q x 1 n v 2 where sf energy slope of the unsteady flow defined by the saint venant s momentum equation y x q x bε and y x s o 1 using eq 4 the saint venant s continuity equation considering lateral flow per unit width q l can be written as 5 t q 0 v 0 q x q l where q 0 v 0 q v a using eq 4 in 5 one can obtain the combined form of the saint venant s continuity and momentum equations accounting for the presence of lateral flow as swain and sahoo 2015 6 t q v o 0 5 q o b ε o s o q x 1 n v 2 q x q l using eq 2 in 6 one can obtain 7 t q v o d f ε o q x q x q l the finite difference equivalent of eq 7 can be obtained by applying it at the centre point of the box grid scheme with space step of δx and time step of δt fig 1 as 8 1 δ t q v o d f ε o q x i 1 2 j 1 q v o d f ε o q x i 1 2 j q i 1 2 j 1 2 x q l i 1 2 j 1 2 where 9a q i 1 2 j 1 0 5 q i j 1 q i 1 j 1 9b q i 1 2 j 0 5 q i j q i 1 j 9c q i 1 2 j 1 2 x q i 1 j 1 2 q i j 1 2 δ x 0 5 δ x q i 1 j 1 q i 1 j q i j 1 q i j 9d q l i 1 2 j 1 2 0 5 q l i 1 2 j 1 q l i 1 2 j 0 5 δ x q l j 1 q l j where ql total lateral flow contributed to the river reach at each δx grid scale using eqs 9a 9d in 8 and rearranging the resulting equation one obtains 10 q i 1 j 1 0 5 δ t k f j 1 θ f j 1 0 5 δ t k f j 1 1 θ f j 1 q i j 1 0 5 δ t k f j θ f j 0 5 δ t k f j 1 1 θ f j 1 q i j 0 5 δ t k f j 1 θ f j 0 5 δ t k f j 1 1 θ f j 1 q i 1 j 0 5 δ t 0 5 δ t k f j 1 1 θ f j 1 q l j 1 q l j where 11a k f j 1 δ x v o i 1 2 j 1 11b k f j δ x v o i 1 2 j 11c θ f j 1 1 2 1 δ x d f ε 0 i 1 2 j 1 11d θ f j 1 2 1 δ x d f ε 0 i 1 2 j corresponding to the routed outflow q i 1 j 1 obtained at the centre of the space state computational grid in fig 1 the flow depth y i 1 j 1 can be estimated using the backward difference scheme as 12 y i 1 j 1 y i 1 2 j 1 q i 1 j 1 q i 1 2 j 1 b i 1 2 j 1 ε i 1 2 j 1 y i 1 2 j 1 q i 1 j 1 0 5 q i j 1 q i 1 j 1 b i 1 2 j 1 ε i 1 2 j 1 in which y i 1 2 j 1 can be obtained by the nonlinear newton raphson optimization method iteratively using the normal discharge relationship given by 13 1 n a i 1 2 j 1 r i 1 2 j 1 s o 0 5 θ f j 1 q i j 1 1 θ f j 1 q i 1 j 1 where n manning s roughness coefficient hence the solution of eq 1 can also be represented by eq 10 2 2 development of vpmm ad embedded model for unsteady flow the non conservative form of the ad model governing the non reactive contaminant transport process in rivers with uniform cross section is given by runkel 1998 14 c t v c x d c 2 c x 2 where c contaminant concentration and dc longitudinal dispersion coefficient eq 14 can also be written in conservative form accounting for lateral contaminant mass qc l as 15 qc t v qc x d c 2 qc x 2 d qc l d x since the form of eq 15 is similar to eq 1 the governing equation of the vpmm ad embedded model for contaminant transport in unsteady flow including lateral contaminant transport can be considered to be similar to eq 10 which is given by 16 qc i 1 j 1 0 5 δ t k c j 1 θ c j 1 0 5 δ t k c j 1 1 θ c j 1 qc i j 1 0 5 δ t k c j θ c j 0 5 δ t k c j 1 1 θ c j 1 qc i j 0 5 δ t k c j 1 θ c j 0 5 δ t k c j 1 1 θ c j 1 qc i 1 j 0 5 δ t 0 5 δ t k c j 1 1 θ c j 1 qc l j 1 qc l j that is 17 c i 1 j 1 0 5 δ t k c j 1 θ c j 1 0 5 δ t k c j 1 1 θ c j 1 qc i j 1 q i 1 j 1 0 5 δ t k c j θ c j 0 5 δ t k c j 1 1 θ c j 1 qc i j q i 1 j 1 0 5 δ t k c j 1 θ c j 0 5 δ t k c j 1 1 θ c j 1 qc i 1 j q i 1 j 1 0 5 δ t 0 5 δ t k c j 1 1 θ c j 1 qc l j 1 qc l j q i 1 j 1 where 18a k c δ x v 0 k f 18b θ c 1 2 1 δ x d c ε 0 and the unsteady flow q i 1 j 1 can be estimated by using eq 10 2 3 evaluation of dispersion coefficient dc 2 3 1 relational constant ϕ based vpmm ad ϕdf model in the vpmm ad ϕdf method the dispersion coefficient dc mainly depends on both the flow and channel characteristics and hence related with the flow diffusion df as mcquivey and keefer 1974 seo and cheong 1998 19 d c ϕ d f where ϕ is the relational constant that can be estimated by calibrating the concentration time c t curve for obtaining the maximum model efficiency 2 3 2 gene expression programming gep based vpmm ad dc model recently sattar and gharabaghi 2015 developed empirical relationships by applying the gene expression programming gep model for estimating the longitudinal dispersion coefficient in steady flow a total of 150 sets of published field data of tracer test including the geometric details of natural channels were used in developing the two gep models gep 1 gep 2 in which the gep 2 model was found to be the best and is given by 20 d c 8 45 y gr s 0 v 0 gr s 0 1 65 w y η where 21 η 0 5 0 514 f 0 516 v 0 v 0 0 42 v 0 v 0 and v 0 gr s 0 steady shear velocity of water g acceleration due to gravity r hydraulic mean radius and w average width of channel 2 3 3 relational constant ψ based vpmm ad ψdc model since the gep model in eq 20 developed by sattar and gharabaghi 2015 uses the datasets under steady flow conditions the dispersion coefficient of the vpmm ad model for unsteady flows can be estimated similar to eq 18 by multiplying a relational constant coefficient ψ as 22 d c 8 45 y ψ gr s 0 v 0 gr s 0 1 65 w y η the solution procedure of the vpmm ad model is illustrated in fig 2 3 mike11 ad the benchmark model the advection dispersion ad module in the mike11 ad model dhi 2014 solves the 1 d ad equation numerically using the 6 point abbott ionescu implicit finite difference scheme this ad module requires the discharge water level cross sectional area and hydraulic radius outputs from the hydrodynamic hd module that solves the full saint venant equations in time and space the governing equation of contaminant transport in mike11 ad is given by 23 ac t qc x a d c c x x akc c 2 d q l dx where dc αvβ dispersion coefficient α β calibration parameters k linear decay coefficient k 0 for conservative pollutants and c2 source sink concentration 4 performance evaluation measures in this study seven performance evaluation measures were used for assessing and quantifying the discharge flow depth and contaminant transport capability of the vpmm ad and mike11 ad models i nash sutcliffe criterion of model efficiency nash and sutcliffe 1970 for discharge nseq flow depth nsey and contaminant concentration nsec in estimated as nash sutcliffe coefficient 100 ii coefficient of determination for discharge r q 2 flow depth r y 2 and concentration r c 2 iii root mean square error for discharge rmseq flow depth rmsey and concentration rmsec iv index of agreement willmott 1982 for discharge ioaq flow depth ioay and concentration ioac v percentage error in peak flow qper peak flow depth yper peak concentration cper expressed as qper simulated peak flow observed peak flow 1 100 yper simulated peak flow depth observed peak flow depth 1 100 cper simulated peak concentration observed peak concentration 1 100 vi error in time to peak flow tpqer peak flow depth tpyer and peak concentration tpcer expressed as tpqer time to simulated peak flow time to observed peak flow tpyer time to simulated peak flow depth time to observed peak flow depth tpcer time to simulated peak concentration time to observed peak concentration and vii percentage error in flow volume evol and contaminant mass emass expressed as 24 evol i 1 m q out i δ t i 1 n q in i δ t 1 100 25 e mass i 1 m q out c out i δ t i 1 n q in c in i δ t 1 100 where qout and cout are the routed discharge and concentration respectively qin and cin are the inflow discharge and concentration respectively δt time interval and m number of time intervals in the timeseries 5 model verification 5 1 numerical experiments to test the applicability of the vpmm ad model numerical experiments were carried out by assuming that the inflow and the corresponding solute concentration follow the 4 parameter pearson type iii distribution given by 26 y x 0 t y b y p y b t t p 1 γ 1 e x p 1 t t p γ 1 27 c x 0 t c b c p c b t t p 1 γ 1 e x p 1 t t p γ 1 where yb and cb denote the initial stage yb 0 5 m and concentration cb 0 at time t 0 respectively yp and cp denote the peak stage 3 5 8 10 m and peak concentration 10 30 50 80 mg l respectively tp time to peak 10 15 20 h and γ shape factor 1 05 1 25 1 50 a wide range of 20 inflow discharge hydrographs were generated corresponding to the stage hydrographs in eq 26 in typical rectangular and trapezoidal channels using the manning s equation with five manning s roughness coefficients 0 02 0 03 0 04 0 05 0 06 and three bed slopes 0 0003 0 0006 0 0009 for routing by the vpmm ad method in which the mike11 ad solutions were considered as the benchmark the bottom widths of the rectangular and trapezoidal channels were kept constant at 50 m whereas the side slope of the trapezoidal channels were fixed at 2h 1v the discharge and concentration hydrographs were generated with the total routing reach length 50 km δx 1 km and δt 1 h the 20 number of benchmark mike11 ad solutions were generated with the dc values of 50 100 200 and 500 m2 s while calibrating the vpmm ad model the relational constant φ in eq 19 was found to be varied from 0 007 to 0 17 the performance evaluation measures for evaluating the vpmm ad and mike11 ad models for all the 20 mike11 ad solutions are shown in the box and whisker plots in fig 3 the corresponding solutions of discharge stage and solute concentration hydrographs for eight typical routing cases are illustrated in fig 4 it can be revealed from fig 4 that the mike11 ad solutions of discharge hydrographs were very well reproduced by the vpmm ad model for different combinations of synthetic inflow hydrographs manning s roughness coefficients and channel bed slopes the accuracy of these discharge reproductions can be envisaged from fig 3 with the mean inter quartile ranges of performance evaluation measures nseq 99 41 99 36 99 75 nsey 99 15 98 72 99 67 evol 0 25 0 47 to 0 1 r q 2 0 99 0 99 1 00 r y 2 0 99 0 99 1 00 rmseq 6 02 4 60 6 99 m3 s rmseq 0 09 0 07 0 11 m ioaq 99 86 99 84 99 94 ioay 99 79 99 68 99 92 qper 3 09 1 19 4 98 yper 3 91 1 18 5 23 tpyer 0 20 0 00 0 00 h and tpqer 0 25 0 47 to 0 10 h these results prove that the vpmm ad model performed very well in reproducing the mike11 ad solutions of discharge and flow depths similarly for reproducing the benchmark solute concentrations the vpmm ad φdf model performed very well with the mean inter quartile ranges of nsec 99 40 99 23 99 69 r c 2 1 00 0 99 1 00 rmsec 1 00 0 37 1 46 mg l ioac 99 85 99 81 99 92 cper 0 93 0 09 2 02 tpcer 0 10 0 00 0 00 h and emass 0 82 0 34 1 06 however the corresponding performance measures of the vpmm ad dc model were slightly inferior with nsec 85 33 81 69 90 11 r c 2 0 87 0 84 0 91 rmsec 4 86 2 49 7 36 mg l ioac 96 09 94 61 97 35 cper 0 58 4 22 to 4 35 tpcer 0 60 2 25 to 1 00 h and emass 0 57 0 54 to 1 40 while the performance of the vpmm ad ψdc model was again very good with nsec 98 80 98 61 99 47 r c 2 0 99 0 99 1 00 rmsec 1 32 0 75 2 01 mg l ioac 99 69 99 64 99 87 cper 0 56 1 74 to 0 73 tpcer 0 10 0 00 0 00 h and emass 0 71 0 05 to 1 30 these results reveal that the vpmm ad φdf and vpmm ad dc models performed almost equally the best since they could account for the unsteadiness in the flow and solute transports conversely the steady state approach based longitudinal dispersion coefficient decreased the performance of the vpmm ad dc model although it may not be discarded fully for its field use 5 2 laboratory scale steady state application the vpmm ad and mike11 ad models were verified using the laboratory scale flume based steady state usgs tracer test fischer 1966 data series 2600 and 2700 e g nordin and sabol 1974 this flume was of 40 m length 1 10 m width 0 00031 bed slope and 0 011 manning s roughness coefficient in which the conservative rhodamine wt tracer was used with an average flow velocity of 0 269 m s and flow depth of 0 069 m the observed concentration time c t curves for the usgs data series 2600 are available at 1 s resolution at four sections from the upstream end x 0 at x 7 06 m section 1 x 14 06 m section 2 x 21 06 m section 3 and x 28 06 m section 4 similarly for the usgs data series 2700 the tracer test was conducted with 0 000257 bed slope 0 01 manning s roughness coefficient 0 362 m s average flow velocity and 0 128 m flow depth the observed concentration time c t curves for this data series 2700 are available at two sections of x 0 section 1 and x 11 00 m section 2 for simulating these data series spatiotemporal computational steps of δx 1 0 m and δt 1 0 s were chosen for all the three variants of the vpmm ad and the mike11 ad models the reaches between sections 1 4 for data series 2600 and 1 2 for data series 2700 were considered for calibrating the dispersion relational parameters φ eq 19 and ψ eq 22 in the vpmm ad φdf and vpmm ad ψdc models to obtain the maximum nse value and also for calibrating the α and β eq 23 values of dispersion coefficient in the mike11 ad model for validation the observed c t curves at sections 2 and 3 for the data series 2600 were used the reproduction of all the c t curves by the vpmm ad and mike11 models are illustrated in fig 5 and the corresponding performance evaluation measures are shown in table 1 it can be envisaged from fig 5 that the vpmm ad ψdc model reproduced the observed c t curves consistently very well followed by the vpmm ad φdf vpmm ad dc and mike11 ad models table 1 reveals that for the data series 2600 the mean estimates of nsec r c 2 rmsec ioac cper tpcer and emass in reproducing the observed c t curves by the vpmm ad φdf approach were 98 01 0 98 1 27 μg l 99 50 0 63 0 08 h and 0 44 respectively whereas these estimates for the vpmm ad dc approach were 96 84 0 97 1 78 μg l 99 19 3 50 0 17 h and 0 24 respectively similarly these mean estimates for the vpmm ad ψdc and mike11 ad models were 99 39 0 99 0 76 μg l 99 85 0 63 0 00 h and 0 45 respectively and 93 20 0 93 2 43 μg l 98 13 11 08 0 25 h and 0 52 respectively these estimates reveal that the vpmm ad ψdc and vpmm ad φdf approaches performed the best almost equally followed by the vpmm ad dc and mike11 ad models the same inference can be drawn for the 2700 series dataset note that since one dataset is available for this data series 2700 only calibration was carried out 5 3 field application steady flow cases 5 3 1 monocacy river usa application to verify the efficacy of the vpmm ad and mike11 ad models under steady flow condition the rhodomine water tracing wt dye test nordin and sabol 1974 conducted in the monocacy river was used herein the measured steady flow discharges at four downstream sections of x 10 30 km x 18 30 km x 26 80 km and x 34 30 km from the upstream dye injection site x 0 as illustrated in fig 6 showing the index map of the monocacy river were 15 57 m3 s 15 15 m3 s 15 86 m3 s and 18 55 m3 s respectively and the corresponding manning s roughness values n at these sites were 0 004 0 070 0 045 and 0 020 respectively the 93 4 km long monocacy river a tributary of the potomac river is a non tidal free flowing stream that originates in pennsylvania having a basin area of about 1927 km2 this basin is constituted with the land uses of agriculture 45 forest 41 and urban area 14 the river runoff generally varies from 16 to 87 m3 s with significant nonpoint source pollutions contributed from farms livestock operations and dairies using eq 20 the steady state dispersion coefficients dc estimated at x 10 30 km x 18 30 km x 26 80 km and x 34 30 km were found to be 37 94 m2 s 38 49 m2 s and 47 80 m2 s respectively which were used directly in the vpmm ad dc method for both the vpmm ad and mike11 ad models a routing grid size of δx 1 km and δt 0 2 h was chosen however for the last grid δx 0 1 km was chosen to match with the location where the observed c t curves were available the reach between x 0 and x 34 3 km was considered for calibrating the vpmm ad φdf vpmm ad ψdc and mike11 ad model parameters φ ψ α and β considering the maximum nse criterion in reproducing the observed c t curve at x 34 3 km the reproduction of the observed c t curves by the variants of the vpmm ad model and mike11 ad model were illustrated in fig 7 fig 7 shows that the observed c t curves were best reproduced by the vpmm ad φdf and vpmm ad ψdc approaches followed by the vpmm ad dc and mike11 ad models table 2 shows that all the vpmm ad models with emass 0 07 are slightly more mass conservative than the mike11 ad model emass 0 12 and the vpmm ad φdf and vpmm ad ψdc approaches performed with nsec 99 whereas the corresponding nsec estimates for the vpmm ad dc and mike11 ad models were 96 and 93 respectively similarly the error in peaks cper of c t curves were 1 in case of the vpmm ad φdf and vpmm ad ψdc approaches which were 4 and 11 in case of the vpmm ad dc and mike11 ad models respectively the other error measures shown in table 2 also infer that the vpmm ad φdf and vpmm ad ψdc approaches performed almost equally the best in simulating the monocacy river contaminant transports followed by the vpmm ad dc and mike11 ad models 5 3 2 missouri river usa application the 3767 km long alluvial missouri river fig 8 a tributary of the mississippi river is having the total basin area of about 1 371 010 km2 the river runoff contributed mostly from this sparsely populated semi arid basin varies from 17 to 21 238 m3 s this basin is characterized by a continental climate system having warm wet summers and intense cold winters with a mean annual precipitation 200 250 mm the developed models were further tested using the steady flow conservative rhodamine wt tracer test experiment data yotsukura et al 1970 nordin and sabol 1974 in the missouri river at four locations of decatur highway bridge rk 1112 x 0 km blair highway bridge rk 1042 8 x 68 7 km ak sar ben bridge in omaha rk 991 3 x 121 0 km and plattsmouth highway bridge rk 951 x 161 2 km as illustrated in fig 8 the steady discharges measured at these four locations were 883 50 m3 s 976 35 m3 s 948 60 m3 s and 962 20 m3 s respectively and the corresponding river widths at these locations were 3 81 m 3 05 m 3 35 m 2 93 m and 3 285 m having the manning s roughness values of 0 01 0 04 0 05 and 0 03 respectively the corresponding bed slopes at these locations were 0 0027 0 0011 0 0011 and 0 0008 respectively the observed c t curves at x 0 and x 161 2 km were used for calibrating the vpmm ad and mike11 ad model parameters viz φ ψ α β as shown in table 3 and the corresponding reproductions at x 161 2 km are illustrated in fig 9 it can be envisaged from fig 9 that the solutions of the vpmm ad φdf and vpmm ad ψdc approaches almost performed equally which always outperformed the vpmm ad dc solutions followed by the mike11 ad solutions the mike11 ad solutions show the maximum under prediction and translation of the c t curves at the validation sites of x 68 7 km and x 121 0 km whereas these properties were less pronounced in case of the vpmm ad dc solutions as seen from table 3 the vpmm ad φdf and vpmm ad ψdc approaches consistently performed the best with nsec 99 ioac 99 emass 0 05 cper 1 07 and tpcer 0 h whereas these estimates for the vpmm ad dc and mike11 ad approaches were nsec 98 ioac 99 emass 1 00 cper 2 00 and tpcer 0 25 h nsec 89 ioac 97 emass 1 20 cper 8 00 and tpcer 0 50 h respectively hence it can be surmised that for simulating the c t curves in the missouri river the model performance decreased in the order vpmm ad ψdc vpmm ad φdf vpmm ad dc mike11 ad 5 4 field application unsteady flow cases 5 4 1 colorado river usa application the 2334 km long colorado river fig 10 characterized by many canyons and whitewater rapids comprises of a basin area of about 637 137 km2 with the river runoff varying from 12 to 10 900 m3 s most part of the basin is arid in nature characterized by a mean annual precipitation including snow of 15 1000 mm the observed unsteady discharge flow depth and concentrations of the conservative rhodamine wt dye tracer in the colorado river at five locations of the nautloid canyon x 0 km little colorado above desert view x 40 6 km nevill s rapid x 65 5 km mile 118 camp x 131 6 km national canyon x 210 2 km and gneiss canyon x 322 8 km graf 1995 were used to test the variants of the vpmm ad and mike11 ad models at five sub reaches of 0 40 6 km 40 6 65 5 km 65 5 131 6 km 131 6 210 2 km and 210 2 322 8 km the channel was characterized by the bed slopes of 0 0013 0 0020 0 0020 0 0019 and 0 0018 and average channel widths of 106 1 m 112 65 m 82 60 m 84 75 m and 88 85 m respectively to estimate the reach averaged manning s roughness the vpmm and mike11 hd modules were first calibrated to reproduce the observed discharge hydrographs in the reach between x 0 322 8 km with the maximum estimate of nseq subsequently considering nautloid canyon x 0 km as the upstream location these two modules were validated to reproduce the observed flow depth and discharge hydrographs as illustrated in fig 11 the visual interpretation of fig 11 reveals that at all the selected locations in the colorado river both the unsteady discharge and flow depth hydrographs were very well reproduced by the vpmm module whereas the mike11 hd module reproduced only the discharge hydrographs very well it can be seen from the corresponding performance evaluation measures presented in table 4 that the vpmm ad model reproduced the unsteady flow depths and the corresponding discharges very well with nseq 96 and nsey 92 respectively whereas the corresponding reproductions by the mike11 ad model were 83 and 85 respectively this shows the superiority of the vpmm ad model over the mike11 ad model although the later model uses unconditionally stable fully implicit finite difference scheme similarly the vpmm ad and mike ad models were calibrated to estimate the model parameters φ ψ α and β table 5 in reproducing the observed c t curves at the downstream section of the reach at x 0 322 8 km subsequently the models were validated to reproduce the observed c t curves at x 40 6 65 5 131 6 210 2 and 322 8 km as illustrated in fig 12 from the visual interpretation of fig 12 it can be inferred that at all the considered sub reaches the vpmm ad ψdc and vpmm ad φdf approaches closely reproduced the observed unsteady c t curves in the colorado river compared to the vpmm ad dc and mike11 ad models as seen in table 5 the vpmm ad ψdc method performed the best with nsec 98 ioac 99 50 emass 1 30 cper 1 tpcer 0 50 h and rmsec 0 25 μg l followed by the vpmm ad φdf method with nsec 97 50 ioac 99 emass 1 70 cper 1 50 and tpcer 0 00 h the vpmm ad dc method with nsec 87 50 ioac 95 50 emass 4 cper 2 50 tpcer 2 50 h and rmsec 0 75 μg l and the mike11 ad model with nsec 76 50 ioac 94 emass 4 cper 3 5 tpcer 1 50 h and rmsec 0 90 μg l overall for simulating the unsteady flow and contaminant transports in the colorado river the model performance decreased in the order vpmm ad ψdc vpmm ad φdf vpmm ad dc mike11 ad 5 4 2 huey creek antarctica application the 2 2 km long huey creek is a glacial meltwater stream that originates from the mount falconer and falls in the lake fryxell in taylor valley antarctica the experimental unsteady c t curve data of lithium li tracer runkel 1998 collected in the huey creek were used to verify all the variants of the vpmm ad model at four locations x 204 m x 448 m x 753 m and x 1043 m where x 0 was considered as the upstream location see fig 13 at seven sub reaches of 0 204 m 204 448 m 448 601 m 601 753 m 753 936 m 936 997 m and 997 1043 m this creek was characterized by the bed slopes of 0 123 0 069 0 05 0 052 0 040 0 019 and 0 011 respectively and channel widths of 1 4 m 1 6 m 1 8 m 1 8 m 1 8 m 1 8 m and 1 8 m respectively runkel et al 1998 to obtain the reach averaged parameters n φ ψ α β the variants of the vpmm ad and mike11 ad models were calibrated in the reach 0 1043 m and the reaches 0 204 m 0 448 m and 0 753 m were used for their validation the reproduction of observed li c t curves by the vpmm ad and mike11 models are shown in fig 14 and the corresponding performance evaluation measures are given in table 6 from the visual interpretation of fig 14 it can be envisaged that the observed c t curves were very well reproduced by the vpmm ad ψdc and vpmm ad φdf approaches whereas there were wiggles in the peak region of the c t curves as reproduced by the vpmm ad dc and mike11 ad models as inferred from table 6 both the vpmm ad ψdc and vpmm ad φdf approaches performed the best with nsec 98 ioac 99 emass 0 30 cper 2 20 tpcer 0 50 h and rmsec 0 75 μg l in which the former approach was slightly better than the later conversely the vpmm ad dc and mike11 ad models performed with nsec 85 ioac 97 emass 0 21 cper 3 tpcer 0 50 h and rmsec 0 25 μg l and nsec 82 ioac 95 emass 0 24 cper 4 50 tpcer 2 00 h and rmsec 0 90 μg l respectively hence these results revealed that for simulating the unsteady flow and contaminant transports in the huey creek the model performance decreased in the order vpmm ad ψdc vpmm ad φdf vpmm ad dc mike11 ad from the above discussion it can be surmised that the vpmm ad ψdc and vpmm ad φdf models always provide consistent performances and are suitable for field application conversely the vpmm ad dc and mike11 ad models were inconsistent in reproducing the c t curves and hence may not always be suitable for field application under both the steady and unsteady conditions 5 5 sensitivity of the vpmm ad ψdc model for meso scale river application to cope with the varying spatial scale of data acquisition in the rivers the best performed vpmm ad ψdc model was chosen to carry out the sensitivity analysis of all the performance evaluation measures with meso scale resolution of δx 0 5 1 0 1 5 2 0 50 0 km in simulating the flow and contaminant concentrations in the 322 8 km long colorado river reach fig 15 the temporal resolution of routing was kept constant at δt 0 2 h which was equal to the resolution of data availability fig 15 illustrates that the estimates of nseq nsey and nsec were 91 94 and 96 for all the lower meso scale spatial resolutions δx 0 5 50 0 km δx δt 41 7 4166 7 m s respectively the central tendency statistics of mean standard deviation of the error measures nsec emass r c 2 rmsec ioac cper and tpcer were estimated as 98 07 1 05 0 94 0 23 0 98 0 01 0 19 0 08 µg l 99 12 0 52 0 14 0 43 and 0 04 0 24 h respectively with the percentage uncertainty of means of all the error measures of 5 it can be seen from fig 15 that the model performances were gradually decreased with the increase in δx however all these estimates were within their acceptable ranges the low estimates of evol 0 99 and emass 1 5 by the vpmm ad ψ dc model even at coarser spatial scale of δx 50 km revealed that this model is very much useful for lower meso scale flow and contaminant transport study 6 conclusions using the saint venant s governing flow and advection dispersion equations three simple variants of the vpmm ad embedded flow and non reactive contaminant transport models were developed in this study that are free from any numerical stability problem on the basis of the numerical and laboratory experiments and real river applications carried out the following conclusions were obtained i during both the steady and unsteady flow conditions the vpmm ad ψdc and vpmm ad φdf models always performed consistently very well in modeling the flow and conservative contaminant transport dynamics with nse 97 and hence these two frameworks are very much suitable for real river applications ii conversely the vpmm ad dc and mike11 ad models were inconsistent in reproducing the c t curves and hence may not be always suitable for their field application iii while both the vpmm and mike11 hd modules reproduced the observed flow almost equally very well the performance of the former model in reproducing the observed flow depths were far better than the latter model iv under all type of flow conditions studied the contaminant transport modeling efficiency decreased in the order vpmm ad ψdc vpmm ad φdf vpmm ad dc mike11 ad revealing the vpmm ad ψdc approach as the best model v the lower meso scale river application results of the vpmm ad ψdc model revealed that this model performed consistently very well with acceptable performance evaluation measures hence based on the study results it can be surmised that the vpmm ad ψdc model could be a very good alternative for lower meso scale 1 d flow and non reactive contaminant transport modeling under both the steady and unsteady flow conditions without any backwater effect since this model uses an iterative computational framework in solving the governing flow and contaminant transport equations it is free from any numerical stability problem hence this model has a very good potential to be integrated as one of the land surface schemes of the climate change models and also with the geographic information system gis framework of remote sensing based pollution data acquisition acknowledgements the authors would like to thank the usgs for the steady state datasets of laboratory tracer test monocacy river and missouri river and unsteady state tracer data of the colorado river and huey creek camacho 2000 camacho l a 2000 development of a hierarchical modelling framework for solute transport under unsteady flow conditions in rivers ph d thesis dept of civil and envir eng imperial college of science and technology and medicine univ london london uk chapra and wilcock 2000 s c chapra r j wilcock transient storage and gas transfer in lowland stream j environ eng 126 2000 708 712 10 1061 asce 0733 9372 2000 126 8 708 chow 1959 v t chow open channel hydraulics 1959 mcgraw hill new york czernuszenko et al 1998 w czernuszenko p m rowinski a sukhodolov experimental and numerical validation of the dead zone model for longitudinal dispersion in rivers j hydraul res 36 2 1998 269 280 10 1080 00221689809498637 danish hydraulic institute dhi 2014 danish hydraulic institute dhi 2014 user s manual and technical 
7169,although umpteen studies are available in the hydrologic literature for modeling the contaminant transports under steady flow conditions similar trend is not seen while modeling this process under unsteady flow conditions and thereby limiting their field application for pollution monitoring in semi gauged rivers in this study three simple model variants namely vpmm ad ψdc vpmm ad φdf and vpmm ad dc were developed for unsteady state contaminant routing by tight coupling the physically based variable parameter mccarthy muskingum vpmm flow transport sub model with the advection dispersion ad contaminant transport sub model these model variants were extensively tested under unsteady and steady flow conditions using the numerical experiments and usgs laboratory and real world river application datasets considering the popular mike11 ad model as the benchmark the study results revealed the consistent superior performance of the vpmm ad ψdc and vpmm ad φdf model variants over the benchmark model the developed approach is a novel one as it is fully physically based free from numerical stability problem as the governing equations are solved iteratively can work at meso scale with the same computational space and time steps in the flow and solute routings compatible with the spatiotemporal scales of observation very simple to use and do not compromise with the routing accuracy as encountered in the benchmark hydrodynamic model even with a fully implicit finite difference scheme keywords advection dispersion contaminant transport flow routing pollution river vpmm ad 1 introduction for pollution monitoring at different spatiotemporal scales as well as to dispose wastewater into the river within its self purification capacity level modeling the transport characteristics of the contaminants in the river becomes essential most of the literature deals with the steady state contaminant transports using the advection dispersion ad model komatsu et al 1997 zoppou and knight 1997 koussis and rodriguez mirasol 1998 the ad equation is solved with long tails of concentration time c t curves using the concepts of transient storage chapra and wilcock 2000 lin and medina 2003 gooseff et al 2007 jin et al 2009 jackson et al 2013 dead zone storage czernuszenko et al 1998 one dimensional transport with inflow and storage runkel 1998 hybrid cells in series ghosh et al 2004 and other approaches seo and cheong 1998 koussis and rodriguez mirasol 1998 singh 2003 ramaswami et al 2005 fant and dortch 2007 kazezyilmaz alhan 2008 deng and jung 2009 neumann et al 2011 moghaddam et al 2017 however contaminant transports in nature mostly occur under unsteady flow conditions zhang and aral 2004 which further increase the complexity of numerical solutions of the governing equations gabriele and perkins 1997 runkel et al 1998 camacho 2000 prasad 2002 deng and jung 2009 although the river flow data is generally available relatively at closer spatiotemporal resolutions the availability of corresponding contaminant concentrations is very limited even in the well instrumented river basins with the advent of remote sensing rs based approaches it becomes feasible now a days to assess the daily scale concentrations of the non reactive riverine contaminants at 30 m 1 km spatial resolutions with better accuracy e g swain and sahoo 2017a b similarly rs based discharge measurements are going to be the next generation of research in applied hydrology e g tarpanelli et al 2013 to use these rs data products in the hydrological models there is a need to develop coupled flow and solute routing models operable at meso scale the scale of remote sensing observations in river hydrology dooge 1986 defined meso scale as the spatial resolution of 1 100 km however many of the existing flow and contaminant transport models cannot be used for meso scale river application due to the inherent numerical problems and excess computational load involved with the solutions of the governing equations at larger computational space and time steps further for ungauged or semi gauged rivers and climate change impact assessment studies these existing micro and mini scale models are of limited use due to the large field data requirement and their copious dependency on calibration sivapalan et al 2003 moreover while operating the existing fine scale ad models at meso scales solved with unconditionally stable fully implicit finite difference scheme it may result in inaccurate routing solution therefore the specific research gaps in many of the existing approaches are i lack of clear distinction between different flow and contaminant transport residence times and propagation velocities ii complexity in unifying the governing flow and contaminant transport equations because of the separate numerical schemes involved in solving these two processes iii not dealing with flow and contaminant transports in ungauged or poorly gauged rivers and iv numerical stability problem in modeling the contaminant transport at larger temporal and spatial scales compatible with the solicited information for river water quantity and quality monitoring this necessitates for advocating a simple physically based and embedded flow and contaminant transport model which can be used in ungauged or poorly gauged river basins and could be applied at relatively coarser spatiotemporal scales attuned with the observed scales of remote sensing based flow and contaminant concentrations among the variants of flow transport models amenable to be used at coarser spatiotemporal scales the variable parameter muskingum cunge vpmc model ponce and chaganti 1994 which shows mass conservation problem is extensively used tang et al 1999 perumal and sahoo 2007 2008 subsequently more mass conservative models viz variable parameter muskingum discharge routing method perumal 1994a b sahoo et al 2014 variable parameter muskingum stage routing method perumal et al 2007 2010 muskingum cunge todini method todini 2007 and variable parameter muskingum price method price 2009 have been developed the historical perspective of the physical interpretations of these variants of the muskingum flow transport models are given by perumal et al 2015 conversely the variable parameter mccarthy muskingum vpmm routing model perumal and price 2013 derived from the approximation of the full saint venant equations is a simplified physically distributed and fully mass conservative swain and sahoo 2015 the vpmm model has the ability to route flow in the ungauged or poorly gauged rivers at coarser spatiotemporal scales therefore this study attempts to answer the research questions i can the advection dispersion ad equation be modified suitably to be embedded tightly with the vpmm model derived from the saint venant equations of continuity and momentum for simulating the flow and conservative contaminant transports simultaneously using the same routing space and time steps for both the processes which is compatible with the spatiotemporal resolution of the observed flow and contaminant concentration data ii how does this developed model perform in numerical experiments and the usgs laboratory and real world river applications under both steady and unsteady flow conditions in comparison with the popular mike11 ad model danish hydraulic institute dhi 2014 considered as the benchmark and iii how does the routing accuracy of the vpmm ad model vary if applied at meso scale the paper is organized as follows section 2 presents the development of the vpmm ad embedded model variants accounting for different approaches to estimate the coefficient of longitudinal dispersion section 3 presents the framework of the benchmark mike11 ad model section 4 explains the performance evaluation measures in calibrating and validating the model variants section 5 describes the model verification details and section 6 presents the conclusions of this study 2 development of the vpmm ad embedded model for flow contaminant transports 2 1 vpmm sub model for flow transport the convection diffusion equation hayami 1951 improved by approximately accounting for inertial forces for describing the one dimensional 1 d gradually varied flow transport in prismatic channels dooge 1973 and accounting for lateral flow can be given by 1 q t ε q x d f 2 q x 2 d q l dx where q unsteady discharge ε celerity of unsteady flow dql dx ql lateral flow contribution per unit reach length x space variable t time variable and df diffusion coefficient of flow transport defined as 2 d f q 0 2 s 0 b 1 n v 2 where q 0 reference discharge s 0 river bed slope b top width of flow corresponding to q 0 and nv vedernikov number chow 1959 expressed as 3 n v 2 f 3 p b dr dy 2 3 1 r dp da f in which f froude number a area of flow section p wetted perimeter of flow section r hydraulic mean radius and y unsteady state flow depth the reference discharge q 0 normal velocity vo and normal celerity εo are the unique functions of flow depth y and the corresponding unsteady discharge q unsteady velocity v and unsteady celerity ε are the functions of both y and y x the longitudinal gradient of the water surface using the binomial series expansion one can obtain perumal and price 2013 4 q 0 q v 0 v ε 0 ε s f s 0 0 5 1 1 s 0 y x 1 n v 2 0 5 1 0 5 b ε s 0 q x 1 n v 2 where sf energy slope of the unsteady flow defined by the saint venant s momentum equation y x q x bε and y x s o 1 using eq 4 the saint venant s continuity equation considering lateral flow per unit width q l can be written as 5 t q 0 v 0 q x q l where q 0 v 0 q v a using eq 4 in 5 one can obtain the combined form of the saint venant s continuity and momentum equations accounting for the presence of lateral flow as swain and sahoo 2015 6 t q v o 0 5 q o b ε o s o q x 1 n v 2 q x q l using eq 2 in 6 one can obtain 7 t q v o d f ε o q x q x q l the finite difference equivalent of eq 7 can be obtained by applying it at the centre point of the box grid scheme with space step of δx and time step of δt fig 1 as 8 1 δ t q v o d f ε o q x i 1 2 j 1 q v o d f ε o q x i 1 2 j q i 1 2 j 1 2 x q l i 1 2 j 1 2 where 9a q i 1 2 j 1 0 5 q i j 1 q i 1 j 1 9b q i 1 2 j 0 5 q i j q i 1 j 9c q i 1 2 j 1 2 x q i 1 j 1 2 q i j 1 2 δ x 0 5 δ x q i 1 j 1 q i 1 j q i j 1 q i j 9d q l i 1 2 j 1 2 0 5 q l i 1 2 j 1 q l i 1 2 j 0 5 δ x q l j 1 q l j where ql total lateral flow contributed to the river reach at each δx grid scale using eqs 9a 9d in 8 and rearranging the resulting equation one obtains 10 q i 1 j 1 0 5 δ t k f j 1 θ f j 1 0 5 δ t k f j 1 1 θ f j 1 q i j 1 0 5 δ t k f j θ f j 0 5 δ t k f j 1 1 θ f j 1 q i j 0 5 δ t k f j 1 θ f j 0 5 δ t k f j 1 1 θ f j 1 q i 1 j 0 5 δ t 0 5 δ t k f j 1 1 θ f j 1 q l j 1 q l j where 11a k f j 1 δ x v o i 1 2 j 1 11b k f j δ x v o i 1 2 j 11c θ f j 1 1 2 1 δ x d f ε 0 i 1 2 j 1 11d θ f j 1 2 1 δ x d f ε 0 i 1 2 j corresponding to the routed outflow q i 1 j 1 obtained at the centre of the space state computational grid in fig 1 the flow depth y i 1 j 1 can be estimated using the backward difference scheme as 12 y i 1 j 1 y i 1 2 j 1 q i 1 j 1 q i 1 2 j 1 b i 1 2 j 1 ε i 1 2 j 1 y i 1 2 j 1 q i 1 j 1 0 5 q i j 1 q i 1 j 1 b i 1 2 j 1 ε i 1 2 j 1 in which y i 1 2 j 1 can be obtained by the nonlinear newton raphson optimization method iteratively using the normal discharge relationship given by 13 1 n a i 1 2 j 1 r i 1 2 j 1 s o 0 5 θ f j 1 q i j 1 1 θ f j 1 q i 1 j 1 where n manning s roughness coefficient hence the solution of eq 1 can also be represented by eq 10 2 2 development of vpmm ad embedded model for unsteady flow the non conservative form of the ad model governing the non reactive contaminant transport process in rivers with uniform cross section is given by runkel 1998 14 c t v c x d c 2 c x 2 where c contaminant concentration and dc longitudinal dispersion coefficient eq 14 can also be written in conservative form accounting for lateral contaminant mass qc l as 15 qc t v qc x d c 2 qc x 2 d qc l d x since the form of eq 15 is similar to eq 1 the governing equation of the vpmm ad embedded model for contaminant transport in unsteady flow including lateral contaminant transport can be considered to be similar to eq 10 which is given by 16 qc i 1 j 1 0 5 δ t k c j 1 θ c j 1 0 5 δ t k c j 1 1 θ c j 1 qc i j 1 0 5 δ t k c j θ c j 0 5 δ t k c j 1 1 θ c j 1 qc i j 0 5 δ t k c j 1 θ c j 0 5 δ t k c j 1 1 θ c j 1 qc i 1 j 0 5 δ t 0 5 δ t k c j 1 1 θ c j 1 qc l j 1 qc l j that is 17 c i 1 j 1 0 5 δ t k c j 1 θ c j 1 0 5 δ t k c j 1 1 θ c j 1 qc i j 1 q i 1 j 1 0 5 δ t k c j θ c j 0 5 δ t k c j 1 1 θ c j 1 qc i j q i 1 j 1 0 5 δ t k c j 1 θ c j 0 5 δ t k c j 1 1 θ c j 1 qc i 1 j q i 1 j 1 0 5 δ t 0 5 δ t k c j 1 1 θ c j 1 qc l j 1 qc l j q i 1 j 1 where 18a k c δ x v 0 k f 18b θ c 1 2 1 δ x d c ε 0 and the unsteady flow q i 1 j 1 can be estimated by using eq 10 2 3 evaluation of dispersion coefficient dc 2 3 1 relational constant ϕ based vpmm ad ϕdf model in the vpmm ad ϕdf method the dispersion coefficient dc mainly depends on both the flow and channel characteristics and hence related with the flow diffusion df as mcquivey and keefer 1974 seo and cheong 1998 19 d c ϕ d f where ϕ is the relational constant that can be estimated by calibrating the concentration time c t curve for obtaining the maximum model efficiency 2 3 2 gene expression programming gep based vpmm ad dc model recently sattar and gharabaghi 2015 developed empirical relationships by applying the gene expression programming gep model for estimating the longitudinal dispersion coefficient in steady flow a total of 150 sets of published field data of tracer test including the geometric details of natural channels were used in developing the two gep models gep 1 gep 2 in which the gep 2 model was found to be the best and is given by 20 d c 8 45 y gr s 0 v 0 gr s 0 1 65 w y η where 21 η 0 5 0 514 f 0 516 v 0 v 0 0 42 v 0 v 0 and v 0 gr s 0 steady shear velocity of water g acceleration due to gravity r hydraulic mean radius and w average width of channel 2 3 3 relational constant ψ based vpmm ad ψdc model since the gep model in eq 20 developed by sattar and gharabaghi 2015 uses the datasets under steady flow conditions the dispersion coefficient of the vpmm ad model for unsteady flows can be estimated similar to eq 18 by multiplying a relational constant coefficient ψ as 22 d c 8 45 y ψ gr s 0 v 0 gr s 0 1 65 w y η the solution procedure of the vpmm ad model is illustrated in fig 2 3 mike11 ad the benchmark model the advection dispersion ad module in the mike11 ad model dhi 2014 solves the 1 d ad equation numerically using the 6 point abbott ionescu implicit finite difference scheme this ad module requires the discharge water level cross sectional area and hydraulic radius outputs from the hydrodynamic hd module that solves the full saint venant equations in time and space the governing equation of contaminant transport in mike11 ad is given by 23 ac t qc x a d c c x x akc c 2 d q l dx where dc αvβ dispersion coefficient α β calibration parameters k linear decay coefficient k 0 for conservative pollutants and c2 source sink concentration 4 performance evaluation measures in this study seven performance evaluation measures were used for assessing and quantifying the discharge flow depth and contaminant transport capability of the vpmm ad and mike11 ad models i nash sutcliffe criterion of model efficiency nash and sutcliffe 1970 for discharge nseq flow depth nsey and contaminant concentration nsec in estimated as nash sutcliffe coefficient 100 ii coefficient of determination for discharge r q 2 flow depth r y 2 and concentration r c 2 iii root mean square error for discharge rmseq flow depth rmsey and concentration rmsec iv index of agreement willmott 1982 for discharge ioaq flow depth ioay and concentration ioac v percentage error in peak flow qper peak flow depth yper peak concentration cper expressed as qper simulated peak flow observed peak flow 1 100 yper simulated peak flow depth observed peak flow depth 1 100 cper simulated peak concentration observed peak concentration 1 100 vi error in time to peak flow tpqer peak flow depth tpyer and peak concentration tpcer expressed as tpqer time to simulated peak flow time to observed peak flow tpyer time to simulated peak flow depth time to observed peak flow depth tpcer time to simulated peak concentration time to observed peak concentration and vii percentage error in flow volume evol and contaminant mass emass expressed as 24 evol i 1 m q out i δ t i 1 n q in i δ t 1 100 25 e mass i 1 m q out c out i δ t i 1 n q in c in i δ t 1 100 where qout and cout are the routed discharge and concentration respectively qin and cin are the inflow discharge and concentration respectively δt time interval and m number of time intervals in the timeseries 5 model verification 5 1 numerical experiments to test the applicability of the vpmm ad model numerical experiments were carried out by assuming that the inflow and the corresponding solute concentration follow the 4 parameter pearson type iii distribution given by 26 y x 0 t y b y p y b t t p 1 γ 1 e x p 1 t t p γ 1 27 c x 0 t c b c p c b t t p 1 γ 1 e x p 1 t t p γ 1 where yb and cb denote the initial stage yb 0 5 m and concentration cb 0 at time t 0 respectively yp and cp denote the peak stage 3 5 8 10 m and peak concentration 10 30 50 80 mg l respectively tp time to peak 10 15 20 h and γ shape factor 1 05 1 25 1 50 a wide range of 20 inflow discharge hydrographs were generated corresponding to the stage hydrographs in eq 26 in typical rectangular and trapezoidal channels using the manning s equation with five manning s roughness coefficients 0 02 0 03 0 04 0 05 0 06 and three bed slopes 0 0003 0 0006 0 0009 for routing by the vpmm ad method in which the mike11 ad solutions were considered as the benchmark the bottom widths of the rectangular and trapezoidal channels were kept constant at 50 m whereas the side slope of the trapezoidal channels were fixed at 2h 1v the discharge and concentration hydrographs were generated with the total routing reach length 50 km δx 1 km and δt 1 h the 20 number of benchmark mike11 ad solutions were generated with the dc values of 50 100 200 and 500 m2 s while calibrating the vpmm ad model the relational constant φ in eq 19 was found to be varied from 0 007 to 0 17 the performance evaluation measures for evaluating the vpmm ad and mike11 ad models for all the 20 mike11 ad solutions are shown in the box and whisker plots in fig 3 the corresponding solutions of discharge stage and solute concentration hydrographs for eight typical routing cases are illustrated in fig 4 it can be revealed from fig 4 that the mike11 ad solutions of discharge hydrographs were very well reproduced by the vpmm ad model for different combinations of synthetic inflow hydrographs manning s roughness coefficients and channel bed slopes the accuracy of these discharge reproductions can be envisaged from fig 3 with the mean inter quartile ranges of performance evaluation measures nseq 99 41 99 36 99 75 nsey 99 15 98 72 99 67 evol 0 25 0 47 to 0 1 r q 2 0 99 0 99 1 00 r y 2 0 99 0 99 1 00 rmseq 6 02 4 60 6 99 m3 s rmseq 0 09 0 07 0 11 m ioaq 99 86 99 84 99 94 ioay 99 79 99 68 99 92 qper 3 09 1 19 4 98 yper 3 91 1 18 5 23 tpyer 0 20 0 00 0 00 h and tpqer 0 25 0 47 to 0 10 h these results prove that the vpmm ad model performed very well in reproducing the mike11 ad solutions of discharge and flow depths similarly for reproducing the benchmark solute concentrations the vpmm ad φdf model performed very well with the mean inter quartile ranges of nsec 99 40 99 23 99 69 r c 2 1 00 0 99 1 00 rmsec 1 00 0 37 1 46 mg l ioac 99 85 99 81 99 92 cper 0 93 0 09 2 02 tpcer 0 10 0 00 0 00 h and emass 0 82 0 34 1 06 however the corresponding performance measures of the vpmm ad dc model were slightly inferior with nsec 85 33 81 69 90 11 r c 2 0 87 0 84 0 91 rmsec 4 86 2 49 7 36 mg l ioac 96 09 94 61 97 35 cper 0 58 4 22 to 4 35 tpcer 0 60 2 25 to 1 00 h and emass 0 57 0 54 to 1 40 while the performance of the vpmm ad ψdc model was again very good with nsec 98 80 98 61 99 47 r c 2 0 99 0 99 1 00 rmsec 1 32 0 75 2 01 mg l ioac 99 69 99 64 99 87 cper 0 56 1 74 to 0 73 tpcer 0 10 0 00 0 00 h and emass 0 71 0 05 to 1 30 these results reveal that the vpmm ad φdf and vpmm ad dc models performed almost equally the best since they could account for the unsteadiness in the flow and solute transports conversely the steady state approach based longitudinal dispersion coefficient decreased the performance of the vpmm ad dc model although it may not be discarded fully for its field use 5 2 laboratory scale steady state application the vpmm ad and mike11 ad models were verified using the laboratory scale flume based steady state usgs tracer test fischer 1966 data series 2600 and 2700 e g nordin and sabol 1974 this flume was of 40 m length 1 10 m width 0 00031 bed slope and 0 011 manning s roughness coefficient in which the conservative rhodamine wt tracer was used with an average flow velocity of 0 269 m s and flow depth of 0 069 m the observed concentration time c t curves for the usgs data series 2600 are available at 1 s resolution at four sections from the upstream end x 0 at x 7 06 m section 1 x 14 06 m section 2 x 21 06 m section 3 and x 28 06 m section 4 similarly for the usgs data series 2700 the tracer test was conducted with 0 000257 bed slope 0 01 manning s roughness coefficient 0 362 m s average flow velocity and 0 128 m flow depth the observed concentration time c t curves for this data series 2700 are available at two sections of x 0 section 1 and x 11 00 m section 2 for simulating these data series spatiotemporal computational steps of δx 1 0 m and δt 1 0 s were chosen for all the three variants of the vpmm ad and the mike11 ad models the reaches between sections 1 4 for data series 2600 and 1 2 for data series 2700 were considered for calibrating the dispersion relational parameters φ eq 19 and ψ eq 22 in the vpmm ad φdf and vpmm ad ψdc models to obtain the maximum nse value and also for calibrating the α and β eq 23 values of dispersion coefficient in the mike11 ad model for validation the observed c t curves at sections 2 and 3 for the data series 2600 were used the reproduction of all the c t curves by the vpmm ad and mike11 models are illustrated in fig 5 and the corresponding performance evaluation measures are shown in table 1 it can be envisaged from fig 5 that the vpmm ad ψdc model reproduced the observed c t curves consistently very well followed by the vpmm ad φdf vpmm ad dc and mike11 ad models table 1 reveals that for the data series 2600 the mean estimates of nsec r c 2 rmsec ioac cper tpcer and emass in reproducing the observed c t curves by the vpmm ad φdf approach were 98 01 0 98 1 27 μg l 99 50 0 63 0 08 h and 0 44 respectively whereas these estimates for the vpmm ad dc approach were 96 84 0 97 1 78 μg l 99 19 3 50 0 17 h and 0 24 respectively similarly these mean estimates for the vpmm ad ψdc and mike11 ad models were 99 39 0 99 0 76 μg l 99 85 0 63 0 00 h and 0 45 respectively and 93 20 0 93 2 43 μg l 98 13 11 08 0 25 h and 0 52 respectively these estimates reveal that the vpmm ad ψdc and vpmm ad φdf approaches performed the best almost equally followed by the vpmm ad dc and mike11 ad models the same inference can be drawn for the 2700 series dataset note that since one dataset is available for this data series 2700 only calibration was carried out 5 3 field application steady flow cases 5 3 1 monocacy river usa application to verify the efficacy of the vpmm ad and mike11 ad models under steady flow condition the rhodomine water tracing wt dye test nordin and sabol 1974 conducted in the monocacy river was used herein the measured steady flow discharges at four downstream sections of x 10 30 km x 18 30 km x 26 80 km and x 34 30 km from the upstream dye injection site x 0 as illustrated in fig 6 showing the index map of the monocacy river were 15 57 m3 s 15 15 m3 s 15 86 m3 s and 18 55 m3 s respectively and the corresponding manning s roughness values n at these sites were 0 004 0 070 0 045 and 0 020 respectively the 93 4 km long monocacy river a tributary of the potomac river is a non tidal free flowing stream that originates in pennsylvania having a basin area of about 1927 km2 this basin is constituted with the land uses of agriculture 45 forest 41 and urban area 14 the river runoff generally varies from 16 to 87 m3 s with significant nonpoint source pollutions contributed from farms livestock operations and dairies using eq 20 the steady state dispersion coefficients dc estimated at x 10 30 km x 18 30 km x 26 80 km and x 34 30 km were found to be 37 94 m2 s 38 49 m2 s and 47 80 m2 s respectively which were used directly in the vpmm ad dc method for both the vpmm ad and mike11 ad models a routing grid size of δx 1 km and δt 0 2 h was chosen however for the last grid δx 0 1 km was chosen to match with the location where the observed c t curves were available the reach between x 0 and x 34 3 km was considered for calibrating the vpmm ad φdf vpmm ad ψdc and mike11 ad model parameters φ ψ α and β considering the maximum nse criterion in reproducing the observed c t curve at x 34 3 km the reproduction of the observed c t curves by the variants of the vpmm ad model and mike11 ad model were illustrated in fig 7 fig 7 shows that the observed c t curves were best reproduced by the vpmm ad φdf and vpmm ad ψdc approaches followed by the vpmm ad dc and mike11 ad models table 2 shows that all the vpmm ad models with emass 0 07 are slightly more mass conservative than the mike11 ad model emass 0 12 and the vpmm ad φdf and vpmm ad ψdc approaches performed with nsec 99 whereas the corresponding nsec estimates for the vpmm ad dc and mike11 ad models were 96 and 93 respectively similarly the error in peaks cper of c t curves were 1 in case of the vpmm ad φdf and vpmm ad ψdc approaches which were 4 and 11 in case of the vpmm ad dc and mike11 ad models respectively the other error measures shown in table 2 also infer that the vpmm ad φdf and vpmm ad ψdc approaches performed almost equally the best in simulating the monocacy river contaminant transports followed by the vpmm ad dc and mike11 ad models 5 3 2 missouri river usa application the 3767 km long alluvial missouri river fig 8 a tributary of the mississippi river is having the total basin area of about 1 371 010 km2 the river runoff contributed mostly from this sparsely populated semi arid basin varies from 17 to 21 238 m3 s this basin is characterized by a continental climate system having warm wet summers and intense cold winters with a mean annual precipitation 200 250 mm the developed models were further tested using the steady flow conservative rhodamine wt tracer test experiment data yotsukura et al 1970 nordin and sabol 1974 in the missouri river at four locations of decatur highway bridge rk 1112 x 0 km blair highway bridge rk 1042 8 x 68 7 km ak sar ben bridge in omaha rk 991 3 x 121 0 km and plattsmouth highway bridge rk 951 x 161 2 km as illustrated in fig 8 the steady discharges measured at these four locations were 883 50 m3 s 976 35 m3 s 948 60 m3 s and 962 20 m3 s respectively and the corresponding river widths at these locations were 3 81 m 3 05 m 3 35 m 2 93 m and 3 285 m having the manning s roughness values of 0 01 0 04 0 05 and 0 03 respectively the corresponding bed slopes at these locations were 0 0027 0 0011 0 0011 and 0 0008 respectively the observed c t curves at x 0 and x 161 2 km were used for calibrating the vpmm ad and mike11 ad model parameters viz φ ψ α β as shown in table 3 and the corresponding reproductions at x 161 2 km are illustrated in fig 9 it can be envisaged from fig 9 that the solutions of the vpmm ad φdf and vpmm ad ψdc approaches almost performed equally which always outperformed the vpmm ad dc solutions followed by the mike11 ad solutions the mike11 ad solutions show the maximum under prediction and translation of the c t curves at the validation sites of x 68 7 km and x 121 0 km whereas these properties were less pronounced in case of the vpmm ad dc solutions as seen from table 3 the vpmm ad φdf and vpmm ad ψdc approaches consistently performed the best with nsec 99 ioac 99 emass 0 05 cper 1 07 and tpcer 0 h whereas these estimates for the vpmm ad dc and mike11 ad approaches were nsec 98 ioac 99 emass 1 00 cper 2 00 and tpcer 0 25 h nsec 89 ioac 97 emass 1 20 cper 8 00 and tpcer 0 50 h respectively hence it can be surmised that for simulating the c t curves in the missouri river the model performance decreased in the order vpmm ad ψdc vpmm ad φdf vpmm ad dc mike11 ad 5 4 field application unsteady flow cases 5 4 1 colorado river usa application the 2334 km long colorado river fig 10 characterized by many canyons and whitewater rapids comprises of a basin area of about 637 137 km2 with the river runoff varying from 12 to 10 900 m3 s most part of the basin is arid in nature characterized by a mean annual precipitation including snow of 15 1000 mm the observed unsteady discharge flow depth and concentrations of the conservative rhodamine wt dye tracer in the colorado river at five locations of the nautloid canyon x 0 km little colorado above desert view x 40 6 km nevill s rapid x 65 5 km mile 118 camp x 131 6 km national canyon x 210 2 km and gneiss canyon x 322 8 km graf 1995 were used to test the variants of the vpmm ad and mike11 ad models at five sub reaches of 0 40 6 km 40 6 65 5 km 65 5 131 6 km 131 6 210 2 km and 210 2 322 8 km the channel was characterized by the bed slopes of 0 0013 0 0020 0 0020 0 0019 and 0 0018 and average channel widths of 106 1 m 112 65 m 82 60 m 84 75 m and 88 85 m respectively to estimate the reach averaged manning s roughness the vpmm and mike11 hd modules were first calibrated to reproduce the observed discharge hydrographs in the reach between x 0 322 8 km with the maximum estimate of nseq subsequently considering nautloid canyon x 0 km as the upstream location these two modules were validated to reproduce the observed flow depth and discharge hydrographs as illustrated in fig 11 the visual interpretation of fig 11 reveals that at all the selected locations in the colorado river both the unsteady discharge and flow depth hydrographs were very well reproduced by the vpmm module whereas the mike11 hd module reproduced only the discharge hydrographs very well it can be seen from the corresponding performance evaluation measures presented in table 4 that the vpmm ad model reproduced the unsteady flow depths and the corresponding discharges very well with nseq 96 and nsey 92 respectively whereas the corresponding reproductions by the mike11 ad model were 83 and 85 respectively this shows the superiority of the vpmm ad model over the mike11 ad model although the later model uses unconditionally stable fully implicit finite difference scheme similarly the vpmm ad and mike ad models were calibrated to estimate the model parameters φ ψ α and β table 5 in reproducing the observed c t curves at the downstream section of the reach at x 0 322 8 km subsequently the models were validated to reproduce the observed c t curves at x 40 6 65 5 131 6 210 2 and 322 8 km as illustrated in fig 12 from the visual interpretation of fig 12 it can be inferred that at all the considered sub reaches the vpmm ad ψdc and vpmm ad φdf approaches closely reproduced the observed unsteady c t curves in the colorado river compared to the vpmm ad dc and mike11 ad models as seen in table 5 the vpmm ad ψdc method performed the best with nsec 98 ioac 99 50 emass 1 30 cper 1 tpcer 0 50 h and rmsec 0 25 μg l followed by the vpmm ad φdf method with nsec 97 50 ioac 99 emass 1 70 cper 1 50 and tpcer 0 00 h the vpmm ad dc method with nsec 87 50 ioac 95 50 emass 4 cper 2 50 tpcer 2 50 h and rmsec 0 75 μg l and the mike11 ad model with nsec 76 50 ioac 94 emass 4 cper 3 5 tpcer 1 50 h and rmsec 0 90 μg l overall for simulating the unsteady flow and contaminant transports in the colorado river the model performance decreased in the order vpmm ad ψdc vpmm ad φdf vpmm ad dc mike11 ad 5 4 2 huey creek antarctica application the 2 2 km long huey creek is a glacial meltwater stream that originates from the mount falconer and falls in the lake fryxell in taylor valley antarctica the experimental unsteady c t curve data of lithium li tracer runkel 1998 collected in the huey creek were used to verify all the variants of the vpmm ad model at four locations x 204 m x 448 m x 753 m and x 1043 m where x 0 was considered as the upstream location see fig 13 at seven sub reaches of 0 204 m 204 448 m 448 601 m 601 753 m 753 936 m 936 997 m and 997 1043 m this creek was characterized by the bed slopes of 0 123 0 069 0 05 0 052 0 040 0 019 and 0 011 respectively and channel widths of 1 4 m 1 6 m 1 8 m 1 8 m 1 8 m 1 8 m and 1 8 m respectively runkel et al 1998 to obtain the reach averaged parameters n φ ψ α β the variants of the vpmm ad and mike11 ad models were calibrated in the reach 0 1043 m and the reaches 0 204 m 0 448 m and 0 753 m were used for their validation the reproduction of observed li c t curves by the vpmm ad and mike11 models are shown in fig 14 and the corresponding performance evaluation measures are given in table 6 from the visual interpretation of fig 14 it can be envisaged that the observed c t curves were very well reproduced by the vpmm ad ψdc and vpmm ad φdf approaches whereas there were wiggles in the peak region of the c t curves as reproduced by the vpmm ad dc and mike11 ad models as inferred from table 6 both the vpmm ad ψdc and vpmm ad φdf approaches performed the best with nsec 98 ioac 99 emass 0 30 cper 2 20 tpcer 0 50 h and rmsec 0 75 μg l in which the former approach was slightly better than the later conversely the vpmm ad dc and mike11 ad models performed with nsec 85 ioac 97 emass 0 21 cper 3 tpcer 0 50 h and rmsec 0 25 μg l and nsec 82 ioac 95 emass 0 24 cper 4 50 tpcer 2 00 h and rmsec 0 90 μg l respectively hence these results revealed that for simulating the unsteady flow and contaminant transports in the huey creek the model performance decreased in the order vpmm ad ψdc vpmm ad φdf vpmm ad dc mike11 ad from the above discussion it can be surmised that the vpmm ad ψdc and vpmm ad φdf models always provide consistent performances and are suitable for field application conversely the vpmm ad dc and mike11 ad models were inconsistent in reproducing the c t curves and hence may not always be suitable for field application under both the steady and unsteady conditions 5 5 sensitivity of the vpmm ad ψdc model for meso scale river application to cope with the varying spatial scale of data acquisition in the rivers the best performed vpmm ad ψdc model was chosen to carry out the sensitivity analysis of all the performance evaluation measures with meso scale resolution of δx 0 5 1 0 1 5 2 0 50 0 km in simulating the flow and contaminant concentrations in the 322 8 km long colorado river reach fig 15 the temporal resolution of routing was kept constant at δt 0 2 h which was equal to the resolution of data availability fig 15 illustrates that the estimates of nseq nsey and nsec were 91 94 and 96 for all the lower meso scale spatial resolutions δx 0 5 50 0 km δx δt 41 7 4166 7 m s respectively the central tendency statistics of mean standard deviation of the error measures nsec emass r c 2 rmsec ioac cper and tpcer were estimated as 98 07 1 05 0 94 0 23 0 98 0 01 0 19 0 08 µg l 99 12 0 52 0 14 0 43 and 0 04 0 24 h respectively with the percentage uncertainty of means of all the error measures of 5 it can be seen from fig 15 that the model performances were gradually decreased with the increase in δx however all these estimates were within their acceptable ranges the low estimates of evol 0 99 and emass 1 5 by the vpmm ad ψ dc model even at coarser spatial scale of δx 50 km revealed that this model is very much useful for lower meso scale flow and contaminant transport study 6 conclusions using the saint venant s governing flow and advection dispersion equations three simple variants of the vpmm ad embedded flow and non reactive contaminant transport models were developed in this study that are free from any numerical stability problem on the basis of the numerical and laboratory experiments and real river applications carried out the following conclusions were obtained i during both the steady and unsteady flow conditions the vpmm ad ψdc and vpmm ad φdf models always performed consistently very well in modeling the flow and conservative contaminant transport dynamics with nse 97 and hence these two frameworks are very much suitable for real river applications ii conversely the vpmm ad dc and mike11 ad models were inconsistent in reproducing the c t curves and hence may not be always suitable for their field application iii while both the vpmm and mike11 hd modules reproduced the observed flow almost equally very well the performance of the former model in reproducing the observed flow depths were far better than the latter model iv under all type of flow conditions studied the contaminant transport modeling efficiency decreased in the order vpmm ad ψdc vpmm ad φdf vpmm ad dc mike11 ad revealing the vpmm ad ψdc approach as the best model v the lower meso scale river application results of the vpmm ad ψdc model revealed that this model performed consistently very well with acceptable performance evaluation measures hence based on the study results it can be surmised that the vpmm ad ψdc model could be a very good alternative for lower meso scale 1 d flow and non reactive contaminant transport modeling under both the steady and unsteady flow conditions without any backwater effect since this model uses an iterative computational framework in solving the governing flow and contaminant transport equations it is free from any numerical stability problem hence this model has a very good potential to be integrated as one of the land surface schemes of the climate change models and also with the geographic information system gis framework of remote sensing based pollution data acquisition acknowledgements the authors would like to thank the usgs for the steady state datasets of laboratory tracer test monocacy river and missouri river and unsteady state tracer data of the colorado river and huey creek camacho 2000 camacho l a 2000 development of a hierarchical modelling framework for solute transport under unsteady flow conditions in rivers ph d thesis dept of civil and envir eng imperial college of science and technology and medicine univ london london uk chapra and wilcock 2000 s c chapra r j wilcock transient storage and gas transfer in lowland stream j environ eng 126 2000 708 712 10 1061 asce 0733 9372 2000 126 8 708 chow 1959 v t chow open channel hydraulics 1959 mcgraw hill new york czernuszenko et al 1998 w czernuszenko p m rowinski a sukhodolov experimental and numerical validation of the dead zone model for longitudinal dispersion in rivers j hydraul res 36 2 1998 269 280 10 1080 00221689809498637 danish hydraulic institute dhi 2014 danish hydraulic institute dhi 2014 user s manual and technical 
