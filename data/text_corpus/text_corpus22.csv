index,text
110,the implementation of nonstationary hydrological frequency analysis ns hfa has often been hampered by the relatively short datasets and the resulting high uncertainty most recently the non asymptotic metastatistical extreme value mev and simplified mev smev distributions which rely on the ordinary events rather than the extremes only have attracted attention in the hfa of both rainfall and streamflow despite their use for trend detection attribution and producing future projections their practical implementation for the ns hfa is absent in the literature this paper therefore implemented these models called mev and smev based models in the ns hfa and comprehensively assessed their performance from the perspectives of fitting efficiency accuracy and uncertainty for both in sample fitting and out of sample prediction purposes the asymptotic models based on the generalized extreme value gev distribution were used as the benchmark the assessment employed synthetic and real rainfall datasets that exhibit stationarity in the number of events per year all the nonstationary ordinary event datasets followed the weibull distribution with linearly changing parameters while their standardized annual maximum series aligned with the gev distribution thus the mev smev and gev based models could be fairly assessed and compared the regula falsi profile likelihood method was extended to quantify the uncertainty of the mev and smev based models the results demonstrated that the mev model was not advantageous over other models in terms of all three evaluation perspectives whereas the smev based models demonstrated superiority due to their higher accuracy equivalent or better fitting efficiency as well as lower uncertainty compared to all other models therefore this paper advocates the use of the smev distribution to advance the ns hfa by harnessing the information from the ordinary events keywords nonstationarity uncertainty ordinary events extreme events metastatistical extreme value distribution simplified metastatistical extreme value distribution 1 introduction the statistical analysis of hydrological extreme events plays a central role in the hydrological risk assessment mitigation and infrastructure design this task is commonly conducted by the hydrological frequency analysis hfa which assesses the recurrence of extreme events based on a probability distribution the hfa conventionally assumes stationarity of the underlying process and thus employs a time invariant distribution however climate change and other changes in the watershed induce nonstationarity in the system and thus such an assumption can be violated aghakouchak et al 2020 blöschl et al 2019 milly et al 2008 papalexiou and montanari 2019 it has been acknowledged that ignoring the nonstationarity in the hfa may provoke underestimation overestimation of the quantiles huang et al 2021 o brien and burn 2014 vu and mishra 2019 as well as accuracy deterioration and uncertainty increase in the analysis vidrio sahagún et al 2021 hence performing the nonstationary hfa ns hfa in which the distribution varies over time according to the selected covariate s becomes indispensable when evidence of nonstationarity presents françois et al 2019 salas et al 2018 in the ns hfa the distribution s variation is governed by the nonstationary structure which commonly expresses the distribution parameters as a function of the covariate s time or physical covariates that vary over time cheng and aghakouchak 2014 o brien and burn 2014 slater et al 2021b the extreme value theory evt provides one of the most popular distribution families employed in the stationary hfa s hfa as well as the ns hfa ossandón et al 2021 papalexiou and koutsoyiannis 2013 yan et al 2021 theoretically the exact distribution of the extremes converges asymptotically to the evt distributions as the number of observations per block tends to infinity coles 2001 katz et al 2002 the evt yields the generalized extreme value gev distribution which combines the three limiting distributions of the block maxima or minima the evt also yields the generalized pareto gp distribution which describes independent events in the tail of the distribution exceeding a sufficiently high threshold provided that the event occurrence process follows the poisson distribution in practice the additional assumption and subjective threshold selection might constrain the implementation of the gp distribution thus the use of the gev distribution in the hfa has been more popular nerantzaki and papalexiou 2021 salas et al 2018 on the other hand the non asymptotic distributions have attracted more attention in the s hfa recently de michele 2019 lombardo et al 2019 marani and ignaccolo 2015 marra et al 2020 unlike the evt based distributions the non asymptotic distributions are advantageous in i exploiting more available information as they use the ordinary events rather than only the extremes ii relaxing the requirement of asymptotic convergence and or iii avoiding the additional assumption of the poisson distributed event arrival as in the gp distribution the non asymptotic distributions have shown superiority in using the available data more efficiently and yielding lower predictive error and estimation uncertainty in the s hfa especially for return periods larger than the sample size de michele and avanzi 2018 marra et al 2018 miniussi et al 2020a miniussi and marani 2020 zorzetto et al 2016 however the implementation of non asymptotic distributions in the context of the ns hfa is very limited in the literature to date the non asymptotic distributions reported in the literature include the compound beta binomial cbb serinaldi et al 2020 the metastatistical extreme value mev marani and ignaccolo 2015 and the simplified mev smev marra et al 2019 distributions the cbb distribution was formulated for serially correlated and stationary processes and has not been extended to nonstationary scenarios to date the mev is a compound distribution that treats both the parameters of the ordinary event distribution and the number of ordinary events per block as stochastic variables this distribution captures the stochastic interannual variability by multiple block based parameterizations and has been argued to be capable of implicitly capturing the potential underlying nonstationarity for instance the mev distribution has been used for detecting and or attributing trends using the series of block based parameter and or quantile estimates e g dallan et al 2022 miniussi and marani 2020 this differs from the common ns hfa in which a nonstationary structure is adopted to deterministically depict the distribution evolution in contrast the smev which is a modified version of the mev distribution is capable of accounting for multiple generating processes and incorporating a nonstationary structure into the distribution for the ns hfa since the smev distribution does not account for stochastic interannual variability its parameterization might be more accurate due to its reduced number of parameters and larger sample size used for the parameterization miniussi and marani 2020 schellander et al 2019 thus in fact the smev essentially corresponds to the distribution of block maxima using the average number of observations per block derived from the theory of order statistics under independence serinaldi et al 2020 to date the smev distribution has been used to produce future projections in nonstationary scenarios by using simplified relationships of the projected changes in the median of rainfall and the number of ordinary events per year with the typical or estimated distribution parameters under stationarity e g marra et al 2019 and 2021 however the smev distribution has not been implemented and assessed in the context of the ns hfa yet i e fitting the nonstationary model to the observations from nonstationary processes the mev and smev distributions are potential alternatives for the ns hfa therefore there is a need for further research on the implementation of these two non asymptotic distributions for the ns hfa moreover the uncertainty is a key aspect in the ns hfa on one hand the hydrometeorological records are often limited and consequently the annual maxima extremes series are usually short the use of short datasets in the ns hfa based on asymptotic distributions would introduce non negligible uncertainty to the analysis the uncertainty is further exacerbated when adopting complex nonstationary structures in the underlying model as a result the uncertainty has overshadowed the benefits of the ns hfa and created an ongoing debate on its practical convenience and feasibility koutsoyiannis and montanari 2015 lins and cohn 2011 milly et al 2015 serinaldi and kilsby 2015 consequently the uncertainty which might hinder the practical application of the ns hfa needs to be reduced for its wide implementation in real practice on the other hand the uncertainty associated with the non asymptotic models has received little attention in the s hfa and of course in the ns hfa so far de michele 2019 pointed out that detailed and thorough investigations on the potential advantages of the non asymptotic models compared to the traditional asymptotic ones in this regard are missing thus such an investigation of the non asymptotic models as well as the comparison with asymptotic models would be desired in the quest of advancing the ns hfa and consequently populating its practical implementation this paper therefore aims to assess the potential of using the non asymptotic distribution derived from the metastatistical approach i e the mev and its simplified version i e the smev in the ns hfa from the perspectives of the uncertainty fitting efficiency and accuracy to the best knowledge of the authors this study is the first of its kind in the field of the ns hfa the non asymptotic distributions were examined using their asymptotic counterpart as the benchmark in the assessment the mev and smev as well as the gev distributions were utilized in the non asymptotic and asymptotic models respectively to fulfill the overarching objective this paper conducted a comparative evaluation of the models under different scenarios of nonstationarity in a simulation study furthermore the practical application of both the non asymptotic and asymptotic models was illustrated using several real rainfall datasets presenting nonstationarity the profile likelihood pl method has shown to be superior to other frequentist methods e g the bootstrap and delta methods in uncertainty estimation due to its higher accuracy and realistic asymmetric estimates bolívar cimé et al 2015 coles 2001 gilleland and katz 2016 obeysekera and salas 2014 hence the regula falsi pl rf pl method vidrio sahagún and he 2022 was extended for the non asymptotic models and employed to estimate the uncertainty herein 2 methodology 2 1 asymptotic models the cumulative gev function of the random variable y which corresponds to the annual maxima of n ordinary events x at every year i e y max x 1 xn is defined as 1 f y θ f y ξ α κ exp 1 κ y ξ α 1 κ κ 0 exp exp y ξ α κ 0 where the parameter vector θ is composed of κ α and ξ namely the shape scale and location parameters respectively the tail behavior of the distribution is described by κ and the gev is categorized into three subfamilies extreme value ev type i distribution when κ 0 ev type ii which is the heavy tailed case when κ 0 and ev type iii which is the upper bounded case when κ 0 the probability density of the gev distribution can be found in the literature e g coles 2001 hosking and wallis 2009 the quantile estimate yt i e the magnitude associated with the return period t 1 p where p is the exceedance probability i e p 1 f y θ is given by 2 y t f y 1 p θ ξ α κ 1 log 1 p κ κ 0 ξ α log log 1 p κ 0 under nonstationarity the distribution is allowed to vary over time by using the covariate dependent distribution parameters in this paper two ns hfa models based on the gev distribution were considered namely the gev distribution with two different nonstationary structures in which the location parameter ξ v and both the location and scale parameters ξ v and α v change as a linear function of the covariate v respectively the κ was assumed constant considering its difficult estimation due to the constraint in the data length and consequently its unrealistic time variant characterization coles 2001 salas et al 2018 these linear nonstationary models were adopted following the principle of parsimony namely favoring simple rather than complex models chebana and ouarda 2021 koutsoyiannis 2016 serago and vogel 2018 these nonstationary models are denoted as gev 1 0 0 and gev 1 1 0 respectively and are given by 3 g e v 1 0 0 g e v ξ v α κ ξ v ξ 0 ξ 1 v α c o n s t a n t κ c o n s t a n t 4 g e v 1 1 0 g e v ξ v α v κ ξ v ξ 0 ξ 1 v α v α 0 α 1 v κ c o n s t a n t where ξ 0 and ξ 1 and α 0 and α 1 are the regression coefficients of the location and scale parameters respectively 2 2 non asymptotic models the mev distribution marani and ignaccolo 2015 treats the parameter vector θ of the distribution depicting the ordinary events x and the number of x occurrences per block n as stochastic variables the mev cumulative distribution is defined as 5 ψ m e v x n ω θ f x θ n g n θ d θ where ωθ is the parameter space g n θ is the joint probability distribution of n and θ discrete in n and continuous in θ respectively and f x θ is the cumulative distribution of x the weibull distribution has been commonly adopted for f x θ in the literature formetta et al 2022 marani and ignaccolo 2015 miniussi et al 2020b miniussi and marani 2020 miniussi and marra 2021 schellander et al 2019 zorzetto et al 2016 the popularity of this choice is supported by the physical justification that the right tail of the daily rainfall distribution is stretched exponential wilson and toumi 2005 this choice is also coherent with serinaldi and kilsby 2014 and de michele and avanzi 2018 for practical applications the mev distribution has been approximated by its expectation using the sample average computed over the observational period by zorzetto et al 2016 6 ψ m e v x 1 m j 1 m f x θ j n j 1 m j 1 m 1 exp x λ j β j n j where m is the length of the sample in years the parameter vector θ is composed of λ and β which are the scale and shape parameters of the weibull distribution respectively and θ j and nj are the θ and n in the jth block year respectively the probability density of the mev distribution is thus given by 7 ψ m e v x d ψ m e v x d x 1 m j 1 m d f x θ j n j d x 1 m j 1 m n j f x θ j f x θ j n j 1 1 m j 1 m n j β j λ j x λ j β 1 exp x λ j β j 1 exp x λ j β j n j 1 the extreme event quantile estimate ψ m e v 1 x equivalent to yt is numerically estimated by finding the xt that satisfy ψ mev xt 1 p as the mev distribution can only implicitly capture the nonstationarity by its block based parameterization the set of annual mev distributions was utilized in this paper this approach has been previously used for long term trend detection and or attribution in hydrometeorological datasets dallan et al 2022 miniussi and marani 2020 as each block is defined according to the year t this model is denoted herein as m e v m e v λ t β t n t in the smev distribution the interannual variability of f x θ and n are neglected and the temporal dependence of the distribution parameters can be deterministically described marra et al 2019 its cumulative distribution is given by 8 ψ s m e v x t i 1 s f i x θ i t n i t i 1 s 1 exp x λ i t β i t n i t where s is the number of different types of x which is set to 1 in this paper θ i t λ i t β i t is the time dependent θ of the ith x type and n i t is the time variant average n of the ith x type it has been shown by both theoretical analysis and simulation studies that neglecting the fluctuations of n with n i produces a negligible impact on the estimates miniussi and marani 2020 the probability density of the smev distribution ψ s m e v x t and the extreme event quantile estimate ψ s m e v 1 x t are thus given by 9 ψ s m e v x t d ψ s m e v x t d x d f x θ t n t d x n t f x θ t f x θ t n t 1 n t β t λ t x λ t β t 1 exp x λ t β t 1 exp x λ t β t n t 1 10 ψ s m e v 1 x t λ t log 1 1 p 1 n t 1 β t under nonstationarity the smev distribution is allowed to vary over time by using the covariate dependent distribution parameters similar to the asymptotic models the smev models adopted parsimonious linear nonstationary structures in which the scale parameter λ v and both the scale and shape parameters λ v and β v are expressed as linear functions of the covariate v in this paper the smev based models adopted a constant n in alignment with the absence of significant temporal trends in the n of all the datasets analyzed here these ns hfa models are denoted as smev 1 0 and smev 1 1 respectively and are given by 11 s m e v 1 0 s m e v λ v β n λ v λ 0 λ 1 v β constant n constant 12 s m e v 1 1 s m e v λ v β v n λ v λ 0 λ 1 v β v β 0 β 1 v n constant 2 3 parameter estimation and uncertainty quantification the estimation of both the distribution parameters and the uncertainty was conducted based upon the likelihood namely by the maximum likelihood estimator mle and the rf pl method the rf pl method is the advanced pl method which reduces its computational burden vidrio sahagún and he 2022 the likelihood is the joint probability of the observations either y t y 1 ym or x t i x 1 1 x n m given a certain θ in practice it is more convenient and easier to use the log likelihood ℓ θ than the likelihood l θ due to its tractability in the optimization procedure katz 2013 the ℓ θ function for the independent but not necessarily identically distributed random variables yt and x t i are 13 ℓ θ log l θ t 1 m log f y t θ 14 ℓ θ log l θ t 1 m i 1 n log f x t i θ respectively where f yt θ and f x t i θ are the probability density functions of the annual maxima and ordinary events respectively and n is the number of events per block and its average for the mev and smev distributions respectively similarly the ℓ θ function of the mev and smev distributions is given by 15 ℓ θ log l θ t 1 m log ψ y t θ where ψ y t θ is the mev or smev probability density function of the extremes derived from the ordinary events the mle of θ denoted as θ is the parameter vector that maximizes ℓ θ i e 16 θ arg max θ θ ℓ θ the θ is estimated using the log likelihood functions of eqs 13 and 14 for the gev based models and both the mev and smev based models respectively the profile likelihood for a target parameter component θ j denoted as ℓ p θ j is derived from the log likelihood function maximized with respect to all other parameter components of θ i e θ j and is defined as coles 2001 17 ℓ p θ j max θ j ℓ θ j θ j then the obtained ℓ p θ j is used to approximate the 100 1 ρ confidence interval c ρ of θ j defined as coles 2001 18 c ρ θ j 2 ℓ θ ℓ p θ j q 1 ρ where ρ is the significance level 0 05 herein and q 1 ρ is the 1 ρ quantile of the chi square distribution with one degree of freedom χ 1 2 in the rf pl method θ j can be a quantile y t t k x t t k associated with the effective return level t at a given point in time tk of the properly reparametrized log likelihood function such reparameterization is obtained by substituting the re arranged quantile expression of the corresponding model into ℓ θ to incorporate y t t k x t t k as a model parameter refer to vidrio sahagún and he 2022 for more details the reparametrized log likelihood functions of the gev 1 0 0 and gev 1 1 0 models can be found in vidrio sahagún and he 2022 whereas those for both the mev and smev based models are not available yet and thus the rf pl method is not readily applicable to these models hence the reparametrized log likelihood functions of the mev smev 1 0 and smev 1 1 models were introduced in this paper and are given for each model by 19 ℓ x t t k β t t 1 m i 1 n log β t log 1 1 p 1 n t 1 β t x t t k log x t i log 1 1 p 1 n t 1 β t x t t k β t 1 x t i log 1 1 p 1 n t 1 β t x t t k β t 20 ℓ x t t k λ 1 β t 1 m i 1 n log β x t t k log 1 1 p 1 n t 1 β λ 1 t t k log x t i x t t k log 1 1 p 1 n t 1 β λ 1 t t k β 1 x t i x t t k log 1 1 p 1 n t 1 β λ 1 t t k β 21 ℓ x t t k λ 1 β 0 β 1 t 1 m i 1 n log β 0 β 1 t x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k log x t i x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t 1 x t i x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t moreover the practical applications of the non asymptotic models in the s hfa have shown that the ordinary events of lower magnitude negatively impact the evaluation of the distribution s right tail by diverging the estimates marra et al 2019 miniussi and marra 2021 this issue has been solved by left censoring namely ignoring the magnitudes of the small ordinary events while retaining their existence in the distribution marra et al 2019 2020 unlike the gp distribution the mev and smev distributions can account for ordinary events rather than only the extremes and do not require any assumption on the event arrival process marra et al 2020 the left censoring of the ordinary events can be also incorporated into the mle and rf pl methods for parameter estimation and uncertainty quantification respectively to this end the left censored version of the log likelihood function cohn 2005 helsel 2011 of the ordinary event distribution eq 14 was adopted when dealing with real datasets 22 ℓ θ l c log l θ l c t 1 m i 1 n δ t i log f x t i θ t 1 m i 1 n 1 δ t i log f τ t r θ where τ t r is the left censor threshold set at the rth quantile of the ordinary events at time t and δ t i is the indicator variable taking the values of 1 and 0 when x t i exceeds and does not exceed the τ t r respectively the threshold selection is case specific and has been determined by scrutiny often optimizing some relevant metric formetta et al 2022 marra et al 2019 2020 miniussi and marra 2021 in this paper the threshold was selected such that the fitting efficiency was maximized while the suitability of the weibull distribution for characterizing the ordinary events was guaranteed the reparametrized log likelihood functions with left censoring of the mev smev 1 0 and smev 1 1 models are thus expressed for each model as 23 ℓ x t t k β t t 1 m i 1 n δ t i log β t log 1 1 p 1 n t 1 β t x t t k log x t i log 1 1 p 1 n t 1 β t x t t k β t 1 x t i log 1 1 p 1 n t 1 β t x t t k β t t 1 m i 1 n 1 δ t i log 1 exp τ t r x t t k log 1 1 p 1 n t 1 β t β t 24 ℓ x t t k λ 1 β t 1 m i 1 n δ t i log β x t t k log 1 1 p 1 n t 1 β λ 1 t t k log x t i x t t k log 1 1 p 1 n t 1 β λ 1 t t k β 1 x t i x t t k log 1 1 p 1 n t 1 β λ 1 t t k β t 1 m i 1 n 1 δ t i log 1 exp τ t r x t t k log 1 1 p 1 n t 1 β λ 1 t t k β 25 ℓ x t t k λ 1 β 0 β 1 t 1 m i 1 n δ t i log β 0 β 1 t x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k log x t i x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t 1 x t i x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t t 1 m i 1 n 1 δ t i log 1 exp τ t r x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t 2 4 model evaluation the model performance was assessed from several perspectives including the fitting efficiency accuracy and uncertainty the akaike information criterion aic which deals with the trade off between the goodness of fit and complexity of a model was used to assess the fitting efficiency the normalized aic naic was used to facilitate the examination of aics among different sample sizes the relative root mean square error rrmse was also used to assess the accuracy of the estimates in which the true quantiles are known a priori these two metrics are calculated as 26 n a i c 2 ℓ θ 2 d m 27 r r m s e 1 m t 1 m r t t p t t r t t 2 where d is the number of parameters of the ns hfa model ℓ θ is calculated by eqs 13 and 15 for the gev based and both mev and smev based models respectively and r t t and p t t are the true and the estimated quantiles associated with t at time t respectively a model of smaller values of naic and rrmse are of higher fitting efficiency and accuracy respectively the uncertainty was quantified using the relative average bandwidth raw and the relative coverage width index rcwi kasiviswanathan et al 2019 of the confidence intervals the rcwi combines the raw and the percentage of coverage poc of the confidence intervals which conflict with each other these metrics are given by 28 r a w 1 m t 1 m p t t u p t t l p t t 29 p o c 1 m t 1 m c t t w h e r e c t t 1 t s t p t t l r t t p t t u 0 elsewhere 30 r c w i r a w exp 1 α c w i p o c 100 2 where p t t u and p t t l are the upper and lower uncertainty bounds at t and t respectively and α cwi is the significance level 0 05 note that similarly to the rrmse the calculations of the poc and rcwi require knowing the true quantiles a model of smaller values of raw and rcwi is less uncertain 2 5 simulation study a simulation study was conducted to compare the asymptotic and non asymptotic ns hfa models using synthetic ordinary event datasets with a priori known statistical properties the synthetic datasets were generated by randomly sampling the quantile function of the weibull distribution in three different scenarios of nonstationarity in scenarios 1 s1 2 s2 and 3 s3 the nonstationarity was introduced in λ in β and in both λ and β of the ordinary event distributions respectively by 31 s 1 x v w e i b u l l λ v β 0 w h e r e λ v λ 0 λ 1 v β 0 constant 32 s 2 x v w e i b u l l λ 0 β v w h e r e λ 0 constant β v β 0 β 1 v 33 s 3 x v w e i b u l l λ v β v w h e r e λ v λ 0 λ 1 2 v β v β 0 β 1 2 v where the covariate v monotonically and linearly increases over time and λ 0 10 λ 1 0 1 β 0 0 8 and β 1 0 002 such that both λ v and β v are always within their commonly reported ranges of 0 5 β v 0 8 and 10 λ v 25 marani and ignaccolo 2015 marra et al 2018 2019 2020 the decrease of β v implies a heavier tail of the ordinary event distribution along with the increase of the covariate v the increase of λ v implies a wider ordinary event distribution along with the increase of v the evolutions of both the densities and quantiles of the distributions employed for generating the datasets in the s1 s2 and s3 are presented in fig 1 the use of λ 1 2 and β 1 2 in s3 was determined to ensure equivalent increases in the distribution quantiles from which the generated datasets were sampled in the three scenarios fig 1 b and avoid numerical problems in the following analyses due to extremely high values two record lengths of synthetic datasets were explored namely m 50 and 100 years the number of events per year was fixed to n 60 which is also in its common range reported in several previous studies marani and ignaccolo 2015 marra et al 2018 miniussi and marani 2020 zorzetto and marani 2020 and consistent with the average n of the real rainfall datasets employed in this paper the simulation study only used generated ordinary event datasets whose annual maximum series ams were verified to be successfully captured by the gev based ns hfa models to this end the two sample kolmogorov smirnov ks test and the modified anderson darling mad test were employed the critical values for the mad test were determined by monte carlo simulation see ahmad et al 1988 shin et al 2012 these two statistical tests complement each other as the ks and mad assess the agreement of the empirical and the assumed distributions in their whole and particularly in their upper tails respectively owing to the lack of homogeneity in the distributional assumption the standard transformation was applied to the nonstationary ams using the corresponding reference model coles 2001 ragno et al 2019 all the generated datasets were also verified to present significant temporal trends by the mann kendall test all the statistical tests were conducted at the 0 05 significance level in this simulation study 1000 datasets were generated for each nonstationary scenario and each record length and thus a total of 6000 datasets were employed the asymptotic and non asymptotic ns hfa models were assessed in two different contexts namely for in sample fitting and out of sample prediction purposes the fitting performance assessment evaluated the models capabilities to depict the extremes in the historical period in which the models were parameterized the model accuracy and uncertainty were assessed using the rrmse as well as the raw and rcwi respectively at t 10 50 and 100 yr the naic was used to evaluate the fitting efficiency of the models to capture both the sample amss and the underlying nonstationary stochastic process of the extreme events to this end the naic was derived in two different ways namely using the available ams and 100 true quantiles derived from the true nonstationary distribution of the extremes with equally spaced exceedance probability at each time slice respectively these two naics were called empirical naic and true naic throughout this paper note that only the empirical naic can be estimated in real practice due to the lack of knowledge of the stochastic process of extremes and thus the true quantiles the true quantiles required for calculating the true naic rrmse and rcwi were derived for each nonstationary scenario by monte carlo simulation as in the previous s hfa simulation studies using the mev distribution marani and ignaccolo 2015 marra et al 2018 firstly 1 107 blocks with n ordinary events each were generated from the weibull distribution with the corresponding values of θ v at a given time slice tk the annual maximum was then extracted from each simulated block this is equivalent to having 1 107 realizations from the nonstationary extreme event stochastic process at tk the t year extreme event quantiles were derived from this large sample of block maxima using the weibull plotting position formula these steps were repeated for each tk of interest furthermore the predictive performance assessment evaluated the skills of the models fitted to historical observations for predicting the extreme event quantiles in the future this assessment employed the true naic the rrmse and the rcwi as evaluation metrics in this simulation study a fixed length of 50 years in the future was adopted regardless of the m used for the model parameterization 2 6 application on real datasets three real rainfall datasets from mexico were employed to assess the non asymptotic and asymptotic ns hfa models these datasets were retrieved from the hydrometeorological stations of león dge conagua 11095 los castillos conagua 11040 and abasolo conagua 11001 these datasets have record lengths of 72 72 and 70 years and are referred to as d1 d2 and d3 respectively throughout this paper the selected datasets have year round measurements without missing data except for two and one complete years 1950 and 1958 and 1950 in d1 and d2 respectively the mann kendall trend test was applied to the ams and the number of ordinary events per year n and per season of the datasets at a significance level of 0 05 the four seasons were defined as winter december february spring march may summer june august and autumn september november as illustrated in fig 2 the datasets d1 d2 and d3 exhibit significant temporal trends in the mean of their amss these significant long term trends are indicative of the presence of nonstationarity in extreme rainfall events in contrast no significant temporal trends were detected in the number of ordinary events at both the annual scale fig 2 and seasonal scales fig s1 in the supplementary material of the datasets in this practical application all the non asymptotic mev smev 1 0 and smev 1 1 and asymptotic gev 1 0 0 and gev 1 1 0 ns hfa models were employed the temporal covariate i e v time which has been commonly used to surrogate any time dependent physical driver s in the ns hfa literature kjeldsen and prosdocimi 2021 obeysekera and salas 2016 serago and vogel 2018 sun et al 2018 was adopted in the gev and smev based models besides the mad and ks tests were used to verify the suitability of the gev based models as in the simulation study whereas the conventional ks test which easily handles the left censored datasets was employed to verify that the mev and smev based models properly fit the ordinary events on an annual basis the datasets were split into two sub samples for the fitting and predictive performance assessments under nonstationarity the underlying stochastic process varies over time as a result the two sub samples were not generated by sampling randomly but by dividing the historical period into two continuous periods to preserve the temporal dependence the first part of the observations was used to evaluate the fitting performance of the models while the rest of the observations were used for the prediction performance assessment in these assessments the datasets were split at two percentages namely 50 and 75 in addition the full sample i e the splitting percentage of 100 was also considered in the fitting performance assessment this case is equivalent to using all the data for the model parameterization without evaluating the prediction performance this has been the common practice in the ns hfa e g agilan and umamahesh 2017 hesarkazzazi et al 2021 lee et al 2020 ouarda et al 2018 prosdocimi et al 2015 as the dataset splitting reduces the sample size for the model parameterization and thus decreases the model s reliability the performance assessments of the models were conducted using the empirical naic and raw only due to the lack of knowledge of the true quantiles to derive the true naic rrmse and rcwi 3 results and discussion 3 1 simulation study 3 1 1 performance in the context of fitting purposes fig 3 presents the fitting efficiency empirical and true naics and accuracy rrmse of the asymptotic and non asymptotic ns hfa models employed for fitting purposes as shown in fig 3 a the mev model fitted the sample amss more efficiently than the smev and gev based models in all three scenarios and both ms as indicated by its lower empirical naics in addition the mev model yielded slightly narrower interquartile and full ranges of the empirical naic the smev and gev based models performed equivalently in general as their empirical naics and their interquartile and full ranges appeared to be equivalent in all three scenarios and both ms in contrast when comparing the models in terms of true naic fig 3 b the mev model was the least fitting efficient overall in all scenarios and ms among all models the mev model resulted in higher true naics and wider interquartile ranges of true naic than the smev and gev based models did except that the gev based models produced the highest maximum true naics in all three scenarios when m 50 compared to the gev based models the smev based models had higher fitting efficiency as they produced lower true naics and narrower interquartile and full ranges of true naic furthermore figs 3 c e present the rrmse of the quantile estimates at the selected ts as shown in these figures the smev based models smev 1 0 and or smev 1 1 yielded lower rrmses and narrower interquartile and full ranges of the rrmse than all other models in all scenarios and ms only when m 100 in s2 smev 1 1 yielded the highest maximum rrmses among the models the mev model had higher rrmses than the gev based models although its full ranges of the rrmse were narrower notably contrasting results were obtained when comparing the fitting efficiency of the models namely the mev model outperformed the smev and gev based models in terms of the empirical naic whereas the smev and gev based models were superior to the mev model in terms of the true naic these results suggest that the mev model might be prone to overfitting this could be ascribed to the block based parameterization of the mev model which would lead to overfitting the samples hence capturing the nonstationarity of extreme events by the stochastic interannual variability rather than by a deterministic time dependent component would be counterproductive due to this fact the mev model might not be preferable over all other models under nonstationary conditions the smev based models were demonstrated to be equivalent and superior to the gev based models in terms of the empirical and true naics respectively moreover the smev based models were also overall more robust than the asymptotic gev based models as shown by their narrower and equivalent variation ranges of true naic and empirical naic respectively therefore the non asymptotic smev based models were superior to the asymptotic gev based models in fitting efficiency furthermore the smev based models achieved overall better accuracy and higher robustness narrower variation ranges of rrmse than all other models for the 10 50 and 100 yr quantile estimates the few very high rrmses produced by the smev 1 1 model when m 100 in s2 would be ascribed to the difficult estimation of the evolution of β over time in a few cases especially when β takes relatively small values i e approaching to the lower bound of its range 0 6 0 8 at the end of the fitting period corresponding to high skewness thus these evaluations of both the fitting efficiency and accuracy advocate the superiority of the smev based models fig 4 presents the uncertainty raw and rcwi of the asymptotic and non asymptotic ns hfa models at the selected ts as shown in this figure the smev based models consistently yielded the lowest raw and rcwi and narrowest interquartile and full ranges of these two metrics irrespective of nonstationary scenarios ms and ts in addition the gev based models produced lower raw and rcwi than the mev model but with wider interquartile and full ranges of both metrics in all the simulation cases whereas the gev based models often produced the highest maximum raw and rcwi when m 50 except in the raw in s1 thus the smev based models were superior to all other models from the perspective of uncertainty the asymptotic models also presented a steeper increase in both the raw and rcwi along with the increase of the t than the non asymptotic models in addition the results demonstrated that the increase of the m generally reduced the uncertainty of both the smev and gev based models in all cases however such a result was not obtained for the mev model for instance the rcwis and raws of the mev model in s2 and s3 did not decrease with the increase of the m similar to the model evaluation in terms of the fitting efficiency and accuracy the assessment from the uncertainty point of view showed prominent superiority of the smev based models over all other models the reduced uncertainty of the smev based models would be primarily ascribed to the increased sample size due to the use of ordinary events for estimating the distribution parameters however the increased sample size did not result in a decrease in the uncertainty of the mev model the high uncertainty yielded by the mev model could be ascribed to the relatively small sample size used for the block based parameterization as well as the larger number of parameters needed for its implementation one set per block the disadvantage of the mev model from the uncertainty perspective further argues that the implementation of this model might not be promising for the ns hfa in particular the superiority of the smev based models compared to the gev based models becomes more prominent as the t increases which is consistent with previous findings for the s hfa e g schellander et al 2019 besides the smev based models were also more robust than their asymptotic counterparts as reflected by their narrower variation ranges of the raw and rcwi all these results demonstrated that the smev based models outperformed the mev and the gev based models in the ns hfa from all three evaluation perspectives including the fitting efficiency accuracy and uncertainty for the fitting purposes thus the non asymptotic approach especially the smev based models could potentially advance the ns hfa in improving their overall performance by harnessing the information of the ordinary events 3 1 2 performance in the context of predictive purposes in this evaluation the mev model was excluded due to its lack of a nonstationary structure and thus its incapability of making predictions beyond the fitting period based upon the covariate fig 5 presents the fitting efficiency true naic and accuracy rrmse of the gev based and smev based models for prediction purposes the empirical naic was not assessed because the objective of the ns hfa is to predict the true quantiles in the future as shown in fig 5 the smev based models smev 1 0 and or smev 1 1 often yielded lower true naics and rrmses as well as narrower interquartile and full ranges of true naic and rrmse than the gev based models in particular smev 1 0 and smev 1 1 whose nonstationary structures align with the data generation of s1 and s2 s3 respectively outperformed the rest of the models namely the smev 1 0 was superior to all other models in s1 while the smev 1 1 outperformed or were equivalent to all other models in s2 and s3 except the maximum rrmses in s2 as aforementioned the highest maximum rrmses of smev 1 1 in s2 might be ascribed to the difficulty in estimating β and its temporal changes unlike smev 1 0 in which β is constant thus in general the smev based models outperformed the gev based models in terms of fitting efficiency and accuracy for prediction purposes as well moreover the results demonstrated that the smev based models also present an overall benefit in robustness especially in s1 as well as s3 to some extent however the superiority of the smev based models was not apparent or absent in s2 when m 50 particularly the nonstationary structure seems to play a major role in s2 as the use of different nonstationary structures in the smev based led to substantially different performance for instance when m 100 and t 10 yr the smev 1 1 and smev 1 0 models were overall the most and least accurate in s2 respectively among all the models thus the nonstationary structure may be especially critical in the smev based models for predictive tasks from the viewpoint of accuracy sometimes despite these exceptions the smev based models seem to be the preferable option for prediction purposes in general fig 6 shows the uncertainty raw and rcwi of the smev and gev based models as illustrated in this figure the smev and gev based models of simpler nonstationary structures i e smev 1 0 and gev 1 0 0 produced lower raws and rcwis than their more complex counterparts i e smev 1 1 and gev 1 1 0 the smev 1 0 model yielded the lowest raws and rcwis as well as the narrowest interquartile and full ranges of raw and rcwi among all models however unlike the evaluation for fitting purposes fig 4 the smev 1 1 did not always yield lower raws and rcwis and narrower interquartile and full ranges of these metrics than the gev based models for instance the smev 1 1 generally produced higher raws and rcwis than gev 1 0 0 in all scenarios for t 10 yr and s2 for t 50 yr nonetheless the smev 1 1 overall presented lower raws and rcwis than the gev based models in the three scenarios for t 100 yr and s1 and s3 for t 50 yr moreover the smev 1 0 model produced the narrowest interquartile and full ranges of raw and rcwi while smev 1 1 yielded narrower or similar interquartile and full ranges than the gev based models for the three scenarios of t 50 and 100 yr in general the gev based models produced exceptionally high maximum values of rcwi especially when m 50 in addition the uncertainty was higher when performing prediction fig 6 than when performing fitting tasks fig 4 in particular the smev based and gev based models with more parameters i e smev 1 1 and gev 1 1 0 showed the largest uncertainty increase among the non asymptotic and asymptotic models respectively for instance the average median raw of the three scenarios of smev 1 0 smev 1 1 gev 1 0 0 and gev 1 1 0 increased by 0 120 0 479 0 108 and 0 374 respectively for m 50 and t 100 yr the lower uncertainty of the simpler smev based and gev based models i e with the smaller number of distribution parameters is consistent with the notion that adding more parameters to the ns hfa models would increase the prediction uncertainty for equivalent model complexity i e smev 1 0 and gev 1 0 0 or smev 1 1 and gev 1 1 0 which have four and five parameters respectively the smev based models showed their superiority in terms of uncertainty besides the smev based models offered similar or better robustness than the gev based models therefore all these results support the preference of the smev based models over the gev based ones for predicting future quantiles with less uncertainty the results indicate that the advantage of the smev based models is particularly more prominent for higher ts the superiority of the smev based models from the uncertainty perspective as well as from the fitting efficiency and accuracy perspectives advocates their preference for prediction purposes in the ns hfa moreover the smaller increases in the uncertainty of the models with parsimonious nonstationary structures in the prediction relative to the fitting also suggest that their use is preferable from the uncertainty viewpoint 3 2 illustrative application on real datasets in the non asymptotic ns hfa models the τ t r was set at the 30th 50th and 50th quantiles of the ordinary events for d1 d2 and d3 respectively after scrutiny these selections maximized the empirical naic in the fitting periods at the three splitting percentages and ensured the suitability of the weibull distribution all the asymptotic and non asymptotic models were confirmed to be statistically significant appropriate for d1 d2 and d3 by the ks and mad tests besides the absence of significant temporal trends in n fig 2 supported the use of a time invariant n in the smev based models for these datasets fig 7 shows the frequency curves at the last year of record of the mev model the optimal smev based models i e smev 1 0 smev 1 0 and smev 1 1 for d1 d2 and d3 respectively and the optimal gev based models i e gev 1 1 0 gev 1 0 0 and gev 1 1 0 for d1 d2 and d3 respectively in terms of empirical naic when 100 of data were used for the parameterization as shown in fig 7 for all three datasets the optimal smev based models consistently yielded the least uncertainty in the frequency estimates among the three models while the optimal gev based models were superior to the mev model in this aspect it is apparent that the advantage of the smev based models was more prominent at the higher ts as the enlargement of their confidence intervals with the increase of t is much less compared to that of the gev based models fig 8 presents the empirical naic and raw at the three ts of all the models used for fitting purposes for all datasets and splitting percentages the solid and dashed black boxes highlight the best and second best models among all in each case respectively on one hand the mev models consistently yielded the lowest empirical naics throughout all cases fig 8 a the smev and gev based models produced similar empirical naics in general although the gev based models often yielded the second lowest empirical naics on the other hand the smev based models always produced lower raws than the mev and gev based models in all cases figs 8 b d in particular the parsimonious smev based model i e smev 1 0 always produced the lowest raws among all the models in contrast the mev model often yielded the highest raws except in six out of twenty seven cases in d2 with 50 splitting percentage at t 10 50 and 100 yr d2 with 75 splitting percentage at t 100 yr and d3 with 50 splitting percentage at both t 50 and 100 yr although the mev model outperformed all other models in terms of the empirical naic this result should be interpreted cautiously due to the observed spuriously high performance of this model in the simulation study the mev model however also yielded the highest uncertainty among all models or higher uncertainty than other models especially the smev based models when comparing the smev and gev based models the smev based models always outperformed from the uncertainty perspective although they overall performed equivalently in fitting efficiency for all datasets therefore the use of the smev based models would be preferable in the ns hfa for fitting purposes as they are advantageous in reducing the uncertainty without degrading the fitting efficiency in particular between the two smev based models the smev 1 0 model which employs the parsimonious nonstationary structure generally led to slightly higher fitting efficiency and lower uncertainty in the frequency estimates furthermore fig 9 displays the empirical naic and raw of the smev and gev based models used for prediction purposes for all datasets at the splitting percentages of 50 and 75 recall that the mev model was excluded due to its incapability to predict beyond the fitting period based on a covariate differing from the assessment for fitting purposes the smev based models consistently yielded lower empirical naic and raw than the gev based models throughout all cases in particular the parsimonious smev 1 0 model produced lower empirical naics in five out of six cases except d3 with a 50 splitting percentage and raw than the smev 1 1 model the overall outperformance of the smev based models in terms of both the fitting efficiency and uncertainty in the prediction assessment confirms their advantage for making out of sample predictions 3 3 the smev based models in the ns hfa and future research recommendations between the non asymptotic mev and smev based models the results from the simulation study for fitting purposes revealed that the smev based models outperformed the mev model in fitting efficiency accuracy and uncertainty except for the empirical naic as discussed previously the conflicting results of the mev model derived based upon the empirical and true naics in the simulation study demonstrated the model s potential to overfit samples thus it is not surprising that the mev model was also found to outperform all other models in terms of the empirical naic in the real applications all these results argue that the mev model might not be preferable in the ns hfa for fitting purposes in addition the lack of an explicit nonstationary structure in the mev model does not allow it to predict out of the sample in the ns hfa therefore the smev based models are preferable over the mev model in the ns hfa both the non asymptotic smev based models and the asymptotic gev based models can incorporate an explicit nonstationary structure as a function of the selected covariate s to depict the nonstationary evolution of extremes when comparing these two models in the fitting assessment the simulation results evidenced that the smev based models were more fitting efficient in terms of true naic and accurate in estimating the quantiles and particularly more favorable from the perspective of uncertainty whereas in the real application the results demonstrated that the smev based models performed equivalently in terms of fitting efficiency and better in terms of uncertainty than the gev based models in addition in the prediction performance assessment both the simulation study and the real application indicated the overall superiority of the smev based models over the gev based models in terms of uncertainty fitting efficiency and accuracy in particular both investigations suggested that the models of parsimonious nonstationary structures i e smev 1 0 and gev 1 0 0 would be preferable for prediction purposes primarily due to their prominently lower uncertainty and often higher fitting efficiency than the other models i e smev 1 1 and gev 1 1 0 although the theoretical asymptotic assumption of n for the gev distribution is often difficult to justify the use of gev based models for both the synthetic and real datasets was supported from the goodness of fit perspective consequently their comparison was considered fair in a practical sense all these results advocate the use of the smev based models can further advance the performance of the ns hfa and the use of the parsimonious smev model would be beneficial in reducing uncertainty in general the uncertainty originated from the parameter estimation due to the limited sample sizes is commonly critical in the ns hfa serinaldi and kilsby 2015 thus compared to the gev based models the enhanced reliability of the smev based models can be ascribed to the increased sample size due to using the ordinary events for the model parameterization it is also worth mentioning that the use of the parsimonious models could deteriorate the models accuracy and fitting efficiency when they cannot adequately capture the nonstationarity although it might be still beneficial in reducing uncertainty e g smev 1 0 in s2 of the simulation study in figs 3 and 4 therefore the selection of an appropriate ns hfa model needs to balance the model s fitting efficiency accuracy and uncertainty it is also worth noting the limitations of this paper and future research recommendations regarding the ordinary events the models were assessed and compared using synthetic and real datasets without significant temporal trends in the n when a trend presents in the n the mev and smev based models could implicitly and explicitly capture it by the block based parametrization and adopting a time variant n i t eq 8 respectively hence further investigations of the impacts of the temporal trend in the n on the mev smev and or gev based models e g potential bias introduction is desired furthermore the synthetic datasets for the simulation study were generated using the values of λ β and n within their commonly reported ranges similar to the λ and β different values of the n have also been reported in different locations marani and ignaccolo 2015 marra et al 2018 miniussi and marani 2020 zorzetto and marani 2020 as the constant n 60 was used in the simulation study a preliminary simulation was conducted to assess the effects of different time invariant values of n but with the same time variant λ and or β the results figs s2 and s3 in the supplementary material demonstrated that the use of different values of n would affect the results quantitively i e the magnitudes of the evaluation metrics but support the overall conclusion namely the smev based models outperformed all other models in general however more elaborated investigations of the variability of the n in different regions as well as its impact on the mev smev and or gev based models performance are recommended regarding the ordinary event types both the mev and smev distributions are capable of accounting for multi type i e mixed events e g dallan et al 2022 marra et al 2021 miniussi et al 2020b 2020a this paper implemented the mev and smev distributions for the ns hfa considering single type events to extend the mev and smev based ns hfa considering multi type events the investigation of potentially different rainfall event types e g considering different linkages with large scale atmospheric patterns and or physical mechanisms which are case specific is desired the assessment of both the mev and smev based models in the context of mixed distributions in the ns hfa is recommended regarding the ns hfa models although this paper demonstrated the superiority of the smev based models there are still opportunities to further generalize their implementation in practice firstly the examination of the smev based models in cases of more complex nonstationary patterns e g non linear of the ordinary events and or nonstationarity in higher order statistical moments of the extremes is recommended this examination can include the effects of indiscriminately using simple linear models under such circumstances however the incorporation of more elaborate characterizations of the nonstationarity may introduce additional uncertainty and thus would require support from a better understanding of the driving mechanisms luke et al 2017 serinaldi et al 2018 serinaldi and kilsby 2015 the association between the nonstationary patterns of ordinary and extreme events which has been acknowledged as complex and difficult to establish marra et al 2019 also requires further investigation secondly in the real applications of this paper the time was adopted as the covariate in the models the use of the temporal i e time and physical covariate s in the ns hfa has been discussed in the literature the general consensus is that the use of physical covariates is commonly hampered by the difficult attribution of the nonstationarity to the physical driver s and their commonly weak to moderate relationships archfield et al 2016 burn and whitfield 2017 easterling et al 2016 slater et al 2021a the nonstationarity attribution and or its improvement is beyond the scope of this paper although it would be beneficial for the ns hfa in general lastly the non asymptotic models are also applicable for other hydrometeorological variables such as streamflow e g miniussi et al 2020a mushtaq et al 2022 and sea level e g caruso and marani 2022 in such applications additional procedures for deriving ordinary events i e conducting the event separation e g decorrelation procedures or determination of the minimum time lag between events among others as well as the identification of a suitable distribution would be needed these additional steps should also be considered by the practitioners when choosing between the non asymptotic and asymptotic models 4 conclusion intending to advance the ns hfa this paper explored the potential of the mev and smev based models in which the ordinary events rather than only the extreme events are employed the implementation of the non asymptotic mev and smev distributions in the context of the ns hfa is very limited so far to the authors best knowledge this paper is the first to comprehensively assess the implementation of these distributions in the ns hfa from the perspectives of fitting efficiency accuracy and uncertainty in addition to facilitate the quantification of uncertainty of the mev and smev based models using the most recently proposed rf pl method this paper introduced their reparametrized log likelihood functions and their left censored versions these non asymptotic models were examined by both a simulation study and real applications using three real rainfall datasets for in sample fitting and out of sample prediction purposes the asymptotic gev based models which rely on the evt and have been widely used in the ns hfa were employed as the benchmark the datasets employed did not present significant temporal trends in the n the synthetic and real ordinary event datasets were generated from and adequately fitted by the weibull distribution with λ and or β linearly changing over time respectively in addition the standardized transformed amss of all the datasets followed the gev distribution all these justified the use of the models examined in this paper the results of the fitting performance assessment in both the simulation study and practical application suggested that the mev model was prone to overfit the samples and had a low fitting efficiency when evaluated based on the true quantiles and low accuracy whereas the smev based models always offered higher accuracy equivalent or better fitting efficiency as well as lower uncertainty than the gev based models in addition the results of the prediction performance assessment in both the simulation and the application studies also revealed that the smev based models were superior to the gev based models as they offered similar or better fitting efficiency higher accuracy and lower uncertainty therefore both the simulation study and the real application evidenced that the smev based models could advance the ns hfa by improving the accuracy and reducing the uncertainty without degrading their fitting efficiency future research on their practical implementations to more complex nonstationary patterns e g non linear and or with a nonstationary n the improvement of the nonstationarity attribution and the extension to other hydrometeorological variables would further promote the smev based models in the ns hfa declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the first author of this paper is funded by a doctoral scholarship from the national council for science and technology of mexico conacyt and the universidad de guadalajara this work is also partially funded by the discovery grant of natural sciences and engineering research council of canada held by the second author data availability the codes of the methods for the mev and smev based models were developed in matlab and are available upon request to the authors supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2022 104244 appendix supplementary materials image application 1 
110,the implementation of nonstationary hydrological frequency analysis ns hfa has often been hampered by the relatively short datasets and the resulting high uncertainty most recently the non asymptotic metastatistical extreme value mev and simplified mev smev distributions which rely on the ordinary events rather than the extremes only have attracted attention in the hfa of both rainfall and streamflow despite their use for trend detection attribution and producing future projections their practical implementation for the ns hfa is absent in the literature this paper therefore implemented these models called mev and smev based models in the ns hfa and comprehensively assessed their performance from the perspectives of fitting efficiency accuracy and uncertainty for both in sample fitting and out of sample prediction purposes the asymptotic models based on the generalized extreme value gev distribution were used as the benchmark the assessment employed synthetic and real rainfall datasets that exhibit stationarity in the number of events per year all the nonstationary ordinary event datasets followed the weibull distribution with linearly changing parameters while their standardized annual maximum series aligned with the gev distribution thus the mev smev and gev based models could be fairly assessed and compared the regula falsi profile likelihood method was extended to quantify the uncertainty of the mev and smev based models the results demonstrated that the mev model was not advantageous over other models in terms of all three evaluation perspectives whereas the smev based models demonstrated superiority due to their higher accuracy equivalent or better fitting efficiency as well as lower uncertainty compared to all other models therefore this paper advocates the use of the smev distribution to advance the ns hfa by harnessing the information from the ordinary events keywords nonstationarity uncertainty ordinary events extreme events metastatistical extreme value distribution simplified metastatistical extreme value distribution 1 introduction the statistical analysis of hydrological extreme events plays a central role in the hydrological risk assessment mitigation and infrastructure design this task is commonly conducted by the hydrological frequency analysis hfa which assesses the recurrence of extreme events based on a probability distribution the hfa conventionally assumes stationarity of the underlying process and thus employs a time invariant distribution however climate change and other changes in the watershed induce nonstationarity in the system and thus such an assumption can be violated aghakouchak et al 2020 blöschl et al 2019 milly et al 2008 papalexiou and montanari 2019 it has been acknowledged that ignoring the nonstationarity in the hfa may provoke underestimation overestimation of the quantiles huang et al 2021 o brien and burn 2014 vu and mishra 2019 as well as accuracy deterioration and uncertainty increase in the analysis vidrio sahagún et al 2021 hence performing the nonstationary hfa ns hfa in which the distribution varies over time according to the selected covariate s becomes indispensable when evidence of nonstationarity presents françois et al 2019 salas et al 2018 in the ns hfa the distribution s variation is governed by the nonstationary structure which commonly expresses the distribution parameters as a function of the covariate s time or physical covariates that vary over time cheng and aghakouchak 2014 o brien and burn 2014 slater et al 2021b the extreme value theory evt provides one of the most popular distribution families employed in the stationary hfa s hfa as well as the ns hfa ossandón et al 2021 papalexiou and koutsoyiannis 2013 yan et al 2021 theoretically the exact distribution of the extremes converges asymptotically to the evt distributions as the number of observations per block tends to infinity coles 2001 katz et al 2002 the evt yields the generalized extreme value gev distribution which combines the three limiting distributions of the block maxima or minima the evt also yields the generalized pareto gp distribution which describes independent events in the tail of the distribution exceeding a sufficiently high threshold provided that the event occurrence process follows the poisson distribution in practice the additional assumption and subjective threshold selection might constrain the implementation of the gp distribution thus the use of the gev distribution in the hfa has been more popular nerantzaki and papalexiou 2021 salas et al 2018 on the other hand the non asymptotic distributions have attracted more attention in the s hfa recently de michele 2019 lombardo et al 2019 marani and ignaccolo 2015 marra et al 2020 unlike the evt based distributions the non asymptotic distributions are advantageous in i exploiting more available information as they use the ordinary events rather than only the extremes ii relaxing the requirement of asymptotic convergence and or iii avoiding the additional assumption of the poisson distributed event arrival as in the gp distribution the non asymptotic distributions have shown superiority in using the available data more efficiently and yielding lower predictive error and estimation uncertainty in the s hfa especially for return periods larger than the sample size de michele and avanzi 2018 marra et al 2018 miniussi et al 2020a miniussi and marani 2020 zorzetto et al 2016 however the implementation of non asymptotic distributions in the context of the ns hfa is very limited in the literature to date the non asymptotic distributions reported in the literature include the compound beta binomial cbb serinaldi et al 2020 the metastatistical extreme value mev marani and ignaccolo 2015 and the simplified mev smev marra et al 2019 distributions the cbb distribution was formulated for serially correlated and stationary processes and has not been extended to nonstationary scenarios to date the mev is a compound distribution that treats both the parameters of the ordinary event distribution and the number of ordinary events per block as stochastic variables this distribution captures the stochastic interannual variability by multiple block based parameterizations and has been argued to be capable of implicitly capturing the potential underlying nonstationarity for instance the mev distribution has been used for detecting and or attributing trends using the series of block based parameter and or quantile estimates e g dallan et al 2022 miniussi and marani 2020 this differs from the common ns hfa in which a nonstationary structure is adopted to deterministically depict the distribution evolution in contrast the smev which is a modified version of the mev distribution is capable of accounting for multiple generating processes and incorporating a nonstationary structure into the distribution for the ns hfa since the smev distribution does not account for stochastic interannual variability its parameterization might be more accurate due to its reduced number of parameters and larger sample size used for the parameterization miniussi and marani 2020 schellander et al 2019 thus in fact the smev essentially corresponds to the distribution of block maxima using the average number of observations per block derived from the theory of order statistics under independence serinaldi et al 2020 to date the smev distribution has been used to produce future projections in nonstationary scenarios by using simplified relationships of the projected changes in the median of rainfall and the number of ordinary events per year with the typical or estimated distribution parameters under stationarity e g marra et al 2019 and 2021 however the smev distribution has not been implemented and assessed in the context of the ns hfa yet i e fitting the nonstationary model to the observations from nonstationary processes the mev and smev distributions are potential alternatives for the ns hfa therefore there is a need for further research on the implementation of these two non asymptotic distributions for the ns hfa moreover the uncertainty is a key aspect in the ns hfa on one hand the hydrometeorological records are often limited and consequently the annual maxima extremes series are usually short the use of short datasets in the ns hfa based on asymptotic distributions would introduce non negligible uncertainty to the analysis the uncertainty is further exacerbated when adopting complex nonstationary structures in the underlying model as a result the uncertainty has overshadowed the benefits of the ns hfa and created an ongoing debate on its practical convenience and feasibility koutsoyiannis and montanari 2015 lins and cohn 2011 milly et al 2015 serinaldi and kilsby 2015 consequently the uncertainty which might hinder the practical application of the ns hfa needs to be reduced for its wide implementation in real practice on the other hand the uncertainty associated with the non asymptotic models has received little attention in the s hfa and of course in the ns hfa so far de michele 2019 pointed out that detailed and thorough investigations on the potential advantages of the non asymptotic models compared to the traditional asymptotic ones in this regard are missing thus such an investigation of the non asymptotic models as well as the comparison with asymptotic models would be desired in the quest of advancing the ns hfa and consequently populating its practical implementation this paper therefore aims to assess the potential of using the non asymptotic distribution derived from the metastatistical approach i e the mev and its simplified version i e the smev in the ns hfa from the perspectives of the uncertainty fitting efficiency and accuracy to the best knowledge of the authors this study is the first of its kind in the field of the ns hfa the non asymptotic distributions were examined using their asymptotic counterpart as the benchmark in the assessment the mev and smev as well as the gev distributions were utilized in the non asymptotic and asymptotic models respectively to fulfill the overarching objective this paper conducted a comparative evaluation of the models under different scenarios of nonstationarity in a simulation study furthermore the practical application of both the non asymptotic and asymptotic models was illustrated using several real rainfall datasets presenting nonstationarity the profile likelihood pl method has shown to be superior to other frequentist methods e g the bootstrap and delta methods in uncertainty estimation due to its higher accuracy and realistic asymmetric estimates bolívar cimé et al 2015 coles 2001 gilleland and katz 2016 obeysekera and salas 2014 hence the regula falsi pl rf pl method vidrio sahagún and he 2022 was extended for the non asymptotic models and employed to estimate the uncertainty herein 2 methodology 2 1 asymptotic models the cumulative gev function of the random variable y which corresponds to the annual maxima of n ordinary events x at every year i e y max x 1 xn is defined as 1 f y θ f y ξ α κ exp 1 κ y ξ α 1 κ κ 0 exp exp y ξ α κ 0 where the parameter vector θ is composed of κ α and ξ namely the shape scale and location parameters respectively the tail behavior of the distribution is described by κ and the gev is categorized into three subfamilies extreme value ev type i distribution when κ 0 ev type ii which is the heavy tailed case when κ 0 and ev type iii which is the upper bounded case when κ 0 the probability density of the gev distribution can be found in the literature e g coles 2001 hosking and wallis 2009 the quantile estimate yt i e the magnitude associated with the return period t 1 p where p is the exceedance probability i e p 1 f y θ is given by 2 y t f y 1 p θ ξ α κ 1 log 1 p κ κ 0 ξ α log log 1 p κ 0 under nonstationarity the distribution is allowed to vary over time by using the covariate dependent distribution parameters in this paper two ns hfa models based on the gev distribution were considered namely the gev distribution with two different nonstationary structures in which the location parameter ξ v and both the location and scale parameters ξ v and α v change as a linear function of the covariate v respectively the κ was assumed constant considering its difficult estimation due to the constraint in the data length and consequently its unrealistic time variant characterization coles 2001 salas et al 2018 these linear nonstationary models were adopted following the principle of parsimony namely favoring simple rather than complex models chebana and ouarda 2021 koutsoyiannis 2016 serago and vogel 2018 these nonstationary models are denoted as gev 1 0 0 and gev 1 1 0 respectively and are given by 3 g e v 1 0 0 g e v ξ v α κ ξ v ξ 0 ξ 1 v α c o n s t a n t κ c o n s t a n t 4 g e v 1 1 0 g e v ξ v α v κ ξ v ξ 0 ξ 1 v α v α 0 α 1 v κ c o n s t a n t where ξ 0 and ξ 1 and α 0 and α 1 are the regression coefficients of the location and scale parameters respectively 2 2 non asymptotic models the mev distribution marani and ignaccolo 2015 treats the parameter vector θ of the distribution depicting the ordinary events x and the number of x occurrences per block n as stochastic variables the mev cumulative distribution is defined as 5 ψ m e v x n ω θ f x θ n g n θ d θ where ωθ is the parameter space g n θ is the joint probability distribution of n and θ discrete in n and continuous in θ respectively and f x θ is the cumulative distribution of x the weibull distribution has been commonly adopted for f x θ in the literature formetta et al 2022 marani and ignaccolo 2015 miniussi et al 2020b miniussi and marani 2020 miniussi and marra 2021 schellander et al 2019 zorzetto et al 2016 the popularity of this choice is supported by the physical justification that the right tail of the daily rainfall distribution is stretched exponential wilson and toumi 2005 this choice is also coherent with serinaldi and kilsby 2014 and de michele and avanzi 2018 for practical applications the mev distribution has been approximated by its expectation using the sample average computed over the observational period by zorzetto et al 2016 6 ψ m e v x 1 m j 1 m f x θ j n j 1 m j 1 m 1 exp x λ j β j n j where m is the length of the sample in years the parameter vector θ is composed of λ and β which are the scale and shape parameters of the weibull distribution respectively and θ j and nj are the θ and n in the jth block year respectively the probability density of the mev distribution is thus given by 7 ψ m e v x d ψ m e v x d x 1 m j 1 m d f x θ j n j d x 1 m j 1 m n j f x θ j f x θ j n j 1 1 m j 1 m n j β j λ j x λ j β 1 exp x λ j β j 1 exp x λ j β j n j 1 the extreme event quantile estimate ψ m e v 1 x equivalent to yt is numerically estimated by finding the xt that satisfy ψ mev xt 1 p as the mev distribution can only implicitly capture the nonstationarity by its block based parameterization the set of annual mev distributions was utilized in this paper this approach has been previously used for long term trend detection and or attribution in hydrometeorological datasets dallan et al 2022 miniussi and marani 2020 as each block is defined according to the year t this model is denoted herein as m e v m e v λ t β t n t in the smev distribution the interannual variability of f x θ and n are neglected and the temporal dependence of the distribution parameters can be deterministically described marra et al 2019 its cumulative distribution is given by 8 ψ s m e v x t i 1 s f i x θ i t n i t i 1 s 1 exp x λ i t β i t n i t where s is the number of different types of x which is set to 1 in this paper θ i t λ i t β i t is the time dependent θ of the ith x type and n i t is the time variant average n of the ith x type it has been shown by both theoretical analysis and simulation studies that neglecting the fluctuations of n with n i produces a negligible impact on the estimates miniussi and marani 2020 the probability density of the smev distribution ψ s m e v x t and the extreme event quantile estimate ψ s m e v 1 x t are thus given by 9 ψ s m e v x t d ψ s m e v x t d x d f x θ t n t d x n t f x θ t f x θ t n t 1 n t β t λ t x λ t β t 1 exp x λ t β t 1 exp x λ t β t n t 1 10 ψ s m e v 1 x t λ t log 1 1 p 1 n t 1 β t under nonstationarity the smev distribution is allowed to vary over time by using the covariate dependent distribution parameters similar to the asymptotic models the smev models adopted parsimonious linear nonstationary structures in which the scale parameter λ v and both the scale and shape parameters λ v and β v are expressed as linear functions of the covariate v in this paper the smev based models adopted a constant n in alignment with the absence of significant temporal trends in the n of all the datasets analyzed here these ns hfa models are denoted as smev 1 0 and smev 1 1 respectively and are given by 11 s m e v 1 0 s m e v λ v β n λ v λ 0 λ 1 v β constant n constant 12 s m e v 1 1 s m e v λ v β v n λ v λ 0 λ 1 v β v β 0 β 1 v n constant 2 3 parameter estimation and uncertainty quantification the estimation of both the distribution parameters and the uncertainty was conducted based upon the likelihood namely by the maximum likelihood estimator mle and the rf pl method the rf pl method is the advanced pl method which reduces its computational burden vidrio sahagún and he 2022 the likelihood is the joint probability of the observations either y t y 1 ym or x t i x 1 1 x n m given a certain θ in practice it is more convenient and easier to use the log likelihood ℓ θ than the likelihood l θ due to its tractability in the optimization procedure katz 2013 the ℓ θ function for the independent but not necessarily identically distributed random variables yt and x t i are 13 ℓ θ log l θ t 1 m log f y t θ 14 ℓ θ log l θ t 1 m i 1 n log f x t i θ respectively where f yt θ and f x t i θ are the probability density functions of the annual maxima and ordinary events respectively and n is the number of events per block and its average for the mev and smev distributions respectively similarly the ℓ θ function of the mev and smev distributions is given by 15 ℓ θ log l θ t 1 m log ψ y t θ where ψ y t θ is the mev or smev probability density function of the extremes derived from the ordinary events the mle of θ denoted as θ is the parameter vector that maximizes ℓ θ i e 16 θ arg max θ θ ℓ θ the θ is estimated using the log likelihood functions of eqs 13 and 14 for the gev based models and both the mev and smev based models respectively the profile likelihood for a target parameter component θ j denoted as ℓ p θ j is derived from the log likelihood function maximized with respect to all other parameter components of θ i e θ j and is defined as coles 2001 17 ℓ p θ j max θ j ℓ θ j θ j then the obtained ℓ p θ j is used to approximate the 100 1 ρ confidence interval c ρ of θ j defined as coles 2001 18 c ρ θ j 2 ℓ θ ℓ p θ j q 1 ρ where ρ is the significance level 0 05 herein and q 1 ρ is the 1 ρ quantile of the chi square distribution with one degree of freedom χ 1 2 in the rf pl method θ j can be a quantile y t t k x t t k associated with the effective return level t at a given point in time tk of the properly reparametrized log likelihood function such reparameterization is obtained by substituting the re arranged quantile expression of the corresponding model into ℓ θ to incorporate y t t k x t t k as a model parameter refer to vidrio sahagún and he 2022 for more details the reparametrized log likelihood functions of the gev 1 0 0 and gev 1 1 0 models can be found in vidrio sahagún and he 2022 whereas those for both the mev and smev based models are not available yet and thus the rf pl method is not readily applicable to these models hence the reparametrized log likelihood functions of the mev smev 1 0 and smev 1 1 models were introduced in this paper and are given for each model by 19 ℓ x t t k β t t 1 m i 1 n log β t log 1 1 p 1 n t 1 β t x t t k log x t i log 1 1 p 1 n t 1 β t x t t k β t 1 x t i log 1 1 p 1 n t 1 β t x t t k β t 20 ℓ x t t k λ 1 β t 1 m i 1 n log β x t t k log 1 1 p 1 n t 1 β λ 1 t t k log x t i x t t k log 1 1 p 1 n t 1 β λ 1 t t k β 1 x t i x t t k log 1 1 p 1 n t 1 β λ 1 t t k β 21 ℓ x t t k λ 1 β 0 β 1 t 1 m i 1 n log β 0 β 1 t x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k log x t i x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t 1 x t i x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t moreover the practical applications of the non asymptotic models in the s hfa have shown that the ordinary events of lower magnitude negatively impact the evaluation of the distribution s right tail by diverging the estimates marra et al 2019 miniussi and marra 2021 this issue has been solved by left censoring namely ignoring the magnitudes of the small ordinary events while retaining their existence in the distribution marra et al 2019 2020 unlike the gp distribution the mev and smev distributions can account for ordinary events rather than only the extremes and do not require any assumption on the event arrival process marra et al 2020 the left censoring of the ordinary events can be also incorporated into the mle and rf pl methods for parameter estimation and uncertainty quantification respectively to this end the left censored version of the log likelihood function cohn 2005 helsel 2011 of the ordinary event distribution eq 14 was adopted when dealing with real datasets 22 ℓ θ l c log l θ l c t 1 m i 1 n δ t i log f x t i θ t 1 m i 1 n 1 δ t i log f τ t r θ where τ t r is the left censor threshold set at the rth quantile of the ordinary events at time t and δ t i is the indicator variable taking the values of 1 and 0 when x t i exceeds and does not exceed the τ t r respectively the threshold selection is case specific and has been determined by scrutiny often optimizing some relevant metric formetta et al 2022 marra et al 2019 2020 miniussi and marra 2021 in this paper the threshold was selected such that the fitting efficiency was maximized while the suitability of the weibull distribution for characterizing the ordinary events was guaranteed the reparametrized log likelihood functions with left censoring of the mev smev 1 0 and smev 1 1 models are thus expressed for each model as 23 ℓ x t t k β t t 1 m i 1 n δ t i log β t log 1 1 p 1 n t 1 β t x t t k log x t i log 1 1 p 1 n t 1 β t x t t k β t 1 x t i log 1 1 p 1 n t 1 β t x t t k β t t 1 m i 1 n 1 δ t i log 1 exp τ t r x t t k log 1 1 p 1 n t 1 β t β t 24 ℓ x t t k λ 1 β t 1 m i 1 n δ t i log β x t t k log 1 1 p 1 n t 1 β λ 1 t t k log x t i x t t k log 1 1 p 1 n t 1 β λ 1 t t k β 1 x t i x t t k log 1 1 p 1 n t 1 β λ 1 t t k β t 1 m i 1 n 1 δ t i log 1 exp τ t r x t t k log 1 1 p 1 n t 1 β λ 1 t t k β 25 ℓ x t t k λ 1 β 0 β 1 t 1 m i 1 n δ t i log β 0 β 1 t x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k log x t i x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t 1 x t i x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t t 1 m i 1 n 1 δ t i log 1 exp τ t r x t t k log 1 1 p 1 n t 1 β 0 β 1 t k λ 1 t t k β 0 β 1 t 2 4 model evaluation the model performance was assessed from several perspectives including the fitting efficiency accuracy and uncertainty the akaike information criterion aic which deals with the trade off between the goodness of fit and complexity of a model was used to assess the fitting efficiency the normalized aic naic was used to facilitate the examination of aics among different sample sizes the relative root mean square error rrmse was also used to assess the accuracy of the estimates in which the true quantiles are known a priori these two metrics are calculated as 26 n a i c 2 ℓ θ 2 d m 27 r r m s e 1 m t 1 m r t t p t t r t t 2 where d is the number of parameters of the ns hfa model ℓ θ is calculated by eqs 13 and 15 for the gev based and both mev and smev based models respectively and r t t and p t t are the true and the estimated quantiles associated with t at time t respectively a model of smaller values of naic and rrmse are of higher fitting efficiency and accuracy respectively the uncertainty was quantified using the relative average bandwidth raw and the relative coverage width index rcwi kasiviswanathan et al 2019 of the confidence intervals the rcwi combines the raw and the percentage of coverage poc of the confidence intervals which conflict with each other these metrics are given by 28 r a w 1 m t 1 m p t t u p t t l p t t 29 p o c 1 m t 1 m c t t w h e r e c t t 1 t s t p t t l r t t p t t u 0 elsewhere 30 r c w i r a w exp 1 α c w i p o c 100 2 where p t t u and p t t l are the upper and lower uncertainty bounds at t and t respectively and α cwi is the significance level 0 05 note that similarly to the rrmse the calculations of the poc and rcwi require knowing the true quantiles a model of smaller values of raw and rcwi is less uncertain 2 5 simulation study a simulation study was conducted to compare the asymptotic and non asymptotic ns hfa models using synthetic ordinary event datasets with a priori known statistical properties the synthetic datasets were generated by randomly sampling the quantile function of the weibull distribution in three different scenarios of nonstationarity in scenarios 1 s1 2 s2 and 3 s3 the nonstationarity was introduced in λ in β and in both λ and β of the ordinary event distributions respectively by 31 s 1 x v w e i b u l l λ v β 0 w h e r e λ v λ 0 λ 1 v β 0 constant 32 s 2 x v w e i b u l l λ 0 β v w h e r e λ 0 constant β v β 0 β 1 v 33 s 3 x v w e i b u l l λ v β v w h e r e λ v λ 0 λ 1 2 v β v β 0 β 1 2 v where the covariate v monotonically and linearly increases over time and λ 0 10 λ 1 0 1 β 0 0 8 and β 1 0 002 such that both λ v and β v are always within their commonly reported ranges of 0 5 β v 0 8 and 10 λ v 25 marani and ignaccolo 2015 marra et al 2018 2019 2020 the decrease of β v implies a heavier tail of the ordinary event distribution along with the increase of the covariate v the increase of λ v implies a wider ordinary event distribution along with the increase of v the evolutions of both the densities and quantiles of the distributions employed for generating the datasets in the s1 s2 and s3 are presented in fig 1 the use of λ 1 2 and β 1 2 in s3 was determined to ensure equivalent increases in the distribution quantiles from which the generated datasets were sampled in the three scenarios fig 1 b and avoid numerical problems in the following analyses due to extremely high values two record lengths of synthetic datasets were explored namely m 50 and 100 years the number of events per year was fixed to n 60 which is also in its common range reported in several previous studies marani and ignaccolo 2015 marra et al 2018 miniussi and marani 2020 zorzetto and marani 2020 and consistent with the average n of the real rainfall datasets employed in this paper the simulation study only used generated ordinary event datasets whose annual maximum series ams were verified to be successfully captured by the gev based ns hfa models to this end the two sample kolmogorov smirnov ks test and the modified anderson darling mad test were employed the critical values for the mad test were determined by monte carlo simulation see ahmad et al 1988 shin et al 2012 these two statistical tests complement each other as the ks and mad assess the agreement of the empirical and the assumed distributions in their whole and particularly in their upper tails respectively owing to the lack of homogeneity in the distributional assumption the standard transformation was applied to the nonstationary ams using the corresponding reference model coles 2001 ragno et al 2019 all the generated datasets were also verified to present significant temporal trends by the mann kendall test all the statistical tests were conducted at the 0 05 significance level in this simulation study 1000 datasets were generated for each nonstationary scenario and each record length and thus a total of 6000 datasets were employed the asymptotic and non asymptotic ns hfa models were assessed in two different contexts namely for in sample fitting and out of sample prediction purposes the fitting performance assessment evaluated the models capabilities to depict the extremes in the historical period in which the models were parameterized the model accuracy and uncertainty were assessed using the rrmse as well as the raw and rcwi respectively at t 10 50 and 100 yr the naic was used to evaluate the fitting efficiency of the models to capture both the sample amss and the underlying nonstationary stochastic process of the extreme events to this end the naic was derived in two different ways namely using the available ams and 100 true quantiles derived from the true nonstationary distribution of the extremes with equally spaced exceedance probability at each time slice respectively these two naics were called empirical naic and true naic throughout this paper note that only the empirical naic can be estimated in real practice due to the lack of knowledge of the stochastic process of extremes and thus the true quantiles the true quantiles required for calculating the true naic rrmse and rcwi were derived for each nonstationary scenario by monte carlo simulation as in the previous s hfa simulation studies using the mev distribution marani and ignaccolo 2015 marra et al 2018 firstly 1 107 blocks with n ordinary events each were generated from the weibull distribution with the corresponding values of θ v at a given time slice tk the annual maximum was then extracted from each simulated block this is equivalent to having 1 107 realizations from the nonstationary extreme event stochastic process at tk the t year extreme event quantiles were derived from this large sample of block maxima using the weibull plotting position formula these steps were repeated for each tk of interest furthermore the predictive performance assessment evaluated the skills of the models fitted to historical observations for predicting the extreme event quantiles in the future this assessment employed the true naic the rrmse and the rcwi as evaluation metrics in this simulation study a fixed length of 50 years in the future was adopted regardless of the m used for the model parameterization 2 6 application on real datasets three real rainfall datasets from mexico were employed to assess the non asymptotic and asymptotic ns hfa models these datasets were retrieved from the hydrometeorological stations of león dge conagua 11095 los castillos conagua 11040 and abasolo conagua 11001 these datasets have record lengths of 72 72 and 70 years and are referred to as d1 d2 and d3 respectively throughout this paper the selected datasets have year round measurements without missing data except for two and one complete years 1950 and 1958 and 1950 in d1 and d2 respectively the mann kendall trend test was applied to the ams and the number of ordinary events per year n and per season of the datasets at a significance level of 0 05 the four seasons were defined as winter december february spring march may summer june august and autumn september november as illustrated in fig 2 the datasets d1 d2 and d3 exhibit significant temporal trends in the mean of their amss these significant long term trends are indicative of the presence of nonstationarity in extreme rainfall events in contrast no significant temporal trends were detected in the number of ordinary events at both the annual scale fig 2 and seasonal scales fig s1 in the supplementary material of the datasets in this practical application all the non asymptotic mev smev 1 0 and smev 1 1 and asymptotic gev 1 0 0 and gev 1 1 0 ns hfa models were employed the temporal covariate i e v time which has been commonly used to surrogate any time dependent physical driver s in the ns hfa literature kjeldsen and prosdocimi 2021 obeysekera and salas 2016 serago and vogel 2018 sun et al 2018 was adopted in the gev and smev based models besides the mad and ks tests were used to verify the suitability of the gev based models as in the simulation study whereas the conventional ks test which easily handles the left censored datasets was employed to verify that the mev and smev based models properly fit the ordinary events on an annual basis the datasets were split into two sub samples for the fitting and predictive performance assessments under nonstationarity the underlying stochastic process varies over time as a result the two sub samples were not generated by sampling randomly but by dividing the historical period into two continuous periods to preserve the temporal dependence the first part of the observations was used to evaluate the fitting performance of the models while the rest of the observations were used for the prediction performance assessment in these assessments the datasets were split at two percentages namely 50 and 75 in addition the full sample i e the splitting percentage of 100 was also considered in the fitting performance assessment this case is equivalent to using all the data for the model parameterization without evaluating the prediction performance this has been the common practice in the ns hfa e g agilan and umamahesh 2017 hesarkazzazi et al 2021 lee et al 2020 ouarda et al 2018 prosdocimi et al 2015 as the dataset splitting reduces the sample size for the model parameterization and thus decreases the model s reliability the performance assessments of the models were conducted using the empirical naic and raw only due to the lack of knowledge of the true quantiles to derive the true naic rrmse and rcwi 3 results and discussion 3 1 simulation study 3 1 1 performance in the context of fitting purposes fig 3 presents the fitting efficiency empirical and true naics and accuracy rrmse of the asymptotic and non asymptotic ns hfa models employed for fitting purposes as shown in fig 3 a the mev model fitted the sample amss more efficiently than the smev and gev based models in all three scenarios and both ms as indicated by its lower empirical naics in addition the mev model yielded slightly narrower interquartile and full ranges of the empirical naic the smev and gev based models performed equivalently in general as their empirical naics and their interquartile and full ranges appeared to be equivalent in all three scenarios and both ms in contrast when comparing the models in terms of true naic fig 3 b the mev model was the least fitting efficient overall in all scenarios and ms among all models the mev model resulted in higher true naics and wider interquartile ranges of true naic than the smev and gev based models did except that the gev based models produced the highest maximum true naics in all three scenarios when m 50 compared to the gev based models the smev based models had higher fitting efficiency as they produced lower true naics and narrower interquartile and full ranges of true naic furthermore figs 3 c e present the rrmse of the quantile estimates at the selected ts as shown in these figures the smev based models smev 1 0 and or smev 1 1 yielded lower rrmses and narrower interquartile and full ranges of the rrmse than all other models in all scenarios and ms only when m 100 in s2 smev 1 1 yielded the highest maximum rrmses among the models the mev model had higher rrmses than the gev based models although its full ranges of the rrmse were narrower notably contrasting results were obtained when comparing the fitting efficiency of the models namely the mev model outperformed the smev and gev based models in terms of the empirical naic whereas the smev and gev based models were superior to the mev model in terms of the true naic these results suggest that the mev model might be prone to overfitting this could be ascribed to the block based parameterization of the mev model which would lead to overfitting the samples hence capturing the nonstationarity of extreme events by the stochastic interannual variability rather than by a deterministic time dependent component would be counterproductive due to this fact the mev model might not be preferable over all other models under nonstationary conditions the smev based models were demonstrated to be equivalent and superior to the gev based models in terms of the empirical and true naics respectively moreover the smev based models were also overall more robust than the asymptotic gev based models as shown by their narrower and equivalent variation ranges of true naic and empirical naic respectively therefore the non asymptotic smev based models were superior to the asymptotic gev based models in fitting efficiency furthermore the smev based models achieved overall better accuracy and higher robustness narrower variation ranges of rrmse than all other models for the 10 50 and 100 yr quantile estimates the few very high rrmses produced by the smev 1 1 model when m 100 in s2 would be ascribed to the difficult estimation of the evolution of β over time in a few cases especially when β takes relatively small values i e approaching to the lower bound of its range 0 6 0 8 at the end of the fitting period corresponding to high skewness thus these evaluations of both the fitting efficiency and accuracy advocate the superiority of the smev based models fig 4 presents the uncertainty raw and rcwi of the asymptotic and non asymptotic ns hfa models at the selected ts as shown in this figure the smev based models consistently yielded the lowest raw and rcwi and narrowest interquartile and full ranges of these two metrics irrespective of nonstationary scenarios ms and ts in addition the gev based models produced lower raw and rcwi than the mev model but with wider interquartile and full ranges of both metrics in all the simulation cases whereas the gev based models often produced the highest maximum raw and rcwi when m 50 except in the raw in s1 thus the smev based models were superior to all other models from the perspective of uncertainty the asymptotic models also presented a steeper increase in both the raw and rcwi along with the increase of the t than the non asymptotic models in addition the results demonstrated that the increase of the m generally reduced the uncertainty of both the smev and gev based models in all cases however such a result was not obtained for the mev model for instance the rcwis and raws of the mev model in s2 and s3 did not decrease with the increase of the m similar to the model evaluation in terms of the fitting efficiency and accuracy the assessment from the uncertainty point of view showed prominent superiority of the smev based models over all other models the reduced uncertainty of the smev based models would be primarily ascribed to the increased sample size due to the use of ordinary events for estimating the distribution parameters however the increased sample size did not result in a decrease in the uncertainty of the mev model the high uncertainty yielded by the mev model could be ascribed to the relatively small sample size used for the block based parameterization as well as the larger number of parameters needed for its implementation one set per block the disadvantage of the mev model from the uncertainty perspective further argues that the implementation of this model might not be promising for the ns hfa in particular the superiority of the smev based models compared to the gev based models becomes more prominent as the t increases which is consistent with previous findings for the s hfa e g schellander et al 2019 besides the smev based models were also more robust than their asymptotic counterparts as reflected by their narrower variation ranges of the raw and rcwi all these results demonstrated that the smev based models outperformed the mev and the gev based models in the ns hfa from all three evaluation perspectives including the fitting efficiency accuracy and uncertainty for the fitting purposes thus the non asymptotic approach especially the smev based models could potentially advance the ns hfa in improving their overall performance by harnessing the information of the ordinary events 3 1 2 performance in the context of predictive purposes in this evaluation the mev model was excluded due to its lack of a nonstationary structure and thus its incapability of making predictions beyond the fitting period based upon the covariate fig 5 presents the fitting efficiency true naic and accuracy rrmse of the gev based and smev based models for prediction purposes the empirical naic was not assessed because the objective of the ns hfa is to predict the true quantiles in the future as shown in fig 5 the smev based models smev 1 0 and or smev 1 1 often yielded lower true naics and rrmses as well as narrower interquartile and full ranges of true naic and rrmse than the gev based models in particular smev 1 0 and smev 1 1 whose nonstationary structures align with the data generation of s1 and s2 s3 respectively outperformed the rest of the models namely the smev 1 0 was superior to all other models in s1 while the smev 1 1 outperformed or were equivalent to all other models in s2 and s3 except the maximum rrmses in s2 as aforementioned the highest maximum rrmses of smev 1 1 in s2 might be ascribed to the difficulty in estimating β and its temporal changes unlike smev 1 0 in which β is constant thus in general the smev based models outperformed the gev based models in terms of fitting efficiency and accuracy for prediction purposes as well moreover the results demonstrated that the smev based models also present an overall benefit in robustness especially in s1 as well as s3 to some extent however the superiority of the smev based models was not apparent or absent in s2 when m 50 particularly the nonstationary structure seems to play a major role in s2 as the use of different nonstationary structures in the smev based led to substantially different performance for instance when m 100 and t 10 yr the smev 1 1 and smev 1 0 models were overall the most and least accurate in s2 respectively among all the models thus the nonstationary structure may be especially critical in the smev based models for predictive tasks from the viewpoint of accuracy sometimes despite these exceptions the smev based models seem to be the preferable option for prediction purposes in general fig 6 shows the uncertainty raw and rcwi of the smev and gev based models as illustrated in this figure the smev and gev based models of simpler nonstationary structures i e smev 1 0 and gev 1 0 0 produced lower raws and rcwis than their more complex counterparts i e smev 1 1 and gev 1 1 0 the smev 1 0 model yielded the lowest raws and rcwis as well as the narrowest interquartile and full ranges of raw and rcwi among all models however unlike the evaluation for fitting purposes fig 4 the smev 1 1 did not always yield lower raws and rcwis and narrower interquartile and full ranges of these metrics than the gev based models for instance the smev 1 1 generally produced higher raws and rcwis than gev 1 0 0 in all scenarios for t 10 yr and s2 for t 50 yr nonetheless the smev 1 1 overall presented lower raws and rcwis than the gev based models in the three scenarios for t 100 yr and s1 and s3 for t 50 yr moreover the smev 1 0 model produced the narrowest interquartile and full ranges of raw and rcwi while smev 1 1 yielded narrower or similar interquartile and full ranges than the gev based models for the three scenarios of t 50 and 100 yr in general the gev based models produced exceptionally high maximum values of rcwi especially when m 50 in addition the uncertainty was higher when performing prediction fig 6 than when performing fitting tasks fig 4 in particular the smev based and gev based models with more parameters i e smev 1 1 and gev 1 1 0 showed the largest uncertainty increase among the non asymptotic and asymptotic models respectively for instance the average median raw of the three scenarios of smev 1 0 smev 1 1 gev 1 0 0 and gev 1 1 0 increased by 0 120 0 479 0 108 and 0 374 respectively for m 50 and t 100 yr the lower uncertainty of the simpler smev based and gev based models i e with the smaller number of distribution parameters is consistent with the notion that adding more parameters to the ns hfa models would increase the prediction uncertainty for equivalent model complexity i e smev 1 0 and gev 1 0 0 or smev 1 1 and gev 1 1 0 which have four and five parameters respectively the smev based models showed their superiority in terms of uncertainty besides the smev based models offered similar or better robustness than the gev based models therefore all these results support the preference of the smev based models over the gev based ones for predicting future quantiles with less uncertainty the results indicate that the advantage of the smev based models is particularly more prominent for higher ts the superiority of the smev based models from the uncertainty perspective as well as from the fitting efficiency and accuracy perspectives advocates their preference for prediction purposes in the ns hfa moreover the smaller increases in the uncertainty of the models with parsimonious nonstationary structures in the prediction relative to the fitting also suggest that their use is preferable from the uncertainty viewpoint 3 2 illustrative application on real datasets in the non asymptotic ns hfa models the τ t r was set at the 30th 50th and 50th quantiles of the ordinary events for d1 d2 and d3 respectively after scrutiny these selections maximized the empirical naic in the fitting periods at the three splitting percentages and ensured the suitability of the weibull distribution all the asymptotic and non asymptotic models were confirmed to be statistically significant appropriate for d1 d2 and d3 by the ks and mad tests besides the absence of significant temporal trends in n fig 2 supported the use of a time invariant n in the smev based models for these datasets fig 7 shows the frequency curves at the last year of record of the mev model the optimal smev based models i e smev 1 0 smev 1 0 and smev 1 1 for d1 d2 and d3 respectively and the optimal gev based models i e gev 1 1 0 gev 1 0 0 and gev 1 1 0 for d1 d2 and d3 respectively in terms of empirical naic when 100 of data were used for the parameterization as shown in fig 7 for all three datasets the optimal smev based models consistently yielded the least uncertainty in the frequency estimates among the three models while the optimal gev based models were superior to the mev model in this aspect it is apparent that the advantage of the smev based models was more prominent at the higher ts as the enlargement of their confidence intervals with the increase of t is much less compared to that of the gev based models fig 8 presents the empirical naic and raw at the three ts of all the models used for fitting purposes for all datasets and splitting percentages the solid and dashed black boxes highlight the best and second best models among all in each case respectively on one hand the mev models consistently yielded the lowest empirical naics throughout all cases fig 8 a the smev and gev based models produced similar empirical naics in general although the gev based models often yielded the second lowest empirical naics on the other hand the smev based models always produced lower raws than the mev and gev based models in all cases figs 8 b d in particular the parsimonious smev based model i e smev 1 0 always produced the lowest raws among all the models in contrast the mev model often yielded the highest raws except in six out of twenty seven cases in d2 with 50 splitting percentage at t 10 50 and 100 yr d2 with 75 splitting percentage at t 100 yr and d3 with 50 splitting percentage at both t 50 and 100 yr although the mev model outperformed all other models in terms of the empirical naic this result should be interpreted cautiously due to the observed spuriously high performance of this model in the simulation study the mev model however also yielded the highest uncertainty among all models or higher uncertainty than other models especially the smev based models when comparing the smev and gev based models the smev based models always outperformed from the uncertainty perspective although they overall performed equivalently in fitting efficiency for all datasets therefore the use of the smev based models would be preferable in the ns hfa for fitting purposes as they are advantageous in reducing the uncertainty without degrading the fitting efficiency in particular between the two smev based models the smev 1 0 model which employs the parsimonious nonstationary structure generally led to slightly higher fitting efficiency and lower uncertainty in the frequency estimates furthermore fig 9 displays the empirical naic and raw of the smev and gev based models used for prediction purposes for all datasets at the splitting percentages of 50 and 75 recall that the mev model was excluded due to its incapability to predict beyond the fitting period based on a covariate differing from the assessment for fitting purposes the smev based models consistently yielded lower empirical naic and raw than the gev based models throughout all cases in particular the parsimonious smev 1 0 model produced lower empirical naics in five out of six cases except d3 with a 50 splitting percentage and raw than the smev 1 1 model the overall outperformance of the smev based models in terms of both the fitting efficiency and uncertainty in the prediction assessment confirms their advantage for making out of sample predictions 3 3 the smev based models in the ns hfa and future research recommendations between the non asymptotic mev and smev based models the results from the simulation study for fitting purposes revealed that the smev based models outperformed the mev model in fitting efficiency accuracy and uncertainty except for the empirical naic as discussed previously the conflicting results of the mev model derived based upon the empirical and true naics in the simulation study demonstrated the model s potential to overfit samples thus it is not surprising that the mev model was also found to outperform all other models in terms of the empirical naic in the real applications all these results argue that the mev model might not be preferable in the ns hfa for fitting purposes in addition the lack of an explicit nonstationary structure in the mev model does not allow it to predict out of the sample in the ns hfa therefore the smev based models are preferable over the mev model in the ns hfa both the non asymptotic smev based models and the asymptotic gev based models can incorporate an explicit nonstationary structure as a function of the selected covariate s to depict the nonstationary evolution of extremes when comparing these two models in the fitting assessment the simulation results evidenced that the smev based models were more fitting efficient in terms of true naic and accurate in estimating the quantiles and particularly more favorable from the perspective of uncertainty whereas in the real application the results demonstrated that the smev based models performed equivalently in terms of fitting efficiency and better in terms of uncertainty than the gev based models in addition in the prediction performance assessment both the simulation study and the real application indicated the overall superiority of the smev based models over the gev based models in terms of uncertainty fitting efficiency and accuracy in particular both investigations suggested that the models of parsimonious nonstationary structures i e smev 1 0 and gev 1 0 0 would be preferable for prediction purposes primarily due to their prominently lower uncertainty and often higher fitting efficiency than the other models i e smev 1 1 and gev 1 1 0 although the theoretical asymptotic assumption of n for the gev distribution is often difficult to justify the use of gev based models for both the synthetic and real datasets was supported from the goodness of fit perspective consequently their comparison was considered fair in a practical sense all these results advocate the use of the smev based models can further advance the performance of the ns hfa and the use of the parsimonious smev model would be beneficial in reducing uncertainty in general the uncertainty originated from the parameter estimation due to the limited sample sizes is commonly critical in the ns hfa serinaldi and kilsby 2015 thus compared to the gev based models the enhanced reliability of the smev based models can be ascribed to the increased sample size due to using the ordinary events for the model parameterization it is also worth mentioning that the use of the parsimonious models could deteriorate the models accuracy and fitting efficiency when they cannot adequately capture the nonstationarity although it might be still beneficial in reducing uncertainty e g smev 1 0 in s2 of the simulation study in figs 3 and 4 therefore the selection of an appropriate ns hfa model needs to balance the model s fitting efficiency accuracy and uncertainty it is also worth noting the limitations of this paper and future research recommendations regarding the ordinary events the models were assessed and compared using synthetic and real datasets without significant temporal trends in the n when a trend presents in the n the mev and smev based models could implicitly and explicitly capture it by the block based parametrization and adopting a time variant n i t eq 8 respectively hence further investigations of the impacts of the temporal trend in the n on the mev smev and or gev based models e g potential bias introduction is desired furthermore the synthetic datasets for the simulation study were generated using the values of λ β and n within their commonly reported ranges similar to the λ and β different values of the n have also been reported in different locations marani and ignaccolo 2015 marra et al 2018 miniussi and marani 2020 zorzetto and marani 2020 as the constant n 60 was used in the simulation study a preliminary simulation was conducted to assess the effects of different time invariant values of n but with the same time variant λ and or β the results figs s2 and s3 in the supplementary material demonstrated that the use of different values of n would affect the results quantitively i e the magnitudes of the evaluation metrics but support the overall conclusion namely the smev based models outperformed all other models in general however more elaborated investigations of the variability of the n in different regions as well as its impact on the mev smev and or gev based models performance are recommended regarding the ordinary event types both the mev and smev distributions are capable of accounting for multi type i e mixed events e g dallan et al 2022 marra et al 2021 miniussi et al 2020b 2020a this paper implemented the mev and smev distributions for the ns hfa considering single type events to extend the mev and smev based ns hfa considering multi type events the investigation of potentially different rainfall event types e g considering different linkages with large scale atmospheric patterns and or physical mechanisms which are case specific is desired the assessment of both the mev and smev based models in the context of mixed distributions in the ns hfa is recommended regarding the ns hfa models although this paper demonstrated the superiority of the smev based models there are still opportunities to further generalize their implementation in practice firstly the examination of the smev based models in cases of more complex nonstationary patterns e g non linear of the ordinary events and or nonstationarity in higher order statistical moments of the extremes is recommended this examination can include the effects of indiscriminately using simple linear models under such circumstances however the incorporation of more elaborate characterizations of the nonstationarity may introduce additional uncertainty and thus would require support from a better understanding of the driving mechanisms luke et al 2017 serinaldi et al 2018 serinaldi and kilsby 2015 the association between the nonstationary patterns of ordinary and extreme events which has been acknowledged as complex and difficult to establish marra et al 2019 also requires further investigation secondly in the real applications of this paper the time was adopted as the covariate in the models the use of the temporal i e time and physical covariate s in the ns hfa has been discussed in the literature the general consensus is that the use of physical covariates is commonly hampered by the difficult attribution of the nonstationarity to the physical driver s and their commonly weak to moderate relationships archfield et al 2016 burn and whitfield 2017 easterling et al 2016 slater et al 2021a the nonstationarity attribution and or its improvement is beyond the scope of this paper although it would be beneficial for the ns hfa in general lastly the non asymptotic models are also applicable for other hydrometeorological variables such as streamflow e g miniussi et al 2020a mushtaq et al 2022 and sea level e g caruso and marani 2022 in such applications additional procedures for deriving ordinary events i e conducting the event separation e g decorrelation procedures or determination of the minimum time lag between events among others as well as the identification of a suitable distribution would be needed these additional steps should also be considered by the practitioners when choosing between the non asymptotic and asymptotic models 4 conclusion intending to advance the ns hfa this paper explored the potential of the mev and smev based models in which the ordinary events rather than only the extreme events are employed the implementation of the non asymptotic mev and smev distributions in the context of the ns hfa is very limited so far to the authors best knowledge this paper is the first to comprehensively assess the implementation of these distributions in the ns hfa from the perspectives of fitting efficiency accuracy and uncertainty in addition to facilitate the quantification of uncertainty of the mev and smev based models using the most recently proposed rf pl method this paper introduced their reparametrized log likelihood functions and their left censored versions these non asymptotic models were examined by both a simulation study and real applications using three real rainfall datasets for in sample fitting and out of sample prediction purposes the asymptotic gev based models which rely on the evt and have been widely used in the ns hfa were employed as the benchmark the datasets employed did not present significant temporal trends in the n the synthetic and real ordinary event datasets were generated from and adequately fitted by the weibull distribution with λ and or β linearly changing over time respectively in addition the standardized transformed amss of all the datasets followed the gev distribution all these justified the use of the models examined in this paper the results of the fitting performance assessment in both the simulation study and practical application suggested that the mev model was prone to overfit the samples and had a low fitting efficiency when evaluated based on the true quantiles and low accuracy whereas the smev based models always offered higher accuracy equivalent or better fitting efficiency as well as lower uncertainty than the gev based models in addition the results of the prediction performance assessment in both the simulation and the application studies also revealed that the smev based models were superior to the gev based models as they offered similar or better fitting efficiency higher accuracy and lower uncertainty therefore both the simulation study and the real application evidenced that the smev based models could advance the ns hfa by improving the accuracy and reducing the uncertainty without degrading their fitting efficiency future research on their practical implementations to more complex nonstationary patterns e g non linear and or with a nonstationary n the improvement of the nonstationarity attribution and the extension to other hydrometeorological variables would further promote the smev based models in the ns hfa declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the first author of this paper is funded by a doctoral scholarship from the national council for science and technology of mexico conacyt and the universidad de guadalajara this work is also partially funded by the discovery grant of natural sciences and engineering research council of canada held by the second author data availability the codes of the methods for the mev and smev based models were developed in matlab and are available upon request to the authors supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2022 104244 appendix supplementary materials image application 1 
111,we propose a novel method to predict fluid flow properties of reservoir rocks from 2d rock images by connecting pore clusters based on their intrinsic properties spatial proximity and connecting large clusters with priority are the two basic connecting principles of this method a few methods from complex networks were used to analyze the topology and connectivity of the connected pore networks resulting in more realistic and optimal pore networks from 2d images a new topological descriptor is proposed and was found to perform well in quantifying the network topology by considering both the isolated pore cluster number and the euler characteristic the new method can predict permeability from the 2d rock images with a reasonable agreement compared to the reference cases for different rock types and complex pore structures keywords pore network modeling new topological descriptor 2d rock images optimal connection predict permeability nomenclature acronyms gan generative adversarial network micro ct micro computed tomography pen percentage of end nodes pnm pore network model sdt self adaptive distance threshold sem scanning electron microscopy greek symbols α coefficient to determine the cross section shape β 0 0th betti number equals to the isolated cluster number β 1 1st betti number equals to the tunnels or loops in pore structure χ euler characteristic χ v specific connectivity function λ power law coefficient of degree distribution μ fluid viscosity pas ϕ porosity ψ connectivity coefficient ρ the ratio between the pore throat and pore body τ tortuosity latin symbols a cross sectional area md d euclidean distance μm f constriction factor used in peng s method g shape factor g hydraulic conductance for the pore elements m4 pas k c a l c calculated absolute permeability md k r e f reference absolute permeability md n number of elements p fluid pressure pa p empirical parameter used in saxena s method r image resolution μm pixel or μm voxel r radius of pore element m r c critical radius μm v volume of 3d image mm3 z coordination number subscripts b e extra bonds added during cluster merging process b p previous bonds quantified from a 2d image c cluster l level of clusters merged into the major cluster network n nodes r root clusters 1 introduction digital rock analyses and pore scale modeling to study the mechanisms of the single and multiphase fluid flow in porous media have developed rapidly in the last two decades bakke and øren 1997 blunt 2001 joekar niasar and hassanizadeh 2012 blunt et al 2013 blunt 2017 direct imaging techniques are commonly used in pore scale modeling as these can accurately visualize and quantify the complicated pore structures dunsmuir et al 1991 arns et al 2001 iassonov et al 2009 schlüter et al 2014 andrä et al 2013a b methods used in fluid flow simulations in 3d micro computed tomography micro ct are divided into two categories pore network method and direct numerical simulations pore network method is an efficient approach to pore scale fluid flow simulations as it extracts hydraulically equivalent networks of pores to represent the original pore structures blunt et al 2013 whereas direct numerical simulation methods such as the finite element method and lattice boltzmann method latt et al 2020 require more computational resources or time in modeling fluid flow in porous media compared to pore network method however there are several limitations of 3d images over 2d the main disadvantages manifest in terms of resolution and sample size the resolution of 3d micro ct images is generally lower as compared to that of 2d scanning electron microscopy sem images the volume of samples are small in order to gain high resolution micro ct images and even at such resolution there are still unresolved micro pores which is the limitation of micro ct imaging technology peng et al 2016 rabbani et al 2016 saxena et al 2017 it is also expensive and time consuming to image and analyze micro ct 3d images in contrast 2d images are more easily obtained in high resolution and also in very large size this is one advantage to predict permeability from 2d rock images currently reconstruction methods of 3d images that start from 2d images have been developed to simulate fluid flow the reconstruction methods include the multiple point statistics reconstruction method okabe and blunt 2007 markov chain monte carlo reconstruction method wu et al 2004 2006 and stochastic methods based on the weighted planar stochastic lattice method scott et al 2019 etc with the 3d reconstruction of pore space statistical properties of geometry and topology between 2d and 3d pore structures have been studied jiang 2008 rabbani et al 2016 scott 2020 however extracting pore networks from 3d images is time consuming for example it takes 10 to 30 hours to extract pore networks from 3d images 1400 1400 1700 voxels by using the maximal ball method in a multicore workstation with 512 gb ram gackiewicz et al 2021 conversely it is much more efficient to build pore networks directly from 2d images using machine learning and deep learning based methods to reconstruct images of 3d porous media is another hot topic in recent years zhang et al 2021 mosser et al 2017 you et al 2021 a well known method is called generative adversarial network gan a gan approach does not require an explicit objective function a priori to ensure the statistical properties to be matched as many classic stochastic methods do mosser et al 2017 machine learning based methods are efficient in a reconstruction of a 3d porous medium image once the training processes were done zhang et al 2021 however a gan method is usually unstable during a training process because of the model collapse and gradient vanishing therefore additional processes are needed to stabilize training processes a gan method needs long training time and requires considerable computational resources and training images are often limited to small size e g 10 0 3 voxels however machine learning based methods are still promising in pore scale modeling with the increase of computational power and the availability of abundant training datasets capillary tube bundle model can also simulate fluid flow properties from 2d images the method assumes that flow is normal to the image plane and is controlled by pore sizes however this method only represents the geometry of the pore space but no topology is honored several improvements are made on the capillary tube bundle model to predict permeability for example peng et al 2016 incorporated the ratio of tortuosity between 2d and 3d rock images and the ratio of pore throat and pore body radius in to the capillary tube bundle model in addition saxena et al 2017 assumed that pore diameters vary sinusoidally along the flow direction in 2d and the cross sections of pores change from circular to elliptical i e the capillary tubesdeviate to improve the capillary tube bundle model however there still are large discrepancies 200 500 between the predicted and measured permeabilities for heterogeneous pore structures such as carbonates peng et al 2016 saxena et al 2017 the key reason that the permeabilities predicted by these methods have large discrepancies with the measured results which will be discussed later is that topology is poorly represented by these methods the topology of a network is a crucial factor that dominates the transport properties however few studies have been conducted on the pore network topology vogel 2002 jiang et al 2007 2013 ushizima et al 2012 an emerging branch of science related to pore networks that studies the mechanisms of topology in a network is called network science barabási and albert 1999 albert and barabasi 2001 the studies of statistical mechanics of network topology and dynamics barabási and albert 1999 albert and barabasi 2001 show that the degree distribution for a large number of networks is governed by a power law tail i e p k k λ where p k is the probability distribution k is the degree the number of links that one node has and λ is the power law coefficient such networks are also called scale free networks the pore network is a type of scale free complex network since its mean coordination number z distribution displays the power law trend with its radius z r λ scott et al 2019 the method proposed in this study borrows some ideas from this relationship to reproduce the 3d connectivity from 2d images based on the statistical information of pore clusters in 2d in this study we investigate a novel approach to simulate fluid flow properties based on 2d rock images by constructing virtual 3d pore network from 2d images the pore space in the 2d images is not fully connected as some connections in the third direction are not visible however 3d micro ct images show that the pore space is well connected indicating that several connections are not detected in the 2d images therefore rebuilding the virtual connections that undetected in 2d based on the properties of pore clusters in 2d is feasible this method does not need the reconstruction of 3d images and extraction of pore networks from 3d images this method can reproduce both the geometry and topology of pore structures to overcome the limitation of existing methods the structure of this manuscript is outlined as follows section 2 elaborates on the general procedures of the new method in section 3 1 the method is justified and sensitivity analyses are presented with respect to the connecting parameters section 3 2 discusses some applications of this method finally conclusions are drawn in section 4 2 methodology this section is divided into three subsections first some basic concepts related to pore clusters are introduced second the procedures of the method to connect pore clusters are illustrated below to provide a general overview of the method the explanation and implementation of these two key principles are then demonstrated third the processes used to calculate the fluid flow properties from the fully connected pore network are introduced 2 1 the basic concepts of pore clusters to merge the clusters the first and second steps are calculating the parameters contained in a cluster and the key concepts are illustrated in figs 1 and 2 first our previously developed method was used to quantify the pore structures from 2d rock images wang et al 2020 as shown in fig 1 this method discretizes the pore space into a set of connected pore elements to capture pore geometry and topology the closely packed circles represent the pore elements each isolated pore space contains several pore elements as shown in fig 1 b which is called base cluster of pore elements or just base cluster our new method starts from these unconnected 2d pore clusters and connects them together to build a fully connected virtual 3d pore network as labeled by the seeded region growing algorithm seven base clusters were identified as shown using different colors in fig 2 the areas of the cluster node and bond elements in a cluster were recorded the node element or node is the major partitioned pore element while joining bond element previous bond or connection resulting in the interface between the two connected nodes the name previous is used to distinguish the bonds added by the new method in this study the later added bonds are called extra bonds the end node is the dead end pore on the dead end chain which was identified and labeled for each cluster the dead end chain as shown in fig 2 is the medial axis that extends from a branch node to an end node end nodes generally result in a minimum distance between two clusters the shortest distances from each cluster to all the other clusters were recorded which are of significant importance for the following procedures 2 2 the procedures to connect pore clusters this section introduces two principles and general procedures to connect the pore clusters the first principle is the spatial proximity principle from the 3d spatial point of view the geometry of pore space changes continually and some bonds cannot be seen directly in the 2d image therefore the two nearest clusters are primarily connected by the minimum distance between them the minimum distance is generally determined by the end nodes because of the concave shape of the pore space the second principle is that clusters with larger area are considered with higher priority the correlation between coordination number and pore size suggests that large nodes generally have more connections jiang 2008 scott 2020 here we used the analogy that large pore clusters are like cities small clusters are like villages and the bonds between them are like roads in general the roads between cities have a higher priority to be connected than those between villages similarly connections between large clusters are more important and should be connected first now let us examine how these two principles can be implemented in a real case 2 2 1 determine clusters neighbors the spatial proximity principle is used to determine the cluster neighbors which is summarized asthe self adaptive distance threshold sdt method and implemented in the following steps step 1 calculate the minimum distances taking a 2d rock image with 25 clusters as an example the minimum distances between each cluster and the other 24 clusters were first calculated fig 3 illustrates a typical minimum distance distribution for a cluster the y axis shows the distances to all the other clusters which are sorted in ascending order and the x axis is the cluster index of all clusters each cluster was assigned a unique preassigned index step 2 group clusters together with similar distances some collective features are observed in fig 3 clusters in the same group indicate that they have a similar distance to the current cluster thus they are grouped together the group with the closest distance is always connected first with the current one which is the spatial proximity principle these groups are numbered and the group number was used as the threshold to decide the number of neighbors the current cluster has this threshold was called the sdt for example sdt3 means that clusters in the first three distance groups were chosen as neighbors to be connected to the current cluster since the minimum distance distribution of each cluster is different the number of neighbors for different clusters also varied therefore we call this distance threshold as self adaptive to make it easier to identify distance groups we introduced the derivative of distance which is defined as d i d i 1 where the denominator is the unit d i is the minimum distance of cluster i with the current cluster peaks in the first derivative curve are the boundary between two distance groups and the negative points shown in the third derivative curve correspond to these peaks it is easier for a computer program to recognize negative values than to find the peak values therefore the third derivative of the distance was used to distinguish the peaks and distance groups a sensitivity analysis was conducted later to study the effect of the self adaptive distance threshold on the connecting results which is discussed in section 3 1 1 2 2 2 determine the extra bonds number between two clusters when two clusters are neighbors the second step is to determine how many extra bonds should be assigned between them this should be controlled by the intrinsic cluster parameters on one hand end nodes between two clusters are always connected first because of the spatial proximity principle on the other hand a 2d image is a part of the cross section of the 3d image and therefore the extra bonds added should not exceed the total bonds in the 3d image we related the extra bond number n b e between two clusters to the number of end nodes when connecting two neighboring clusters only specific part of the clusters face each other therefore not all end nodes should be connected it is rare for one cluster to be totally surrounded by another when a small cluster is a neighbor of a big cluster n b e should be the minimum number of end node of the two clusters in practice the end node number of each cluster is the same as the number of dead end chains number here n b e is assumed to be the minimum dead end chain number of two clusters divided by a value which isfurther discussed in section 3 1 3 2 2 3 merge cluster level by level the second principle requires large clusters to be connected first clusters were sorted by area and several large clusters were chosen as the root clusters roots which are the primary candidates where the connecting starts all root clusters were firstly connected with their neighbors as determined from the sdt which is the first level of the connecting process fig 4 illustrates the cluster merging processes with explanations of the key concepts new clusters were formed after joining neighboring clusters and they are the new root clusters for the next merging level the cluster level is defined as a certain merging stage when all root clusters are connected with their neighbors the merging processes were repeated iteratively until all clusters were connected to the major cluster network and the number of isolated clusters is zero the total number of levels needed to connect all clusters reflects the connecting efficiency where the fewer the number levels the more efficient the connection both the total number of levels and the topology of the connected network are influenced by the number of root clusters which will be discussed in the following section 3 1 4 2 3 extract pore network and assign properties after all the clusters are connected to the main network a fully connected pore network can be built with nodes connected by the previous and extra bonds the extra bond radius was taken as the harmonic mean of the two connected nodes permeability can be computed from the pore network where the procedures are the same as those introduced in wang et al 2020 a brief introduction is provided here we considered the single phase incompressible laminar flow a constant pressure boundary condition was applied to the model inlet and outlet and the other faces of the model were assumed to be no flow boundaries we assumed that the model s length and height are the same as the 2d image while the width of the model depth in the third direction was the maximum diameter of pore elements scott 2020 showed that there is not many differences between the shape factor distributions for 2d and 3d images the cross sectional area and shape factor assigned to the pore element i is shown in fig 5 i e the orange shaded zone flow direction was assumed to be parallel to the 2d image plane which is a major difference compared to the capillary tube bundle model saxena et al 2017 peng et al 2016 the latter only honors the pore size of porous media while our approach honors both the pore size and connectivity which is known to be important rabbani et al 2016 under the quasi static condition the flow rate between two connected nodes in a pore network can be determined using the hagien poiseuille law 1 q i j g i j l i j p i p j where g i j is the harmonic mean conductance between two connected nodes i j and bond b l i j is the length in the center of the two nodes 2 g i j l i j l i g i l j g j l b g b mass conservation was imposed on each node the unknowns here are the node pressures which were solved from a set of linear equations by integrating the flow rate equation into the mass conservation equation with the pressure known at the center of each node the total flow rate can be determined by calculating the average flow rate along the inlet and outlet and the absolute permeability of the pore network was determined using darcy s law 3 results and discussions this section is divided into two main sections first sensitivity analyses of the new method were conducted with regard to the connecting parameters a new topological descriptor was introduced to quantify the topology of the pore network during each cluster merging process second this method was applied to different types of rock samples to quantify the influence of pore structures on the fluid flow properties furthermore we demonstrated the ability of this method to predict permeability directly from 2d images 3 1 discussion on the method sensitivity analyses the sdt was used to determine the neighbors of a cluster a sensitivity analysis was conducted later to study the effect of the threshold on the connecting results see section 3 1 1 below 3 1 1 influence of sdt on the connections as discussed in section 2 2 1 the sdt method controls the number of neighbors of each cluster next we determined how the threshold of the number of connected neighbors influences the connecting results a 2d image with 57 clusters was used for this study as shown in fig 6 three sdt values were selected and analyzed i e sdt1 sdt3 and sdt5 for example sdt3 indicates that clusters ranked in the top three distance groups were chosen as the candidates to be connected for each cluster in this case the cluster with the maximum area was selected as the root cluster which is defined as the primary cluster where the connecting starts fig 6 and table 1 present the connections results the total number of merging levels n l reflects the connecting efficiency the fewer the number of levels the more efficient the connection we can see that a larger sdt has smaller n l and more efficient connections as it reaches more distance groups and connects further clusters at the same time for example sdt5 as shown in fig 6 however this results in several long bonds which is unreasonable as it contradicts the spatial proximity principle the calculated permeability of sdt5 was smaller than that of sdt1 and sdt3 this is because once a cluster is connected to the major network it will not have further connections with other clusters at the same level sdt5 searches for more clusters at one level but misses the connections between clusters at the same level for example clusters in the level 5 yellow clusters in sdt5 in fig 6 are not well connected which deteriorates the connectivity and reduces the permeability for a small sdt some nearby large clusters may not be connected early enough in summary sdt3 provided a better connection 3 1 2 connect large clusters preferentially this section discusses the implementation of the second principle namely connecting the large clusters preferentially and its influence on the permeability to add more neighboring clusters near neighbors e g sdt3 are extended to farther distant neighbors e g sdt5 by increasing the distance threshold however not all clusters inside the distance threshold were connected to the base cluster the priority of the connection is determined by the area of a cluster therefore clusters inside the larger distance threshold were first treated as potential neighbors these potential neighboring clusters were sorted by area in descending order to select the large clusters first but not all of them were selected as the final neighbors for example by increasing the distance threshold from 3 to 5 the potential neighbors were decided by sdt5 while the number of final neighbors is the same as the cluster number in sdt3 this process is called sdt35 where sdt3 controls the number of final neighboring clusters while sdt5 ensured larger clusters are connected first fig 7 shows the results of the connections for sdt3 and sdt35 it is clear that the large clusters were connected by sdt35 but not by sdt3 these two cases had almost the same number of extra bonds 41 for sdt3 and 40 for sdt35 but the permeability of sdt35 11 16md is dramatically larger than that of sdt3 2 72md this shows that connecting large clusters with priority can significantly improve the conductivity of the connected pore network therefore it is important to preferentially connect the large clusters to achieve better connectivity 3 1 3 influence of extra bonds number between two clusters on the connections as mentioned in section 3 1 3 the number of extra bonds between two clusters is the minimum dead end chain number divided by a value three different values 1 3 and 5 were compared the results of the connected clusters are plotted in fig 8 several unreasonable bonds were added at value 1 as indicated by the red ovals there is not many differences in the connectivity results between the cases of value 3 and 5 this is because most clusters are small and the number of dead end chains in small clusters is few e g less than 10 such that the same number of extra bonds is obtained when it is divided by 3 or 5 then the number of extra bonds between two clusters was set to the minimum dead end chain number divided by 3 3 1 4 influence of root clusters on the connections cluster merging processes start from the root clusters this section discusses the effect of the selection of roots on connecting results we study a 2d image shown in fig 9 a which is a slice randomly extracted from the 3d micro ct image of an estaillades carbonate sample blunt and bijeljic 2015 all the clusters were sorted by area in ascending order and fig 9 b shows the cumulative cluster size distribution curve the number of large clusters is small but they occupy a large percentage of total area root clusters are chosen starting from the largest one three different root numbers are selected from the curve i e root 0 3 0 5 and 0 8 where root 0 8 indicates that clusters which account for 80 of the area of pore space are selected as the roots for this case the cluster number of root 0 8 is 42 fig 9 b fig 10 shows the images of the connected pore clusters in addition the vivid processes of merging clusters into the major network gif images can be viewed from our mendeley data repository and the data that support the findings of this manuscript are also available wang 2021 take the case of root 0 3 for an example fig 11 shows some snapshots during the cluster merging processes three clusters were selected as roots which were located at the top left top right and bottom right of the image in the early stages level 3 root clusters absorb neighboring clusters and become large clusters at level 6 the two big roots on the right are bridged and a new giant cluster is formed at level 12 the left root cluster is included into the right giant cluster and a major network is constructed the system becomes percolating at this level this process continues until all clusters are merged into the major network the total number of level is 19 table 2 shows results of the connected pore clusters root 0 8 has the smallest number of levels while root 0 3 has the largest number of levels the euler characteristic χ is a parameter used to quantify the topology of the network and is an invariant parameter under continuous deformation of void spaces jiang et al 2013 ushizima et al 2012 blunt 2017 for a fully connected pore network the euler characteristic is given by 3 χ n n n b in general the larger the absolute euler characteristic is the better the connectivity is the euler characteristic χ can also be calculated from the betti numbers blunt 2017 4 χ β 0 β 1 where β 0 reflects the number of isolated clusters and β 1 is the number of handles or loops in the network the smaller the β 0 is the better the connectivity is therefore a new topology descriptor is introduced to quantify the network connectivity of a pore network which is called the connectivity coefficient ψ 5 ψ χ β 0 it can be seen that the larger the absolute χ is the better the connectivity is the curves of the connectivity coefficient ψ versus the cluster adding level for the above three cases are plotted in fig 12 root 0 8 has the best connectivity followed by root 0 5 and root 0 3 has the least connectivity in addition the calculated permeability listed in table 2 also shows the same trend i e case of root 0 8 has the largest permeability 1993 23md while root 0 3 has the smallest 102 73md which confirms that root 0 8 has the best connectivity comparing the results of root 0 3 and 0 8 the number of extra bonds increases by 22 9 but the permeability dramatically increase by 1840 26 a small fraction of extra bonds has a substantial influence on the network connectivity indicating that the selection of the root clusters plays an important role in the overall connectivity of the connected pore network however does this mean that more root clusters will lead to more optimal connecting results to address this issue the extreme case is considered where all clusters are regarded as roots namely root is 1 0 table 3 reports the results between root 0 8 and 1 0 absolute connectivity coefficient of root 1 0 is three times larger than that of root 0 8 but the permeability difference between them is only 9 18 this is because too many ineffective bonds are added in the case of root 1 0 therefore more roots cannot result in more optimal connection results 3 1 5 influence of connected nodes size of extra bonds in the last few sections extra bonds are connected between end nodes fig 13 shows the mean coordination number versus the pore radius for the sample estaillades in 2d 3d and connected 2d images in log log plot the 2d image without adding extra bonds and 3d image both show linear correlations which has also been reported previously scott 2020 however the trend of the 2d image with extra bonds deviates within a small radius the small pores in the connected 2d images have more connections than the original 2d image without adding extra bonds this is because the added extra bonds only connect with the end nodes but end nodes usually have a smaller radius to solve the problem some large nodes in a cluster are selected as candidates to connect the extra bonds apart from the end nodes first all nodes excluding end nodes in a cluster are sorted in descending order in size second candidate nodes are linearly selected and the number is the same as the number of end nodes in the cluster now we have two groups of nodes end nodes and other nodes a new parameter percentage of end nodes pen is introduced to adjust the percentage of end nodes to be connected by the extra bonds for example pen 0 3 means that 30 of the extra bonds are added between end nodes whereas 70 are selected from the other nodes in the same cluster to investigate the influence of pen on the connecting results two different pen values 0 3 and 0 8 are examined the 2d image of estaillades shown in fig 9 is used and the root is set to 0 8 table 4 presents the connection results these two cases have almost similar connectivity coefficient because topology does not change however the critical radius and permeability of the cases pen 0 3 and 0 8 are different the critical radius is calculated from the connectivity function curve as shown in fig 14 which is the radius when the euler characteristic is zero the connectivity function or intensive euler characteristic is the relationship between the euler characteristic and pore radius and is given below scott 2020 6 χ v r n n r n b r where n n r is the number of nodes with a radius larger than r and n b r is the number of bonds that satisfy the following two criteria first the bond radius is larger than the given radius r second the radii of the two connected nodes should also be larger than the given radius two features of the connectivity function curve should be emphasized first is the left endpoint which is the euler characteristic of the fully connected pore network the larger the absolute euler characteristic is the better the connectivity is second is the critical radius when the euler characteristic is zero in general a network percolates when the euler characteristic is negative and vice versa critical radius reflects the main size of pore element that connects the entire pore network results for pen 0 3 and 0 8 are listed in table 4 these two cases have almost the same connectivity however they have different critical radius and permeability the critical radius for case pen 0 3 and 0 8 are 5 59μm and 2 94μm respectively the smaller the pen is the larger the critical radius is and so is the permeability 3 2 discussions on application results real rock samples table 5 summarizes the data sets 3d used in this study four sandstone samples were obtained from a north sea sandstone reservoir three additional data sets were downloaded from pore scale modeling group at imperial college london blunt and bijeljic 2015 the reference permeability was calculated by the pore network method for the first four sandstone samples using the imagenet tool scott 2020 and direct numerical simulation for the other three samples dns results were downloaded from the pore scale modeling group at imperial college as well blunt and bijeljic 2015 fig 15 shows the normalized cumulative cluster size distribution for the seven samples in a log log plot as the clusters are sorted in ascending order by area the left region consists of small clusters and the right consists of the large clusters the x axis is the cluster index divided by the total number of clusters and the y axis is the cumulative cluster area two features can be inferred from the curves first a linear trend is observed for small clusters indicating a power law correlation between the clusters area and number of small clusters second the sample with the curve at the bottom right has a more distinguished boundary between the large and small clusters 3 2 1 predict permeability directly from 2d images this new method can construct a connected pore network from a 2d image and this section demonstrates how to use it to predict permeability directly from 2d images as mentioned before several methods have been developed to predict the permeability from 2d images stec et al 2019 keehm et al 2004 peng et al 2016 rabbani et al 2016 saxena et al 2017 however the main problem with these methods is that they only represent the pore size distribution and the connectivity of pore structure is poorly represented for example saxena et al 2017 assumed that the flow is perpendicular to a 2d image plane and they used the capillary bundle model to calculate the permeability although they proposed some correlations to correct the topology of the capillary bundles the topology is still weakly represented the topology perpendicular to 2d image plane is as complex as that parallel to the image which cannot be represented by a simple capillary tube bundle model it is better to utilize the existing topology information in the 2d image the samples listed in table 5 were used similarly three random 2d images were extracted from the x y and z directions of the 3d image making nine 2d images to be studied in total two permeabilities were calculated for each 2d image by simulating fluid flow from left to right and from top to bottom the arithmetic average permeability and standard deviation for each sample were calculated the merging clusters parameters roots and percentage of end nodes are 0 5 and 0 4 respectively for all cases fig 16 shows a connected 2d images of four samples with distinctive and complex pore structures the rest of connected 2d images and gif images showing the cluster merging processes can be found in the online repository wang 2021 fig 17 shows the cross plot of the predicted average permeability and reference permeability between the connected 2d and 3d images a reasonable match was observed for most of the samples in addition the time and efficiency to construct pore networks from 2d and 3d images are compared the new method takes about 10 to 20min to build pore networks directly from 2d images for samples with 1000 1000 pixels on a desktop pc intel core i7 cpu 32gb ram however it takes 10 to 30h to extract pore networks from 3d images 1400 1400 1700 voxels by using the maximal ball method in a multicore workstation with 512 gb ram gackiewicz et al 2021 therefore our method is much more efficient than its 3d counterpart on the other hand machine learning based methods are efficient in reconstruction once the training processes were done however these methods need long training time and considerable computational resources for example training was performed for approximately 24h for each dataset with training image of 6 4 3 voxels mosser et al 2017 3 2 2 comparisons with other methods this section compares the results computed from our method with two other methods as shown in the literature i e the peng s method peng et al 2016 and the saxena s method saxena et al 2017 the similarities and differences between these two methods lie in two parts the first is the initial estimation method used for a 2d permeability and the second is the 2d 3d transformation equation used to calibrate the 3d permeability first both approaches obtain the 2d permeability by assuming that the flow is normal to the 2d image plane and the capillary tube bundle model is adopted the peng s method used avzio 9 0 to calculate the 2d permeability while the saxena s method adopted the lattice boltzmann method second the kozeny carman equation is applied in both 2d and 3d images to derive the 2d 3d transformation equation kruczek 2015 in the peng s method the ratio of tortuosity between 2d and 3d rock images and the ratio of pore throat and pore body radius are incorporated into the kozeny carman equation to compute the permeability of the 3d rock samples on the other hand the sexena s method assumes that pore diameters vary sinusoidally along the flow direction in 2d and the cross sections of pores change from circular to elliptical i e the capillary tubesdeviate to derive the 2d 3d transformation equation in the peng s method the transformation is expressed as 7 k 3 d k 2 d 2 3 f τ 2 where τ is the tortuosity and is derived from the archie s law τ 2 ϕ 1 m ϕ is the porosity of the 2d image and the cementation factor m 2 is used in the peng s method f is the constriction factor used to calibrate the capillary tube bundle model which assumes that pore radii vary sinusoidally along the capillary tube f is given by 8 f 256 ρ 3 5 1 ρ 4 5 ρ 3 3 ρ 2 3 ρ 5 in which ρ is the ratio between the pore throat and pore body peng s method suggests ρ d 10 d 60 d 10 and d 60 correspond to the diameters of 10 and 60 in the cumulative pore size distribution curve in the saxena s method the transformation equation is 9 k 3 d k 2 d 4 9 1 1 p log ϕ 2 where p is an empirical parameter and ϕ is the porosity saxena et al 2017 suggest that p varies from 1 to 2 for sandstones and 3 to 6 for carbonates therefore a low and high limit of permeabilities are calculated for each sample from saxena s method similarly the seven samples listed in table 5 were used to calculate the permeability from peng s method and saxena s method each sample has nine 2d images and the arithmetic mean permeability is calculated table 6 reports the predicted 3d permeability by the three methods and the deviations with the reference results fig 18 shows the permeability deviations of the seven samples these three methods can predict reasonable permeabilities but our method has more accurate results than peng s method and saxena s method for most samples the main reason is that the topology can be well represented by our method but not by the capillary tube bundle model the latter only honors the pore size of porous media while our method honors both the pore size and connectivity which is important for the fluid flow simulation from the method implementation point of view the peng s method and saxena s method are easy to be understood and replicated which are the advantages of these methods however these two methods have large uncertainties in predicting permeabilities in particular for samples with small permeabilities in addition saxena s method relies on the empirical parameter p while it is hard to obtain the proper p for various rock types 4 conclusions in this study a novel method for constructing pore network from 2d rock images has been introduced 2d images are not fully connected as some connections are remain undetected therefore we rebuilt the missing connections from 2d images by connecting the isolated pore clusters based on the statistical relationships between 2d and 3d images the spatial proximity and priority of connecting large clusters are the two basic connecting principles in this new method connecting the close and large clusters preferentially and carefully selecting the root clusters are important for the overall connectivity and conductivity of the pore network few concepts from complex networks were used to analyze the topology and connectivity of pore networks that make the connections in 2d images more realistic and optimal a new topological descriptor was proposed and was found to perform well in quantifying the network topology by considering both the isolated pore cluster number and the euler characteristic two basic parameters involved in the new method i e root clusters and the percentage of end nodes have been discussed the pore network extracted from 2d images by the new method can predict permeability with an appropriate choice of the two basic parameters the results are in reasonable agreement with the reference cases for different rock types and complex pore structures the key reason is that the new method can honor not only the pore size distribution but also the topology of the real pore structures which is known to be important credit authorship contribution statement chenhui wang conceptualization methodology software formal analysis formal analysis writing original draft writing review editing visualization kejian wu conceptualization methodology writing review editing supervision project administration gilbert g scott validation writing review editing ailin jia writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment c w thanks the financial support from china scholarship council csc for his ph d study the authors thank anasuria operating company limited aoc for making available the core plug samples the authors thank john still of university of aberdeen centre for electron microscopy analysis and characterisation acemac for the assistance in the acquisition of micro ct and sem images 
111,we propose a novel method to predict fluid flow properties of reservoir rocks from 2d rock images by connecting pore clusters based on their intrinsic properties spatial proximity and connecting large clusters with priority are the two basic connecting principles of this method a few methods from complex networks were used to analyze the topology and connectivity of the connected pore networks resulting in more realistic and optimal pore networks from 2d images a new topological descriptor is proposed and was found to perform well in quantifying the network topology by considering both the isolated pore cluster number and the euler characteristic the new method can predict permeability from the 2d rock images with a reasonable agreement compared to the reference cases for different rock types and complex pore structures keywords pore network modeling new topological descriptor 2d rock images optimal connection predict permeability nomenclature acronyms gan generative adversarial network micro ct micro computed tomography pen percentage of end nodes pnm pore network model sdt self adaptive distance threshold sem scanning electron microscopy greek symbols α coefficient to determine the cross section shape β 0 0th betti number equals to the isolated cluster number β 1 1st betti number equals to the tunnels or loops in pore structure χ euler characteristic χ v specific connectivity function λ power law coefficient of degree distribution μ fluid viscosity pas ϕ porosity ψ connectivity coefficient ρ the ratio between the pore throat and pore body τ tortuosity latin symbols a cross sectional area md d euclidean distance μm f constriction factor used in peng s method g shape factor g hydraulic conductance for the pore elements m4 pas k c a l c calculated absolute permeability md k r e f reference absolute permeability md n number of elements p fluid pressure pa p empirical parameter used in saxena s method r image resolution μm pixel or μm voxel r radius of pore element m r c critical radius μm v volume of 3d image mm3 z coordination number subscripts b e extra bonds added during cluster merging process b p previous bonds quantified from a 2d image c cluster l level of clusters merged into the major cluster network n nodes r root clusters 1 introduction digital rock analyses and pore scale modeling to study the mechanisms of the single and multiphase fluid flow in porous media have developed rapidly in the last two decades bakke and øren 1997 blunt 2001 joekar niasar and hassanizadeh 2012 blunt et al 2013 blunt 2017 direct imaging techniques are commonly used in pore scale modeling as these can accurately visualize and quantify the complicated pore structures dunsmuir et al 1991 arns et al 2001 iassonov et al 2009 schlüter et al 2014 andrä et al 2013a b methods used in fluid flow simulations in 3d micro computed tomography micro ct are divided into two categories pore network method and direct numerical simulations pore network method is an efficient approach to pore scale fluid flow simulations as it extracts hydraulically equivalent networks of pores to represent the original pore structures blunt et al 2013 whereas direct numerical simulation methods such as the finite element method and lattice boltzmann method latt et al 2020 require more computational resources or time in modeling fluid flow in porous media compared to pore network method however there are several limitations of 3d images over 2d the main disadvantages manifest in terms of resolution and sample size the resolution of 3d micro ct images is generally lower as compared to that of 2d scanning electron microscopy sem images the volume of samples are small in order to gain high resolution micro ct images and even at such resolution there are still unresolved micro pores which is the limitation of micro ct imaging technology peng et al 2016 rabbani et al 2016 saxena et al 2017 it is also expensive and time consuming to image and analyze micro ct 3d images in contrast 2d images are more easily obtained in high resolution and also in very large size this is one advantage to predict permeability from 2d rock images currently reconstruction methods of 3d images that start from 2d images have been developed to simulate fluid flow the reconstruction methods include the multiple point statistics reconstruction method okabe and blunt 2007 markov chain monte carlo reconstruction method wu et al 2004 2006 and stochastic methods based on the weighted planar stochastic lattice method scott et al 2019 etc with the 3d reconstruction of pore space statistical properties of geometry and topology between 2d and 3d pore structures have been studied jiang 2008 rabbani et al 2016 scott 2020 however extracting pore networks from 3d images is time consuming for example it takes 10 to 30 hours to extract pore networks from 3d images 1400 1400 1700 voxels by using the maximal ball method in a multicore workstation with 512 gb ram gackiewicz et al 2021 conversely it is much more efficient to build pore networks directly from 2d images using machine learning and deep learning based methods to reconstruct images of 3d porous media is another hot topic in recent years zhang et al 2021 mosser et al 2017 you et al 2021 a well known method is called generative adversarial network gan a gan approach does not require an explicit objective function a priori to ensure the statistical properties to be matched as many classic stochastic methods do mosser et al 2017 machine learning based methods are efficient in a reconstruction of a 3d porous medium image once the training processes were done zhang et al 2021 however a gan method is usually unstable during a training process because of the model collapse and gradient vanishing therefore additional processes are needed to stabilize training processes a gan method needs long training time and requires considerable computational resources and training images are often limited to small size e g 10 0 3 voxels however machine learning based methods are still promising in pore scale modeling with the increase of computational power and the availability of abundant training datasets capillary tube bundle model can also simulate fluid flow properties from 2d images the method assumes that flow is normal to the image plane and is controlled by pore sizes however this method only represents the geometry of the pore space but no topology is honored several improvements are made on the capillary tube bundle model to predict permeability for example peng et al 2016 incorporated the ratio of tortuosity between 2d and 3d rock images and the ratio of pore throat and pore body radius in to the capillary tube bundle model in addition saxena et al 2017 assumed that pore diameters vary sinusoidally along the flow direction in 2d and the cross sections of pores change from circular to elliptical i e the capillary tubesdeviate to improve the capillary tube bundle model however there still are large discrepancies 200 500 between the predicted and measured permeabilities for heterogeneous pore structures such as carbonates peng et al 2016 saxena et al 2017 the key reason that the permeabilities predicted by these methods have large discrepancies with the measured results which will be discussed later is that topology is poorly represented by these methods the topology of a network is a crucial factor that dominates the transport properties however few studies have been conducted on the pore network topology vogel 2002 jiang et al 2007 2013 ushizima et al 2012 an emerging branch of science related to pore networks that studies the mechanisms of topology in a network is called network science barabási and albert 1999 albert and barabasi 2001 the studies of statistical mechanics of network topology and dynamics barabási and albert 1999 albert and barabasi 2001 show that the degree distribution for a large number of networks is governed by a power law tail i e p k k λ where p k is the probability distribution k is the degree the number of links that one node has and λ is the power law coefficient such networks are also called scale free networks the pore network is a type of scale free complex network since its mean coordination number z distribution displays the power law trend with its radius z r λ scott et al 2019 the method proposed in this study borrows some ideas from this relationship to reproduce the 3d connectivity from 2d images based on the statistical information of pore clusters in 2d in this study we investigate a novel approach to simulate fluid flow properties based on 2d rock images by constructing virtual 3d pore network from 2d images the pore space in the 2d images is not fully connected as some connections in the third direction are not visible however 3d micro ct images show that the pore space is well connected indicating that several connections are not detected in the 2d images therefore rebuilding the virtual connections that undetected in 2d based on the properties of pore clusters in 2d is feasible this method does not need the reconstruction of 3d images and extraction of pore networks from 3d images this method can reproduce both the geometry and topology of pore structures to overcome the limitation of existing methods the structure of this manuscript is outlined as follows section 2 elaborates on the general procedures of the new method in section 3 1 the method is justified and sensitivity analyses are presented with respect to the connecting parameters section 3 2 discusses some applications of this method finally conclusions are drawn in section 4 2 methodology this section is divided into three subsections first some basic concepts related to pore clusters are introduced second the procedures of the method to connect pore clusters are illustrated below to provide a general overview of the method the explanation and implementation of these two key principles are then demonstrated third the processes used to calculate the fluid flow properties from the fully connected pore network are introduced 2 1 the basic concepts of pore clusters to merge the clusters the first and second steps are calculating the parameters contained in a cluster and the key concepts are illustrated in figs 1 and 2 first our previously developed method was used to quantify the pore structures from 2d rock images wang et al 2020 as shown in fig 1 this method discretizes the pore space into a set of connected pore elements to capture pore geometry and topology the closely packed circles represent the pore elements each isolated pore space contains several pore elements as shown in fig 1 b which is called base cluster of pore elements or just base cluster our new method starts from these unconnected 2d pore clusters and connects them together to build a fully connected virtual 3d pore network as labeled by the seeded region growing algorithm seven base clusters were identified as shown using different colors in fig 2 the areas of the cluster node and bond elements in a cluster were recorded the node element or node is the major partitioned pore element while joining bond element previous bond or connection resulting in the interface between the two connected nodes the name previous is used to distinguish the bonds added by the new method in this study the later added bonds are called extra bonds the end node is the dead end pore on the dead end chain which was identified and labeled for each cluster the dead end chain as shown in fig 2 is the medial axis that extends from a branch node to an end node end nodes generally result in a minimum distance between two clusters the shortest distances from each cluster to all the other clusters were recorded which are of significant importance for the following procedures 2 2 the procedures to connect pore clusters this section introduces two principles and general procedures to connect the pore clusters the first principle is the spatial proximity principle from the 3d spatial point of view the geometry of pore space changes continually and some bonds cannot be seen directly in the 2d image therefore the two nearest clusters are primarily connected by the minimum distance between them the minimum distance is generally determined by the end nodes because of the concave shape of the pore space the second principle is that clusters with larger area are considered with higher priority the correlation between coordination number and pore size suggests that large nodes generally have more connections jiang 2008 scott 2020 here we used the analogy that large pore clusters are like cities small clusters are like villages and the bonds between them are like roads in general the roads between cities have a higher priority to be connected than those between villages similarly connections between large clusters are more important and should be connected first now let us examine how these two principles can be implemented in a real case 2 2 1 determine clusters neighbors the spatial proximity principle is used to determine the cluster neighbors which is summarized asthe self adaptive distance threshold sdt method and implemented in the following steps step 1 calculate the minimum distances taking a 2d rock image with 25 clusters as an example the minimum distances between each cluster and the other 24 clusters were first calculated fig 3 illustrates a typical minimum distance distribution for a cluster the y axis shows the distances to all the other clusters which are sorted in ascending order and the x axis is the cluster index of all clusters each cluster was assigned a unique preassigned index step 2 group clusters together with similar distances some collective features are observed in fig 3 clusters in the same group indicate that they have a similar distance to the current cluster thus they are grouped together the group with the closest distance is always connected first with the current one which is the spatial proximity principle these groups are numbered and the group number was used as the threshold to decide the number of neighbors the current cluster has this threshold was called the sdt for example sdt3 means that clusters in the first three distance groups were chosen as neighbors to be connected to the current cluster since the minimum distance distribution of each cluster is different the number of neighbors for different clusters also varied therefore we call this distance threshold as self adaptive to make it easier to identify distance groups we introduced the derivative of distance which is defined as d i d i 1 where the denominator is the unit d i is the minimum distance of cluster i with the current cluster peaks in the first derivative curve are the boundary between two distance groups and the negative points shown in the third derivative curve correspond to these peaks it is easier for a computer program to recognize negative values than to find the peak values therefore the third derivative of the distance was used to distinguish the peaks and distance groups a sensitivity analysis was conducted later to study the effect of the self adaptive distance threshold on the connecting results which is discussed in section 3 1 1 2 2 2 determine the extra bonds number between two clusters when two clusters are neighbors the second step is to determine how many extra bonds should be assigned between them this should be controlled by the intrinsic cluster parameters on one hand end nodes between two clusters are always connected first because of the spatial proximity principle on the other hand a 2d image is a part of the cross section of the 3d image and therefore the extra bonds added should not exceed the total bonds in the 3d image we related the extra bond number n b e between two clusters to the number of end nodes when connecting two neighboring clusters only specific part of the clusters face each other therefore not all end nodes should be connected it is rare for one cluster to be totally surrounded by another when a small cluster is a neighbor of a big cluster n b e should be the minimum number of end node of the two clusters in practice the end node number of each cluster is the same as the number of dead end chains number here n b e is assumed to be the minimum dead end chain number of two clusters divided by a value which isfurther discussed in section 3 1 3 2 2 3 merge cluster level by level the second principle requires large clusters to be connected first clusters were sorted by area and several large clusters were chosen as the root clusters roots which are the primary candidates where the connecting starts all root clusters were firstly connected with their neighbors as determined from the sdt which is the first level of the connecting process fig 4 illustrates the cluster merging processes with explanations of the key concepts new clusters were formed after joining neighboring clusters and they are the new root clusters for the next merging level the cluster level is defined as a certain merging stage when all root clusters are connected with their neighbors the merging processes were repeated iteratively until all clusters were connected to the major cluster network and the number of isolated clusters is zero the total number of levels needed to connect all clusters reflects the connecting efficiency where the fewer the number levels the more efficient the connection both the total number of levels and the topology of the connected network are influenced by the number of root clusters which will be discussed in the following section 3 1 4 2 3 extract pore network and assign properties after all the clusters are connected to the main network a fully connected pore network can be built with nodes connected by the previous and extra bonds the extra bond radius was taken as the harmonic mean of the two connected nodes permeability can be computed from the pore network where the procedures are the same as those introduced in wang et al 2020 a brief introduction is provided here we considered the single phase incompressible laminar flow a constant pressure boundary condition was applied to the model inlet and outlet and the other faces of the model were assumed to be no flow boundaries we assumed that the model s length and height are the same as the 2d image while the width of the model depth in the third direction was the maximum diameter of pore elements scott 2020 showed that there is not many differences between the shape factor distributions for 2d and 3d images the cross sectional area and shape factor assigned to the pore element i is shown in fig 5 i e the orange shaded zone flow direction was assumed to be parallel to the 2d image plane which is a major difference compared to the capillary tube bundle model saxena et al 2017 peng et al 2016 the latter only honors the pore size of porous media while our approach honors both the pore size and connectivity which is known to be important rabbani et al 2016 under the quasi static condition the flow rate between two connected nodes in a pore network can be determined using the hagien poiseuille law 1 q i j g i j l i j p i p j where g i j is the harmonic mean conductance between two connected nodes i j and bond b l i j is the length in the center of the two nodes 2 g i j l i j l i g i l j g j l b g b mass conservation was imposed on each node the unknowns here are the node pressures which were solved from a set of linear equations by integrating the flow rate equation into the mass conservation equation with the pressure known at the center of each node the total flow rate can be determined by calculating the average flow rate along the inlet and outlet and the absolute permeability of the pore network was determined using darcy s law 3 results and discussions this section is divided into two main sections first sensitivity analyses of the new method were conducted with regard to the connecting parameters a new topological descriptor was introduced to quantify the topology of the pore network during each cluster merging process second this method was applied to different types of rock samples to quantify the influence of pore structures on the fluid flow properties furthermore we demonstrated the ability of this method to predict permeability directly from 2d images 3 1 discussion on the method sensitivity analyses the sdt was used to determine the neighbors of a cluster a sensitivity analysis was conducted later to study the effect of the threshold on the connecting results see section 3 1 1 below 3 1 1 influence of sdt on the connections as discussed in section 2 2 1 the sdt method controls the number of neighbors of each cluster next we determined how the threshold of the number of connected neighbors influences the connecting results a 2d image with 57 clusters was used for this study as shown in fig 6 three sdt values were selected and analyzed i e sdt1 sdt3 and sdt5 for example sdt3 indicates that clusters ranked in the top three distance groups were chosen as the candidates to be connected for each cluster in this case the cluster with the maximum area was selected as the root cluster which is defined as the primary cluster where the connecting starts fig 6 and table 1 present the connections results the total number of merging levels n l reflects the connecting efficiency the fewer the number of levels the more efficient the connection we can see that a larger sdt has smaller n l and more efficient connections as it reaches more distance groups and connects further clusters at the same time for example sdt5 as shown in fig 6 however this results in several long bonds which is unreasonable as it contradicts the spatial proximity principle the calculated permeability of sdt5 was smaller than that of sdt1 and sdt3 this is because once a cluster is connected to the major network it will not have further connections with other clusters at the same level sdt5 searches for more clusters at one level but misses the connections between clusters at the same level for example clusters in the level 5 yellow clusters in sdt5 in fig 6 are not well connected which deteriorates the connectivity and reduces the permeability for a small sdt some nearby large clusters may not be connected early enough in summary sdt3 provided a better connection 3 1 2 connect large clusters preferentially this section discusses the implementation of the second principle namely connecting the large clusters preferentially and its influence on the permeability to add more neighboring clusters near neighbors e g sdt3 are extended to farther distant neighbors e g sdt5 by increasing the distance threshold however not all clusters inside the distance threshold were connected to the base cluster the priority of the connection is determined by the area of a cluster therefore clusters inside the larger distance threshold were first treated as potential neighbors these potential neighboring clusters were sorted by area in descending order to select the large clusters first but not all of them were selected as the final neighbors for example by increasing the distance threshold from 3 to 5 the potential neighbors were decided by sdt5 while the number of final neighbors is the same as the cluster number in sdt3 this process is called sdt35 where sdt3 controls the number of final neighboring clusters while sdt5 ensured larger clusters are connected first fig 7 shows the results of the connections for sdt3 and sdt35 it is clear that the large clusters were connected by sdt35 but not by sdt3 these two cases had almost the same number of extra bonds 41 for sdt3 and 40 for sdt35 but the permeability of sdt35 11 16md is dramatically larger than that of sdt3 2 72md this shows that connecting large clusters with priority can significantly improve the conductivity of the connected pore network therefore it is important to preferentially connect the large clusters to achieve better connectivity 3 1 3 influence of extra bonds number between two clusters on the connections as mentioned in section 3 1 3 the number of extra bonds between two clusters is the minimum dead end chain number divided by a value three different values 1 3 and 5 were compared the results of the connected clusters are plotted in fig 8 several unreasonable bonds were added at value 1 as indicated by the red ovals there is not many differences in the connectivity results between the cases of value 3 and 5 this is because most clusters are small and the number of dead end chains in small clusters is few e g less than 10 such that the same number of extra bonds is obtained when it is divided by 3 or 5 then the number of extra bonds between two clusters was set to the minimum dead end chain number divided by 3 3 1 4 influence of root clusters on the connections cluster merging processes start from the root clusters this section discusses the effect of the selection of roots on connecting results we study a 2d image shown in fig 9 a which is a slice randomly extracted from the 3d micro ct image of an estaillades carbonate sample blunt and bijeljic 2015 all the clusters were sorted by area in ascending order and fig 9 b shows the cumulative cluster size distribution curve the number of large clusters is small but they occupy a large percentage of total area root clusters are chosen starting from the largest one three different root numbers are selected from the curve i e root 0 3 0 5 and 0 8 where root 0 8 indicates that clusters which account for 80 of the area of pore space are selected as the roots for this case the cluster number of root 0 8 is 42 fig 9 b fig 10 shows the images of the connected pore clusters in addition the vivid processes of merging clusters into the major network gif images can be viewed from our mendeley data repository and the data that support the findings of this manuscript are also available wang 2021 take the case of root 0 3 for an example fig 11 shows some snapshots during the cluster merging processes three clusters were selected as roots which were located at the top left top right and bottom right of the image in the early stages level 3 root clusters absorb neighboring clusters and become large clusters at level 6 the two big roots on the right are bridged and a new giant cluster is formed at level 12 the left root cluster is included into the right giant cluster and a major network is constructed the system becomes percolating at this level this process continues until all clusters are merged into the major network the total number of level is 19 table 2 shows results of the connected pore clusters root 0 8 has the smallest number of levels while root 0 3 has the largest number of levels the euler characteristic χ is a parameter used to quantify the topology of the network and is an invariant parameter under continuous deformation of void spaces jiang et al 2013 ushizima et al 2012 blunt 2017 for a fully connected pore network the euler characteristic is given by 3 χ n n n b in general the larger the absolute euler characteristic is the better the connectivity is the euler characteristic χ can also be calculated from the betti numbers blunt 2017 4 χ β 0 β 1 where β 0 reflects the number of isolated clusters and β 1 is the number of handles or loops in the network the smaller the β 0 is the better the connectivity is therefore a new topology descriptor is introduced to quantify the network connectivity of a pore network which is called the connectivity coefficient ψ 5 ψ χ β 0 it can be seen that the larger the absolute χ is the better the connectivity is the curves of the connectivity coefficient ψ versus the cluster adding level for the above three cases are plotted in fig 12 root 0 8 has the best connectivity followed by root 0 5 and root 0 3 has the least connectivity in addition the calculated permeability listed in table 2 also shows the same trend i e case of root 0 8 has the largest permeability 1993 23md while root 0 3 has the smallest 102 73md which confirms that root 0 8 has the best connectivity comparing the results of root 0 3 and 0 8 the number of extra bonds increases by 22 9 but the permeability dramatically increase by 1840 26 a small fraction of extra bonds has a substantial influence on the network connectivity indicating that the selection of the root clusters plays an important role in the overall connectivity of the connected pore network however does this mean that more root clusters will lead to more optimal connecting results to address this issue the extreme case is considered where all clusters are regarded as roots namely root is 1 0 table 3 reports the results between root 0 8 and 1 0 absolute connectivity coefficient of root 1 0 is three times larger than that of root 0 8 but the permeability difference between them is only 9 18 this is because too many ineffective bonds are added in the case of root 1 0 therefore more roots cannot result in more optimal connection results 3 1 5 influence of connected nodes size of extra bonds in the last few sections extra bonds are connected between end nodes fig 13 shows the mean coordination number versus the pore radius for the sample estaillades in 2d 3d and connected 2d images in log log plot the 2d image without adding extra bonds and 3d image both show linear correlations which has also been reported previously scott 2020 however the trend of the 2d image with extra bonds deviates within a small radius the small pores in the connected 2d images have more connections than the original 2d image without adding extra bonds this is because the added extra bonds only connect with the end nodes but end nodes usually have a smaller radius to solve the problem some large nodes in a cluster are selected as candidates to connect the extra bonds apart from the end nodes first all nodes excluding end nodes in a cluster are sorted in descending order in size second candidate nodes are linearly selected and the number is the same as the number of end nodes in the cluster now we have two groups of nodes end nodes and other nodes a new parameter percentage of end nodes pen is introduced to adjust the percentage of end nodes to be connected by the extra bonds for example pen 0 3 means that 30 of the extra bonds are added between end nodes whereas 70 are selected from the other nodes in the same cluster to investigate the influence of pen on the connecting results two different pen values 0 3 and 0 8 are examined the 2d image of estaillades shown in fig 9 is used and the root is set to 0 8 table 4 presents the connection results these two cases have almost similar connectivity coefficient because topology does not change however the critical radius and permeability of the cases pen 0 3 and 0 8 are different the critical radius is calculated from the connectivity function curve as shown in fig 14 which is the radius when the euler characteristic is zero the connectivity function or intensive euler characteristic is the relationship between the euler characteristic and pore radius and is given below scott 2020 6 χ v r n n r n b r where n n r is the number of nodes with a radius larger than r and n b r is the number of bonds that satisfy the following two criteria first the bond radius is larger than the given radius r second the radii of the two connected nodes should also be larger than the given radius two features of the connectivity function curve should be emphasized first is the left endpoint which is the euler characteristic of the fully connected pore network the larger the absolute euler characteristic is the better the connectivity is second is the critical radius when the euler characteristic is zero in general a network percolates when the euler characteristic is negative and vice versa critical radius reflects the main size of pore element that connects the entire pore network results for pen 0 3 and 0 8 are listed in table 4 these two cases have almost the same connectivity however they have different critical radius and permeability the critical radius for case pen 0 3 and 0 8 are 5 59μm and 2 94μm respectively the smaller the pen is the larger the critical radius is and so is the permeability 3 2 discussions on application results real rock samples table 5 summarizes the data sets 3d used in this study four sandstone samples were obtained from a north sea sandstone reservoir three additional data sets were downloaded from pore scale modeling group at imperial college london blunt and bijeljic 2015 the reference permeability was calculated by the pore network method for the first four sandstone samples using the imagenet tool scott 2020 and direct numerical simulation for the other three samples dns results were downloaded from the pore scale modeling group at imperial college as well blunt and bijeljic 2015 fig 15 shows the normalized cumulative cluster size distribution for the seven samples in a log log plot as the clusters are sorted in ascending order by area the left region consists of small clusters and the right consists of the large clusters the x axis is the cluster index divided by the total number of clusters and the y axis is the cumulative cluster area two features can be inferred from the curves first a linear trend is observed for small clusters indicating a power law correlation between the clusters area and number of small clusters second the sample with the curve at the bottom right has a more distinguished boundary between the large and small clusters 3 2 1 predict permeability directly from 2d images this new method can construct a connected pore network from a 2d image and this section demonstrates how to use it to predict permeability directly from 2d images as mentioned before several methods have been developed to predict the permeability from 2d images stec et al 2019 keehm et al 2004 peng et al 2016 rabbani et al 2016 saxena et al 2017 however the main problem with these methods is that they only represent the pore size distribution and the connectivity of pore structure is poorly represented for example saxena et al 2017 assumed that the flow is perpendicular to a 2d image plane and they used the capillary bundle model to calculate the permeability although they proposed some correlations to correct the topology of the capillary bundles the topology is still weakly represented the topology perpendicular to 2d image plane is as complex as that parallel to the image which cannot be represented by a simple capillary tube bundle model it is better to utilize the existing topology information in the 2d image the samples listed in table 5 were used similarly three random 2d images were extracted from the x y and z directions of the 3d image making nine 2d images to be studied in total two permeabilities were calculated for each 2d image by simulating fluid flow from left to right and from top to bottom the arithmetic average permeability and standard deviation for each sample were calculated the merging clusters parameters roots and percentage of end nodes are 0 5 and 0 4 respectively for all cases fig 16 shows a connected 2d images of four samples with distinctive and complex pore structures the rest of connected 2d images and gif images showing the cluster merging processes can be found in the online repository wang 2021 fig 17 shows the cross plot of the predicted average permeability and reference permeability between the connected 2d and 3d images a reasonable match was observed for most of the samples in addition the time and efficiency to construct pore networks from 2d and 3d images are compared the new method takes about 10 to 20min to build pore networks directly from 2d images for samples with 1000 1000 pixels on a desktop pc intel core i7 cpu 32gb ram however it takes 10 to 30h to extract pore networks from 3d images 1400 1400 1700 voxels by using the maximal ball method in a multicore workstation with 512 gb ram gackiewicz et al 2021 therefore our method is much more efficient than its 3d counterpart on the other hand machine learning based methods are efficient in reconstruction once the training processes were done however these methods need long training time and considerable computational resources for example training was performed for approximately 24h for each dataset with training image of 6 4 3 voxels mosser et al 2017 3 2 2 comparisons with other methods this section compares the results computed from our method with two other methods as shown in the literature i e the peng s method peng et al 2016 and the saxena s method saxena et al 2017 the similarities and differences between these two methods lie in two parts the first is the initial estimation method used for a 2d permeability and the second is the 2d 3d transformation equation used to calibrate the 3d permeability first both approaches obtain the 2d permeability by assuming that the flow is normal to the 2d image plane and the capillary tube bundle model is adopted the peng s method used avzio 9 0 to calculate the 2d permeability while the saxena s method adopted the lattice boltzmann method second the kozeny carman equation is applied in both 2d and 3d images to derive the 2d 3d transformation equation kruczek 2015 in the peng s method the ratio of tortuosity between 2d and 3d rock images and the ratio of pore throat and pore body radius are incorporated into the kozeny carman equation to compute the permeability of the 3d rock samples on the other hand the sexena s method assumes that pore diameters vary sinusoidally along the flow direction in 2d and the cross sections of pores change from circular to elliptical i e the capillary tubesdeviate to derive the 2d 3d transformation equation in the peng s method the transformation is expressed as 7 k 3 d k 2 d 2 3 f τ 2 where τ is the tortuosity and is derived from the archie s law τ 2 ϕ 1 m ϕ is the porosity of the 2d image and the cementation factor m 2 is used in the peng s method f is the constriction factor used to calibrate the capillary tube bundle model which assumes that pore radii vary sinusoidally along the capillary tube f is given by 8 f 256 ρ 3 5 1 ρ 4 5 ρ 3 3 ρ 2 3 ρ 5 in which ρ is the ratio between the pore throat and pore body peng s method suggests ρ d 10 d 60 d 10 and d 60 correspond to the diameters of 10 and 60 in the cumulative pore size distribution curve in the saxena s method the transformation equation is 9 k 3 d k 2 d 4 9 1 1 p log ϕ 2 where p is an empirical parameter and ϕ is the porosity saxena et al 2017 suggest that p varies from 1 to 2 for sandstones and 3 to 6 for carbonates therefore a low and high limit of permeabilities are calculated for each sample from saxena s method similarly the seven samples listed in table 5 were used to calculate the permeability from peng s method and saxena s method each sample has nine 2d images and the arithmetic mean permeability is calculated table 6 reports the predicted 3d permeability by the three methods and the deviations with the reference results fig 18 shows the permeability deviations of the seven samples these three methods can predict reasonable permeabilities but our method has more accurate results than peng s method and saxena s method for most samples the main reason is that the topology can be well represented by our method but not by the capillary tube bundle model the latter only honors the pore size of porous media while our method honors both the pore size and connectivity which is important for the fluid flow simulation from the method implementation point of view the peng s method and saxena s method are easy to be understood and replicated which are the advantages of these methods however these two methods have large uncertainties in predicting permeabilities in particular for samples with small permeabilities in addition saxena s method relies on the empirical parameter p while it is hard to obtain the proper p for various rock types 4 conclusions in this study a novel method for constructing pore network from 2d rock images has been introduced 2d images are not fully connected as some connections are remain undetected therefore we rebuilt the missing connections from 2d images by connecting the isolated pore clusters based on the statistical relationships between 2d and 3d images the spatial proximity and priority of connecting large clusters are the two basic connecting principles in this new method connecting the close and large clusters preferentially and carefully selecting the root clusters are important for the overall connectivity and conductivity of the pore network few concepts from complex networks were used to analyze the topology and connectivity of pore networks that make the connections in 2d images more realistic and optimal a new topological descriptor was proposed and was found to perform well in quantifying the network topology by considering both the isolated pore cluster number and the euler characteristic two basic parameters involved in the new method i e root clusters and the percentage of end nodes have been discussed the pore network extracted from 2d images by the new method can predict permeability with an appropriate choice of the two basic parameters the results are in reasonable agreement with the reference cases for different rock types and complex pore structures the key reason is that the new method can honor not only the pore size distribution but also the topology of the real pore structures which is known to be important credit authorship contribution statement chenhui wang conceptualization methodology software formal analysis formal analysis writing original draft writing review editing visualization kejian wu conceptualization methodology writing review editing supervision project administration gilbert g scott validation writing review editing ailin jia writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment c w thanks the financial support from china scholarship council csc for his ph d study the authors thank anasuria operating company limited aoc for making available the core plug samples the authors thank john still of university of aberdeen centre for electron microscopy analysis and characterisation acemac for the assistance in the acquisition of micro ct and sem images 
112,ganglia or bubbles trapped by capillary forces inside porous materials occur in a wide range of subsurface and manufacturing applications in geologic co2 storage ganglia are desired as they render the injected co2 hydrodynamically immobile but they may evolve by dissolution or mass exchange across the brine called ripening in fuel cells and electrolyzers water oxygen ganglia must be removed to ensure optimal performance of the device in both applications the porous microstructure plays a key role in how the geometry topology of ganglia evolve as they grow shrink in size this dependence is poorly understood but important for controlling ganglion dynamics pore scale models are useful tools for probing the physics but existing ones are either computationally expensive e g cfd or incapable of accurately simulating ganglia spanning multiple pores e g pore networks our main contribution is a new pore network model pnm that removes this barrier the pnm can simulate the evolution of multi pore occupying ganglia due to diffusive mass transfer by ripening or an external concentration field we validate the pnm against published microfluidic experiments 2d direct numerical simulations and an analytical solution previously derived by the authors for a 2d homogeneous domain we then use the pnm to study quasi static growth shrinkage cycles of trapped ganglia inside heterogeneous porous media the findings constitute our second contribution generalizing previous theoretical results by the authors from 2d homogeneous to 3d planar heterogeneous microstructures they include 1 the interfacial area of a ganglion depends approximately linearly on its volume 2 if the throat to pore aspect ratio is large growth is percolation like but 3 if it is small a hitherto unreported intermittent growth regime precedes percolation in which ganglia repeatedly fragment and reconnect these outcomes have implications for selecting optimal storage sites for co2 and designing fuel cells and electrolyzers with finetuned porous microstructures keywords porous media ganglia ostwald ripening pore network capillary trapping co2 storage nomenclature σ interfacial tension κ interfacial curvature pc capillary pressure of ganglion non wetting phase vb volume of ganglion non wetting phase γb interfacial area of ganglion non wetting phase χb euler characteristic of ganglion non wetting phase fb interfacial free energy of ganglion non wetting phase mb mass of a bubble ganglion vp volume of a pore ap surface area of a pore rp radius of inscribed sphere in a pore vc volume of inscribed sphere in a pore p c min minimum capillary pressure at v b v c rt side half length of a square cross sectioned throat ls lattice spacing of a pore network lt length of a throat vpi volume of pore i vci volume of inscribed sphere in pore i rpi radius of inscribed sphere in pore i vbi non wetting phase volume in pore i ni of throats connected to pore i ci solute concentration in pore i aij throat cross sectional area between pores i and j lij throat length between pores i and j a b n empirical parameters in eq 1 pci s capillary pressure at singleton pore i pci i capillary pressure at interior pore i pci b capillary pressure at branch pore i pci t capillary pressure at terminal pore i pci o capillary pressure at non terminal branch pore i ni of interior pores in a ganglion s graph nb of branch pores in a ganglion s graph no of non terminal branch pores in a ganglion s graph vb c critical volume of a ganglion pce capillary entry pressure of a throat pcso snap off capillary pressure of a throat co reference concentration r universal gas constant vbm molar volume of non wetting phase t temperature dm molecular diffusion coefficient ntb of boundary throats of a ganglion dt time step dvb increment in bubble ganglion volume sb saturation of non wetting phase in network sb critical non wetting phase saturation ξ throat to pore aspect ratio rt rp rhet network heterogeneity measure r p max r p min ca capillary number 1 introduction a ganglion or bubble trapped inside a porous medium is a disconnected fluid phase with respect to which the porous solid is non wetting ganglia occur commonly in a number of applications ranging anywhere from the sequestration of co2 in deep saline aquifers to mitigate climate change to the removal of non aqueous pollutant liquids napl from groundwater sahloul et al 2002 dillard and blunt 2000 chomsurin and werth 2003 imhoff et al 1996 design of optimal microstructures to manage water or oxygen in fuel cells or electrolyzers lee et al 2020 andersson et al 2016 lu et al 2010 nucleation and growth of vapor bubbles during boiling in heat exchangers mori and okuyama 2009 drying and wicking of water droplets through hydrophobic face masks sarkar et al 2020 and oxygenation of groundwater by air bubbles created after rainfalls holocher et al 2003 bloomsburg and corey 1964 oswald et al 2008 despite their ubiquity the growth and shrinkage of ganglia inside heterogeneous porous materials specifically the relationship between their geometry topology and the porous microstructure remains poorly understood in this work we focus on the growth and shrinkage of partially miscible ganglia due to mass transfer by ostwald ripening ostwald 1897 or an external concentration field imposed through the wetting phase we explore this topic in the context of geologic co2 sequestration gcs as it constitutes our primary motivation ostwald ripening is the process by which mass is transferred from ganglia with a high capillary pressure pc to those with a low capillary pressure or interfacial curvature voorhees 1985 it occurs because high pc ganglia dissolve faster into the wetting phase creating a concentration gradient that drives molecular diffusion in a bulk fluid where ganglia are always spherical ripening causes small bubbles high pc to become absorbed by large bubbles low pc voorhees 1985 voorhees 1992 bray 1994 in a porous medium however a ganglion s capillary pressure pc and volume vb are not monotonically correlated xu et al 2017 wang et al 2021 de chalendar et al 2018 it is therefore entirely possible for a large ganglion to be in thermodynamic equilibrium with a small ganglion de chalendar et al 2018 mehmani and xu 2022 xu et al 2019 li et al 2020 gao et al 2021 the reason is that the geometry of the void space plays an important role rendering the relation between pc and vb not only non monotonic but also discontinuous wang et al 2021 given an initial population of differently sized ganglia in a porous medium the equilibrium state of the non wetting phase no longer consists of a single large spherical bubble as in a bulk fluid instead it consists of a new population of ganglia that share the same pc an important question in the context of gcs is can ripening cause super sized ganglia to emerge which can then leak by buoyancy from the subsurface in this paper we do not answer this question directly instead we develop the necessary modeling tools a pore network model pnm that allows probing this question deeply and systematically in the future we do however use the pnm to obtain partial answers by focusing on the quasi static growth shrinkage cycles of trapped ganglia to understand the linkage between their geometry topology and the confining porous microstructure what do trapped ganglia inside a porous medium look like experiments over the past decade have painted a vivid picture most involve injecting a non wetting phase e g supercritical co2 into a core sample followed by a wetting phase e g brine to induce capillary trapping the generated ganglia are then imaged with an x ray µct scanner and analyzed three important observations have been reported 1 it is much more common for ganglia to occupy multiple pores than a single pore iglauer et al 2011 iglauer et al 2013 andrew et al 2014 geistlinger et al 2014 garing et al 2017 2 the relationship between a ganglion s interfacial area гb and volume vb is approximately linear at large vb andrew et al 2014 geistlinger et al 2014 2015 geistlinger and mohammadian 2015 iglauer et al 2013 landry et al 2011 and 3 the more connected a ganglion is the easier it can be mobilized herring et al 2013 the first places a requirement on pore scale models of ostwald ripening to incorporate multi pore ganglia this applies especially to pnms as alternative direct numerical simulation dns approaches are computationally expensive beyond a handful of ganglia the requirement however is not satisfied by any existing pnm the second observation implies that super sized ganglia are unlikely to emerge by ripening because ripening is driven by differences in pc and such differences are zero if гb is a linear function of vb note pc dгb dvb in the literature linearity is explained by frequent appeal to percolation theory iglauer et al 2011 geistlinger and mohammadian 2015 geistlinger et al 2015 stauffer and aharony 1992 which is valid for ganglia trapped during fluid fluid displacements such processes can often be approximated as a sequence of bond invasion or site retraction events in section 4 2 we show that ganglion evolution post trapping and due to ripening or solute transport is not percolation like in all microstructures only some the third and final observation implies that it is safer to store co2 in rocks that promote ganglion fragmentation because then large connected ganglia with a potential to leak by buoyancy cannot form a follow up question then is what microstructures favor fragmentation this work fills the above knowledge gaps the main contribution of this work is a new pore network model pnm that can simulate the ostwald ripening or more generally solute induced growth shrinkage of arbitrarily sized ganglia inside heterogeneous porous domains the pnm conceptualizes the complex microstructure of a porous medium with a computational graph consisting of pores or nodes and throats or links pores provide storage volume and throats capillary resistance to ganglia we assume that ganglia are perfectly non wetting incompressible and hydrodynamically stagnant the last condition entails the bulk pressure gradient within each phase is zero and ganglion evolution is driven entirely by ripening or solute transport in the pnm ganglia can invade new pores retract from old ones dislocate or displace entirely into larger pores fragment into smaller clusters and coalesce with other ganglia these processes occur quasi statically or in a sequence of equilibrium steps the pnm s algorithm consists of two parts 1 one that computes the capillary equilibrium state of each ganglion given their volume and pore occupancy and 2 another that computes the mass transfer to from each ganglion due to ripening or an external concentration field the first part is more complex as it must ensure the equilibrium state of each ganglion is thermodynamically consistent this means each ganglion must satisfy mass conservation have uniform interfacial curvature and be stable to perturbations much of this paper is therefore devoted to this first part the second part of the algorithm is simpler and the exposition commensurately shorter pnms capable of simulating ganglion evolution are not new but rare most are developed in the contexts of either 1 nucleation and growth of gas bubbles due to depressurization or boiling in porous media li and yortsos 1991 li and yortsos 1995 dominguez et al 2000 felipe et al 2005 bories and prat 2002 zhao and ioannidis 2011 or 2 napl dissolution in groundwater aquifers dillard and blunt 2000 jia et al 1999 held and celia 2001 agaoglu et al 2016 aminnaji et al 2019 the former focuses exclusively on ganglion growth and the latter on ganglion shrinkage despite significant progress in both areas available pnms have two key limitations they either force percolation like patterns on growth shrinkage of ganglia instead of allowing them to emerge naturally from the underlying physics or they oversimplify the relationship between a ganglion s pc and vb inside each occupied pore if not neglect it altogether the latter prohibits the use of current pnms for modeling ostwald ripening in which mass transfer is driven by differences in the capillary pressure of ganglia more recently pnms specifically designed to model ostwald ripening have been proposed de chalendar et al 2018 mehmani and xu 2022 however all are limited to ganglia that occupy only one pore the main novelty of our pnm is that it can handle ganglia spanning multiple pores while accounting for the detailed relationship between pc and vb inside each pore we validate our pnm against published microfluidic experiments direct numerical simulation dns and an analytical solution the pnm extends a previous model mehmani and xu 2022 developed by the authors that is limited to ganglia confined to only one pore we next use the pnm to simulate the quasi static growth shrinkage cycles of a non wetting phase inside porous microstructures that have different aspect ratios ξ and pore size distributions psd the non wetting phase is grown shrunk by imposing a fixed concentration at the domain s boundary if during a cycle the non wetting phase fragments into disconnected ganglia the capillary pressure of those ganglia are kept equal by periodically allowing them to ripen while imposing a zero flux external boundary we record the capillary pressure pc interfacial area гb euler characteristic a measure of topology χb and volume vb of the non wetting phase throughout each cycle our findings constitute the second contribution of this work and include 1 the relation between гb and vb is indeed linear for all ξ and psd during growth but only approximately so during shrinkage 2 growth shrinkage paths are not percolation like for all ξ and psd and may exhibit intermittency akin to the dynamic connectivity flow regime recently reported for fluid fluid displacements reynolds et al 2017 3 the non wetting phase is more connected either when ξ is large i e pores and throats have similar sizes or when ganglia are larger than a microstructure dependent threshold and 4 the relationship between pc and vb is oscillatory and the magnitude of oscillations attenuates as vb these findings generalize the conclusions of a recent paper by the authors in which an analytical solution for the growth shrinkage cycles of a ganglion inside a 2d homogeneous porous domain was derived wang et al 2021 the paper s outline is as follows section 2 describes the problem we aim to solve section 3 details the pnm which include a statement of definitions used throughout this work section 3 1 an algorithm to compute the capillary equilibrium of multi pore ganglia sections 3 2 8 and an algorithm to simulate mass transfer by ostwald ripening or an external concentration field section 3 9 in section 4 1 we validate the pnm against two published micromodel experiments dns and an analytical solution section 4 2 presents results for quasi static growth shrinkage cycles of trapped ganglia inside heterogeneous microstructures in section 5 we discuss the limitations of the pnm its future extensions and implications for gcs the paper concludes with section 6 2 problem description consider a porous medium occupied by a wetting phase and a non wetting phase the non wetting phase is trapped in the form of isolated ganglia whereas the wetting phase is continuous and spans the entire pore space via thin films see fig 1 we make the following assumptions 1 both phases are incompressible and hydrodynamically stagnant i e the bulk pressure gradient inside each phase is zero 2 the capillary pressure across each ganglion s interface satisfies the young laplace equation pc σκ where σ is the interfacial tension and κ the interfacial curvature 3 the solid is rigid and perfectly non wetting with respect to each ganglion i e contact angle is zero 4 the non wetting phase is partially miscible into the wetting phase but not the reverse i e ganglia are pure 5 the concentration of the dissolved non wetting phase within the wetting phase is dilute and obeys fick s law of diffusion and 6 each ganglion is in local thermodynamic equilibrium with its immediately surrounding wetting fluid i e dissolution is instantaneous our goal is to understand the interplay between the geometry topology of trapped ganglia during quasi static growth shrinkage cycles and the microstructure of a porous medium in the following sections we propose a pore network model pnm that enables just that it captures all the salient capillary physics ganglia might undergo including pore invasion interface retraction snap off dislocation fragmentation and coalescence the pnm consists of two parts around which the exposition is organized 1 an algorithm that computes the capillary equilibrium of each ganglion given their volume and pore occupancy and 2 another that computes the mass transfer between ganglia due to ripening or an imposed concentration field sections 3 2 3 8 lay the foundations of the first algorithm and section 3 9 those of the second in section 3 1 we describe the conceptual model adopted by the pnm and its associated definitions sections 3 2 3 3 present constitutive relations that capture the capillary pressure of ganglia within pores and throats section 3 4 describes how these relations can be combined to compute the capillary equilibrium state of a multi pore ganglion in sections 3 5 3 6 discrete capillary events e g breakthrough snap off experienced by ganglia are discussed section 3 7 provides two examples of quasi static growth shrinkage cycles inside 1d pore networks section 3 8 summarizes the final capillary equilibration algorithm proposed and section 3 9 presents the equations used to model mass transfer 3 pore network model 3 1 conceptual model and definitions the pnm conceptualizes a porous medium as an interconnected network of pores nodes and throats links see fig 1 without loss of generality we consider 2d lattice networks and denote the lattice spacing by ls we assume pores to be approximately cubic in shape with a side half length of rp and an inscribed sphere volume of vc by approximately cubic we mean each pore has a volume and maximal inscribed sphere identical to a cube we refer to vc as the critical volume of a pore we assume throats to be prismatic in shape with a square cross section the side half length of which is rt for a throat connecting pores p1 and p2 rt is obtained from rt ξ min rp1 rp2 where ξ 0 1 is the throat to pore aspect ratio this equation ensures that adjacent pores and throats are correlated in size as is the case in geologic porous media bryant et al 1993 and that throats are always smaller than the sandwiching pores the throat length between pores p1 and p2 is obtained from lt ls rp1 rp2 we assume throats to be mere links between pores with zero volume in other words all the void volume of the network is assigned to the pores the pore network is occupied by a non wetting phase surrounded by a wetting phase fig 1 because pores and throats are assigned angular shapes the wetting phase is assumed to be connected throughout the network the non wetting phase by contrast is disconnected into clusters we refer to each cluster as a bubble if it occupies only one pore and a ganglion if it occupies one or more pores fig 1 with reference to fig 2 we define the graph of a ganglion as the subnetwork of pores and throats that the ganglion occupies we classify pores in the ganglion s graph into four types if the ganglion is a bubble we call the occupied pore a singleton if the ganglion occupies more than one pore the occupied pores are one of two types branch or interior branch pores lie at the extremities of a ganglion s graph and are connected to the graph by only one throat interior pores constitute all the remaining pores in the ganglion s graph they connect to the graph by more than one throat we call the smallest branch pore of a ganglion its terminal pore a ganglion can have at most one terminal pore or none if its graph has no branch pores fig 2 illustrates three ganglia along with their corresponding graphs the different pore types are annotated the leftmost ganglion consists of a singleton pore the middle ganglion occupies two interior pores and three branch pores the terminal pore is colored in black the rightmost ganglion has no branch pores and is thus made up of only interior pores the neighbor pores of a ganglion are defined as those pores not occupied by the ganglion but separated from it by only one throat throats that connect the ganglion to its neighbor pores are called boundary throats which lie at the outer perimeter of the ganglion we define interior throats as all the throats occupied by the ganglion note that two pores sandwiching an interior throat must always be occupied by the same ganglion we use two terms to describe the non wetting phase content of a pore occupied by a ganglion if the non wetting phase volume in a pore is less than vc the ganglion is said to be in a hypocritical state locally otherwise the state is hypercritical see fig 2 we note that among all the branch pores of a ganglion only the terminal pore may be hypocritical the terminal pore is the smallest of all branch pores and can sustain capillary pressures larger than or equal to the maximal inscribed sphere in it but such capillary pressures can only be sustained by other branch pores if they are hypercritical otherwise the ganglion will become unstable and fill those larger branch pores until they reach a hypercritical state wang et al 2021 as a result our pnm defines capillary equilibrium as the most thermodynamically stable among the many metastable configuration a ganglion can assume 3 2 capillary pressures within pores to each of the pore types in a ganglion s graph fig 2 a constitutive equation is assigned that describes the relationship between the ganglion s capillary pressure and volume in that pore the equation takes the form pci pci vbi where pci and vbi are the capillary pressure and volume of the ganglion in pore i respectively the equations are summarized below for a singleton pore 1a p c i p c i s v b i p c i min v c i v b i 1 3 if v b i v c i p c i min 1 a v b i v c i v p i v c i b v b i v c i v p i v b i if v b i v c i for an interior pore 1b p c i p c i i v b i p c i m i n 1 a v b i v c i v p i v c i b v b i v c i v p i v b i for a branch pore 1c p c i p c i b v b i p c e p c i m i n v c i v b i v c i n p c i m i n i f v b i v c i p c i m i n 1 a v b i v c i v p i v c i b v b i v c i v p i v b i i f v b i v c i eq 1c also applies to terminal pores which are just a special kind of branch pore in eqs 1a c vci is the critical volume and vpi the total volume of pore i pci min is the capillary pressure corresponding to the largest inscribed sphere within pore i notice when vbi vci eqs 1a c satisfy pci pci min in eq 1c pce is the capillary entry pressure defined in section 3 3 of the interior throat that connects the branch pore to the ganglion s graph parameters a b and n depend on the pore geometry for simplicity and unless otherwise stated we use a 0 905 b 0 01 and n 2 for all pore types in this work which mimic recent microfluidic experiments by the authors xu et al 2017 we note the specific forms of eqs 1a c are not derived from first principles but rather postulated based on prior experimental and theoretical analyses xu et al 2017 wang et al 2021 in section 5 2 we discuss how similar equations for more complex pore shapes beyond the semi cubic pores considered herein can be derived using direct numerical simulation the task however falls outside the scope of this paper figs 3 a c provide a graphical illustration of eqs 1a c for a singleton pore the pci s vbi function is u shaped when vbi vci the ganglion is spherical and does not touch the pore walls and when vbi vci the ganglion is deformed by the pore walls and is no longer spherical causing pci to increase with vbi for an interior pore the pci i vbi function is monotonic this is an approximation but one that is consistent with microfluidic experiments tsimpanogiannis et al 1999 held and celia 2001 the rationale behind the monotonicity is that interior pores act as bridges within a ganglion s graph and can therefore tolerate very small capillary pressures two examples an i bridge and an l bridge are depicted in the inset of fig 3b while the pci i vbi function in fig 3b extends all the way to pci 0 such low capillary pressures are never actually achieved in the pnm because of the lower bound eq 3 in section 3 3 imposed by a process called snap off described in section 3 5 4 this means that the ganglion will fragment if its capillary pressure gets too low for a branch pore the pci b vbi function is also u shaped but unlike pci s vbi it has a finite intercept with the y axis the capillary pressure pci at this intercept is pce the insets of fig 3c display ganglion configurations that correspond to two different parts of pci b vbi in all the three graphs shown in fig 3 pci goes to infinity as vbi approaches the pore volume vpi similar to the case of pci i vbi at low capillary pressures very high capillary pressures are never achieved in the pnm because of the upper bound eq 2 in section 3 3 imposed by a process called breakthrough described in section 3 5 1 this means the ganglion will invade a neighbor pore if its capillary pressure gets too high 3 3 capillary pressures within throats because throats here have a square cross section and the contact angle is assumed zero if a throat is occupied by a ganglion the wetting phase resides in the corners and the non wetting phase in the center of the throat s cross section two capillary pressure thresholds are associated with each throat 1 entry capillary pressure and 2 snap off capillary pressure for a throat initially filled with the wetting phase the entry pressure pce is the minimum pressure drop that must be exerted across the interface of a ganglion to push it through that throat the invasion event is referred to as a breakthrough the entry pressure of a throat with side half length rt is rabbani et al 2016 2 p c e σ r t 1 π 2 for a throat initially occupied by both phases the snap off pressure pcso is the minimum capillary pressure that the fluid fluid interface can sustain without rupturing roof 1970 more specifically if a ganglion s capillary pressure drops below pcso the wetting phase occupying the corners of the throat will swell and eventually sever the non wetting phase occupying the center the event is referred to as a snap off in the aftermath of a snap off the throat becomes saturated with the wetting phase the snap off pressure of a throat with side half length rt is chen et al 2020 3 p c s o σ r t eq 3 corresponds to the largest inscribed cylinder in the throat notice pce pcso always holds 3 4 capillary pressure of a multi pore ganglion the capillary pressure of a ganglion pc depends on its volume vb and the pores and throats it occupies if the ganglion is a bubble occupying only one pore the dependence follows eq 1a but if the ganglion occupies more than one pore pc must be calculated using the capillary equilibration algorithm described below the crux of this algorithm is to combine the constitutive eqs 1b c presented in section 3 2 for all the different pore types in the ganglion s graph this combination must be done in such a way so as to ensure 1 the capillary pressure of the ganglion is uniform across all the pores it occupies and 2 the sum of the non wetting phase volumes inside all occupied pores equals the ganglion s volume the latter requirement is a statement of volume or mass conservation which holds because ganglia are assumed to be incompressible section 2 the ganglion equilibration algorithm goes as follows consider a ganglion with a known volume vb that occupies n 1 pores denote the volume of these pores by vp1 vp2 vpn each pore is either an interior pore or a branch pore let vbi be the volume of the ganglion inside pore i to compute the capillary pressure of the ganglion we must solve the nonlinear algebraic equation below for pc which is a statement of volume conservation 4 v b i 1 n v b i s t v b i p c i x i 1 p c in eq 4 subscript xi is a placeholder for either i or b respectively they stand for interior and branch pores and indicate the use of either eq 1b or 1c if pore i is a branch pore xi b otherwise xi i to develop a robust way of solving eq 4 we proceed by examining its structure more closely we start by first partitioning branch pores into one terminal pore if it exists because there can be at most one and all remaining non terminal branch pores we denote the former with the subscript xi t and the latter with xi o i e b t o next we combine the two equations in eq 4 and split the summation according to the different pore types to obtain 5a v b i 1 n i p c i i 1 p c i 1 n o p c i o 1 p c p c t 1 p c which applies when a terminal pore exists and 5b v b i 1 n i p c i i 1 p c when a terminal pore does not exist notice that the absence of a terminal pore implies the absence of any branch pore from the ganglion s graph an example is an o shaped ganglion i e ring formation in eq 5 ni is the number of interior pores and no the number of non terminal branch pores if either ni 0 or no 0 in eq 5a the corresponding summation is zero solving eq 5b for pc is straightforward because pci i vbi is a monotonic function of vbi eq 1b as seen from fig 3b note the inverse of a monotonic function is monotonic and the finite sum of monotonic functions is also monotonic therefore the right hand side rhs of eq 5b is a monotonic function of pc which means it has exactly one root by contrast eq 5a is more difficult to solve because pci t vbi and pci o vbi are non monotonic functions as both equal eq 1c see fig 3c and so eq 5a may have multiple roots but recall from section 3 1 that only the terminal pore of a ganglion can be in a hypocritical state vbi vci while all non terminal branch pores are always hypercritical vbi vci because the hypercritical limb of pci o vbi is monotonic the only source of non monotonicity in eq 5a is pci t vbi to eliminate it we must determine a priori whether the terminal pore is hypocritical or hypercritical because then we can select the appropriate monotonic limb of pci t vbi in eq 1c we proceed by defining the critical volume of a ganglion as 6 v b c i 1 n i p c i i 1 p c min t i 1 n o p c i o 1 p c min t p c t 1 p c min t where pc min t is the minimum capillary pressure of the terminal pore i e pc min t σ rp min t such that rp min t is the radius of the maximal inscribed sphere within the terminal pore notice pc min t is the smallest capillary pressure that the ganglion can sustain without having to alter its pore occupancy the key observation here is that if vb v b c the terminal pore must be hypercritical and if vb v b c it must be hypocritical as a result by comparing vb to v b c we can determine whether to use the hypocritical or hypercritical limb of pci t vbi in eq 1c to solve eq 5a for pc the choice would render p ci t vbi and thus the rhs of eq 5a monotonic with a unique root in this work we use the bisection method as a robust way of solving eqs 5a b the above algorithm can be used to construct the pc vb curve of a multi pore ganglion figs 4 5 show two examples the blue magenta green and black curves correspond to ganglia that occupy 1 2 3 and 4 pores respectively in fig 4 occupied pores have equal sizes whereas in fig 5 they have different sizes the local minima correspond to vb vb c and pc pc min t the dotted lines also highlighted in yellow indicate unstable ganglion configurations and should be ignored only solid lines count towards the pc vb curves of ganglia the dotted lines are unstable because they correspond to vb vb c and dpc dvb 0 the first condition says that the ganglion s graph has a terminal pore in it and it is in a hypocritical state the second condition says the capillary pressure of the ganglion must increase if its volume grows but that is physically impossible because the ganglion is free to move inside the terminal pore i e hypocritical if the ganglion grows its volume within the terminal pore will increase and with it its capillary pressure or interfacial curvature will drop we conclude from this contradiction that for ganglia satisfying vb vb c dpc dvb 0 must hold for a more in depth discussion the reader is referred to a recent stability analysis published by the authors for multi pore ganglia wang et al 2021 in the next section we show that if a growing shrinking ganglion attempts to enter a dotted segment of the pc vb curve figs 4 5 a rapid reconfiguration of the ganglion s geometry ensues which we call a capillary event 3 5 capillary events of a ganglion there are four capillary events that a ganglion may undergo which are discussed below 3 5 1 breakthrough a breakthrough event is defined as the increase in the pore occupancy of a ganglion by 1 it occurs if the ganglion s capillary pressure pc exceeds the capillary entry pressure of one of its boundary throats pce if pc pce holds for more than one boundary throat the throat with the smallest pce is invaded in other words breakthrough is modeled quasi statically where throats are invaded one at a time not simultaneously on a ganglion s pc vb curve a breakthrough event is identified by a transition from a segment associated with a pore occupancy of n to another with a pore occupancy of n 1 fig 6 shows parts of the pc vb curves of three ganglia breakthrough events are marked by red dots notice the breakthroughs can either coincide with a sudden drop in pc as in fig 6a or with a continuous decrease in pc as in figs 6b c the occurrence of one or the other depends on the geometries of occupied pores reflected in the constitutive pci vbi equations eq 1 of section 3 2 for the pci vbi curves assumed herein we observe that if breakthrough is continuous it tends to be short lived and a sudden drop in pc follows immediately after see figs 6b c we also note that if the ganglion has a terminal pore that is hypocritical breakthrough cannot occur because the ganglion is free to move inside the terminal pore to adjust itself 3 5 2 pop the sudden drop in the pc of a growing ganglion is defined as a pop event it occurs if any further increase in the ganglion s volume would place it on an unstable segment of the ganglion s pc vb curve the transitions from points 6 to 7 in fig 6a 7 to 8 in fig 6b and 8 to 9 in fig 6c are pop events notice a pop does not necessarily coincide with a breakthrough in fig 6a pop and breakthrough events coincide but in figs 6b c they do not in the former case pore occupancy increases by 1 but in the latter pore occupancy remains unchanged we note that for very large vb pop and breakthrough events almost always coincide 3 5 3 flinch a flinch event is defined as a sudden surge in the pc of a shrinking ganglion it occurs if any further decrease in the ganglion s volume would place it on an unstable segment of the ganglion s pc vb curve in fig 7 the upward red arrows between points 4 and 5 are flinch events there are two types of flinch events partial and complete partial flinch does not change the pore occupancy of a ganglion as seen in fig 7a by contrast complete flinch reduces the pore occupancy of a ganglion by one or more pores fig 7b illustrates a complete flinch where pore occupancy decreases from n to n 1 fig 7c shows another complete flinch where pore occupancy decreases from n to n 2 a flinch can therefore be thought of as a pop event run in reverse 3 5 4 snap off a snap off event is the sudden disconnection of a ganglion along an occupied throat s length it occurs if the ganglion s pc falls below the snap off capillary pressure pcso of one of its interior throats quantified by eq 3 if pc pcso holds for more than one interior throat the ganglion snaps off in all such throats since the pc of a ganglion does not change during snap off andrew et al 2014 simultaneous snap off of multiple throats is equivalent to their one by one or quasi static snap off 3 6 topological changes caused by capillary events during any one of the capillary events described above the topology of a ganglion may change this requires updating the ganglion s graph which includes its pore types interior branch terminal boundary throats interior throats and neighbor pores what follows are a few specific examples if during a breakthrough event a ganglion invades a pore already occupied by another ganglion the two ganglia are merged if the invaded pore is occupied by the ganglion itself i e self intersection the connecting throat is added to the ganglion s interior throats list during snap off a ganglion may fragment into multiple smaller ganglia therefore after every snap off event we perform a graph search to identify the number of disconnected fragments and label them as new ganglia with their own graphs and thermodynamic states e g vb pc the capillary pressure of each fragment equals that of the original ganglion before snap off section 3 5 4 after a flinch event the pore occupancy and hence topology of a ganglion can also change a very common scenario is when a breakthrough or flinch occurs immediately after a flinch or breakthrough event such two event sequences are caused by the fact that the volume or equivalently mass due to incompressibility of a ganglion is conserved we therefore check for all possible breakthrough or flinch events immediately after every flinch or breakthrough event in the pnm finally when a ganglion invades a pore that is much larger than those already occupied it may fully move into that pore we call this ganglion dislocation and it is captured automatically by the iterative pnm algorithm presented later in section 3 8 3 7 ganglion growth shrinkage cycles now that we know how to construct the pc vb curve of a multi pore ganglion section 3 4 and understand the capillary events it may undergo section 3 5 we can visualize the evolution paths of a simple ganglion on its pc vb curve during growth and shrinkage figs 8 9 exemplify two such growth and shrinkage paths inside a string of four pores highlighted in yellow in fig 8 pores have identical size homogeneous whereas in fig 9 they do not heterogeneous let us focus first on the growth path of fig 8 at point a the ganglion occupies only one pore once it reaches point b the ganglion breaks through into the second pore from the left had the breakthrough not occurred the ganglion would have entered an unstable dotted segment of the pc vb curve notice the capillary pressure at point b is equal to the capillary entry pressure of the throat connecting pores 1 and 2 as the ganglion grows further it travels on the solid magenta segment of the pc vb curve until it reaches the unstable limb marked by the dotted green line at this point the ganglion breaks through into pore 3 and simultaneously undergoes a pop event causing a sudden decrease in the ganglion s capillary pressure we are now at point c note that unlike the breakthrough event at point b which was continuous the breakthrough at point c coincided with a pop as the ganglion grows even further it travels on the solid green line of the pc vb curve until it undergoes a similar breakthrough event coincident again with a pop leading it to point d focusing next on the shrinkage path of fig 8 the ganglion initially occupies four pores once it shrinks to point a the ganglion undergoes a flinch event that places it at point b the flinch is accompanied by a sudden surge in the ganglion s capillary pressure had it not occurred the ganglion would have entered an unstable segment of the pc vb curve black dotted line after the ganglion has shrunk further to point c a similar flinch takes place landing the ganglion at point d beyond point d shrinkage is continuous and no sudden jumps in capillary pressure occur specifically at point e the ganglion retracts from pore 2 into pore 1 without flinching fig 9 illustrates similar growth and shrinkage paths inside four heterogeneous pores the only marked difference compared to fig 8 is that the first flinch event along the shrinkage path between points a and b reduces the ganglion s pore occupancy by two not one and by so doing the flinch completely bypasses the solid green segment of the pc vb curve overall a key takeaway from figs 8 9 is that the growth shrinkage cycle of a ganglion within a porous medium is hysteretic i e growth and shrinkage paths do not overlap in section 4 2 we examine such cycles in more detail 3 8 capillary equilibrium of a ganglion population for a topologically complex ganglion residing inside a heterogeneous porous medium that is occupied by other ganglia it is difficult if not impossible to visualize growth and shrinkage paths on a pc vb curve similar to figs 8 9 instead these paths must be computed algorithmically in appendix a we present algorithm 1 to do just that the problem algorithm 1 aims to solve is this given a population of differently sized ganglia that are at capillary equilibrium and have known pore occupancies what is the new equilibrium configuration if each ganglion s volume is incremented or decremented by a small amount the problem is important for solving ganglion evolution problems like ostwald ripening where ganglia increase or decrease in volume due to mass transfer algorithm 1 is iterative and executes the following steps until convergence at which point the population s new equilibrium state is determined 1 holding the pore throat occupancies of all ganglia fixed use algorithm 2 in appendix a to compute the pc of each ganglion algorithm 2 embeds the ganglion equilibration algorithm described in section 3 4 whose aim is to find the roots of eqs 5a b in addition algorithm 2 accounts for the direction of each ganglion s evolution growth versus shrinkage if no roots are found flagfl 1 is returned this means it is impossible for the current pore occupancy to sustain a stable configuration a complete flinch is required if a root is found set flagfl 0 2 if flagfl 1 for any ganglion perform a complete flinch and return to step 1 else continue 3 given the pc obtained for each ganglion check for all possible breakthrough events if any are detected for a ganglion set flagbt 1 and perform the breakthrough if the invaded pore is empty add it to the ganglion s graph if the pore is occupied by another ganglion merge the two ganglia and if the invaded pore is occupied by the ganglion itself add the connecting throat to the ganglion s interior throats list if no breakthroughs are detected set flagbt 0 4 if flagbt 1 for any ganglion return to step 1 otherwise continue 5 next check for all possible snap off events by comparing the pc of each ganglion to the pcso of its interior throats if any are detected set flagso 1 and perform the snap off by removing the affected throats from the ganglion s graph then perform a graph search to label any isolated fragments as new ganglia note these fragments have the same pc as the initial ganglion if no snap offs are detected set flagso 0 6 if flagso 1 for any ganglion return to step 1 else exit algorithm 1 outputs the updated capillary pressures of all ganglia their new pore throat occupancies and their volumes inside each occupied pore the algorithm automatically captures several experimentally observed phenomena such as a breakthrough flinch following a flinch breakthrough ganglion dislocation and a snap off following a breakthrough unlike other pnms no explicit rules are needed to capture these physics they simply emerge 3 9 balance equations for mass transfer and ostwald ripening we now present the governing equations solved by the pnm to simulate the evolution of a population of partially miscible ganglia inside a heterogeneous porous medium due to mass transfer by ostwald ripening or an imposed concentration field in section 2 the concentration at a ganglion s interface was assumed to be in local equilibrium in the pnm this means if pore j is occupied by ganglion i with capillary pressure pc i then the concentration inside pore j cj equals 7 ln c j c o p c i v b m r t eq 7 is a statement of the equality of chemical potentials between the dissolved species and the non wetting phase derived elsewhere xu et al 2019 in eq 7 vbm is the molar volume of the ganglion r the universal gas constant t temperature and co a reference concentration according to eq 7 pores occupied by ganglia that have high capillary pressures also have high dissolved concentrations if the capillary pressures of these ganglia differ eq 7 engenders a concentration gradient through the wetting phase that drives molecular diffusion the result is mass transfer from ganglia that have a high capillary pressure to those with a low capillary pressure over time some ganglia will grow while others will shrink or even disappear notice because the capillary pressure of a ganglion is uniform across all the pores it occupies i e capillary equilibrium eq 7 entails that the dissolved concentration within those pores is also uniform the evolution of the solute concentration in an empty pore j not occupied by a ganglion is governed by the following species balance equation 8 d c j d t k 1 n j d m a j k c k c j l j k the lhs denotes the accumulation term and the rhs the mass exchange by diffusion between pore j and its neighboring pores in eq 8 dm is the molecular diffusion coefficient and nj the number of pores or throats connected to pore j the parameters ajk and ljk denote respectively the cross sectional area and length of the throat connecting pores j and k we solve eq 8 for the concentration of all empty pores by using the occupied pore concentrations from eq 7 as boundary conditions bcs in this work we also impose bcs on the external boundaries of the pore network which are either no flux neuman or constant concentration dirichlet to impose neumann we simply drop the diffusive flux associated with throats intersecting the external boundaries of the network from the rhs summation of eq 8 to impose dirichlet we fix the concentrations associated with pores neighboring the external boundaries the resulting system of equations is linear and solved here with a direct solver for the quasi static growth shrinkage cycles considered in section 4 2 diffusion is much faster than the rate of volume evolution of ganglia we therefore simplify eq 8 by neglecting the time derivative on the lhs once dissolved concentrations within occupied and empty pores are obtained from eqs 7 and 8 respectively we can compute the total solute mass transferred into or out of each ganglion for a ganglion with ntb boundary throats the total mass change induced by diffusion is 9 d m b d t j k 1 n t b d m a j k c k c j l j k the rhs of eq 9 sums the diffusive mass fluxes through all the boundary throats of the ganglion over one time step dt we convert the resulting mass change dmb to a volume change dvb by 10 d v b v b m d m b the new volume of the ganglion after one time step is therefore 11 v b t dt v b t d v b once all ganglion volumes have been updated via eq 11 algorithm 1 of appendix a is invoked to recalculate the capillary equilibrium of the system namely the capillary pressures pore occupancies and topologies of all ganglia are recomputed and the occurrence of capillary events e g snap off pop flinch breakthrough are checked detected and executed for the next time step the above steps are repeated starting from the solution of eq 8 subject to eq 7 and external bcs to summarize the pnm simulates mass transfer between ganglia by executing the steps below 1 set the concentration of all occupied pores using eq 7 2 compute the concentration of all empty pores by solving eq 8 use the concentrations of occupied pores from step 1 as dirichlet bcs set the external bcs of the network to either no flux neumann or constant concentration dirichlet 3 compute the mass change of each ganglion using eq 9 4 convert the mass change from step 3 into a volume change using eq 10 5 update the volume of all ganglia using eq 11 6 run algorithm 1 of appendix a to update the capillary pressure pore occupancy and topology of all ganglia in the process some ganglia may merge fragment or vanish 7 return to step 1 and repeat until a user defined termination time is reached the pseudo code of the above steps is summarized in algorithm 3 of appendix b example the network shown in fig 10 contains two ganglia the first is a singleton and occupies pore 13 and the second is a multi pore ganglion and occupies pores 2 3 4 7 and 8 the capillary pressure and dissolved concentration across pores 2 3 4 7 and 8 are uniform the concentrations in pores 2 3 4 7 8 and 13 are set by eq 7 and used as dirichlet bcs to solve the concentrations in the remaining pores via eq 8 the external bcs in fig 10 are no flux which is apparent from the fact that the external boundary throats of the network are not drawn closed system remark a note about the time step dt used in eq 9 is in order if dt is constant ripening simulations tend to be either too slow small dt or unstable large dt to circumvent this issue and to render computations fast and accurate we adjust dt adaptively during the course of the simulation we do this by picking dt such that the maximum change in the volume dvb of any ganglion is less than x of the volume of the smallest pore in the network here we set x 5 10 moreover if during simulations the volume of a singleton ganglion or bubble falls below y of the volume of the smallest pore in the network we declare it as having vanished in this work we set y 2 4 results in this section we first validate the proposed pnm against two microfluidic experiments sections 4 1 1 4 1 2 direct numerical simulation dns section 4 1 3 and an analytical solution for the growth shrinkage cycles of a ganglion in a 2d homogeneous porous medium section 4 1 4 we then apply the pnm to study growth shrinkage cycles of ganglia inside large heterogeneous pore networks section 4 2 we track the evolution of capillary pressure interfacial area volume and topology quantified by the euler characteristic of each ganglion during these cycles and examine how their interdependence is impacted by the porous microstructure 4 1 validation 4 1 1 pnm versus microfluidic experiment ripening of a bubble population we compare the pnm against ripening experiments conducted by xu et al 2017 for a population of air bubbles trapped inside a water saturated micromodel air is the non wetting phase and water the wetting phase the micromodel consists of a regular array of identical cylindrical posts or grains as shown in fig 1 sandwiched between two parallel plates bubbles occupy no more than one pore each throughout the experiment the comparison probes the validity of the pnm in predicting ripening kinetics section 3 9 not capillary dynamics of multi pore ganglia section 3 8 in a previous work mehmani and xu 2022 the authors used these experiments to validate an older pnm limited to bubbles confined to only one pore solute transport equations therein were formulated differently from those of section 3 8 eqs 8 11 including additional terms for higher order physics in this section we want to ensure that the generalized pnm herein for multi pore ganglia can still capture ripening kinetics of a bubble population with comparable accuracy while our account is self contained the reader is referred to mehmani and xu 2022 for further details relevant to this comparison the micromodel consists of 15 8 identical pores each encased by four grains the grains have a diameter of 165 μm and a depth of 26 4 μm at their narrowest cross section throats have a width of 35 μm and a depth of 14 7 μm the properties of the fluid and solute are vbm 24 200 cm3 mole dm 2 10 5 cm2 s t 293 k co 7 94 10 7 mole cm3 σ 25 4 dyne cm a key difference between the micromodel and the pnm is in the pore shapes semi cubic in the pnm but pancake shaped in the micromodel to allow for a one to one comparison in mehmani and xu 2022 we established an equivalence relation that ensures pnm and micromodel data satisfy the same dimensionless equation using this relation we obtained the following pnm parameters rpi 68 23 µm lij 80 µm and aij 2 716 103 µm2 the pci vbi function used here is slightly different from eq 1a namely we use eq 4 in mehmani and xu 2022 with a 8 and n 0 2 with these settings the relative bubble volumes vbi vpi from the pnm and the experiment become comparable to initialize the bubble volumes in the pnm we draw vbi vpi values from the initial distribution measured experimentally fig 3 in xu et al 2017 but because there are only 120 pores in the network predictions are prone to sampling variance we thus run 10 independent realizations with the pnm to obtain a statistically converged solution fig 11 a shows that the pnm agrees well with the experiment where the probability density functions pdf of vbi vpi at different time snapshots t 10 50 and 120 hr are shown note the agreement at t 0 hr is by design fig 11b depicts the same information but in the form of cummulative distribution functions cdf the only notable discrepancy in fig 11 is that at t 50 hr the pnm predicts slightly faster kinetics than the experiment in mehmani and xu 2022 this was attributed to differences in the crtical volume vci between the two geometries not equalized by the equivalence relation mentioned above we emphasize that no parameter tuning of any sort was performed in obtaining the pnm results of fig 11 4 1 2 pnm versus microfluidic experiment dissolution of a two pore ganglion here our goal is to validate the pnm in capturing dissolution induced ripening and fragmentation of a two pore ganglion fig 12 shows a microfluidic experiment by sahloul et al 2002 where a two pore ganglion isobutanol is allowed to dissolve slowly into the surrounding wetting phase water as the ganglion shrinks it first snaps off into two singleton fragments fig 12c and the fragments then continue to dissolve while simultaneously undergoing ripening at this stage they compete for survival the process culminates in the bottom fragment being absorbed into the top one the dissolution of the two pore ganglion is induced by lowering the solute concentration in the wetting phase at two outer ports not shown in fig 12 fig 13 shows the corresponding pnm simulation where the domain consists of four nearly identical pores a variance of 1 in pore size was introduced to mimic the variability in fabricating the micromodel and to introduce a slight asymmetry in ripening the ganglion is partially miscible in the wetting phase and its dissolution is induced by lowering the concentration at the two outermost empty pores of fig 13 the resulting simulated sequence of events are depicted in fig 13 and seen to agree well with the experiment in fig 12 the ganglion first snaps off into two fragments and then undergoes simultaneous dissolution and ripening we note that while the pnm and the micromodel have geometric differences 3d versus 2 5d or pancake shaped respectively their throat to pore aspect ratios are equal we also note that in fig 13 we have visualized the ganglion in each pore using circles for convenience even though its actual shape may not be spherical due to deformations induced by the pores walls this remark applies to all other figures presented in later sections that visualize pnm simulations 4 1 3 pnm versus direct numerical simulation ganglion dislocation we next validate the pnm against dns for its reproducibility of a capillary event we call ganglion dislocation or hop fig 14 shows the pnm simulation of a ganglion grown inside an array of four pores ordered in descending size from left to right the ganglion is initially placed inside pore 4 and then grown until the capillary entry pressure of the connecting throat is exceeded at this point the ganglion not only invades pore 3 but simultaneously retracts from pore 4 since pore 3 is larger than pore 4 the pnm predicts the ganglion will move entirely or dislocate from pore 4 into pore 3 as the ganglion grows further it undergoes the same event two more times namely the ganglion dislocates from pores 3 to 2 and then again from pores 2 to 1 in fig 15 we validate the above sequence of events predicted by the pnm fig 14 with direct numerical simulation dns we use a level set method for solving the two phase navier stokes equations published previously by the authors mehmani and tchelepi 2019 as it is less prone to so called spurious currents near the ganglion s interface at low capillary numbers popinet 2018 because our dns is expensive and the pnm predictions in fig 14 consist of three similar dislocation events we focus only on validating the dislocation event highlighted by the green rectangle in fig 14 put differently we aim to replicate figs 14e g with dns to render dns computationally tractable we opt for a 2d domain which is sufficient for our purpose of validating the sequence of capillary events not their timing to closely approximate the pnm geometry in fig 14 we design the dns domain as shown in fig 15 it consists of square pores that have the same relative dimensions as in the pnm i e ratio of successive pore sizes are identical rp i rp i 1 3 2 where i and i 1 are pore indices throats are made to have near zero length because their volumes are assumed zero in the pnm and finally the throat to pore aspect ratio in the dns is set equal to that of the pnm i e rt rp 2 3 using dns to grow a ganglion is more nuanced than with the pnm a ganglion is grown in the pnm by simply adding a constant increment to its volume in dns mass conservation for each incompressible phase must be imposed this means we must add two ports one to the left and another to the right boundary of the domain red rectangles in fig 15a to allow the wetting phase to escape the domain as the ganglion grows moreover a point source for the non wetting phase must be introduced to increment the ganglion in fig 15 we use a virtual needle red point placed inside pore 2 to slowly inject the non wetting phase the injection is stopped and the needle removed immediately after the ganglion breaks through into pore 1 fig 15d the system is then allowed to equilibrate figs 15e h capture this equilibration process during which the ganglion leaves pore 2 and moves entirely into pore 1 the reason the needle must be removed is because it would otherwise obstruct the ganglion other mechanisms like ostwald ripening could have been employed to grow the ganglion but growth by injection was the only option available to us in our dns we note the injection rate had to be very slow in the dns to ensure a capillary dominated regime the requirement was met in fig 15 by fixing the capillary number at ca 6 6 10 6 comparing figs 14 and 15 we see the agreement between pnm and dns is very good fig 15 confirms that the dislocation of ganglia from small to large pores is not an artifact of our pnm but a physically valid state that the ganglion finds energetically favorable to assume the phenomenon emerges naturally in the pnm without hard coding any explicit rules in the supplmentary material we also include a movie that captures the dislocation of a ganglion inside a 3d printed micromodel because geometric details of the micromodel were hard to control using our 3d printer we excluded it from the pnm validation of this section the movie however does provide further support that dislocation is an experimentally observed phenomenon 4 1 4 pnm versus analytical solution ganglion growth shrinkage cycle we now validate the pnm against an analytical solution for the growth shrinkage cycle of a perfectly non wetting ganglion inside a 2d homogeneous lattice network the analytical solution was derived previously by the authors wang et al 2021 in the pnm a ganglion is initially placed inside a single pore at the center of the network and slowly grown to a prescribed size the ganglion is then shrunk back to its original size during this cycle the capillary pressure pc interfacial free energy fb and volume vb of the ganglion are measured interfacial energy is related to interfacial area гb via fb σгb the procedure for calculating fb is detailed in appendix c we normalize pc by the capillary entry pressure of one of the identical throats pce fb by σap where ap is the surface area of one of the pores 24 rp 2 and vb by vp where vp is the volume of one of the identical pores the measured variables by the pnm are plotted in figs 16 a b and compared against those from the analytical solution in figs 16c d the agreement is very good but we note that the comparison is intended to be qualitative for the following reasons 1 the analytical solution corresponds to a 2d array of posts whereas the pnm can only handle 3d pores throats 2 the analytical solution ignores snap off because snap off is a 3d phenomenon not 2d the throat to pore aspect ratio ξ rt rp in the analytical solution is ξ 1 6 the same aspect ratio in the pnm would cause the ganglion to fragment by snap off during shrinkage rendering the comparison invalid we have therefore suppressed snap off in the pnm by choosing a larger aspect ratio ξ 2 3 for the square prismatic throats considered in the pnm the criterion ξ ½ suppresses snap off because it ensures that the minimum capillary pressure inside pores pc min 2σ rp is always larger than the snap off capillary pressure inside throats pcso σ rt in fig 16 the difference in ξ has contributed to the quantitative difference between the pnm and analytical predictions a final consideration made in the pnm simulations was to prevent the ganglion from intersecting itself i e invade a throat that connects to a pore already occupied by the ganglion this is because the analytical solution prohibits self intersections in reality however ganglia do self intersect provided they are grown or shrunk very slowly to allow the wetting phase to escape through wetting films self intersections are therefore permitted in all the pnm simulations presented in later sections the key takeaway from fig 16 is our pnm can capture salient features of growth shrinkage cycles inside porous microstructures these include in particular the characteristic oscillations of a ganglion s capillary pressure versus volume the attenuation of these oscillations at large volumes and the linear dependence between the ganglion s interfacial area and volume the fact that these features emerge naturally from the combination of a handful of constitutive pci vbi relations eqs 1a c is not at all obvious a priori this offers hope that developing better constitutive relations in the future from experiments or dns may enable quantitative predictions 4 2 growth shrinkage cycles inside heterogeneous microstructures in the previous section we discussed an analytical solution by wang et al 2021 for describing the growth shrinkage cycle of a ganglion inside a homogeneous network the main findings of that work were 1 growth shrinakge cycles are hysteretic 2 a ganglion s capillary pressure is a non monotonic oscillatory function of its volume 3 oscillations attenuate at large volumes and 4 the relationship between a ganglion s interfacial area and volume is linear during both growth and shrinkage in the following sections we attempt to generalize these observations for heterogeneous networks we control heterogeneity via two parameters 1 the variance of the pore size distribution psd and 2 throat to pore aspect ratio ξ we assume all networks have a uniform psd and we define the ratio of the largest pore rp max to the smallest pore rp min in the network as rhet rp max rp min we use rhet as a proxy for the psd s variance or heterogeneity and consider networks with rhet 1 01 3 and 9 we use rhet 1 01 instead of rhet 1 to introduce a small amount of randomness into the network this breaks any unrealistic symmetries in the evolution process of ganglia and mimics the natural randomness that is always present in fabricated micromodels even those that are nominally homogeneous we consider 2d lattice networks that are 101 101 in size 10 201 pores which is sufficient for suppressing any boundary effects that might influence a ganglion s growth or shrinkage to construct each network we first assign pore sizes drawn randomly from the psd and then assign throat sizes according to rt ξ min rp1 rp2 as described in section 3 1 three aspect ratios are considered herein ξ ¼ ½ and ¾ the pnm simualtions are initialized by placing a tiny ganglion inside a single pore at the center of the network the ganglion is then grown until it invades one of the outer boundary pores at which point it is shrunk back to its original size during this cycle the ganglion may fragment into disconnected clusters unlike the analytical solution of fig 16 to ensure all clusters are always at capillary equilibrium i e evolution is quasi static they are allowed to periodically ripen more specifically we assume that ganglia are partially miscible and their growth shrinkage is induced by turning on off a constant concentration at the external boundary of the network when the concentration is on the system is temporarily open to allow a small increment of solute to diffuse into or out of the system to induce growth or shrinkage we call this the evolution period when the boundary concentration is off the system is closed i e zero boundary flux and ganglia exchange mass until their capillary pressures equalize we call this the ripening period the ripening period ends once the capillary pressures of all ganglia reach within 1 of each other similar to fig 16 we measure the capillary pressure pc total interfacial area гb and total volume vb of the non wetting phase we express interfacial area on a per unit volume basis by defining the specific interfacial area of the non wetting phase as γb гb vb we also normalize volume vb by expressing it as the non wetting phase saturation in the pore network sb lastly we measure the euler characteristic χb of the non wetting phase defined by χb n l o where n l and o are called the betti numbers they correspond to the number of isolated objects n redundant loops l and cavities o zero here of the non wetting phase respectively armstrong et al 2019 in the following we analyze the evolution of pc γb and χb versus sb for different heterogeneities i e rhet and ξ we then juxtapose the results against those of the homogeneous network in fig 16 4 2 1 capillary pressure fig 17 shows the evolution of pc versus sb during both growth black and shrinkage red in pore networks that have different rhet and ξ compared to the analytical solution in fig 16 for a homogeneous network the plots are qualitatively similar with a few key differences first the similarities 1 growth shrinkage cylces are hysteretic and 2 pc exhibits oscillations along growth paths that attenuate at large sb the differences are 1 as ξ decreases the attentuation rate of oscillations during growth diminishes and the magnitude of oscillations amplifies 2 for large ξ ½ shrinkage paths exhibit spikes that increase in magnitude and frequency as rhet decreases and 3 for small ξ ½ shrinkage paths are relatively smooth and devoid of spikes we now proceed to explain these differences while noting that further evidence for our arguments is provided in the next two sections let us focus on the growth paths first if the aspect ratio ξ is small pores are larger than their adjacent throats hence every time the non wetting phase invades a new pore its pc drops precipitously to accommodate the lower curvature enabled by that pore immediately before invasion pc is also high because it equals the entry pressure of the connecting small throat the drop in pc causes the ganglion s capillary pressure to fall below the snap off threshold of some or all of its interior throats causing the ganlgion to fragment into multiple clusters the smaller ξ is the more extensive is fragmentation as the ganglion grows further the fragments reconnect and the process starts anew leading to the next pc spike the above process associated with small ξ ½ describes a growth pattern that is intermittent it is characterized by a sequence of fragmentation and reconnection events that give rise to highly oscillatory trajectories in pc for the square prismatic throats and cubic pores assumed herein fragmentation is triggered when ξ ½ and suppressed when ξ ½ this threshold is exact if the pore network is perfectly homogeneous i e rhet 1 and approximate otherwise for other pore and throat shapes the cut off will be different from ½ now suppose ξ is large in this case the oscillations in pc will be small because invaded pores are comparable in size to adjacent throats moreover ganglion fragmentation will be suppressed because the drop in pc after every invasion event will be insufficient to go below the snap off threshold of the interior throats of the ganglion the emergent growth pattern is thus continuous resembling a percolation process stauffer and aharony 1992 we note the intuitive reason why pc oscillations attentuate at large sb regardless of ξ is that larger ganglia have more spare volume to fill newly invaded pores with without having to drop their pc by much let us next focus on the shrinkage paths if ξ is small the initially connected ganglion fragments instantaneously into numerous isolated clusters in reponse to a slight decrease in sb or pc as mentioned earlier this is because a ganglion s interior throats have a high snap off threshold when ξ is small the fragmented clusters subsequently shrink in unison while maintaing an equal capillary pressure throughout the network ensured by the ripening periods described in section 4 2 as sb decreases further the clusters first reduce to bubbles occupying only one pore and then vanish one at a time by dissolution the result is a smooth decrease in pc suppose now that ξ is large in this case the initially connected shrinking ganglion retracts from its branch pores one by one simultaneously some interior throats undergo snap off causing the ganglion to become less connected or even to fragment the competition between pore retraction and snap off is controlled by rhet if rhet is large snap off occurs continuously during shrinkage destroying loops and creating new branch pores from which the ganglion can later retract hence the resulting pc versus vb curve fig 17 is relatively smooth and devoid of large spikes if rhet is small however pore retraction precedes snap off the ganglion first retracts from all of its branch pores until the only pores constituting its graph are interior pores i e the graph consists of only loops because interior pores can tolerate extremely low pc evident from fig 3b the ganglion s capillary pressure continues to drop until it falls below the snap off threshold of its interior throats but since rhet is small the network is approximately homogeneous and snap off occurs in multiple throats at once as a result the ganglion fragments into many small clusters engendering the large spikes observed in the shrinkage paths of fig 17 bottom left corner overall shrinkage paths mimick a site percolation process stauffer and aharony 1992 only when ξ is large not otherwise 4 2 2 interfacial area fig 18 shows the evolution of γb versus sb during both growth black and shrinkage red in pore networks with different rhet and ξ what is remarkable about the growth paths is that γb asymptotes to a constant as sb for all rhet and ξ this is true despite differences in growth regimes intermittent versus continuous as discussed in section 4 2 1 because the total interfacial area of the non wetting phase satisfies гb γbvb the dependence between гb and vb is linear for all of the heterogeneities considered the implication is extremely useful for continuum scale models of ostwald ripening li et al 2020 among others since ripening is driven by gradients in the pc of trapped ganglia and pc and гb are related by pc σ dгb dvb if гb is a linear function of vb as suggested by fig 18 then pc must be approximately constant and the driving force for ripening is zero in other words growth paths in fig 18 say that beyond a certain sb ganglia have no thermodynamic tendency to exchange mass with each other but we note that the constancy of γb at large sb holds strictly for growth paths shrinkage paths are not perfectly constant only approximately so most exhibit a smooth and slightly increasing γb with sb at large sb and a few with rhet 1 01 i e homogeneous networks and large ξ ½ exhibit discontinuities and spikes along their shrinkage paths which have the same origin as those in fig 17 see section 4 2 1 these deviations together with the overall hysteresis between growth and shrinkage paths may matter for ripening because in ripening some gangia grow while others shrink however the only way to know for certain if they do matter is to run dynamic simulations of ostwald ripening which we defer to future work we conclude with three additional remarks 1 as sb 0 the dependence between γb and sb approaches that of a spherical bubble namely γ b sb 1 3 this is consistent with experimental observations in the literature landry et al 2011 2 for small ξ ¼ in fig 18 there appears to be a minimum ganglion size below which growth is intermittent marked by chaotic variations in γb and above which growth is continuous marked by smooth variations in γb this size threshold sb increases with rhet in fig 18 the growth path for rhet 9 and ξ ¼ is dominated entirely by the intermittent regime because the network is too small we have therefore repeated the simulation in a larger 301 301 network and included it as an inset of fig 18 we see the existence of a similar threshold sb here as well in section 4 2 3 we elaborate more on this threshold and the two growth regimes note that sb in the x axis of the inset is calculated with respect to a much larger pore volume than the other plots in fig 18 3 the observation that гb is approximately a linear fuction of sb is not new similar observations have been reported for specific classes of porous materials e g sandstones in the literature iglauer et al 2013 geistlinger et al 2014 landry et al 2011 andrew et al 2014 geistlinger and mohammadian 2015 geistlinger et al 2015 to explain them frequent appeal to percolation theory iglauer et al 2011 geistlinger and mohammadian 2015 geistlinger et al 2015 stauffer and aharony 1992 is made which is valid for displacement processes that can be approximated by a sequence of bond invasion or site retraction events as noted in section 4 2 1 not all e g low ξ networks fit this mold growth paths can be intermittent for example which bears no resemblance to an orderly and sequential invasion pattern expected from percolation theory the systematic and high fidelity simulations of fig 18 fill this gap in the literature but astonishingly do not alter its existing conclusions 4 fig 18 applies strictly to spatially uncorrelated and unfractured media the relationship between γb and sb or equivalently гb and vb will likely differ for correlated porous media 4 2 3 euler characteristic fig 19 shows the evolution of χb versus sb during both growth black and shrinkage red in pore networks with different rhet and ξ fig 19 supports many of the observations made in figs 17 18 by providing a visual understanding of the non wetting phase topology let us focus on the growth path first when ξ ½ the growth of a ganglion is accompanied by a continuous generation of loops driving χb towards negative values this means that the non wetting phase becomes more connected as sb increases the observation also extends to ξ ½ except that loop generation is preceded by a period where χb is nearly constant and varies somewhat chaotically this period corresponds to the intermittent growth regime discussed in section 4 2 1 in which loop generation causing χb to decrease is balanced by ganglion fragmentation causing χb to increase as noted in section 4 2 2 what is surprising here is that there is a critical saturation sb above which growth is no longer intermittent but continuous for sb sb all ganglion fragments connect into a single cluster and χb decreases smoothly with sb thereafter similar to ξ ½ moreover sb increases with rhet for rhet 9 and ξ ¼ in fig 19 the entire growth path lies in the intermittent regime because the 101 101 network used in the simulation is too small we therefore repeated this simulation with a 301 301 network and replotted the growth path in the upper right inset of fig 19 similar to rhet 1 01 and rhet 3 we see the existence of sb here as well as in fig 18 note that sb in the x axis of the inset is calculated with respect to a much larger pore volume than the other plots in fig 19 we next focus on the shrinkage paths which are seen to consist of roughly three periods the first period large sb is dominated by the non wetting phase retracting from branch pores because pore retraction does not alter the topology of the non wetting phase χb remains roughly constant the second period medium sb is dominated by a continuous destruction of loops due to snap off as the non wetting phase becomes less and less connected χb increases towards positive values in the third period small sb the non wetting phase begins as small isolated fragments generated during period 2 and as sb decreases the fragments vanish one by one due to dissolution in order of small to large pores occupied by them the result is a continuous decrease in χb fig 19 shows that the strength and duration of each period is controlled by ξ and rhet to first order the duration of all periods depends primarily on ξ not rhet as ξ decreases periods 1 and 2 become shorter while period 3 becomes longer four extreme cases are worth noting 1 when ξ is small ¼ period 1 is nearly absent and period 2 is almost instantaneous physically this means that the non wetting phase immediately fragments into numerous small clusters in response to a tiny decrease in sb 2 when both ξ ¾ and rhet 3 are large period 3 disappears 3 when the network is homogeneous rhet 1 01 and ξ is large ½ period 2 is discontinuous and marked by occasional spikes the interpretation of this last case is as follows since all pores and throats are nearly identical when rhet 1 01 snap off in one interior throat coincides with snap off in all or most interior throats leading to the simultaneous destruction of a large number of loops and a comensurate jump in χb the spikes here have the same origin as those in figs 17 18 see sections 4 2 1 4 2 2 lastly 3 when ξ is small ¼ a new period apears between periods 2 and 3 during which χb remains constant in this period fragments generated at the end of period 2 undergo simultaneous shrinkage without any of them vanishing recall again that because shrinkage is quasi static all fragments have equal capillary pressures at all times 5 discussion 5 1 implications for geolgoic co2 sequestration figs 17 19 have two important implications for geologic co2 storage 1 ostwald ripening may not pose a serious threat to the leakage of capillary trapped co2 ganglia by buoyancy from spatially uncorrelated and unfractured rocks because the interfacial area or energy of trapped ganglia гb depends at least approximately linearly on their volume vb ganglia will have a weak tendency to merge by ripening and to subsequently mobilize by buoyancy to conclusively verify this claim however time dependent simulations of ostwald ripening for a population of multi pore ganglia are needed moreover fig 18 says nothing about the stability of trapped co2 bubbles inside spatially correlated rocks which are more common in the subsurface bryant et al 1993 both open questions will be the subject of future work 2 it appears perhaps unsurprisingly that it is safer to store co2 in rocks that have a small throat to pore size ratio ξ this is because the smaller ξ is the higher the probability will be that the non wetting phase fragments what is surprising however is that there is a minimum ganglion size sb above which the ganglion ceases to fragment and remains connected fig 19 which increases the probability of leakage by buoyancy the precise value of sb depends on the heterogeneity of the rock or rhet the higher the heterogeneity the larger is sb and the higher is the likelihood of fragmentation hence the lower is the likelihood of leakage the implication is that it is safer to store co2 in rocks that are more heterogeneous not less but since heterogeneous rocks tend to contain more potential pathways for leakage e g fractures and have less storage capacity i e poor sweep efficiency the impact of multiple competing factors must be accounted for in selecting storage sites 5 2 limitations and future extensions aside from the assumptions listed in section 2 our pnm has several limitations chief among them are the pci vbi curves in eq 1 or fig 3 for different pore types while the qualitative shape of these curves are consistent with recent experimental and theoretical observations xu et al 2017 wang et al 2021 their quantitative values are assumed herein not derived from first principles this presents a future opportunity to employ dns shams et al 2021 alpak et al 2019 or x ray µct experiments singh et al 2022 bultreys et al 2020 as means to parameterize or replace eq 1 for specific and potentially more complex pore shapes we expect the resulting pnm to be quantitatively more accurate but to not alter any of the qualitative conclusions drawn in section 4 2 another simplification related to eq 1 is that the pci vbi curves associated with l bridge and i bridge interior pores depicted in fig 3b are assumed identical in reality the two pore types will likely exhibit differences that might be worth capturing separately but whether doing so will significantly increase the accuracy of pnm predictions remains to be determined a second limitation of the pnm is that ganglia are assumed to be perfectly non wetting or have a contact angle of zero to account for non zero contact angles the main parts of the pnm that need modification are the pci vbi functions in eq 1 and the snap off and breakthrough criteria for throats given by eqs 2 3 we note that pci vbi functions corresponding to non zero contact angles tend to be more complex and discontinuous wang et al 2021 at vbi vci unlike eq 1 or fig 3 nonetheless we think here too dns can be used to numerically construct the pci vbi functions as an upscaled input to pnm the key difficulty we anticipate is in computing pci vbi functions for interior pores where more than one configuration of the non wetting phase may need to be considered i versus l bridge pores see fig 3b a theoretical analysis of the general form of pci vbi functions for non zero contact angles was recently reported by the authors wang et al 2021 a third limitation lies with the assumed throat shapes as square prisms other shapes say with a converging diverging geometry will have a different capillary entry pressure eq 2 and snap off threshold eq 3 while we do not expect different throat shapes to qualitatively alter the observations in section 4 2 we do expect quantitative impact one example is the critical aspect ratio ξ below which ganglion growth is intermittent and above which it is continuous see fig 19 another is the critical saturation sb when ξ is small above which the non wetting phase transitions from an intermittent to a continuous growth regime the exact values of the critical ξ and sb will likely depend on the throat shape and pore shape but that is embedded into eq 1 the final limitation not of the pnm but of the results presented in figs 17 19 is that all pore networks considered herein are spatially uncorrelated and planar 3d it is entirely possible that for spatially correlated networks the evolution paths of pc γb and χb versus sb look qualitatively different a reasonable expectation is that the larger the correlation length the larger sb must be for pc and γb to asymptote along growth paths see fig 18 for fully 3d domains we expect results to remain qualitatively unaltered verifying these claims however is left as future work 5 3 algorithmic considerations of the pnm for ostwald ripening in a recent work by mehmani and xu 2022 a fully implicit pnm for modeling ostwald ripening in arbitrary pore networks was proposed the pnm had one key limitation ganglia were assumed to occupy no more than one pore the pnm presented in section 3 generalizes this previous version to multi pore ganglia but the formulation algorithm 3 corresponds to a sequential not fully implicit algorithm in mehmani and xu 2022 the authors outlined two drawbacks of sequential algorithms 1 they tend to be very slow and 2 they incur errors by neglecting the gain loss in dissolved solute due to changes in the non wetting phase volume within pores i e the term ci dvbi dt is negligible see section 6 4 of mehmani and xu 2022 the latter assumption may become invalid when ganglia are in the process of vanishing by dissolution i e dvbi dt is large the first drawback is removed here by employing an adaptive time stepping strategy as described at the end of section 3 9 the second drawback however persists our initial attempt to generalize the pnm of mehmani and xu 2022 was to adopt a fully implicit framework devoid of this drawback but we realized quickly that the resulting algorithm becomes infinitely more complex than the one outlined in section 3 such an algorithm requires merging algorithms 1 and 3 appendices a b in a monolithic or iterative fashion we concluded therefore that the small price paid in accuracy for adopting a sequential scheme is worth the ability to simulate the evolution of multi pore ganglia which would otherwise be intractable the validation of our pnm against the microfluidic experiment in section 4 1 1 is encouraging as it suggests the actual loss in accuracy is minimal 6 summary and conclusions we developed a novel pore network model pnm capable of simulating the evolution of large multi pore ganglia inside heterogeneous pore networks due to mass transfer by ostwald ripening or an external concentration field ganglia are assumed to be incompressible and perfectly non wetting with respect to the solid pores are simplified as semi cubes and throats as square prisms the pnm accounts for all salient capillary events that a ganglion might undergo including pore invasion interface retraction snap off dislocation coalescence and fragmentation much of these physics have either been ignored or captured incompletely in the literature we validated the pnm against two microfluidic experiments 2d direct numerical simulation dns and an analytical solution for the growth shrinkage cycle of a ganglion inside a 2d homogeneous domain in all cases the pnm exhibited good agreement and predicted the correct sequence of capillary and ripening events future extensions should focus on capturing non zero contact angles and more complex pore throat shapes this requires open source datasets experimental or dns of ganglion evolution by ripening or solute transport if the pnm is to be validated and applied to realistic 3d microstructures the literature is currently in short supply of such data we next applied the pnm to study growth shrinkage cycles of a ganglion inside lattice pore networks with varying degrees of heterogeneity controlled by the throat to pore aspect ratio ξ and the variance of pore size distribution psd rhet overall simulated cycles bore qualitative similarities to the analytical solution of wang et al 2021 for 2d homogeneous networks in the following ways 1 cycles are hysteretic 2 a ganglion s capillary pressure exhibits oscillations that attenuate at large volumes and 3 the dependence between a ganglion s interfacial area or energy and volume is exactly linear at large volumes along growth paths regardless of ξ and rhet but approximately linear along shrinkage paths there were however key differences between the heterogeneous networks simulated and the homogeneous network described analytically 1 if ξ is large ganglion growth is macroscopically continuous or percolation like similar to the analytical solution but if ξ is small a new intermittent growth regime emerges that precedes continuous growth during which ganglia repeatedly fragment and reconnect across multiple pores unlike the analytical solution moreover there exists a size threshold sb below which ganglion growth is intermittent and above which it is continuous the threshold increases with rhet this means once a ganglion reaches a sufficiently large size fragmentation is suppressed and the ganglion remains connected 2 shrinkage paths are strong functions of ξ but weak functions of rhet specifically the topological evolution of the non wetting phase during shrinkage can be divided into three periods of pore retraction loop destruction and fragment dissolution as shrinkage is induced here by dissolution the duration and intensity of each period is controlled primarily by ξ the key takeaway is that the non wetting phase shrinks like a site percolation process or a sequence of pore retraction events only when ξ is large similar to the analytical solution otherwise shrinkage is dominated by the wholesale fragmentation of the non wetting phase into small clusters one implication for geologic co2 storage is that it seems safer to store co2 in rocks that are more heterogeneous not less rocks with small ξ and large rhet are favorable as they promote fragmentation and thus prevent super sized ganglia from emerging which may leak by buoyancy but heterogeneous rocks also come with other trade offs e g poor storage capacity that must be factored into site selection another implication is that ripening seems not to pose a serious threat to co2 leakage from rocks that are microstructurally uncorrelated the reason lies with the approximately linear dependence between a ganglion s interfacial energy and volume fig 18 to render this claim conclusive however time dependent ripening simulations of multi pore ganglia are needed this is now enabled by the proposed pnm credit authorship contribution statement yashar mehmani conceptualization methodology formal analysis writing original draft writing review editing ke xu formal analysis validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements yashar mehmani acknowledges the department of energy and mineral engineering eme the college of earth and mineral sciences ems and the institutes of energy and the environment iee at the pennsylvania state university for providing the funds for this project the institute for computational and data sciences at penn state university is also thanked for providing access to computational resources ke xu gratefully acknowledges support and funding from cnpc research institute of petroleum exploration and development for the project key fluid mechanisms of co2 eor for gu long shale oil development supplementary materials we have included with this paper the following supplementary materials 1 a movie of an experiment capturing the dislocation of a ganglion inside a 3d printed micromodel and 2 two videos visualizing growth paths inside two 11 11 pore networks with different throat to pore aspect ratios ξ ¼ and ¾ and a pore size heterogeneity of rhet 2 the videos are captioned for detail the supplementary material can be found in the online version at doi 10 1016 j advwatres 2022 104223 appendix d supplementary materials image application 1 image application 2 image video 3 image video 4 appendix a algorithm for equilibrating ganglion populations algorithm 1 is used to compute the capillary equilibrium configuration of a population of ganglia inside a porous medium it calls algorithm 2 as a subroutine to compute the capillary pressures of each individual ganglion at a fixed pore throat occupancy appendix b algorithm for simulating mass transfer and ostwald ripening algorithm 3 outlines the steps required to simulate the ostwald ripening or solute driven evolution of a population of partially miscible ganglia note that algorithm 3 calls algorithm 1 at the end of each time step to ensure all ganglia are in capillary equilibrium at all times i e quasi static evolution appendix c computing interfacial free energy or area of a ganglion the interfacial energy of a ganglion fb is related to its capillary pressure pc through pc dfb dvb we can use this equation to calculate fb by integrating the pci vbi relations in eq 1 corresponding to the different pore types in the ganglion s graph concretely suppose a ganglion s graph consists of ni interior pores and nb branch pores then fb is the sum of the interfacial energies associated with the portions of the ganglion residing in each pore c 1 f b i 1 n i 0 v b i p c i i d v b i i 1 n b 0 v b i p c i b d v b i and if the ganglion occupies a singleton pore i e it is a bubble then c 2 f b 0 v b i p c i s d v b i by substituting eqs 1a b into eqs c 1 2 and carrying out the integrations we obtain fb dividing fb by the interfacial tension σ yields гb because f b σ г b 
112,ganglia or bubbles trapped by capillary forces inside porous materials occur in a wide range of subsurface and manufacturing applications in geologic co2 storage ganglia are desired as they render the injected co2 hydrodynamically immobile but they may evolve by dissolution or mass exchange across the brine called ripening in fuel cells and electrolyzers water oxygen ganglia must be removed to ensure optimal performance of the device in both applications the porous microstructure plays a key role in how the geometry topology of ganglia evolve as they grow shrink in size this dependence is poorly understood but important for controlling ganglion dynamics pore scale models are useful tools for probing the physics but existing ones are either computationally expensive e g cfd or incapable of accurately simulating ganglia spanning multiple pores e g pore networks our main contribution is a new pore network model pnm that removes this barrier the pnm can simulate the evolution of multi pore occupying ganglia due to diffusive mass transfer by ripening or an external concentration field we validate the pnm against published microfluidic experiments 2d direct numerical simulations and an analytical solution previously derived by the authors for a 2d homogeneous domain we then use the pnm to study quasi static growth shrinkage cycles of trapped ganglia inside heterogeneous porous media the findings constitute our second contribution generalizing previous theoretical results by the authors from 2d homogeneous to 3d planar heterogeneous microstructures they include 1 the interfacial area of a ganglion depends approximately linearly on its volume 2 if the throat to pore aspect ratio is large growth is percolation like but 3 if it is small a hitherto unreported intermittent growth regime precedes percolation in which ganglia repeatedly fragment and reconnect these outcomes have implications for selecting optimal storage sites for co2 and designing fuel cells and electrolyzers with finetuned porous microstructures keywords porous media ganglia ostwald ripening pore network capillary trapping co2 storage nomenclature σ interfacial tension κ interfacial curvature pc capillary pressure of ganglion non wetting phase vb volume of ganglion non wetting phase γb interfacial area of ganglion non wetting phase χb euler characteristic of ganglion non wetting phase fb interfacial free energy of ganglion non wetting phase mb mass of a bubble ganglion vp volume of a pore ap surface area of a pore rp radius of inscribed sphere in a pore vc volume of inscribed sphere in a pore p c min minimum capillary pressure at v b v c rt side half length of a square cross sectioned throat ls lattice spacing of a pore network lt length of a throat vpi volume of pore i vci volume of inscribed sphere in pore i rpi radius of inscribed sphere in pore i vbi non wetting phase volume in pore i ni of throats connected to pore i ci solute concentration in pore i aij throat cross sectional area between pores i and j lij throat length between pores i and j a b n empirical parameters in eq 1 pci s capillary pressure at singleton pore i pci i capillary pressure at interior pore i pci b capillary pressure at branch pore i pci t capillary pressure at terminal pore i pci o capillary pressure at non terminal branch pore i ni of interior pores in a ganglion s graph nb of branch pores in a ganglion s graph no of non terminal branch pores in a ganglion s graph vb c critical volume of a ganglion pce capillary entry pressure of a throat pcso snap off capillary pressure of a throat co reference concentration r universal gas constant vbm molar volume of non wetting phase t temperature dm molecular diffusion coefficient ntb of boundary throats of a ganglion dt time step dvb increment in bubble ganglion volume sb saturation of non wetting phase in network sb critical non wetting phase saturation ξ throat to pore aspect ratio rt rp rhet network heterogeneity measure r p max r p min ca capillary number 1 introduction a ganglion or bubble trapped inside a porous medium is a disconnected fluid phase with respect to which the porous solid is non wetting ganglia occur commonly in a number of applications ranging anywhere from the sequestration of co2 in deep saline aquifers to mitigate climate change to the removal of non aqueous pollutant liquids napl from groundwater sahloul et al 2002 dillard and blunt 2000 chomsurin and werth 2003 imhoff et al 1996 design of optimal microstructures to manage water or oxygen in fuel cells or electrolyzers lee et al 2020 andersson et al 2016 lu et al 2010 nucleation and growth of vapor bubbles during boiling in heat exchangers mori and okuyama 2009 drying and wicking of water droplets through hydrophobic face masks sarkar et al 2020 and oxygenation of groundwater by air bubbles created after rainfalls holocher et al 2003 bloomsburg and corey 1964 oswald et al 2008 despite their ubiquity the growth and shrinkage of ganglia inside heterogeneous porous materials specifically the relationship between their geometry topology and the porous microstructure remains poorly understood in this work we focus on the growth and shrinkage of partially miscible ganglia due to mass transfer by ostwald ripening ostwald 1897 or an external concentration field imposed through the wetting phase we explore this topic in the context of geologic co2 sequestration gcs as it constitutes our primary motivation ostwald ripening is the process by which mass is transferred from ganglia with a high capillary pressure pc to those with a low capillary pressure or interfacial curvature voorhees 1985 it occurs because high pc ganglia dissolve faster into the wetting phase creating a concentration gradient that drives molecular diffusion in a bulk fluid where ganglia are always spherical ripening causes small bubbles high pc to become absorbed by large bubbles low pc voorhees 1985 voorhees 1992 bray 1994 in a porous medium however a ganglion s capillary pressure pc and volume vb are not monotonically correlated xu et al 2017 wang et al 2021 de chalendar et al 2018 it is therefore entirely possible for a large ganglion to be in thermodynamic equilibrium with a small ganglion de chalendar et al 2018 mehmani and xu 2022 xu et al 2019 li et al 2020 gao et al 2021 the reason is that the geometry of the void space plays an important role rendering the relation between pc and vb not only non monotonic but also discontinuous wang et al 2021 given an initial population of differently sized ganglia in a porous medium the equilibrium state of the non wetting phase no longer consists of a single large spherical bubble as in a bulk fluid instead it consists of a new population of ganglia that share the same pc an important question in the context of gcs is can ripening cause super sized ganglia to emerge which can then leak by buoyancy from the subsurface in this paper we do not answer this question directly instead we develop the necessary modeling tools a pore network model pnm that allows probing this question deeply and systematically in the future we do however use the pnm to obtain partial answers by focusing on the quasi static growth shrinkage cycles of trapped ganglia to understand the linkage between their geometry topology and the confining porous microstructure what do trapped ganglia inside a porous medium look like experiments over the past decade have painted a vivid picture most involve injecting a non wetting phase e g supercritical co2 into a core sample followed by a wetting phase e g brine to induce capillary trapping the generated ganglia are then imaged with an x ray µct scanner and analyzed three important observations have been reported 1 it is much more common for ganglia to occupy multiple pores than a single pore iglauer et al 2011 iglauer et al 2013 andrew et al 2014 geistlinger et al 2014 garing et al 2017 2 the relationship between a ganglion s interfacial area гb and volume vb is approximately linear at large vb andrew et al 2014 geistlinger et al 2014 2015 geistlinger and mohammadian 2015 iglauer et al 2013 landry et al 2011 and 3 the more connected a ganglion is the easier it can be mobilized herring et al 2013 the first places a requirement on pore scale models of ostwald ripening to incorporate multi pore ganglia this applies especially to pnms as alternative direct numerical simulation dns approaches are computationally expensive beyond a handful of ganglia the requirement however is not satisfied by any existing pnm the second observation implies that super sized ganglia are unlikely to emerge by ripening because ripening is driven by differences in pc and such differences are zero if гb is a linear function of vb note pc dгb dvb in the literature linearity is explained by frequent appeal to percolation theory iglauer et al 2011 geistlinger and mohammadian 2015 geistlinger et al 2015 stauffer and aharony 1992 which is valid for ganglia trapped during fluid fluid displacements such processes can often be approximated as a sequence of bond invasion or site retraction events in section 4 2 we show that ganglion evolution post trapping and due to ripening or solute transport is not percolation like in all microstructures only some the third and final observation implies that it is safer to store co2 in rocks that promote ganglion fragmentation because then large connected ganglia with a potential to leak by buoyancy cannot form a follow up question then is what microstructures favor fragmentation this work fills the above knowledge gaps the main contribution of this work is a new pore network model pnm that can simulate the ostwald ripening or more generally solute induced growth shrinkage of arbitrarily sized ganglia inside heterogeneous porous domains the pnm conceptualizes the complex microstructure of a porous medium with a computational graph consisting of pores or nodes and throats or links pores provide storage volume and throats capillary resistance to ganglia we assume that ganglia are perfectly non wetting incompressible and hydrodynamically stagnant the last condition entails the bulk pressure gradient within each phase is zero and ganglion evolution is driven entirely by ripening or solute transport in the pnm ganglia can invade new pores retract from old ones dislocate or displace entirely into larger pores fragment into smaller clusters and coalesce with other ganglia these processes occur quasi statically or in a sequence of equilibrium steps the pnm s algorithm consists of two parts 1 one that computes the capillary equilibrium state of each ganglion given their volume and pore occupancy and 2 another that computes the mass transfer to from each ganglion due to ripening or an external concentration field the first part is more complex as it must ensure the equilibrium state of each ganglion is thermodynamically consistent this means each ganglion must satisfy mass conservation have uniform interfacial curvature and be stable to perturbations much of this paper is therefore devoted to this first part the second part of the algorithm is simpler and the exposition commensurately shorter pnms capable of simulating ganglion evolution are not new but rare most are developed in the contexts of either 1 nucleation and growth of gas bubbles due to depressurization or boiling in porous media li and yortsos 1991 li and yortsos 1995 dominguez et al 2000 felipe et al 2005 bories and prat 2002 zhao and ioannidis 2011 or 2 napl dissolution in groundwater aquifers dillard and blunt 2000 jia et al 1999 held and celia 2001 agaoglu et al 2016 aminnaji et al 2019 the former focuses exclusively on ganglion growth and the latter on ganglion shrinkage despite significant progress in both areas available pnms have two key limitations they either force percolation like patterns on growth shrinkage of ganglia instead of allowing them to emerge naturally from the underlying physics or they oversimplify the relationship between a ganglion s pc and vb inside each occupied pore if not neglect it altogether the latter prohibits the use of current pnms for modeling ostwald ripening in which mass transfer is driven by differences in the capillary pressure of ganglia more recently pnms specifically designed to model ostwald ripening have been proposed de chalendar et al 2018 mehmani and xu 2022 however all are limited to ganglia that occupy only one pore the main novelty of our pnm is that it can handle ganglia spanning multiple pores while accounting for the detailed relationship between pc and vb inside each pore we validate our pnm against published microfluidic experiments direct numerical simulation dns and an analytical solution the pnm extends a previous model mehmani and xu 2022 developed by the authors that is limited to ganglia confined to only one pore we next use the pnm to simulate the quasi static growth shrinkage cycles of a non wetting phase inside porous microstructures that have different aspect ratios ξ and pore size distributions psd the non wetting phase is grown shrunk by imposing a fixed concentration at the domain s boundary if during a cycle the non wetting phase fragments into disconnected ganglia the capillary pressure of those ganglia are kept equal by periodically allowing them to ripen while imposing a zero flux external boundary we record the capillary pressure pc interfacial area гb euler characteristic a measure of topology χb and volume vb of the non wetting phase throughout each cycle our findings constitute the second contribution of this work and include 1 the relation between гb and vb is indeed linear for all ξ and psd during growth but only approximately so during shrinkage 2 growth shrinkage paths are not percolation like for all ξ and psd and may exhibit intermittency akin to the dynamic connectivity flow regime recently reported for fluid fluid displacements reynolds et al 2017 3 the non wetting phase is more connected either when ξ is large i e pores and throats have similar sizes or when ganglia are larger than a microstructure dependent threshold and 4 the relationship between pc and vb is oscillatory and the magnitude of oscillations attenuates as vb these findings generalize the conclusions of a recent paper by the authors in which an analytical solution for the growth shrinkage cycles of a ganglion inside a 2d homogeneous porous domain was derived wang et al 2021 the paper s outline is as follows section 2 describes the problem we aim to solve section 3 details the pnm which include a statement of definitions used throughout this work section 3 1 an algorithm to compute the capillary equilibrium of multi pore ganglia sections 3 2 8 and an algorithm to simulate mass transfer by ostwald ripening or an external concentration field section 3 9 in section 4 1 we validate the pnm against two published micromodel experiments dns and an analytical solution section 4 2 presents results for quasi static growth shrinkage cycles of trapped ganglia inside heterogeneous microstructures in section 5 we discuss the limitations of the pnm its future extensions and implications for gcs the paper concludes with section 6 2 problem description consider a porous medium occupied by a wetting phase and a non wetting phase the non wetting phase is trapped in the form of isolated ganglia whereas the wetting phase is continuous and spans the entire pore space via thin films see fig 1 we make the following assumptions 1 both phases are incompressible and hydrodynamically stagnant i e the bulk pressure gradient inside each phase is zero 2 the capillary pressure across each ganglion s interface satisfies the young laplace equation pc σκ where σ is the interfacial tension and κ the interfacial curvature 3 the solid is rigid and perfectly non wetting with respect to each ganglion i e contact angle is zero 4 the non wetting phase is partially miscible into the wetting phase but not the reverse i e ganglia are pure 5 the concentration of the dissolved non wetting phase within the wetting phase is dilute and obeys fick s law of diffusion and 6 each ganglion is in local thermodynamic equilibrium with its immediately surrounding wetting fluid i e dissolution is instantaneous our goal is to understand the interplay between the geometry topology of trapped ganglia during quasi static growth shrinkage cycles and the microstructure of a porous medium in the following sections we propose a pore network model pnm that enables just that it captures all the salient capillary physics ganglia might undergo including pore invasion interface retraction snap off dislocation fragmentation and coalescence the pnm consists of two parts around which the exposition is organized 1 an algorithm that computes the capillary equilibrium of each ganglion given their volume and pore occupancy and 2 another that computes the mass transfer between ganglia due to ripening or an imposed concentration field sections 3 2 3 8 lay the foundations of the first algorithm and section 3 9 those of the second in section 3 1 we describe the conceptual model adopted by the pnm and its associated definitions sections 3 2 3 3 present constitutive relations that capture the capillary pressure of ganglia within pores and throats section 3 4 describes how these relations can be combined to compute the capillary equilibrium state of a multi pore ganglion in sections 3 5 3 6 discrete capillary events e g breakthrough snap off experienced by ganglia are discussed section 3 7 provides two examples of quasi static growth shrinkage cycles inside 1d pore networks section 3 8 summarizes the final capillary equilibration algorithm proposed and section 3 9 presents the equations used to model mass transfer 3 pore network model 3 1 conceptual model and definitions the pnm conceptualizes a porous medium as an interconnected network of pores nodes and throats links see fig 1 without loss of generality we consider 2d lattice networks and denote the lattice spacing by ls we assume pores to be approximately cubic in shape with a side half length of rp and an inscribed sphere volume of vc by approximately cubic we mean each pore has a volume and maximal inscribed sphere identical to a cube we refer to vc as the critical volume of a pore we assume throats to be prismatic in shape with a square cross section the side half length of which is rt for a throat connecting pores p1 and p2 rt is obtained from rt ξ min rp1 rp2 where ξ 0 1 is the throat to pore aspect ratio this equation ensures that adjacent pores and throats are correlated in size as is the case in geologic porous media bryant et al 1993 and that throats are always smaller than the sandwiching pores the throat length between pores p1 and p2 is obtained from lt ls rp1 rp2 we assume throats to be mere links between pores with zero volume in other words all the void volume of the network is assigned to the pores the pore network is occupied by a non wetting phase surrounded by a wetting phase fig 1 because pores and throats are assigned angular shapes the wetting phase is assumed to be connected throughout the network the non wetting phase by contrast is disconnected into clusters we refer to each cluster as a bubble if it occupies only one pore and a ganglion if it occupies one or more pores fig 1 with reference to fig 2 we define the graph of a ganglion as the subnetwork of pores and throats that the ganglion occupies we classify pores in the ganglion s graph into four types if the ganglion is a bubble we call the occupied pore a singleton if the ganglion occupies more than one pore the occupied pores are one of two types branch or interior branch pores lie at the extremities of a ganglion s graph and are connected to the graph by only one throat interior pores constitute all the remaining pores in the ganglion s graph they connect to the graph by more than one throat we call the smallest branch pore of a ganglion its terminal pore a ganglion can have at most one terminal pore or none if its graph has no branch pores fig 2 illustrates three ganglia along with their corresponding graphs the different pore types are annotated the leftmost ganglion consists of a singleton pore the middle ganglion occupies two interior pores and three branch pores the terminal pore is colored in black the rightmost ganglion has no branch pores and is thus made up of only interior pores the neighbor pores of a ganglion are defined as those pores not occupied by the ganglion but separated from it by only one throat throats that connect the ganglion to its neighbor pores are called boundary throats which lie at the outer perimeter of the ganglion we define interior throats as all the throats occupied by the ganglion note that two pores sandwiching an interior throat must always be occupied by the same ganglion we use two terms to describe the non wetting phase content of a pore occupied by a ganglion if the non wetting phase volume in a pore is less than vc the ganglion is said to be in a hypocritical state locally otherwise the state is hypercritical see fig 2 we note that among all the branch pores of a ganglion only the terminal pore may be hypocritical the terminal pore is the smallest of all branch pores and can sustain capillary pressures larger than or equal to the maximal inscribed sphere in it but such capillary pressures can only be sustained by other branch pores if they are hypercritical otherwise the ganglion will become unstable and fill those larger branch pores until they reach a hypercritical state wang et al 2021 as a result our pnm defines capillary equilibrium as the most thermodynamically stable among the many metastable configuration a ganglion can assume 3 2 capillary pressures within pores to each of the pore types in a ganglion s graph fig 2 a constitutive equation is assigned that describes the relationship between the ganglion s capillary pressure and volume in that pore the equation takes the form pci pci vbi where pci and vbi are the capillary pressure and volume of the ganglion in pore i respectively the equations are summarized below for a singleton pore 1a p c i p c i s v b i p c i min v c i v b i 1 3 if v b i v c i p c i min 1 a v b i v c i v p i v c i b v b i v c i v p i v b i if v b i v c i for an interior pore 1b p c i p c i i v b i p c i m i n 1 a v b i v c i v p i v c i b v b i v c i v p i v b i for a branch pore 1c p c i p c i b v b i p c e p c i m i n v c i v b i v c i n p c i m i n i f v b i v c i p c i m i n 1 a v b i v c i v p i v c i b v b i v c i v p i v b i i f v b i v c i eq 1c also applies to terminal pores which are just a special kind of branch pore in eqs 1a c vci is the critical volume and vpi the total volume of pore i pci min is the capillary pressure corresponding to the largest inscribed sphere within pore i notice when vbi vci eqs 1a c satisfy pci pci min in eq 1c pce is the capillary entry pressure defined in section 3 3 of the interior throat that connects the branch pore to the ganglion s graph parameters a b and n depend on the pore geometry for simplicity and unless otherwise stated we use a 0 905 b 0 01 and n 2 for all pore types in this work which mimic recent microfluidic experiments by the authors xu et al 2017 we note the specific forms of eqs 1a c are not derived from first principles but rather postulated based on prior experimental and theoretical analyses xu et al 2017 wang et al 2021 in section 5 2 we discuss how similar equations for more complex pore shapes beyond the semi cubic pores considered herein can be derived using direct numerical simulation the task however falls outside the scope of this paper figs 3 a c provide a graphical illustration of eqs 1a c for a singleton pore the pci s vbi function is u shaped when vbi vci the ganglion is spherical and does not touch the pore walls and when vbi vci the ganglion is deformed by the pore walls and is no longer spherical causing pci to increase with vbi for an interior pore the pci i vbi function is monotonic this is an approximation but one that is consistent with microfluidic experiments tsimpanogiannis et al 1999 held and celia 2001 the rationale behind the monotonicity is that interior pores act as bridges within a ganglion s graph and can therefore tolerate very small capillary pressures two examples an i bridge and an l bridge are depicted in the inset of fig 3b while the pci i vbi function in fig 3b extends all the way to pci 0 such low capillary pressures are never actually achieved in the pnm because of the lower bound eq 3 in section 3 3 imposed by a process called snap off described in section 3 5 4 this means that the ganglion will fragment if its capillary pressure gets too low for a branch pore the pci b vbi function is also u shaped but unlike pci s vbi it has a finite intercept with the y axis the capillary pressure pci at this intercept is pce the insets of fig 3c display ganglion configurations that correspond to two different parts of pci b vbi in all the three graphs shown in fig 3 pci goes to infinity as vbi approaches the pore volume vpi similar to the case of pci i vbi at low capillary pressures very high capillary pressures are never achieved in the pnm because of the upper bound eq 2 in section 3 3 imposed by a process called breakthrough described in section 3 5 1 this means the ganglion will invade a neighbor pore if its capillary pressure gets too high 3 3 capillary pressures within throats because throats here have a square cross section and the contact angle is assumed zero if a throat is occupied by a ganglion the wetting phase resides in the corners and the non wetting phase in the center of the throat s cross section two capillary pressure thresholds are associated with each throat 1 entry capillary pressure and 2 snap off capillary pressure for a throat initially filled with the wetting phase the entry pressure pce is the minimum pressure drop that must be exerted across the interface of a ganglion to push it through that throat the invasion event is referred to as a breakthrough the entry pressure of a throat with side half length rt is rabbani et al 2016 2 p c e σ r t 1 π 2 for a throat initially occupied by both phases the snap off pressure pcso is the minimum capillary pressure that the fluid fluid interface can sustain without rupturing roof 1970 more specifically if a ganglion s capillary pressure drops below pcso the wetting phase occupying the corners of the throat will swell and eventually sever the non wetting phase occupying the center the event is referred to as a snap off in the aftermath of a snap off the throat becomes saturated with the wetting phase the snap off pressure of a throat with side half length rt is chen et al 2020 3 p c s o σ r t eq 3 corresponds to the largest inscribed cylinder in the throat notice pce pcso always holds 3 4 capillary pressure of a multi pore ganglion the capillary pressure of a ganglion pc depends on its volume vb and the pores and throats it occupies if the ganglion is a bubble occupying only one pore the dependence follows eq 1a but if the ganglion occupies more than one pore pc must be calculated using the capillary equilibration algorithm described below the crux of this algorithm is to combine the constitutive eqs 1b c presented in section 3 2 for all the different pore types in the ganglion s graph this combination must be done in such a way so as to ensure 1 the capillary pressure of the ganglion is uniform across all the pores it occupies and 2 the sum of the non wetting phase volumes inside all occupied pores equals the ganglion s volume the latter requirement is a statement of volume or mass conservation which holds because ganglia are assumed to be incompressible section 2 the ganglion equilibration algorithm goes as follows consider a ganglion with a known volume vb that occupies n 1 pores denote the volume of these pores by vp1 vp2 vpn each pore is either an interior pore or a branch pore let vbi be the volume of the ganglion inside pore i to compute the capillary pressure of the ganglion we must solve the nonlinear algebraic equation below for pc which is a statement of volume conservation 4 v b i 1 n v b i s t v b i p c i x i 1 p c in eq 4 subscript xi is a placeholder for either i or b respectively they stand for interior and branch pores and indicate the use of either eq 1b or 1c if pore i is a branch pore xi b otherwise xi i to develop a robust way of solving eq 4 we proceed by examining its structure more closely we start by first partitioning branch pores into one terminal pore if it exists because there can be at most one and all remaining non terminal branch pores we denote the former with the subscript xi t and the latter with xi o i e b t o next we combine the two equations in eq 4 and split the summation according to the different pore types to obtain 5a v b i 1 n i p c i i 1 p c i 1 n o p c i o 1 p c p c t 1 p c which applies when a terminal pore exists and 5b v b i 1 n i p c i i 1 p c when a terminal pore does not exist notice that the absence of a terminal pore implies the absence of any branch pore from the ganglion s graph an example is an o shaped ganglion i e ring formation in eq 5 ni is the number of interior pores and no the number of non terminal branch pores if either ni 0 or no 0 in eq 5a the corresponding summation is zero solving eq 5b for pc is straightforward because pci i vbi is a monotonic function of vbi eq 1b as seen from fig 3b note the inverse of a monotonic function is monotonic and the finite sum of monotonic functions is also monotonic therefore the right hand side rhs of eq 5b is a monotonic function of pc which means it has exactly one root by contrast eq 5a is more difficult to solve because pci t vbi and pci o vbi are non monotonic functions as both equal eq 1c see fig 3c and so eq 5a may have multiple roots but recall from section 3 1 that only the terminal pore of a ganglion can be in a hypocritical state vbi vci while all non terminal branch pores are always hypercritical vbi vci because the hypercritical limb of pci o vbi is monotonic the only source of non monotonicity in eq 5a is pci t vbi to eliminate it we must determine a priori whether the terminal pore is hypocritical or hypercritical because then we can select the appropriate monotonic limb of pci t vbi in eq 1c we proceed by defining the critical volume of a ganglion as 6 v b c i 1 n i p c i i 1 p c min t i 1 n o p c i o 1 p c min t p c t 1 p c min t where pc min t is the minimum capillary pressure of the terminal pore i e pc min t σ rp min t such that rp min t is the radius of the maximal inscribed sphere within the terminal pore notice pc min t is the smallest capillary pressure that the ganglion can sustain without having to alter its pore occupancy the key observation here is that if vb v b c the terminal pore must be hypercritical and if vb v b c it must be hypocritical as a result by comparing vb to v b c we can determine whether to use the hypocritical or hypercritical limb of pci t vbi in eq 1c to solve eq 5a for pc the choice would render p ci t vbi and thus the rhs of eq 5a monotonic with a unique root in this work we use the bisection method as a robust way of solving eqs 5a b the above algorithm can be used to construct the pc vb curve of a multi pore ganglion figs 4 5 show two examples the blue magenta green and black curves correspond to ganglia that occupy 1 2 3 and 4 pores respectively in fig 4 occupied pores have equal sizes whereas in fig 5 they have different sizes the local minima correspond to vb vb c and pc pc min t the dotted lines also highlighted in yellow indicate unstable ganglion configurations and should be ignored only solid lines count towards the pc vb curves of ganglia the dotted lines are unstable because they correspond to vb vb c and dpc dvb 0 the first condition says that the ganglion s graph has a terminal pore in it and it is in a hypocritical state the second condition says the capillary pressure of the ganglion must increase if its volume grows but that is physically impossible because the ganglion is free to move inside the terminal pore i e hypocritical if the ganglion grows its volume within the terminal pore will increase and with it its capillary pressure or interfacial curvature will drop we conclude from this contradiction that for ganglia satisfying vb vb c dpc dvb 0 must hold for a more in depth discussion the reader is referred to a recent stability analysis published by the authors for multi pore ganglia wang et al 2021 in the next section we show that if a growing shrinking ganglion attempts to enter a dotted segment of the pc vb curve figs 4 5 a rapid reconfiguration of the ganglion s geometry ensues which we call a capillary event 3 5 capillary events of a ganglion there are four capillary events that a ganglion may undergo which are discussed below 3 5 1 breakthrough a breakthrough event is defined as the increase in the pore occupancy of a ganglion by 1 it occurs if the ganglion s capillary pressure pc exceeds the capillary entry pressure of one of its boundary throats pce if pc pce holds for more than one boundary throat the throat with the smallest pce is invaded in other words breakthrough is modeled quasi statically where throats are invaded one at a time not simultaneously on a ganglion s pc vb curve a breakthrough event is identified by a transition from a segment associated with a pore occupancy of n to another with a pore occupancy of n 1 fig 6 shows parts of the pc vb curves of three ganglia breakthrough events are marked by red dots notice the breakthroughs can either coincide with a sudden drop in pc as in fig 6a or with a continuous decrease in pc as in figs 6b c the occurrence of one or the other depends on the geometries of occupied pores reflected in the constitutive pci vbi equations eq 1 of section 3 2 for the pci vbi curves assumed herein we observe that if breakthrough is continuous it tends to be short lived and a sudden drop in pc follows immediately after see figs 6b c we also note that if the ganglion has a terminal pore that is hypocritical breakthrough cannot occur because the ganglion is free to move inside the terminal pore to adjust itself 3 5 2 pop the sudden drop in the pc of a growing ganglion is defined as a pop event it occurs if any further increase in the ganglion s volume would place it on an unstable segment of the ganglion s pc vb curve the transitions from points 6 to 7 in fig 6a 7 to 8 in fig 6b and 8 to 9 in fig 6c are pop events notice a pop does not necessarily coincide with a breakthrough in fig 6a pop and breakthrough events coincide but in figs 6b c they do not in the former case pore occupancy increases by 1 but in the latter pore occupancy remains unchanged we note that for very large vb pop and breakthrough events almost always coincide 3 5 3 flinch a flinch event is defined as a sudden surge in the pc of a shrinking ganglion it occurs if any further decrease in the ganglion s volume would place it on an unstable segment of the ganglion s pc vb curve in fig 7 the upward red arrows between points 4 and 5 are flinch events there are two types of flinch events partial and complete partial flinch does not change the pore occupancy of a ganglion as seen in fig 7a by contrast complete flinch reduces the pore occupancy of a ganglion by one or more pores fig 7b illustrates a complete flinch where pore occupancy decreases from n to n 1 fig 7c shows another complete flinch where pore occupancy decreases from n to n 2 a flinch can therefore be thought of as a pop event run in reverse 3 5 4 snap off a snap off event is the sudden disconnection of a ganglion along an occupied throat s length it occurs if the ganglion s pc falls below the snap off capillary pressure pcso of one of its interior throats quantified by eq 3 if pc pcso holds for more than one interior throat the ganglion snaps off in all such throats since the pc of a ganglion does not change during snap off andrew et al 2014 simultaneous snap off of multiple throats is equivalent to their one by one or quasi static snap off 3 6 topological changes caused by capillary events during any one of the capillary events described above the topology of a ganglion may change this requires updating the ganglion s graph which includes its pore types interior branch terminal boundary throats interior throats and neighbor pores what follows are a few specific examples if during a breakthrough event a ganglion invades a pore already occupied by another ganglion the two ganglia are merged if the invaded pore is occupied by the ganglion itself i e self intersection the connecting throat is added to the ganglion s interior throats list during snap off a ganglion may fragment into multiple smaller ganglia therefore after every snap off event we perform a graph search to identify the number of disconnected fragments and label them as new ganglia with their own graphs and thermodynamic states e g vb pc the capillary pressure of each fragment equals that of the original ganglion before snap off section 3 5 4 after a flinch event the pore occupancy and hence topology of a ganglion can also change a very common scenario is when a breakthrough or flinch occurs immediately after a flinch or breakthrough event such two event sequences are caused by the fact that the volume or equivalently mass due to incompressibility of a ganglion is conserved we therefore check for all possible breakthrough or flinch events immediately after every flinch or breakthrough event in the pnm finally when a ganglion invades a pore that is much larger than those already occupied it may fully move into that pore we call this ganglion dislocation and it is captured automatically by the iterative pnm algorithm presented later in section 3 8 3 7 ganglion growth shrinkage cycles now that we know how to construct the pc vb curve of a multi pore ganglion section 3 4 and understand the capillary events it may undergo section 3 5 we can visualize the evolution paths of a simple ganglion on its pc vb curve during growth and shrinkage figs 8 9 exemplify two such growth and shrinkage paths inside a string of four pores highlighted in yellow in fig 8 pores have identical size homogeneous whereas in fig 9 they do not heterogeneous let us focus first on the growth path of fig 8 at point a the ganglion occupies only one pore once it reaches point b the ganglion breaks through into the second pore from the left had the breakthrough not occurred the ganglion would have entered an unstable dotted segment of the pc vb curve notice the capillary pressure at point b is equal to the capillary entry pressure of the throat connecting pores 1 and 2 as the ganglion grows further it travels on the solid magenta segment of the pc vb curve until it reaches the unstable limb marked by the dotted green line at this point the ganglion breaks through into pore 3 and simultaneously undergoes a pop event causing a sudden decrease in the ganglion s capillary pressure we are now at point c note that unlike the breakthrough event at point b which was continuous the breakthrough at point c coincided with a pop as the ganglion grows even further it travels on the solid green line of the pc vb curve until it undergoes a similar breakthrough event coincident again with a pop leading it to point d focusing next on the shrinkage path of fig 8 the ganglion initially occupies four pores once it shrinks to point a the ganglion undergoes a flinch event that places it at point b the flinch is accompanied by a sudden surge in the ganglion s capillary pressure had it not occurred the ganglion would have entered an unstable segment of the pc vb curve black dotted line after the ganglion has shrunk further to point c a similar flinch takes place landing the ganglion at point d beyond point d shrinkage is continuous and no sudden jumps in capillary pressure occur specifically at point e the ganglion retracts from pore 2 into pore 1 without flinching fig 9 illustrates similar growth and shrinkage paths inside four heterogeneous pores the only marked difference compared to fig 8 is that the first flinch event along the shrinkage path between points a and b reduces the ganglion s pore occupancy by two not one and by so doing the flinch completely bypasses the solid green segment of the pc vb curve overall a key takeaway from figs 8 9 is that the growth shrinkage cycle of a ganglion within a porous medium is hysteretic i e growth and shrinkage paths do not overlap in section 4 2 we examine such cycles in more detail 3 8 capillary equilibrium of a ganglion population for a topologically complex ganglion residing inside a heterogeneous porous medium that is occupied by other ganglia it is difficult if not impossible to visualize growth and shrinkage paths on a pc vb curve similar to figs 8 9 instead these paths must be computed algorithmically in appendix a we present algorithm 1 to do just that the problem algorithm 1 aims to solve is this given a population of differently sized ganglia that are at capillary equilibrium and have known pore occupancies what is the new equilibrium configuration if each ganglion s volume is incremented or decremented by a small amount the problem is important for solving ganglion evolution problems like ostwald ripening where ganglia increase or decrease in volume due to mass transfer algorithm 1 is iterative and executes the following steps until convergence at which point the population s new equilibrium state is determined 1 holding the pore throat occupancies of all ganglia fixed use algorithm 2 in appendix a to compute the pc of each ganglion algorithm 2 embeds the ganglion equilibration algorithm described in section 3 4 whose aim is to find the roots of eqs 5a b in addition algorithm 2 accounts for the direction of each ganglion s evolution growth versus shrinkage if no roots are found flagfl 1 is returned this means it is impossible for the current pore occupancy to sustain a stable configuration a complete flinch is required if a root is found set flagfl 0 2 if flagfl 1 for any ganglion perform a complete flinch and return to step 1 else continue 3 given the pc obtained for each ganglion check for all possible breakthrough events if any are detected for a ganglion set flagbt 1 and perform the breakthrough if the invaded pore is empty add it to the ganglion s graph if the pore is occupied by another ganglion merge the two ganglia and if the invaded pore is occupied by the ganglion itself add the connecting throat to the ganglion s interior throats list if no breakthroughs are detected set flagbt 0 4 if flagbt 1 for any ganglion return to step 1 otherwise continue 5 next check for all possible snap off events by comparing the pc of each ganglion to the pcso of its interior throats if any are detected set flagso 1 and perform the snap off by removing the affected throats from the ganglion s graph then perform a graph search to label any isolated fragments as new ganglia note these fragments have the same pc as the initial ganglion if no snap offs are detected set flagso 0 6 if flagso 1 for any ganglion return to step 1 else exit algorithm 1 outputs the updated capillary pressures of all ganglia their new pore throat occupancies and their volumes inside each occupied pore the algorithm automatically captures several experimentally observed phenomena such as a breakthrough flinch following a flinch breakthrough ganglion dislocation and a snap off following a breakthrough unlike other pnms no explicit rules are needed to capture these physics they simply emerge 3 9 balance equations for mass transfer and ostwald ripening we now present the governing equations solved by the pnm to simulate the evolution of a population of partially miscible ganglia inside a heterogeneous porous medium due to mass transfer by ostwald ripening or an imposed concentration field in section 2 the concentration at a ganglion s interface was assumed to be in local equilibrium in the pnm this means if pore j is occupied by ganglion i with capillary pressure pc i then the concentration inside pore j cj equals 7 ln c j c o p c i v b m r t eq 7 is a statement of the equality of chemical potentials between the dissolved species and the non wetting phase derived elsewhere xu et al 2019 in eq 7 vbm is the molar volume of the ganglion r the universal gas constant t temperature and co a reference concentration according to eq 7 pores occupied by ganglia that have high capillary pressures also have high dissolved concentrations if the capillary pressures of these ganglia differ eq 7 engenders a concentration gradient through the wetting phase that drives molecular diffusion the result is mass transfer from ganglia that have a high capillary pressure to those with a low capillary pressure over time some ganglia will grow while others will shrink or even disappear notice because the capillary pressure of a ganglion is uniform across all the pores it occupies i e capillary equilibrium eq 7 entails that the dissolved concentration within those pores is also uniform the evolution of the solute concentration in an empty pore j not occupied by a ganglion is governed by the following species balance equation 8 d c j d t k 1 n j d m a j k c k c j l j k the lhs denotes the accumulation term and the rhs the mass exchange by diffusion between pore j and its neighboring pores in eq 8 dm is the molecular diffusion coefficient and nj the number of pores or throats connected to pore j the parameters ajk and ljk denote respectively the cross sectional area and length of the throat connecting pores j and k we solve eq 8 for the concentration of all empty pores by using the occupied pore concentrations from eq 7 as boundary conditions bcs in this work we also impose bcs on the external boundaries of the pore network which are either no flux neuman or constant concentration dirichlet to impose neumann we simply drop the diffusive flux associated with throats intersecting the external boundaries of the network from the rhs summation of eq 8 to impose dirichlet we fix the concentrations associated with pores neighboring the external boundaries the resulting system of equations is linear and solved here with a direct solver for the quasi static growth shrinkage cycles considered in section 4 2 diffusion is much faster than the rate of volume evolution of ganglia we therefore simplify eq 8 by neglecting the time derivative on the lhs once dissolved concentrations within occupied and empty pores are obtained from eqs 7 and 8 respectively we can compute the total solute mass transferred into or out of each ganglion for a ganglion with ntb boundary throats the total mass change induced by diffusion is 9 d m b d t j k 1 n t b d m a j k c k c j l j k the rhs of eq 9 sums the diffusive mass fluxes through all the boundary throats of the ganglion over one time step dt we convert the resulting mass change dmb to a volume change dvb by 10 d v b v b m d m b the new volume of the ganglion after one time step is therefore 11 v b t dt v b t d v b once all ganglion volumes have been updated via eq 11 algorithm 1 of appendix a is invoked to recalculate the capillary equilibrium of the system namely the capillary pressures pore occupancies and topologies of all ganglia are recomputed and the occurrence of capillary events e g snap off pop flinch breakthrough are checked detected and executed for the next time step the above steps are repeated starting from the solution of eq 8 subject to eq 7 and external bcs to summarize the pnm simulates mass transfer between ganglia by executing the steps below 1 set the concentration of all occupied pores using eq 7 2 compute the concentration of all empty pores by solving eq 8 use the concentrations of occupied pores from step 1 as dirichlet bcs set the external bcs of the network to either no flux neumann or constant concentration dirichlet 3 compute the mass change of each ganglion using eq 9 4 convert the mass change from step 3 into a volume change using eq 10 5 update the volume of all ganglia using eq 11 6 run algorithm 1 of appendix a to update the capillary pressure pore occupancy and topology of all ganglia in the process some ganglia may merge fragment or vanish 7 return to step 1 and repeat until a user defined termination time is reached the pseudo code of the above steps is summarized in algorithm 3 of appendix b example the network shown in fig 10 contains two ganglia the first is a singleton and occupies pore 13 and the second is a multi pore ganglion and occupies pores 2 3 4 7 and 8 the capillary pressure and dissolved concentration across pores 2 3 4 7 and 8 are uniform the concentrations in pores 2 3 4 7 8 and 13 are set by eq 7 and used as dirichlet bcs to solve the concentrations in the remaining pores via eq 8 the external bcs in fig 10 are no flux which is apparent from the fact that the external boundary throats of the network are not drawn closed system remark a note about the time step dt used in eq 9 is in order if dt is constant ripening simulations tend to be either too slow small dt or unstable large dt to circumvent this issue and to render computations fast and accurate we adjust dt adaptively during the course of the simulation we do this by picking dt such that the maximum change in the volume dvb of any ganglion is less than x of the volume of the smallest pore in the network here we set x 5 10 moreover if during simulations the volume of a singleton ganglion or bubble falls below y of the volume of the smallest pore in the network we declare it as having vanished in this work we set y 2 4 results in this section we first validate the proposed pnm against two microfluidic experiments sections 4 1 1 4 1 2 direct numerical simulation dns section 4 1 3 and an analytical solution for the growth shrinkage cycles of a ganglion in a 2d homogeneous porous medium section 4 1 4 we then apply the pnm to study growth shrinkage cycles of ganglia inside large heterogeneous pore networks section 4 2 we track the evolution of capillary pressure interfacial area volume and topology quantified by the euler characteristic of each ganglion during these cycles and examine how their interdependence is impacted by the porous microstructure 4 1 validation 4 1 1 pnm versus microfluidic experiment ripening of a bubble population we compare the pnm against ripening experiments conducted by xu et al 2017 for a population of air bubbles trapped inside a water saturated micromodel air is the non wetting phase and water the wetting phase the micromodel consists of a regular array of identical cylindrical posts or grains as shown in fig 1 sandwiched between two parallel plates bubbles occupy no more than one pore each throughout the experiment the comparison probes the validity of the pnm in predicting ripening kinetics section 3 9 not capillary dynamics of multi pore ganglia section 3 8 in a previous work mehmani and xu 2022 the authors used these experiments to validate an older pnm limited to bubbles confined to only one pore solute transport equations therein were formulated differently from those of section 3 8 eqs 8 11 including additional terms for higher order physics in this section we want to ensure that the generalized pnm herein for multi pore ganglia can still capture ripening kinetics of a bubble population with comparable accuracy while our account is self contained the reader is referred to mehmani and xu 2022 for further details relevant to this comparison the micromodel consists of 15 8 identical pores each encased by four grains the grains have a diameter of 165 μm and a depth of 26 4 μm at their narrowest cross section throats have a width of 35 μm and a depth of 14 7 μm the properties of the fluid and solute are vbm 24 200 cm3 mole dm 2 10 5 cm2 s t 293 k co 7 94 10 7 mole cm3 σ 25 4 dyne cm a key difference between the micromodel and the pnm is in the pore shapes semi cubic in the pnm but pancake shaped in the micromodel to allow for a one to one comparison in mehmani and xu 2022 we established an equivalence relation that ensures pnm and micromodel data satisfy the same dimensionless equation using this relation we obtained the following pnm parameters rpi 68 23 µm lij 80 µm and aij 2 716 103 µm2 the pci vbi function used here is slightly different from eq 1a namely we use eq 4 in mehmani and xu 2022 with a 8 and n 0 2 with these settings the relative bubble volumes vbi vpi from the pnm and the experiment become comparable to initialize the bubble volumes in the pnm we draw vbi vpi values from the initial distribution measured experimentally fig 3 in xu et al 2017 but because there are only 120 pores in the network predictions are prone to sampling variance we thus run 10 independent realizations with the pnm to obtain a statistically converged solution fig 11 a shows that the pnm agrees well with the experiment where the probability density functions pdf of vbi vpi at different time snapshots t 10 50 and 120 hr are shown note the agreement at t 0 hr is by design fig 11b depicts the same information but in the form of cummulative distribution functions cdf the only notable discrepancy in fig 11 is that at t 50 hr the pnm predicts slightly faster kinetics than the experiment in mehmani and xu 2022 this was attributed to differences in the crtical volume vci between the two geometries not equalized by the equivalence relation mentioned above we emphasize that no parameter tuning of any sort was performed in obtaining the pnm results of fig 11 4 1 2 pnm versus microfluidic experiment dissolution of a two pore ganglion here our goal is to validate the pnm in capturing dissolution induced ripening and fragmentation of a two pore ganglion fig 12 shows a microfluidic experiment by sahloul et al 2002 where a two pore ganglion isobutanol is allowed to dissolve slowly into the surrounding wetting phase water as the ganglion shrinks it first snaps off into two singleton fragments fig 12c and the fragments then continue to dissolve while simultaneously undergoing ripening at this stage they compete for survival the process culminates in the bottom fragment being absorbed into the top one the dissolution of the two pore ganglion is induced by lowering the solute concentration in the wetting phase at two outer ports not shown in fig 12 fig 13 shows the corresponding pnm simulation where the domain consists of four nearly identical pores a variance of 1 in pore size was introduced to mimic the variability in fabricating the micromodel and to introduce a slight asymmetry in ripening the ganglion is partially miscible in the wetting phase and its dissolution is induced by lowering the concentration at the two outermost empty pores of fig 13 the resulting simulated sequence of events are depicted in fig 13 and seen to agree well with the experiment in fig 12 the ganglion first snaps off into two fragments and then undergoes simultaneous dissolution and ripening we note that while the pnm and the micromodel have geometric differences 3d versus 2 5d or pancake shaped respectively their throat to pore aspect ratios are equal we also note that in fig 13 we have visualized the ganglion in each pore using circles for convenience even though its actual shape may not be spherical due to deformations induced by the pores walls this remark applies to all other figures presented in later sections that visualize pnm simulations 4 1 3 pnm versus direct numerical simulation ganglion dislocation we next validate the pnm against dns for its reproducibility of a capillary event we call ganglion dislocation or hop fig 14 shows the pnm simulation of a ganglion grown inside an array of four pores ordered in descending size from left to right the ganglion is initially placed inside pore 4 and then grown until the capillary entry pressure of the connecting throat is exceeded at this point the ganglion not only invades pore 3 but simultaneously retracts from pore 4 since pore 3 is larger than pore 4 the pnm predicts the ganglion will move entirely or dislocate from pore 4 into pore 3 as the ganglion grows further it undergoes the same event two more times namely the ganglion dislocates from pores 3 to 2 and then again from pores 2 to 1 in fig 15 we validate the above sequence of events predicted by the pnm fig 14 with direct numerical simulation dns we use a level set method for solving the two phase navier stokes equations published previously by the authors mehmani and tchelepi 2019 as it is less prone to so called spurious currents near the ganglion s interface at low capillary numbers popinet 2018 because our dns is expensive and the pnm predictions in fig 14 consist of three similar dislocation events we focus only on validating the dislocation event highlighted by the green rectangle in fig 14 put differently we aim to replicate figs 14e g with dns to render dns computationally tractable we opt for a 2d domain which is sufficient for our purpose of validating the sequence of capillary events not their timing to closely approximate the pnm geometry in fig 14 we design the dns domain as shown in fig 15 it consists of square pores that have the same relative dimensions as in the pnm i e ratio of successive pore sizes are identical rp i rp i 1 3 2 where i and i 1 are pore indices throats are made to have near zero length because their volumes are assumed zero in the pnm and finally the throat to pore aspect ratio in the dns is set equal to that of the pnm i e rt rp 2 3 using dns to grow a ganglion is more nuanced than with the pnm a ganglion is grown in the pnm by simply adding a constant increment to its volume in dns mass conservation for each incompressible phase must be imposed this means we must add two ports one to the left and another to the right boundary of the domain red rectangles in fig 15a to allow the wetting phase to escape the domain as the ganglion grows moreover a point source for the non wetting phase must be introduced to increment the ganglion in fig 15 we use a virtual needle red point placed inside pore 2 to slowly inject the non wetting phase the injection is stopped and the needle removed immediately after the ganglion breaks through into pore 1 fig 15d the system is then allowed to equilibrate figs 15e h capture this equilibration process during which the ganglion leaves pore 2 and moves entirely into pore 1 the reason the needle must be removed is because it would otherwise obstruct the ganglion other mechanisms like ostwald ripening could have been employed to grow the ganglion but growth by injection was the only option available to us in our dns we note the injection rate had to be very slow in the dns to ensure a capillary dominated regime the requirement was met in fig 15 by fixing the capillary number at ca 6 6 10 6 comparing figs 14 and 15 we see the agreement between pnm and dns is very good fig 15 confirms that the dislocation of ganglia from small to large pores is not an artifact of our pnm but a physically valid state that the ganglion finds energetically favorable to assume the phenomenon emerges naturally in the pnm without hard coding any explicit rules in the supplmentary material we also include a movie that captures the dislocation of a ganglion inside a 3d printed micromodel because geometric details of the micromodel were hard to control using our 3d printer we excluded it from the pnm validation of this section the movie however does provide further support that dislocation is an experimentally observed phenomenon 4 1 4 pnm versus analytical solution ganglion growth shrinkage cycle we now validate the pnm against an analytical solution for the growth shrinkage cycle of a perfectly non wetting ganglion inside a 2d homogeneous lattice network the analytical solution was derived previously by the authors wang et al 2021 in the pnm a ganglion is initially placed inside a single pore at the center of the network and slowly grown to a prescribed size the ganglion is then shrunk back to its original size during this cycle the capillary pressure pc interfacial free energy fb and volume vb of the ganglion are measured interfacial energy is related to interfacial area гb via fb σгb the procedure for calculating fb is detailed in appendix c we normalize pc by the capillary entry pressure of one of the identical throats pce fb by σap where ap is the surface area of one of the pores 24 rp 2 and vb by vp where vp is the volume of one of the identical pores the measured variables by the pnm are plotted in figs 16 a b and compared against those from the analytical solution in figs 16c d the agreement is very good but we note that the comparison is intended to be qualitative for the following reasons 1 the analytical solution corresponds to a 2d array of posts whereas the pnm can only handle 3d pores throats 2 the analytical solution ignores snap off because snap off is a 3d phenomenon not 2d the throat to pore aspect ratio ξ rt rp in the analytical solution is ξ 1 6 the same aspect ratio in the pnm would cause the ganglion to fragment by snap off during shrinkage rendering the comparison invalid we have therefore suppressed snap off in the pnm by choosing a larger aspect ratio ξ 2 3 for the square prismatic throats considered in the pnm the criterion ξ ½ suppresses snap off because it ensures that the minimum capillary pressure inside pores pc min 2σ rp is always larger than the snap off capillary pressure inside throats pcso σ rt in fig 16 the difference in ξ has contributed to the quantitative difference between the pnm and analytical predictions a final consideration made in the pnm simulations was to prevent the ganglion from intersecting itself i e invade a throat that connects to a pore already occupied by the ganglion this is because the analytical solution prohibits self intersections in reality however ganglia do self intersect provided they are grown or shrunk very slowly to allow the wetting phase to escape through wetting films self intersections are therefore permitted in all the pnm simulations presented in later sections the key takeaway from fig 16 is our pnm can capture salient features of growth shrinkage cycles inside porous microstructures these include in particular the characteristic oscillations of a ganglion s capillary pressure versus volume the attenuation of these oscillations at large volumes and the linear dependence between the ganglion s interfacial area and volume the fact that these features emerge naturally from the combination of a handful of constitutive pci vbi relations eqs 1a c is not at all obvious a priori this offers hope that developing better constitutive relations in the future from experiments or dns may enable quantitative predictions 4 2 growth shrinkage cycles inside heterogeneous microstructures in the previous section we discussed an analytical solution by wang et al 2021 for describing the growth shrinkage cycle of a ganglion inside a homogeneous network the main findings of that work were 1 growth shrinakge cycles are hysteretic 2 a ganglion s capillary pressure is a non monotonic oscillatory function of its volume 3 oscillations attenuate at large volumes and 4 the relationship between a ganglion s interfacial area and volume is linear during both growth and shrinkage in the following sections we attempt to generalize these observations for heterogeneous networks we control heterogeneity via two parameters 1 the variance of the pore size distribution psd and 2 throat to pore aspect ratio ξ we assume all networks have a uniform psd and we define the ratio of the largest pore rp max to the smallest pore rp min in the network as rhet rp max rp min we use rhet as a proxy for the psd s variance or heterogeneity and consider networks with rhet 1 01 3 and 9 we use rhet 1 01 instead of rhet 1 to introduce a small amount of randomness into the network this breaks any unrealistic symmetries in the evolution process of ganglia and mimics the natural randomness that is always present in fabricated micromodels even those that are nominally homogeneous we consider 2d lattice networks that are 101 101 in size 10 201 pores which is sufficient for suppressing any boundary effects that might influence a ganglion s growth or shrinkage to construct each network we first assign pore sizes drawn randomly from the psd and then assign throat sizes according to rt ξ min rp1 rp2 as described in section 3 1 three aspect ratios are considered herein ξ ¼ ½ and ¾ the pnm simualtions are initialized by placing a tiny ganglion inside a single pore at the center of the network the ganglion is then grown until it invades one of the outer boundary pores at which point it is shrunk back to its original size during this cycle the ganglion may fragment into disconnected clusters unlike the analytical solution of fig 16 to ensure all clusters are always at capillary equilibrium i e evolution is quasi static they are allowed to periodically ripen more specifically we assume that ganglia are partially miscible and their growth shrinkage is induced by turning on off a constant concentration at the external boundary of the network when the concentration is on the system is temporarily open to allow a small increment of solute to diffuse into or out of the system to induce growth or shrinkage we call this the evolution period when the boundary concentration is off the system is closed i e zero boundary flux and ganglia exchange mass until their capillary pressures equalize we call this the ripening period the ripening period ends once the capillary pressures of all ganglia reach within 1 of each other similar to fig 16 we measure the capillary pressure pc total interfacial area гb and total volume vb of the non wetting phase we express interfacial area on a per unit volume basis by defining the specific interfacial area of the non wetting phase as γb гb vb we also normalize volume vb by expressing it as the non wetting phase saturation in the pore network sb lastly we measure the euler characteristic χb of the non wetting phase defined by χb n l o where n l and o are called the betti numbers they correspond to the number of isolated objects n redundant loops l and cavities o zero here of the non wetting phase respectively armstrong et al 2019 in the following we analyze the evolution of pc γb and χb versus sb for different heterogeneities i e rhet and ξ we then juxtapose the results against those of the homogeneous network in fig 16 4 2 1 capillary pressure fig 17 shows the evolution of pc versus sb during both growth black and shrinkage red in pore networks that have different rhet and ξ compared to the analytical solution in fig 16 for a homogeneous network the plots are qualitatively similar with a few key differences first the similarities 1 growth shrinkage cylces are hysteretic and 2 pc exhibits oscillations along growth paths that attenuate at large sb the differences are 1 as ξ decreases the attentuation rate of oscillations during growth diminishes and the magnitude of oscillations amplifies 2 for large ξ ½ shrinkage paths exhibit spikes that increase in magnitude and frequency as rhet decreases and 3 for small ξ ½ shrinkage paths are relatively smooth and devoid of spikes we now proceed to explain these differences while noting that further evidence for our arguments is provided in the next two sections let us focus on the growth paths first if the aspect ratio ξ is small pores are larger than their adjacent throats hence every time the non wetting phase invades a new pore its pc drops precipitously to accommodate the lower curvature enabled by that pore immediately before invasion pc is also high because it equals the entry pressure of the connecting small throat the drop in pc causes the ganglion s capillary pressure to fall below the snap off threshold of some or all of its interior throats causing the ganlgion to fragment into multiple clusters the smaller ξ is the more extensive is fragmentation as the ganglion grows further the fragments reconnect and the process starts anew leading to the next pc spike the above process associated with small ξ ½ describes a growth pattern that is intermittent it is characterized by a sequence of fragmentation and reconnection events that give rise to highly oscillatory trajectories in pc for the square prismatic throats and cubic pores assumed herein fragmentation is triggered when ξ ½ and suppressed when ξ ½ this threshold is exact if the pore network is perfectly homogeneous i e rhet 1 and approximate otherwise for other pore and throat shapes the cut off will be different from ½ now suppose ξ is large in this case the oscillations in pc will be small because invaded pores are comparable in size to adjacent throats moreover ganglion fragmentation will be suppressed because the drop in pc after every invasion event will be insufficient to go below the snap off threshold of the interior throats of the ganglion the emergent growth pattern is thus continuous resembling a percolation process stauffer and aharony 1992 we note the intuitive reason why pc oscillations attentuate at large sb regardless of ξ is that larger ganglia have more spare volume to fill newly invaded pores with without having to drop their pc by much let us next focus on the shrinkage paths if ξ is small the initially connected ganglion fragments instantaneously into numerous isolated clusters in reponse to a slight decrease in sb or pc as mentioned earlier this is because a ganglion s interior throats have a high snap off threshold when ξ is small the fragmented clusters subsequently shrink in unison while maintaing an equal capillary pressure throughout the network ensured by the ripening periods described in section 4 2 as sb decreases further the clusters first reduce to bubbles occupying only one pore and then vanish one at a time by dissolution the result is a smooth decrease in pc suppose now that ξ is large in this case the initially connected shrinking ganglion retracts from its branch pores one by one simultaneously some interior throats undergo snap off causing the ganglion to become less connected or even to fragment the competition between pore retraction and snap off is controlled by rhet if rhet is large snap off occurs continuously during shrinkage destroying loops and creating new branch pores from which the ganglion can later retract hence the resulting pc versus vb curve fig 17 is relatively smooth and devoid of large spikes if rhet is small however pore retraction precedes snap off the ganglion first retracts from all of its branch pores until the only pores constituting its graph are interior pores i e the graph consists of only loops because interior pores can tolerate extremely low pc evident from fig 3b the ganglion s capillary pressure continues to drop until it falls below the snap off threshold of its interior throats but since rhet is small the network is approximately homogeneous and snap off occurs in multiple throats at once as a result the ganglion fragments into many small clusters engendering the large spikes observed in the shrinkage paths of fig 17 bottom left corner overall shrinkage paths mimick a site percolation process stauffer and aharony 1992 only when ξ is large not otherwise 4 2 2 interfacial area fig 18 shows the evolution of γb versus sb during both growth black and shrinkage red in pore networks with different rhet and ξ what is remarkable about the growth paths is that γb asymptotes to a constant as sb for all rhet and ξ this is true despite differences in growth regimes intermittent versus continuous as discussed in section 4 2 1 because the total interfacial area of the non wetting phase satisfies гb γbvb the dependence between гb and vb is linear for all of the heterogeneities considered the implication is extremely useful for continuum scale models of ostwald ripening li et al 2020 among others since ripening is driven by gradients in the pc of trapped ganglia and pc and гb are related by pc σ dгb dvb if гb is a linear function of vb as suggested by fig 18 then pc must be approximately constant and the driving force for ripening is zero in other words growth paths in fig 18 say that beyond a certain sb ganglia have no thermodynamic tendency to exchange mass with each other but we note that the constancy of γb at large sb holds strictly for growth paths shrinkage paths are not perfectly constant only approximately so most exhibit a smooth and slightly increasing γb with sb at large sb and a few with rhet 1 01 i e homogeneous networks and large ξ ½ exhibit discontinuities and spikes along their shrinkage paths which have the same origin as those in fig 17 see section 4 2 1 these deviations together with the overall hysteresis between growth and shrinkage paths may matter for ripening because in ripening some gangia grow while others shrink however the only way to know for certain if they do matter is to run dynamic simulations of ostwald ripening which we defer to future work we conclude with three additional remarks 1 as sb 0 the dependence between γb and sb approaches that of a spherical bubble namely γ b sb 1 3 this is consistent with experimental observations in the literature landry et al 2011 2 for small ξ ¼ in fig 18 there appears to be a minimum ganglion size below which growth is intermittent marked by chaotic variations in γb and above which growth is continuous marked by smooth variations in γb this size threshold sb increases with rhet in fig 18 the growth path for rhet 9 and ξ ¼ is dominated entirely by the intermittent regime because the network is too small we have therefore repeated the simulation in a larger 301 301 network and included it as an inset of fig 18 we see the existence of a similar threshold sb here as well in section 4 2 3 we elaborate more on this threshold and the two growth regimes note that sb in the x axis of the inset is calculated with respect to a much larger pore volume than the other plots in fig 18 3 the observation that гb is approximately a linear fuction of sb is not new similar observations have been reported for specific classes of porous materials e g sandstones in the literature iglauer et al 2013 geistlinger et al 2014 landry et al 2011 andrew et al 2014 geistlinger and mohammadian 2015 geistlinger et al 2015 to explain them frequent appeal to percolation theory iglauer et al 2011 geistlinger and mohammadian 2015 geistlinger et al 2015 stauffer and aharony 1992 is made which is valid for displacement processes that can be approximated by a sequence of bond invasion or site retraction events as noted in section 4 2 1 not all e g low ξ networks fit this mold growth paths can be intermittent for example which bears no resemblance to an orderly and sequential invasion pattern expected from percolation theory the systematic and high fidelity simulations of fig 18 fill this gap in the literature but astonishingly do not alter its existing conclusions 4 fig 18 applies strictly to spatially uncorrelated and unfractured media the relationship between γb and sb or equivalently гb and vb will likely differ for correlated porous media 4 2 3 euler characteristic fig 19 shows the evolution of χb versus sb during both growth black and shrinkage red in pore networks with different rhet and ξ fig 19 supports many of the observations made in figs 17 18 by providing a visual understanding of the non wetting phase topology let us focus on the growth path first when ξ ½ the growth of a ganglion is accompanied by a continuous generation of loops driving χb towards negative values this means that the non wetting phase becomes more connected as sb increases the observation also extends to ξ ½ except that loop generation is preceded by a period where χb is nearly constant and varies somewhat chaotically this period corresponds to the intermittent growth regime discussed in section 4 2 1 in which loop generation causing χb to decrease is balanced by ganglion fragmentation causing χb to increase as noted in section 4 2 2 what is surprising here is that there is a critical saturation sb above which growth is no longer intermittent but continuous for sb sb all ganglion fragments connect into a single cluster and χb decreases smoothly with sb thereafter similar to ξ ½ moreover sb increases with rhet for rhet 9 and ξ ¼ in fig 19 the entire growth path lies in the intermittent regime because the 101 101 network used in the simulation is too small we therefore repeated this simulation with a 301 301 network and replotted the growth path in the upper right inset of fig 19 similar to rhet 1 01 and rhet 3 we see the existence of sb here as well as in fig 18 note that sb in the x axis of the inset is calculated with respect to a much larger pore volume than the other plots in fig 19 we next focus on the shrinkage paths which are seen to consist of roughly three periods the first period large sb is dominated by the non wetting phase retracting from branch pores because pore retraction does not alter the topology of the non wetting phase χb remains roughly constant the second period medium sb is dominated by a continuous destruction of loops due to snap off as the non wetting phase becomes less and less connected χb increases towards positive values in the third period small sb the non wetting phase begins as small isolated fragments generated during period 2 and as sb decreases the fragments vanish one by one due to dissolution in order of small to large pores occupied by them the result is a continuous decrease in χb fig 19 shows that the strength and duration of each period is controlled by ξ and rhet to first order the duration of all periods depends primarily on ξ not rhet as ξ decreases periods 1 and 2 become shorter while period 3 becomes longer four extreme cases are worth noting 1 when ξ is small ¼ period 1 is nearly absent and period 2 is almost instantaneous physically this means that the non wetting phase immediately fragments into numerous small clusters in response to a tiny decrease in sb 2 when both ξ ¾ and rhet 3 are large period 3 disappears 3 when the network is homogeneous rhet 1 01 and ξ is large ½ period 2 is discontinuous and marked by occasional spikes the interpretation of this last case is as follows since all pores and throats are nearly identical when rhet 1 01 snap off in one interior throat coincides with snap off in all or most interior throats leading to the simultaneous destruction of a large number of loops and a comensurate jump in χb the spikes here have the same origin as those in figs 17 18 see sections 4 2 1 4 2 2 lastly 3 when ξ is small ¼ a new period apears between periods 2 and 3 during which χb remains constant in this period fragments generated at the end of period 2 undergo simultaneous shrinkage without any of them vanishing recall again that because shrinkage is quasi static all fragments have equal capillary pressures at all times 5 discussion 5 1 implications for geolgoic co2 sequestration figs 17 19 have two important implications for geologic co2 storage 1 ostwald ripening may not pose a serious threat to the leakage of capillary trapped co2 ganglia by buoyancy from spatially uncorrelated and unfractured rocks because the interfacial area or energy of trapped ganglia гb depends at least approximately linearly on their volume vb ganglia will have a weak tendency to merge by ripening and to subsequently mobilize by buoyancy to conclusively verify this claim however time dependent simulations of ostwald ripening for a population of multi pore ganglia are needed moreover fig 18 says nothing about the stability of trapped co2 bubbles inside spatially correlated rocks which are more common in the subsurface bryant et al 1993 both open questions will be the subject of future work 2 it appears perhaps unsurprisingly that it is safer to store co2 in rocks that have a small throat to pore size ratio ξ this is because the smaller ξ is the higher the probability will be that the non wetting phase fragments what is surprising however is that there is a minimum ganglion size sb above which the ganglion ceases to fragment and remains connected fig 19 which increases the probability of leakage by buoyancy the precise value of sb depends on the heterogeneity of the rock or rhet the higher the heterogeneity the larger is sb and the higher is the likelihood of fragmentation hence the lower is the likelihood of leakage the implication is that it is safer to store co2 in rocks that are more heterogeneous not less but since heterogeneous rocks tend to contain more potential pathways for leakage e g fractures and have less storage capacity i e poor sweep efficiency the impact of multiple competing factors must be accounted for in selecting storage sites 5 2 limitations and future extensions aside from the assumptions listed in section 2 our pnm has several limitations chief among them are the pci vbi curves in eq 1 or fig 3 for different pore types while the qualitative shape of these curves are consistent with recent experimental and theoretical observations xu et al 2017 wang et al 2021 their quantitative values are assumed herein not derived from first principles this presents a future opportunity to employ dns shams et al 2021 alpak et al 2019 or x ray µct experiments singh et al 2022 bultreys et al 2020 as means to parameterize or replace eq 1 for specific and potentially more complex pore shapes we expect the resulting pnm to be quantitatively more accurate but to not alter any of the qualitative conclusions drawn in section 4 2 another simplification related to eq 1 is that the pci vbi curves associated with l bridge and i bridge interior pores depicted in fig 3b are assumed identical in reality the two pore types will likely exhibit differences that might be worth capturing separately but whether doing so will significantly increase the accuracy of pnm predictions remains to be determined a second limitation of the pnm is that ganglia are assumed to be perfectly non wetting or have a contact angle of zero to account for non zero contact angles the main parts of the pnm that need modification are the pci vbi functions in eq 1 and the snap off and breakthrough criteria for throats given by eqs 2 3 we note that pci vbi functions corresponding to non zero contact angles tend to be more complex and discontinuous wang et al 2021 at vbi vci unlike eq 1 or fig 3 nonetheless we think here too dns can be used to numerically construct the pci vbi functions as an upscaled input to pnm the key difficulty we anticipate is in computing pci vbi functions for interior pores where more than one configuration of the non wetting phase may need to be considered i versus l bridge pores see fig 3b a theoretical analysis of the general form of pci vbi functions for non zero contact angles was recently reported by the authors wang et al 2021 a third limitation lies with the assumed throat shapes as square prisms other shapes say with a converging diverging geometry will have a different capillary entry pressure eq 2 and snap off threshold eq 3 while we do not expect different throat shapes to qualitatively alter the observations in section 4 2 we do expect quantitative impact one example is the critical aspect ratio ξ below which ganglion growth is intermittent and above which it is continuous see fig 19 another is the critical saturation sb when ξ is small above which the non wetting phase transitions from an intermittent to a continuous growth regime the exact values of the critical ξ and sb will likely depend on the throat shape and pore shape but that is embedded into eq 1 the final limitation not of the pnm but of the results presented in figs 17 19 is that all pore networks considered herein are spatially uncorrelated and planar 3d it is entirely possible that for spatially correlated networks the evolution paths of pc γb and χb versus sb look qualitatively different a reasonable expectation is that the larger the correlation length the larger sb must be for pc and γb to asymptote along growth paths see fig 18 for fully 3d domains we expect results to remain qualitatively unaltered verifying these claims however is left as future work 5 3 algorithmic considerations of the pnm for ostwald ripening in a recent work by mehmani and xu 2022 a fully implicit pnm for modeling ostwald ripening in arbitrary pore networks was proposed the pnm had one key limitation ganglia were assumed to occupy no more than one pore the pnm presented in section 3 generalizes this previous version to multi pore ganglia but the formulation algorithm 3 corresponds to a sequential not fully implicit algorithm in mehmani and xu 2022 the authors outlined two drawbacks of sequential algorithms 1 they tend to be very slow and 2 they incur errors by neglecting the gain loss in dissolved solute due to changes in the non wetting phase volume within pores i e the term ci dvbi dt is negligible see section 6 4 of mehmani and xu 2022 the latter assumption may become invalid when ganglia are in the process of vanishing by dissolution i e dvbi dt is large the first drawback is removed here by employing an adaptive time stepping strategy as described at the end of section 3 9 the second drawback however persists our initial attempt to generalize the pnm of mehmani and xu 2022 was to adopt a fully implicit framework devoid of this drawback but we realized quickly that the resulting algorithm becomes infinitely more complex than the one outlined in section 3 such an algorithm requires merging algorithms 1 and 3 appendices a b in a monolithic or iterative fashion we concluded therefore that the small price paid in accuracy for adopting a sequential scheme is worth the ability to simulate the evolution of multi pore ganglia which would otherwise be intractable the validation of our pnm against the microfluidic experiment in section 4 1 1 is encouraging as it suggests the actual loss in accuracy is minimal 6 summary and conclusions we developed a novel pore network model pnm capable of simulating the evolution of large multi pore ganglia inside heterogeneous pore networks due to mass transfer by ostwald ripening or an external concentration field ganglia are assumed to be incompressible and perfectly non wetting with respect to the solid pores are simplified as semi cubes and throats as square prisms the pnm accounts for all salient capillary events that a ganglion might undergo including pore invasion interface retraction snap off dislocation coalescence and fragmentation much of these physics have either been ignored or captured incompletely in the literature we validated the pnm against two microfluidic experiments 2d direct numerical simulation dns and an analytical solution for the growth shrinkage cycle of a ganglion inside a 2d homogeneous domain in all cases the pnm exhibited good agreement and predicted the correct sequence of capillary and ripening events future extensions should focus on capturing non zero contact angles and more complex pore throat shapes this requires open source datasets experimental or dns of ganglion evolution by ripening or solute transport if the pnm is to be validated and applied to realistic 3d microstructures the literature is currently in short supply of such data we next applied the pnm to study growth shrinkage cycles of a ganglion inside lattice pore networks with varying degrees of heterogeneity controlled by the throat to pore aspect ratio ξ and the variance of pore size distribution psd rhet overall simulated cycles bore qualitative similarities to the analytical solution of wang et al 2021 for 2d homogeneous networks in the following ways 1 cycles are hysteretic 2 a ganglion s capillary pressure exhibits oscillations that attenuate at large volumes and 3 the dependence between a ganglion s interfacial area or energy and volume is exactly linear at large volumes along growth paths regardless of ξ and rhet but approximately linear along shrinkage paths there were however key differences between the heterogeneous networks simulated and the homogeneous network described analytically 1 if ξ is large ganglion growth is macroscopically continuous or percolation like similar to the analytical solution but if ξ is small a new intermittent growth regime emerges that precedes continuous growth during which ganglia repeatedly fragment and reconnect across multiple pores unlike the analytical solution moreover there exists a size threshold sb below which ganglion growth is intermittent and above which it is continuous the threshold increases with rhet this means once a ganglion reaches a sufficiently large size fragmentation is suppressed and the ganglion remains connected 2 shrinkage paths are strong functions of ξ but weak functions of rhet specifically the topological evolution of the non wetting phase during shrinkage can be divided into three periods of pore retraction loop destruction and fragment dissolution as shrinkage is induced here by dissolution the duration and intensity of each period is controlled primarily by ξ the key takeaway is that the non wetting phase shrinks like a site percolation process or a sequence of pore retraction events only when ξ is large similar to the analytical solution otherwise shrinkage is dominated by the wholesale fragmentation of the non wetting phase into small clusters one implication for geologic co2 storage is that it seems safer to store co2 in rocks that are more heterogeneous not less rocks with small ξ and large rhet are favorable as they promote fragmentation and thus prevent super sized ganglia from emerging which may leak by buoyancy but heterogeneous rocks also come with other trade offs e g poor storage capacity that must be factored into site selection another implication is that ripening seems not to pose a serious threat to co2 leakage from rocks that are microstructurally uncorrelated the reason lies with the approximately linear dependence between a ganglion s interfacial energy and volume fig 18 to render this claim conclusive however time dependent ripening simulations of multi pore ganglia are needed this is now enabled by the proposed pnm credit authorship contribution statement yashar mehmani conceptualization methodology formal analysis writing original draft writing review editing ke xu formal analysis validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements yashar mehmani acknowledges the department of energy and mineral engineering eme the college of earth and mineral sciences ems and the institutes of energy and the environment iee at the pennsylvania state university for providing the funds for this project the institute for computational and data sciences at penn state university is also thanked for providing access to computational resources ke xu gratefully acknowledges support and funding from cnpc research institute of petroleum exploration and development for the project key fluid mechanisms of co2 eor for gu long shale oil development supplementary materials we have included with this paper the following supplementary materials 1 a movie of an experiment capturing the dislocation of a ganglion inside a 3d printed micromodel and 2 two videos visualizing growth paths inside two 11 11 pore networks with different throat to pore aspect ratios ξ ¼ and ¾ and a pore size heterogeneity of rhet 2 the videos are captioned for detail the supplementary material can be found in the online version at doi 10 1016 j advwatres 2022 104223 appendix d supplementary materials image application 1 image application 2 image video 3 image video 4 appendix a algorithm for equilibrating ganglion populations algorithm 1 is used to compute the capillary equilibrium configuration of a population of ganglia inside a porous medium it calls algorithm 2 as a subroutine to compute the capillary pressures of each individual ganglion at a fixed pore throat occupancy appendix b algorithm for simulating mass transfer and ostwald ripening algorithm 3 outlines the steps required to simulate the ostwald ripening or solute driven evolution of a population of partially miscible ganglia note that algorithm 3 calls algorithm 1 at the end of each time step to ensure all ganglia are in capillary equilibrium at all times i e quasi static evolution appendix c computing interfacial free energy or area of a ganglion the interfacial energy of a ganglion fb is related to its capillary pressure pc through pc dfb dvb we can use this equation to calculate fb by integrating the pci vbi relations in eq 1 corresponding to the different pore types in the ganglion s graph concretely suppose a ganglion s graph consists of ni interior pores and nb branch pores then fb is the sum of the interfacial energies associated with the portions of the ganglion residing in each pore c 1 f b i 1 n i 0 v b i p c i i d v b i i 1 n b 0 v b i p c i b d v b i and if the ganglion occupies a singleton pore i e it is a bubble then c 2 f b 0 v b i p c i s d v b i by substituting eqs 1a b into eqs c 1 2 and carrying out the integrations we obtain fb dividing fb by the interfacial tension σ yields гb because f b σ г b 
113,in this paper we develop a two dimensional modelling framework suitable to study the morphological evolution of vegetated braided rivers the mathematical model features a unisize sediment morphological model which includes accounting for bank erosion and a vegetation model while these model components had already appeared separately in different contexts here we improve and tailor them for modelling vegetated braided river dynamics we implement a numerical solution to this problem in the framework of the pre existing morphological model giamt2d we devise a hydrograph splitting technique to avoid excessive run times in the multi decadal applications needed to appreciate vegetation driven morphological change this hydrograph splitting technique uses the full model to solve for flood periods while applying a fixed bed approximation and only updating vegetation density during low flow periods finally we apply the developed formulation tools and techniques to simulate an idealised reach of the lower waitaki river aotearoa new zealand where we reproduce vegetation encroachment and morphological change observed between 1936 and 1964 keywords numerical modelling braided rivers morphodynamics vegetation transitional rivers bank erosion 1 introduction 1 1 background and objective river braiding i e the spreading of river channels into multiple threads characterised by an active rapidly evolving morphology ashmore 1991 happens in pro glacial mountain and piedmont areas bristow and best 1993 under high energy flows and intense sediment transport with limited development of vegetation ashmore 2013 we are here concerned with gravel bed braided rivers where fluvial sediment transport occurs predominantly as bedload the presence of vegetation can interfere with the ability of rivers to braid plants acting as river engineers affect the flow field and retain sediment with their trunks branches and foliage and strengthen soils with their root systems e g gurnell 2014 while being controlled by hydrological and hydromorphological processes that affect plant settling growth and mortality gurnell et al 2012 2016 through its effects vegetation exerts a critical control on the planform of gravel bed rivers gran and paola 2001 tal et al 2004 shifting vegetation presence has been shown to be a key driver of morphological change capable of inducing originally braided rivers to transition towards single thread styles stecca et al 2019 this is particularly relevant in dammed rivers where the modified hydrological regime can favour vegetation spread petts and gurnell 2005 in europe with a few notable exceptions rivers lost braided character due to multiple anthropogenic stressors in the last 150 years e g stecca et al 2019 to the extent that braided channel patterns have become rare tockner et al 2003 schiemer et al 2020 hohensinner et al 2021 as braided rivers create diverse landscapes with unique ecological values tockner et al 2006 loss of braiding has ecological and environmental implications that are becoming increasingly considered by scientists and managers piégay et al 2006 le lay et al 2013 in aotearoa new zealand rivers have generally been exposed to less intense pressure than in europe and the country has many braided rivers wilson 2001 hicks et al 2021 with unique ecosystems gray and harding 2007 gray et al 2016 however encroachment of exotic non native vegetation is a particular issue this is because new zealand braided rivers host several endangered endemic species o donnell et al 2016 including birds which prefer bare gravel surfaces for nesting robertson et al 2017 maloney et al 1997 and vegetation encroachment is reducing habitat availability for these threatened species robertson et al 1983 hughey and warren 1997 also loss of these unique river landscapes causes degradation of cultural values and māori wellbeing crow et al 2020 which is associated with maintaining the health of the natural environment durie 1998 with increasing interest in forecasting the morphological response of gravel bed rivers to changes in vegetation presence and in other drivers solari et al 2016 and while river geomorphology is progressively evolving towards a more model based quantitative discipline grant 2012 stecca et al 2019 a compelling objective is to construct and operate physics based numerical modelling tools that can predict planform changes due to changes in vegetation presence this is the objective of this paper 1 2 numerical modelling of vegetated braided rivers morphological modelling of braided rivers has been attempted for decades with progressively increasing complexity and realism following two alternative approaches reduced complexity models which route flow and sediment without solving for the full momentum balance were first popular for their reduced computational cost starting from the pioneering work of murray and paola 2003 this modelling approach has been widely used to study the long term impact of vegetation on morphology e g coulthard et al 2007 ziliani et al 2013 ziliani and surian 2016 ziliani et al 2020 the alternative physics based modelling approach solving the full momentum balance and sediment continuity has been initially daunting due to its high computational cost often resulting in impractical run times the main reasons are the inherently two dimensional nature of flow fields which mandates a two occasionally three dimensional model formulation the need to resolve morphology at sufficiently fine scales to observe the interplay between the development of in channel features and planform shape while covering computational domains wide enough to contain braided reaches and when vegetation is considered the need to run models over multi decadal time scales to appreciate the impact of vegetation on morphology in recent years however with increasing availability of computing power physics based modelling of braiding river morphodynamics has gained popularity schuurman et al 2013 nicholas 2013 nicholas et al 2013 schuurman and kleinhans 2015 yang et al 2015 sun et al 2015 nicholas et al 2016 schuurman et al 2016 williams et al 2016 singh et al 2017 schuurman et al 2018 yang et al 2018 yang 2020 olsen 2021 yet models of this class that feature vegetation are few and generally apply rule based approaches to render vegetation morphology interactions li and millar 2011 crosato and saleh 2011 nicholas 2013 without explicitly accounting for vegetation growth and mortality in detail nicholas 2013 and nicholas et al 2013 2016 provide the only such application to date to fully developed multi thread channel patterns over timescales of a few centuries with a model accounting for vegetation related flow drag and parameterising changes in vegetation presence using threshold submerged time and threshold velocity rules none of these models however has been validated by closely reproducing the evolutionary trajectory observed in a real world test case more refined renderings of vegetation morphodynamics interactions were put forward in models for single thread river applications bertoldi et al 2014 van oorschot et al 2016 jourdain et al 2020 amongst them bertoldi et al 2014 undertook the most physics based treatment to date of vegetation morphology feedbacks while modelling a straight channel with alternate bars 1 3 approach in this paper we develop a two dimensional numerical model framework suitable for studying vegetation driven morphological change in braided rivers which uses one of the most physics based formulations available and we validate the framework by applying it to the test case given by vegetation encroachment and morphological change observed in the coastal reach of the lower waitaki river new zealand between 1936 and 1964 the model will prove capable of matching the reduction in unvegetated width seen in the historic field data reported in hicks et al 2003 our modelling framework features innovations in the mathematical formulation in the solution strategy and the computational tools salient features of the formulation are i a bank erosion model that generalises in 2d the critical bank height approach that we developed in previous work in 1d stecca et al 2017 and ii a vegetation model for the braided river cases developed off an earlier formulation for single thread channels bertoldi et al 2014 one key improvement with respect to the latter work critical to modelling braided rivers is that we account for the feedback of vegetation presence on the stability of banks the solution strategy puts forward a hydrograph splitting technique that mitigates the problem of long run times needed for decadal scale applications and hence is key to the feasibility of our simulations this hydrograph splitting technique only uses the full flow morphology and vegetation model for flood periods while a much faster solution which only evolves vegetation with a fixed bed and steady flow approximation is used during low flow periods to implement the hydrograph splitting technique we develop an integrated set of computational tools that features a full vegetation and morphology solver named giamt2d veg and a stand alone vegetation evolution model save the bed of the lower waitaki river which in the 1930s was composed of bare sediment became heavily vegetated within just a few decades after the introduction of exotic woody vegetation including gorse broom and willows while the lower waitaki features a naturally damped flow regime due to the presence of three natural headwater lakes hicks et al 2007 the flow regime has been progressively further damped by hydropower development since the 1930s with the construction and operation of dams and control structures on the natural lakes hicks et al 2006 this artificial flow damping likely favoured vegetation encroachment with our simulation we show that the model can reproduce decreasing trends in unvegetated river width and braiding intensity as measured from historic photos of the lower waitaki in previous work hicks et al 2003 hicks 2006 the paper is organised as follows in section 2 we present the mathematical model in section 3 we describe the numerical solution strategy and tools in section 4 we introduce the test case and the model setup needed to reproduce it and in section 5 we present our results finally the strengths limitations and potential for further development of this work are discussed in section 6 conclusions are presented in section 7 2 mathematical model in this section we describe the mathematical model used to describe the morphological evolution of vegetated gravel bed braided rivers the model comprises a set of governing equations section 2 1 and appropriate closure relations section 2 2 2 1 governing equations the model governing equations feature a hydrodynamic model a sediment continuity model for morphological evolution and a vegetation evolution model 2 1 1 hydrodynamic model as commonly done when modelling flow in braided rivers the hydrodynamic model uses a two dimensional x y depth averaged shallow flow formulation commonly referred to as the saint venant equations i e 1 h t u h t v h t 0 u h t x 1 2 g h 2 u 2 h u v h y g h b x g h s f x v h t u v h x y 1 2 g h 2 v 2 h g h b y g h s f y where x and y m are the two planimetric coordinates t s is time h m is the flow depth u and v ms 1 are the depth averaged flow velocities in the x and y directions respectively g 9 81 ms 2 is the acceleration due to gravity b m is the bed elevation and s f x and s f y are the friction slopes in the x and y directions 2 1 2 morphological model the morphological model uses the simplifying assumption that the bed sediment comprises only one size unisize sediment approximation this assumption is sufficiently accurate when modelling river beds that are not significantly degrading as happens for the modelled reach of the waitaki river in this work while significantly reducing the computational load compared with mixed sediment models which is key for the present application with unisize sediment the model consists of one two dimensional mass continuity equation 2 1 p b t q b x x q b y y d if x y bank toe e if bank top 0 otherwise here p is the bed porosity assumed as constant and equal to 0 4 q b x and q b y m 2 s 1 are the sediment discharges per unit width in the x and y directions respectively and d and e ms 1 are the deposition and erosion rates at the bank top and bank toe eq 2 is a variation of the standard two dimensional exner model see e g siviglia et al 2013 where the right hand side of the equation has been modified to include a bank erosion model by considering three distinct cases pertaining to the bank toe bank top or elsewhere e g channel beds as done by stecca et al 2017 in 1d notably this formulation resembles a non capacity model of bankside transport the algorithm for the spatial identification of the bank top and toe will be presented in section 3 2 1 3 2 1 3 vegetation model to predict the evolution of vegetation density in space and time we adopt the vegetation model put forward by bertoldi et al 2014 for single thread channels but with a few key enhancements and modifications that make it suitable for simulating vegetated braided rivers following their approach vegetation presence is described by a variable b t x y that indicates the ratio of actual areal stem density to the maximum admissible areal stem density for the considered vegetation species hereinafter we will call this variable vegetation density fraction admissible values for b are between 0 and 1 the former associated with bare sediment the latter with a fully developed vegetation cover notably the same value of b could indicate a different dimensional density of vegetation depending on the considered vegetation type and hence a different intensity of the hydro morphodynamic effects of vegetation furthermore an equilibrium vegetation density fraction variable b e q h b is introduced b e q represents the density fraction value that would be achieved at a location after infinite time in the absence of bed elevation or flow depth changes or of vegetation removal events and will be specified by a closure relation in section 2 2 4 unlike in bertoldi et al 2014 here we account for the seasonality of vegetation growth during the growing season represented in the model as the period from september 1 to april 30 vegetation density can both increase and decay trending towards the equilibrium value following the relation 3 d b d t 3 t v b b e q were t v is the time scale of vegetation adaptation during the winter from may 1 to august 31 vegetation density is not allowed to increase due to dormancy but only to decay if the equilibrium density fraction is smaller than the actual density fraction which yields the relation 4 d b d t 3 t v b b e q if b b e q 0 otherwise further to this framework for slow adaptation two simplified mechanisms of abrupt vegetation removal are considered removal happens due to morphological evolution of the bed as plants are removed due to either sediment transport within a channel or collapse of an eroding bank the latter mechanism has been introduced specifically for this study the model sets the vegetation density fraction to zero for the next time step at all locations where either the shields stress exceeds the critical value for the onset of sediment transport θ c or accumulated erosion in that cell exceeds a preset threshold δ b t as will be described later with eq 11 the critical shields stress θ c will be assumed as an increasing function of the vegetation density fraction this allows the model to account in a simplified manner for denser vegetation being harder to remove 2 2 closure relations closure relations are needed to evaluate the friction slope terms s f x s f y in the saint venant equations 1 and the sediment fluxes q b x q b y and the deposition and erosion terms d e associated with bank erosion in the exner type equation 2 these relations include a dependence on the local vegetation density fraction unlike analogous relations adopted in models for unvegetated rivers furthermore the relation yielding the equilibrium vegetation density fraction b e q to be used in eqs 3 and 4 will be presented 2 2 1 flow resistance the friction slope terms in the saint venant equations 1 are evaluated using a chézy type law namely 5 s f x u u 2 v 2 c 2 h s f y v u 2 v 2 c 2 h where c m 1 2 s 1 is the chézy coefficient the latter is obtained by combining a chézy coefficient associated with bare gravel c g and a chézy coefficient associated with fully developed vegetation c v using the vegetation density fraction b as a weight namely 6 c 2 c g 2 b c v 2 eq 6 can be derived by adding the shear stress contributions exerted on the flow by gravel and vegetation as done in previous work in the waitaki river by aberle et al 2003 in eq 6 the chézy coefficient of bare gravel is specified with the classical relation of keulegan 1938 as a logarithmic function of depth 7 c g 6 2 5 ln h k s g where k s m is the bed roughness height the chézy coefficient of fully developed vegetation is evaluated using the approach of lindner 1982 8 c v 2 c w 2 g d p h a x a y where c w is a calibration coefficient in the range 1 3 d p m is the plant diameter and a x and a y m denote spacing between plants along the x and y directions at maximum vegetation density the present approach improves the approach of bertoldi et al 2014 who used instead a manning type friction relation with the inverse of the manning coefficient obtained by a weighted average of the inverse of two constant manning coefficients for bare gravel and fully developed vegetation respectively here eqs 7 and 8 account for the different dependence of gravel and vegetation related friction on depth in bare gravel areas the logarithmic law 7 is preferable to the manning approach ferguson 2010 and in vegetated areas eq 8 allows one to relate friction to measurable properties of the tree cover 2 2 2 sediment transport the sediment fluxes q b x and q b y to be used in the exner type equation 2 are modelled using the classical meyer peter and müller relation meyer peter and müller 1948 extended to a two dimensional setting and modified to account for vegetation presence the intensity of bedload denoted with q b m 2 s 1 is given by 9 q b 8 g s 1 d s 3 max θ θ c 0 3 2 where d s m is the sediment diameter representative of transported sediment having adopted the unisize sediment approximation s ρ s ρ w is the ratio between the sediment density ρ s 2650 kg m 3 and the water density ρ w 1000 kg m 3 θ is the shields stress exerted by the flow over the bed sediment 10 θ u 2 v 2 c g 2 s 1 d s and θ c is the critical shields stress value evaluated as 11 θ c 1 b θ c g b θ c v where θ c g and θ c v assumed as constants and assigned as input parameters see section 4 2 6 are the critical shields stress associated with bare gravel and with fully developed vegetation respectively with the constraint θ c v θ c g once the bedload intensity q b has been calculated using eq 9 the two components q b x and q b y must be evaluated to do so sediment transport is essentially projected in the direction given by the local flow velocity but with a deviation that accounts for the role of secondary currents in the cross sectional plane following the approach of engelund 1974 as in sun et al 2015 and the gravity deflection driven by the bed slope orthogonal to the flow following the approach of ikeda 1982 as in siviglia et al 2013 to this end we define with p n an orthogonal reference system where p and n are the unit vectors parallel and normal to the local flow respectively and n takes positive values in the direction given by a 90 anticlockwise rotation from p see fig 1 we specify the bedload transport vector in this reference system by defining the two components q b p and q b n that are aligned with p and n respectively the ratio between q b n and q p b is given by 12 q b n q b p n h r r θ b n on the right hand side of eq 12 the first term accounts for the effect of secondary currents n being a dimensionless parameter that indicates the secondary current strength having typical value of 7 sun et al 2015 and r being the curvature radius of the local streamline taken as positive when the streamline rotates in the counter clockwise direction the second term accounts for the gravity deflection r being a dimensionless parameter in the range 0 3 0 6 that indicates the strength of the deflection and b n the bed gradient in the direction normal to the flow once q b p and q b n have been calculated their projection onto the x y reference system yields q b x and q b y 2 2 3 bank erosion following stecca et al 2017 the purpose of any bank erosion sub model is to identify the top and toes of eroding banks compute for each top an erosional mass exchange rate e and for each toe a depositional rate d and to feed these contributions into the sediment mass conservation equation 2 bank erosion models are available at different degrees of complexity stecca et al 2017 here we use a simple approach suitable for non cohesive soils since comparable approaches have been successfully applied for modelling braided river dynamics e g nicholas 2013 sun et al 2015 we extend to the present two dimensional framework the critical bank height approach in stecca et al 2017 and we adapt it to account for vegetation presence the critical bank height approach is similar to the widely used critical slope approach but has some advantages critical slope in morphological modelling is a mesh size dependent calibration parameter with little physical basis on coarse meshes its value must be set unphysically small to compensate for the underestimation of bed slopes and still produce reasonable bank erosion the alternative being the use of very refined grids e g having size comparable to the flow depth which is often unaffordable computationally conversely as shown by stecca et al 2017 with the application of a 1d cross sectional model critical bank height is almost mesh size independent and can be more confidently set based on field observations mesh size independence is also an advantage when working with irregular grids as happens with curvilinear or as in the present case triangular grids since it helps preserving spatial homogeneity of bank erodibility throughout the model domain the model works as follows eroding banks are located where the difference between the bed elevation in two neighbouring cells is greater than a preset critical bank height δ b c m detail on our particular implementation on triangular meshes to identify for each erosion event the bank top and toe cells is given later in section 3 2 1 the effect of vegetation presence on bank erosion is incorporated as previously done for the critical shields stress 11 two separate values of critical bank height are defined one for bare gravel banks δ b c g and one for fully vegetated banks δ b c v the local critical bank height is 13 δ b c 1 b δ b c g b δ b c v and the constraint δ b c v δ b c g guarantees that a vegetated bank is more stable than a bare one bank collapse induces a sediment flux between the bank top and bank toe q b e ms 2 in our formulation we keep q b e constant for whenever δ b c is exceeded and assign it as an input finally the mass exchange contributions e and d having magnitude that matches q b e are computed see section 3 2 1 2 2 4 equilibrium vegetation density following bertoldi et al 2014 and references therein the equilibrium vegetation density fraction b e q to be used in eqs 3 4 is specified as a bell shaped function of the bed elevation the underlying assumption is that there exists an optimal range of river bar and bank relief values for supporting vegetation presence due to optimal availability of moisture for tree roots we introduce a correction to their relation so as to prescribe zero equilibrium density fraction in significantly wetted channels where plants cannot establish as seeds and dead wood cannot settle on the ground this correction proved key for model applicability to the complex morphology of braided rivers as it prevents permanently flowing channels from developing vegetation with these settings b e q is given by 14 b e q b e q 0 exp λ 1 b z v exp λ 2 b z v if h h t 0 otherwise where λ 1 and λ 2 m 1 are two parameters defining the bell shape z v m specifies the vertical offset of the curve h t m is the depth threshold used to identify significantly wetted areas b bed level and h depth have been introduced previously and b e q 0 is a constant coefficient that normalises the curve maximum to 1 equal to 15 b e q 0 λ 1 λ 2 λ 2 λ 1 λ 2 λ 2 λ 1 λ 1 λ 1 λ 2 in eq 14 we prescribe z v as unchanging in time but varying spatially in detail z v is given by the sum of a constant offset value z v 0 with the elevation given by the reference plane b 0 x sloping along the streamwise direction x that represents the initial morphology of simulations the equilibrium vegetation density fraction function used in the applications of this paper is shown in fig 2 3 solution in this section we present our strategy and tools for solving for braided river morphology and vegetation evolution 3 1 hydrograph splitting technique while designing the present solution strategy the key issue has been striking the balance between accuracy and computational effort simulating the morphological evolution of vegetated braided rivers is computationally challenging as it requires model application to multi decadal flow series over reaches that are several kilometres long and 1 2 km wide with a spatial resolution sufficient to resolve braiding dynamics ideally of the order of 1 m therefore direct numerical solution of the full problem 1 4 for realistic cases would have resulted in impracticable run times to mitigate the problem we developed an approximate solution strategy that we name hydrograph splitting technique with this strategy we solve the full problem only during flood periods while during low flow periods we only update vegetation density assuming that the bed topography is unchanging the logic behind this approximation is as follows during floods changes in the flow morphology and vegetation distribution occur simultaneously and interact with each other over short time scales which mandates the use of an integrated solution conversely during low flow periods morphological modification of the braided channel and associated vegetation removal are negligible and it is possible to only solve for vegetation adaptation for a small fraction of the computational effort than if the complete model was employed notably the hydrograph splitting technique can be applied to raw discharge records that may have different sources the options available to modellers to source an initial discharge record are discussed in section 6 5 3 2 model framework implementation of the hydrograph splitting technique required the development of a suitable model framework the primary tool to solve the full flow morphology and vegetation evolution problem is the numerical model giamt2d veg section 3 2 1 for evolving vegetation during low flow periods we implemented the stand alone vegetation evolution model save see section 3 2 2 to identify floods and low flow periods within the input hydrograph we developed a hydrograph splitting tool section 3 2 3 finally a master program was implemented to mange the calls to each of these tools 3 2 1 giamt2d veg a 2d morphology and vegetation evolution model the giamt2d veg model built upon the framework of the pre existing giamt2d model stecca 2012 siviglia et al 2013 solves the system of governing equations for river flow 1 morphology 2 and vegetation evolution 3 4 3 2 1 1 numerics giamt2d veg essentially retains the numerical structure of giamt2d i e a coupled solution that allows the model to stably address morphological evolution under trans and super critical flows which may be useful for steep riffles and the use of unstructured triangular meshes time stepping is explicit and adaptive with time step duration dictated by the stability of the hydro morphodynamic solution we refer the reader to stecca 2012 and siviglia et al 2013 for a full description of the model numerics 3 2 1 2 novel features key new features with respect to giamt2d are reconstruction of the morphological effect of secondary currents in eq 12 the bank erosion model section 2 2 3 added using a time splitting procedure after a solution without bank erosion has been achieved closure relations for flow resistance 5 critical shear stress 11 and critical bank height 13 that account for vegetation presence and the vegetation evolution model which solves eqs 3 and 4 with closure relation 14 and applies the abrupt removal mechanisms described in section 2 1 3 as needed the solution to eqs 3 and 4 for vegetation evolution obtained under the assumption of steady bed level and flow during each time step is analytical and hence unconditionally stable under any time step however the time step applied here matches the overall model time step which is restricted by the stability condition of the hydro morphodynamic solution 3 2 1 3 bank erosion implementation detail consider the current triangular cell t i and its three neighbours t j across each edge l j of t i for 1 j 3 see fig 3 applying the critical bank height criterion see section 2 2 3 cell t i is identified as an eroding bank top if the condition 16 b i b j δ b c is met for at least one value of j where b i and b j are the bed elevations within t i and t j respectively and δ b c is the critical height 13 calculated with the vegetation density fraction in t i erosion of the bed in cell t i happens independently across every edge l j for which the condition 16 is satisfied a key issue for effective bank erosion modelling concerns the identification of the bank toe cell to which the depositional contribution d in eq 2 will be applied poor identification algorithms can induce spurious stalling of the erosion process if the material eroded from a bank top is simply deposited in the neighbouring cell this happens when deposition at the toe reduces the bank profile steepness to a stable angle and due to bed level increase at the toe the decrease in flow velocity and transport capacity prevent the flow from scouring the toe any further stecca et al 2017 this problem is well known and various solutions such as intermittent bank updating nicholas 2013 or the use of very refined meshes sun et al 2015 have been proposed to mitigate it our solution instead uses a stencil approach for bank toe identification see fig 3 for each edge l j of cell t i a stencil comprising all the cells that share at least one vertex with one of the two ends of l j and have centroid within the extension of the two medians of t i that contain l j is identified and stored during model initialisation as seen from fig 3 the stencil across edge l j includes by construction the neighbouring cell t j but also includes other cells for an erosion event across edge l j the toe cell t toe is adaptively identified as the cell that has the smallest bed elevation at the current time amongst the cells in the stencil adjoined to l j this approach reduces the likelihood of stalling as the eroded material is dumped into the cell of the stencil having the lowest bed elevation and not just by default into the neighbouring cell t j where the bank stability condition 16 is checked once the toe cell has been identified within the stencil the erosional contribution e i in cell t i and the depositional contribution d toe in t toe are readily computed as 17 e i q b e l j t i d toe q b e l j t toe where l j is the edge length and t i and t toe are the areas of the respective cells 3 2 1 4 model parallelisation and acceleration notwithstanding the hydrograph splitting technique computational efficiency during floods is still critical since the great majority of computing time is spent solving for floods the computational speed issue is mitigated by the capability of running in parallel on shared memory using the openmp protocol e g chapman et al 2007 this feature which giamt2d veg inherits from giamt2d makes it suited to run on a cpu node of a high performance computing machine to further improve run times in giamt2d veg we implemented morphological acceleration and used a first order accurate integration scheme morphological acceleration involves multiplying the bedload discharges and elapsed simulation time by an acceleration factor greater than one one key drawback of this approach when applied to unsteady flows is that excessive acceleration can induce spurious temporal compression damping flood waves and preventing the lower part of simulated reaches from experiencing the same morphological activity as the upper part morgan et al 2020 however with the heavy computational load of multi decadal simulations the use of morphological acceleration is unavoidable crosato and saleh 2011 nicholas 2013 to minimise the effect on results acceleration was implemented in a flow dependent fashion i e with varying acceleration factors depending on the current discharge this mainly accelerated the smaller flows of floods waves for which less morphological activity is expected while solving the major flood peaks in real time although the integration scheme of giamt2d has been extended to second order accuracy siviglia et al 2013 here we used giamt2d veg only in basic first order mode running in first order mode the model is twice as fast as it would be in second order mode which allowed us to use a more refined mesh than the one that would have been feasible with a second order solution this was critical since being able to afford the use of computational meshes refined enough that morphological features are acceptably resolved while retaining practical run times is key for capturing braided channel dynamics furthermore wet dry transitions which are frequently found moving from wetted channels to emerging bars and banks would have been solved to first order accuracy anyway siviglia et al 2013 hence the overall accuracy gain of a second order setup would have been limited 3 2 2 stand alone vegetation evolution model save the stand alone vegetation evolution model save solves eqs 3 and 4 in the relevant period of the year under the assumptions of steady flow and stable bed morphology sudden removal mechanisms section 2 1 3 are not featured as they cannot happen without morphological change with these assumptions the solution is analytical and in the absence of other model components posing a more restrictive stability condition the time step is virtually unlimited therefore save can update the vegetation distribution to the end of the low flow period with run times of just seconds using save requires prior determination of a static inundation pattern to determine the pattern of the equilibrium vegetation density fraction 14 this inundation pattern is computed with the median flow for the period with a brief spin up run of the giamt2d veg model with static vegetation and morphology 3 2 3 hydrograph splitting tool the hydrograph splitting tool is used during simulation initialisation to identify low flow periods and floods within the input hydrograph for each flood to isolate and store the corresponding portion of the hydrograph that will be used as a boundary condition for morphological computations section 3 2 1 and for each low flow period to compute and record the period s median flow that will be used to compute the inundation pattern see section 3 2 2 the hydrograph is essentially split by comparing the current discharge with a threshold discharge q t q t is a river specific input parameter that must be set equal to the discharge above which non negligible morphological modification and vegetation removal are expected correctly setting q t is critical to the trade off between accuracy and efficiency while reducing q t reduces the extent of low flow periods treated with a steady flow and morphology approximation and hence increases model accuracy this occurs at the expense of additional run time due to the increased length of flood periods furthermore the program implements several filters to optimise splitting for computational efficiency amongst them one filter identifies floods of little importance those which have peak discharge smaller than another threshold value to be set slightly greater than q t and have duration smaller than a threshold time and aggregates their time to the surrounding low flow periods merging them into a single low flow while another filter aggregates short low flow periods to the two surrounding floods and merges them into a single flood when solving for these additional flood points is deemed more efficient than initialising the flow for a low flow period 4 test case in this section we will set up the model to simulate the vegetation encroachment and consequent channel pattern change observed on aereal imagery hicks et al 2003 in the coastal reach of the lower waitaki river new zealand between 1936 and the end of 1964 this is an ideal timeframe to assess the model capability to reproduce real world observed vegetation encroachment since in 1936 the riverbed was essentially bare while by 1964 encroachment had happened we limit the exercise to 1964 because after that the implementation of an artificial vegetation control plan changed the vegetation dynamics observed in the lower waitaki introducing further changes that would require a specific model implementation to be reproduced due to the excessive computational effort of modelling the entire river length 70 km we limit our modelling to one representative reach our aim will not be to reproduce exactly the river s behaviour at any location but rather to produce a faithful analogue of the river that has similar temporal trends of vegetation cover and morphological change metrics therefore we will use an idealised rectangular domain with dimensions that are representative of one real reach and the initial unvegetated channel topography will be computed by the model with a preliminary simulation in section 4 1 we introduce the test case while in section 4 2 we describe the model setup needed to reproduce it 4 1 lower waitaki river 4 1 1 geographic and historic settings by discharge the waitaki river is the fourth largest river and the largest braided river in new zealand see fig 4 three natural headwater lakes tekapō pūkaki ōhau dominate the source of flow and provide a natural damping of the flood regime hicks et al 2007 in modern times the waitaki has been intensely used for hydropower with the construction of dams and artificial lakes control structures on natural lakes and canals collectively named the waitaki power scheme hereinafter wps which has increased the damping effect on the flow regime hydropower exploitation started in the late 1920s with the beginning of the construction of waitaki dam and electricity generation commenced in the mid 1930s we are here concerned with the lower waitaki i e the 70 km long course running from the most downstream dam waitaki dam to the coast despite the presence of the dams the lower waitaki appears to be vertically stable throughout most of its course with degradation confined to its upper reach hicks 2006 stecca et al 2019 following the introduction of exotic vegetation such as crack willow salix fragilis broom cytisus scoparius gorse ulex europaeus and other weeds the lower waitaki experienced a dramatic change in vegetation cover that severely impacted the planform shape of the river hicks 2006 before 1940 the lower waitaki riverbed was largely bare and windswept up to 2 km wide by 1950 the active bed had become increasingly congested with exotic vegetation that had established in the riverbed and on the riparian margins together with vegetation spread a tendency towards simplification of the braided configuration has been observed to the extent that the river now flows in a few main central braids and has a more stable morphology than in the past tal et al 2004 our study reach is the coastal reach hicks et al 2003 i e the 10 km long stretch from between grays road and papakaio road to the coast fig 5 the reach has a slope of 0 355 in 1936 fig 5a the reach was largely unvegetated and 1600 m wide hicks et al 2006 see fig 5a subsequently vegetation cover gradually increased and this prompted the river to simplify its braided structure see figs 5b d 4 1 2 discharge record a discharge record measured at waitaki dam daily averages is available from 1926 onwards while data at higher frequency become available more recently in this work we have simply used daily averages in principle the discharge record of the coastal reach should not only account for flows at waitaki dam but also for the inflows from tributaries that join the waitaki between waitaki dam and the upstream end of the coastal reach however we have disregarded these contributions because flows in the lower waitaki are dominated by those at waitaki dam which account for 80 of the discharge measured in the coastal reach stecca et al 2019 there is no discharge record available in the waitaki downstream of the tributaries and the discharge records of the tributaries are not available for the study period 4 2 model setup 4 2 1 domain and initial morphology the computational domain is rectangular shaped with dimensions representative of the coastal reach see fig 6 the domain is 1 6 km wide and comprises an upper 600 m long fixed bed stretch and a lower 10 km long movable bed stretch the purpose of the upper fixed bed stretch is to move the flow injection point upstream from the movable bed stretch within the movable bed stretch and close to its upstream end a 200 m long stretch is set to damp sediment and impose sediment feed both the fixed bed stretch and the sediment damping stretch will be disregarded from results analysis and visualisation as result presentation will be restricted to the lower 9 5 kilometres of the movable bed stretch the initial morphology was set as a flat slope along the x direction with slope s 0 355 a value equal to the valley slope downstream of georgetown hicks et al 2003 4 2 2 boundaries at the upstream boundary of the fixed bed stretch an inflow discharge boundary condition is imposed at the lateral boundaries a slip reflective condition is imposed within the movable bed stretch close to the lateral boundaries two very narrow 20 m wide vegetated buffer zones with non removable vegetation cover are set these buffers are meant to mimic the action of outer vegetated stopbanks and to repel channels that otherwise would stick to the side boundaries and create unrealistically deep scour pools tal and paola 2010 vegetation density fraction values within the buffers vary along the transverse direction declining from 1 at the outer margin of the buffer to 0 at the inner margin during simulations with vegetation evolution the vegetation density fraction within the buffer is allowed to grow higher than the imposed value but never to be smaller for consistency identical vegetated buffers are applied even to the models used for creating the unvegetated braided channel the downstream boundary condition is given as an imposed water level this level is determined independently for each cell of the domain adjoining the downstream boundary and is imposed using a rating curve based on the normal flow with the present outflow in that cell the sediment is recirculated this is achieved by instantaneously matching the volume of material deposited in the sediment damping stretch to the sediment outflow measured at the lower boundary therefore the domain averaged bed elevation remains constant i e in an average sense the reach is neither aggrading nor degrading the assumption that the reach does not degrade is realistic for the present case see section 4 1 and is key to allowing the application of a unisize sediment model since the study of degradational reaches would mandate a mixed sediment model to reproduce bed armouring 4 2 3 mesh the mesh was generated with open source meshing software gmsh geuzaine and remacle 2009 the movable bed domain was covered with 199398 triangular cells with average cell surface area of 85 m 2 yielding average cell length the square root of the surface area of 9 2 m although our mesh is coarser than the mesh used in similar modelling studies singh et al 2017 nicholas 2013 this setup represents our best attempt to strike the balance between accuracy and efficiency 4 2 4 hydrograph splitting the key setting in the hydrograph splitting tool is the threshold discharge q t used to discriminate between low flow periods and floods we set this value equal to 450 m 3 s 1 a value above which 85 of bedload transport is achieved according to the time weighted bedload distribution by discharge derived by combining the bedload transport rating function and the flow duration curve see fig 8 2 in hicks et al 2003 for efficiency floods that last less than 5 days and have peak discharge smaller than 550 m 3 s 1 are aggregated to the surrounding low flows while low flow periods shorter than 5 days are aggregated to the surrounding floods the input hydrograph measured at waitaki dam see section 4 1 2 trimmed for the study period and the resulting model hydrograph produced by the hydrograph splitting tool with these settings are compared in fig 7 4 2 5 morphological acceleration we took advantage of the implementation of morphological acceleration as dependent on the inflow discharge to significantly accelerate the small flows while applying less acceleration to major flood peaks this benefited the model stability and minimised spurious compression and damping of the flood waves in the lower part of the domain see morgan et al 2020 the morphological factors used for our simulation presented in table 1 never exceeded 50 i e significantly smaller than those up to 200 used by nicholas 2013 and nicholas et al 2013 4 2 6 physical parameter choice 4 2 6 1 general parameters general parameters needed for morphological model simulation are the grainsize of transported material d s in eq 9 the gravel related roughness height k s in 7 the gravel related critical shields stress θ c g in 11 and the critical height of unvegetated banks δ b c g in 13 we set d s 0 022 m which corresponds to the median diameter of a bulk sample collected at priest road reach on the lower waitaki in 2005 hicks 2006 and is very similar to the median diameter for the entire lower waitaki 0 021 m hicks et al 2003 we imposed k s 0 126 m which we obtained from a calibrated hydrodynamic model of the lower waitaki in aberle et al 2003 for θ c we used the standard value of 0 047 as in bertoldi et al 2014 finally we set δ b c g 1 m a value indicative of the typical height of gravel banks according to our field observations 4 2 6 2 vegetation related parameters vegetation related parameters are the timescale of vegetation adaptation t v in eqs 3 and 4 the parameters determining the equilibrium vegetation density fraction curve b e q in 14 namely λ 1 λ 2 z v 0 and h t the parameters of the vegetation related friction coefficient 8 a x a y d p c w the critical shields stress of vegetated areas θ c v in 11 and the parameters of vegetated banks i e the vegetated critical bank height δ b c v 13 and the threshold bank erosion for vegetation removal δ b t see section 2 2 3 setting the values of these parameters for real world cases is not straightforward even when as for our case estimates of the realistic ranges for some parameters for the vegetation species that are present in the river are available from the literature in fact the adopted vegetation model can only handle one single vegetation type while in a real river there is a variety of vegetation species with differing rates of growth and thresholds of removal we deal with this issue observing that the model vegetation density fraction b is essentially a measure of the strength of the hydro morphodynamic impact of vegetation see eqs 5 11 13 therefore the increase of the vegetation density fraction from 0 to 1 can be interpreted as the progressive development on initially bare sediment of a succession of different species from the faster growing and least impacting e g for the lower waitaki grass lupins to the intermediate woody weeds such as gorse and broom to the slowest growing most impacting trees such as willows therefore when estimates of parameter values were available for the different vegetation species present in the waitaki as in aberle et al 2003 we adopted for our modelling those related to willows we set t v 12 y as a representative measure of the time needed for the full development of a willow cover in an initially bare sediment area in fact while individual willow plants can grow to maturity in a shorter time the adopted value is more realistic as it aims to represent the time needed for the full hydro morphodynamic effect of a dense willow cover to develop over an area that is at least as wide as one computational cell 85 m 2 we imposed the parameters of the equilibrium vegetation density fraction λ 1 0 1 m 1 λ 2 3 m 1 z v 0 0 5 m which are within the range set by bertoldi et al 2014 and we set h t 0 1 m as a realistic estimate for the minimum depth of permanently wetted areas where vegetation cannot establish if not initially present the resulting curve has been shown previously in fig 2 finally we set the parameters of the friction model as a x a y 0 5 m d p 0 8 m and c w 1 to the same settings used for willows in previous hydrodynamic modelling work in the lower waitaki aberle et al 2003 we impose θ c v 0 21 which is the value used to model strong vegetation in bertoldi et al 2014 based on previous work by li and millar 2011 we impose the vegetated critical bank height as δ b c v 1 5 m a value larger by 50 than the unvegetated value δ b c g which agrees with our field observations and set the threshold for vegetation removal on eroding banks as δ b t 0 5 m i e equal to the difference δ b c v δ b c g this value is equal to the half of the typical root depth of 1 m for willows salix fragilis van de wiel and darby 2004 li and millar 2011 and is used under the assumption that when half of the root is exposed the plant will fail 4 3 simulation sequence the sequence adopted for the simulations of this case example is schematised in fig 8 first we conducted a preliminary simulation to create the unvegetated braided channel to be used as an initial condition for the following simulation with vegetation evolution this is analogous to the approach utilised by tal and paola 2010 for their laboratory experiment where they developed a braided channel in a bare sediment bed before introducing vegetation this preliminary simulation started from a planar bed section 4 2 1 and lasted for 150 days a time period sufficient to develop a braided network in dynamic equilibrium vegetation density was zero throughout most of the domain except for a static vegetation cover in the lateral buffers section 4 2 2 the inflow discharge was constant and set equal to the formative discharge i e to the theoretical discharge that if maintained indefinitely would produce the same channel geometry as the natural long term hydrograph wolman and miller 1960 assumed equal to 1260 m3s 1 this value corresponds to the mean annual flood discharge at waitaki dam in the period 1928 2020 in the natural reconstructed hydrograph henderson 2020 i e the hydrograph that would have been measured in the absence of the wps and hence well approximates the discharge that shaped the river before the wps was developed once this bare braided channel was developed we used it as the initial condition for the simulation with evolving vegetation and unsteady flows applying the hydrograph splitting technique section 3 after classifying the flow record using the hydrograph splitting tool the solutions to low flow periods and floods were applied sequentially and each event took as initial condition the final output computed during the previous event 4 4 postprocessing of results here we will briefly detail the calculation of metrics used to characterise the evolution of the simulated reach metrics were computed in a subset of the reach for values of the streamwise coordinate greater than 500 m as explained in section 4 2 1 4 4 1 vegetation metrics to evaluate changes in vegetation presence in section 5 2 3 we calculated time series of domain averaged vegetation density fraction and unvegetated width for the latter series we evaluated for each model output the total area of substantially unvegetated cells and divided such area by the reach length substantially unvegetated cells were defined as those carrying a vegetation density fraction value smaller than a small threshold b t while setting b t we aimed to be consistent with the historic aerial photo analysis procedure in hicks et al 2003 since in their work unvegetated areas were defined as those covered by water bare gravel and even sparse and low vegetation we have tested b t 0 2 and b t 0 3 obtaining two distinct time series as a sensitivity exercise 4 4 2 braiding index to evaluate changes in braiding intensity in section 5 2 4 we computed time series of braiding index as this is the most consistent and easily measured metric of braiding intensity egozi and ashmore 2008 following the approach of howard et al 1970 braiding index was calculated by defining channel links along the centreline of each braid counting the number of links crossed by a series of cross sections and averaging the results along the length of the analysis domain as the braiding index is a discharge dependent metric we produced four different series with different discharge values we used half of the median discharge 1 2 q m 169 m 3 s 1 the median discharge q m 338 m 3 s 1 and twice and four times the median 2 q m 676 m 3 s 1 and 4 q m 1352 m 3 s 1 to gather the channel pattern associated with these discharges we run additional simulations of the giamt2d veg model over a fixed bed with static vegetation with the above inflow discharges taken as steady these simulations were performed at a yearly frequency gathering morphology and vegetation from the outputs of the full morphological simulation sampled at the start of the first low flow period of the year this choice was made for consistency as floods can remove vegetation and recessions tend to create small scale morphology thus affecting the channel pattern 5 results 5 1 creation of the unvegetated braided channel the creation of the unvegetated braided channel is shown by snapshots of shaded relief bed topography with overlain flow depth in fig 9 starting from an initially flat bed fig 9a the figure shows stages of channel development towards its final braided shape after 15 days fig 9b a rather regular bed instability pattern has developed after 30 days fig 9c the river starts carving one or two deeper channels while smaller bedforms have coalesced into bigger bedforms the process of fully developing into a braided channel continues until the end of the simulation figs 9d f this simulation is successful in producing an active braided network with channel pattern that keeps evolving contrast the last two snapshots in figs 9e f however the channel geometry at the final time fig 9f shows braids that are quite wide with morphological features appearing less sharply defined than in the real river in the absence of vegetation see fig 5a this discrepancy indicates that numerically generated topographies are excessively smoothed and individual braids are too wide and lacking small scale detail the reason is twofold first that the resolution of morphological features is limited by the adoption of a relatively coarse grid average cell size of 9 2 m since the width of the smallest representable braid scales with cell size as the availability of at least a few cells in the transverse direction is critical to represent the braid topography and second that the present simulation for braided channel formation is carried out with a constant formative discharge which may prevent the development of the smaller scale morphological features that are generally developed during flood recessions we decided to accept this discrepancy between the model result and the physical prototype as increasing the mesh resolution would have made the following unsteady computations excessively expensive this will not prevent the model however from producing realistic trends of unvegetated channel width and braiding intensity 5 2 vegetation and morphology evolution 5 2 1 planform changes the simulated channel evolution in the waitaki river starting in 1936 from the unvegetated configuration seen at the end of braiding development in fig 9f is shown in fig 10 by 1940 fig 10a vegetation had established on elevated bar tops by 1945 fig 10b vegetation had visibly grown on the channel margins and islands but the channel mainly in its lower section still maintained a central braided configuration by 1950 fig 10c the width of the vegetated margins had increased significantly and the channel had been further confined loosing part of its braided character and by 1955 fig 10d the river had reduced to a 2 channel system surrounded by margins with thick vegetation and featuring densely vegetated islands the situation partially changed in 1960 fig 10e because a spike of more frequent and intense floods from 1957 following a period with deficit in floods see fig 7 managed to halt vegetation encroachment and increase the unvegetated channel width notably in the lower part of the domain the right branch that was present in 1955 was abandoned as newly grown vegetation blocked the inlet to the former right channel and the width of the left branch increased the river in this configuration also featured less pronounced vegetated islands and one former island had coalesced with the right margin these changes will be analysed in detail in the next section finally at the end of 1964 fig 10f the situation was similar to 1960 apart for some still mild vegetation growth on low lying bars in the upstream section of the channel 5 2 2 vegetation changes during the 1957 1958 flood spike after years with prolonged low flow periods and brief isolated intervening floods from 1953 onwards the period from 1957 featured more frequent floods see fig 7b in response the model predicted vegetation removal along the main channel channel widening and increase in braiding intensity in fig 11 we focus on the spike of floods from early november 1957 until early june 1958 this had multiple peaks around 1000 m 3 s 1 and the major one happened at the end of 1957 with a discharge of 1734 7 m 3 s 1 on december 29 figs 11a c show the topography flow pattern and vegetation distribution before the flood spike at the main flood peak and after the flood spike respectively in fig 11c the vegetated channel margins of the channel seen before the flood in fig 11a are overlain to better appreciate channel widening the initial state of this sequence fig 11a was an almost single thread channel heavily confined by vegetation as the absence of floods between 1955 and 1957 had allowed vegetation to close a former channel bifurcation at about the half of the reach the flood spike fig 11b caused modification of the in channel bar pattern removal of sparse vegetation on low lying bars in the lower part of the reach due to morphological reworking and generalised channel widening due to the erosion of its vegetated margins at the expense of banks and islands however the flow was not intense enough to reactivate the right branch of the former bifurcation located at the domain half at the flood peak this right branch was flowing but not undergoing any significant morphological change due to the stabilising effect of vegetation and hence vegetation could not be removed there instead the flood induced widening of the left branch with increased flow conveyance in the left branch the river was further induced to assume a single thread configuration the changes produced by the flood spike vegetation removal channel widening are visible in fig 11c where the post flood channel is shown and compared with contours of the pre flood channel notably most of vegetation removal from the pre flood configuration happened due to bank collapse and erosion from channel banks that were not submerged even at the flood peak fig 11b this suggests that the introduction of vegetation removal driven by bank erosion in the present vegetation model implementation see section 2 1 3 was critical to modelling braided channel dynamics conversely vegetation removal due to in channel morphological change was limited to a few areas such as the sparsely vegetated bars in the lower part of the domain that were submerged during the flood spike this flood spike despite lasting for 6 months and having quite significant peak discharges while inducing channel widening and vegetation removal from retreating banks and islands could not reset the channel configuration and revert it to an unvegetated condition this behaviour is realistic for the lower waitaki river as it is consistent with the field observations of hicks et al 2003 who noted that even a much bigger flood in 1995 peak discharge of 2700 m 3 s 1 had only a moderate vegetation removal effect and could not reset the channel 5 2 3 reproduction of observed changes in vegetation presence fig 12a shows the time series of reach averaged vegetation density fraction starting from a bare channel in 1936 the river develops a vegetation cover that grows almost linearly in time until 1957 reaching an average density fraction of 0 26 small wiggles in this trend are due to removal by the floods and limited periods with steady vegetation cover can be explained as seasonal hiatuses of vegetation growth described by eq 4 the increased frequency of floods from 1957 compared to the previous period see fig 7 causes a visible drop in average vegetation density fraction that stabilises at 0 24 as vegetation finds a dynamic equilibrium with this new flow regime these observations are consistent with those of channel widening accompanied by vegetation removal from the banks during the 1957 1958 flood spike fig 11 and overall constancy of vegetation presence until 1964 fig 10e f fig 12b shows the evolution of reach averaged unvegetated width see section 4 4 1 two distinct model series are presented obtained with threshold b t 0 2 and b t 0 3 for identifying unvegetated areas respectively these are compared width data for 1936 and 1964 measured from historic photos hicks et al 2003 starting in 1936 from a value equal to 1560 m i e the total domain width minus the width of the two lateral vegetated buffers model series show a decline in unvegetated width after just a few years this decline is visible slightly earlier in the curve with b t 0 2 than in the time series with b t 0 3 and for both continues until 1957 reaching the minimum value of 800 m or 1000 m respectively eventually due to the increased frequency of floods fig 7 that caused erosion of vegetation banks fig 11 and decline in averaged vegetation density fraction fig 12a the unvegetated width increases sharply finally in the early 1960s settling on the quasi constant values of 950 m or 1050 m for the two series with both thresholds model results replicate reasonably well the unvegetated with reduction seen in the historic data of hicks et al 2003 the final historic width of 997 m in 1964 is within 50 m from the values of 1050 m and 950 in the two model series therefore with both b t settings the model shows capable of reproducing observed vegetation encroachment yielding a reasonably good agreement this reasonably good match shows quantitatively that the developed modelling tools and techniques can capture some salient features of the observed vegetation encroachment process and its interaction with the morphodynamics 5 2 4 changes in braiding intensity in fig 13 we analyse the change in braiding intensity from the braiding index computed with four reference discharges 1 2 q m 4 q m section 4 4 2 braiding intensity shows an overall declining trend for each reference discharge which is consistent with the observations in hicks et al 2003 and hicks 2006 a strong decline is evident until the mid to late 1950s after which the braiding index increases a behaviour somewhat associated with the clearing done by the spike of floods from 1957 see section 5 2 2 however the braiding index at the end of the simulation generally has values smaller than at the beginning for discharges from 1 2 q m to 2 q m the braiding index is generally an increasing function of discharge throughout most of the study period however this behaviour changes for the braiding index associated with the highest discharge 4 q m depending on the year considered the braiding index of 4 q m can be the highest in the set e g in 1038 1939 and 1958 1960 or the smallest in the set 1948 1954 or have intermediate values that the braiding index for a given channel morphology can be both an increasing and a decreasing function of the discharge depending on the considered discharge range has been reported elsewhere in the literature see e g welber et al 2012 this is because with the discharge increasing from small values the number of wetted channel initially increases but beyond a certain discharge some channels will merge into one as overbank flows develop and during large floods lateral confinement can corral the flow in a single wide channel temporal changes in the discharge value associated with the maximum braiding intensity reflect changes in the reach morphology and vegetation distribution in fig 13 when the braiding index of 4 q m drops below the value associated with the smaller discharges 1948 1954 this reflects flow confinement due to vegetation spread on channel banks which happens progressively from the start of the simulation see topographies in figs 4a c eventually the braiding index of 4 q m shows a sharp increase between 1957 and 1960 the latter change is related to the partial reset of the channel braided character fig 11 due to the flood spike from 1957 fig 7b from 1958 onwards while the unvegetated width does not change significantly fig 12b the braiding index of the three smallest discharges increases sharply this happens because the braided channel in this period fig 10e f keeps being mobilised by quite frequent albeit small floods fig 7b that are not strong enough to further relieve vegetation confinement and hence to significantly affect the braiding index of 4 q m while these trends generally indicate loss of braiding qualitatively similar to the observations in hicks et al 2003 and provide insight on morphology and vegetation changes a strictly quantitative comparison with these observations exposes a model weakness the historic data for the study period are sparse but generally show higher braiding index values than those found from the numerical results for similar discharges for instance the braiding index measured from the 1936 photo was 11 6 for a discharge of 151 2 m 3 s 1 significantly higher than the value we obtained from model results at the similar discharge of 1 2 q m 169 m 3 s 1 fig 13 this discrepancy reflects the lack of sharpness in the braided morphology already observed in section 5 1 the reasons for which are discussed in section 6 6 discussion in this section we will discuss the limitations weaknesses and prospected developments and further applications of the present modelling framework 6 1 lack of small scale morphology role of mesh resolution and incomplete flood recessions in section 5 2 4 we observed that the model failed to accurately reproduce the braiding index values observed from historic photos while the modelled braiding index trends show a decrease in braiding that is qualitatively consistent with the historic observation the braiding index values are underestimated we related this behaviour to the lack of small scale morphological features and hence of braids in the numerical topographies which had been observed even in the initial unvegetated braided channel section 5 1 this lack of small scale morphology stems from two causes i incomplete modelling of flood recessions which in real rivers sculpt finely detailed channel features and ii the use of a relatively coarse grid average cell size of 9 2 m causing numerically generated topographies to lack sharpness compared with the real ones with braids being too wide and lacking small scale detail regarding the first issue we observe that although the simulation with evolving vegetation applied an unsteady flow regime unlike the preliminary simulation for braided channel formation where a constant discharge was applied flood recessions were truncated by the hydrograph splitting technique however this strategy was critical to computational feasibility since direct application of the morphodynamics and vegetation model to the entire time series would have produced a 6 fold increase in simulation time in regard of the second issue we note that the impact of mesh size on the resolution of morphological features has been observed elsewhere for instance schuurman and kleinhans 2011 showed that while large scale bar pattern statistics are independent of grid size the shape of bars improves when a finer grid is used to increase model realism these limitations should be mitigated by using finer meshes and lowering the hydrograph splitting discharge threshold this however would require a significant computational performance improvement to still retain practical run times and we leave it for future work 6 2 incomplete parameter calibration quantitative validation of the model results in this work is limited to observing that the model can accurately match recorded trends in vegetated width section 5 2 3 this is a reflection of the relative paucity of quantitative historic observations achieving this match with historic data required a sensitivity analysis of model parameters that we have not detailed here for the sake of brevity however the essence of the analysis involved the following firstly we varied the critical bank height of bare gravel δ b c g during the initial unvegetated channel formation we observed that with a smaller critical bank height e g δ b c g 0 75 m the braided morphology would have been even more diffuse but would have produced a network subject to a faster evolution due to the lateral shift of channels as we did not possess information on the speed of lateral reworking to calibrate the model to we opted for a higher δ b c value to increase sharpness of the morphology conversely we did not calibrate the parameters of the sediment transport formula but rather stayed with the classical values of the relation of meyer peter and müller 1948 this is because we did not possess detailed sediment transport data for this kind of calibration we devoted more attention to calibrating the vegetation parameters for which we could not find literature values see section 4 2 6 2 we tested a few equilibrium density fraction curves varying the parameters λ 1 λ 2 and z v 0 in eq 14 we found that using a more aggressive vegetation type more capable of establishing at low elevations on the bars and to interact with the flow would have sped up vegetation encroachment furthermore we tested models with a reduced adaptation timescale t v obtaining faster encroachment which still converged to similar unvegetated width reduction values we finally adopted the parameter set that described the least aggressive slowest growing vegetation that was still capable of producing an unvegetated width reduction that compared well with the historic data this limited model sensitivity to changes of parameters indicates that the lower waitaki was naturally prone to vegetation encroachment once european vegetation was introduced this is because even prior to the introduction of exotic vegetation the river barely possessed the energy needed to braid due to its naturally damped flow regime below the three headwater lakes stecca et al 2019 hence model wise the observed vegetation encroachment can be achieved by adopting a wide range of vegetation parameter values more modelling work focussed on other rivers is needed to show that the model can also reproduce different vegetation trajectories and better validate the current parameter choice 6 3 unisize sediment approximation the present model features a unisize sediment approximation this simplifying assumption may be admissible when modelling rivers that do not show generalised bed degradation as the coastal reach of the lower waitaki conversely a mixed sediment model formulation is mandatory when modelling river reaches subject to generalised bed degradation as in these reaches the dynamics of sediment transport is critically influenced by bed armouring our choice was further motivated by considerations over the feasibility of the present computational exercise as neglecting the additional continuity equations that would have been needed for mixed sediment helped us to achieve reasonable run times which was critical for our decadal simulations furthermore the inaccuracy introduced with this choice does not seem decisive when compared with all the other sources of inaccuracy lack of small scale morphology simplified rendering of vegetation processes incomplete assessment of parameter choice that affected the modelled sediment dynamics the consequences of a unisize sediment approximation while simulating braiding dynamics are not fully understood the only modelling study to date on this topic is due to singh et al 2017 who found that larger sediment heterogeneity produces higher braiding indices they did not completely rule out the use of unisize models arguing that they may be adequate under full sediment mobility i e larger floods but not under partial mobility moving to vegetated braided rivers the model of nicholas 2013 and nicholas et al 2013 2016 developed for sand bed rivers features mixed sediment but limits complexity of the formulation by adopting only two fractions sand and silt as silt deposition is a key component of floodplain development for these rivers this is still too simple a mixture to enable armour development while the debate on the importance of modelling mixed size sediment transport is ongoing we remark that the most commonly used mathematical representation of mixed size sediment the active layer model hirano 1971 1972 produces models that are mathematically ill posed for some parameter values chavarrías et al 2018 2019c this issue is severe under some common cases such as bed degradation into a finer substrate stecca et al 2014 which would defy the purpose of adopting mixed sediment models even in degradational reaches research to produce unconditionally well posed formulations of the problem is in progress chavarrías et al 2019b chavarrías et al 2019a 6 4 initial data availability and impossibility of exact long term predictions the initial data needed for a vegetation and morphology simulation is a braided topography and a map of vegetation density fraction over that topography for the applications of this paper we assumed the initial channel to be unvegetated except for the lateral buffers and we let the model determine an equilibrium unvegetated morphology with a preliminary steady flow simulation this approach was convenient for our case since we did not possess a detailed 2d bed topography of the 1936 channel it also suited the overall purpose of our modelling i e to develop a realistic analogue of the real world river that would show similar vegetation dynamics and morphological trajectories there is no barrier preventing the user of the model from initiating a model with a surveyed channel morphology if this is available in the attempt to track the exact evolution of channel configurations even doing so however as we have shown in recent research stecca and hicks 2022 channel configurations can be predicted in exact terms only for a very short period e g a few floods owing to the deterministic chaos nature of braiding morphodynamics the issue is with the sensitive dependence on the initial conditions shown by braiding which makes any simulation even carried out with a perfectly accurate model diverge from the real prototype if the initial topography is known ever so slightly inaccurately as happens in practice therefore the unavailability of a surveyed topography to initiate the model is not an issue because the modelled configuration would have rapidly diverged from the real configuration anyway 6 5 discharge record availability the model requires a discharge time series for the upstream boundary condition unlike modelling studies in unvegetated settings for which knowledge of only a dominant or formative discharge may be sufficient for conducting at least preliminary simulations modelling vegetated rivers requires an unsteady discharge record that comprises both low flow periods when vegetation establishes and floods when vegetation is scoured furthermore the discharge record must be time accurate enough to capture the flow variability depending on the hydrological character of the river at hand for our hindcasting application we simply used a recorded hydrograph with daily averaged values which suits well the damped hydrology of the lower waitaki since this dataset was directly available however for most applications this approach may not be viable either because a reliable and sufficiently refined discharge record is not available or because the applications are aimed at forecasting future evolution or because the modelled reach is idealised and the applications are theoretical in this case a hydrograph of some form must be assumed the easiest choice which well suits modelling for theoretical purposes is to generate a synthetic flow regime from a few control parameters e g the shape of the flood hydrograph the magnitude of its peak and the low flow duration see bertoldi et al 2014 nicholas et al 2016 to study the sensitivity of the river morphology to changes in these hydrological parameters another more realistic approach suited to hindcasting is to generate a flow record from precipitation data using a hydrological model for the lower waitaki a potential application of this approach is to use the natural reconstructed flow regime i e the discharge series that would have been recorded in the absence of dams henderson 2020 to tease apart the role of dam operation on observed vegetation spread when the modelling exercise aims to forecast future evolution however a modeller needs to make assumptions over the future flow regime the most straightforward scenario follows the assumption that the hydrology is stationary and hence that an available flow record can be projected unaltered into the future otherwise different hydrographs could be adopted depending on assumed changes in the river s hydrology 6 6 potential for further applications despite the limitations of the present modelling framework highlighted in this section the model has been shown capable of closely reproducing observed historical vegetation encroachment in the lower waitaki the model therefore has potential applications in understanding the relative role of flow regime changes and of vegetation introduction on braided morphology evolution and to inform on management questions regarding vegetation control and hydropower management ongoing and future work includes i the application to other new zealand rivers to demonstrate the model capability to reproduce different morphological and vegetation evolution trajectories ii model applications to the lower waitaki with the natural reconstructed flow regime henderson 2020 to understand the role of damming on vegetation spread iii the implementation of rules to simulate the artificial vegetation management scheme in place in the waitaki from 1960 onwards and iv use of the model to understand future trajectories according to different management scenarios 7 conclusions in this work we constructed a two dimensional numerical model framework for reproducing vegetation driven morphological change in braided rivers and we applied it to the test case given by vegetation encroachment in the coastal reach of the lower waitaki river new zealand between 1936 and 1964 salient features of the mathematical model are a bank erosion model that extends to the present two dimensional framework the critical bank height approach that we developed in previous work in one space dimension and a vegetation model that drives vegetation density change and features relations that express the feedback of vegetation density on the hydro morphodynamics we devised an approximate solution strategy named hydrograph splitting capable of providing practical run times for the decadal scale simulations needed to appreciate vegetation driven morphological changes in braided reaches this technique involves solving the full flow morphology and vegetation problem only during floods when morphological change drives vegetation removal and the interaction between flow morphology and vegetation happens over short time scales and in only updating vegetation with a static bed and inundation pattern during low flow periods the braided river numerical modelling framework developed in this study proved capable of reproducing unvegetated channel width trends that compare well with the historic data available use of the model allows a deeper understanding of the flow vegetation morphology interactions that occurred in the lower waitaki which was not discernible in the sparse historic data the analysis of morphological changes during the 6 months duration spike of floods in 1957 1958 shows that even repeated floods of significant magnitude while inducing channel widening and vegetation removal from retreating banks and islands could not reset the channel configuration and revert it to an unvegetated condition the analysis of trends in braiding intensity shows that the model qualitatively reproduced the loss of braiding character that was observed between 1936 and the 1950s and the partial recovery following increased frequency and magnitude of floods from 1957 onwards however the present application also exposes model weaknesses mainly that the numeric values of braiding index are underestimated with respect to the sparse observations available the cause of this model weakness is the lack of fine scale morphology due to both mesh coarseness and the incomplete rendering of flood recessions due to the hydrograph splitting strategy however both these approximations were key to containing run times and could be relaxed only by a critical increase in the model s computational performance these approximations together with the simplifications in the model formulation essentially the adoption of a unisize sediment continuity framework and the incomplete assessment of the bank erosion and vegetation parameters deserve further investigation in future work due to its ability to match observed vegetation encroachment and explain long term evolutionary trajectories and despite its inevitable limitations and approximations the model has potential applications to understand the relationship between flow vegetation and morphology in other rivers and to support management decisions ongoing work includes the application to other new zealand rivers to demonstrate the model capability to reproduce different morphological trajectories the implementation of rules to simulate the artificial vegetation management scheme in place in the lower waitaki from 1960 onwards and use of the model to understand future trajectories according to different management scenarios in the lower waitaki credit authorship contribution statement guglielmo stecca conceptualization methodology software investigation resources writing original draft writing review editing visualisation supervision project administration funding acquisition davide fedrizzi methodology software investigation resources visualisation richard measures writing review editing methodology software d murray hicks project administration funding acquisition supervision writing review editing jo hoyle project administration funding acquisition writing review editing guido zolezzi project administration funding acquisition supervision writing original draft resources declaration of competing interest one or more of the authors of this paper have disclosed potential or pertinent conflicts of interest which may include receipt of payment either direct or indirect institutional support or association with an entity in the biomedical field which may be perceived to have potential conflict of interest with this work for full disclosure statements refer to https doi org 10 1016 j advwatres 2022 104236 guglielmo stecca reports financial support was provided by meridian energy ltd guglielmo stecca reports financial support was provided by european commission seventh framework programme for research and technological development davide fedrizzi reports financial support was provided by european commission seventh framework programme for research and technological development richard measures reports financial support was provided by meridian energy ltd jo hoyle reports financial support was provided by meridian energy ltd murray hicks reports financial support was provided by meridian energy ltd acknowledgements this project has received funding from the european union s seventh framework programme for research technological development and demonstration under marie curie international outgoing fellowship no 2013 621886 2015 2018 meridian energy ltd new zealand under niwa project mel20534 2020 2021 niwa new zealand core funding under the environmental flows programme eflows 2020 2021 the university of trento italy under student mobility funds fondo ricerca tesi fund for thesis reseach 2017 2018 stecca s activity was initially funded by the marie curie fellowship and eventually by the meridian project and eflows programme fedrizzi s visit to niwa christchurch for his m sc thesis work was supported by marie curie funds and by the student mobility funds of the university of trento fedrizzi s post graduate grant was covered by marie curie funds the involvement of measures hoyle and hicks was covered by the eflows programme and meridian project initial numerical simulations were run on the university of trento high performance computing facility the final numerical simulations were run on the high performance computing facility mahuika of the new zealand escience infrastructure nesi https www nesi org nz and their cost was covered by the merdian project we thank j zais niwa and a shaw nesi for helping us set up and manage this simulation project 
113,in this paper we develop a two dimensional modelling framework suitable to study the morphological evolution of vegetated braided rivers the mathematical model features a unisize sediment morphological model which includes accounting for bank erosion and a vegetation model while these model components had already appeared separately in different contexts here we improve and tailor them for modelling vegetated braided river dynamics we implement a numerical solution to this problem in the framework of the pre existing morphological model giamt2d we devise a hydrograph splitting technique to avoid excessive run times in the multi decadal applications needed to appreciate vegetation driven morphological change this hydrograph splitting technique uses the full model to solve for flood periods while applying a fixed bed approximation and only updating vegetation density during low flow periods finally we apply the developed formulation tools and techniques to simulate an idealised reach of the lower waitaki river aotearoa new zealand where we reproduce vegetation encroachment and morphological change observed between 1936 and 1964 keywords numerical modelling braided rivers morphodynamics vegetation transitional rivers bank erosion 1 introduction 1 1 background and objective river braiding i e the spreading of river channels into multiple threads characterised by an active rapidly evolving morphology ashmore 1991 happens in pro glacial mountain and piedmont areas bristow and best 1993 under high energy flows and intense sediment transport with limited development of vegetation ashmore 2013 we are here concerned with gravel bed braided rivers where fluvial sediment transport occurs predominantly as bedload the presence of vegetation can interfere with the ability of rivers to braid plants acting as river engineers affect the flow field and retain sediment with their trunks branches and foliage and strengthen soils with their root systems e g gurnell 2014 while being controlled by hydrological and hydromorphological processes that affect plant settling growth and mortality gurnell et al 2012 2016 through its effects vegetation exerts a critical control on the planform of gravel bed rivers gran and paola 2001 tal et al 2004 shifting vegetation presence has been shown to be a key driver of morphological change capable of inducing originally braided rivers to transition towards single thread styles stecca et al 2019 this is particularly relevant in dammed rivers where the modified hydrological regime can favour vegetation spread petts and gurnell 2005 in europe with a few notable exceptions rivers lost braided character due to multiple anthropogenic stressors in the last 150 years e g stecca et al 2019 to the extent that braided channel patterns have become rare tockner et al 2003 schiemer et al 2020 hohensinner et al 2021 as braided rivers create diverse landscapes with unique ecological values tockner et al 2006 loss of braiding has ecological and environmental implications that are becoming increasingly considered by scientists and managers piégay et al 2006 le lay et al 2013 in aotearoa new zealand rivers have generally been exposed to less intense pressure than in europe and the country has many braided rivers wilson 2001 hicks et al 2021 with unique ecosystems gray and harding 2007 gray et al 2016 however encroachment of exotic non native vegetation is a particular issue this is because new zealand braided rivers host several endangered endemic species o donnell et al 2016 including birds which prefer bare gravel surfaces for nesting robertson et al 2017 maloney et al 1997 and vegetation encroachment is reducing habitat availability for these threatened species robertson et al 1983 hughey and warren 1997 also loss of these unique river landscapes causes degradation of cultural values and māori wellbeing crow et al 2020 which is associated with maintaining the health of the natural environment durie 1998 with increasing interest in forecasting the morphological response of gravel bed rivers to changes in vegetation presence and in other drivers solari et al 2016 and while river geomorphology is progressively evolving towards a more model based quantitative discipline grant 2012 stecca et al 2019 a compelling objective is to construct and operate physics based numerical modelling tools that can predict planform changes due to changes in vegetation presence this is the objective of this paper 1 2 numerical modelling of vegetated braided rivers morphological modelling of braided rivers has been attempted for decades with progressively increasing complexity and realism following two alternative approaches reduced complexity models which route flow and sediment without solving for the full momentum balance were first popular for their reduced computational cost starting from the pioneering work of murray and paola 2003 this modelling approach has been widely used to study the long term impact of vegetation on morphology e g coulthard et al 2007 ziliani et al 2013 ziliani and surian 2016 ziliani et al 2020 the alternative physics based modelling approach solving the full momentum balance and sediment continuity has been initially daunting due to its high computational cost often resulting in impractical run times the main reasons are the inherently two dimensional nature of flow fields which mandates a two occasionally three dimensional model formulation the need to resolve morphology at sufficiently fine scales to observe the interplay between the development of in channel features and planform shape while covering computational domains wide enough to contain braided reaches and when vegetation is considered the need to run models over multi decadal time scales to appreciate the impact of vegetation on morphology in recent years however with increasing availability of computing power physics based modelling of braiding river morphodynamics has gained popularity schuurman et al 2013 nicholas 2013 nicholas et al 2013 schuurman and kleinhans 2015 yang et al 2015 sun et al 2015 nicholas et al 2016 schuurman et al 2016 williams et al 2016 singh et al 2017 schuurman et al 2018 yang et al 2018 yang 2020 olsen 2021 yet models of this class that feature vegetation are few and generally apply rule based approaches to render vegetation morphology interactions li and millar 2011 crosato and saleh 2011 nicholas 2013 without explicitly accounting for vegetation growth and mortality in detail nicholas 2013 and nicholas et al 2013 2016 provide the only such application to date to fully developed multi thread channel patterns over timescales of a few centuries with a model accounting for vegetation related flow drag and parameterising changes in vegetation presence using threshold submerged time and threshold velocity rules none of these models however has been validated by closely reproducing the evolutionary trajectory observed in a real world test case more refined renderings of vegetation morphodynamics interactions were put forward in models for single thread river applications bertoldi et al 2014 van oorschot et al 2016 jourdain et al 2020 amongst them bertoldi et al 2014 undertook the most physics based treatment to date of vegetation morphology feedbacks while modelling a straight channel with alternate bars 1 3 approach in this paper we develop a two dimensional numerical model framework suitable for studying vegetation driven morphological change in braided rivers which uses one of the most physics based formulations available and we validate the framework by applying it to the test case given by vegetation encroachment and morphological change observed in the coastal reach of the lower waitaki river new zealand between 1936 and 1964 the model will prove capable of matching the reduction in unvegetated width seen in the historic field data reported in hicks et al 2003 our modelling framework features innovations in the mathematical formulation in the solution strategy and the computational tools salient features of the formulation are i a bank erosion model that generalises in 2d the critical bank height approach that we developed in previous work in 1d stecca et al 2017 and ii a vegetation model for the braided river cases developed off an earlier formulation for single thread channels bertoldi et al 2014 one key improvement with respect to the latter work critical to modelling braided rivers is that we account for the feedback of vegetation presence on the stability of banks the solution strategy puts forward a hydrograph splitting technique that mitigates the problem of long run times needed for decadal scale applications and hence is key to the feasibility of our simulations this hydrograph splitting technique only uses the full flow morphology and vegetation model for flood periods while a much faster solution which only evolves vegetation with a fixed bed and steady flow approximation is used during low flow periods to implement the hydrograph splitting technique we develop an integrated set of computational tools that features a full vegetation and morphology solver named giamt2d veg and a stand alone vegetation evolution model save the bed of the lower waitaki river which in the 1930s was composed of bare sediment became heavily vegetated within just a few decades after the introduction of exotic woody vegetation including gorse broom and willows while the lower waitaki features a naturally damped flow regime due to the presence of three natural headwater lakes hicks et al 2007 the flow regime has been progressively further damped by hydropower development since the 1930s with the construction and operation of dams and control structures on the natural lakes hicks et al 2006 this artificial flow damping likely favoured vegetation encroachment with our simulation we show that the model can reproduce decreasing trends in unvegetated river width and braiding intensity as measured from historic photos of the lower waitaki in previous work hicks et al 2003 hicks 2006 the paper is organised as follows in section 2 we present the mathematical model in section 3 we describe the numerical solution strategy and tools in section 4 we introduce the test case and the model setup needed to reproduce it and in section 5 we present our results finally the strengths limitations and potential for further development of this work are discussed in section 6 conclusions are presented in section 7 2 mathematical model in this section we describe the mathematical model used to describe the morphological evolution of vegetated gravel bed braided rivers the model comprises a set of governing equations section 2 1 and appropriate closure relations section 2 2 2 1 governing equations the model governing equations feature a hydrodynamic model a sediment continuity model for morphological evolution and a vegetation evolution model 2 1 1 hydrodynamic model as commonly done when modelling flow in braided rivers the hydrodynamic model uses a two dimensional x y depth averaged shallow flow formulation commonly referred to as the saint venant equations i e 1 h t u h t v h t 0 u h t x 1 2 g h 2 u 2 h u v h y g h b x g h s f x v h t u v h x y 1 2 g h 2 v 2 h g h b y g h s f y where x and y m are the two planimetric coordinates t s is time h m is the flow depth u and v ms 1 are the depth averaged flow velocities in the x and y directions respectively g 9 81 ms 2 is the acceleration due to gravity b m is the bed elevation and s f x and s f y are the friction slopes in the x and y directions 2 1 2 morphological model the morphological model uses the simplifying assumption that the bed sediment comprises only one size unisize sediment approximation this assumption is sufficiently accurate when modelling river beds that are not significantly degrading as happens for the modelled reach of the waitaki river in this work while significantly reducing the computational load compared with mixed sediment models which is key for the present application with unisize sediment the model consists of one two dimensional mass continuity equation 2 1 p b t q b x x q b y y d if x y bank toe e if bank top 0 otherwise here p is the bed porosity assumed as constant and equal to 0 4 q b x and q b y m 2 s 1 are the sediment discharges per unit width in the x and y directions respectively and d and e ms 1 are the deposition and erosion rates at the bank top and bank toe eq 2 is a variation of the standard two dimensional exner model see e g siviglia et al 2013 where the right hand side of the equation has been modified to include a bank erosion model by considering three distinct cases pertaining to the bank toe bank top or elsewhere e g channel beds as done by stecca et al 2017 in 1d notably this formulation resembles a non capacity model of bankside transport the algorithm for the spatial identification of the bank top and toe will be presented in section 3 2 1 3 2 1 3 vegetation model to predict the evolution of vegetation density in space and time we adopt the vegetation model put forward by bertoldi et al 2014 for single thread channels but with a few key enhancements and modifications that make it suitable for simulating vegetated braided rivers following their approach vegetation presence is described by a variable b t x y that indicates the ratio of actual areal stem density to the maximum admissible areal stem density for the considered vegetation species hereinafter we will call this variable vegetation density fraction admissible values for b are between 0 and 1 the former associated with bare sediment the latter with a fully developed vegetation cover notably the same value of b could indicate a different dimensional density of vegetation depending on the considered vegetation type and hence a different intensity of the hydro morphodynamic effects of vegetation furthermore an equilibrium vegetation density fraction variable b e q h b is introduced b e q represents the density fraction value that would be achieved at a location after infinite time in the absence of bed elevation or flow depth changes or of vegetation removal events and will be specified by a closure relation in section 2 2 4 unlike in bertoldi et al 2014 here we account for the seasonality of vegetation growth during the growing season represented in the model as the period from september 1 to april 30 vegetation density can both increase and decay trending towards the equilibrium value following the relation 3 d b d t 3 t v b b e q were t v is the time scale of vegetation adaptation during the winter from may 1 to august 31 vegetation density is not allowed to increase due to dormancy but only to decay if the equilibrium density fraction is smaller than the actual density fraction which yields the relation 4 d b d t 3 t v b b e q if b b e q 0 otherwise further to this framework for slow adaptation two simplified mechanisms of abrupt vegetation removal are considered removal happens due to morphological evolution of the bed as plants are removed due to either sediment transport within a channel or collapse of an eroding bank the latter mechanism has been introduced specifically for this study the model sets the vegetation density fraction to zero for the next time step at all locations where either the shields stress exceeds the critical value for the onset of sediment transport θ c or accumulated erosion in that cell exceeds a preset threshold δ b t as will be described later with eq 11 the critical shields stress θ c will be assumed as an increasing function of the vegetation density fraction this allows the model to account in a simplified manner for denser vegetation being harder to remove 2 2 closure relations closure relations are needed to evaluate the friction slope terms s f x s f y in the saint venant equations 1 and the sediment fluxes q b x q b y and the deposition and erosion terms d e associated with bank erosion in the exner type equation 2 these relations include a dependence on the local vegetation density fraction unlike analogous relations adopted in models for unvegetated rivers furthermore the relation yielding the equilibrium vegetation density fraction b e q to be used in eqs 3 and 4 will be presented 2 2 1 flow resistance the friction slope terms in the saint venant equations 1 are evaluated using a chézy type law namely 5 s f x u u 2 v 2 c 2 h s f y v u 2 v 2 c 2 h where c m 1 2 s 1 is the chézy coefficient the latter is obtained by combining a chézy coefficient associated with bare gravel c g and a chézy coefficient associated with fully developed vegetation c v using the vegetation density fraction b as a weight namely 6 c 2 c g 2 b c v 2 eq 6 can be derived by adding the shear stress contributions exerted on the flow by gravel and vegetation as done in previous work in the waitaki river by aberle et al 2003 in eq 6 the chézy coefficient of bare gravel is specified with the classical relation of keulegan 1938 as a logarithmic function of depth 7 c g 6 2 5 ln h k s g where k s m is the bed roughness height the chézy coefficient of fully developed vegetation is evaluated using the approach of lindner 1982 8 c v 2 c w 2 g d p h a x a y where c w is a calibration coefficient in the range 1 3 d p m is the plant diameter and a x and a y m denote spacing between plants along the x and y directions at maximum vegetation density the present approach improves the approach of bertoldi et al 2014 who used instead a manning type friction relation with the inverse of the manning coefficient obtained by a weighted average of the inverse of two constant manning coefficients for bare gravel and fully developed vegetation respectively here eqs 7 and 8 account for the different dependence of gravel and vegetation related friction on depth in bare gravel areas the logarithmic law 7 is preferable to the manning approach ferguson 2010 and in vegetated areas eq 8 allows one to relate friction to measurable properties of the tree cover 2 2 2 sediment transport the sediment fluxes q b x and q b y to be used in the exner type equation 2 are modelled using the classical meyer peter and müller relation meyer peter and müller 1948 extended to a two dimensional setting and modified to account for vegetation presence the intensity of bedload denoted with q b m 2 s 1 is given by 9 q b 8 g s 1 d s 3 max θ θ c 0 3 2 where d s m is the sediment diameter representative of transported sediment having adopted the unisize sediment approximation s ρ s ρ w is the ratio between the sediment density ρ s 2650 kg m 3 and the water density ρ w 1000 kg m 3 θ is the shields stress exerted by the flow over the bed sediment 10 θ u 2 v 2 c g 2 s 1 d s and θ c is the critical shields stress value evaluated as 11 θ c 1 b θ c g b θ c v where θ c g and θ c v assumed as constants and assigned as input parameters see section 4 2 6 are the critical shields stress associated with bare gravel and with fully developed vegetation respectively with the constraint θ c v θ c g once the bedload intensity q b has been calculated using eq 9 the two components q b x and q b y must be evaluated to do so sediment transport is essentially projected in the direction given by the local flow velocity but with a deviation that accounts for the role of secondary currents in the cross sectional plane following the approach of engelund 1974 as in sun et al 2015 and the gravity deflection driven by the bed slope orthogonal to the flow following the approach of ikeda 1982 as in siviglia et al 2013 to this end we define with p n an orthogonal reference system where p and n are the unit vectors parallel and normal to the local flow respectively and n takes positive values in the direction given by a 90 anticlockwise rotation from p see fig 1 we specify the bedload transport vector in this reference system by defining the two components q b p and q b n that are aligned with p and n respectively the ratio between q b n and q p b is given by 12 q b n q b p n h r r θ b n on the right hand side of eq 12 the first term accounts for the effect of secondary currents n being a dimensionless parameter that indicates the secondary current strength having typical value of 7 sun et al 2015 and r being the curvature radius of the local streamline taken as positive when the streamline rotates in the counter clockwise direction the second term accounts for the gravity deflection r being a dimensionless parameter in the range 0 3 0 6 that indicates the strength of the deflection and b n the bed gradient in the direction normal to the flow once q b p and q b n have been calculated their projection onto the x y reference system yields q b x and q b y 2 2 3 bank erosion following stecca et al 2017 the purpose of any bank erosion sub model is to identify the top and toes of eroding banks compute for each top an erosional mass exchange rate e and for each toe a depositional rate d and to feed these contributions into the sediment mass conservation equation 2 bank erosion models are available at different degrees of complexity stecca et al 2017 here we use a simple approach suitable for non cohesive soils since comparable approaches have been successfully applied for modelling braided river dynamics e g nicholas 2013 sun et al 2015 we extend to the present two dimensional framework the critical bank height approach in stecca et al 2017 and we adapt it to account for vegetation presence the critical bank height approach is similar to the widely used critical slope approach but has some advantages critical slope in morphological modelling is a mesh size dependent calibration parameter with little physical basis on coarse meshes its value must be set unphysically small to compensate for the underestimation of bed slopes and still produce reasonable bank erosion the alternative being the use of very refined grids e g having size comparable to the flow depth which is often unaffordable computationally conversely as shown by stecca et al 2017 with the application of a 1d cross sectional model critical bank height is almost mesh size independent and can be more confidently set based on field observations mesh size independence is also an advantage when working with irregular grids as happens with curvilinear or as in the present case triangular grids since it helps preserving spatial homogeneity of bank erodibility throughout the model domain the model works as follows eroding banks are located where the difference between the bed elevation in two neighbouring cells is greater than a preset critical bank height δ b c m detail on our particular implementation on triangular meshes to identify for each erosion event the bank top and toe cells is given later in section 3 2 1 the effect of vegetation presence on bank erosion is incorporated as previously done for the critical shields stress 11 two separate values of critical bank height are defined one for bare gravel banks δ b c g and one for fully vegetated banks δ b c v the local critical bank height is 13 δ b c 1 b δ b c g b δ b c v and the constraint δ b c v δ b c g guarantees that a vegetated bank is more stable than a bare one bank collapse induces a sediment flux between the bank top and bank toe q b e ms 2 in our formulation we keep q b e constant for whenever δ b c is exceeded and assign it as an input finally the mass exchange contributions e and d having magnitude that matches q b e are computed see section 3 2 1 2 2 4 equilibrium vegetation density following bertoldi et al 2014 and references therein the equilibrium vegetation density fraction b e q to be used in eqs 3 4 is specified as a bell shaped function of the bed elevation the underlying assumption is that there exists an optimal range of river bar and bank relief values for supporting vegetation presence due to optimal availability of moisture for tree roots we introduce a correction to their relation so as to prescribe zero equilibrium density fraction in significantly wetted channels where plants cannot establish as seeds and dead wood cannot settle on the ground this correction proved key for model applicability to the complex morphology of braided rivers as it prevents permanently flowing channels from developing vegetation with these settings b e q is given by 14 b e q b e q 0 exp λ 1 b z v exp λ 2 b z v if h h t 0 otherwise where λ 1 and λ 2 m 1 are two parameters defining the bell shape z v m specifies the vertical offset of the curve h t m is the depth threshold used to identify significantly wetted areas b bed level and h depth have been introduced previously and b e q 0 is a constant coefficient that normalises the curve maximum to 1 equal to 15 b e q 0 λ 1 λ 2 λ 2 λ 1 λ 2 λ 2 λ 1 λ 1 λ 1 λ 2 in eq 14 we prescribe z v as unchanging in time but varying spatially in detail z v is given by the sum of a constant offset value z v 0 with the elevation given by the reference plane b 0 x sloping along the streamwise direction x that represents the initial morphology of simulations the equilibrium vegetation density fraction function used in the applications of this paper is shown in fig 2 3 solution in this section we present our strategy and tools for solving for braided river morphology and vegetation evolution 3 1 hydrograph splitting technique while designing the present solution strategy the key issue has been striking the balance between accuracy and computational effort simulating the morphological evolution of vegetated braided rivers is computationally challenging as it requires model application to multi decadal flow series over reaches that are several kilometres long and 1 2 km wide with a spatial resolution sufficient to resolve braiding dynamics ideally of the order of 1 m therefore direct numerical solution of the full problem 1 4 for realistic cases would have resulted in impracticable run times to mitigate the problem we developed an approximate solution strategy that we name hydrograph splitting technique with this strategy we solve the full problem only during flood periods while during low flow periods we only update vegetation density assuming that the bed topography is unchanging the logic behind this approximation is as follows during floods changes in the flow morphology and vegetation distribution occur simultaneously and interact with each other over short time scales which mandates the use of an integrated solution conversely during low flow periods morphological modification of the braided channel and associated vegetation removal are negligible and it is possible to only solve for vegetation adaptation for a small fraction of the computational effort than if the complete model was employed notably the hydrograph splitting technique can be applied to raw discharge records that may have different sources the options available to modellers to source an initial discharge record are discussed in section 6 5 3 2 model framework implementation of the hydrograph splitting technique required the development of a suitable model framework the primary tool to solve the full flow morphology and vegetation evolution problem is the numerical model giamt2d veg section 3 2 1 for evolving vegetation during low flow periods we implemented the stand alone vegetation evolution model save see section 3 2 2 to identify floods and low flow periods within the input hydrograph we developed a hydrograph splitting tool section 3 2 3 finally a master program was implemented to mange the calls to each of these tools 3 2 1 giamt2d veg a 2d morphology and vegetation evolution model the giamt2d veg model built upon the framework of the pre existing giamt2d model stecca 2012 siviglia et al 2013 solves the system of governing equations for river flow 1 morphology 2 and vegetation evolution 3 4 3 2 1 1 numerics giamt2d veg essentially retains the numerical structure of giamt2d i e a coupled solution that allows the model to stably address morphological evolution under trans and super critical flows which may be useful for steep riffles and the use of unstructured triangular meshes time stepping is explicit and adaptive with time step duration dictated by the stability of the hydro morphodynamic solution we refer the reader to stecca 2012 and siviglia et al 2013 for a full description of the model numerics 3 2 1 2 novel features key new features with respect to giamt2d are reconstruction of the morphological effect of secondary currents in eq 12 the bank erosion model section 2 2 3 added using a time splitting procedure after a solution without bank erosion has been achieved closure relations for flow resistance 5 critical shear stress 11 and critical bank height 13 that account for vegetation presence and the vegetation evolution model which solves eqs 3 and 4 with closure relation 14 and applies the abrupt removal mechanisms described in section 2 1 3 as needed the solution to eqs 3 and 4 for vegetation evolution obtained under the assumption of steady bed level and flow during each time step is analytical and hence unconditionally stable under any time step however the time step applied here matches the overall model time step which is restricted by the stability condition of the hydro morphodynamic solution 3 2 1 3 bank erosion implementation detail consider the current triangular cell t i and its three neighbours t j across each edge l j of t i for 1 j 3 see fig 3 applying the critical bank height criterion see section 2 2 3 cell t i is identified as an eroding bank top if the condition 16 b i b j δ b c is met for at least one value of j where b i and b j are the bed elevations within t i and t j respectively and δ b c is the critical height 13 calculated with the vegetation density fraction in t i erosion of the bed in cell t i happens independently across every edge l j for which the condition 16 is satisfied a key issue for effective bank erosion modelling concerns the identification of the bank toe cell to which the depositional contribution d in eq 2 will be applied poor identification algorithms can induce spurious stalling of the erosion process if the material eroded from a bank top is simply deposited in the neighbouring cell this happens when deposition at the toe reduces the bank profile steepness to a stable angle and due to bed level increase at the toe the decrease in flow velocity and transport capacity prevent the flow from scouring the toe any further stecca et al 2017 this problem is well known and various solutions such as intermittent bank updating nicholas 2013 or the use of very refined meshes sun et al 2015 have been proposed to mitigate it our solution instead uses a stencil approach for bank toe identification see fig 3 for each edge l j of cell t i a stencil comprising all the cells that share at least one vertex with one of the two ends of l j and have centroid within the extension of the two medians of t i that contain l j is identified and stored during model initialisation as seen from fig 3 the stencil across edge l j includes by construction the neighbouring cell t j but also includes other cells for an erosion event across edge l j the toe cell t toe is adaptively identified as the cell that has the smallest bed elevation at the current time amongst the cells in the stencil adjoined to l j this approach reduces the likelihood of stalling as the eroded material is dumped into the cell of the stencil having the lowest bed elevation and not just by default into the neighbouring cell t j where the bank stability condition 16 is checked once the toe cell has been identified within the stencil the erosional contribution e i in cell t i and the depositional contribution d toe in t toe are readily computed as 17 e i q b e l j t i d toe q b e l j t toe where l j is the edge length and t i and t toe are the areas of the respective cells 3 2 1 4 model parallelisation and acceleration notwithstanding the hydrograph splitting technique computational efficiency during floods is still critical since the great majority of computing time is spent solving for floods the computational speed issue is mitigated by the capability of running in parallel on shared memory using the openmp protocol e g chapman et al 2007 this feature which giamt2d veg inherits from giamt2d makes it suited to run on a cpu node of a high performance computing machine to further improve run times in giamt2d veg we implemented morphological acceleration and used a first order accurate integration scheme morphological acceleration involves multiplying the bedload discharges and elapsed simulation time by an acceleration factor greater than one one key drawback of this approach when applied to unsteady flows is that excessive acceleration can induce spurious temporal compression damping flood waves and preventing the lower part of simulated reaches from experiencing the same morphological activity as the upper part morgan et al 2020 however with the heavy computational load of multi decadal simulations the use of morphological acceleration is unavoidable crosato and saleh 2011 nicholas 2013 to minimise the effect on results acceleration was implemented in a flow dependent fashion i e with varying acceleration factors depending on the current discharge this mainly accelerated the smaller flows of floods waves for which less morphological activity is expected while solving the major flood peaks in real time although the integration scheme of giamt2d has been extended to second order accuracy siviglia et al 2013 here we used giamt2d veg only in basic first order mode running in first order mode the model is twice as fast as it would be in second order mode which allowed us to use a more refined mesh than the one that would have been feasible with a second order solution this was critical since being able to afford the use of computational meshes refined enough that morphological features are acceptably resolved while retaining practical run times is key for capturing braided channel dynamics furthermore wet dry transitions which are frequently found moving from wetted channels to emerging bars and banks would have been solved to first order accuracy anyway siviglia et al 2013 hence the overall accuracy gain of a second order setup would have been limited 3 2 2 stand alone vegetation evolution model save the stand alone vegetation evolution model save solves eqs 3 and 4 in the relevant period of the year under the assumptions of steady flow and stable bed morphology sudden removal mechanisms section 2 1 3 are not featured as they cannot happen without morphological change with these assumptions the solution is analytical and in the absence of other model components posing a more restrictive stability condition the time step is virtually unlimited therefore save can update the vegetation distribution to the end of the low flow period with run times of just seconds using save requires prior determination of a static inundation pattern to determine the pattern of the equilibrium vegetation density fraction 14 this inundation pattern is computed with the median flow for the period with a brief spin up run of the giamt2d veg model with static vegetation and morphology 3 2 3 hydrograph splitting tool the hydrograph splitting tool is used during simulation initialisation to identify low flow periods and floods within the input hydrograph for each flood to isolate and store the corresponding portion of the hydrograph that will be used as a boundary condition for morphological computations section 3 2 1 and for each low flow period to compute and record the period s median flow that will be used to compute the inundation pattern see section 3 2 2 the hydrograph is essentially split by comparing the current discharge with a threshold discharge q t q t is a river specific input parameter that must be set equal to the discharge above which non negligible morphological modification and vegetation removal are expected correctly setting q t is critical to the trade off between accuracy and efficiency while reducing q t reduces the extent of low flow periods treated with a steady flow and morphology approximation and hence increases model accuracy this occurs at the expense of additional run time due to the increased length of flood periods furthermore the program implements several filters to optimise splitting for computational efficiency amongst them one filter identifies floods of little importance those which have peak discharge smaller than another threshold value to be set slightly greater than q t and have duration smaller than a threshold time and aggregates their time to the surrounding low flow periods merging them into a single low flow while another filter aggregates short low flow periods to the two surrounding floods and merges them into a single flood when solving for these additional flood points is deemed more efficient than initialising the flow for a low flow period 4 test case in this section we will set up the model to simulate the vegetation encroachment and consequent channel pattern change observed on aereal imagery hicks et al 2003 in the coastal reach of the lower waitaki river new zealand between 1936 and the end of 1964 this is an ideal timeframe to assess the model capability to reproduce real world observed vegetation encroachment since in 1936 the riverbed was essentially bare while by 1964 encroachment had happened we limit the exercise to 1964 because after that the implementation of an artificial vegetation control plan changed the vegetation dynamics observed in the lower waitaki introducing further changes that would require a specific model implementation to be reproduced due to the excessive computational effort of modelling the entire river length 70 km we limit our modelling to one representative reach our aim will not be to reproduce exactly the river s behaviour at any location but rather to produce a faithful analogue of the river that has similar temporal trends of vegetation cover and morphological change metrics therefore we will use an idealised rectangular domain with dimensions that are representative of one real reach and the initial unvegetated channel topography will be computed by the model with a preliminary simulation in section 4 1 we introduce the test case while in section 4 2 we describe the model setup needed to reproduce it 4 1 lower waitaki river 4 1 1 geographic and historic settings by discharge the waitaki river is the fourth largest river and the largest braided river in new zealand see fig 4 three natural headwater lakes tekapō pūkaki ōhau dominate the source of flow and provide a natural damping of the flood regime hicks et al 2007 in modern times the waitaki has been intensely used for hydropower with the construction of dams and artificial lakes control structures on natural lakes and canals collectively named the waitaki power scheme hereinafter wps which has increased the damping effect on the flow regime hydropower exploitation started in the late 1920s with the beginning of the construction of waitaki dam and electricity generation commenced in the mid 1930s we are here concerned with the lower waitaki i e the 70 km long course running from the most downstream dam waitaki dam to the coast despite the presence of the dams the lower waitaki appears to be vertically stable throughout most of its course with degradation confined to its upper reach hicks 2006 stecca et al 2019 following the introduction of exotic vegetation such as crack willow salix fragilis broom cytisus scoparius gorse ulex europaeus and other weeds the lower waitaki experienced a dramatic change in vegetation cover that severely impacted the planform shape of the river hicks 2006 before 1940 the lower waitaki riverbed was largely bare and windswept up to 2 km wide by 1950 the active bed had become increasingly congested with exotic vegetation that had established in the riverbed and on the riparian margins together with vegetation spread a tendency towards simplification of the braided configuration has been observed to the extent that the river now flows in a few main central braids and has a more stable morphology than in the past tal et al 2004 our study reach is the coastal reach hicks et al 2003 i e the 10 km long stretch from between grays road and papakaio road to the coast fig 5 the reach has a slope of 0 355 in 1936 fig 5a the reach was largely unvegetated and 1600 m wide hicks et al 2006 see fig 5a subsequently vegetation cover gradually increased and this prompted the river to simplify its braided structure see figs 5b d 4 1 2 discharge record a discharge record measured at waitaki dam daily averages is available from 1926 onwards while data at higher frequency become available more recently in this work we have simply used daily averages in principle the discharge record of the coastal reach should not only account for flows at waitaki dam but also for the inflows from tributaries that join the waitaki between waitaki dam and the upstream end of the coastal reach however we have disregarded these contributions because flows in the lower waitaki are dominated by those at waitaki dam which account for 80 of the discharge measured in the coastal reach stecca et al 2019 there is no discharge record available in the waitaki downstream of the tributaries and the discharge records of the tributaries are not available for the study period 4 2 model setup 4 2 1 domain and initial morphology the computational domain is rectangular shaped with dimensions representative of the coastal reach see fig 6 the domain is 1 6 km wide and comprises an upper 600 m long fixed bed stretch and a lower 10 km long movable bed stretch the purpose of the upper fixed bed stretch is to move the flow injection point upstream from the movable bed stretch within the movable bed stretch and close to its upstream end a 200 m long stretch is set to damp sediment and impose sediment feed both the fixed bed stretch and the sediment damping stretch will be disregarded from results analysis and visualisation as result presentation will be restricted to the lower 9 5 kilometres of the movable bed stretch the initial morphology was set as a flat slope along the x direction with slope s 0 355 a value equal to the valley slope downstream of georgetown hicks et al 2003 4 2 2 boundaries at the upstream boundary of the fixed bed stretch an inflow discharge boundary condition is imposed at the lateral boundaries a slip reflective condition is imposed within the movable bed stretch close to the lateral boundaries two very narrow 20 m wide vegetated buffer zones with non removable vegetation cover are set these buffers are meant to mimic the action of outer vegetated stopbanks and to repel channels that otherwise would stick to the side boundaries and create unrealistically deep scour pools tal and paola 2010 vegetation density fraction values within the buffers vary along the transverse direction declining from 1 at the outer margin of the buffer to 0 at the inner margin during simulations with vegetation evolution the vegetation density fraction within the buffer is allowed to grow higher than the imposed value but never to be smaller for consistency identical vegetated buffers are applied even to the models used for creating the unvegetated braided channel the downstream boundary condition is given as an imposed water level this level is determined independently for each cell of the domain adjoining the downstream boundary and is imposed using a rating curve based on the normal flow with the present outflow in that cell the sediment is recirculated this is achieved by instantaneously matching the volume of material deposited in the sediment damping stretch to the sediment outflow measured at the lower boundary therefore the domain averaged bed elevation remains constant i e in an average sense the reach is neither aggrading nor degrading the assumption that the reach does not degrade is realistic for the present case see section 4 1 and is key to allowing the application of a unisize sediment model since the study of degradational reaches would mandate a mixed sediment model to reproduce bed armouring 4 2 3 mesh the mesh was generated with open source meshing software gmsh geuzaine and remacle 2009 the movable bed domain was covered with 199398 triangular cells with average cell surface area of 85 m 2 yielding average cell length the square root of the surface area of 9 2 m although our mesh is coarser than the mesh used in similar modelling studies singh et al 2017 nicholas 2013 this setup represents our best attempt to strike the balance between accuracy and efficiency 4 2 4 hydrograph splitting the key setting in the hydrograph splitting tool is the threshold discharge q t used to discriminate between low flow periods and floods we set this value equal to 450 m 3 s 1 a value above which 85 of bedload transport is achieved according to the time weighted bedload distribution by discharge derived by combining the bedload transport rating function and the flow duration curve see fig 8 2 in hicks et al 2003 for efficiency floods that last less than 5 days and have peak discharge smaller than 550 m 3 s 1 are aggregated to the surrounding low flows while low flow periods shorter than 5 days are aggregated to the surrounding floods the input hydrograph measured at waitaki dam see section 4 1 2 trimmed for the study period and the resulting model hydrograph produced by the hydrograph splitting tool with these settings are compared in fig 7 4 2 5 morphological acceleration we took advantage of the implementation of morphological acceleration as dependent on the inflow discharge to significantly accelerate the small flows while applying less acceleration to major flood peaks this benefited the model stability and minimised spurious compression and damping of the flood waves in the lower part of the domain see morgan et al 2020 the morphological factors used for our simulation presented in table 1 never exceeded 50 i e significantly smaller than those up to 200 used by nicholas 2013 and nicholas et al 2013 4 2 6 physical parameter choice 4 2 6 1 general parameters general parameters needed for morphological model simulation are the grainsize of transported material d s in eq 9 the gravel related roughness height k s in 7 the gravel related critical shields stress θ c g in 11 and the critical height of unvegetated banks δ b c g in 13 we set d s 0 022 m which corresponds to the median diameter of a bulk sample collected at priest road reach on the lower waitaki in 2005 hicks 2006 and is very similar to the median diameter for the entire lower waitaki 0 021 m hicks et al 2003 we imposed k s 0 126 m which we obtained from a calibrated hydrodynamic model of the lower waitaki in aberle et al 2003 for θ c we used the standard value of 0 047 as in bertoldi et al 2014 finally we set δ b c g 1 m a value indicative of the typical height of gravel banks according to our field observations 4 2 6 2 vegetation related parameters vegetation related parameters are the timescale of vegetation adaptation t v in eqs 3 and 4 the parameters determining the equilibrium vegetation density fraction curve b e q in 14 namely λ 1 λ 2 z v 0 and h t the parameters of the vegetation related friction coefficient 8 a x a y d p c w the critical shields stress of vegetated areas θ c v in 11 and the parameters of vegetated banks i e the vegetated critical bank height δ b c v 13 and the threshold bank erosion for vegetation removal δ b t see section 2 2 3 setting the values of these parameters for real world cases is not straightforward even when as for our case estimates of the realistic ranges for some parameters for the vegetation species that are present in the river are available from the literature in fact the adopted vegetation model can only handle one single vegetation type while in a real river there is a variety of vegetation species with differing rates of growth and thresholds of removal we deal with this issue observing that the model vegetation density fraction b is essentially a measure of the strength of the hydro morphodynamic impact of vegetation see eqs 5 11 13 therefore the increase of the vegetation density fraction from 0 to 1 can be interpreted as the progressive development on initially bare sediment of a succession of different species from the faster growing and least impacting e g for the lower waitaki grass lupins to the intermediate woody weeds such as gorse and broom to the slowest growing most impacting trees such as willows therefore when estimates of parameter values were available for the different vegetation species present in the waitaki as in aberle et al 2003 we adopted for our modelling those related to willows we set t v 12 y as a representative measure of the time needed for the full development of a willow cover in an initially bare sediment area in fact while individual willow plants can grow to maturity in a shorter time the adopted value is more realistic as it aims to represent the time needed for the full hydro morphodynamic effect of a dense willow cover to develop over an area that is at least as wide as one computational cell 85 m 2 we imposed the parameters of the equilibrium vegetation density fraction λ 1 0 1 m 1 λ 2 3 m 1 z v 0 0 5 m which are within the range set by bertoldi et al 2014 and we set h t 0 1 m as a realistic estimate for the minimum depth of permanently wetted areas where vegetation cannot establish if not initially present the resulting curve has been shown previously in fig 2 finally we set the parameters of the friction model as a x a y 0 5 m d p 0 8 m and c w 1 to the same settings used for willows in previous hydrodynamic modelling work in the lower waitaki aberle et al 2003 we impose θ c v 0 21 which is the value used to model strong vegetation in bertoldi et al 2014 based on previous work by li and millar 2011 we impose the vegetated critical bank height as δ b c v 1 5 m a value larger by 50 than the unvegetated value δ b c g which agrees with our field observations and set the threshold for vegetation removal on eroding banks as δ b t 0 5 m i e equal to the difference δ b c v δ b c g this value is equal to the half of the typical root depth of 1 m for willows salix fragilis van de wiel and darby 2004 li and millar 2011 and is used under the assumption that when half of the root is exposed the plant will fail 4 3 simulation sequence the sequence adopted for the simulations of this case example is schematised in fig 8 first we conducted a preliminary simulation to create the unvegetated braided channel to be used as an initial condition for the following simulation with vegetation evolution this is analogous to the approach utilised by tal and paola 2010 for their laboratory experiment where they developed a braided channel in a bare sediment bed before introducing vegetation this preliminary simulation started from a planar bed section 4 2 1 and lasted for 150 days a time period sufficient to develop a braided network in dynamic equilibrium vegetation density was zero throughout most of the domain except for a static vegetation cover in the lateral buffers section 4 2 2 the inflow discharge was constant and set equal to the formative discharge i e to the theoretical discharge that if maintained indefinitely would produce the same channel geometry as the natural long term hydrograph wolman and miller 1960 assumed equal to 1260 m3s 1 this value corresponds to the mean annual flood discharge at waitaki dam in the period 1928 2020 in the natural reconstructed hydrograph henderson 2020 i e the hydrograph that would have been measured in the absence of the wps and hence well approximates the discharge that shaped the river before the wps was developed once this bare braided channel was developed we used it as the initial condition for the simulation with evolving vegetation and unsteady flows applying the hydrograph splitting technique section 3 after classifying the flow record using the hydrograph splitting tool the solutions to low flow periods and floods were applied sequentially and each event took as initial condition the final output computed during the previous event 4 4 postprocessing of results here we will briefly detail the calculation of metrics used to characterise the evolution of the simulated reach metrics were computed in a subset of the reach for values of the streamwise coordinate greater than 500 m as explained in section 4 2 1 4 4 1 vegetation metrics to evaluate changes in vegetation presence in section 5 2 3 we calculated time series of domain averaged vegetation density fraction and unvegetated width for the latter series we evaluated for each model output the total area of substantially unvegetated cells and divided such area by the reach length substantially unvegetated cells were defined as those carrying a vegetation density fraction value smaller than a small threshold b t while setting b t we aimed to be consistent with the historic aerial photo analysis procedure in hicks et al 2003 since in their work unvegetated areas were defined as those covered by water bare gravel and even sparse and low vegetation we have tested b t 0 2 and b t 0 3 obtaining two distinct time series as a sensitivity exercise 4 4 2 braiding index to evaluate changes in braiding intensity in section 5 2 4 we computed time series of braiding index as this is the most consistent and easily measured metric of braiding intensity egozi and ashmore 2008 following the approach of howard et al 1970 braiding index was calculated by defining channel links along the centreline of each braid counting the number of links crossed by a series of cross sections and averaging the results along the length of the analysis domain as the braiding index is a discharge dependent metric we produced four different series with different discharge values we used half of the median discharge 1 2 q m 169 m 3 s 1 the median discharge q m 338 m 3 s 1 and twice and four times the median 2 q m 676 m 3 s 1 and 4 q m 1352 m 3 s 1 to gather the channel pattern associated with these discharges we run additional simulations of the giamt2d veg model over a fixed bed with static vegetation with the above inflow discharges taken as steady these simulations were performed at a yearly frequency gathering morphology and vegetation from the outputs of the full morphological simulation sampled at the start of the first low flow period of the year this choice was made for consistency as floods can remove vegetation and recessions tend to create small scale morphology thus affecting the channel pattern 5 results 5 1 creation of the unvegetated braided channel the creation of the unvegetated braided channel is shown by snapshots of shaded relief bed topography with overlain flow depth in fig 9 starting from an initially flat bed fig 9a the figure shows stages of channel development towards its final braided shape after 15 days fig 9b a rather regular bed instability pattern has developed after 30 days fig 9c the river starts carving one or two deeper channels while smaller bedforms have coalesced into bigger bedforms the process of fully developing into a braided channel continues until the end of the simulation figs 9d f this simulation is successful in producing an active braided network with channel pattern that keeps evolving contrast the last two snapshots in figs 9e f however the channel geometry at the final time fig 9f shows braids that are quite wide with morphological features appearing less sharply defined than in the real river in the absence of vegetation see fig 5a this discrepancy indicates that numerically generated topographies are excessively smoothed and individual braids are too wide and lacking small scale detail the reason is twofold first that the resolution of morphological features is limited by the adoption of a relatively coarse grid average cell size of 9 2 m since the width of the smallest representable braid scales with cell size as the availability of at least a few cells in the transverse direction is critical to represent the braid topography and second that the present simulation for braided channel formation is carried out with a constant formative discharge which may prevent the development of the smaller scale morphological features that are generally developed during flood recessions we decided to accept this discrepancy between the model result and the physical prototype as increasing the mesh resolution would have made the following unsteady computations excessively expensive this will not prevent the model however from producing realistic trends of unvegetated channel width and braiding intensity 5 2 vegetation and morphology evolution 5 2 1 planform changes the simulated channel evolution in the waitaki river starting in 1936 from the unvegetated configuration seen at the end of braiding development in fig 9f is shown in fig 10 by 1940 fig 10a vegetation had established on elevated bar tops by 1945 fig 10b vegetation had visibly grown on the channel margins and islands but the channel mainly in its lower section still maintained a central braided configuration by 1950 fig 10c the width of the vegetated margins had increased significantly and the channel had been further confined loosing part of its braided character and by 1955 fig 10d the river had reduced to a 2 channel system surrounded by margins with thick vegetation and featuring densely vegetated islands the situation partially changed in 1960 fig 10e because a spike of more frequent and intense floods from 1957 following a period with deficit in floods see fig 7 managed to halt vegetation encroachment and increase the unvegetated channel width notably in the lower part of the domain the right branch that was present in 1955 was abandoned as newly grown vegetation blocked the inlet to the former right channel and the width of the left branch increased the river in this configuration also featured less pronounced vegetated islands and one former island had coalesced with the right margin these changes will be analysed in detail in the next section finally at the end of 1964 fig 10f the situation was similar to 1960 apart for some still mild vegetation growth on low lying bars in the upstream section of the channel 5 2 2 vegetation changes during the 1957 1958 flood spike after years with prolonged low flow periods and brief isolated intervening floods from 1953 onwards the period from 1957 featured more frequent floods see fig 7b in response the model predicted vegetation removal along the main channel channel widening and increase in braiding intensity in fig 11 we focus on the spike of floods from early november 1957 until early june 1958 this had multiple peaks around 1000 m 3 s 1 and the major one happened at the end of 1957 with a discharge of 1734 7 m 3 s 1 on december 29 figs 11a c show the topography flow pattern and vegetation distribution before the flood spike at the main flood peak and after the flood spike respectively in fig 11c the vegetated channel margins of the channel seen before the flood in fig 11a are overlain to better appreciate channel widening the initial state of this sequence fig 11a was an almost single thread channel heavily confined by vegetation as the absence of floods between 1955 and 1957 had allowed vegetation to close a former channel bifurcation at about the half of the reach the flood spike fig 11b caused modification of the in channel bar pattern removal of sparse vegetation on low lying bars in the lower part of the reach due to morphological reworking and generalised channel widening due to the erosion of its vegetated margins at the expense of banks and islands however the flow was not intense enough to reactivate the right branch of the former bifurcation located at the domain half at the flood peak this right branch was flowing but not undergoing any significant morphological change due to the stabilising effect of vegetation and hence vegetation could not be removed there instead the flood induced widening of the left branch with increased flow conveyance in the left branch the river was further induced to assume a single thread configuration the changes produced by the flood spike vegetation removal channel widening are visible in fig 11c where the post flood channel is shown and compared with contours of the pre flood channel notably most of vegetation removal from the pre flood configuration happened due to bank collapse and erosion from channel banks that were not submerged even at the flood peak fig 11b this suggests that the introduction of vegetation removal driven by bank erosion in the present vegetation model implementation see section 2 1 3 was critical to modelling braided channel dynamics conversely vegetation removal due to in channel morphological change was limited to a few areas such as the sparsely vegetated bars in the lower part of the domain that were submerged during the flood spike this flood spike despite lasting for 6 months and having quite significant peak discharges while inducing channel widening and vegetation removal from retreating banks and islands could not reset the channel configuration and revert it to an unvegetated condition this behaviour is realistic for the lower waitaki river as it is consistent with the field observations of hicks et al 2003 who noted that even a much bigger flood in 1995 peak discharge of 2700 m 3 s 1 had only a moderate vegetation removal effect and could not reset the channel 5 2 3 reproduction of observed changes in vegetation presence fig 12a shows the time series of reach averaged vegetation density fraction starting from a bare channel in 1936 the river develops a vegetation cover that grows almost linearly in time until 1957 reaching an average density fraction of 0 26 small wiggles in this trend are due to removal by the floods and limited periods with steady vegetation cover can be explained as seasonal hiatuses of vegetation growth described by eq 4 the increased frequency of floods from 1957 compared to the previous period see fig 7 causes a visible drop in average vegetation density fraction that stabilises at 0 24 as vegetation finds a dynamic equilibrium with this new flow regime these observations are consistent with those of channel widening accompanied by vegetation removal from the banks during the 1957 1958 flood spike fig 11 and overall constancy of vegetation presence until 1964 fig 10e f fig 12b shows the evolution of reach averaged unvegetated width see section 4 4 1 two distinct model series are presented obtained with threshold b t 0 2 and b t 0 3 for identifying unvegetated areas respectively these are compared width data for 1936 and 1964 measured from historic photos hicks et al 2003 starting in 1936 from a value equal to 1560 m i e the total domain width minus the width of the two lateral vegetated buffers model series show a decline in unvegetated width after just a few years this decline is visible slightly earlier in the curve with b t 0 2 than in the time series with b t 0 3 and for both continues until 1957 reaching the minimum value of 800 m or 1000 m respectively eventually due to the increased frequency of floods fig 7 that caused erosion of vegetation banks fig 11 and decline in averaged vegetation density fraction fig 12a the unvegetated width increases sharply finally in the early 1960s settling on the quasi constant values of 950 m or 1050 m for the two series with both thresholds model results replicate reasonably well the unvegetated with reduction seen in the historic data of hicks et al 2003 the final historic width of 997 m in 1964 is within 50 m from the values of 1050 m and 950 in the two model series therefore with both b t settings the model shows capable of reproducing observed vegetation encroachment yielding a reasonably good agreement this reasonably good match shows quantitatively that the developed modelling tools and techniques can capture some salient features of the observed vegetation encroachment process and its interaction with the morphodynamics 5 2 4 changes in braiding intensity in fig 13 we analyse the change in braiding intensity from the braiding index computed with four reference discharges 1 2 q m 4 q m section 4 4 2 braiding intensity shows an overall declining trend for each reference discharge which is consistent with the observations in hicks et al 2003 and hicks 2006 a strong decline is evident until the mid to late 1950s after which the braiding index increases a behaviour somewhat associated with the clearing done by the spike of floods from 1957 see section 5 2 2 however the braiding index at the end of the simulation generally has values smaller than at the beginning for discharges from 1 2 q m to 2 q m the braiding index is generally an increasing function of discharge throughout most of the study period however this behaviour changes for the braiding index associated with the highest discharge 4 q m depending on the year considered the braiding index of 4 q m can be the highest in the set e g in 1038 1939 and 1958 1960 or the smallest in the set 1948 1954 or have intermediate values that the braiding index for a given channel morphology can be both an increasing and a decreasing function of the discharge depending on the considered discharge range has been reported elsewhere in the literature see e g welber et al 2012 this is because with the discharge increasing from small values the number of wetted channel initially increases but beyond a certain discharge some channels will merge into one as overbank flows develop and during large floods lateral confinement can corral the flow in a single wide channel temporal changes in the discharge value associated with the maximum braiding intensity reflect changes in the reach morphology and vegetation distribution in fig 13 when the braiding index of 4 q m drops below the value associated with the smaller discharges 1948 1954 this reflects flow confinement due to vegetation spread on channel banks which happens progressively from the start of the simulation see topographies in figs 4a c eventually the braiding index of 4 q m shows a sharp increase between 1957 and 1960 the latter change is related to the partial reset of the channel braided character fig 11 due to the flood spike from 1957 fig 7b from 1958 onwards while the unvegetated width does not change significantly fig 12b the braiding index of the three smallest discharges increases sharply this happens because the braided channel in this period fig 10e f keeps being mobilised by quite frequent albeit small floods fig 7b that are not strong enough to further relieve vegetation confinement and hence to significantly affect the braiding index of 4 q m while these trends generally indicate loss of braiding qualitatively similar to the observations in hicks et al 2003 and provide insight on morphology and vegetation changes a strictly quantitative comparison with these observations exposes a model weakness the historic data for the study period are sparse but generally show higher braiding index values than those found from the numerical results for similar discharges for instance the braiding index measured from the 1936 photo was 11 6 for a discharge of 151 2 m 3 s 1 significantly higher than the value we obtained from model results at the similar discharge of 1 2 q m 169 m 3 s 1 fig 13 this discrepancy reflects the lack of sharpness in the braided morphology already observed in section 5 1 the reasons for which are discussed in section 6 6 discussion in this section we will discuss the limitations weaknesses and prospected developments and further applications of the present modelling framework 6 1 lack of small scale morphology role of mesh resolution and incomplete flood recessions in section 5 2 4 we observed that the model failed to accurately reproduce the braiding index values observed from historic photos while the modelled braiding index trends show a decrease in braiding that is qualitatively consistent with the historic observation the braiding index values are underestimated we related this behaviour to the lack of small scale morphological features and hence of braids in the numerical topographies which had been observed even in the initial unvegetated braided channel section 5 1 this lack of small scale morphology stems from two causes i incomplete modelling of flood recessions which in real rivers sculpt finely detailed channel features and ii the use of a relatively coarse grid average cell size of 9 2 m causing numerically generated topographies to lack sharpness compared with the real ones with braids being too wide and lacking small scale detail regarding the first issue we observe that although the simulation with evolving vegetation applied an unsteady flow regime unlike the preliminary simulation for braided channel formation where a constant discharge was applied flood recessions were truncated by the hydrograph splitting technique however this strategy was critical to computational feasibility since direct application of the morphodynamics and vegetation model to the entire time series would have produced a 6 fold increase in simulation time in regard of the second issue we note that the impact of mesh size on the resolution of morphological features has been observed elsewhere for instance schuurman and kleinhans 2011 showed that while large scale bar pattern statistics are independent of grid size the shape of bars improves when a finer grid is used to increase model realism these limitations should be mitigated by using finer meshes and lowering the hydrograph splitting discharge threshold this however would require a significant computational performance improvement to still retain practical run times and we leave it for future work 6 2 incomplete parameter calibration quantitative validation of the model results in this work is limited to observing that the model can accurately match recorded trends in vegetated width section 5 2 3 this is a reflection of the relative paucity of quantitative historic observations achieving this match with historic data required a sensitivity analysis of model parameters that we have not detailed here for the sake of brevity however the essence of the analysis involved the following firstly we varied the critical bank height of bare gravel δ b c g during the initial unvegetated channel formation we observed that with a smaller critical bank height e g δ b c g 0 75 m the braided morphology would have been even more diffuse but would have produced a network subject to a faster evolution due to the lateral shift of channels as we did not possess information on the speed of lateral reworking to calibrate the model to we opted for a higher δ b c value to increase sharpness of the morphology conversely we did not calibrate the parameters of the sediment transport formula but rather stayed with the classical values of the relation of meyer peter and müller 1948 this is because we did not possess detailed sediment transport data for this kind of calibration we devoted more attention to calibrating the vegetation parameters for which we could not find literature values see section 4 2 6 2 we tested a few equilibrium density fraction curves varying the parameters λ 1 λ 2 and z v 0 in eq 14 we found that using a more aggressive vegetation type more capable of establishing at low elevations on the bars and to interact with the flow would have sped up vegetation encroachment furthermore we tested models with a reduced adaptation timescale t v obtaining faster encroachment which still converged to similar unvegetated width reduction values we finally adopted the parameter set that described the least aggressive slowest growing vegetation that was still capable of producing an unvegetated width reduction that compared well with the historic data this limited model sensitivity to changes of parameters indicates that the lower waitaki was naturally prone to vegetation encroachment once european vegetation was introduced this is because even prior to the introduction of exotic vegetation the river barely possessed the energy needed to braid due to its naturally damped flow regime below the three headwater lakes stecca et al 2019 hence model wise the observed vegetation encroachment can be achieved by adopting a wide range of vegetation parameter values more modelling work focussed on other rivers is needed to show that the model can also reproduce different vegetation trajectories and better validate the current parameter choice 6 3 unisize sediment approximation the present model features a unisize sediment approximation this simplifying assumption may be admissible when modelling rivers that do not show generalised bed degradation as the coastal reach of the lower waitaki conversely a mixed sediment model formulation is mandatory when modelling river reaches subject to generalised bed degradation as in these reaches the dynamics of sediment transport is critically influenced by bed armouring our choice was further motivated by considerations over the feasibility of the present computational exercise as neglecting the additional continuity equations that would have been needed for mixed sediment helped us to achieve reasonable run times which was critical for our decadal simulations furthermore the inaccuracy introduced with this choice does not seem decisive when compared with all the other sources of inaccuracy lack of small scale morphology simplified rendering of vegetation processes incomplete assessment of parameter choice that affected the modelled sediment dynamics the consequences of a unisize sediment approximation while simulating braiding dynamics are not fully understood the only modelling study to date on this topic is due to singh et al 2017 who found that larger sediment heterogeneity produces higher braiding indices they did not completely rule out the use of unisize models arguing that they may be adequate under full sediment mobility i e larger floods but not under partial mobility moving to vegetated braided rivers the model of nicholas 2013 and nicholas et al 2013 2016 developed for sand bed rivers features mixed sediment but limits complexity of the formulation by adopting only two fractions sand and silt as silt deposition is a key component of floodplain development for these rivers this is still too simple a mixture to enable armour development while the debate on the importance of modelling mixed size sediment transport is ongoing we remark that the most commonly used mathematical representation of mixed size sediment the active layer model hirano 1971 1972 produces models that are mathematically ill posed for some parameter values chavarrías et al 2018 2019c this issue is severe under some common cases such as bed degradation into a finer substrate stecca et al 2014 which would defy the purpose of adopting mixed sediment models even in degradational reaches research to produce unconditionally well posed formulations of the problem is in progress chavarrías et al 2019b chavarrías et al 2019a 6 4 initial data availability and impossibility of exact long term predictions the initial data needed for a vegetation and morphology simulation is a braided topography and a map of vegetation density fraction over that topography for the applications of this paper we assumed the initial channel to be unvegetated except for the lateral buffers and we let the model determine an equilibrium unvegetated morphology with a preliminary steady flow simulation this approach was convenient for our case since we did not possess a detailed 2d bed topography of the 1936 channel it also suited the overall purpose of our modelling i e to develop a realistic analogue of the real world river that would show similar vegetation dynamics and morphological trajectories there is no barrier preventing the user of the model from initiating a model with a surveyed channel morphology if this is available in the attempt to track the exact evolution of channel configurations even doing so however as we have shown in recent research stecca and hicks 2022 channel configurations can be predicted in exact terms only for a very short period e g a few floods owing to the deterministic chaos nature of braiding morphodynamics the issue is with the sensitive dependence on the initial conditions shown by braiding which makes any simulation even carried out with a perfectly accurate model diverge from the real prototype if the initial topography is known ever so slightly inaccurately as happens in practice therefore the unavailability of a surveyed topography to initiate the model is not an issue because the modelled configuration would have rapidly diverged from the real configuration anyway 6 5 discharge record availability the model requires a discharge time series for the upstream boundary condition unlike modelling studies in unvegetated settings for which knowledge of only a dominant or formative discharge may be sufficient for conducting at least preliminary simulations modelling vegetated rivers requires an unsteady discharge record that comprises both low flow periods when vegetation establishes and floods when vegetation is scoured furthermore the discharge record must be time accurate enough to capture the flow variability depending on the hydrological character of the river at hand for our hindcasting application we simply used a recorded hydrograph with daily averaged values which suits well the damped hydrology of the lower waitaki since this dataset was directly available however for most applications this approach may not be viable either because a reliable and sufficiently refined discharge record is not available or because the applications are aimed at forecasting future evolution or because the modelled reach is idealised and the applications are theoretical in this case a hydrograph of some form must be assumed the easiest choice which well suits modelling for theoretical purposes is to generate a synthetic flow regime from a few control parameters e g the shape of the flood hydrograph the magnitude of its peak and the low flow duration see bertoldi et al 2014 nicholas et al 2016 to study the sensitivity of the river morphology to changes in these hydrological parameters another more realistic approach suited to hindcasting is to generate a flow record from precipitation data using a hydrological model for the lower waitaki a potential application of this approach is to use the natural reconstructed flow regime i e the discharge series that would have been recorded in the absence of dams henderson 2020 to tease apart the role of dam operation on observed vegetation spread when the modelling exercise aims to forecast future evolution however a modeller needs to make assumptions over the future flow regime the most straightforward scenario follows the assumption that the hydrology is stationary and hence that an available flow record can be projected unaltered into the future otherwise different hydrographs could be adopted depending on assumed changes in the river s hydrology 6 6 potential for further applications despite the limitations of the present modelling framework highlighted in this section the model has been shown capable of closely reproducing observed historical vegetation encroachment in the lower waitaki the model therefore has potential applications in understanding the relative role of flow regime changes and of vegetation introduction on braided morphology evolution and to inform on management questions regarding vegetation control and hydropower management ongoing and future work includes i the application to other new zealand rivers to demonstrate the model capability to reproduce different morphological and vegetation evolution trajectories ii model applications to the lower waitaki with the natural reconstructed flow regime henderson 2020 to understand the role of damming on vegetation spread iii the implementation of rules to simulate the artificial vegetation management scheme in place in the waitaki from 1960 onwards and iv use of the model to understand future trajectories according to different management scenarios 7 conclusions in this work we constructed a two dimensional numerical model framework for reproducing vegetation driven morphological change in braided rivers and we applied it to the test case given by vegetation encroachment in the coastal reach of the lower waitaki river new zealand between 1936 and 1964 salient features of the mathematical model are a bank erosion model that extends to the present two dimensional framework the critical bank height approach that we developed in previous work in one space dimension and a vegetation model that drives vegetation density change and features relations that express the feedback of vegetation density on the hydro morphodynamics we devised an approximate solution strategy named hydrograph splitting capable of providing practical run times for the decadal scale simulations needed to appreciate vegetation driven morphological changes in braided reaches this technique involves solving the full flow morphology and vegetation problem only during floods when morphological change drives vegetation removal and the interaction between flow morphology and vegetation happens over short time scales and in only updating vegetation with a static bed and inundation pattern during low flow periods the braided river numerical modelling framework developed in this study proved capable of reproducing unvegetated channel width trends that compare well with the historic data available use of the model allows a deeper understanding of the flow vegetation morphology interactions that occurred in the lower waitaki which was not discernible in the sparse historic data the analysis of morphological changes during the 6 months duration spike of floods in 1957 1958 shows that even repeated floods of significant magnitude while inducing channel widening and vegetation removal from retreating banks and islands could not reset the channel configuration and revert it to an unvegetated condition the analysis of trends in braiding intensity shows that the model qualitatively reproduced the loss of braiding character that was observed between 1936 and the 1950s and the partial recovery following increased frequency and magnitude of floods from 1957 onwards however the present application also exposes model weaknesses mainly that the numeric values of braiding index are underestimated with respect to the sparse observations available the cause of this model weakness is the lack of fine scale morphology due to both mesh coarseness and the incomplete rendering of flood recessions due to the hydrograph splitting strategy however both these approximations were key to containing run times and could be relaxed only by a critical increase in the model s computational performance these approximations together with the simplifications in the model formulation essentially the adoption of a unisize sediment continuity framework and the incomplete assessment of the bank erosion and vegetation parameters deserve further investigation in future work due to its ability to match observed vegetation encroachment and explain long term evolutionary trajectories and despite its inevitable limitations and approximations the model has potential applications to understand the relationship between flow vegetation and morphology in other rivers and to support management decisions ongoing work includes the application to other new zealand rivers to demonstrate the model capability to reproduce different morphological trajectories the implementation of rules to simulate the artificial vegetation management scheme in place in the lower waitaki from 1960 onwards and use of the model to understand future trajectories according to different management scenarios in the lower waitaki credit authorship contribution statement guglielmo stecca conceptualization methodology software investigation resources writing original draft writing review editing visualisation supervision project administration funding acquisition davide fedrizzi methodology software investigation resources visualisation richard measures writing review editing methodology software d murray hicks project administration funding acquisition supervision writing review editing jo hoyle project administration funding acquisition writing review editing guido zolezzi project administration funding acquisition supervision writing original draft resources declaration of competing interest one or more of the authors of this paper have disclosed potential or pertinent conflicts of interest which may include receipt of payment either direct or indirect institutional support or association with an entity in the biomedical field which may be perceived to have potential conflict of interest with this work for full disclosure statements refer to https doi org 10 1016 j advwatres 2022 104236 guglielmo stecca reports financial support was provided by meridian energy ltd guglielmo stecca reports financial support was provided by european commission seventh framework programme for research and technological development davide fedrizzi reports financial support was provided by european commission seventh framework programme for research and technological development richard measures reports financial support was provided by meridian energy ltd jo hoyle reports financial support was provided by meridian energy ltd murray hicks reports financial support was provided by meridian energy ltd acknowledgements this project has received funding from the european union s seventh framework programme for research technological development and demonstration under marie curie international outgoing fellowship no 2013 621886 2015 2018 meridian energy ltd new zealand under niwa project mel20534 2020 2021 niwa new zealand core funding under the environmental flows programme eflows 2020 2021 the university of trento italy under student mobility funds fondo ricerca tesi fund for thesis reseach 2017 2018 stecca s activity was initially funded by the marie curie fellowship and eventually by the meridian project and eflows programme fedrizzi s visit to niwa christchurch for his m sc thesis work was supported by marie curie funds and by the student mobility funds of the university of trento fedrizzi s post graduate grant was covered by marie curie funds the involvement of measures hoyle and hicks was covered by the eflows programme and meridian project initial numerical simulations were run on the university of trento high performance computing facility the final numerical simulations were run on the high performance computing facility mahuika of the new zealand escience infrastructure nesi https www nesi org nz and their cost was covered by the merdian project we thank j zais niwa and a shaw nesi for helping us set up and manage this simulation project 
114,in this paper we present a new computationally efficient and high resolution depth averaged two phase flow model for hydro sediment morphydynamic processes featuring an advance over existing models in terms of accuracy and efficiency of numerical solution under the framework of finite volume method fvm on unstructured grids the harten lax van leer contact hllc approximate riemann solver is proposed to compute inter cell fluxes by applying the classical upwind hllc approach to the water sediment mixture and the sediment phases separately in contrast to previous two phase flow models using centered schemes moreover to improve computational efficiency the local time stepping lts approach is implemented the first attempt in the field of two phase flow modelling after a convergence rate study the model is tested against a series of flow sediment bed evolutions induced by 1 two refilling processes of dredged trenches 2 two instantaneous dam break flooding flows and 3 one levee breaching process by overtopping flows it features encouraging performance when compared to a two phase flow model based on a centered scheme and global time bound characterized by more accurate results and much less computational cost the present modelling framework shows promise in practical shallow water hydro sediment morphodynamic modelling applications keywords hydro sediment morphodynamic process two phase flow modeling hllc riemann solver local time step globally maximum time step 1 introduction refined and efficient modelling of shallow water hydro sediment flows is important for not only river engineering practice but also flood risk management the last two decades have witnessed increasingly widespread applications of shallow water depth averaged hydro sediment morphodynamic shsm models and their variants cao et al 2017 however existing shsm models are mostly based on the single phase premise hoey and ferguson 1994 armanini and disilvio 1998 cao et al 2011 2017 guy and castelltort 2006 wu and wang 2008 canestrelli and toro 2012 hu et al 2012 2014 2018 2019 juez et al 2014 zhao et al 2019 meurice and soares frazão 2020 in these models the velocities of the sediment phases are assumed equal to the mixture velocity or are empirically determined by the mixture velocity along with a modification coefficient less than unity consequently the relative motions and interactions between water and sediment phases are not incorporated in fact not only is the advection velocity of bedload appreciably lower than the flow greimann et al 2008 but also a velocity lag between the flow and the suspended sediments has been observed muste et al 2005 in this regard a two phase model is certainly warranted there have been different types of two phase models for shallow water hydro sediment flows for example vertical 2d two phase models were used to investigate the vertical sediment concentration distributions bakhtyar et al 2009 chen et al 2011 meshfree sph two phase models were used to tackle problems with strong free surface variations shi et al 2017 2019 the two phase shsm models which are the present topic have been developed for not only fluvial processes greco et al 2012 di crisco et al 2016 li et al 2018 2019 2020 but also earth surface flows such as debris flows and granular flows e g pitman and le 2005 pudasaini 2012 it is appreciated that bedload occurs mainly in a thin layer on the top of the erodible bed surface where the sediment concentration is much higher than the depth averaged value in this regard a two layer two phase model may also be appealing zech et al 2008 martínez aranda et al 2019 which is reserved for future study unless otherwise stated the present two phase shsm models are all depth averaged versions in the last decades the shock capturing finite volume method has been widely used to deal with shallow water modeling challenges such as wet dry treatments capturing shock contact discontinuities greco et al 2012 di crisco et al 2016 li et al 2018 2019 2020 however existing two phase shsm models have still suffered from two major shortcomings first existing two phase shsm models exclusively employ the centered schemes or more simplified method to estimate the inter cell numerical flux greco et al 2012 di crisco et al 2016 li et al 2018 2019 2020 while using a centered scheme avoids the difficulty of managing complex wave structures by minimizing the use of eigenvalues they tend to spread the solution more than upwind schemes e g the hllc riemann solver and the roe riemann solver in particular when multi dimensional problems are studied vortices are excessively dissipated by numerical diffusion as well as any shear flow canestrelli and toro 2012 moreover when passive scalars are conveyed centered schemes may also spread the solution the hllc riemann solver which represents a classical upwind scheme by making full use of the eigen structures will be adopted for the present two phase shsm model a major challenge for applying the hllc solver in two phase shsm models is their complex eigen structures arising from the additional momentum equations of the sediment phases briefly the hllc riemann solver was developed for 3 wave riemann structures toro 2001 2019 whereas the two phase flow model even if a single sized sediment transport is assumed would produce 6 wave speeds and 7 riemann fields moreover if the momentum source terms are included into the riemann structures an additional stationary wave may appear murillo and garcía navarro 2012 furfaro and saurel 2015 also appreciated the difficulty for applying the hllc solver to the compressible fluid fluid two phase flows that have seven wave speeds furfaro and saurel 2015 proposed to use the hllc solver separately for different phases because each fluid phase has its own set of mass momentum and energy balancing equations this strategy is extended to present two phase shsm model specifically the entire system is split into a mixture part and several parts of different sediment sizes facilitating usage of the hllc solver second the attractiveness of existing two phase shsm models is limited by its relatively high computational cost specifically existing two phase shsm models have employed the globally minimum time step gmits for variable updating that is the globally minimum value of all locally allowable maximum time steps which are computed by the courant friedrichs lewy cfl stability condition is used for most cells however the gmits is much smaller than the locally allowable maximum time steps in contrast to the gmits an alternative appealing method is the hybrid local time step lts globally maximum time step gmats by this hybrid approach updating of the hydro sediment module is completed by using local time steps close to the locally maximum time steps as much as possible sanders 2008 whereas updating of the morphodynamic model is completed by using the gmats it has been demonstrated that this hybrid approach can bring significant reduction in the computational cost of quasi single phase shsm models hu et al 2019 however it has been rarely reported for two phase shsm models furthermore gpu acceleration is also an important option for improving the computational efficiency ingelsten et al 2020 conde et al 2020 martínez aranda et al 2022 sweet et al 2018 which is reserved for future study this paper presents a new computationally efficient and high resolution depth averaged two phase model for hydro sediment morphodynamic processes mathematical formulations are presented in section 2 specifically the governing equations are solved by the finite volume method on unstructured triangular cells the inter cell numerical flux is estimated by the hllc solver which is novel as compared to previous two phase shsm models that are mostly based on centered schemes for variable updating the hybrid lts gmats approach is implemented which to the authors best knowledge has rarely been reported for two phase shsm modelling moreover the model is parallelized by using the open mp technique in section 3 the convergence rate studies are firstly conducted afterwards the new two phase shsm model is tested against a series of flow sediment bed evolutions due to 1 two refilling processes of dredged trenches 2 two instantaneous dam break flooding flows and 3 one levee breaching process by overtopping flows particular attention is given to its improved quantitative accuracy and enhanced computational efficiency as compared to previous two phase shsm models greco et al 2012 di cristo et al 2016 the paper is concluded in section 4 2 mathematical formulations 2 1 governing equations and empirical closures consider shallow water sediment flows over an erodible bed composed of non cohesive sediment with nsps size classes let dk denote the diameter of the k th sediment size where subscript k 1 2 nsps the proposed model is a two dimensional extension of the one dimensional depth averaged two phase flow model li et al 2019 the governing equations comprise mass and momentum conservation equations for the water sediment mixture the sediment phases and the mass conservation equations for the bed material the resulting system of equations can be expressed in standard well structured conservation form as follows 1 u t f x g y s b s τ s f s m s s 2 u h h u h v h c k h c k u s k h c k v s k f h u h u 2 g h 2 2 h u v h u s k c k h c k u s k 2 ρ c k g h 2 2 ρ s h c k u s k v s k g h v h u v h v 2 g h 2 2 h v s k c k h c k u s k v s k h c k v s k 2 ρ c k g h 2 2 ρ s s b 0 g h s b x g h s b y 0 ρ g h c k s b x ρ s ρ g h c k s b y ρ s s τ 0 τ b x ρ τ b y ρ 0 τ s k b x ρ s τ s k b y ρ s s f n m n m x n m y 0 n s k x n s k y s m f ρ 0 ρ u f ρ ρ 0 ρ v f ρ e k d k 0 0 s s 0 r g h 2 2 c x r g h 2 2 c y 0 1 2 g h 2 c k x 1 2 g h 2 c k y and bed deformation equation 3 z b t d t e t 1 p 0 as well as the active layer equation 4 δ f a k t d k e k 1 p 0 f s k η t where u represents the vector of the conserved variables f gare the vectors of the flux variables s b denotes the vector of the bed slope s τ denotes the vector of the friction source terms s f is the vector containing physically based contributions from the interactions between the water and sediment phases and sediment sediment phases s m is the vector of the source terms representing mass and momentum contributions from bed exchange and s s is the vector of the source terms representing momentum contributions derived of decoupling the flow density from the mass and momentum conservative variables t is the time x y are the spatial horizontal coordinates in the cartesian coordinate system h is the depth of the water sediment mixture zb is the bed elevation g 9 8 m2 s is the gravitational acceleration u v are the depth averaged velocities of the water sediment mixture in the x and y directions respectively usk vsk are the depth averaged size specific velocities of the sediment phase in the x and y directions ck is the depth averaged size specific volumetric sediment concentration r ρ s ρ f ρ ρ ρ f 1 c ρ s c is the density of the water sediment mixture ρ f 1000 kg m3 and ρ s are the densities of water and sediment respectively c ck is the depth averaged total sediment concentration s b x z b x sby zb y are the bed slopes in the x and y directions τ bx τ fbx τ skbx and τ by τ fby τ skby are the total bed shear stresses for the hydro sediment mixture by which the total bed shear stresses for the water sediment mixture are divided into the bed shear stress components exerted respectively on the water and sediment phases τ fbx and τ fby are the bed resistance stresses for the water phase in the x and y directions τ skbx τ skby are the bed shear stresses for sediment phases in the x and y directions f et dt 1 p 0 et ek and dt dk are the total sediment entrainment and deposition fluxes ek and dk are the size specific sediment entrainment and deposition fluxes p 0 is the bed sediment porosity η zb δ is the bottom elevation of the active layer δ ahd 84 is the thickness of the active layer ah is an empirical coefficient ranging from 1 to 4 d 84 is a characteristic sediment size the subscript 84 means that 84 sediments are finer than d 84 fak is the sediment fractions within the bed active layer fsk is the sediment fractions at the interface between the active layer and those below the active layer nm nmx nmy nskx nsky are components of the vector s f which are expressed as follows 5a n m ρ s ρ f ρ f h c k u u s k x h c k v v s k y 5b n m x 1 ρ x h ρ s c k i s k x i s k x i f x 1 ρ y h ρ s c k i s k x i s k y i f y 5c n m y 1 ρ y h ρ s c k i s k y i s k y i f y 1 ρ x h ρ s c k i s k y i s k x i f x 5d n s k x 1 ρ s f s k f x f s s k x 5e n s k y 1 ρ s f s k f y f s s k y where ρ0 ρ f p 0 ρ s 1 p 0 is the density of bed materials i s k x u s k u i s k y v s k v are inter phase velocity discrepancy between the size specific sediment phase and the water sediment mixture ifx uf u ify vf v denote velocity discrepancy between the water phase and the water sediment mixture uf and vf are the depth averaged velocity of the water phase eq 6a 6b fskfx ρ f drkh uf usk fskfy ρ f drkh vf vsk are the size specific depth averaged interphase interaction forces drk is a function related to the drag coefficient see eq 7a 7b f s skx and f s sky are the size specific depth averaged particle particle interactive drag forces eq 8a 8b 6a u f ρ u ρ s u s k c k ρ f 1 c 6b v f ρ v ρ s v s k c k ρ f 1 c 7a d r k 150 c k 2 ν μ f 1 c k d k 2 7 c k 4 d k u f u s k 2 v f v s k 2 i f c k 0 2 3 c d 1 c k c k 4 d k 1 c k 2 65 u f u s k 2 v f v s k 2 i f c k 0 2 7b c d 24 1 0 15 r e k 0 687 r e k i f r e k 1000 0 44 i f r e k 1000 8a f s s k x 1 2 c ρ g h 2 c k x c k c ρ s c k c c s d u s k u s h c k ρ s ν d h c k x c k c 8b f s s k y 1 2 c ρ g h 2 c k y c k c ρ s c k c c s d v s k v s h c k ρ s ν d h c k y c k c where r e k 1 c u f u s k 2 v f v s k 2 d k ν μ f νμf 10 6 m 2 s is the kinematic viscosity of fluid phase csd 6 3s 1 is the liner drag coefficient v d 1 26 1 0 5 m 2 s 2 is the linear diffusive coefficient hill and tan 2014 u s c k u s k c v s c k v s k c are mean sediment velocity by eq 7a 7b the interphase drag force is determined by combining the ergun equation for dense water sediment mixtures and the power law for dilute suspensions gidaspow 1994 by eq 8a 8b the inter grain size interaction force includes a linear velocity dependent drag force an inter grain size surface interaction force and a remixing force gray and chugunov 2006 hill and tan 2014 eqs 9 10 present empirical relations for bed resistance from the water phase using the manning roughness and for the sediment phase using the coulomb friction law savage and hutter 1989 respectively 9 τ f b x ρ f g n 2 u f u f 2 v f 2 h f 1 3 τ f b y ρ f g n 2 v f u f 2 v f 2 h f 1 3 10 τ s k b x ρ s ρ f g h c k tan ϕ b e d u s k u s k 2 v s k 2 τ s k b y ρ s ρ f g h c k tan ϕ b e d v s k u s k 2 v s k 2 where n is the manning roughness hf h 1 c is the depth of the water phase the parameter tan φ bed expresses the collinearity of shear stress and normal stress φ bed is s the friction angle of the sheared granular material while it has been demonstrated that the dynamic pore fluid pressure i e the excess of pressure within the liquid phase respect to the hydrostatic value is important for very dense packed water solid flows mcardell et al 2007 iverson et al 2010 such as debris flows hungr and mcdougall 2009 george and iverson 2014 the present study used the coulomb relation savage and hutter 1989 for the sediment resistance which expresses the collinearity of shear stress and normal stress through a friction coefficient this relation implicitly indicates that the pressure within the liquid phase at the bed surface is hydrostatic which is reasonable because in the present cases all sediment volume concentrations are below 0 1 sediment exchange with the bed is estimated by eqs 11 11 d k α k c k ω k e k α k c e k ω k where ω k is the settling velocity for sediment of diameter dk which is calculated using the zhang 1961 formulation cek is the size specific depth averaged sediment transport capacity of which the estimation will be introduced in the specific case study and the parameter α k represents the difference between the near bed concentration and the depth averaged concentration is estimated with an upper limit α k h ω k δ t derived by hu et al 2014 eq 12 presents empirical relation for the fraction fsk at the lower boundary of the active layer hoey and ferguson 1994 12 f s k f s k 0 η t 0 f a k η t 0 where f s k 0 is the sediment fraction of the k th size sediment in the substrate layer 2 2 time step estimations fig 1 shows sketches of internal triangular cells a triangular cell has three nodes three faces and three neighboring cells fig 1a and a face has two nodes and is shared by two neighboring cells fig 1b the total number of cells is nc and the total number of faces is nf in fig 1a rij is the distance from cell i center to its j th face where the i indicates the sequence of the cells and j indicates the j th face of the cell i with j 1 2 3 ai is the area of the cell i δlij is the length of the j th face of the cell i n ij nx ny ij represents the normal outward direction of the j th face of the cell i physical conserved variables shown in fig 1 will be introduced when they appear in the mathematical formulations below the locally allowable maximum time step δtami where the subscript am indicates allowable maximum is firstly estimated as follows 13 δ t am i c r min j 1 2 3 k 1 n s p s r i j u i j 2 v i j 2 g h i r i j u s k i j 2 v s k i j 2 0 5 ρ i g h i ρ s i 1 2 3 n c where cr is the courant number which is set as 0 9 in this paper and hi ρ i are the depth and the density for the hydro sediment mixture at cell i uij vij uskij vskij are velocities of the j th face of the cell i traditional models always use the globally minimum time step δtgmi to update the physical variables and here we use the approach of the local graded time step presented by hu et al 2019 the potential graded lts level for every cell is computed as 14a m i min int log δ t a m i δ t g m i log 2 m u s e r i 1 2 3 n c 14b δ t g m i min i 1 n c δ t a m i where m u s e r is a user defined upper limit value setting m u s e r 0 means the graded levels of all cells are zero which will make the model equivalent to the gmits model the model further modifies the lts level of neighboring cells that are characterized by abrupt flow regime changes i e the wet dry front and the static dynamic front of both sediment and water specifically lts level of such neighboring cells are set to a locally minimum value the actual grade level mfm for face m is computed as follows 15 m f m min m m l m m r m 1 2 3 n f where mml mmr represent the potential graded levels of two neighboring cells of face m see fig 1b the potential graded time step level of each cell is finally computed in the following 16 m i min m i m i 1 m i 2 m i 3 i 1 2 3 n c where m i1 m i2 m i3 represents the potential graded level of the three neighboring cells of cell i afterwards the graded local time step is computed as 17 δ t l i 2 m i δ t g m i i 1 2 3 n c finally the gmats can be computed as 18 δ t max δ t l i i 1 2 3 n c 2 3 finite volume discretization as shown in eqs 19 21 the hybrid lts gmats approach is used for variable updating specifically the hydro sediment part is updated by the lts and the morphodynamic part are updated by gmats see fig 2 for a summary 19 u i u i δ t l i a i j 1 3 e n i j δ l i j δ t l i s b i s τ i s f i s m i s s i 20 z b i t 0 δ t z b i t 0 s c 1 n p δ t l i d t i s c e t i s c 1 p o 21 δ f a k i t 0 δ t δ f a k i t 0 s c 1 n p δ t l i d k i s c e k i s c 1 p o f s k i s c 1 n p δ t l i d t i s c e t i s c 1 p o where e n i j f n x g n y i j is the numerical flux crossing the j th face of the cell i which is estimated by approximate riemann solvers see section 2 4 the superscripts and represents two consecutive sub time levels the temporal interval is δt l i between t 0 and t 0 δt the temporal interval between the two synchronized time levels t 0 and t 0 δt is termed a full cycle np δt δtgmi is the maximum number of sub cycles in the full cycle and the symbol sc is used to indicate the sequence of sub cycles with s c 1 2 n p within a full cycle the hydro sediment morphodynamic system will be updated from one synchronized time level to the next to complete such update the morphodynamic part at all cells is updated only once eqs 20 21 whereas the times that the hydro sediment part has to be updated at a specific cell i is equal to the ratio δt δt l i eq 19 if δ t l i 2 m i δ t min the times that the hydro sediment part at cell i is updated are n p 2 m i indicating that hydro sediment part in cell i will be updated every 2 m i sub cycles in a specific sub cycle sc the implementation of the hydro sediment part is activated if this inequality m i l s s c is satisfied where ls is a function of the sequence sc see hu et al 2019 for the function whereas estimation of numerical fluxes in a specific sub cycle depends on whether mod s c 1 2 m f m 0 if the hydro sediment part is to be updated in the sc sub cycle the source terms would also be estimated otherwise the source terms in the s b i sub cycle take zero value specifically the source terms for the bed slope sc are evaluated using the slope flux method hou et al 2013 with flow variables at the sub cycle but bed elevations at the initial synchronized time level as input the vectors s s i s t i s f i and s m i are evaluated explicitly using empirical relations with flow variables at the time level after updating s b i and s n i j as input to overcome numerical instabilities arising from the relatively large spatial and time steps that lead to an issue of stiff source term the following numerical treatments are proposed to attach the implementation of theoretically derived lower and upper limits for the inter phase interactive forces for updating momentum equations of hydro sediment mixture modified source term s x i m i x t u r e s τ i 2 s s i 2 s f i 2 and s y i m i x t u r e s τ i 3 s s i 3 s f i 3 in the x y direction can be defined as 22a s x i m i x t u r e max s x i m i x t u r e h i u i δ t l i u i 0 min s x i m i x t u r e h i u i δ t l i u i 0 22b s y i m i x t u r e max s y i m i x t u r e h i v i δ t l i v i 0 min s y i m i x t u r e h i v i δ t l i v i 0 for updating momentum equations of sediment phase with the size dk modified source term can be defined as 23a s x i s e d k max s x i s e d k h c k u s k i δ t l i u s k i 0 min s x i s e d k h c k u s k i δ t l i u s k i 0 min s x i s e d k h c k u f i h c k u s k i δ t l i u s k i 0 max s x i s e d k h c k u f i h c k u s k i δ t l i u s k i 0 23b s y i s e d k max s y i s e d k h c k v s k i δ t l i v s k i 0 min s y i s e d k h c k v s k i δ t l i v s k i 0 min s y i s e d k h c k v f i h c k v s k i δ t l i v s k i 0 max s y i s e d k h c k v f i h c k v s k i δ t l i v s k i 0 for the subcritical inflowing boundary face the unit discharge and unit width sediment transport rate or the sediment concentration must be given the tangential velocity to the face is set to zero the water depth and the normal flow velocities are estimated by the method of characteristics for supercritical outlet boundary face and a wall boundary face all physical variables at the face are set equal to the values at the neighboring cell 2 4 estimation of numerical flux using the hllc riemann solver estimation of the inter cell numerical fluxes e g e n i j for the j th face of the cell i is of high importance for high resolution two phase shsm modeling one aim of this paper is to apply the hllc riemann solver to estimate the numerical flux which makes full use of the eigen structures and thus is more accurate than the widely adopted centered schemes to derive the eigenvalues the governing equations are rewritten in the jacobian matrix form as follows 24a u t j u u x u y s b s τ s f s s s m with the jacobian matrix reads 24b j u f n x g n y u 0 n x n y 0 0 0 0 0 0 a 21 a 22 a 23 0 0 0 0 0 0 a 31 a 32 a 33 0 0 0 0 0 0 0 0 0 0 0 n x 0 n y 0 0 n x n y 0 0 0 0 0 0 n x 0 n y a 51 1 0 0 a 54 1 0 a 55 1 0 a 56 1 0 a 51 k a 54 k a 55 k a 56 k a 51 n s p s 0 0 0 a 54 n s p s 0 a 55 n s p s 0 a 56 n s p s a 61 1 0 0 a 64 1 0 a 65 1 0 a 66 1 0 a 61 k a 64 k a 65 k a 66 k a 61 n s p s 0 0 0 a 64 n s p s 0 a 65 n s p s 0 a 66 n s p s where a 21 ghnx uu a 22 unx u a 23 uny a 31 g h n y v u a 32 vnx a 33 u vny a 51 k ρ g h c k n x 2 ρ s a 61 k ρ g h c k n y 2 ρ s a 54 k ρ g h n x 2 ρ s u s k u s k a 64 k ρ g h n y 2 ρ s v s k u s k a 55 k usknx u sk a 65 k v sk nx a 56 k uskny a 66 k u s k v s k n y and u sk usknx vskny u unx vny are the velocities perpendicular to the cell face the eigenvalues λ can be estimated from j λi 0 where i is the unit matrix and thus are the roots of the following characteristic polynomial 25 λ u λ u 2 g h k 1 n s p s λ u s k δ λ u s k δ 2 ρ g h 2 ρ s 0 there are 3nsps 3 roots for eq 25 corresponding to the 3nsps 3 distinct eigenvalues however the hllc riemann solver was designed for 3 wave system to overcome this challenge these distinct eigenvalues are grouped into nsps 1 parts one part for the water sediment mixture eq 26 and nsps part for the nsps sediment sizes eq 27 for the hydro sediment mixture λ 1 m i x t u r e u and 26 λ 2 3 m i x t u r e u g h for the k th sediment phase λ 1 s e d k u s k and 27 λ 2 3 s e d k u s k ρ g h 2 ρ s where λ 1 2 3 m i x t u r e are eigenvalues related to the motion of the hydro sediment mixture and λ 1 2 3 s e d k for the k th sediment size respectively it is obvious from eqs 26 27 that each part consists of three eigenvalues which can be used to construct an independent 3 wave system and thus facilitates the implementation of the hllc riemann solver take the estimation of the numerical flux e nm at the face m as an example the numerical flux should be also split into nsps 1 parts eq 28 one part for the hydro sediment mixture f h l l c m i x t u r e w l w r and nsps part for the nsps sediment sizes f h l l c s e d k w l w r k 1 nsps 28 e n m e n m mixture e n m s e d 1 e n m s e d k e n m s e d n s p s f h l l c m i x t u r e w l w r f h l l c s e d k w l w r f h l l c s e d k w l w r f h l l c s e d k w l w r where w l w r are the two conservative variable vectors at the left and right side of the face m which are used by the hllc type riemann solver see the appendix a the subscripts l r indicates the left and right sides respectively for convenience in description the three elements of the vector w are represented by w 1 w 1 w 2 and w 1 w 3 for the mixture part 29 w 1 h w 2 u w 3 v for the k th sediment size part 30 w 1 h c k w 2 u s k w 3 v s k in the present model the first order method is used by setting the riemann states w l w r directly equal to the values of the conserved variables at the neighboring cell center to ensure non negative water depth reconstruction the following modifications on the left and right riemann states must be implemented audusse et al 2004 firstly the bed elevations at two sides are estimated as follows 31a z b m l η b m l h m l z b m r η b m r h m r secondly the water depth at two sides are modified as 32b h m l max 0 η b m l z b m h m r max 0 η b m r z b m where z b m max z b m l z b m r the specific expressions for the classical hllc type riemann solver can be found in the literature toro 2001 2019 and in the appendix a to demonstrate the advantages of the upwind hllc solver for two phase shsm modeling another two phase shsm model is also developed with the centered force solver for which no information of the eigenvalues and wave structures are needed the details of the force solver can also be found in the appendix a 3 model performance to demonstrate the performance of the new two phase shsm model convergence rate study is firstly conducted afterwards the new model is tested against a series of flow sediment bed evolutions due to 1 two refilling processes of dredged trenches van rijn 1986 armanini and di silvio 1988 2 two instantaneous dam break flooding flows spinewine and zech 2007 soares frazão et al 2012 and 3 one levee breaching process tingsanchali and chinnarasri 2001 it is appreciated that these flow scenarios have been intensively simulated by quasi single phase shsm models zhao et al 2019 juez et al 2014 meurice and soares frazão 2020 and hu et al 2019 or two phase shsm models that are based on the centered schemes greco et al 2012 di cristo et al 2016 as compared to quasi single phase shsm models the present new model can shed lights on the role of inter phase interaction between water and sediment for example the velocity discrepancy between the sediment phase and the water phase can be resolved by the present two phase shsm model however such inter phase interaction is ignored by the previous single phase shsm models from a perspective of physics this velocity lag may significantly alter bed topography evolution nevertheless comparisons of numerical solutions between the quasi single phase model and the two phase model are not shown in this paper because the focus of this paper is to advance existing two phase shsm modeling capabilities as compared to previous two phase shsm models the present model features improvements in both numerical accuracy and the ability to capture key flow features which will be demonstrated in the following 3 1 convergence rate study an idealized dam break flow over a frictionless dry bed is simulated on successively refined meshes the averaged mesh sizes are 0 2 m 0 1 m 0 05 m and 0 025 m respectively a square domain of 20 1 m2 is considered the bed is initially dry for x 0 m and the initial water depth h 0 for x 0 m is set to 0 6 m the analytical solution for the water depth is as follows 33 h x y t h 0 x x a t 4 9 g g h 0 x x 0 2 t 2 x a t x x b t 0 x x b t where x a t t g h 0 and x b t 2 t g h 0 fig 3 presents comparisons between the exact solutions and the numerical solutions water depth on successive refined meshes by the two phase shsm model using a the hllc solver and b the force solver from fig 3 the computed water depth by both solvers agree with the analytical solutions quite well for which the discrepancy between the numerical and the analytical solutions decreases as the mesh size is refined standard norms l 1 and l between the computed and analytical solutions of the water depth are computed based on which the relative convergence rates are estimated table 1 shows the mesh statistics cell number averaged cell sizes the standard norms l 1 l and the relative convergence rates at t 0 5s from table 1 the orders 0 68 0 73 0 75 of accuracy of the hllc solver are consistently higher than those 0 58 0 65 0 73 of the force solver moreover the discrepancies between numerical solutions and analytical solutions e g about 1 61e 2 2 71e 2 4 49e 2 7 2e 2 for different meshes for the hllc solver are consistently smaller than those e g about 2 98e 2 4 93e 2 7 74e 2 1 16e 1 for different meshes for the force solver the computed convergence rates for dam break flow problems using the hllc solver is consistent with previous evaluations prebeg et al 2018 daude et al 2014 afterwards a pure scalar advection process in a horizontal square domain of 10000 1000 m2 petti and bosa 2007 is numerically simulated on successively refined meshes the averaged mesh sizes are 200 m 100 m 50 m 25 m and 12 5 m respectively the bed slopes are sbx 0 001 sby 0 and the bed manning roughness n 0 025 at the upstream boundary a steady flow rate q 0 1243m2 s is imposed to obtain a uniform flow h q n s b x 3 5 and u q h an initially distribution of scalar concentration is imposed at the domain 34 c 0 x y 0 10 e 0 5 x 1400 264 δ 2 6 5 e 0 5 x 2400 264 δ 2 which is a linear superposition of two gaussian distribution the first centred at 1400 m with a peak value of 10 m and the second centred at 2400 m with a peak value of 6 5 both having a standard deviation of 264 m the analytical solution of the scalar concentration is c x y t c 0 x ut y t the simulation time is 9600 s fig 4 illustrates comparisons between the analytical and numerical at 9600 s solutions of scalar concentration on successively refined meshes by the two phase shsm model using a the hllc solver and b the force solver table 2 summarizes the mesh statistics cell number averaged cell sizes the standard norms l 1 and l as well as the relative convergence rates it is obvious from fig 4 and table 2 that the hllc solver is advantageous in simulating sediment advection process as compared to the force solver specifically the order about 0 32 0 41 0 58 0 74 0 24 0 36 0 53 0 70 of the hllc solver is higher than the order about 0 32 0 32 0 31 0 40 0 17 0 21 0 25 0 35 of the force solver the discrepancy about 1 60e 01 for a mesh of 151040 between numerical solutions and analytical solutions for the hllc solver is much smaller than that about 4 04e 01 for a mesh of 151040 for the force solver this confirms previous understanding that a centred solver may spread solution when scalar transport is concerned canestrelli and toro 2012 3 2 refilling of dredged trench two scenarios about refilling of dredged trench are numerically simulated the first scenario concerns the laboratory experiment carried out at a flume of dimensions 30 m length 0 5 m width 0 7 m height by van rijn 1986 at delft hydraulics laboratory case 3 2 1 the geometry of the trench was 0 15 m depth with a slope gradient of 1 10 during the experiment a constant unit inflow discharge of 0 2 m2 s was specified at the inlet with the mean flow depth and velocity stabilizing at 0 39 m and 0 51 m s respectively the bed was composed of fine sand 0 16 mm 2650 kg m3 with a setting velocity of 0 013 m s a porosity of 0 4 the bed roughness is set to 0 011 during the experiment equilibrium sediment transport was maintained at the inlet boundary thus the corresponding equilibrium rate was 0 03 kg m s and the sediment concentration by weight at the cross section was 0 1508 kg m3 the sediment transport capacity is estimated by the wu et al 2000 s formula with the threshold shields parameter equal to 0 03 which is calibrated using the inlet sediment transport rate the empirical parameter α is calibrated as 18 the computational domain covers the entire flume channel based on a sensitivity study on the mesh sizes a total of 3084 triangular cells are used with an averaged cell size of 0 1 m fig 5 shows the bed elevation profiles computed by the models based on hllc and force solvers along with the measurements at t 7 5 h and 15 h despite the observed slight discrepancy between model predictions and measured data the process of refilling of a dredged trench is well reproduced by the two models with bed aggradation due to sediment input occurring in the front end of the trench and bed degradation due to erosion appearing around the tip of the rear edge of the trench as time go on a small amount of the sediment are gradually deposited at the bottom of the trailing edge causing the slope gradient to gradually decrease the relative discrepancy between model prediction and the measured data is quantified by i 1 n m e a δ z b i δ z b m i i 1 n m e a δ z b m i the relative discrepancy is reduced from 9 56 for the force solver to 6 36 for the hllc solver note that this relation of relative discrepancy is used also in the following sections to further evaluate the capability of the two phase model in modelling non uniform sediment transport and morphological evolution an extended case of trench refilling designed by armanini and di silvio 1988 is revisited case 3 2 2 in this case a trench of the rather steep side slope 1 3 was set up and the sediment mixture consisted of two fractions d 1 0 075 mm 50 and d 2 0 3 mm 50 the sediment density is 2650 kg m3 the unit inflow discharge was kept constant as 0 2 m 2 s the computational domain covers the entire flume channel therefore generating a total of 3084 triangular cells and 1853 nodes the following parameters are used li et al 2019 p 0 0 4 n 0 011 a 25 and θ c 0 03 the sediment transport capacity is estimated by the wu et al 2000 s formula fig 6 shows the bed elevation profiles computed by the models based on hllc and force solver along with the armanini solution at t 7 5 h and 15 h the process of refilling of a dredged trench can be also well reproduced by the two models which can demonstrate the two phase models ability to evaluate the non uniform sediment transport rather limited differences in the bed profiles are observed for this case featuring similar performances of the hllc solver force solver and armanini and di silvio 1988 3 3 instantaneous dam break flooding flows and sediment transport in this section two scenarios about instantaneous dam break flooding flows and sediment transport are numerically simulated the first scenario case 3 3 1 concerns full dam break flows in an abruptly widening erodible channel which was conducted at the civil engineering laboratory of the universite catholique de louvain spinewine and zech 2007 the 6 m long flume has a sudden asymmetrical enlargement in the channel width from 0 25 m to 0 5 m at x 4 m fig 7 dam break flows was created by the rapid removal of a thin gate representing an idealized dam which is located at the middle of the flume x 3 m initially the bed was horizontal composed of fully saturated non cohesive sediments diameter 1 82 mm density 2680 kg m3 porosity p 0 0 47 with a thickness of 0 1 m and extended both sides of the gate the initial water depth was 0 25 m upstream of the dam and the bed was dry downstream of the dam at the outlet of the flume a weir was installed to control the downstream water level following previous calibration efforts hu et al 2019 the mpm formula is used for the sediment transport capacity and the following parameters are used bed roughness n 0 024 a 10 and θ c 0 047 the computational domain covers the entire flume channel based on a sensitivity study on the mesh sizes a total of 5182 triangular cells are used with an averaged cell size of 0 03 m a free slip non permeable condition was employed in the upstream boundary and side walls it was observed during the course of the experiment that a hydraulic drop occurred downstream of the weir so the outflow did not affect flow upstream of the weir hence a transmissive condition was imposed at the downstream boundary measurements of stage time series and final bed topography were carried out at several gauges and cross sections the measured data at three gauges labelled p1 p2 and p3 and two cross sections labelled cs1 and cs2 are selected to compare with the model predictions the locations of p1 p2 and p3 as well as cs1 and cs2 were indicated in fig 7 fig 8 shows water level time series computed from models using the hllc and force solvers as well as two phase flow model of greco et al 2012 along with the measured data in general as the dam break flow bore propagates downstream water levels at gauges p1 and p3 undergoes a rapid initial rising followed by a gradual decrease for the gauge p2 at the corner of the enlarged cross section water level experiences a relatively slow increase as can be seen from fig 8 at gauge p1 which is immediately downstream of the dam the water level time series predicted by the three model agree rather well with the observed data however at p2 and p3 located in the abruptly widening area the model using hllc solver performs appreciably better than the other two models when compared to the measured data this phenomenon demonstrates the superiority of hllc solver in shock capturing fig 9 presents measured and computed bed level profiles from these aforementioned models although appreciable discrepancy can be identified the model based on hllc solver agrees well with the measured data as compared to the other models this is further quantitatively confirmed by the relative discrepancy the relative discrepancy by the hllc solver 36 9 for cs1 44 2 for cs2 is much smaller than those by the force solver 64 for cs1 60 for cs2 and those 45 for cs1 65 for cs2 from greco et al 2012 most notably the discrepancy value of model based on hllc solver is about 20 percent smaller than that of its counterpart using force solver fig 10 shows the contour plots of final bed deformation depth with flow velocity vectors for the water sediment mixture and the sediment phase predicted by models based on hllc solver and force solver respectively note that the velocity plots produced using the original triangular mesh look ugly we have interpolated the velocity on structured meshes based on which the velocity plots are produced both models have reproduced the phenomenon that intense bed erosion occurs downstream of the dam and then the eroded sediments are deposited downstream of the right side of the enlarged cross section and form a stripe of bed aggradation moreover the depth averaged velocity of the sediment phase is shown to be remarkably lower than that of the water sediment mixture according to the results by model using hllc solver a vortex is formed at the corner of the enlarged cross section whereas this behavior is not exhibited from the results due to model based on force solver the second scenario case 3 3 2 concerns partial dam break flows in a straight erodible channel by soares frazao et al 2012 the flume is of 35 m length and 3 6 m width fig 11 the partial dam break was created by rapid lifting the 1 m wide gate which was originally located in the middle of the flume and between two imperious blocks the rigid bed of the flume was covered by a 0 85 m thick layer of fully saturated sands with median diameter 1 61 mm and density 2630 kg m3 which extended from 1 m upstream of the gate to 9 m downstream of the gate the outlet of the flume consisted of a weir and sediment entrapment system initially the water level inside the reservoir was 0 47 m and the downstream reach was dry the experiment lasted for 20 s measurements of water levels and final bed elevations were conducted in two repeated experiment runs given the above experimental setup labelled mea 1 and mea 2 respectively water level measurements were undertaken at eight gauges during the course of both experiment runs gauges 1 4 were located along x 0 64 m withy 0 5 0 165 0 165 and 0 5 m respectively gauges 5 8 were along x 1 94 m with y 0 99 0 33 0 33 and 0 99 m bed elevation measurements were carried out at the end of the two experiments i e t 20 s with data available for three longitudinal lines y 0 2 0 7 and 1 45 m following calibrations by hu et al 2019 p 0 0 47 n 0 0165 for the sand bed region and n 0 01 for otherwise and parameter α is set equal to 5 the sediment transport capacity is estimated by the mpm relation with θ c 0 04 the computational domain covers the entire flume channel with a total of 21440 triangular cells with the average cell size of 0 1 m fig 12 presents the computed water level time series at four gauges computed from the hllc solver the force solver and di cristo et al 2016 along with the measured data in general with the propagation of dam break flow toward to the outlet water levels at all gauges undergo a rapid increase at the early stage and then decrease gradually fig 13 shows the measured and predicted final bed elevation profiles along three longitudinal lines i e a y 0 2 m b y 0 7 m and c y 1 45 m from the aforementioned three models in fig 13 considerable discrepancies between the two sets of measured bed elevation profiles are observed especially in the near downstream of the dam although the two experiment runs are conducted under the same setup it indicates the bed change near the dam region is very sensitive and uncertain even to trivial disturbances in doing the experiments as can be seen from figs 12 and 13 less accurate results are observed in the near downstream region of the dam this is arguably because the flow region around the corners of the expansion are characterized by strong and complicated 3 d flow structure which however cannot be well captured by the depth averaged models moreover as compared to the other models numerical predictions of maximum values of bed scouring and deposited depth by hllc model are closer to measured data in the far downstream region where close agreement is observed between the two sets of measurement the accuracy of the predicted bed level is much improved in all models this is further quantitatively confirmed by the relative discrepancy the relative discrepancy by the hllc solver about 62 5 is much smaller than those by the force solver 74 7 and those 72 1 from di cristo et al 2016 fig 14 presents the flow velocity vectors for the water phase and the sediment phase at different time instants computed from hllc sovler and force sovler in general the water phase moves faster than the sediment phase at the early stage i e t 2 s the velocity difference between the water and sediment phases is relatively small as the dam break flow is energetic enough to carry the sediments at almost the same velocity later when the flow energy decreases i e t 5 s such difference grows as the grains decelerate more rapidly and move slower as compared to the water phase comparatively the hllc model is able to capture the vortex when dam break flow hits the sidewalls echoing the findings from di cristo et al 2016 however the force model fails to reproduce such behavior possibly leading to the distortion of deposition and erosion 3 4 levee breaching by overtopping flows here the experimental levee breaching process by overtopping flows which was reported by tingsanchali and chinnarasri 2001 is numerically simulated case 3 4 this experiment has been widely applied to verify the performance of the hydro sediment model wu and wang 2008 zhao et al 2019 martínez aranda murillo and garcía navarro 2019 mahdizadeh and sharifi 2021 the flume is 35 m long and 1 m wide a dyke of 0 8 m high and 1 m wide is placed at the middle of the flume with a crest width of 0 3 m the upstream and downstream slopes of the dyke are 1 3 and 1 2 5 see fig 15 the bottom of upstream and downstream of the dyke is fixed and unmovable and the dyke is made of medium sand with a diameter of d 1 13mm and ρ s 2650kg m 3 the sediment transport capacity is estimated by mpm formulation p 0 0 47 n 0 024 α h ω δ t and θ c 0 047 based on a sensitivity study on mesh sizes a total of 5182 triangular cells and 2802 nodes is generated with an averaged size of 0 01 m fig 16 presents the measured and computed at 30 s and at 60 s bed level profiles from these aforementioned quasi single phase models and the present two phase models from fig 16 model predictions by the two phase model with hllc solver appears to agree better with the measured data as compared to the two phase model with force solver and other quasi single phase models the averaged relative discrepancy is 19 06 for the two phase model with the hllc solver whereas it is 35 27 for the two phase model with the force solver as compared to these previous quasi single phase models the quantitative accuracy of the present two phase model is not only satisfactory but also can resolve the complex interactions between the water phase and the sediment phase 3 5 evaluation of the computational efficiency while the hllc solver is more accurate than the force solver the former is more complex than the later see the appendix inevitably this will induce some extra computational cost nevertheless it is expected that the implementation of the hybrid lts gmats can overcome this extra computational cost in this regard computational cost of three versions of two phase shsm models are compared the traditional version using the force solver and the gmits the present improved version using the hllc solver and the hybrid approach and an intermediate version using the hllc solver and the gmits obviously the intermediate version should be computationally most demanding therefore computational costs of the other two versions is regularized against the intermediate version the resultant statistics of the relative computational cost and the speed ups of the other two versions are presented in table 3 from table 3 the following is observed first in terms of the computational efficiency using the simple force solver can only bring very negligible advantage over the complex hllc solver the speed ups of the force are about 1 07 1 1 which is negligible second implementation of the hybrid lts gmats brings significant improvement in the computational efficiency the corresponding speed ups can be as high as 1 88 for the steady flow scenario refilling of dredged channels and 3 0 3 2 for unsteady flow scenarios full and partial dam breaks levee breaching for simulations in section 3 2 3 4 relatively uniform meshes are adopted if the mesh is locally further refined which is common for natural scale simulations more speed ups can be expected 4 conclusions this paper presents a new depth averaged two phase flow model for hydro sediment morphodynamic processes which is computationally efficient and high resolution based on the hllc riemann solver a hybrid lts gmats approach the two phase shsm models exhibits excellent potential for direct analysis of velocity lag between water and sediment phases and can exhibit encouraging performance as compared to the counterpart using centered force solver and gmits approach when tested against several typical cases concerning flow sediment bed evolution the hllc solver performs much better than force solver in that it not only better captures complex flow behaviors of the water and sediment phases but also appreciably reduces the discrepancy between numerical solution and measured data moreover the implementation of the hybrid lts gmats approach significantly reduces run time and improves computational efficiency further reduction in computational cost is expected when the hybrid approach is combined with parallel computing strategy such as multi gpu and high performance computing hpc clusters the present work facilitates a promising modelling framework to shallow water sediment flows applications of the present model to hydro sediment morphodynamic processes in typical waterways of the yangtze river china are ongoing inevitably the proposed model bears uncertainties arising from closures for boundary resistance and sediment exchange with the bed these still require systematic fundamental investigations into the associated mechanisms declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research is supported by the national natural science foundation of china no 12172331 the changjiang waterway institute of planning and design the zhejiang natural science foundation lr19e090002 and the hpc center of zju zhoushan campus appendix a the hllc solver and the force solver here we presented the specific expressions of the hllc solver and the force solver toro et al 2009 the hllc solver reads a 1 f h l l c w l w r e l s l 0 e l s l 0 s m i d e r s m i d 0 s r e r s r 0 where s l s r and s m i d are three wave speeds computed by eq a 2 e l e l e r and e r are four riemann numerical fluxes estimated by eqs a 5 for the hydro sediment mixture the wave speed s l and s r on the left and right sides are as follows a 2a s l min w l g l w 1 l w g w 1 if w 1 l 0 w r 2 g r w 1 r if w 1 l 0 a 2b s r min w r g r w 1 r w g w 1 if w 1 r 0 w l 2 g l w 1 l if w 1 r 0 the intermediate contact wave speed s m i d is calculated as follows a 2c s m i d w 1 r s l w r s r w 1 l s r w l s l w 1 r s l w r s r w 1 l w l s l where w l r w 2 nx w 3 ny l r are the normal velocities w w 1 are the modified value on both sides of the flux with average methods which can be calculated as follows a 3 w w 1 l w l w 1 r w r w 1 l w 1 r w 1 w 1 l w 1 r 2 the parameters g l r and g in eq a2 should be treated differently for the mixture part and for the sediment part which are as follows for the mixture part g l r g and g g for the k th sediment part a 4 g l r ρ ml r 2 ρ s c kml r g g ρ ml 4 ρ s c kml ρ mr 4 ρ s c kmr g numerical flux vectors in the eq a 1 can be estimated as follows a 5 e l r w 1 w w 1 w 2 w 0 5 g w 1 2 n x w 1 w 3 w 0 5 g w 1 2 n y l r e l r e h l l 1 e h l l 2 n x w e h l l 1 n y e h l l 2 n y w e h l l 1 n x l r where w l r w 2 ny w 3 nx l r represent tangential velocity and the parameter g in eq a5 should also be treated separately for the mixture part and for the sediment part for the mixture part a 6a g g for the k th sediment part a 6b g ρ m l 2 ρ s c k m l ρ m r 2 ρ s c k m r g the flux e h l l is calculated from the hll formula a 7a e h l l s r e w l s l e w r s l s r w r w l s r s l a 7b 1 0 0 0 n x n y 0 n y n x e w l r e w l r the force solver reads a 8 e n m f f o r c e u m l u m r 1 2 f m l f f m l w m 1 n f where u ml u mr are two riemann states immediately at the left and right side of the face as conserved variables f m l f f m l w represent the lax wendroff flux and the lax friedrichs flux which can be estimated as follows a 9a f m l f a m l y u m r n m a m r y u m l n m a m l a m r 2 a m l a m r δ t l i a m l a m r δ l m u m l u m r a 9b f m l w y u m l w n m a 9c u m l w u m r a m r u m l a m l a m r a m l δ t l i δ l m 2 a m r a m l y u m l y u m r n m where n m nmx nmy represents the normal outward direction of the m th face andy u ml r lw n m f u ml r lw nmx g u ml r lw nmy δlm is the length of the m th face aml amr denote the area of the triangle formed by the face and the cell center 
114,in this paper we present a new computationally efficient and high resolution depth averaged two phase flow model for hydro sediment morphydynamic processes featuring an advance over existing models in terms of accuracy and efficiency of numerical solution under the framework of finite volume method fvm on unstructured grids the harten lax van leer contact hllc approximate riemann solver is proposed to compute inter cell fluxes by applying the classical upwind hllc approach to the water sediment mixture and the sediment phases separately in contrast to previous two phase flow models using centered schemes moreover to improve computational efficiency the local time stepping lts approach is implemented the first attempt in the field of two phase flow modelling after a convergence rate study the model is tested against a series of flow sediment bed evolutions induced by 1 two refilling processes of dredged trenches 2 two instantaneous dam break flooding flows and 3 one levee breaching process by overtopping flows it features encouraging performance when compared to a two phase flow model based on a centered scheme and global time bound characterized by more accurate results and much less computational cost the present modelling framework shows promise in practical shallow water hydro sediment morphodynamic modelling applications keywords hydro sediment morphodynamic process two phase flow modeling hllc riemann solver local time step globally maximum time step 1 introduction refined and efficient modelling of shallow water hydro sediment flows is important for not only river engineering practice but also flood risk management the last two decades have witnessed increasingly widespread applications of shallow water depth averaged hydro sediment morphodynamic shsm models and their variants cao et al 2017 however existing shsm models are mostly based on the single phase premise hoey and ferguson 1994 armanini and disilvio 1998 cao et al 2011 2017 guy and castelltort 2006 wu and wang 2008 canestrelli and toro 2012 hu et al 2012 2014 2018 2019 juez et al 2014 zhao et al 2019 meurice and soares frazão 2020 in these models the velocities of the sediment phases are assumed equal to the mixture velocity or are empirically determined by the mixture velocity along with a modification coefficient less than unity consequently the relative motions and interactions between water and sediment phases are not incorporated in fact not only is the advection velocity of bedload appreciably lower than the flow greimann et al 2008 but also a velocity lag between the flow and the suspended sediments has been observed muste et al 2005 in this regard a two phase model is certainly warranted there have been different types of two phase models for shallow water hydro sediment flows for example vertical 2d two phase models were used to investigate the vertical sediment concentration distributions bakhtyar et al 2009 chen et al 2011 meshfree sph two phase models were used to tackle problems with strong free surface variations shi et al 2017 2019 the two phase shsm models which are the present topic have been developed for not only fluvial processes greco et al 2012 di crisco et al 2016 li et al 2018 2019 2020 but also earth surface flows such as debris flows and granular flows e g pitman and le 2005 pudasaini 2012 it is appreciated that bedload occurs mainly in a thin layer on the top of the erodible bed surface where the sediment concentration is much higher than the depth averaged value in this regard a two layer two phase model may also be appealing zech et al 2008 martínez aranda et al 2019 which is reserved for future study unless otherwise stated the present two phase shsm models are all depth averaged versions in the last decades the shock capturing finite volume method has been widely used to deal with shallow water modeling challenges such as wet dry treatments capturing shock contact discontinuities greco et al 2012 di crisco et al 2016 li et al 2018 2019 2020 however existing two phase shsm models have still suffered from two major shortcomings first existing two phase shsm models exclusively employ the centered schemes or more simplified method to estimate the inter cell numerical flux greco et al 2012 di crisco et al 2016 li et al 2018 2019 2020 while using a centered scheme avoids the difficulty of managing complex wave structures by minimizing the use of eigenvalues they tend to spread the solution more than upwind schemes e g the hllc riemann solver and the roe riemann solver in particular when multi dimensional problems are studied vortices are excessively dissipated by numerical diffusion as well as any shear flow canestrelli and toro 2012 moreover when passive scalars are conveyed centered schemes may also spread the solution the hllc riemann solver which represents a classical upwind scheme by making full use of the eigen structures will be adopted for the present two phase shsm model a major challenge for applying the hllc solver in two phase shsm models is their complex eigen structures arising from the additional momentum equations of the sediment phases briefly the hllc riemann solver was developed for 3 wave riemann structures toro 2001 2019 whereas the two phase flow model even if a single sized sediment transport is assumed would produce 6 wave speeds and 7 riemann fields moreover if the momentum source terms are included into the riemann structures an additional stationary wave may appear murillo and garcía navarro 2012 furfaro and saurel 2015 also appreciated the difficulty for applying the hllc solver to the compressible fluid fluid two phase flows that have seven wave speeds furfaro and saurel 2015 proposed to use the hllc solver separately for different phases because each fluid phase has its own set of mass momentum and energy balancing equations this strategy is extended to present two phase shsm model specifically the entire system is split into a mixture part and several parts of different sediment sizes facilitating usage of the hllc solver second the attractiveness of existing two phase shsm models is limited by its relatively high computational cost specifically existing two phase shsm models have employed the globally minimum time step gmits for variable updating that is the globally minimum value of all locally allowable maximum time steps which are computed by the courant friedrichs lewy cfl stability condition is used for most cells however the gmits is much smaller than the locally allowable maximum time steps in contrast to the gmits an alternative appealing method is the hybrid local time step lts globally maximum time step gmats by this hybrid approach updating of the hydro sediment module is completed by using local time steps close to the locally maximum time steps as much as possible sanders 2008 whereas updating of the morphodynamic model is completed by using the gmats it has been demonstrated that this hybrid approach can bring significant reduction in the computational cost of quasi single phase shsm models hu et al 2019 however it has been rarely reported for two phase shsm models furthermore gpu acceleration is also an important option for improving the computational efficiency ingelsten et al 2020 conde et al 2020 martínez aranda et al 2022 sweet et al 2018 which is reserved for future study this paper presents a new computationally efficient and high resolution depth averaged two phase model for hydro sediment morphodynamic processes mathematical formulations are presented in section 2 specifically the governing equations are solved by the finite volume method on unstructured triangular cells the inter cell numerical flux is estimated by the hllc solver which is novel as compared to previous two phase shsm models that are mostly based on centered schemes for variable updating the hybrid lts gmats approach is implemented which to the authors best knowledge has rarely been reported for two phase shsm modelling moreover the model is parallelized by using the open mp technique in section 3 the convergence rate studies are firstly conducted afterwards the new two phase shsm model is tested against a series of flow sediment bed evolutions due to 1 two refilling processes of dredged trenches 2 two instantaneous dam break flooding flows and 3 one levee breaching process by overtopping flows particular attention is given to its improved quantitative accuracy and enhanced computational efficiency as compared to previous two phase shsm models greco et al 2012 di cristo et al 2016 the paper is concluded in section 4 2 mathematical formulations 2 1 governing equations and empirical closures consider shallow water sediment flows over an erodible bed composed of non cohesive sediment with nsps size classes let dk denote the diameter of the k th sediment size where subscript k 1 2 nsps the proposed model is a two dimensional extension of the one dimensional depth averaged two phase flow model li et al 2019 the governing equations comprise mass and momentum conservation equations for the water sediment mixture the sediment phases and the mass conservation equations for the bed material the resulting system of equations can be expressed in standard well structured conservation form as follows 1 u t f x g y s b s τ s f s m s s 2 u h h u h v h c k h c k u s k h c k v s k f h u h u 2 g h 2 2 h u v h u s k c k h c k u s k 2 ρ c k g h 2 2 ρ s h c k u s k v s k g h v h u v h v 2 g h 2 2 h v s k c k h c k u s k v s k h c k v s k 2 ρ c k g h 2 2 ρ s s b 0 g h s b x g h s b y 0 ρ g h c k s b x ρ s ρ g h c k s b y ρ s s τ 0 τ b x ρ τ b y ρ 0 τ s k b x ρ s τ s k b y ρ s s f n m n m x n m y 0 n s k x n s k y s m f ρ 0 ρ u f ρ ρ 0 ρ v f ρ e k d k 0 0 s s 0 r g h 2 2 c x r g h 2 2 c y 0 1 2 g h 2 c k x 1 2 g h 2 c k y and bed deformation equation 3 z b t d t e t 1 p 0 as well as the active layer equation 4 δ f a k t d k e k 1 p 0 f s k η t where u represents the vector of the conserved variables f gare the vectors of the flux variables s b denotes the vector of the bed slope s τ denotes the vector of the friction source terms s f is the vector containing physically based contributions from the interactions between the water and sediment phases and sediment sediment phases s m is the vector of the source terms representing mass and momentum contributions from bed exchange and s s is the vector of the source terms representing momentum contributions derived of decoupling the flow density from the mass and momentum conservative variables t is the time x y are the spatial horizontal coordinates in the cartesian coordinate system h is the depth of the water sediment mixture zb is the bed elevation g 9 8 m2 s is the gravitational acceleration u v are the depth averaged velocities of the water sediment mixture in the x and y directions respectively usk vsk are the depth averaged size specific velocities of the sediment phase in the x and y directions ck is the depth averaged size specific volumetric sediment concentration r ρ s ρ f ρ ρ ρ f 1 c ρ s c is the density of the water sediment mixture ρ f 1000 kg m3 and ρ s are the densities of water and sediment respectively c ck is the depth averaged total sediment concentration s b x z b x sby zb y are the bed slopes in the x and y directions τ bx τ fbx τ skbx and τ by τ fby τ skby are the total bed shear stresses for the hydro sediment mixture by which the total bed shear stresses for the water sediment mixture are divided into the bed shear stress components exerted respectively on the water and sediment phases τ fbx and τ fby are the bed resistance stresses for the water phase in the x and y directions τ skbx τ skby are the bed shear stresses for sediment phases in the x and y directions f et dt 1 p 0 et ek and dt dk are the total sediment entrainment and deposition fluxes ek and dk are the size specific sediment entrainment and deposition fluxes p 0 is the bed sediment porosity η zb δ is the bottom elevation of the active layer δ ahd 84 is the thickness of the active layer ah is an empirical coefficient ranging from 1 to 4 d 84 is a characteristic sediment size the subscript 84 means that 84 sediments are finer than d 84 fak is the sediment fractions within the bed active layer fsk is the sediment fractions at the interface between the active layer and those below the active layer nm nmx nmy nskx nsky are components of the vector s f which are expressed as follows 5a n m ρ s ρ f ρ f h c k u u s k x h c k v v s k y 5b n m x 1 ρ x h ρ s c k i s k x i s k x i f x 1 ρ y h ρ s c k i s k x i s k y i f y 5c n m y 1 ρ y h ρ s c k i s k y i s k y i f y 1 ρ x h ρ s c k i s k y i s k x i f x 5d n s k x 1 ρ s f s k f x f s s k x 5e n s k y 1 ρ s f s k f y f s s k y where ρ0 ρ f p 0 ρ s 1 p 0 is the density of bed materials i s k x u s k u i s k y v s k v are inter phase velocity discrepancy between the size specific sediment phase and the water sediment mixture ifx uf u ify vf v denote velocity discrepancy between the water phase and the water sediment mixture uf and vf are the depth averaged velocity of the water phase eq 6a 6b fskfx ρ f drkh uf usk fskfy ρ f drkh vf vsk are the size specific depth averaged interphase interaction forces drk is a function related to the drag coefficient see eq 7a 7b f s skx and f s sky are the size specific depth averaged particle particle interactive drag forces eq 8a 8b 6a u f ρ u ρ s u s k c k ρ f 1 c 6b v f ρ v ρ s v s k c k ρ f 1 c 7a d r k 150 c k 2 ν μ f 1 c k d k 2 7 c k 4 d k u f u s k 2 v f v s k 2 i f c k 0 2 3 c d 1 c k c k 4 d k 1 c k 2 65 u f u s k 2 v f v s k 2 i f c k 0 2 7b c d 24 1 0 15 r e k 0 687 r e k i f r e k 1000 0 44 i f r e k 1000 8a f s s k x 1 2 c ρ g h 2 c k x c k c ρ s c k c c s d u s k u s h c k ρ s ν d h c k x c k c 8b f s s k y 1 2 c ρ g h 2 c k y c k c ρ s c k c c s d v s k v s h c k ρ s ν d h c k y c k c where r e k 1 c u f u s k 2 v f v s k 2 d k ν μ f νμf 10 6 m 2 s is the kinematic viscosity of fluid phase csd 6 3s 1 is the liner drag coefficient v d 1 26 1 0 5 m 2 s 2 is the linear diffusive coefficient hill and tan 2014 u s c k u s k c v s c k v s k c are mean sediment velocity by eq 7a 7b the interphase drag force is determined by combining the ergun equation for dense water sediment mixtures and the power law for dilute suspensions gidaspow 1994 by eq 8a 8b the inter grain size interaction force includes a linear velocity dependent drag force an inter grain size surface interaction force and a remixing force gray and chugunov 2006 hill and tan 2014 eqs 9 10 present empirical relations for bed resistance from the water phase using the manning roughness and for the sediment phase using the coulomb friction law savage and hutter 1989 respectively 9 τ f b x ρ f g n 2 u f u f 2 v f 2 h f 1 3 τ f b y ρ f g n 2 v f u f 2 v f 2 h f 1 3 10 τ s k b x ρ s ρ f g h c k tan ϕ b e d u s k u s k 2 v s k 2 τ s k b y ρ s ρ f g h c k tan ϕ b e d v s k u s k 2 v s k 2 where n is the manning roughness hf h 1 c is the depth of the water phase the parameter tan φ bed expresses the collinearity of shear stress and normal stress φ bed is s the friction angle of the sheared granular material while it has been demonstrated that the dynamic pore fluid pressure i e the excess of pressure within the liquid phase respect to the hydrostatic value is important for very dense packed water solid flows mcardell et al 2007 iverson et al 2010 such as debris flows hungr and mcdougall 2009 george and iverson 2014 the present study used the coulomb relation savage and hutter 1989 for the sediment resistance which expresses the collinearity of shear stress and normal stress through a friction coefficient this relation implicitly indicates that the pressure within the liquid phase at the bed surface is hydrostatic which is reasonable because in the present cases all sediment volume concentrations are below 0 1 sediment exchange with the bed is estimated by eqs 11 11 d k α k c k ω k e k α k c e k ω k where ω k is the settling velocity for sediment of diameter dk which is calculated using the zhang 1961 formulation cek is the size specific depth averaged sediment transport capacity of which the estimation will be introduced in the specific case study and the parameter α k represents the difference between the near bed concentration and the depth averaged concentration is estimated with an upper limit α k h ω k δ t derived by hu et al 2014 eq 12 presents empirical relation for the fraction fsk at the lower boundary of the active layer hoey and ferguson 1994 12 f s k f s k 0 η t 0 f a k η t 0 where f s k 0 is the sediment fraction of the k th size sediment in the substrate layer 2 2 time step estimations fig 1 shows sketches of internal triangular cells a triangular cell has three nodes three faces and three neighboring cells fig 1a and a face has two nodes and is shared by two neighboring cells fig 1b the total number of cells is nc and the total number of faces is nf in fig 1a rij is the distance from cell i center to its j th face where the i indicates the sequence of the cells and j indicates the j th face of the cell i with j 1 2 3 ai is the area of the cell i δlij is the length of the j th face of the cell i n ij nx ny ij represents the normal outward direction of the j th face of the cell i physical conserved variables shown in fig 1 will be introduced when they appear in the mathematical formulations below the locally allowable maximum time step δtami where the subscript am indicates allowable maximum is firstly estimated as follows 13 δ t am i c r min j 1 2 3 k 1 n s p s r i j u i j 2 v i j 2 g h i r i j u s k i j 2 v s k i j 2 0 5 ρ i g h i ρ s i 1 2 3 n c where cr is the courant number which is set as 0 9 in this paper and hi ρ i are the depth and the density for the hydro sediment mixture at cell i uij vij uskij vskij are velocities of the j th face of the cell i traditional models always use the globally minimum time step δtgmi to update the physical variables and here we use the approach of the local graded time step presented by hu et al 2019 the potential graded lts level for every cell is computed as 14a m i min int log δ t a m i δ t g m i log 2 m u s e r i 1 2 3 n c 14b δ t g m i min i 1 n c δ t a m i where m u s e r is a user defined upper limit value setting m u s e r 0 means the graded levels of all cells are zero which will make the model equivalent to the gmits model the model further modifies the lts level of neighboring cells that are characterized by abrupt flow regime changes i e the wet dry front and the static dynamic front of both sediment and water specifically lts level of such neighboring cells are set to a locally minimum value the actual grade level mfm for face m is computed as follows 15 m f m min m m l m m r m 1 2 3 n f where mml mmr represent the potential graded levels of two neighboring cells of face m see fig 1b the potential graded time step level of each cell is finally computed in the following 16 m i min m i m i 1 m i 2 m i 3 i 1 2 3 n c where m i1 m i2 m i3 represents the potential graded level of the three neighboring cells of cell i afterwards the graded local time step is computed as 17 δ t l i 2 m i δ t g m i i 1 2 3 n c finally the gmats can be computed as 18 δ t max δ t l i i 1 2 3 n c 2 3 finite volume discretization as shown in eqs 19 21 the hybrid lts gmats approach is used for variable updating specifically the hydro sediment part is updated by the lts and the morphodynamic part are updated by gmats see fig 2 for a summary 19 u i u i δ t l i a i j 1 3 e n i j δ l i j δ t l i s b i s τ i s f i s m i s s i 20 z b i t 0 δ t z b i t 0 s c 1 n p δ t l i d t i s c e t i s c 1 p o 21 δ f a k i t 0 δ t δ f a k i t 0 s c 1 n p δ t l i d k i s c e k i s c 1 p o f s k i s c 1 n p δ t l i d t i s c e t i s c 1 p o where e n i j f n x g n y i j is the numerical flux crossing the j th face of the cell i which is estimated by approximate riemann solvers see section 2 4 the superscripts and represents two consecutive sub time levels the temporal interval is δt l i between t 0 and t 0 δt the temporal interval between the two synchronized time levels t 0 and t 0 δt is termed a full cycle np δt δtgmi is the maximum number of sub cycles in the full cycle and the symbol sc is used to indicate the sequence of sub cycles with s c 1 2 n p within a full cycle the hydro sediment morphodynamic system will be updated from one synchronized time level to the next to complete such update the morphodynamic part at all cells is updated only once eqs 20 21 whereas the times that the hydro sediment part has to be updated at a specific cell i is equal to the ratio δt δt l i eq 19 if δ t l i 2 m i δ t min the times that the hydro sediment part at cell i is updated are n p 2 m i indicating that hydro sediment part in cell i will be updated every 2 m i sub cycles in a specific sub cycle sc the implementation of the hydro sediment part is activated if this inequality m i l s s c is satisfied where ls is a function of the sequence sc see hu et al 2019 for the function whereas estimation of numerical fluxes in a specific sub cycle depends on whether mod s c 1 2 m f m 0 if the hydro sediment part is to be updated in the sc sub cycle the source terms would also be estimated otherwise the source terms in the s b i sub cycle take zero value specifically the source terms for the bed slope sc are evaluated using the slope flux method hou et al 2013 with flow variables at the sub cycle but bed elevations at the initial synchronized time level as input the vectors s s i s t i s f i and s m i are evaluated explicitly using empirical relations with flow variables at the time level after updating s b i and s n i j as input to overcome numerical instabilities arising from the relatively large spatial and time steps that lead to an issue of stiff source term the following numerical treatments are proposed to attach the implementation of theoretically derived lower and upper limits for the inter phase interactive forces for updating momentum equations of hydro sediment mixture modified source term s x i m i x t u r e s τ i 2 s s i 2 s f i 2 and s y i m i x t u r e s τ i 3 s s i 3 s f i 3 in the x y direction can be defined as 22a s x i m i x t u r e max s x i m i x t u r e h i u i δ t l i u i 0 min s x i m i x t u r e h i u i δ t l i u i 0 22b s y i m i x t u r e max s y i m i x t u r e h i v i δ t l i v i 0 min s y i m i x t u r e h i v i δ t l i v i 0 for updating momentum equations of sediment phase with the size dk modified source term can be defined as 23a s x i s e d k max s x i s e d k h c k u s k i δ t l i u s k i 0 min s x i s e d k h c k u s k i δ t l i u s k i 0 min s x i s e d k h c k u f i h c k u s k i δ t l i u s k i 0 max s x i s e d k h c k u f i h c k u s k i δ t l i u s k i 0 23b s y i s e d k max s y i s e d k h c k v s k i δ t l i v s k i 0 min s y i s e d k h c k v s k i δ t l i v s k i 0 min s y i s e d k h c k v f i h c k v s k i δ t l i v s k i 0 max s y i s e d k h c k v f i h c k v s k i δ t l i v s k i 0 for the subcritical inflowing boundary face the unit discharge and unit width sediment transport rate or the sediment concentration must be given the tangential velocity to the face is set to zero the water depth and the normal flow velocities are estimated by the method of characteristics for supercritical outlet boundary face and a wall boundary face all physical variables at the face are set equal to the values at the neighboring cell 2 4 estimation of numerical flux using the hllc riemann solver estimation of the inter cell numerical fluxes e g e n i j for the j th face of the cell i is of high importance for high resolution two phase shsm modeling one aim of this paper is to apply the hllc riemann solver to estimate the numerical flux which makes full use of the eigen structures and thus is more accurate than the widely adopted centered schemes to derive the eigenvalues the governing equations are rewritten in the jacobian matrix form as follows 24a u t j u u x u y s b s τ s f s s s m with the jacobian matrix reads 24b j u f n x g n y u 0 n x n y 0 0 0 0 0 0 a 21 a 22 a 23 0 0 0 0 0 0 a 31 a 32 a 33 0 0 0 0 0 0 0 0 0 0 0 n x 0 n y 0 0 n x n y 0 0 0 0 0 0 n x 0 n y a 51 1 0 0 a 54 1 0 a 55 1 0 a 56 1 0 a 51 k a 54 k a 55 k a 56 k a 51 n s p s 0 0 0 a 54 n s p s 0 a 55 n s p s 0 a 56 n s p s a 61 1 0 0 a 64 1 0 a 65 1 0 a 66 1 0 a 61 k a 64 k a 65 k a 66 k a 61 n s p s 0 0 0 a 64 n s p s 0 a 65 n s p s 0 a 66 n s p s where a 21 ghnx uu a 22 unx u a 23 uny a 31 g h n y v u a 32 vnx a 33 u vny a 51 k ρ g h c k n x 2 ρ s a 61 k ρ g h c k n y 2 ρ s a 54 k ρ g h n x 2 ρ s u s k u s k a 64 k ρ g h n y 2 ρ s v s k u s k a 55 k usknx u sk a 65 k v sk nx a 56 k uskny a 66 k u s k v s k n y and u sk usknx vskny u unx vny are the velocities perpendicular to the cell face the eigenvalues λ can be estimated from j λi 0 where i is the unit matrix and thus are the roots of the following characteristic polynomial 25 λ u λ u 2 g h k 1 n s p s λ u s k δ λ u s k δ 2 ρ g h 2 ρ s 0 there are 3nsps 3 roots for eq 25 corresponding to the 3nsps 3 distinct eigenvalues however the hllc riemann solver was designed for 3 wave system to overcome this challenge these distinct eigenvalues are grouped into nsps 1 parts one part for the water sediment mixture eq 26 and nsps part for the nsps sediment sizes eq 27 for the hydro sediment mixture λ 1 m i x t u r e u and 26 λ 2 3 m i x t u r e u g h for the k th sediment phase λ 1 s e d k u s k and 27 λ 2 3 s e d k u s k ρ g h 2 ρ s where λ 1 2 3 m i x t u r e are eigenvalues related to the motion of the hydro sediment mixture and λ 1 2 3 s e d k for the k th sediment size respectively it is obvious from eqs 26 27 that each part consists of three eigenvalues which can be used to construct an independent 3 wave system and thus facilitates the implementation of the hllc riemann solver take the estimation of the numerical flux e nm at the face m as an example the numerical flux should be also split into nsps 1 parts eq 28 one part for the hydro sediment mixture f h l l c m i x t u r e w l w r and nsps part for the nsps sediment sizes f h l l c s e d k w l w r k 1 nsps 28 e n m e n m mixture e n m s e d 1 e n m s e d k e n m s e d n s p s f h l l c m i x t u r e w l w r f h l l c s e d k w l w r f h l l c s e d k w l w r f h l l c s e d k w l w r where w l w r are the two conservative variable vectors at the left and right side of the face m which are used by the hllc type riemann solver see the appendix a the subscripts l r indicates the left and right sides respectively for convenience in description the three elements of the vector w are represented by w 1 w 1 w 2 and w 1 w 3 for the mixture part 29 w 1 h w 2 u w 3 v for the k th sediment size part 30 w 1 h c k w 2 u s k w 3 v s k in the present model the first order method is used by setting the riemann states w l w r directly equal to the values of the conserved variables at the neighboring cell center to ensure non negative water depth reconstruction the following modifications on the left and right riemann states must be implemented audusse et al 2004 firstly the bed elevations at two sides are estimated as follows 31a z b m l η b m l h m l z b m r η b m r h m r secondly the water depth at two sides are modified as 32b h m l max 0 η b m l z b m h m r max 0 η b m r z b m where z b m max z b m l z b m r the specific expressions for the classical hllc type riemann solver can be found in the literature toro 2001 2019 and in the appendix a to demonstrate the advantages of the upwind hllc solver for two phase shsm modeling another two phase shsm model is also developed with the centered force solver for which no information of the eigenvalues and wave structures are needed the details of the force solver can also be found in the appendix a 3 model performance to demonstrate the performance of the new two phase shsm model convergence rate study is firstly conducted afterwards the new model is tested against a series of flow sediment bed evolutions due to 1 two refilling processes of dredged trenches van rijn 1986 armanini and di silvio 1988 2 two instantaneous dam break flooding flows spinewine and zech 2007 soares frazão et al 2012 and 3 one levee breaching process tingsanchali and chinnarasri 2001 it is appreciated that these flow scenarios have been intensively simulated by quasi single phase shsm models zhao et al 2019 juez et al 2014 meurice and soares frazão 2020 and hu et al 2019 or two phase shsm models that are based on the centered schemes greco et al 2012 di cristo et al 2016 as compared to quasi single phase shsm models the present new model can shed lights on the role of inter phase interaction between water and sediment for example the velocity discrepancy between the sediment phase and the water phase can be resolved by the present two phase shsm model however such inter phase interaction is ignored by the previous single phase shsm models from a perspective of physics this velocity lag may significantly alter bed topography evolution nevertheless comparisons of numerical solutions between the quasi single phase model and the two phase model are not shown in this paper because the focus of this paper is to advance existing two phase shsm modeling capabilities as compared to previous two phase shsm models the present model features improvements in both numerical accuracy and the ability to capture key flow features which will be demonstrated in the following 3 1 convergence rate study an idealized dam break flow over a frictionless dry bed is simulated on successively refined meshes the averaged mesh sizes are 0 2 m 0 1 m 0 05 m and 0 025 m respectively a square domain of 20 1 m2 is considered the bed is initially dry for x 0 m and the initial water depth h 0 for x 0 m is set to 0 6 m the analytical solution for the water depth is as follows 33 h x y t h 0 x x a t 4 9 g g h 0 x x 0 2 t 2 x a t x x b t 0 x x b t where x a t t g h 0 and x b t 2 t g h 0 fig 3 presents comparisons between the exact solutions and the numerical solutions water depth on successive refined meshes by the two phase shsm model using a the hllc solver and b the force solver from fig 3 the computed water depth by both solvers agree with the analytical solutions quite well for which the discrepancy between the numerical and the analytical solutions decreases as the mesh size is refined standard norms l 1 and l between the computed and analytical solutions of the water depth are computed based on which the relative convergence rates are estimated table 1 shows the mesh statistics cell number averaged cell sizes the standard norms l 1 l and the relative convergence rates at t 0 5s from table 1 the orders 0 68 0 73 0 75 of accuracy of the hllc solver are consistently higher than those 0 58 0 65 0 73 of the force solver moreover the discrepancies between numerical solutions and analytical solutions e g about 1 61e 2 2 71e 2 4 49e 2 7 2e 2 for different meshes for the hllc solver are consistently smaller than those e g about 2 98e 2 4 93e 2 7 74e 2 1 16e 1 for different meshes for the force solver the computed convergence rates for dam break flow problems using the hllc solver is consistent with previous evaluations prebeg et al 2018 daude et al 2014 afterwards a pure scalar advection process in a horizontal square domain of 10000 1000 m2 petti and bosa 2007 is numerically simulated on successively refined meshes the averaged mesh sizes are 200 m 100 m 50 m 25 m and 12 5 m respectively the bed slopes are sbx 0 001 sby 0 and the bed manning roughness n 0 025 at the upstream boundary a steady flow rate q 0 1243m2 s is imposed to obtain a uniform flow h q n s b x 3 5 and u q h an initially distribution of scalar concentration is imposed at the domain 34 c 0 x y 0 10 e 0 5 x 1400 264 δ 2 6 5 e 0 5 x 2400 264 δ 2 which is a linear superposition of two gaussian distribution the first centred at 1400 m with a peak value of 10 m and the second centred at 2400 m with a peak value of 6 5 both having a standard deviation of 264 m the analytical solution of the scalar concentration is c x y t c 0 x ut y t the simulation time is 9600 s fig 4 illustrates comparisons between the analytical and numerical at 9600 s solutions of scalar concentration on successively refined meshes by the two phase shsm model using a the hllc solver and b the force solver table 2 summarizes the mesh statistics cell number averaged cell sizes the standard norms l 1 and l as well as the relative convergence rates it is obvious from fig 4 and table 2 that the hllc solver is advantageous in simulating sediment advection process as compared to the force solver specifically the order about 0 32 0 41 0 58 0 74 0 24 0 36 0 53 0 70 of the hllc solver is higher than the order about 0 32 0 32 0 31 0 40 0 17 0 21 0 25 0 35 of the force solver the discrepancy about 1 60e 01 for a mesh of 151040 between numerical solutions and analytical solutions for the hllc solver is much smaller than that about 4 04e 01 for a mesh of 151040 for the force solver this confirms previous understanding that a centred solver may spread solution when scalar transport is concerned canestrelli and toro 2012 3 2 refilling of dredged trench two scenarios about refilling of dredged trench are numerically simulated the first scenario concerns the laboratory experiment carried out at a flume of dimensions 30 m length 0 5 m width 0 7 m height by van rijn 1986 at delft hydraulics laboratory case 3 2 1 the geometry of the trench was 0 15 m depth with a slope gradient of 1 10 during the experiment a constant unit inflow discharge of 0 2 m2 s was specified at the inlet with the mean flow depth and velocity stabilizing at 0 39 m and 0 51 m s respectively the bed was composed of fine sand 0 16 mm 2650 kg m3 with a setting velocity of 0 013 m s a porosity of 0 4 the bed roughness is set to 0 011 during the experiment equilibrium sediment transport was maintained at the inlet boundary thus the corresponding equilibrium rate was 0 03 kg m s and the sediment concentration by weight at the cross section was 0 1508 kg m3 the sediment transport capacity is estimated by the wu et al 2000 s formula with the threshold shields parameter equal to 0 03 which is calibrated using the inlet sediment transport rate the empirical parameter α is calibrated as 18 the computational domain covers the entire flume channel based on a sensitivity study on the mesh sizes a total of 3084 triangular cells are used with an averaged cell size of 0 1 m fig 5 shows the bed elevation profiles computed by the models based on hllc and force solvers along with the measurements at t 7 5 h and 15 h despite the observed slight discrepancy between model predictions and measured data the process of refilling of a dredged trench is well reproduced by the two models with bed aggradation due to sediment input occurring in the front end of the trench and bed degradation due to erosion appearing around the tip of the rear edge of the trench as time go on a small amount of the sediment are gradually deposited at the bottom of the trailing edge causing the slope gradient to gradually decrease the relative discrepancy between model prediction and the measured data is quantified by i 1 n m e a δ z b i δ z b m i i 1 n m e a δ z b m i the relative discrepancy is reduced from 9 56 for the force solver to 6 36 for the hllc solver note that this relation of relative discrepancy is used also in the following sections to further evaluate the capability of the two phase model in modelling non uniform sediment transport and morphological evolution an extended case of trench refilling designed by armanini and di silvio 1988 is revisited case 3 2 2 in this case a trench of the rather steep side slope 1 3 was set up and the sediment mixture consisted of two fractions d 1 0 075 mm 50 and d 2 0 3 mm 50 the sediment density is 2650 kg m3 the unit inflow discharge was kept constant as 0 2 m 2 s the computational domain covers the entire flume channel therefore generating a total of 3084 triangular cells and 1853 nodes the following parameters are used li et al 2019 p 0 0 4 n 0 011 a 25 and θ c 0 03 the sediment transport capacity is estimated by the wu et al 2000 s formula fig 6 shows the bed elevation profiles computed by the models based on hllc and force solver along with the armanini solution at t 7 5 h and 15 h the process of refilling of a dredged trench can be also well reproduced by the two models which can demonstrate the two phase models ability to evaluate the non uniform sediment transport rather limited differences in the bed profiles are observed for this case featuring similar performances of the hllc solver force solver and armanini and di silvio 1988 3 3 instantaneous dam break flooding flows and sediment transport in this section two scenarios about instantaneous dam break flooding flows and sediment transport are numerically simulated the first scenario case 3 3 1 concerns full dam break flows in an abruptly widening erodible channel which was conducted at the civil engineering laboratory of the universite catholique de louvain spinewine and zech 2007 the 6 m long flume has a sudden asymmetrical enlargement in the channel width from 0 25 m to 0 5 m at x 4 m fig 7 dam break flows was created by the rapid removal of a thin gate representing an idealized dam which is located at the middle of the flume x 3 m initially the bed was horizontal composed of fully saturated non cohesive sediments diameter 1 82 mm density 2680 kg m3 porosity p 0 0 47 with a thickness of 0 1 m and extended both sides of the gate the initial water depth was 0 25 m upstream of the dam and the bed was dry downstream of the dam at the outlet of the flume a weir was installed to control the downstream water level following previous calibration efforts hu et al 2019 the mpm formula is used for the sediment transport capacity and the following parameters are used bed roughness n 0 024 a 10 and θ c 0 047 the computational domain covers the entire flume channel based on a sensitivity study on the mesh sizes a total of 5182 triangular cells are used with an averaged cell size of 0 03 m a free slip non permeable condition was employed in the upstream boundary and side walls it was observed during the course of the experiment that a hydraulic drop occurred downstream of the weir so the outflow did not affect flow upstream of the weir hence a transmissive condition was imposed at the downstream boundary measurements of stage time series and final bed topography were carried out at several gauges and cross sections the measured data at three gauges labelled p1 p2 and p3 and two cross sections labelled cs1 and cs2 are selected to compare with the model predictions the locations of p1 p2 and p3 as well as cs1 and cs2 were indicated in fig 7 fig 8 shows water level time series computed from models using the hllc and force solvers as well as two phase flow model of greco et al 2012 along with the measured data in general as the dam break flow bore propagates downstream water levels at gauges p1 and p3 undergoes a rapid initial rising followed by a gradual decrease for the gauge p2 at the corner of the enlarged cross section water level experiences a relatively slow increase as can be seen from fig 8 at gauge p1 which is immediately downstream of the dam the water level time series predicted by the three model agree rather well with the observed data however at p2 and p3 located in the abruptly widening area the model using hllc solver performs appreciably better than the other two models when compared to the measured data this phenomenon demonstrates the superiority of hllc solver in shock capturing fig 9 presents measured and computed bed level profiles from these aforementioned models although appreciable discrepancy can be identified the model based on hllc solver agrees well with the measured data as compared to the other models this is further quantitatively confirmed by the relative discrepancy the relative discrepancy by the hllc solver 36 9 for cs1 44 2 for cs2 is much smaller than those by the force solver 64 for cs1 60 for cs2 and those 45 for cs1 65 for cs2 from greco et al 2012 most notably the discrepancy value of model based on hllc solver is about 20 percent smaller than that of its counterpart using force solver fig 10 shows the contour plots of final bed deformation depth with flow velocity vectors for the water sediment mixture and the sediment phase predicted by models based on hllc solver and force solver respectively note that the velocity plots produced using the original triangular mesh look ugly we have interpolated the velocity on structured meshes based on which the velocity plots are produced both models have reproduced the phenomenon that intense bed erosion occurs downstream of the dam and then the eroded sediments are deposited downstream of the right side of the enlarged cross section and form a stripe of bed aggradation moreover the depth averaged velocity of the sediment phase is shown to be remarkably lower than that of the water sediment mixture according to the results by model using hllc solver a vortex is formed at the corner of the enlarged cross section whereas this behavior is not exhibited from the results due to model based on force solver the second scenario case 3 3 2 concerns partial dam break flows in a straight erodible channel by soares frazao et al 2012 the flume is of 35 m length and 3 6 m width fig 11 the partial dam break was created by rapid lifting the 1 m wide gate which was originally located in the middle of the flume and between two imperious blocks the rigid bed of the flume was covered by a 0 85 m thick layer of fully saturated sands with median diameter 1 61 mm and density 2630 kg m3 which extended from 1 m upstream of the gate to 9 m downstream of the gate the outlet of the flume consisted of a weir and sediment entrapment system initially the water level inside the reservoir was 0 47 m and the downstream reach was dry the experiment lasted for 20 s measurements of water levels and final bed elevations were conducted in two repeated experiment runs given the above experimental setup labelled mea 1 and mea 2 respectively water level measurements were undertaken at eight gauges during the course of both experiment runs gauges 1 4 were located along x 0 64 m withy 0 5 0 165 0 165 and 0 5 m respectively gauges 5 8 were along x 1 94 m with y 0 99 0 33 0 33 and 0 99 m bed elevation measurements were carried out at the end of the two experiments i e t 20 s with data available for three longitudinal lines y 0 2 0 7 and 1 45 m following calibrations by hu et al 2019 p 0 0 47 n 0 0165 for the sand bed region and n 0 01 for otherwise and parameter α is set equal to 5 the sediment transport capacity is estimated by the mpm relation with θ c 0 04 the computational domain covers the entire flume channel with a total of 21440 triangular cells with the average cell size of 0 1 m fig 12 presents the computed water level time series at four gauges computed from the hllc solver the force solver and di cristo et al 2016 along with the measured data in general with the propagation of dam break flow toward to the outlet water levels at all gauges undergo a rapid increase at the early stage and then decrease gradually fig 13 shows the measured and predicted final bed elevation profiles along three longitudinal lines i e a y 0 2 m b y 0 7 m and c y 1 45 m from the aforementioned three models in fig 13 considerable discrepancies between the two sets of measured bed elevation profiles are observed especially in the near downstream of the dam although the two experiment runs are conducted under the same setup it indicates the bed change near the dam region is very sensitive and uncertain even to trivial disturbances in doing the experiments as can be seen from figs 12 and 13 less accurate results are observed in the near downstream region of the dam this is arguably because the flow region around the corners of the expansion are characterized by strong and complicated 3 d flow structure which however cannot be well captured by the depth averaged models moreover as compared to the other models numerical predictions of maximum values of bed scouring and deposited depth by hllc model are closer to measured data in the far downstream region where close agreement is observed between the two sets of measurement the accuracy of the predicted bed level is much improved in all models this is further quantitatively confirmed by the relative discrepancy the relative discrepancy by the hllc solver about 62 5 is much smaller than those by the force solver 74 7 and those 72 1 from di cristo et al 2016 fig 14 presents the flow velocity vectors for the water phase and the sediment phase at different time instants computed from hllc sovler and force sovler in general the water phase moves faster than the sediment phase at the early stage i e t 2 s the velocity difference between the water and sediment phases is relatively small as the dam break flow is energetic enough to carry the sediments at almost the same velocity later when the flow energy decreases i e t 5 s such difference grows as the grains decelerate more rapidly and move slower as compared to the water phase comparatively the hllc model is able to capture the vortex when dam break flow hits the sidewalls echoing the findings from di cristo et al 2016 however the force model fails to reproduce such behavior possibly leading to the distortion of deposition and erosion 3 4 levee breaching by overtopping flows here the experimental levee breaching process by overtopping flows which was reported by tingsanchali and chinnarasri 2001 is numerically simulated case 3 4 this experiment has been widely applied to verify the performance of the hydro sediment model wu and wang 2008 zhao et al 2019 martínez aranda murillo and garcía navarro 2019 mahdizadeh and sharifi 2021 the flume is 35 m long and 1 m wide a dyke of 0 8 m high and 1 m wide is placed at the middle of the flume with a crest width of 0 3 m the upstream and downstream slopes of the dyke are 1 3 and 1 2 5 see fig 15 the bottom of upstream and downstream of the dyke is fixed and unmovable and the dyke is made of medium sand with a diameter of d 1 13mm and ρ s 2650kg m 3 the sediment transport capacity is estimated by mpm formulation p 0 0 47 n 0 024 α h ω δ t and θ c 0 047 based on a sensitivity study on mesh sizes a total of 5182 triangular cells and 2802 nodes is generated with an averaged size of 0 01 m fig 16 presents the measured and computed at 30 s and at 60 s bed level profiles from these aforementioned quasi single phase models and the present two phase models from fig 16 model predictions by the two phase model with hllc solver appears to agree better with the measured data as compared to the two phase model with force solver and other quasi single phase models the averaged relative discrepancy is 19 06 for the two phase model with the hllc solver whereas it is 35 27 for the two phase model with the force solver as compared to these previous quasi single phase models the quantitative accuracy of the present two phase model is not only satisfactory but also can resolve the complex interactions between the water phase and the sediment phase 3 5 evaluation of the computational efficiency while the hllc solver is more accurate than the force solver the former is more complex than the later see the appendix inevitably this will induce some extra computational cost nevertheless it is expected that the implementation of the hybrid lts gmats can overcome this extra computational cost in this regard computational cost of three versions of two phase shsm models are compared the traditional version using the force solver and the gmits the present improved version using the hllc solver and the hybrid approach and an intermediate version using the hllc solver and the gmits obviously the intermediate version should be computationally most demanding therefore computational costs of the other two versions is regularized against the intermediate version the resultant statistics of the relative computational cost and the speed ups of the other two versions are presented in table 3 from table 3 the following is observed first in terms of the computational efficiency using the simple force solver can only bring very negligible advantage over the complex hllc solver the speed ups of the force are about 1 07 1 1 which is negligible second implementation of the hybrid lts gmats brings significant improvement in the computational efficiency the corresponding speed ups can be as high as 1 88 for the steady flow scenario refilling of dredged channels and 3 0 3 2 for unsteady flow scenarios full and partial dam breaks levee breaching for simulations in section 3 2 3 4 relatively uniform meshes are adopted if the mesh is locally further refined which is common for natural scale simulations more speed ups can be expected 4 conclusions this paper presents a new depth averaged two phase flow model for hydro sediment morphodynamic processes which is computationally efficient and high resolution based on the hllc riemann solver a hybrid lts gmats approach the two phase shsm models exhibits excellent potential for direct analysis of velocity lag between water and sediment phases and can exhibit encouraging performance as compared to the counterpart using centered force solver and gmits approach when tested against several typical cases concerning flow sediment bed evolution the hllc solver performs much better than force solver in that it not only better captures complex flow behaviors of the water and sediment phases but also appreciably reduces the discrepancy between numerical solution and measured data moreover the implementation of the hybrid lts gmats approach significantly reduces run time and improves computational efficiency further reduction in computational cost is expected when the hybrid approach is combined with parallel computing strategy such as multi gpu and high performance computing hpc clusters the present work facilitates a promising modelling framework to shallow water sediment flows applications of the present model to hydro sediment morphodynamic processes in typical waterways of the yangtze river china are ongoing inevitably the proposed model bears uncertainties arising from closures for boundary resistance and sediment exchange with the bed these still require systematic fundamental investigations into the associated mechanisms declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research is supported by the national natural science foundation of china no 12172331 the changjiang waterway institute of planning and design the zhejiang natural science foundation lr19e090002 and the hpc center of zju zhoushan campus appendix a the hllc solver and the force solver here we presented the specific expressions of the hllc solver and the force solver toro et al 2009 the hllc solver reads a 1 f h l l c w l w r e l s l 0 e l s l 0 s m i d e r s m i d 0 s r e r s r 0 where s l s r and s m i d are three wave speeds computed by eq a 2 e l e l e r and e r are four riemann numerical fluxes estimated by eqs a 5 for the hydro sediment mixture the wave speed s l and s r on the left and right sides are as follows a 2a s l min w l g l w 1 l w g w 1 if w 1 l 0 w r 2 g r w 1 r if w 1 l 0 a 2b s r min w r g r w 1 r w g w 1 if w 1 r 0 w l 2 g l w 1 l if w 1 r 0 the intermediate contact wave speed s m i d is calculated as follows a 2c s m i d w 1 r s l w r s r w 1 l s r w l s l w 1 r s l w r s r w 1 l w l s l where w l r w 2 nx w 3 ny l r are the normal velocities w w 1 are the modified value on both sides of the flux with average methods which can be calculated as follows a 3 w w 1 l w l w 1 r w r w 1 l w 1 r w 1 w 1 l w 1 r 2 the parameters g l r and g in eq a2 should be treated differently for the mixture part and for the sediment part which are as follows for the mixture part g l r g and g g for the k th sediment part a 4 g l r ρ ml r 2 ρ s c kml r g g ρ ml 4 ρ s c kml ρ mr 4 ρ s c kmr g numerical flux vectors in the eq a 1 can be estimated as follows a 5 e l r w 1 w w 1 w 2 w 0 5 g w 1 2 n x w 1 w 3 w 0 5 g w 1 2 n y l r e l r e h l l 1 e h l l 2 n x w e h l l 1 n y e h l l 2 n y w e h l l 1 n x l r where w l r w 2 ny w 3 nx l r represent tangential velocity and the parameter g in eq a5 should also be treated separately for the mixture part and for the sediment part for the mixture part a 6a g g for the k th sediment part a 6b g ρ m l 2 ρ s c k m l ρ m r 2 ρ s c k m r g the flux e h l l is calculated from the hll formula a 7a e h l l s r e w l s l e w r s l s r w r w l s r s l a 7b 1 0 0 0 n x n y 0 n y n x e w l r e w l r the force solver reads a 8 e n m f f o r c e u m l u m r 1 2 f m l f f m l w m 1 n f where u ml u mr are two riemann states immediately at the left and right side of the face as conserved variables f m l f f m l w represent the lax wendroff flux and the lax friedrichs flux which can be estimated as follows a 9a f m l f a m l y u m r n m a m r y u m l n m a m l a m r 2 a m l a m r δ t l i a m l a m r δ l m u m l u m r a 9b f m l w y u m l w n m a 9c u m l w u m r a m r u m l a m l a m r a m l δ t l i δ l m 2 a m r a m l y u m l y u m r n m where n m nmx nmy represents the normal outward direction of the m th face andy u ml r lw n m f u ml r lw nmx g u ml r lw nmy δlm is the length of the m th face aml amr denote the area of the triangle formed by the face and the cell center 
