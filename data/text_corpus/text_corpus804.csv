index,text
4020,hydrologic extremes often lead to droughts and floods that adversely affect the socio economic development change in the characteristics and causes of hydrologic extremes due to climate variability and climate change poses a challenge for its reliable prediction we propose a time varying approach to capture such temporal changes often gradual in hydrologic extremes through temporal networks a series of network structures graphical modelling gm based networks are developed through bayesian model averaging bma to deal with the complexity between the causal variables and extreme events a demonstration of the proposed time varying approach is shown for 1 month and 3 month ahead hydrological drought prediction in terms of standardized streamflow anomaly index ssai at basin scale that has notably changed in the recent years in terms of its frequency and severity the frequency and severity of below normal flow events has increased particularly during the monsoon season high flow months we hypothesize that time varying cause effect relationship is important to capture such gradual change in the characteristics of hydrologic extremes the results indicate that ssai values for the low flow months are strongly associated with streamflow whereas for the high flow months the dominant predictors are rainfall precipitable water and relative humidity furthermore the cause effect relationship between hydroclimatic variables and extreme events needs to be updated every 2 years for high flow and 3 years for low flow months the proposed model very well captures the above and below normal flow events and can be used as a remedial measure to handle similar cases through a proper assessment of time varying cause effect relationship between hydroclimatic variables and extreme events keywords hydrologic extremes climate change droughts time varying approach bayesian networks bns 1 introduction spatio temporal re distribution of hydro meteorological variables due to changing climate and dynamic terrestrial environment leads to changes in the characteristics and causes of extreme events these changes negatively impact the socio economic development and are often incomprehensible as it follows a complex mechanism van lanen et al 2013 van loon et al 2016 hydrologic extremes mostly originate from a deficit excess of precipitation however hydrologists are more concerned with how this plays out through the different processes in the hydrologic cycle the evolution of water deficit excess through the different components of the hydrological cycle like soil moisture and streamflow is not instantaneous and is controlled by complex processes hao et al 2018 kiem et al 2016 other hydro meteorological variables such as temperature potential evapotranspiration relative humidity precipitable water and pressure also directly or indirectly influence the occurrence of hydrologic extremes cook et al 2014 livneh and hoerling 2016 luo et al 2017 the aforementioned list of hydro meteorological variables still remains incomplete and may vary with space and time overall the development and evolution of an extreme event is dependent on multiple interacting factors such as hydro meteorological forcings land surface processes and human activities and these factors are further accelerated under the impact of climate change cook et al 2018 mukherjee et al 2018 thereby the complexity and uncertainty associated with the occurrence of such extremes make the investigation modelling analysis of these events a challenging task statistical modelling of hydrologic extremes such as floods and droughts has a long history ranging from regression based models barros and bowden 2008 liu and negrón juárez 2001 panu and sharma 2002 sun et al 2012 to artificial intelligence ai including machine learning ml and deep learning dl based techniques barua et al 2012 fung et al 2020 kaur and sood 2020 khan et al 2020 maity et al 2021 mishra et al 2007 mishra and desai 2006 santos et al 2014 yang et al 2015 some of the probabilistic approaches are able to capture the nonlinear dependence among the variables and provide probabilistic prediction from the conditional distribution hao et al 2016 liu et al 2015 madadgar and moradkhani 2013 svoboda et al 2002 wang et al 2009 wu et al 2011 yan et al 2012 zink et al 2016 however a major drawback of many modelling approaches is significant difficulty to build the joint distribution in higher dimensions when the pool of influencing variables is relatively large hao et al 2018 studies have utilized different techniques such as correlation analysis step wise regression analysis conditional independence structure based approach model free approach self organizing map partial informational correlation partial weights wavelet based techniques to deal with such issues bowden et al 2005 dutta and maity 2020a 2020b jiang et al 2020 may et al 2011 sharma et al 2016 new techniques for identifying important model inputs continue to emerge with each technique having its own advantages and limitations however no single method is best suited for all modelling purposes dutta and maity 2020a galelli et al 2014 maity and kashid 2011 most of the existing techniques are either unable to avoid the redundant information from multiple associated variables or miss out important variables due to the complex nature of association schisterman et al 2017 when a system like hydroclimatic system is composed of multiple interacting variables a complete information on the conditional independence structure is helpful to obtain a well defined set of input variables for a target variable only the directly associated variables may be picked out to use in the model leaving out the effect of conditionally independent and independent variables ihler et al 2007 this addresses the issues of high dimensionality due to large pool of influencing variables and effectively deals with redundant information from multiple variables here lies the advantage of graphical modelling gm approaches that provides a complete conditional independence structure that helps to further understand predict and optimize the behavior of dynamical systems dutta and maity 2020c 2020a 2018 bayesian networks bns a class of gm approaches are directed graphical models for representing probabilistic relationships among multiple interacting variables cooper 1990 heckerman et al 1995 witten et al 2005 formally a bn is defined by a graphical structure a family of conditional probability distributions and their parameters which together specify a joint distribution over a set of random variables of interest the graphical structure of a bn consists of a set of nodes and a set of directed edges the nodes represent random variables while the edges indicate conditional independence relations a detailed literature review on the application of bns in the field of hydrology and hydroclimatology can be found in avilés et al 2016 and morrison and stone 2014 recently studies have utilized graphical modelling and bayesian network based approaches to analyze primary hydrologic variables like precipitation das and chanda 2020 dutta and maity 2020c 2018 secondary hydrologic variables like streamflow dutta and maity 2020a ramadas et al 2015 and tertiary hydrologic variables like drought avilés et al 2016 ramadas and govindaraju 2015 whereas mostly the benefits of gm were realized in these studies inherent non stationarity may sometimes hinder the performance dutta and maity 2020a moreover complexity in the graph structure may increase from primary to tertiary hydrologic variables for example identification of a single static graph structure assuming that the dependence among the variables remains constant over time may be questionable in a changing climate even keeping the effect of changing climate aside moving from primary to tertiary hydrologic variables such as droughts and floods the uncertainty associated with the modelling framework substantially increases due to the complex interactions among the variables in addition to this climate variability and climate change leads to temporal redistribution of the hydro meteorological variables causing intensification alteration of the hydrologic cycle dutta and maity 2020a this gradually changes the cause effect relationship of the influencing variables and hydrologic extremes and the characteristics of such events in terms of its frequency and severity such changes fluctuations in the process may often lead to a non stationary system betterle et al 2017 gibbs et al 2018 hwang et al 2018 milly et al 2008 wagener et al 2010 non stationarity owing to gradual change in the association of the hydro meteorological drivers and hydrologic extremes poses a challenge for modelling and development of the prediction models recent studies have used different techniques for modelling of extreme events in a non stationary environment using copulas based techniques detecting non stationary hydrologic model parameters time varying model based on generalized additive models for location scale and shape and break change point analysis apurv and cai 2019 chebana and ouarda 2021 das et al 2021 he et al 2021 hesarkazzazi et al 2021 machado et al 2015 pathiraja et al 2016 however in a time evolving process the set of input variables may also change over time that most of the aforementioned approaches do not consider or need further development in case of conventional gm approaches a single high scoring static model is utilized which may not represent the true time varying association among the variables and there might be different models that explain the dependence reasonably well friedman and koller 2003 tian et al 2010 this forms the motivation of this study there are two primary aspects to be considered firstly the aspect of time varying association among the influencing variables and hydrologic extremes can be dealt by updating re calibrating the model after a fixed time interval such graph network structures are referred to as temporal networks and have been successfully utilized to analyze primary and secondary hydrologic variables dutta and maity 2020a 2020b secondly in the context of tertiary hydrologic variables like droughts the aspect of uncertainty in identifying the robust networks can be dealt with by using bayesian model averaging bma for structural learning of bayesian temporal network structures bma can be efficiently used to merge the information from multiple graph structures to truly understand the underlying process friedman koller 2003 in some other context bma is utilized for merging forecast information from multiple models in order to improve the predictability of hydrologic variables such as precipitation streamflow and drought duan et al 2007 huo et al 2019 jiang et al 2012 lu et al 2019 meira neto et al 2018 qu et al 2017 tian et al 2018 xu et al 2018 ye et al 2004 however utilization of combined potential of temporal networks along with bma may be highly beneficial to deal with the inherent complexity in the tertiary hydrologic variables being influenced by a large pool of variables and changing climatic and terrestrial conditions the objective of this study is to propose a bma based temporal network approach to model the temporal evolution of the hydrologic extremes caused by changing climate and dynamic terrestrial environment a demonstration is shown for 1 month ahead hydrological drought prediction defined by standardized streamflow anomaly index ssai which has notably changed in recent years in terms of its frequency and severity designated by ssai magnitude the two key components of the proposed modelling framework are a bayesian framework where bma of bns is used to learn the graph structures and b the temporal networks where the graph structure obtained using the bayesian framework is re iteratively updated along with the model parameters after a fixed time interval this fixed time interval is optimized based on the model performance during model testing period month wise ssai values are estimated twelve different series corresponding to each month and analyzed to develop twelve different prediction models for each month of analysis the performance of the proposed model is compared with its time invariant counterpart and a commonly used machine learning based modelling frameworks 2 study area and data used the upper mahanadi river basin up to basantpur gauging station is considered as the study area with an approximate spatial extent of 61 152 km2 lying between 20 n to 23 5 n latitude and 80 5 e to 83 e longitude it may be noted that mahanadi is one of the major rain fed east flowing rivers in india different indices can be utilized to characterize the hydrological drought like streamflow drought index sdi standardized streamflow anomaly index ssai palmer hydrological drought index phdi standardized standardized reservoir supply index srsi to name a few https www droughtmanagement info indices first two indices are evaluated using streamflow data phdi is evaluated using precipitation temperature and available water content and srsi uses reservoir data each index has its own advantages and disadvantages and selection of an index primarily depends on the application and the study area under consideration considering the strong seasonality in india ssai is used as the hydrological drought index to characterize the below above normal flow events detailed description on evaluation of ssai is provided in the methodology section section 3 1 the time period considered for the study is from january 1971 to december 2018 and the daily streamflow data at the outlet of the basin basantpur station for the above time period is obtained from the india water resources information system india wris https indiawris gov in wris there are very few minor structures in the upstream such as small check dams however given the large enough spatial extent of the basin the streamflow values can be considered as unregulated in addition to streamflow other input variables are temperature precipitable water potential evapotranspiration pressure relative humidity soil moisture and rainfall all from the previous time step these are selected based on the physical feedback mechanism of the hydroclimatic forcings as established in different literature maity et al 2010 maity and kashid 2011 meenu et al 2013 pichuka et al 2017 ramadas et al 2015 rehana and mujumdar 2014 month wise standardized anomaly values for each variable are obtained by subtracting each data series from their respective monthly mean and dividing by the respective standard deviation of that month daily rainfall data is obtained from india meteorological department imd rajeevan et al 2008 and data at each grid point is converted to monthly rainfall depth by accumulating it over the month temperature and potential evapotranspiration data are obtained from climatic research unit cru time series ts gridded data harris et al 2013 soil moisture data is obtained from the climate prediction centre cpc of the national oceanic and atmospheric administration noaa fan and van den dool 2004 cpc 2014 evaluated using a land surface model one layer bucket water balance model and rest of the variables are obtained from ncep ncar reanalysis 1 project using historical data to present kalnay et al 1996 gridded data is obtained from all the above mentioned sources and the data are taken from the grid points lying within the study area it may be noted that the ncep ncar reanalysis 2 product is an improvement over the ncep ncar reanalysis 1 improvement in the quality of the input variables may have an improvement in the model performance however the primary reason for using reanalysis 1 products is the availability of the data for a longer time period and a longer overlap with the available streamflow data for the study area for development of a time varying model it is important to have a long enough data set so that the fixed time interval for model re calibration can be effectively optimized however with the availability of longer streamflow data series it might be interesting to explore the uncertainty associated with each data source for different regions 3 methodology following sub sections illustrate the main steps involved in the proposed time varying approach to develop the prediction model in brief section 3 1 deals with drought characterization next a network graph structure is developed through bma of bns in section 3 2 among the associated variables input and target variables in section 3 3 the concept of temporal networks is developed by imparting time varying characteristics lastly section 3 4 provides details on the other existing approaches utilized for comparing the performance of the proposed bma based temporal network approach 3 1 hydrological drought characterization a streamflow based drought index referred to as standardized streamflow anomaly index ssai is utilized to characterize the hydrologic drought first month wise anomaly values of streamflow are obtained following eqn 1 as follow 1 x aij x ij x i where x aij is the anomaly value for the i th month of the j th year x ij is the observed streamflow for the i th month of the j th year and x i is the long term mean for the i th month next these anomaly values are fitted to a best fit probability distribution identified using the chi square goodness of fit test considering 5 significance level the parameters of the fitted distribution are used to estimate the cumulative distribution function cdf of the anomaly values represented by f x a p x a x a these values range between zero to one and are referred to as reduced variates of streamflow anomaly next these reduced variates are transformed to standard normal variates as follows 2 z a 1 f x a where 1 is the inverse of cumulative standard normal distribution these values are the standardized streamflow anomaly values and can range between to positive values of this index indicate above normal flow events and the negative values indicate below normal flow events or droughts resulting from streamflow excess and deficit respectively these ssai values define the severity of extremes and are used as the target variable in developing the bma based temporal network model initially these ssai values are used as the target variable in developing the bma based temporal network model additionally the frequency of occurrence of below above normal flow events is evaluated as the total number of such events occurring over a particular time period divided by the length of the respective time period it may also be noted that for effective implementation of the proposed methodology the streamflow data should be de trended before evaluating the ssai values next different categories of droughts e g moderate severe extreme are considered in the analysis depending on the numerical values also referred to as severity of the index following maity et al 2013 following near normal flow category n near normal events including normal abnormally dry and abnormally wet conditions below near normal flow drought categories d1 moderately dry d2 severely dry d3 extremely dry and d4 exceptionally dry events and above near normal flow categories w1 moderately wet w2 severely wet w3 extremely wet and w4 exceptionally wet events are considered in this categorization a value in the range of 0 7 0 7 are considered as near normal events as shown in figs 2 and 3 3 2 development of the bma based network structure and the prediction model bns are a class of graphical models that represent the association between different variables by means of directed acyclic graphs dags cooper 1990 heckerman et al 1995 witten et al 2005 given the causes causal input variables a bn can be used to compute the effect target variable development of a bn involves learning the network structure also referred to as the graph structure development of the probabilistic model parameter estimation of conditional probabilities and prediction of the target variable given the directly influencing input variables in traditional bns two different learning model selection algorithms namely score based algorithm and constraint based algorithm are utilized to learn the graph structure scutari 2017 these algorithms provide a single high scoring model that is selected as the final graph structure heckerman et al 1995 however considering the uncertainty associated with tertiary hydrologic variables such as drought and flood there may be multiple graph structures in addition to the single high scoring model that represent the dependency among the associated variables equally well furthermore other structures may present some vital information related to the conditional independence among the variables that may get overlooked while selecting the single high scoring model owing to the complexity of the hydroclimatic forcings behind hydrologic droughts it may be advantageous to identify multiple graph structures that fit the data reasonably well and derive the combined information from all these structures to obtain the association among the variables in this study the order markov chain monte carlo order mcmc algorithm based on the bma of bns is used for precisely learning the graph structure friedman and koller 2003 by averaging the information from multiple graph structures to start with all the graph structures that fit the data comparatively well based on the likelihood equivalent bayesian score also referred to as the bde score detailed description for evaluation of bde score is provided in appendix a are selected the number of selected structures is optimized so that the highly scoring graph structures are not excluded and the computational cost is minimized next the selected graph structures are grouped based on their topological order designated by θ these orders are arranged in such a way that each node may only have parents from further up the chain or following it in the ordering all the graph structures consistent with an order are combined to reduce the search to smaller space and a score is assigned to each group which is equal to the sum of the scores of all graph structures in the group next a markov chain is constructed considering all the node orders rather than all the graph structures detailed description on evaluation of the group score and construction of the markov chain is provided in appendix a by grouping together and averaging the score over so many graph structures an optimized structure is obtained that represents the association among the input variables and the target variable after identification of the final graph structure that represents the association among the variables the degree of association between the input variables and target variable is evaluated this degree of association is measured as score gained lost bde score when a particular edge for which the strength is being evaluated is included excluded from the structure that is the bde score for two graph structures one with and another without the edge are evaluated the difference between the score of the graph is considered as the edge strength using the obtained graph structure the prediction model is developed by factorization of the graph and parameter learning the prediction model is the joint probability distribution associated with a given graph structure it is obtained as a product of functions associated with a subset of the nodes variables the function turns out to be the conditional probability of a variable given its parent variables ihler et al 2007 identification of the conditional probability distribution also referred to as parameter learning is carried out using the maximum likelihood estimation mle approach details provided in appendix a the prediction model becomes ready once the parameters are estimated next the prediction of the target variable is carried out by plugging in the new values for the parents of the target variable variables directly associated with the target variable as obtained from the graph structure in the conditional probability distribution of the target variable it may be noted that the above methodology is used for the model calibration considering a particular model development period 3 3 development of the temporal networks and re calibration of prediction model the time varying characteristics are imparted to the prediction model by gradually updating the network structures over time also referred to as temporal networks dutta and maity 2020a the model development period is considered as a moving window of 30 years and the model is re calibrated iteratively after a fixed time interval say n years in terms of model inputs and parameters the value of n needs to be optimized and this optimized value is designated by τ and referred to as the optimum recursive interval ori for model re calibration dutta and maity 2020a 2018 in order to obtain τ different values of n starting from n 1 to n 5 years are considered as the time period of the study is from 1971 to 2018 the first model development period is considered from 1971 to 2000 and the model testing period is from 2001 to 2001 n 1 as the model is updated after n years the next model development period is shifted by n years and the second model development period is considered from 1971 n to 2000 n the process continues over the entire time period of the study to identify the value of τ this procedure is repeated for different values of n and the model performance during all the contiguous model testing periods is evaluated to identify the ori of model re calibration 3 4 comparison with existing approaches performance of the proposed bma based temporal network approach is compared with three commonly used modelling concepts in the field of hydrology to start with a time invariant counterpart of the bma based temporal network approach is used next two machine learning ml techniques namely support vector regression svr and artificial neural network ann are utilized in a time varying framework details on all the three models are as follows firstly for development of the bma based time invariant network approach the procedure explained in the previous sub section remains the same but only one graph structure is developed using 30 years data next the developed prediction model is used for the entire testing period without the concept of time varying models explained before lastly two commonly used ml based approaches namely svr and ann are developed based on the time varying concept but the concept of conditional independence structure is not utilized svr and ann are common machine learning techniques utilized in different hydroclimatic studies ardabili et al 2019 barua et al 2012 cristianini and shawe taylor 2000 khan et al 2020 maity et al 2010 prasad et al 2017 raghavendra and deka 2014 inputs for the svr model are identified through correlation analysis as followed traditionally in this comparison the ml based models are developed with the aforementioned time varying concept and thus the inputs and the parameters of the models are updated after n years as in the proposed bma based temporal network approach 4 results and discussions broadly the results are presented to show the temporal changes in the characteristics of hydrologic drought and the ability of the proposed model to capture temporal change in the association among the hydroclimatic variables and predict the occurrence of below above normal flow events section wise presentation of results and discussion is as follows section 4 1 shows the change in the frequency and severity of observed extreme events considering the first model development period and the contiguous model testing period next the hydroclimatic forcings directly influencing the hydrologic drought as revealed by the network structures developed using the proposed model is presented in section 4 2 section 4 3 shows the temporal change in the network structures developed using the proposed model and establishes the fact the association between the hydroclimatic forcings and extreme events is gradually changing over time section 4 4 shows the ability of the proposed bma based temporal network approach to capture the below above normal flow events lastly section 4 5 compares the performance of the proposed model with other well established modelling approaches 4 1 temporal change in the frequency and severity of hydrologic drought at the outset the change in the characteristics of extreme events is ascertained in terms of change in the frequency and severity of below above normal flow events fig 1a shows the temporal change in the frequency of the below above normal flow events evaluated individually for each month considering the time periods of 1971 2000 henceforth denoted as t1 and 2001 2018 henceforth denoted as t2 additionally the significant changes in the frequency identified using the two sample z test of proportions considering 5 significance level is also shown it is clearly noticed that the frequency of below normal flow events has increased for the post monsoon season october and november with significant increase in october winter season december february with significant increase in december and february and two monsoon months of july and august significant change in both the months furthermore the pre monsoon season march may with significant increase in april and may and other monsoon months i e june and september significant change in september exhibit an increase in the frequency of above normal flow events the higher frequency of below above normal flow events especially considering the months in the pre monsoon march may monsoon june september and post monsoon october november seasons may arise from the change in monsoon intensity and shift in monsoon pattern sahu et al 2020 secondly the temporal change considering the time periods of t1 and t2 in the severity of below above normal flow events assessed by considering the negative and positive values of ssai as two different data series is shown in fig 1b and 1c respectively through boxplots the figures show the change in the severity of below above normal flow events in terms of either increase or decrease in the mean range 25th quartile lower and 75th quartile upper values of ssai for each month of analysis the significant changes in the mean identified using the two sample t test considering 5 significance level for the below above normal flow events are shown in grey considering the months of july october months falling in the monsoon and post monsoon season an increase in the mean maximum and upper quartile value is observed thereby showing an increase in the severity of above normal flow events fig 1b similar observations can be made for the comparatively low flow months of february march april and may that exhibit significant change at 5 significance in its mean it is interesting to note that in the pre monsoon season both the frequency and severity of above normal flow events have increased in the recent time period i e t2 as compared to t1 further the severity of below normal flow events in terms of mean lower quartile and minimum value has increased considering the monsoon season june september similar observations are made for the months of november december and january too a decrease in the severity in terms of mean is observed for the months of february may significant at 5 significance however an increase in the severity in terms of the lower quartile value is observed for these months it is interesting to note that the months in the monsoon season show change in the frequency and severity of below above normal flow events depending on the month of analysis in order to ascertain the temporal change in the frequency and severity of below above near normal events the ssai values have been divided into three categories as shown in the contingency tables in fig 9 first table fig 2 shows the temporal change considering time periods t1 and t2 in the frequency of different categories of below above near normal flow events for each month of analysis it may be noted that for all months starting from january to december the frequency of below near normal events has increased similarly the frequency of above near normal events has also increased for the months of february september thereby considering the months in the monsoon season june september the frequency of near normal events has decreased and the frequency of both above and below near normal events have increased moreover the severity of above near normal and below near normal events has increased decreased either in terms of mean upper quartile lower quartile or maximum minimum values for almost all the months fig 3 the significant changes in the mean identified using the two sample t test considering 5 significance level for all the three categories of below above near normal flow events are shown in grey the pre monsoon months of march and april show significant increase in the mean severity of above near normal events and significant decrease in the mean severity of below near normal events the month of may shows a significant decrease in the mean severity of below near normal events next considering the monsoon months of june july and august significant change is observed in the mean severity of both above and below near normal events for instance the months of june and august show significant decrease in the mean severity of above near normal events and july shows significant increase in the mean severity of above near normal events furthermore the post monsoon season october and november shows significant decrease in the mean severity of below near normal events thereby alterations of the hydrologic cycle strongly impact the characteristics of the extreme events over time and significant temporal changes are noticed in the recent decades t2 as compared to past t1 4 2 hydroclimatic forcings behind hydrologic droughts as revealed by the network structures the proposed approach is based on the concept of network structures which provides the complete conditional independence structure that reveals the hydroclimatic forcings behind the hydrologic droughts figs 5 panel 1 and 6 panel 1 show the network structures for the first model development period 1971 2000 considering one typical low flow january and high flow july month respectively the input variables temperature te precipitable water pw potential evapotranspiration pe pressure pr relative humidity rh soil moisture sm rainfall ra streamflow st all inputs from the previous month and the target variable ssai current month of analysis are represented by differently colored nodes and the association between any two variables is shown by a directed edge absence of an edge can be interpreted as the variables being independent or conditionally independent and presence of an edge can be interpreted as the variables being directly dependent considering the month of january a typical high flow month ssai target variable is directly dependent on streamflow and conditionally independent of all the other input variables streamflow is directly influenced by soil moisture which is in turn directly dependent on rainfall and temperature further relative humidity is associated with rainfall precipitable water and potential evapotranspiration a possible reason for the indirect connection between rainfall and precipitable water could be the multiple factors affecting precipitation quantity like degree of saturation atmospheric water vapor and the presence of dynamic mechanisms which provide the cooling necessary to produce saturation similar network structures are identified for each month and the input variables directly influencing ssai are shown in fig 7 in fig 7 input variables are represented by colored squares black color indicates no association or conditionally independent association and different shades of red indicates significant association with varying values of edge strengths strength of association considering other low flow months of december february march april and may and the first model development period fig 7a streamflow emerges as the primary influencing variable for 1 month ahead prediction for the months of may and december in addition to streamflow rainfall also shows direct association with ssai a probable reason can be the higher rainfall magnitude in the months of may falling in the pre monsoon season and december falling in the winter monsoon season as compared to the other low flow months for the considered study area next considering the month of july a typical high flow month and the first model development period fig 6 panel 1 ssai target variable is found to be directly dependent on rainfall and precipitable water furthermore the streamflow variations show direct dependence on soil moisture and rainfall and relative humidity is directly associated with temperature potential evapotranspiration and precipitable water during high flow months it is expected that the moderately sized catchment will almost be in a stationary state as the precipitation is quite continuous over time thus the variation in extreme events will respond mainly to precipitation variation in time fig 7b shows that precipitable water directly influences ssai for august and september other monsoon months during the first model development period streamflow shows a direct association with ssai in case of june first monsoon month and november thereby the complete conditional independence structure as identified by the proposed approach helps to identify the directly influencing variables and given these variables below above normal flow events are conditionally independent or independent of the other hydroclimatic forcings 4 3 temporal change in the hydroclimatic forcings behind hydrologic droughts the time varying association between hydroclimatic forcings and ssai is assessed through the proposed bma based temporal network approach to start with the first 30 year period is considered as the first model development period and the initial network structure is developed the network structure is recursively re developed after each τ years interval denoted as ori as defined in the methodology section section 3 3 the value of τ is ascertained by assuming different values n 1 2 3 and comparing the model performance for the contiguous model testing period four performance metrics namely correlation coefficient r nash sutcliffe efficiency nse index of agreement dr coefficient of determination r 2 and root mean square error rmse are utilized for assessment fig 4 shows the month wise performance of the models considering the different values of n 1 2 5 years it is observed that a value of n 2 years and n 3 years provides the best possible performance considering the months in the monsoon and post monsoon season june november and the months in winter and pre monsoon season december may respectively thereby the prediction model needs to be re calibrated after 2 and 3 years considering the comparatively low flow and high flow months respectively in order to capture the time varying association among the hydro meteorological variables considering the value of τ as 2 years the corresponding model development periods testing periods are 1971 2000 2001 2002 1973 2002 2003 2005 1987 2016 2017 2018 and considering the same as 3 years the corresponding model development periods testing periods are 1971 2000 2001 2003 1974 2003 2004 2006 1986 2015 2016 2018 thereby the model is calibrated 9 times for the high flow months and 6 times for the low flow months considering the entire time period 1971 2018 of the study figs 5 and 6 show the time varying temporal networks obtained for the 6 model development periods considering a typical low flow january and a typical high flow july month respectively for example considering the month of january and the first model development period ssai is directly dependent on streamflow whereas for the second model development period fig 5 panel 2 in addition to streamflow ssai also shows a direct dependence on temperature further it is interesting to note a distinct change in the interaction among the other input variables also for instance soil moisture is conditionally independent of rainfall and temperature similar observations can be made for the third model development period also such changes in the interaction among the variables are accounted for by the modified rainfall pattern for the considered study area and a change in the terrestrial environment considering the fifth and sixth model development period ssai shows direct dependence on the streamflow and potential evapotranspiration in addition to other input variables change in climatic factors like high low vapor pressure increased decreased radiation in the surrounding region and change in terrestrial environment may affect the influence of potential evapotranspiration over time next considering the month of july and the first model development period ssai is found to be directly dependent on rainfall and precipitable water it is interesting to note that considering the second model development period fig 6 panel 2 in addition to rainfall and precipitable water potential evapotranspiration also shows a direct association with ssai the interaction between the other input variables is more or less similar with pressure remaining independent of all the other variables this result contradicts the findings obtained for a typical low flow month whereas the interaction between the variables drastically changes over the time considering the sixth model development period 1981 2010 ssai shows a direct dependence on rainfall relative humidity and precipitable water a gradual shift in the directly dependent input variables is observed considering the last two model development periods with increasing dependence of ssai on soil moisture and potential evapotranspiration similar temporal networks are identified for each month and the input variables directly influencing ssai are shown in fig 7 for example considering the month of february during the first model development period 1971 2000 ssai is directly dependent on streamflow and potential evapotranspiration but conditionally independent of precipitable water pressure temperature relative humidity soil moisture and rainfall moreover the strength of association between ssai and streamflow is stronger considering the first three model development periods i e 1971 2000 1974 2003 and 1977 2006 gradually the strength reduces over time as noticed for the fourth 1980 2009 fifth 1983 2012 and sixth 1986 2015 development periods a closure observation reveals that the high variation in february streamflow series is noticed during the entire time period with a significantly increasing trend till late 1990s and a decreasing trend afterwards this leads to a changing below above normal flow events and alteration in the association of ssai with streamflow over time based on the obtained results it is interesting to notice that ssai for the low flow months namely january february march april may and december with the streamflow range of 1 83 to 249 55 cumec is strongly associated with streamflow fig 7a contrary to this during the high flow months of june july august september october and november where the range of streamflow lies between 247 88 and 6572 32 cumec the dominant predictors are rainfall precipitable water and relative humidity fig 7b furthermore the number of input variables directly influencing ssai considering a particular model development period for the high flow months is more as compared to the low flow months as streamflow is the dominant predictor considering the ssai of the low flow months with high strength of association most of the information on the below above normal flow events can be extracted from streamflow itself making the contribution of other variables insignificant however considering the high flow months most of the significant input variables show similar association with ssai and information from all these variables is vital to explain the below above normal flow events it can be clearly stated that the causal factors input variables of extreme events change temporally for a particular season as well as from one season to another thereby it is vital to iteratively re calibrate the model to successfully capture the below above normal flow events 4 4 performance of the proposed time varying approach the observed and predicted ssai values obtained using the bma based temporal network approach along with the different categories of below above near normal flow events depicted with different color gradations of red blue are shown in fig 8 the near normal events are shown in grey the proposed approach shows satisfactory performance in capturing the events falling near normal to severe dry wet flow events however considering the extreme and exceptional dry wet flow events the model shows better performance in capturing these two wet flow categories as compared to these dry flow categories further considering four different contingency tables fig 9 shows the different categorizations of ssai maintaining the range of near normal events as 0 7 0 7 and the efficacy of the proposed model to capture the same the values mentioned in the diagonals shown in grey of the contingency tables show that the observed and predicted values of ssai fall in the same range i e a near normal below near normal above near normal events have been correctly captured along with its severity range for instance considering the third type of categorization 23 summation of last column above near normal flow events have been observed to be greater than 1 2 out of these events 18 diagonal element events have been correctly predicted to lie in this range the remaining five events have been under predicted as less severe above near normal flow events 4 and a near normal flow event 1 similarly considering the second type of categorization 57 summation of third column below normal flow events have been observed to lie in the range 1 2 0 7 24 events have been correctly predicted to fall in this range and the rest of the events are predicted as either less or more severe above normal flow events it can be observed that as the range of ssai is made smaller for categorization of below above normal flow events the model error gradually increases however the model performance is satisfactory considering all the four categories overall the ssai as well the range are well captured by the proposed bma based temporal network approach due to its ability to re calibrate the model and capture the time varying characteristics among the variables next month wise prediction performance of the proposed bma based temporal network approach is assessed by comparing the observed and the predicted ssai values fig 10 the results show that the predicted values closely follow the observed values for many months such as january march may october and november for the months of february april july and september positive errors are noticed and for the months of june august and december negative errors are observed it is also interesting to note that as compared to the high flow months the statics value lie in the following range r 0 85 0 91 rmse 0 50 1 13 nse 0 75 0 82 and dr 0 75 0 83 the performance of the model is comparatively better considering the low flow months the statics value lie in the following range r 0 86 0 92 rmse 0 32 1 01 nse 0 75 0 87 and dr 0 80 0 91 a probable reason is the high variations in streamflow during the high flow months leads to extreme and exceptional above near normal flow events that are complex in nature further the uncertainty range considering the predictions at the 5th and 95th percentile is also shown in fig 10 it may be noted that all the observed values fall within the uncertainty range except one observed ssai value in the months of february and april 4 5 comparison of the proposed approach with the other modelling approaches performance of the bma based temporal network approach is compared with three other modelling approaches i bma based time invariant network approach ii svr based time varying approach and iii ann based time varying approach the performance statistics obtained using all the three models are compared in table 1 the models are designated as m1 m2 m3 and m4 and the data series for month wise analysis is designated as s1 furthermore fig 11 shows that the bma based temporal network approach successfully captures the mean and range of the ssai values considering all the months of analysis moving our attention to the low flow months it is clearly evident that the bma based time invariant network approach gives sub power performance due to its inability to identify the temporal change in the causes effect relationship moving on to the ml based time varying approaches the results indicate that for the low flow months the model is able to reasonably capture the mean and range of ssai except for the months of january and may however considering the high flow months performance of the proposed model is better as compared to the ml based time varying approaches month wise analysis is also carried out with non detrended series and the results are presented in table 1 data series for month wise analysis is designated as s1 ndt for all the four models it may be observed that the analysis carried out after removing the trend shows a slightly improved performance as compared to using the non detrended series overall the ability of the proposed approach to capture the true dependence structure between the large pool of hydro meteorological variables and drought index improves the prediction skill of the proposed model next additional analysis is carried our considering ssai for all the months as a single series having established the efficacy of the time varying approach over the time invariant counterpart results obtained using the three time varying approaches temporal network svr and ann based considering all the months as a single series is shown in fig 12 a while carrying out the month wise analysis it was observed that a unique set of predictors are identified for each month considering a particular time period when ssai for each month is analyzed as a single series it is observed that the set of predictors identified are dominated by the fact that most of the months november may are low flow months as compared to the monsoon season june september thereby the model performance deteriorates the statics value using the proposed approach are r 0 69 rmse 0 70 nse 0 56 and dr 0 62 table 1 in comparison to the month wise analysis the model is unable to specially capture the below above normal flow events for the high flow months due to the inability of the model to appropriately identify the predictor set fig 12a also compares the performance of the three time varying models utilizing the box plots in terms of capturing the mean and range of the observed data the performance of all the models are comparable however when comparing the performance statics considering the svr ann based time varying approach and monthly drought index as a single series are r 0 50 0 45 rmse 0 89 0 99 nse 0 40 0 38 and dr 0 43 0 41 table 1 it is observed that the proposed model out performs the ml based time varying approaches due to its ability to appropriately identify the complex mechanism associated with hydrologic drought the prediction models developed so far can be utilized to provide 1 month ahead forecast of below above normal flow events in order to provide an outlook of the model performance with a longer lead time results for 3 month ahead forecast are also presented in table 1 and fig 12b considering a longer lead time the statics value using the proposed approach are r 0 75 rmse 0 88 nse 0 66 and dr 0 73 table 1 the model performance gradually deteriorates the primary reason being the increase in the lag time of the influencing hydro meteorological variable and ssai however given the complex nature of tertiary hydrological variables such as floods and droughts the model very well captures the extreme flow events for the considered study area with the availability of the data for the hydroclimatic forcings that influence the hydrologic droughts from different sources like the ground observations and reanalysis products effective forecast with a lead time of 1 to 3 months can be provided using the developed model further on availability of the observed streamflow data the model should be re calibrated at span of 2 3 years based on the identified ori of model re calibration in order to capture time varying association among the hydroclimatic variables and extreme events this time span may change based on the study area considered 5 summary and conclusions inherent non stationarity owing to the impact of climate and terrestrial changes causes a gradual change in the characteristics of hydrological extremes this study proposes a bma based temporal network approach as an efficient modelling technique for capturing such slow moving changes and prediction of hydrologic extremes by assessing the time varying cause effect relationship between hydroclimatic variables and extreme events changing climate and dynamic terrestrial environment suggests a change in the characteristics of extreme events like flood and drought considering the river basin used for this study results indicate temporal change in the characteristics of extreme events an increase in the frequency of occurrence during the time period of 2001 2018 with respect to the first model development period of 1971 2000 of below normal flow events can be observed with an increased severity especially during the monsoon season june september studies have established that change in climatic factors such as high temperature precipitation deficit increased evaporation reduced runoff and infiltration caused due to combined effect of climate variability and human activities has reduced streamflow which might be a primary cause for increase in hydrologic drought kim and jehanzaib 2020 similar observations of change in frequency and severity are also made considering the non monsoon months hence establishing the temporality associated with the characteristics of extremes further the benefit of applying the time varying concept in prediction of extreme events is established by carrying out basin scale prediction in the proposed time varying approach bma is used to develop the network graph structures that are re iteratively updated to obtain a series of networks temporal networks this helps to establish the change in the causality of extreme events in this technique instead of learning a single static high scoring graph structure the information from multiple probable graph structures is used to obtain the final graph structure that are updated after a fixed time interval which reduces the uncertainty while dealing with tertiary hydrologic variables like flood and drought and capture the temporal change in the causality of the extreme events in a non stationary environment as a typical example 1 month ahead hydrologic drought prediction defined by a streamflow based index ssai is carried out to study the efficacy of the proposed approach applying the concept of bma based temporal networks the results indicate that the proposed prediction model in terms of model inputs and parameters needs to be re calibrated every 2 years and 3 years considering the high and low flow months respectively in order to appropriately capture the time varying association between the input and target variables based on the time varying dependence structure obtained among the variables drought index ssai for the low flow months are strongly associated with streamflow contrary to this considering the high flow months the dominant predictors are rainfall precipitable water and relative humidity results also show that the bma based temporal network approach successfully captures the extreme events associated with both low and high flows further dividing the extreme events into different classes based on the severity of below above normal flow events the proposed model shows satisfactory agreement with the observed events that is the predicted ssai values very well captures the severity of the below above normal flow events with higher efficacy considering the above normal flow events the ability of the proposed approach to identify the conditional independence structure among a large pool of associated variables considering the complexity associated with tertiary hydrologic variables and capture the time varying association among the variables can be effective for analyzing complex hydrologic processes overall the findings of this study establish i the change in the drought frequency and severity over time and ii benefit of the time varying concept as an efficient approach for such complex hydrologic extremes exhibiting gradual change in its characteristics whereas the first issue is being realized established for many hydrological variables at different places around the world the second aspect is a valuable contribution in terms of a remedial measure to handle such cases through a proper assessment of time varying cause effect relationship between hydroclimatic variables and extreme events credit authorship contribution statement riya dutta methodology investigation writing original draft rajib maity conceptualization methodology investigation writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work is supported by the ministry of earth science government of india through a sponsored project daily streamflow data are collected from the water resources information system in india at http www india wris nrsc gov in daily rainfall data are obtained from india meteorological department imd the climatic variables are obtained from the climate prediction centre cpc of the national oceanic and atmospheric administration noaa at https www cpc ncep noaa gov appendix a mathematical details for development of the bma based network approach the following section gives the mathematical details for evaluation of the bde score evaluation of the group score development of the markov chain and factorization of the final graph structure evaluation of the bde score the score of each graph structure also known as the bde score geiger and heckerman 2002 is the posterior probability of the structure evaluated as 1 p g d p d g p g i 1 n s x i p a i d where g refers to the network structure among the variables d represents the data set s is a score function dependent on variable xi and pai is the parent set of variable xi scoring of the topological orders θ each order θ receives a score r θ d equal to the sum of the scores of all graph structures in the order 2 r θ d g θ p g d the score of each node s possible parent sets is computed and efficiently used as the sum of the scores of all the graph structures compatible with a particular order friendman and koller 2003 the score of the order is evaluated as the product of the node score sums over possible parent sets 3 r θ d g θ p g d i 1 n p a θ i s x i p a i d construction of the markov chain a chain with stationary distribution proportional to r θ d is produced by a metropolis hastings algorithm with acceptance probability 4 ρ m i n 1 q θ j θ r θ d q θ θ j r θ j d where q θ θ j is the probability of proposing a move to θ from θ and can be any move in the space of orders the simplest move is flipping two nodes in the order while leaving the position of others unchanged upon convergence order mcmc provides a sample of an order θ from a distribution proportional to the score r θ d over the space of possible orders of the nodes of the graph structure given a sampled order a network structure is selected by sampling the parents of each node independently according to the scores of its permissible parent sets factorization and parameter learning of the final graph structure let x 1 x 2 x n be n random variables with a known graph structure directed graph the joint probability distribution also known as the global probability distribution depends on a set of local probability distributions one for each node variable it can be expressed as follows 5 p x 1 x 2 x n i 1 n p x i p a i where p x i p a i is the local conditional probability associated with node i a specific form of the factorization given by the markov property of bns korb and nicholson 2004 states that every random variable xi directly depends only on its parents thereby the conditional probability of any variable xi given rest of the variables can be written as 6 p x i r e s t p x i p a i in order to identify the local probability distribution two methods namely bayesian parameter estimation and maximum likelihood parameter estimation can be utilized scutari 2017 2010 in this study mle is used to learn the parameter set φ of the joint probability distribution function of the variables that can be represented as 7 p x 1 x 2 x n φ i 1 n p x i p a i θ i where θ i is the vector of parameters for the conditional distribution of x i and φ θ i θ n given the training data x x 1 x m where x l x l 1 x ln and m is the number of observations for each variable the log likelihood of θ with rest to x is computed as 8 l o g φ x l 1 m i 1 n l o g p x li p a i θ i the likelihood function as given in equation 5 which decomposes according to the network structure thereby the mles for each node is computed independently neapolitan and jiang 2007 the local probability distribution is extracted from the fitted probabilistic graphical model scutari 2017 the probabilistic distribution is used to predict the target variables given the directly influencing input variables 
4020,hydrologic extremes often lead to droughts and floods that adversely affect the socio economic development change in the characteristics and causes of hydrologic extremes due to climate variability and climate change poses a challenge for its reliable prediction we propose a time varying approach to capture such temporal changes often gradual in hydrologic extremes through temporal networks a series of network structures graphical modelling gm based networks are developed through bayesian model averaging bma to deal with the complexity between the causal variables and extreme events a demonstration of the proposed time varying approach is shown for 1 month and 3 month ahead hydrological drought prediction in terms of standardized streamflow anomaly index ssai at basin scale that has notably changed in the recent years in terms of its frequency and severity the frequency and severity of below normal flow events has increased particularly during the monsoon season high flow months we hypothesize that time varying cause effect relationship is important to capture such gradual change in the characteristics of hydrologic extremes the results indicate that ssai values for the low flow months are strongly associated with streamflow whereas for the high flow months the dominant predictors are rainfall precipitable water and relative humidity furthermore the cause effect relationship between hydroclimatic variables and extreme events needs to be updated every 2 years for high flow and 3 years for low flow months the proposed model very well captures the above and below normal flow events and can be used as a remedial measure to handle similar cases through a proper assessment of time varying cause effect relationship between hydroclimatic variables and extreme events keywords hydrologic extremes climate change droughts time varying approach bayesian networks bns 1 introduction spatio temporal re distribution of hydro meteorological variables due to changing climate and dynamic terrestrial environment leads to changes in the characteristics and causes of extreme events these changes negatively impact the socio economic development and are often incomprehensible as it follows a complex mechanism van lanen et al 2013 van loon et al 2016 hydrologic extremes mostly originate from a deficit excess of precipitation however hydrologists are more concerned with how this plays out through the different processes in the hydrologic cycle the evolution of water deficit excess through the different components of the hydrological cycle like soil moisture and streamflow is not instantaneous and is controlled by complex processes hao et al 2018 kiem et al 2016 other hydro meteorological variables such as temperature potential evapotranspiration relative humidity precipitable water and pressure also directly or indirectly influence the occurrence of hydrologic extremes cook et al 2014 livneh and hoerling 2016 luo et al 2017 the aforementioned list of hydro meteorological variables still remains incomplete and may vary with space and time overall the development and evolution of an extreme event is dependent on multiple interacting factors such as hydro meteorological forcings land surface processes and human activities and these factors are further accelerated under the impact of climate change cook et al 2018 mukherjee et al 2018 thereby the complexity and uncertainty associated with the occurrence of such extremes make the investigation modelling analysis of these events a challenging task statistical modelling of hydrologic extremes such as floods and droughts has a long history ranging from regression based models barros and bowden 2008 liu and negrón juárez 2001 panu and sharma 2002 sun et al 2012 to artificial intelligence ai including machine learning ml and deep learning dl based techniques barua et al 2012 fung et al 2020 kaur and sood 2020 khan et al 2020 maity et al 2021 mishra et al 2007 mishra and desai 2006 santos et al 2014 yang et al 2015 some of the probabilistic approaches are able to capture the nonlinear dependence among the variables and provide probabilistic prediction from the conditional distribution hao et al 2016 liu et al 2015 madadgar and moradkhani 2013 svoboda et al 2002 wang et al 2009 wu et al 2011 yan et al 2012 zink et al 2016 however a major drawback of many modelling approaches is significant difficulty to build the joint distribution in higher dimensions when the pool of influencing variables is relatively large hao et al 2018 studies have utilized different techniques such as correlation analysis step wise regression analysis conditional independence structure based approach model free approach self organizing map partial informational correlation partial weights wavelet based techniques to deal with such issues bowden et al 2005 dutta and maity 2020a 2020b jiang et al 2020 may et al 2011 sharma et al 2016 new techniques for identifying important model inputs continue to emerge with each technique having its own advantages and limitations however no single method is best suited for all modelling purposes dutta and maity 2020a galelli et al 2014 maity and kashid 2011 most of the existing techniques are either unable to avoid the redundant information from multiple associated variables or miss out important variables due to the complex nature of association schisterman et al 2017 when a system like hydroclimatic system is composed of multiple interacting variables a complete information on the conditional independence structure is helpful to obtain a well defined set of input variables for a target variable only the directly associated variables may be picked out to use in the model leaving out the effect of conditionally independent and independent variables ihler et al 2007 this addresses the issues of high dimensionality due to large pool of influencing variables and effectively deals with redundant information from multiple variables here lies the advantage of graphical modelling gm approaches that provides a complete conditional independence structure that helps to further understand predict and optimize the behavior of dynamical systems dutta and maity 2020c 2020a 2018 bayesian networks bns a class of gm approaches are directed graphical models for representing probabilistic relationships among multiple interacting variables cooper 1990 heckerman et al 1995 witten et al 2005 formally a bn is defined by a graphical structure a family of conditional probability distributions and their parameters which together specify a joint distribution over a set of random variables of interest the graphical structure of a bn consists of a set of nodes and a set of directed edges the nodes represent random variables while the edges indicate conditional independence relations a detailed literature review on the application of bns in the field of hydrology and hydroclimatology can be found in avilés et al 2016 and morrison and stone 2014 recently studies have utilized graphical modelling and bayesian network based approaches to analyze primary hydrologic variables like precipitation das and chanda 2020 dutta and maity 2020c 2018 secondary hydrologic variables like streamflow dutta and maity 2020a ramadas et al 2015 and tertiary hydrologic variables like drought avilés et al 2016 ramadas and govindaraju 2015 whereas mostly the benefits of gm were realized in these studies inherent non stationarity may sometimes hinder the performance dutta and maity 2020a moreover complexity in the graph structure may increase from primary to tertiary hydrologic variables for example identification of a single static graph structure assuming that the dependence among the variables remains constant over time may be questionable in a changing climate even keeping the effect of changing climate aside moving from primary to tertiary hydrologic variables such as droughts and floods the uncertainty associated with the modelling framework substantially increases due to the complex interactions among the variables in addition to this climate variability and climate change leads to temporal redistribution of the hydro meteorological variables causing intensification alteration of the hydrologic cycle dutta and maity 2020a this gradually changes the cause effect relationship of the influencing variables and hydrologic extremes and the characteristics of such events in terms of its frequency and severity such changes fluctuations in the process may often lead to a non stationary system betterle et al 2017 gibbs et al 2018 hwang et al 2018 milly et al 2008 wagener et al 2010 non stationarity owing to gradual change in the association of the hydro meteorological drivers and hydrologic extremes poses a challenge for modelling and development of the prediction models recent studies have used different techniques for modelling of extreme events in a non stationary environment using copulas based techniques detecting non stationary hydrologic model parameters time varying model based on generalized additive models for location scale and shape and break change point analysis apurv and cai 2019 chebana and ouarda 2021 das et al 2021 he et al 2021 hesarkazzazi et al 2021 machado et al 2015 pathiraja et al 2016 however in a time evolving process the set of input variables may also change over time that most of the aforementioned approaches do not consider or need further development in case of conventional gm approaches a single high scoring static model is utilized which may not represent the true time varying association among the variables and there might be different models that explain the dependence reasonably well friedman and koller 2003 tian et al 2010 this forms the motivation of this study there are two primary aspects to be considered firstly the aspect of time varying association among the influencing variables and hydrologic extremes can be dealt by updating re calibrating the model after a fixed time interval such graph network structures are referred to as temporal networks and have been successfully utilized to analyze primary and secondary hydrologic variables dutta and maity 2020a 2020b secondly in the context of tertiary hydrologic variables like droughts the aspect of uncertainty in identifying the robust networks can be dealt with by using bayesian model averaging bma for structural learning of bayesian temporal network structures bma can be efficiently used to merge the information from multiple graph structures to truly understand the underlying process friedman koller 2003 in some other context bma is utilized for merging forecast information from multiple models in order to improve the predictability of hydrologic variables such as precipitation streamflow and drought duan et al 2007 huo et al 2019 jiang et al 2012 lu et al 2019 meira neto et al 2018 qu et al 2017 tian et al 2018 xu et al 2018 ye et al 2004 however utilization of combined potential of temporal networks along with bma may be highly beneficial to deal with the inherent complexity in the tertiary hydrologic variables being influenced by a large pool of variables and changing climatic and terrestrial conditions the objective of this study is to propose a bma based temporal network approach to model the temporal evolution of the hydrologic extremes caused by changing climate and dynamic terrestrial environment a demonstration is shown for 1 month ahead hydrological drought prediction defined by standardized streamflow anomaly index ssai which has notably changed in recent years in terms of its frequency and severity designated by ssai magnitude the two key components of the proposed modelling framework are a bayesian framework where bma of bns is used to learn the graph structures and b the temporal networks where the graph structure obtained using the bayesian framework is re iteratively updated along with the model parameters after a fixed time interval this fixed time interval is optimized based on the model performance during model testing period month wise ssai values are estimated twelve different series corresponding to each month and analyzed to develop twelve different prediction models for each month of analysis the performance of the proposed model is compared with its time invariant counterpart and a commonly used machine learning based modelling frameworks 2 study area and data used the upper mahanadi river basin up to basantpur gauging station is considered as the study area with an approximate spatial extent of 61 152 km2 lying between 20 n to 23 5 n latitude and 80 5 e to 83 e longitude it may be noted that mahanadi is one of the major rain fed east flowing rivers in india different indices can be utilized to characterize the hydrological drought like streamflow drought index sdi standardized streamflow anomaly index ssai palmer hydrological drought index phdi standardized standardized reservoir supply index srsi to name a few https www droughtmanagement info indices first two indices are evaluated using streamflow data phdi is evaluated using precipitation temperature and available water content and srsi uses reservoir data each index has its own advantages and disadvantages and selection of an index primarily depends on the application and the study area under consideration considering the strong seasonality in india ssai is used as the hydrological drought index to characterize the below above normal flow events detailed description on evaluation of ssai is provided in the methodology section section 3 1 the time period considered for the study is from january 1971 to december 2018 and the daily streamflow data at the outlet of the basin basantpur station for the above time period is obtained from the india water resources information system india wris https indiawris gov in wris there are very few minor structures in the upstream such as small check dams however given the large enough spatial extent of the basin the streamflow values can be considered as unregulated in addition to streamflow other input variables are temperature precipitable water potential evapotranspiration pressure relative humidity soil moisture and rainfall all from the previous time step these are selected based on the physical feedback mechanism of the hydroclimatic forcings as established in different literature maity et al 2010 maity and kashid 2011 meenu et al 2013 pichuka et al 2017 ramadas et al 2015 rehana and mujumdar 2014 month wise standardized anomaly values for each variable are obtained by subtracting each data series from their respective monthly mean and dividing by the respective standard deviation of that month daily rainfall data is obtained from india meteorological department imd rajeevan et al 2008 and data at each grid point is converted to monthly rainfall depth by accumulating it over the month temperature and potential evapotranspiration data are obtained from climatic research unit cru time series ts gridded data harris et al 2013 soil moisture data is obtained from the climate prediction centre cpc of the national oceanic and atmospheric administration noaa fan and van den dool 2004 cpc 2014 evaluated using a land surface model one layer bucket water balance model and rest of the variables are obtained from ncep ncar reanalysis 1 project using historical data to present kalnay et al 1996 gridded data is obtained from all the above mentioned sources and the data are taken from the grid points lying within the study area it may be noted that the ncep ncar reanalysis 2 product is an improvement over the ncep ncar reanalysis 1 improvement in the quality of the input variables may have an improvement in the model performance however the primary reason for using reanalysis 1 products is the availability of the data for a longer time period and a longer overlap with the available streamflow data for the study area for development of a time varying model it is important to have a long enough data set so that the fixed time interval for model re calibration can be effectively optimized however with the availability of longer streamflow data series it might be interesting to explore the uncertainty associated with each data source for different regions 3 methodology following sub sections illustrate the main steps involved in the proposed time varying approach to develop the prediction model in brief section 3 1 deals with drought characterization next a network graph structure is developed through bma of bns in section 3 2 among the associated variables input and target variables in section 3 3 the concept of temporal networks is developed by imparting time varying characteristics lastly section 3 4 provides details on the other existing approaches utilized for comparing the performance of the proposed bma based temporal network approach 3 1 hydrological drought characterization a streamflow based drought index referred to as standardized streamflow anomaly index ssai is utilized to characterize the hydrologic drought first month wise anomaly values of streamflow are obtained following eqn 1 as follow 1 x aij x ij x i where x aij is the anomaly value for the i th month of the j th year x ij is the observed streamflow for the i th month of the j th year and x i is the long term mean for the i th month next these anomaly values are fitted to a best fit probability distribution identified using the chi square goodness of fit test considering 5 significance level the parameters of the fitted distribution are used to estimate the cumulative distribution function cdf of the anomaly values represented by f x a p x a x a these values range between zero to one and are referred to as reduced variates of streamflow anomaly next these reduced variates are transformed to standard normal variates as follows 2 z a 1 f x a where 1 is the inverse of cumulative standard normal distribution these values are the standardized streamflow anomaly values and can range between to positive values of this index indicate above normal flow events and the negative values indicate below normal flow events or droughts resulting from streamflow excess and deficit respectively these ssai values define the severity of extremes and are used as the target variable in developing the bma based temporal network model initially these ssai values are used as the target variable in developing the bma based temporal network model additionally the frequency of occurrence of below above normal flow events is evaluated as the total number of such events occurring over a particular time period divided by the length of the respective time period it may also be noted that for effective implementation of the proposed methodology the streamflow data should be de trended before evaluating the ssai values next different categories of droughts e g moderate severe extreme are considered in the analysis depending on the numerical values also referred to as severity of the index following maity et al 2013 following near normal flow category n near normal events including normal abnormally dry and abnormally wet conditions below near normal flow drought categories d1 moderately dry d2 severely dry d3 extremely dry and d4 exceptionally dry events and above near normal flow categories w1 moderately wet w2 severely wet w3 extremely wet and w4 exceptionally wet events are considered in this categorization a value in the range of 0 7 0 7 are considered as near normal events as shown in figs 2 and 3 3 2 development of the bma based network structure and the prediction model bns are a class of graphical models that represent the association between different variables by means of directed acyclic graphs dags cooper 1990 heckerman et al 1995 witten et al 2005 given the causes causal input variables a bn can be used to compute the effect target variable development of a bn involves learning the network structure also referred to as the graph structure development of the probabilistic model parameter estimation of conditional probabilities and prediction of the target variable given the directly influencing input variables in traditional bns two different learning model selection algorithms namely score based algorithm and constraint based algorithm are utilized to learn the graph structure scutari 2017 these algorithms provide a single high scoring model that is selected as the final graph structure heckerman et al 1995 however considering the uncertainty associated with tertiary hydrologic variables such as drought and flood there may be multiple graph structures in addition to the single high scoring model that represent the dependency among the associated variables equally well furthermore other structures may present some vital information related to the conditional independence among the variables that may get overlooked while selecting the single high scoring model owing to the complexity of the hydroclimatic forcings behind hydrologic droughts it may be advantageous to identify multiple graph structures that fit the data reasonably well and derive the combined information from all these structures to obtain the association among the variables in this study the order markov chain monte carlo order mcmc algorithm based on the bma of bns is used for precisely learning the graph structure friedman and koller 2003 by averaging the information from multiple graph structures to start with all the graph structures that fit the data comparatively well based on the likelihood equivalent bayesian score also referred to as the bde score detailed description for evaluation of bde score is provided in appendix a are selected the number of selected structures is optimized so that the highly scoring graph structures are not excluded and the computational cost is minimized next the selected graph structures are grouped based on their topological order designated by θ these orders are arranged in such a way that each node may only have parents from further up the chain or following it in the ordering all the graph structures consistent with an order are combined to reduce the search to smaller space and a score is assigned to each group which is equal to the sum of the scores of all graph structures in the group next a markov chain is constructed considering all the node orders rather than all the graph structures detailed description on evaluation of the group score and construction of the markov chain is provided in appendix a by grouping together and averaging the score over so many graph structures an optimized structure is obtained that represents the association among the input variables and the target variable after identification of the final graph structure that represents the association among the variables the degree of association between the input variables and target variable is evaluated this degree of association is measured as score gained lost bde score when a particular edge for which the strength is being evaluated is included excluded from the structure that is the bde score for two graph structures one with and another without the edge are evaluated the difference between the score of the graph is considered as the edge strength using the obtained graph structure the prediction model is developed by factorization of the graph and parameter learning the prediction model is the joint probability distribution associated with a given graph structure it is obtained as a product of functions associated with a subset of the nodes variables the function turns out to be the conditional probability of a variable given its parent variables ihler et al 2007 identification of the conditional probability distribution also referred to as parameter learning is carried out using the maximum likelihood estimation mle approach details provided in appendix a the prediction model becomes ready once the parameters are estimated next the prediction of the target variable is carried out by plugging in the new values for the parents of the target variable variables directly associated with the target variable as obtained from the graph structure in the conditional probability distribution of the target variable it may be noted that the above methodology is used for the model calibration considering a particular model development period 3 3 development of the temporal networks and re calibration of prediction model the time varying characteristics are imparted to the prediction model by gradually updating the network structures over time also referred to as temporal networks dutta and maity 2020a the model development period is considered as a moving window of 30 years and the model is re calibrated iteratively after a fixed time interval say n years in terms of model inputs and parameters the value of n needs to be optimized and this optimized value is designated by τ and referred to as the optimum recursive interval ori for model re calibration dutta and maity 2020a 2018 in order to obtain τ different values of n starting from n 1 to n 5 years are considered as the time period of the study is from 1971 to 2018 the first model development period is considered from 1971 to 2000 and the model testing period is from 2001 to 2001 n 1 as the model is updated after n years the next model development period is shifted by n years and the second model development period is considered from 1971 n to 2000 n the process continues over the entire time period of the study to identify the value of τ this procedure is repeated for different values of n and the model performance during all the contiguous model testing periods is evaluated to identify the ori of model re calibration 3 4 comparison with existing approaches performance of the proposed bma based temporal network approach is compared with three commonly used modelling concepts in the field of hydrology to start with a time invariant counterpart of the bma based temporal network approach is used next two machine learning ml techniques namely support vector regression svr and artificial neural network ann are utilized in a time varying framework details on all the three models are as follows firstly for development of the bma based time invariant network approach the procedure explained in the previous sub section remains the same but only one graph structure is developed using 30 years data next the developed prediction model is used for the entire testing period without the concept of time varying models explained before lastly two commonly used ml based approaches namely svr and ann are developed based on the time varying concept but the concept of conditional independence structure is not utilized svr and ann are common machine learning techniques utilized in different hydroclimatic studies ardabili et al 2019 barua et al 2012 cristianini and shawe taylor 2000 khan et al 2020 maity et al 2010 prasad et al 2017 raghavendra and deka 2014 inputs for the svr model are identified through correlation analysis as followed traditionally in this comparison the ml based models are developed with the aforementioned time varying concept and thus the inputs and the parameters of the models are updated after n years as in the proposed bma based temporal network approach 4 results and discussions broadly the results are presented to show the temporal changes in the characteristics of hydrologic drought and the ability of the proposed model to capture temporal change in the association among the hydroclimatic variables and predict the occurrence of below above normal flow events section wise presentation of results and discussion is as follows section 4 1 shows the change in the frequency and severity of observed extreme events considering the first model development period and the contiguous model testing period next the hydroclimatic forcings directly influencing the hydrologic drought as revealed by the network structures developed using the proposed model is presented in section 4 2 section 4 3 shows the temporal change in the network structures developed using the proposed model and establishes the fact the association between the hydroclimatic forcings and extreme events is gradually changing over time section 4 4 shows the ability of the proposed bma based temporal network approach to capture the below above normal flow events lastly section 4 5 compares the performance of the proposed model with other well established modelling approaches 4 1 temporal change in the frequency and severity of hydrologic drought at the outset the change in the characteristics of extreme events is ascertained in terms of change in the frequency and severity of below above normal flow events fig 1a shows the temporal change in the frequency of the below above normal flow events evaluated individually for each month considering the time periods of 1971 2000 henceforth denoted as t1 and 2001 2018 henceforth denoted as t2 additionally the significant changes in the frequency identified using the two sample z test of proportions considering 5 significance level is also shown it is clearly noticed that the frequency of below normal flow events has increased for the post monsoon season october and november with significant increase in october winter season december february with significant increase in december and february and two monsoon months of july and august significant change in both the months furthermore the pre monsoon season march may with significant increase in april and may and other monsoon months i e june and september significant change in september exhibit an increase in the frequency of above normal flow events the higher frequency of below above normal flow events especially considering the months in the pre monsoon march may monsoon june september and post monsoon october november seasons may arise from the change in monsoon intensity and shift in monsoon pattern sahu et al 2020 secondly the temporal change considering the time periods of t1 and t2 in the severity of below above normal flow events assessed by considering the negative and positive values of ssai as two different data series is shown in fig 1b and 1c respectively through boxplots the figures show the change in the severity of below above normal flow events in terms of either increase or decrease in the mean range 25th quartile lower and 75th quartile upper values of ssai for each month of analysis the significant changes in the mean identified using the two sample t test considering 5 significance level for the below above normal flow events are shown in grey considering the months of july october months falling in the monsoon and post monsoon season an increase in the mean maximum and upper quartile value is observed thereby showing an increase in the severity of above normal flow events fig 1b similar observations can be made for the comparatively low flow months of february march april and may that exhibit significant change at 5 significance in its mean it is interesting to note that in the pre monsoon season both the frequency and severity of above normal flow events have increased in the recent time period i e t2 as compared to t1 further the severity of below normal flow events in terms of mean lower quartile and minimum value has increased considering the monsoon season june september similar observations are made for the months of november december and january too a decrease in the severity in terms of mean is observed for the months of february may significant at 5 significance however an increase in the severity in terms of the lower quartile value is observed for these months it is interesting to note that the months in the monsoon season show change in the frequency and severity of below above normal flow events depending on the month of analysis in order to ascertain the temporal change in the frequency and severity of below above near normal events the ssai values have been divided into three categories as shown in the contingency tables in fig 9 first table fig 2 shows the temporal change considering time periods t1 and t2 in the frequency of different categories of below above near normal flow events for each month of analysis it may be noted that for all months starting from january to december the frequency of below near normal events has increased similarly the frequency of above near normal events has also increased for the months of february september thereby considering the months in the monsoon season june september the frequency of near normal events has decreased and the frequency of both above and below near normal events have increased moreover the severity of above near normal and below near normal events has increased decreased either in terms of mean upper quartile lower quartile or maximum minimum values for almost all the months fig 3 the significant changes in the mean identified using the two sample t test considering 5 significance level for all the three categories of below above near normal flow events are shown in grey the pre monsoon months of march and april show significant increase in the mean severity of above near normal events and significant decrease in the mean severity of below near normal events the month of may shows a significant decrease in the mean severity of below near normal events next considering the monsoon months of june july and august significant change is observed in the mean severity of both above and below near normal events for instance the months of june and august show significant decrease in the mean severity of above near normal events and july shows significant increase in the mean severity of above near normal events furthermore the post monsoon season october and november shows significant decrease in the mean severity of below near normal events thereby alterations of the hydrologic cycle strongly impact the characteristics of the extreme events over time and significant temporal changes are noticed in the recent decades t2 as compared to past t1 4 2 hydroclimatic forcings behind hydrologic droughts as revealed by the network structures the proposed approach is based on the concept of network structures which provides the complete conditional independence structure that reveals the hydroclimatic forcings behind the hydrologic droughts figs 5 panel 1 and 6 panel 1 show the network structures for the first model development period 1971 2000 considering one typical low flow january and high flow july month respectively the input variables temperature te precipitable water pw potential evapotranspiration pe pressure pr relative humidity rh soil moisture sm rainfall ra streamflow st all inputs from the previous month and the target variable ssai current month of analysis are represented by differently colored nodes and the association between any two variables is shown by a directed edge absence of an edge can be interpreted as the variables being independent or conditionally independent and presence of an edge can be interpreted as the variables being directly dependent considering the month of january a typical high flow month ssai target variable is directly dependent on streamflow and conditionally independent of all the other input variables streamflow is directly influenced by soil moisture which is in turn directly dependent on rainfall and temperature further relative humidity is associated with rainfall precipitable water and potential evapotranspiration a possible reason for the indirect connection between rainfall and precipitable water could be the multiple factors affecting precipitation quantity like degree of saturation atmospheric water vapor and the presence of dynamic mechanisms which provide the cooling necessary to produce saturation similar network structures are identified for each month and the input variables directly influencing ssai are shown in fig 7 in fig 7 input variables are represented by colored squares black color indicates no association or conditionally independent association and different shades of red indicates significant association with varying values of edge strengths strength of association considering other low flow months of december february march april and may and the first model development period fig 7a streamflow emerges as the primary influencing variable for 1 month ahead prediction for the months of may and december in addition to streamflow rainfall also shows direct association with ssai a probable reason can be the higher rainfall magnitude in the months of may falling in the pre monsoon season and december falling in the winter monsoon season as compared to the other low flow months for the considered study area next considering the month of july a typical high flow month and the first model development period fig 6 panel 1 ssai target variable is found to be directly dependent on rainfall and precipitable water furthermore the streamflow variations show direct dependence on soil moisture and rainfall and relative humidity is directly associated with temperature potential evapotranspiration and precipitable water during high flow months it is expected that the moderately sized catchment will almost be in a stationary state as the precipitation is quite continuous over time thus the variation in extreme events will respond mainly to precipitation variation in time fig 7b shows that precipitable water directly influences ssai for august and september other monsoon months during the first model development period streamflow shows a direct association with ssai in case of june first monsoon month and november thereby the complete conditional independence structure as identified by the proposed approach helps to identify the directly influencing variables and given these variables below above normal flow events are conditionally independent or independent of the other hydroclimatic forcings 4 3 temporal change in the hydroclimatic forcings behind hydrologic droughts the time varying association between hydroclimatic forcings and ssai is assessed through the proposed bma based temporal network approach to start with the first 30 year period is considered as the first model development period and the initial network structure is developed the network structure is recursively re developed after each τ years interval denoted as ori as defined in the methodology section section 3 3 the value of τ is ascertained by assuming different values n 1 2 3 and comparing the model performance for the contiguous model testing period four performance metrics namely correlation coefficient r nash sutcliffe efficiency nse index of agreement dr coefficient of determination r 2 and root mean square error rmse are utilized for assessment fig 4 shows the month wise performance of the models considering the different values of n 1 2 5 years it is observed that a value of n 2 years and n 3 years provides the best possible performance considering the months in the monsoon and post monsoon season june november and the months in winter and pre monsoon season december may respectively thereby the prediction model needs to be re calibrated after 2 and 3 years considering the comparatively low flow and high flow months respectively in order to capture the time varying association among the hydro meteorological variables considering the value of τ as 2 years the corresponding model development periods testing periods are 1971 2000 2001 2002 1973 2002 2003 2005 1987 2016 2017 2018 and considering the same as 3 years the corresponding model development periods testing periods are 1971 2000 2001 2003 1974 2003 2004 2006 1986 2015 2016 2018 thereby the model is calibrated 9 times for the high flow months and 6 times for the low flow months considering the entire time period 1971 2018 of the study figs 5 and 6 show the time varying temporal networks obtained for the 6 model development periods considering a typical low flow january and a typical high flow july month respectively for example considering the month of january and the first model development period ssai is directly dependent on streamflow whereas for the second model development period fig 5 panel 2 in addition to streamflow ssai also shows a direct dependence on temperature further it is interesting to note a distinct change in the interaction among the other input variables also for instance soil moisture is conditionally independent of rainfall and temperature similar observations can be made for the third model development period also such changes in the interaction among the variables are accounted for by the modified rainfall pattern for the considered study area and a change in the terrestrial environment considering the fifth and sixth model development period ssai shows direct dependence on the streamflow and potential evapotranspiration in addition to other input variables change in climatic factors like high low vapor pressure increased decreased radiation in the surrounding region and change in terrestrial environment may affect the influence of potential evapotranspiration over time next considering the month of july and the first model development period ssai is found to be directly dependent on rainfall and precipitable water it is interesting to note that considering the second model development period fig 6 panel 2 in addition to rainfall and precipitable water potential evapotranspiration also shows a direct association with ssai the interaction between the other input variables is more or less similar with pressure remaining independent of all the other variables this result contradicts the findings obtained for a typical low flow month whereas the interaction between the variables drastically changes over the time considering the sixth model development period 1981 2010 ssai shows a direct dependence on rainfall relative humidity and precipitable water a gradual shift in the directly dependent input variables is observed considering the last two model development periods with increasing dependence of ssai on soil moisture and potential evapotranspiration similar temporal networks are identified for each month and the input variables directly influencing ssai are shown in fig 7 for example considering the month of february during the first model development period 1971 2000 ssai is directly dependent on streamflow and potential evapotranspiration but conditionally independent of precipitable water pressure temperature relative humidity soil moisture and rainfall moreover the strength of association between ssai and streamflow is stronger considering the first three model development periods i e 1971 2000 1974 2003 and 1977 2006 gradually the strength reduces over time as noticed for the fourth 1980 2009 fifth 1983 2012 and sixth 1986 2015 development periods a closure observation reveals that the high variation in february streamflow series is noticed during the entire time period with a significantly increasing trend till late 1990s and a decreasing trend afterwards this leads to a changing below above normal flow events and alteration in the association of ssai with streamflow over time based on the obtained results it is interesting to notice that ssai for the low flow months namely january february march april may and december with the streamflow range of 1 83 to 249 55 cumec is strongly associated with streamflow fig 7a contrary to this during the high flow months of june july august september october and november where the range of streamflow lies between 247 88 and 6572 32 cumec the dominant predictors are rainfall precipitable water and relative humidity fig 7b furthermore the number of input variables directly influencing ssai considering a particular model development period for the high flow months is more as compared to the low flow months as streamflow is the dominant predictor considering the ssai of the low flow months with high strength of association most of the information on the below above normal flow events can be extracted from streamflow itself making the contribution of other variables insignificant however considering the high flow months most of the significant input variables show similar association with ssai and information from all these variables is vital to explain the below above normal flow events it can be clearly stated that the causal factors input variables of extreme events change temporally for a particular season as well as from one season to another thereby it is vital to iteratively re calibrate the model to successfully capture the below above normal flow events 4 4 performance of the proposed time varying approach the observed and predicted ssai values obtained using the bma based temporal network approach along with the different categories of below above near normal flow events depicted with different color gradations of red blue are shown in fig 8 the near normal events are shown in grey the proposed approach shows satisfactory performance in capturing the events falling near normal to severe dry wet flow events however considering the extreme and exceptional dry wet flow events the model shows better performance in capturing these two wet flow categories as compared to these dry flow categories further considering four different contingency tables fig 9 shows the different categorizations of ssai maintaining the range of near normal events as 0 7 0 7 and the efficacy of the proposed model to capture the same the values mentioned in the diagonals shown in grey of the contingency tables show that the observed and predicted values of ssai fall in the same range i e a near normal below near normal above near normal events have been correctly captured along with its severity range for instance considering the third type of categorization 23 summation of last column above near normal flow events have been observed to be greater than 1 2 out of these events 18 diagonal element events have been correctly predicted to lie in this range the remaining five events have been under predicted as less severe above near normal flow events 4 and a near normal flow event 1 similarly considering the second type of categorization 57 summation of third column below normal flow events have been observed to lie in the range 1 2 0 7 24 events have been correctly predicted to fall in this range and the rest of the events are predicted as either less or more severe above normal flow events it can be observed that as the range of ssai is made smaller for categorization of below above normal flow events the model error gradually increases however the model performance is satisfactory considering all the four categories overall the ssai as well the range are well captured by the proposed bma based temporal network approach due to its ability to re calibrate the model and capture the time varying characteristics among the variables next month wise prediction performance of the proposed bma based temporal network approach is assessed by comparing the observed and the predicted ssai values fig 10 the results show that the predicted values closely follow the observed values for many months such as january march may october and november for the months of february april july and september positive errors are noticed and for the months of june august and december negative errors are observed it is also interesting to note that as compared to the high flow months the statics value lie in the following range r 0 85 0 91 rmse 0 50 1 13 nse 0 75 0 82 and dr 0 75 0 83 the performance of the model is comparatively better considering the low flow months the statics value lie in the following range r 0 86 0 92 rmse 0 32 1 01 nse 0 75 0 87 and dr 0 80 0 91 a probable reason is the high variations in streamflow during the high flow months leads to extreme and exceptional above near normal flow events that are complex in nature further the uncertainty range considering the predictions at the 5th and 95th percentile is also shown in fig 10 it may be noted that all the observed values fall within the uncertainty range except one observed ssai value in the months of february and april 4 5 comparison of the proposed approach with the other modelling approaches performance of the bma based temporal network approach is compared with three other modelling approaches i bma based time invariant network approach ii svr based time varying approach and iii ann based time varying approach the performance statistics obtained using all the three models are compared in table 1 the models are designated as m1 m2 m3 and m4 and the data series for month wise analysis is designated as s1 furthermore fig 11 shows that the bma based temporal network approach successfully captures the mean and range of the ssai values considering all the months of analysis moving our attention to the low flow months it is clearly evident that the bma based time invariant network approach gives sub power performance due to its inability to identify the temporal change in the causes effect relationship moving on to the ml based time varying approaches the results indicate that for the low flow months the model is able to reasonably capture the mean and range of ssai except for the months of january and may however considering the high flow months performance of the proposed model is better as compared to the ml based time varying approaches month wise analysis is also carried out with non detrended series and the results are presented in table 1 data series for month wise analysis is designated as s1 ndt for all the four models it may be observed that the analysis carried out after removing the trend shows a slightly improved performance as compared to using the non detrended series overall the ability of the proposed approach to capture the true dependence structure between the large pool of hydro meteorological variables and drought index improves the prediction skill of the proposed model next additional analysis is carried our considering ssai for all the months as a single series having established the efficacy of the time varying approach over the time invariant counterpart results obtained using the three time varying approaches temporal network svr and ann based considering all the months as a single series is shown in fig 12 a while carrying out the month wise analysis it was observed that a unique set of predictors are identified for each month considering a particular time period when ssai for each month is analyzed as a single series it is observed that the set of predictors identified are dominated by the fact that most of the months november may are low flow months as compared to the monsoon season june september thereby the model performance deteriorates the statics value using the proposed approach are r 0 69 rmse 0 70 nse 0 56 and dr 0 62 table 1 in comparison to the month wise analysis the model is unable to specially capture the below above normal flow events for the high flow months due to the inability of the model to appropriately identify the predictor set fig 12a also compares the performance of the three time varying models utilizing the box plots in terms of capturing the mean and range of the observed data the performance of all the models are comparable however when comparing the performance statics considering the svr ann based time varying approach and monthly drought index as a single series are r 0 50 0 45 rmse 0 89 0 99 nse 0 40 0 38 and dr 0 43 0 41 table 1 it is observed that the proposed model out performs the ml based time varying approaches due to its ability to appropriately identify the complex mechanism associated with hydrologic drought the prediction models developed so far can be utilized to provide 1 month ahead forecast of below above normal flow events in order to provide an outlook of the model performance with a longer lead time results for 3 month ahead forecast are also presented in table 1 and fig 12b considering a longer lead time the statics value using the proposed approach are r 0 75 rmse 0 88 nse 0 66 and dr 0 73 table 1 the model performance gradually deteriorates the primary reason being the increase in the lag time of the influencing hydro meteorological variable and ssai however given the complex nature of tertiary hydrological variables such as floods and droughts the model very well captures the extreme flow events for the considered study area with the availability of the data for the hydroclimatic forcings that influence the hydrologic droughts from different sources like the ground observations and reanalysis products effective forecast with a lead time of 1 to 3 months can be provided using the developed model further on availability of the observed streamflow data the model should be re calibrated at span of 2 3 years based on the identified ori of model re calibration in order to capture time varying association among the hydroclimatic variables and extreme events this time span may change based on the study area considered 5 summary and conclusions inherent non stationarity owing to the impact of climate and terrestrial changes causes a gradual change in the characteristics of hydrological extremes this study proposes a bma based temporal network approach as an efficient modelling technique for capturing such slow moving changes and prediction of hydrologic extremes by assessing the time varying cause effect relationship between hydroclimatic variables and extreme events changing climate and dynamic terrestrial environment suggests a change in the characteristics of extreme events like flood and drought considering the river basin used for this study results indicate temporal change in the characteristics of extreme events an increase in the frequency of occurrence during the time period of 2001 2018 with respect to the first model development period of 1971 2000 of below normal flow events can be observed with an increased severity especially during the monsoon season june september studies have established that change in climatic factors such as high temperature precipitation deficit increased evaporation reduced runoff and infiltration caused due to combined effect of climate variability and human activities has reduced streamflow which might be a primary cause for increase in hydrologic drought kim and jehanzaib 2020 similar observations of change in frequency and severity are also made considering the non monsoon months hence establishing the temporality associated with the characteristics of extremes further the benefit of applying the time varying concept in prediction of extreme events is established by carrying out basin scale prediction in the proposed time varying approach bma is used to develop the network graph structures that are re iteratively updated to obtain a series of networks temporal networks this helps to establish the change in the causality of extreme events in this technique instead of learning a single static high scoring graph structure the information from multiple probable graph structures is used to obtain the final graph structure that are updated after a fixed time interval which reduces the uncertainty while dealing with tertiary hydrologic variables like flood and drought and capture the temporal change in the causality of the extreme events in a non stationary environment as a typical example 1 month ahead hydrologic drought prediction defined by a streamflow based index ssai is carried out to study the efficacy of the proposed approach applying the concept of bma based temporal networks the results indicate that the proposed prediction model in terms of model inputs and parameters needs to be re calibrated every 2 years and 3 years considering the high and low flow months respectively in order to appropriately capture the time varying association between the input and target variables based on the time varying dependence structure obtained among the variables drought index ssai for the low flow months are strongly associated with streamflow contrary to this considering the high flow months the dominant predictors are rainfall precipitable water and relative humidity results also show that the bma based temporal network approach successfully captures the extreme events associated with both low and high flows further dividing the extreme events into different classes based on the severity of below above normal flow events the proposed model shows satisfactory agreement with the observed events that is the predicted ssai values very well captures the severity of the below above normal flow events with higher efficacy considering the above normal flow events the ability of the proposed approach to identify the conditional independence structure among a large pool of associated variables considering the complexity associated with tertiary hydrologic variables and capture the time varying association among the variables can be effective for analyzing complex hydrologic processes overall the findings of this study establish i the change in the drought frequency and severity over time and ii benefit of the time varying concept as an efficient approach for such complex hydrologic extremes exhibiting gradual change in its characteristics whereas the first issue is being realized established for many hydrological variables at different places around the world the second aspect is a valuable contribution in terms of a remedial measure to handle such cases through a proper assessment of time varying cause effect relationship between hydroclimatic variables and extreme events credit authorship contribution statement riya dutta methodology investigation writing original draft rajib maity conceptualization methodology investigation writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work is supported by the ministry of earth science government of india through a sponsored project daily streamflow data are collected from the water resources information system in india at http www india wris nrsc gov in daily rainfall data are obtained from india meteorological department imd the climatic variables are obtained from the climate prediction centre cpc of the national oceanic and atmospheric administration noaa at https www cpc ncep noaa gov appendix a mathematical details for development of the bma based network approach the following section gives the mathematical details for evaluation of the bde score evaluation of the group score development of the markov chain and factorization of the final graph structure evaluation of the bde score the score of each graph structure also known as the bde score geiger and heckerman 2002 is the posterior probability of the structure evaluated as 1 p g d p d g p g i 1 n s x i p a i d where g refers to the network structure among the variables d represents the data set s is a score function dependent on variable xi and pai is the parent set of variable xi scoring of the topological orders θ each order θ receives a score r θ d equal to the sum of the scores of all graph structures in the order 2 r θ d g θ p g d the score of each node s possible parent sets is computed and efficiently used as the sum of the scores of all the graph structures compatible with a particular order friendman and koller 2003 the score of the order is evaluated as the product of the node score sums over possible parent sets 3 r θ d g θ p g d i 1 n p a θ i s x i p a i d construction of the markov chain a chain with stationary distribution proportional to r θ d is produced by a metropolis hastings algorithm with acceptance probability 4 ρ m i n 1 q θ j θ r θ d q θ θ j r θ j d where q θ θ j is the probability of proposing a move to θ from θ and can be any move in the space of orders the simplest move is flipping two nodes in the order while leaving the position of others unchanged upon convergence order mcmc provides a sample of an order θ from a distribution proportional to the score r θ d over the space of possible orders of the nodes of the graph structure given a sampled order a network structure is selected by sampling the parents of each node independently according to the scores of its permissible parent sets factorization and parameter learning of the final graph structure let x 1 x 2 x n be n random variables with a known graph structure directed graph the joint probability distribution also known as the global probability distribution depends on a set of local probability distributions one for each node variable it can be expressed as follows 5 p x 1 x 2 x n i 1 n p x i p a i where p x i p a i is the local conditional probability associated with node i a specific form of the factorization given by the markov property of bns korb and nicholson 2004 states that every random variable xi directly depends only on its parents thereby the conditional probability of any variable xi given rest of the variables can be written as 6 p x i r e s t p x i p a i in order to identify the local probability distribution two methods namely bayesian parameter estimation and maximum likelihood parameter estimation can be utilized scutari 2017 2010 in this study mle is used to learn the parameter set φ of the joint probability distribution function of the variables that can be represented as 7 p x 1 x 2 x n φ i 1 n p x i p a i θ i where θ i is the vector of parameters for the conditional distribution of x i and φ θ i θ n given the training data x x 1 x m where x l x l 1 x ln and m is the number of observations for each variable the log likelihood of θ with rest to x is computed as 8 l o g φ x l 1 m i 1 n l o g p x li p a i θ i the likelihood function as given in equation 5 which decomposes according to the network structure thereby the mles for each node is computed independently neapolitan and jiang 2007 the local probability distribution is extracted from the fitted probabilistic graphical model scutari 2017 the probabilistic distribution is used to predict the target variables given the directly influencing input variables 
4021,data assimilation of snow observations significantly improves the accuracy of snow cover simulations however remotely sensed snowpack observations made in areas of complex topography are typically subject to large error and biases creating a challenge for data assimilation to improve the reliability of ensemble snowpack simulations this study investigated the appropriate conditions for assimilating modis like synthetic surface reflectances we used a simulation system that included the particle filter data assimilation technique more than 270 ensemble simulations involving assimilation of synthetic observations were conducted in a twin experiment procedure for three snow seasons these tests were aimed at establishing the spectral combination of modis like reflectances that convey the more information in the assimilation system rendering the most reliable snowpack simulation and determining the maximum observation errors that the assimilation system could tolerate the assimilation of the first seven modis like bands covering visible and near infrared wavelengths provided the best scores compared with any other band combination and thus are highly recommended for use when possible the simulation system tolerated a maximum deviation from ground truth of 5 without loss of performance however the assimilation of the first seven bands of true modis surface of reflectance fails on improving simulation results in rouged mountain areas keywords snowpack modelling snow surface reflectance data assimilation particle filter mountain areas 1 introduction some of the major natural hazards in mountain areas are directly linked to the snowpack distribution and its evolution over time and include snow avalanches schweizer et al 2003 2008 and floods in downstream areas gaál et al 2015 forecasting snowpack evolution in mountain areas is increasingly based on numerical snowpack models lehning et al 2006 vionnet et al 2012 morin et al 2020 the marked natural spatial and temporal variability in the snowpack in mountain areas scipión et al 2013 seidel et al 2016 necessitates accurate simulation of snowpack processes and accurate meteorological inputs hence snowpack modelling is affected by forcing and model errors that result in discrepancies between the real state and the simulated snowpack morin et al 2020 the accumulation of such discrepancies over time decreases forecasting capabilities leading to large uncertainties in risk management consequently for robust operational use the snowpack models need to provide upgraded real time forecasts wayand et al 2015 ensemble approaches are commonly used to quantify the uncertainties associated with simulations e g swinbank et al 2016 vernay et al 2015 moreover data assimilation techniques enable optimal combinations of simulations usually an ensemble representing possible simulation states and observations to mitigate uncertainties arising from both sources of information andreadis and lettenmaier 2006 clark et al 2008 largeron et al 2020 data assimilation techniques in snowpack modelling are known to significantly reduce simulation uncertainties and biases magnusson et al 2017 piazzi et al 2019 however the possible assimilation observations and their optimal frequencies and spatial extent may vary depending on the assimilation technique and the characteristics of the observations in situ measurements are the most accurate observations ménard et al 2019 winstral et al 2019 but their generally poor spatial extent and representativeness makes them inappropriate for large scale simulations at reasonable spatial resolution i e several hundreds or thousands of meters however different studies have exploited these observations with different data assimilation schemes magnusson et al 2017 piazzi et al 2018 remote sensing observations including those involving optical space borne sensors collect information on the snowpack surface at high spatial resolution over large areas immerzeel et al 2009 gascoin et al 2015 dumont and gascoin 2016 although the frequency of optical remote sensing in some regions is limited by cloud cover hall and riggs 2007 the assimilation of sparse satellite observations into snowpack models has significantly improved the simulation results in theoretical experiments based on synthetic observations charrois et al 2016 cluzet et al 2020a similarly active satellite sensors have been assimilated in large study areas cortés et al 2016 larue et al 2018 margulis et al 2019 and in some cases combined with in situ observations piazzi et al 2019 showing encouraging results these works demonstrate the effort of the snow modeling community on assimilating snow observations to improve forecasting capabilities of snow models probably remote sensing techniques capability of retrieving information over extended and remote areas is the main reason that has motivated this attempt snow spectral reflectance varies substantially with wavelength in the solar spectrum warren 1982 the information held in the various bands of optical satellite sensors can provide information about various snowpack surface properties including snow aging snow microstructure or light absorbing particle content painter et al 2012 skiles et al 2018 in addition snow cover monitoring using satellites particularly in highly heterogeneous areas having patchy snow distribution and or highly complex topography is affected by a number of sources of uncertainty frei et al 2012 cluzet et al 2020a when this information is assimilated using a data assimilation scheme the potential deviations of the observation must be taken into account and appropriately represented in the simulation system janjic et al 2018 various data assimilation techniques have been tested depending on the characteristics of the snowpack model and the type of observations the ensemble kalman filter scheme evensen 2003 has been shown to efficiently assimilate remote sensed and ground based snow observations improving simulation accuracy piazzi et al 2019 however the implementation of this technique is challenging and is associated with significant limitations for detailed snowpack models piazzi et al 2018 the particle filter pf van leeuwen 2009 is a data assimilation technique that does not rely on physical assumptions of the system and is well suited to snowpack models charrois et al 2016 piazzi et al 2018 the efficiency of the pf in assimilating observations into snowpack models has been tested in many study areas and with differing observation datasets thirel et al 2013 magnusson et al 2017 the pf technique largely reduces the uncertainty in ensemble simulations of the snowpack when reproducing the snow depth sd and snow water equivalent swe smyth et al 2019 and has also showed encouraging results in distributed simulations baba et al 2018 moreover the pf technique only selects or discards particles resampling those members selected depending on the distance to the observed variable and in this way maintains the consistency between state variables magnusson et al 2017 these attributes have encouraged snow modelling scientists to implement the pf technique in assimilating snowpack variables retrieved using satellite sensors largeron et al 2020 nevertheless in view of the fast development of both remote sensing and models arising in the snow science community girotto et al 2020 an assessment on measurement errors that may be admissible for improving simulation results is required this study relied on the detailed crocus snowpack model vionnet et al 2012 which has been used for more than 25 years in the french mountain ranges to provide operational support for avalanche hazard forecasting to reduce discrepancies between the observed and simulated snowpack revuelto et al 2018 recent developments in this simulation system have aimed to assimilate different snowpack variables with pf assimilation algorithm charrois et al 2016 charrois 2017 cluzet et al 2020a b the assimilation of synthetic observations including sd and snow surface reflectance has already demonstrated a remarkable improvement on the forecasting capabilities of crocus charrois et al 2016 similarly the assimilation of ground based surface reflectance also reduced crocus simulations uncertainties but oppositely the assimilation of true satellite retrieved optical reflectance with modis sensors failed charrois 2017 this is mainly attributed to the bias of modis snow surface reflectances likely due to complex terrain effects cluzet et al 2020a previous studies have paved the way for substantial improvements to detailed snowpack simulations but have also highlighted the need of determining the maximum observation uncertainties that can be tolerated in the assimilation system and which spectral observations convey the more information in the system this study aims at determining the minimum accuracy of snow surface reflectance satellite observations needed to guarantee an effective assimilation that improves snow simulation capabilities this study describes assimilation experiments using both synthetic and modis surface reflectance with croco c1 0 an ensemble data assimilation system cluzet et al 2020b first we investigated the performance of pf algorithm with respect to the spectral bands assimilated which enabled us to determine whether there was a particular band combination rendering better simulation scores second we assessed the maximum observation errors acceptable with respect to improving the forecasting capability of simulations using data assimilation to address these objectives we tested the performance of pf in assimilating synthetic observations using a twin experiment involving data assimilation dates selected from true modis images made under ideal conditions no clouds and high viewing zenith angles for retrieving snow surface information in view of the potential for implementation of this system to assimilate real optical surface reflectances the synthetic observations involved modis like surface reflectances extracted from various reference members considered to represent the truth snowpack conditions termed truth members this procedure included information on all snowpack variables at any time enabling full evaluation of the assimilation and also overcame potential shortcomings of real observations the performance of the assimilation system was evaluated by assessing the impact that data assimilation had on the bulk snow variables sd and swe finally for the band combination rendering the best results the assimilation of true modis surface reflectance was evaluated analyzing the capability of the simulation system on reproducing the observed sd the simulation exercise presented here spanned three snow seasons 2014 15 2015 16 and 2016 17 at the col du lautaret study site in the french alps in total 270 data assimilation experiments were carried out and combined differing modis like spectral bands and various biases and errors introduced in the assimilated reflectances section 2 describes the simulation and assimilation systems provides detailed information about the study period and the study site and describes the evaluation procedure section 3 presents and describes the main results obtained section 4 discusses the main results and section 5 presents the conclusions from the study 2 data and methods the snowpack data assimilation system aims to reduce the dispersion of an ensemble of simulations towards the true evolution of the snowpack globally the simulation system reproduces the snowpack along the snow season when a snowpack observation is available the ensemble of simulations is stopped and resampled trough the particle filter afterwards the simulation of the resampled ensemble continues until the next assimilation or the end of the snow season if no more observations are available this section after describing the study area and period provides an overview on the simulation system comprising snowpack simulations meteorological forcing generation of the ensemble and the assimilation procedure later on once modis data processing is described section 2 4 the twin experiment procedure followed in this work is detailed section 2 5 finally the assimilation experiments that enabled the assessment on the efficiency of the system in view to the different bands combinations assimilated section 2 6 and the bias of surface reflectance tolerated by the system section 2 7 are specified 2 1 study site and period the simulations were conducted in col du lautaret a mountain pass located in the central french alps 45 02 n 6 46 e between four alpine massifs ecrins pelvoux grandes rousses and thabor at an elevation of 2058 m a s l the study area is completely covered by alpine grassland and has a flat topography and without any predominant exposition see summer and winter pictures of fig 1 despite the surrounding topography is rugged but locally open see fig 1 the satellite observations of this study site are also influenced by the diffuse radiation scattered by the neighborhood that characterizes snow covered rugged terrain and by direct re illumination effects lamare et al 2020 because of its accessibility and high elevation it has been involved in many snow studies lamare et al 2020 larue et al 2020 revuelto et al 2020 tuzet et al 2020 moreover this site is equipped with an automatic weather station acquiring different variables including sd as other data assimilation studies in mountain areas smyth et al 2019 winstral et al 2019 our study period included three snow seasons 2014 15 2015 16 and 2016 17 and thus included a wide variety of meteorological events and snowpack conditions 2 2 open loop simulation system the simulation platform used for simulating snow evolution is the externalized surface model surfex which integrates the crocus snowpack model vionnet et al 2012 and the multilayer soil model isba dif decharme et al 2016 crocus is a detailed multilayer snowpack model that simulates the most important processes within the snowpack including all energy and mass exchanges between the snow layers the soil and the atmosphere the tartes radiative transfer scheme libois et al 2015 was recently implemented in crocus to provide a vertical profile of solar radiation absorption from snow microstructure profiles based on the specific surface area ssa and the concentrations of light absorbing particles laps e g black carbon and mineral dust deposited on the snow surface tuzet et al 2017 in this study the multi physics version of crocus was used escroc ensemble system crocus lafaysse et al 2017 to account for model errors in ensemble simulations this way crocus simulates the temporal evolution of nearly all variables describing the different snowpack layers vionnet et al 2012 including the seven modis like surface reflectance bands and bulk snow pack variables as the sd and the swe the simulations were conducted on a 250 250 m pixel with the topographical attributes slope elevation aspect of col du lautaret the meteorological inputs were obtained from the safran reanalyses durand et al 2009 vernay et al 2015 safran reanalysis provides at hourly time step all atmospheric variables needed to run crocus model including air temperature specific humidity precipitation phase and rate direct and diffuse radiation long wave radiation and wind speed this analysis scheme has a semi distributed geometry providing for discrete units of the alps of about 1000 km2 named massifs and included all meteorological variables needed for running crocus simulations we considered the meteorological forcings corresponding to the elevation aspect and slope of the study sites for the four safran massifs oisans pelvoux grandes rousses and thabor because of the position of our study site at the intersection of these massifs from each of these four reanalyses we obtained 50 members perturbed using a stochastic approach charrois et al 2016 using mocage outputs which is the chemistry transport model of météofrance modèle de chimie atmosphérique de grande echelle josse et al 2004 an ensemble of lap deposition fluxes was generated and stochastically associated with safran members the 200 meteorological members obtained were randomly combined with 200 parameterizations of crocus through the e1tartes option of escroc as described by cluzet et al 2020a an example of the temporal variability of the ensemble of snowpack simulations without data assimilation open loop based on the evolution of sd during the study period is provided in fig 2 2 3 data assimilation algorithm the pf technique was implemented using the sampling importance resampling sir algorithm gordon et al 1993 van leeuwen 2009 the pf technique estimates the distribution of possible states of a system using a probability density function based on the sampling of the members of an ensemble each time that an observation is available all particles of the ensemble are weighted through the likelihood to the observation by computing the change in the relative importance of the probability density function this function also takes into account the inherent error in the observations through a covariance matrix r cluzet et al 2020b once the ensemble of possible states particles has been weighted particles are resampled those having a negligible weight are discarded and those having higher weights closer to the observed value are replicated the resampling essentially maintains the total number of particles but outputs a less dispersive ensemble shifted towards the observed value when properly settled see fig 2 in van leeuwen 2009 further details of this technique and the theory behind it are described by van leeuwen 2009 the practical implementation of the crocus model and reflectance assimilation is described in detail by cluzet et al 2020b 2 4 modis data processing many studies have demonstrated the usefulness of modis images for snow cover mapping in mountain areas at 500 m spatial resolution gascoin et al 2015 parajka and blöschl 2008 sub pixel snow monitoring of the snow cover at 250 m spatial resolution was performed using modimlab software dumont et al 2012 sirguey et al 2009 multispectral fusion between mod02hkm and mod02qkm sirguey et al 2008 enabled this software to generate images at 250 250 m spatial resolution to derive various snow ice products including the first seven bands of modis sensor respectively 460 560 640 860 1240 1640 and 2120 nm central wavelengths and also cloud cover fraction these variables were obtained for all available modis sensor images from terra platform along the study period modis images were used to select data assimilation dates to ensure the highest quality satellite images we checked modis images for col du lautaret to find dates on which the site was fully snow covered the sky was clear and the viewing azimuth angle was high 60 sirguey et al 2016 for the 2014 15 2015 16 and 2016 17 snow seasons 16 14 and 19 assimilation dates respectively met these requirements for these dates snow surface reflectance for the first seven modis bands was also kept for assimilation 2 5 twin experiment with true and synthetic observations twin experiments are typically used to test data assimilation techniques matgen et al 2010 dubinkina et al 2011 browne and van leeuwen 2015 in essence a twin experiment compares two ensembles an open loop ensemble without data assimilation and a second ensemble assimilating observations the data assimilation system has been tested with two different observations datasets modis like surface reflectance derived from the open loop ensemble and true modis surface reflectance these two datasets allowed to explore different assimilation scenarios having a detailed description of the snowpack at any time and also to evaluate the performance of the simulation system when assimilating true satellite observations for the distinct assimilation experiments detailed in the next section synthetic observation values were only obtained for dates in which modis observations had high quality section 2 4 from one member of the open loop ensemble this member named the truth or reference run was considered to describe the real snowpack state for the given experiment and contained temporal information on all variables of the simulation system when assimilating synthetic observations the reference run was removed from the ensemble the assimilation of both true and synthetic observations had same data assimilation dates which selection was only based on the quality of satellite images and thus they reproduces true operational assimilation procedures based on the availability of high quality observations providing a realistic temporal repetitiveness of assimilation dates 2 6 assimilation experiments one major advantage of the twin experiment framework is that we were able to conduct various tests assimilating distinct reference runs including true modis observations this enabled assessment of the efficiency of the system as a function of the location of the true state within the ensemble for the three snow seasons we tested the assimilation of seven reference runs 21 in total randomly selected from the open loop simulation table 1 shows the sd and the swe percentiles based on mean values during the period when snow was on the ground in at least one member for the various reference runs in the open loop ensemble the random selection of several reference runs for each snow season illustrate how possible snowpack conditions may be simulated and how data assimilation may impact simulation results for different cases in turn this procedure allows determining which spectral bands convey the more info in the system the final objective is the assimilation of true modis observations this way the covariance matrix of errors r of the pf density function had to account for real modis sensor errors in the case study of twin experiments this is a diagonal matrix having the following errors 7 1e 4 4 6e 4 5 6e 4 5 6e 4 2 0e 3 1 5e 3 and 7 8e 4 wright et al 2014 errors reported in this later work were determined comparing modis observations with spectral albedo field measurements and as far author knows these are one of the few datasets available on modis spectral bands accuracy over snow thereby our assimilation experiments used r matrix with elements from deviations reported by wright et al 2014 since some exploratory analysis of charrois 2017 suggested that an r matrix with elements multiplied by a factor of 5 obtained more reliable ensembles we also tested the assimilation of synthetic observations with r matrix with such a multiplicative factor termed here in after f5 additionally the impact of assimilating four combinations of surface reflectance bands was investigated for each of the 21 synthetic observations evaluated the first of these combinations comprised the assimilation of the seven bands configuration a the second combination included the assimilation of the first and fifth modis like reflectances 460 and 1240 mm configuration b the third combination tested configuration c aimed to evaluate the impact of assimilating visible and the first very near infrared band together 460 560 640 860 nm this involved the first four modis like reflectances the fourth combination configuration d assimilated three near infrared bands 1240 1640 2120 nm all band combinations and configuration names used here after are detailed in table 2 these band combinations were aimed at evaluating the performance of the system for several spectral band configurations spectral reflectances more sensitive to impurities on the snow surface first four modis like bands reflectances accounting for snow aging the three higher wavelength modis like bands dozier et al 2009 skiles et al 2018 or those assimilating other band combinations having better scores the band combination showing the best results has been evaluated with true modis surface reflectance to analyze the reliability of true data assimilation of snow surface reflectance whereas the assimilation experiments with synthetic observations were evaluated with sd and swe forecast of the true state reference run the assimilation of true modis surface reflectance was evaluated with the sd observed at the automatic weather station located within the study area 2 7 biased surface reflectances to investigate the robustness of data assimilation to random errors and systematic biases in optical satellite observations we also ran the following experiments first three white noises 2 5 and 10 having random values within these intervals for the various assimilation dates were introduced to the synthetic surface reflectances secondly the synthetic observations were systematically biased for all assimilation dates using 2 2 5 5 10 and 10 of the truth member values these experiments were only applied to the best band combination identified by the experiments described in section 2 6 2 8 evaluation metrics the evaluation metrics must assess the performance and quality of the ensemble in reproducing the evolution of an observed variable i e verification variable of the truth member the metrics obtained with and without data assimilation were compared enabling evaluation of the impact that data assimilation had on the forecast of the ensemble the mean of the daily continuous ranked probability score crps hersbach 2000 gneiting et al 2007 tödter and ahrens 2012 over time was chosen because it is one of the most common probabilistic metrics for jointly evaluating both the reliability and sharpness of the probability distribution simulated by an ensemble system this score decreases towards 0 when the ensemble tends towards a perfect deterministic simulation and is expected to be reduced by data assimilation an ensemble is reliable if events are forecast with the right probability and has good resolution if it is able to discriminate among different events by issuing different forecasts for further details see atger 1999 the reliability component of the score reli can be isolated following hersbach 2000 the crps and reli were computed for the ensembles with and without data assimilation for the verification variables sd and swe the crps for each time step crpst was obtained from eq 1 1 crp s t r f t x o t x 2 d x where ft x is the cumulative distribution function at time t and ot x is the corresponding cumulative distribution function of the observation heviside function with center in the true value at time t afterwards the crpst is averaged over time to obtain crps values of the different simulation tests the crps is the sum of the reliability reli of the ensemble and its resolution resol 2 crps r e l i r e s o l thus the crps is both a metric of ensemble reliability and its resolution an ensemble is reliable the lower reli is the better forecasts the ensemble if events are forecasted with the right probability and has good resolution if it is able to discriminate between different events by issuing different forecasts atger 1999 for reliable systems it is considered that the spread of the forecasted ensemble is equivalent to the resolution cluzet et al 2020b and thus it allows to easily compute the reliability 3 results figs 3 and 4 show the temporal evolution of the snow surface reflectance in 2016 17 snow season for the seven bands assimilated the open loop run is shown in green percentiles 10 90 of this ensemble whereas the simulation with data assimilation is represented by blue color percentiles 10 90 and 25 75 of the ensemble with data assimilation as the synthetic observations of surface reflectances were not used for evaluating the simulation and were only considered in the simulation system when a potential satellite observation was possible see the criteria in section 2 4 these observations are only included in the graph red points when the assimilation took place both figures include the temporal evolution of the ensemble of sd and swe simulations with the same color representation as for surface reflectance fig 3 shows the assimilation of member vii table 1 for the 2016 17 snow season with the seven bands assimilated using the r matrix errors of wright et al 2014 and fig 4 shows the same member season and bands but with an inflation by 5 of the r matrix in the assimilation process the dispersion of the reflectances for all bands was reduced on each assimilation date in each case however the assimilation involving higher r matrix errors fig 4 showed slightly wider dispersion as more members were admitted in the resampling algorithm this was similarly observed in the dispersion of the ensemble for sd and swe in fig 3 the truth member is within the p25 75 percentile envelope from the beginning of the season until the first days of march and within the p10 90 percentile envelope for the entire season in fig 4 higher r matrix errors the reference values were within the p10 90 envelope but generally not in the p25 75 envelope this is acceptable for a data assimilation system for a relatively short time period but should not be systematic over a longer period otherwise the forecast of the simulation system may advance along the different assimilations dates toward an ensemble too far from true snowpack variables and thus diverging from ground truth 3 1 assimilation of different spectral bands combinations the crps scores for both the sd fig 5 and swe fig 6 for most data assimilation tests showed improved simulation results compared with the open loop simulation a minor improvement was observed when only near infrared bands configuration d in fig 5 were assimilated as similar or slightly better crps scores were obtained throughout the study period for both verification variables of the four combinations tested the best result was obtained when the pf algorithm assimilated the seven spectral bands together the use of a multiplicative factor to inflate the r matrix errors did not result in any improvement in the four band combinations tested despite the three snow seasons analyzed had a contrasted temporal evolution in terms of snow accumulation fig 2 it was found an equivalent performance on reproducing the assimilated member with the different band combinations along the study period the reliability scores for our simulation system for the entire study period fig 7 were lower i e a more reliable ensemble for all assimilation tests than that for the open loop ensemble the best sd reliability value was obtained when assimilating the seven reflectance bands configuration a whereas for the swe the best result was obtained for the configuration c visible spectral bands given that the crps scores for both bulk evaluation variables improved when assimilating all spectral bands together and that the swe reliability improvement when assimilating visible spectral bands configuration c was only minor compared with that of configuration a the seven modis like reflectances we selected this later configuration for further analysis of the assimilation of biased observations using configuration a true modis surface reflectance was assimilated for same dates of synthetic assimilation the ensemble of sd obtained assimilating true satellite observations was evaluated with sd observations obtained in the automatic weather station and thus are considered as ground truth these sd represented the following percentiles of the open loop simulation 2014 15 p68 2015 16 p41 and 2016 17 p63 moreover the observed sd was nearly for the entire study period comprised in the p25 p75 envelope the crps fig 5 obtained for these three simulations assimilating modis surface reflectance mean crps 0 3 m show that even with the bands that conveys the more information in the assimilation system simulations results did not improve scores obtained in the open loop simulation mean crps of 0 245 m similarly the mean reliability score for these three simulations is 0 12 m what has same order of magnitude of that obtained for simulations without data assimilation fig 7 and nearly three times higher than the average reliability value 0 045 m obtained assimilating synthetic reflectance with configuration a nonetheless it must be highlighted that these values are obtained in three simulations along the study period and box plots in figs 5 7 show values obtained in 7 simulations when annual values are plotted and 21 simulations in the case of box plots for the entire study period and thus extreme crps and reli values obtained in some assimilation tests are blurred in the boxplot representation 3 2 biased surface reflectances impact fig 8 shows the scores obtained when assimilating systematically biased surface reflectances during the study period the results show that the assimilation of surface reflectances having a systematic bias of 10 performed less well than the open loop ensemble when the systematic bias was 5 similar scores to those of the open loop simulation were obtained while our simulation system allowed a random noise of up to 5 in the assimilation reflectance more reliable ensembles and results closer to the truth member were obtained with assimilation of reflectances involving biases 2 3 3 impact of the reference run position within the ensemble on the assimilation efficiency figs 9 and 10 show the crps and reli values for the various simulations carried out for the best band configuration all bands assimilated and for the highest random noise in the observed reflectances that the assimilation permitted 5 from these graphs we concluded that the position or percentile of the reference run within the ensemble also impacted the score of the assimilation the 21 twin experiments shown in fig 9 demonstrated that the greatest improvement in data assimilation was obtained with smaller percentiles while moderate improvement was obtained with medium percentiles 20 40 sd and swe percentiles this result does not depend on the snow season characteristics since contrasted snow seasons in terms of snow accumulations were evaluated fig 2 and this behavior greatest improvement in data assimilation with smaller percentiles was observed along the entire study period fig 9 also shows that for some twin experiments the pf failed and even for the best case scenario it did not improve the simulation results for the open loop ensemble similar conclusions were drawn for the data assimilation experiments involving a random noise between 5 and 5 4 discussion the assimilation of snow surface reflectance is known to improve the forecasting ability of ensemble crocus snowpack simulations thirel et al 2013 charrois et al 2016 cluzet et al 2020a even within a spatial framework cluzet et al 2020b to build on these previous studies our study aimed firstly to determine the optimal spectral band combination to obtain the greatest improvement in ensemble snowpack simulations the second aim was to investigate the maximum tolerable errors in the observations acceptable for the assimilation system the ability to reproduce the snowpack evolution with and without data assimilation was assessed by evaluating the snowpack bulk variables sd and swe overall the assimilation of surface reflectance over three snow seasons for several dates between 14 and 19 assimilations improved the simulation of these two variables the open loop ensemble of snowpack simulations was sufficiently dispersive because of the wide variety of meteorological runs and the various model parameterizations lafaysse et al 2017 and this way observed sd at the automatic weather station of the study site were comprised between percentiles p41 and p68 in total we conducted 276 assimilation tests based on the random extraction of 21 truth members from the open loop ensemble we evaluated the impact of the assimilation of members having intermediate deep and shallow snowpacks the percentile classification of the truth members showed that greater improvement was obtained for shallow sd figs 9 and 10 with satisfactory improvement of the ensemble simulations for most of the assimilation tests probably the simulation of shallow snow accumulations is more sensible to small differences when the pf selects and replicates those members that are closer to the observed surface reflectance than when simulating a thick snowpack oppositely the three ensemble simulations assimilating true modis surface reflectance observations did not improve simulation results the number of simulations that comprise the ensemble is an important issue when simulating over large domains because an exponential number of in situ simulations is required as shown in the example of the col du lautaret which markedly increases the requirement for computational resources larger ensembles have been shown to be associated with a major decrease in forecast errors when simulating the snowpack e g 2000 members magnusson et al 2017 similarly smaller ensembles including 300 members charrois et al 2016 and 100 members piazzi et al 2018 have also shown good results and improved simulation performance the latter study showed that taking into account the uncertainty inherent in the model using a stochastic procedure ensures a suitable spread of the ensemble with a moderate number of particles 100 in their case consequently we followed a similar procedure to that of piazzi et al 2018 and proposed by moradkhani et al 2005 but took advantage of the crocus multi physics ensemble escroc lafaysse et al 2017 for each assimilation step following resampling of particles through the sir algorithm both the ensemble of meteorological forcings and the various escroc configurations were randomly assigned to the particles issued by the filter we showed that this procedure was effective with our ensemble of 200 members for simulating snowpack evolution with respect to the various combinations of spectral bands the crps for both the sd and swe for most combinations was smaller than that obtained for the open loop ensemble for the entire study period only configuration d near infrared reflectance only showed higher crps scores than those of the reference run versus the open loop ensemble the greater improvement obtained when assimilating the first seven modis like bands indicates that information over the entire spectrum is required in the assimilation system visible bands are known to provide information about the lap content of the snow surface whereas near infrared bands are more sensitive to snow grain ssa during the snow season both lap deposition and changes in the ssa occur therefore assimilating information on the snow surface reflectance in various regions of the solar spectrum is strongly recommended however some data assimilation twin experiments failed including for the best case configuration assimilation of all modis like reflectance bands with similar or worse results than for the open loop simulation these failures in the assimilation system have two plausible explanations one is degeneration of the ensemble to too few particles which requires the use of strategies to tackle and mitigate this problem cluzet et al 2020b another explanation is the nature of the observations assimilated for instance when assimilating true modis surface reflectance if after a long period without solid precipitation e g during the melt period a small amount of snowfall accumulates some hours prior to a valid satellite acquisition and is not adequately simulated by the meteorological forcing the snow surface reflectance describing the snowpack will differ substantially from the simulated value similarly an erroneous simulation of surface reflectance when assimilating synthetic observations may introduce deviation which potentially originate an ensemble far from the reference run under these circumstances the pf algorithm would select particles not accurately simulated contributing to degeneration of the ensemble our pf data assimilation scheme failed to improve simulation results when assimilating true modis snow surface reflectance this may be related to the errors in surface reflectance retrieved from modis in complex terrain the study site is locally flat close to the meteorological station but the surface reflectance retrieved by the space borne modis sensor is affected by complex terrain effects e g lamare et al 2020 the small deviations between ground based and satellite observations reported in greenland by wright et al 2014 are likely not transferable to such sites in complex terrain snow observations from optical satellite sensors are indeed affected by various shortcomings mainly because of the complex interactions between radiation and topography dumont and gascoin 2016 lamare et al 2020 these often result in biased observations cluzet et al 2020a however to the best of our knowledge the accuracy of modis spectral surface reflectance in highly heterogeneous mountain areas has not been accurately determined and thus accuracy assessments from other areas having distinct characteristics are applied several studies have attempted to use modis observations in complex topography but the assimilation experiment were either non successful charrois et al 2016 or non possible because of the high observation errors cluzet et al 2020a on the contrary the assimilation of ground based snow surface reflectance observations using the same spectral bands as modis improved simulation results charrois 2017 therefore assimilating accurate snow surface reflectance guarantees more reliable snowpack simulations aiming to provide guidelines about the maximum deviation from ground truth that the assimilation of snow surface reflectance admits to improve simulations differing biases to the synthetic observations were tested we showed that the maximum deviation from ground truth that our data assimilation scheme could tolerate before there was a decrease in the simulation performance was 5 for white noise and 2 for systematic bias although these criteria could be met for flat snow covered surfaces kokhanovsky et al 2019 moustafa et al 2017 they are beyond the current limit of standard modis products in heterogeneous mountain areas masson et al 2018 cluzet et al 2020a however recent progress in accounting for topographic effects lamare et al 2020 combined with increased availability of higher resolution satellite data gascoin et al 2019 suggest that such criteria may soon be met even in mountainous areas our findings confirm that when remote sensing science can achieve the deviations from ground truth reported here the assimilation of data from optical satellite sensors will improve ensemble forecasting capabilities 5 conclusions our results demonstrate that the assimilation of snowpack surface reflectances using the particle filter algorithm improves simulation of the temporal evolution of snowpack bulk variables our study used synthetic observations but the assimilation dates were selected from true modis images made under appropriate conditions clear sky full snow cover viewing zenith angle 60 for retrieving surface reflectance from the snowpack these restricted conditions for acquiring snow surface reflectance led to the assimilation of data from 14 to 20 dates in each of three snow seasons despite the reduced number of assimilation dates over more than seven months of snowpack simulations the simulation system showed an improvement in results compared with the simulations made without data assimilation the assimilation of the first seven modis like bands including information in visible and near infrared wavelengths showed the best results from all band combinations tested in the contrary the assimilation of true modis surface reflectance failed and did not improve open loop simulations results in light of this shortcoming different biases were introduced to the synthetic observations to obtain the maximum deviation from ground truth that data assimilation admits the simulation system enabled the assimilation of surface reflectances having a random white noise less than or equal to 5 or a systematic bias less than or equal to 2 from ground truth this indicates the maximum deviation that satellite derived products will have to provide for improvement of ensemble simulations through data assimilation to occur the results of this study provide the specifications in terms of accuracy for the processing of satellite reflectances credit authorship contribution statement j revuelto methodology data curation formal analysis resources investigation validation visualization writing original draft writing review editing project administration funding acquisition b cluzet methodology software validation data curation investigation writing review editing n duran software validation visualization m fructus software validation visualization m lafaysse conceptualization software writing review editing e cosme conceptualization writing review editing m dumont conceptualization methodology supervision writing review editing project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments j revuelto was supported by a post doctoral fellowship of the axa research fund le post doctorant jesús revuelto est bénéficiaire d une bourse postdoctorale du fonds axa pour la recherchem ref cnrm 3 2 01 17 j revuelto is now supported by a juan de la cierva incorporación fellowship of the spanish ministry of science and innovation ijc2018 036260 i ige and cnrm cen are part of labex osug 2020 this work was partly supported by the french national program lefe insu assurance apr cnes miosoti and an anr jcjc eboni grant anr 16 ce01 0006 this research was also supported by lautaret garden ums 3370 univ grenoble alpes cnrs sajf 38000 grenoble france a member of anaee france anr 11 inbs 0001anaee services investissements d avenir frame and the elter europe network univ grenoble alpes cnrs lster zone atelier alpes 38000 grenoble france 
4021,data assimilation of snow observations significantly improves the accuracy of snow cover simulations however remotely sensed snowpack observations made in areas of complex topography are typically subject to large error and biases creating a challenge for data assimilation to improve the reliability of ensemble snowpack simulations this study investigated the appropriate conditions for assimilating modis like synthetic surface reflectances we used a simulation system that included the particle filter data assimilation technique more than 270 ensemble simulations involving assimilation of synthetic observations were conducted in a twin experiment procedure for three snow seasons these tests were aimed at establishing the spectral combination of modis like reflectances that convey the more information in the assimilation system rendering the most reliable snowpack simulation and determining the maximum observation errors that the assimilation system could tolerate the assimilation of the first seven modis like bands covering visible and near infrared wavelengths provided the best scores compared with any other band combination and thus are highly recommended for use when possible the simulation system tolerated a maximum deviation from ground truth of 5 without loss of performance however the assimilation of the first seven bands of true modis surface of reflectance fails on improving simulation results in rouged mountain areas keywords snowpack modelling snow surface reflectance data assimilation particle filter mountain areas 1 introduction some of the major natural hazards in mountain areas are directly linked to the snowpack distribution and its evolution over time and include snow avalanches schweizer et al 2003 2008 and floods in downstream areas gaál et al 2015 forecasting snowpack evolution in mountain areas is increasingly based on numerical snowpack models lehning et al 2006 vionnet et al 2012 morin et al 2020 the marked natural spatial and temporal variability in the snowpack in mountain areas scipión et al 2013 seidel et al 2016 necessitates accurate simulation of snowpack processes and accurate meteorological inputs hence snowpack modelling is affected by forcing and model errors that result in discrepancies between the real state and the simulated snowpack morin et al 2020 the accumulation of such discrepancies over time decreases forecasting capabilities leading to large uncertainties in risk management consequently for robust operational use the snowpack models need to provide upgraded real time forecasts wayand et al 2015 ensemble approaches are commonly used to quantify the uncertainties associated with simulations e g swinbank et al 2016 vernay et al 2015 moreover data assimilation techniques enable optimal combinations of simulations usually an ensemble representing possible simulation states and observations to mitigate uncertainties arising from both sources of information andreadis and lettenmaier 2006 clark et al 2008 largeron et al 2020 data assimilation techniques in snowpack modelling are known to significantly reduce simulation uncertainties and biases magnusson et al 2017 piazzi et al 2019 however the possible assimilation observations and their optimal frequencies and spatial extent may vary depending on the assimilation technique and the characteristics of the observations in situ measurements are the most accurate observations ménard et al 2019 winstral et al 2019 but their generally poor spatial extent and representativeness makes them inappropriate for large scale simulations at reasonable spatial resolution i e several hundreds or thousands of meters however different studies have exploited these observations with different data assimilation schemes magnusson et al 2017 piazzi et al 2018 remote sensing observations including those involving optical space borne sensors collect information on the snowpack surface at high spatial resolution over large areas immerzeel et al 2009 gascoin et al 2015 dumont and gascoin 2016 although the frequency of optical remote sensing in some regions is limited by cloud cover hall and riggs 2007 the assimilation of sparse satellite observations into snowpack models has significantly improved the simulation results in theoretical experiments based on synthetic observations charrois et al 2016 cluzet et al 2020a similarly active satellite sensors have been assimilated in large study areas cortés et al 2016 larue et al 2018 margulis et al 2019 and in some cases combined with in situ observations piazzi et al 2019 showing encouraging results these works demonstrate the effort of the snow modeling community on assimilating snow observations to improve forecasting capabilities of snow models probably remote sensing techniques capability of retrieving information over extended and remote areas is the main reason that has motivated this attempt snow spectral reflectance varies substantially with wavelength in the solar spectrum warren 1982 the information held in the various bands of optical satellite sensors can provide information about various snowpack surface properties including snow aging snow microstructure or light absorbing particle content painter et al 2012 skiles et al 2018 in addition snow cover monitoring using satellites particularly in highly heterogeneous areas having patchy snow distribution and or highly complex topography is affected by a number of sources of uncertainty frei et al 2012 cluzet et al 2020a when this information is assimilated using a data assimilation scheme the potential deviations of the observation must be taken into account and appropriately represented in the simulation system janjic et al 2018 various data assimilation techniques have been tested depending on the characteristics of the snowpack model and the type of observations the ensemble kalman filter scheme evensen 2003 has been shown to efficiently assimilate remote sensed and ground based snow observations improving simulation accuracy piazzi et al 2019 however the implementation of this technique is challenging and is associated with significant limitations for detailed snowpack models piazzi et al 2018 the particle filter pf van leeuwen 2009 is a data assimilation technique that does not rely on physical assumptions of the system and is well suited to snowpack models charrois et al 2016 piazzi et al 2018 the efficiency of the pf in assimilating observations into snowpack models has been tested in many study areas and with differing observation datasets thirel et al 2013 magnusson et al 2017 the pf technique largely reduces the uncertainty in ensemble simulations of the snowpack when reproducing the snow depth sd and snow water equivalent swe smyth et al 2019 and has also showed encouraging results in distributed simulations baba et al 2018 moreover the pf technique only selects or discards particles resampling those members selected depending on the distance to the observed variable and in this way maintains the consistency between state variables magnusson et al 2017 these attributes have encouraged snow modelling scientists to implement the pf technique in assimilating snowpack variables retrieved using satellite sensors largeron et al 2020 nevertheless in view of the fast development of both remote sensing and models arising in the snow science community girotto et al 2020 an assessment on measurement errors that may be admissible for improving simulation results is required this study relied on the detailed crocus snowpack model vionnet et al 2012 which has been used for more than 25 years in the french mountain ranges to provide operational support for avalanche hazard forecasting to reduce discrepancies between the observed and simulated snowpack revuelto et al 2018 recent developments in this simulation system have aimed to assimilate different snowpack variables with pf assimilation algorithm charrois et al 2016 charrois 2017 cluzet et al 2020a b the assimilation of synthetic observations including sd and snow surface reflectance has already demonstrated a remarkable improvement on the forecasting capabilities of crocus charrois et al 2016 similarly the assimilation of ground based surface reflectance also reduced crocus simulations uncertainties but oppositely the assimilation of true satellite retrieved optical reflectance with modis sensors failed charrois 2017 this is mainly attributed to the bias of modis snow surface reflectances likely due to complex terrain effects cluzet et al 2020a previous studies have paved the way for substantial improvements to detailed snowpack simulations but have also highlighted the need of determining the maximum observation uncertainties that can be tolerated in the assimilation system and which spectral observations convey the more information in the system this study aims at determining the minimum accuracy of snow surface reflectance satellite observations needed to guarantee an effective assimilation that improves snow simulation capabilities this study describes assimilation experiments using both synthetic and modis surface reflectance with croco c1 0 an ensemble data assimilation system cluzet et al 2020b first we investigated the performance of pf algorithm with respect to the spectral bands assimilated which enabled us to determine whether there was a particular band combination rendering better simulation scores second we assessed the maximum observation errors acceptable with respect to improving the forecasting capability of simulations using data assimilation to address these objectives we tested the performance of pf in assimilating synthetic observations using a twin experiment involving data assimilation dates selected from true modis images made under ideal conditions no clouds and high viewing zenith angles for retrieving snow surface information in view of the potential for implementation of this system to assimilate real optical surface reflectances the synthetic observations involved modis like surface reflectances extracted from various reference members considered to represent the truth snowpack conditions termed truth members this procedure included information on all snowpack variables at any time enabling full evaluation of the assimilation and also overcame potential shortcomings of real observations the performance of the assimilation system was evaluated by assessing the impact that data assimilation had on the bulk snow variables sd and swe finally for the band combination rendering the best results the assimilation of true modis surface reflectance was evaluated analyzing the capability of the simulation system on reproducing the observed sd the simulation exercise presented here spanned three snow seasons 2014 15 2015 16 and 2016 17 at the col du lautaret study site in the french alps in total 270 data assimilation experiments were carried out and combined differing modis like spectral bands and various biases and errors introduced in the assimilated reflectances section 2 describes the simulation and assimilation systems provides detailed information about the study period and the study site and describes the evaluation procedure section 3 presents and describes the main results obtained section 4 discusses the main results and section 5 presents the conclusions from the study 2 data and methods the snowpack data assimilation system aims to reduce the dispersion of an ensemble of simulations towards the true evolution of the snowpack globally the simulation system reproduces the snowpack along the snow season when a snowpack observation is available the ensemble of simulations is stopped and resampled trough the particle filter afterwards the simulation of the resampled ensemble continues until the next assimilation or the end of the snow season if no more observations are available this section after describing the study area and period provides an overview on the simulation system comprising snowpack simulations meteorological forcing generation of the ensemble and the assimilation procedure later on once modis data processing is described section 2 4 the twin experiment procedure followed in this work is detailed section 2 5 finally the assimilation experiments that enabled the assessment on the efficiency of the system in view to the different bands combinations assimilated section 2 6 and the bias of surface reflectance tolerated by the system section 2 7 are specified 2 1 study site and period the simulations were conducted in col du lautaret a mountain pass located in the central french alps 45 02 n 6 46 e between four alpine massifs ecrins pelvoux grandes rousses and thabor at an elevation of 2058 m a s l the study area is completely covered by alpine grassland and has a flat topography and without any predominant exposition see summer and winter pictures of fig 1 despite the surrounding topography is rugged but locally open see fig 1 the satellite observations of this study site are also influenced by the diffuse radiation scattered by the neighborhood that characterizes snow covered rugged terrain and by direct re illumination effects lamare et al 2020 because of its accessibility and high elevation it has been involved in many snow studies lamare et al 2020 larue et al 2020 revuelto et al 2020 tuzet et al 2020 moreover this site is equipped with an automatic weather station acquiring different variables including sd as other data assimilation studies in mountain areas smyth et al 2019 winstral et al 2019 our study period included three snow seasons 2014 15 2015 16 and 2016 17 and thus included a wide variety of meteorological events and snowpack conditions 2 2 open loop simulation system the simulation platform used for simulating snow evolution is the externalized surface model surfex which integrates the crocus snowpack model vionnet et al 2012 and the multilayer soil model isba dif decharme et al 2016 crocus is a detailed multilayer snowpack model that simulates the most important processes within the snowpack including all energy and mass exchanges between the snow layers the soil and the atmosphere the tartes radiative transfer scheme libois et al 2015 was recently implemented in crocus to provide a vertical profile of solar radiation absorption from snow microstructure profiles based on the specific surface area ssa and the concentrations of light absorbing particles laps e g black carbon and mineral dust deposited on the snow surface tuzet et al 2017 in this study the multi physics version of crocus was used escroc ensemble system crocus lafaysse et al 2017 to account for model errors in ensemble simulations this way crocus simulates the temporal evolution of nearly all variables describing the different snowpack layers vionnet et al 2012 including the seven modis like surface reflectance bands and bulk snow pack variables as the sd and the swe the simulations were conducted on a 250 250 m pixel with the topographical attributes slope elevation aspect of col du lautaret the meteorological inputs were obtained from the safran reanalyses durand et al 2009 vernay et al 2015 safran reanalysis provides at hourly time step all atmospheric variables needed to run crocus model including air temperature specific humidity precipitation phase and rate direct and diffuse radiation long wave radiation and wind speed this analysis scheme has a semi distributed geometry providing for discrete units of the alps of about 1000 km2 named massifs and included all meteorological variables needed for running crocus simulations we considered the meteorological forcings corresponding to the elevation aspect and slope of the study sites for the four safran massifs oisans pelvoux grandes rousses and thabor because of the position of our study site at the intersection of these massifs from each of these four reanalyses we obtained 50 members perturbed using a stochastic approach charrois et al 2016 using mocage outputs which is the chemistry transport model of météofrance modèle de chimie atmosphérique de grande echelle josse et al 2004 an ensemble of lap deposition fluxes was generated and stochastically associated with safran members the 200 meteorological members obtained were randomly combined with 200 parameterizations of crocus through the e1tartes option of escroc as described by cluzet et al 2020a an example of the temporal variability of the ensemble of snowpack simulations without data assimilation open loop based on the evolution of sd during the study period is provided in fig 2 2 3 data assimilation algorithm the pf technique was implemented using the sampling importance resampling sir algorithm gordon et al 1993 van leeuwen 2009 the pf technique estimates the distribution of possible states of a system using a probability density function based on the sampling of the members of an ensemble each time that an observation is available all particles of the ensemble are weighted through the likelihood to the observation by computing the change in the relative importance of the probability density function this function also takes into account the inherent error in the observations through a covariance matrix r cluzet et al 2020b once the ensemble of possible states particles has been weighted particles are resampled those having a negligible weight are discarded and those having higher weights closer to the observed value are replicated the resampling essentially maintains the total number of particles but outputs a less dispersive ensemble shifted towards the observed value when properly settled see fig 2 in van leeuwen 2009 further details of this technique and the theory behind it are described by van leeuwen 2009 the practical implementation of the crocus model and reflectance assimilation is described in detail by cluzet et al 2020b 2 4 modis data processing many studies have demonstrated the usefulness of modis images for snow cover mapping in mountain areas at 500 m spatial resolution gascoin et al 2015 parajka and blöschl 2008 sub pixel snow monitoring of the snow cover at 250 m spatial resolution was performed using modimlab software dumont et al 2012 sirguey et al 2009 multispectral fusion between mod02hkm and mod02qkm sirguey et al 2008 enabled this software to generate images at 250 250 m spatial resolution to derive various snow ice products including the first seven bands of modis sensor respectively 460 560 640 860 1240 1640 and 2120 nm central wavelengths and also cloud cover fraction these variables were obtained for all available modis sensor images from terra platform along the study period modis images were used to select data assimilation dates to ensure the highest quality satellite images we checked modis images for col du lautaret to find dates on which the site was fully snow covered the sky was clear and the viewing azimuth angle was high 60 sirguey et al 2016 for the 2014 15 2015 16 and 2016 17 snow seasons 16 14 and 19 assimilation dates respectively met these requirements for these dates snow surface reflectance for the first seven modis bands was also kept for assimilation 2 5 twin experiment with true and synthetic observations twin experiments are typically used to test data assimilation techniques matgen et al 2010 dubinkina et al 2011 browne and van leeuwen 2015 in essence a twin experiment compares two ensembles an open loop ensemble without data assimilation and a second ensemble assimilating observations the data assimilation system has been tested with two different observations datasets modis like surface reflectance derived from the open loop ensemble and true modis surface reflectance these two datasets allowed to explore different assimilation scenarios having a detailed description of the snowpack at any time and also to evaluate the performance of the simulation system when assimilating true satellite observations for the distinct assimilation experiments detailed in the next section synthetic observation values were only obtained for dates in which modis observations had high quality section 2 4 from one member of the open loop ensemble this member named the truth or reference run was considered to describe the real snowpack state for the given experiment and contained temporal information on all variables of the simulation system when assimilating synthetic observations the reference run was removed from the ensemble the assimilation of both true and synthetic observations had same data assimilation dates which selection was only based on the quality of satellite images and thus they reproduces true operational assimilation procedures based on the availability of high quality observations providing a realistic temporal repetitiveness of assimilation dates 2 6 assimilation experiments one major advantage of the twin experiment framework is that we were able to conduct various tests assimilating distinct reference runs including true modis observations this enabled assessment of the efficiency of the system as a function of the location of the true state within the ensemble for the three snow seasons we tested the assimilation of seven reference runs 21 in total randomly selected from the open loop simulation table 1 shows the sd and the swe percentiles based on mean values during the period when snow was on the ground in at least one member for the various reference runs in the open loop ensemble the random selection of several reference runs for each snow season illustrate how possible snowpack conditions may be simulated and how data assimilation may impact simulation results for different cases in turn this procedure allows determining which spectral bands convey the more info in the system the final objective is the assimilation of true modis observations this way the covariance matrix of errors r of the pf density function had to account for real modis sensor errors in the case study of twin experiments this is a diagonal matrix having the following errors 7 1e 4 4 6e 4 5 6e 4 5 6e 4 2 0e 3 1 5e 3 and 7 8e 4 wright et al 2014 errors reported in this later work were determined comparing modis observations with spectral albedo field measurements and as far author knows these are one of the few datasets available on modis spectral bands accuracy over snow thereby our assimilation experiments used r matrix with elements from deviations reported by wright et al 2014 since some exploratory analysis of charrois 2017 suggested that an r matrix with elements multiplied by a factor of 5 obtained more reliable ensembles we also tested the assimilation of synthetic observations with r matrix with such a multiplicative factor termed here in after f5 additionally the impact of assimilating four combinations of surface reflectance bands was investigated for each of the 21 synthetic observations evaluated the first of these combinations comprised the assimilation of the seven bands configuration a the second combination included the assimilation of the first and fifth modis like reflectances 460 and 1240 mm configuration b the third combination tested configuration c aimed to evaluate the impact of assimilating visible and the first very near infrared band together 460 560 640 860 nm this involved the first four modis like reflectances the fourth combination configuration d assimilated three near infrared bands 1240 1640 2120 nm all band combinations and configuration names used here after are detailed in table 2 these band combinations were aimed at evaluating the performance of the system for several spectral band configurations spectral reflectances more sensitive to impurities on the snow surface first four modis like bands reflectances accounting for snow aging the three higher wavelength modis like bands dozier et al 2009 skiles et al 2018 or those assimilating other band combinations having better scores the band combination showing the best results has been evaluated with true modis surface reflectance to analyze the reliability of true data assimilation of snow surface reflectance whereas the assimilation experiments with synthetic observations were evaluated with sd and swe forecast of the true state reference run the assimilation of true modis surface reflectance was evaluated with the sd observed at the automatic weather station located within the study area 2 7 biased surface reflectances to investigate the robustness of data assimilation to random errors and systematic biases in optical satellite observations we also ran the following experiments first three white noises 2 5 and 10 having random values within these intervals for the various assimilation dates were introduced to the synthetic surface reflectances secondly the synthetic observations were systematically biased for all assimilation dates using 2 2 5 5 10 and 10 of the truth member values these experiments were only applied to the best band combination identified by the experiments described in section 2 6 2 8 evaluation metrics the evaluation metrics must assess the performance and quality of the ensemble in reproducing the evolution of an observed variable i e verification variable of the truth member the metrics obtained with and without data assimilation were compared enabling evaluation of the impact that data assimilation had on the forecast of the ensemble the mean of the daily continuous ranked probability score crps hersbach 2000 gneiting et al 2007 tödter and ahrens 2012 over time was chosen because it is one of the most common probabilistic metrics for jointly evaluating both the reliability and sharpness of the probability distribution simulated by an ensemble system this score decreases towards 0 when the ensemble tends towards a perfect deterministic simulation and is expected to be reduced by data assimilation an ensemble is reliable if events are forecast with the right probability and has good resolution if it is able to discriminate among different events by issuing different forecasts for further details see atger 1999 the reliability component of the score reli can be isolated following hersbach 2000 the crps and reli were computed for the ensembles with and without data assimilation for the verification variables sd and swe the crps for each time step crpst was obtained from eq 1 1 crp s t r f t x o t x 2 d x where ft x is the cumulative distribution function at time t and ot x is the corresponding cumulative distribution function of the observation heviside function with center in the true value at time t afterwards the crpst is averaged over time to obtain crps values of the different simulation tests the crps is the sum of the reliability reli of the ensemble and its resolution resol 2 crps r e l i r e s o l thus the crps is both a metric of ensemble reliability and its resolution an ensemble is reliable the lower reli is the better forecasts the ensemble if events are forecasted with the right probability and has good resolution if it is able to discriminate between different events by issuing different forecasts atger 1999 for reliable systems it is considered that the spread of the forecasted ensemble is equivalent to the resolution cluzet et al 2020b and thus it allows to easily compute the reliability 3 results figs 3 and 4 show the temporal evolution of the snow surface reflectance in 2016 17 snow season for the seven bands assimilated the open loop run is shown in green percentiles 10 90 of this ensemble whereas the simulation with data assimilation is represented by blue color percentiles 10 90 and 25 75 of the ensemble with data assimilation as the synthetic observations of surface reflectances were not used for evaluating the simulation and were only considered in the simulation system when a potential satellite observation was possible see the criteria in section 2 4 these observations are only included in the graph red points when the assimilation took place both figures include the temporal evolution of the ensemble of sd and swe simulations with the same color representation as for surface reflectance fig 3 shows the assimilation of member vii table 1 for the 2016 17 snow season with the seven bands assimilated using the r matrix errors of wright et al 2014 and fig 4 shows the same member season and bands but with an inflation by 5 of the r matrix in the assimilation process the dispersion of the reflectances for all bands was reduced on each assimilation date in each case however the assimilation involving higher r matrix errors fig 4 showed slightly wider dispersion as more members were admitted in the resampling algorithm this was similarly observed in the dispersion of the ensemble for sd and swe in fig 3 the truth member is within the p25 75 percentile envelope from the beginning of the season until the first days of march and within the p10 90 percentile envelope for the entire season in fig 4 higher r matrix errors the reference values were within the p10 90 envelope but generally not in the p25 75 envelope this is acceptable for a data assimilation system for a relatively short time period but should not be systematic over a longer period otherwise the forecast of the simulation system may advance along the different assimilations dates toward an ensemble too far from true snowpack variables and thus diverging from ground truth 3 1 assimilation of different spectral bands combinations the crps scores for both the sd fig 5 and swe fig 6 for most data assimilation tests showed improved simulation results compared with the open loop simulation a minor improvement was observed when only near infrared bands configuration d in fig 5 were assimilated as similar or slightly better crps scores were obtained throughout the study period for both verification variables of the four combinations tested the best result was obtained when the pf algorithm assimilated the seven spectral bands together the use of a multiplicative factor to inflate the r matrix errors did not result in any improvement in the four band combinations tested despite the three snow seasons analyzed had a contrasted temporal evolution in terms of snow accumulation fig 2 it was found an equivalent performance on reproducing the assimilated member with the different band combinations along the study period the reliability scores for our simulation system for the entire study period fig 7 were lower i e a more reliable ensemble for all assimilation tests than that for the open loop ensemble the best sd reliability value was obtained when assimilating the seven reflectance bands configuration a whereas for the swe the best result was obtained for the configuration c visible spectral bands given that the crps scores for both bulk evaluation variables improved when assimilating all spectral bands together and that the swe reliability improvement when assimilating visible spectral bands configuration c was only minor compared with that of configuration a the seven modis like reflectances we selected this later configuration for further analysis of the assimilation of biased observations using configuration a true modis surface reflectance was assimilated for same dates of synthetic assimilation the ensemble of sd obtained assimilating true satellite observations was evaluated with sd observations obtained in the automatic weather station and thus are considered as ground truth these sd represented the following percentiles of the open loop simulation 2014 15 p68 2015 16 p41 and 2016 17 p63 moreover the observed sd was nearly for the entire study period comprised in the p25 p75 envelope the crps fig 5 obtained for these three simulations assimilating modis surface reflectance mean crps 0 3 m show that even with the bands that conveys the more information in the assimilation system simulations results did not improve scores obtained in the open loop simulation mean crps of 0 245 m similarly the mean reliability score for these three simulations is 0 12 m what has same order of magnitude of that obtained for simulations without data assimilation fig 7 and nearly three times higher than the average reliability value 0 045 m obtained assimilating synthetic reflectance with configuration a nonetheless it must be highlighted that these values are obtained in three simulations along the study period and box plots in figs 5 7 show values obtained in 7 simulations when annual values are plotted and 21 simulations in the case of box plots for the entire study period and thus extreme crps and reli values obtained in some assimilation tests are blurred in the boxplot representation 3 2 biased surface reflectances impact fig 8 shows the scores obtained when assimilating systematically biased surface reflectances during the study period the results show that the assimilation of surface reflectances having a systematic bias of 10 performed less well than the open loop ensemble when the systematic bias was 5 similar scores to those of the open loop simulation were obtained while our simulation system allowed a random noise of up to 5 in the assimilation reflectance more reliable ensembles and results closer to the truth member were obtained with assimilation of reflectances involving biases 2 3 3 impact of the reference run position within the ensemble on the assimilation efficiency figs 9 and 10 show the crps and reli values for the various simulations carried out for the best band configuration all bands assimilated and for the highest random noise in the observed reflectances that the assimilation permitted 5 from these graphs we concluded that the position or percentile of the reference run within the ensemble also impacted the score of the assimilation the 21 twin experiments shown in fig 9 demonstrated that the greatest improvement in data assimilation was obtained with smaller percentiles while moderate improvement was obtained with medium percentiles 20 40 sd and swe percentiles this result does not depend on the snow season characteristics since contrasted snow seasons in terms of snow accumulations were evaluated fig 2 and this behavior greatest improvement in data assimilation with smaller percentiles was observed along the entire study period fig 9 also shows that for some twin experiments the pf failed and even for the best case scenario it did not improve the simulation results for the open loop ensemble similar conclusions were drawn for the data assimilation experiments involving a random noise between 5 and 5 4 discussion the assimilation of snow surface reflectance is known to improve the forecasting ability of ensemble crocus snowpack simulations thirel et al 2013 charrois et al 2016 cluzet et al 2020a even within a spatial framework cluzet et al 2020b to build on these previous studies our study aimed firstly to determine the optimal spectral band combination to obtain the greatest improvement in ensemble snowpack simulations the second aim was to investigate the maximum tolerable errors in the observations acceptable for the assimilation system the ability to reproduce the snowpack evolution with and without data assimilation was assessed by evaluating the snowpack bulk variables sd and swe overall the assimilation of surface reflectance over three snow seasons for several dates between 14 and 19 assimilations improved the simulation of these two variables the open loop ensemble of snowpack simulations was sufficiently dispersive because of the wide variety of meteorological runs and the various model parameterizations lafaysse et al 2017 and this way observed sd at the automatic weather station of the study site were comprised between percentiles p41 and p68 in total we conducted 276 assimilation tests based on the random extraction of 21 truth members from the open loop ensemble we evaluated the impact of the assimilation of members having intermediate deep and shallow snowpacks the percentile classification of the truth members showed that greater improvement was obtained for shallow sd figs 9 and 10 with satisfactory improvement of the ensemble simulations for most of the assimilation tests probably the simulation of shallow snow accumulations is more sensible to small differences when the pf selects and replicates those members that are closer to the observed surface reflectance than when simulating a thick snowpack oppositely the three ensemble simulations assimilating true modis surface reflectance observations did not improve simulation results the number of simulations that comprise the ensemble is an important issue when simulating over large domains because an exponential number of in situ simulations is required as shown in the example of the col du lautaret which markedly increases the requirement for computational resources larger ensembles have been shown to be associated with a major decrease in forecast errors when simulating the snowpack e g 2000 members magnusson et al 2017 similarly smaller ensembles including 300 members charrois et al 2016 and 100 members piazzi et al 2018 have also shown good results and improved simulation performance the latter study showed that taking into account the uncertainty inherent in the model using a stochastic procedure ensures a suitable spread of the ensemble with a moderate number of particles 100 in their case consequently we followed a similar procedure to that of piazzi et al 2018 and proposed by moradkhani et al 2005 but took advantage of the crocus multi physics ensemble escroc lafaysse et al 2017 for each assimilation step following resampling of particles through the sir algorithm both the ensemble of meteorological forcings and the various escroc configurations were randomly assigned to the particles issued by the filter we showed that this procedure was effective with our ensemble of 200 members for simulating snowpack evolution with respect to the various combinations of spectral bands the crps for both the sd and swe for most combinations was smaller than that obtained for the open loop ensemble for the entire study period only configuration d near infrared reflectance only showed higher crps scores than those of the reference run versus the open loop ensemble the greater improvement obtained when assimilating the first seven modis like bands indicates that information over the entire spectrum is required in the assimilation system visible bands are known to provide information about the lap content of the snow surface whereas near infrared bands are more sensitive to snow grain ssa during the snow season both lap deposition and changes in the ssa occur therefore assimilating information on the snow surface reflectance in various regions of the solar spectrum is strongly recommended however some data assimilation twin experiments failed including for the best case configuration assimilation of all modis like reflectance bands with similar or worse results than for the open loop simulation these failures in the assimilation system have two plausible explanations one is degeneration of the ensemble to too few particles which requires the use of strategies to tackle and mitigate this problem cluzet et al 2020b another explanation is the nature of the observations assimilated for instance when assimilating true modis surface reflectance if after a long period without solid precipitation e g during the melt period a small amount of snowfall accumulates some hours prior to a valid satellite acquisition and is not adequately simulated by the meteorological forcing the snow surface reflectance describing the snowpack will differ substantially from the simulated value similarly an erroneous simulation of surface reflectance when assimilating synthetic observations may introduce deviation which potentially originate an ensemble far from the reference run under these circumstances the pf algorithm would select particles not accurately simulated contributing to degeneration of the ensemble our pf data assimilation scheme failed to improve simulation results when assimilating true modis snow surface reflectance this may be related to the errors in surface reflectance retrieved from modis in complex terrain the study site is locally flat close to the meteorological station but the surface reflectance retrieved by the space borne modis sensor is affected by complex terrain effects e g lamare et al 2020 the small deviations between ground based and satellite observations reported in greenland by wright et al 2014 are likely not transferable to such sites in complex terrain snow observations from optical satellite sensors are indeed affected by various shortcomings mainly because of the complex interactions between radiation and topography dumont and gascoin 2016 lamare et al 2020 these often result in biased observations cluzet et al 2020a however to the best of our knowledge the accuracy of modis spectral surface reflectance in highly heterogeneous mountain areas has not been accurately determined and thus accuracy assessments from other areas having distinct characteristics are applied several studies have attempted to use modis observations in complex topography but the assimilation experiment were either non successful charrois et al 2016 or non possible because of the high observation errors cluzet et al 2020a on the contrary the assimilation of ground based snow surface reflectance observations using the same spectral bands as modis improved simulation results charrois 2017 therefore assimilating accurate snow surface reflectance guarantees more reliable snowpack simulations aiming to provide guidelines about the maximum deviation from ground truth that the assimilation of snow surface reflectance admits to improve simulations differing biases to the synthetic observations were tested we showed that the maximum deviation from ground truth that our data assimilation scheme could tolerate before there was a decrease in the simulation performance was 5 for white noise and 2 for systematic bias although these criteria could be met for flat snow covered surfaces kokhanovsky et al 2019 moustafa et al 2017 they are beyond the current limit of standard modis products in heterogeneous mountain areas masson et al 2018 cluzet et al 2020a however recent progress in accounting for topographic effects lamare et al 2020 combined with increased availability of higher resolution satellite data gascoin et al 2019 suggest that such criteria may soon be met even in mountainous areas our findings confirm that when remote sensing science can achieve the deviations from ground truth reported here the assimilation of data from optical satellite sensors will improve ensemble forecasting capabilities 5 conclusions our results demonstrate that the assimilation of snowpack surface reflectances using the particle filter algorithm improves simulation of the temporal evolution of snowpack bulk variables our study used synthetic observations but the assimilation dates were selected from true modis images made under appropriate conditions clear sky full snow cover viewing zenith angle 60 for retrieving surface reflectance from the snowpack these restricted conditions for acquiring snow surface reflectance led to the assimilation of data from 14 to 20 dates in each of three snow seasons despite the reduced number of assimilation dates over more than seven months of snowpack simulations the simulation system showed an improvement in results compared with the simulations made without data assimilation the assimilation of the first seven modis like bands including information in visible and near infrared wavelengths showed the best results from all band combinations tested in the contrary the assimilation of true modis surface reflectance failed and did not improve open loop simulations results in light of this shortcoming different biases were introduced to the synthetic observations to obtain the maximum deviation from ground truth that data assimilation admits the simulation system enabled the assimilation of surface reflectances having a random white noise less than or equal to 5 or a systematic bias less than or equal to 2 from ground truth this indicates the maximum deviation that satellite derived products will have to provide for improvement of ensemble simulations through data assimilation to occur the results of this study provide the specifications in terms of accuracy for the processing of satellite reflectances credit authorship contribution statement j revuelto methodology data curation formal analysis resources investigation validation visualization writing original draft writing review editing project administration funding acquisition b cluzet methodology software validation data curation investigation writing review editing n duran software validation visualization m fructus software validation visualization m lafaysse conceptualization software writing review editing e cosme conceptualization writing review editing m dumont conceptualization methodology supervision writing review editing project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments j revuelto was supported by a post doctoral fellowship of the axa research fund le post doctorant jesús revuelto est bénéficiaire d une bourse postdoctorale du fonds axa pour la recherchem ref cnrm 3 2 01 17 j revuelto is now supported by a juan de la cierva incorporación fellowship of the spanish ministry of science and innovation ijc2018 036260 i ige and cnrm cen are part of labex osug 2020 this work was partly supported by the french national program lefe insu assurance apr cnes miosoti and an anr jcjc eboni grant anr 16 ce01 0006 this research was also supported by lautaret garden ums 3370 univ grenoble alpes cnrs sajf 38000 grenoble france a member of anaee france anr 11 inbs 0001anaee services investissements d avenir frame and the elter europe network univ grenoble alpes cnrs lster zone atelier alpes 38000 grenoble france 
4022,as the fifth largest super tropical cyclone landed on mainland china in history typhoon lekima occurred in august 2019 caused at least 71 deaths 14 million disaster victims and cost rmb 65 37 billion in damages here we use six latest gpm based near real time satellite precipitation estimates imerg early imerg late gsmap now gsmap nrt gsmap mvk and cmorph rt to quantify the spatiotemporal pattern of typhoon rainfall and meanwhile the potentials of these satellite precipitation products in detecting heavy storms are systematically investigated retrieval results indicate that the expansive rain belt of typhoon lekima brought approximately 93 2 billion m3 water in total onto the chinese mainland during the typhoon period and the precipitation process maintained higher intensities on the earlier two days august 10 and 11 specifically it is found that a precipitation window with higher precipitation intensities appeared between 5 00 a m and 10 00 a m implying that a greater probability of rainstorms may occur during this period moreover at the storm center around the dongying city of shandong province the dual frequency precipitation radar of gpm gpm dpr successfully revealed the existence of precipitation columns with the peak value of 121 mm h 1 which seem to play a key role in the regional torrential rainfall additionally our evaluation shows imerg late and cmorph rt perform better under higher rain rates relative to other satellite precipitation estimates this can be primarily attributed to their sufficient inputs from pmw sensors and respectively the former benefits well from both dpr and gmi while the latter significantly reduces its ir inputs this study illustrates an example of monitoring the extreme heavy precipitation storms by the latest gpm based near real time satellite precipitation estimates and highlights future possible improvements for algorithm developers keywords gpm satellite precipitation estimates typhoon lekima imerg gsmap mainland china 1 introduction tropical cyclones tcs and their associated torrential rains are the deadliest and most destructive natural hazards on earth especially for those coastal areas emanuel 2005 liu et al 2019 patricola and wehner 2018 as a supper tropical cyclone originated from the western north pacific typhoon lekima is one of the costliest natural disasters in china causing 14 million victims at least 71 deaths and costing 65 37 billion in damages fig 1 a and b it landed on wenling city of zhejiang province at 1 45 a m local time utc 8 similarly hereafter on august 10 2019 fig 1c then slowly moved toward the north along the east coast of china and finally dissipated in the bohai gulf on august 13 this typhoon lingered over the land for 44 h and brought about a record breaking rainfall total the land area covered by torrential rains beyond 100 mm was approximately 361 000 km2 while even that beyond 250 mm reached 66 000 km2 particularly typhoon lekima resulted in unprecedented rainstorm disasters in shandong province where the disaster affected population was over 5 million taking the national weather station of shikou as an example the total accumulative precipitation for three days reached 463 mm far exceeding the historical maximum https en wikipedia org wiki typhoon lekima as the earth s atmosphere warms the translation speed of tcs is found to decrease globally by 10 per cent over the period 1949 2016 kossin 2018 the total amount of rainfall associated with tcs over a given region is proportional to the rainfall intensity and the inverse of tc translation speed zhang et al 2020 as expected the amount of tc related rainfall may increase under climate warming due to the increasing duration of tcs passing through a specific region this suggests greater disaster risks in response to more intense rainfall may be potentially elevated in the future elsner et al 2008 mendelsohn et al 2012 therefore quantitatively understanding the changing characteristics of tc induced rainfall is rather important for preventing the threats of tcs and the associated flood risks at coastal regions lai et al 2020 reul et al 2017 however precisely measuring precipitation at a large scale is still a challenging task owing to the broad coverage and high spatiotemporal variability of precipitation itself min et al 2011 particularly it is mostly infeasible to entirely monitor tc induced rainfall with conventional rain gauge networks and ground radars which cannot capture the precipitation information on the sea surface satellite based remote sensing provides an effective way to measure the large scale areal rainfall induced by tcs with fine resolution and quasi global coverage from space peng et al 2020 over the past few decades satellite based precipitation estimations have experienced rapid developments skofronick jackson et al 2017 at present the latest multi satellite precipitation estimates have transited from the tropical rainfall measuring mission trmm to global precipitation measurement gpm mission which is cooperatively deployed by the national aeronautics and space administration nasa and the japan aerospace exploration agency jaxa hou et al 2014 yong et al 2015 the gpm is an international network of satellites that provide the next generation global observation of rain and snow to advance our understanding of earth s water and energy cycle one chief science objective of gpm is to further extend capabilities in monitoring and predicting tcs and other extreme weather events https gpm nasa gov missions gpm the gpm based multi satellite precipitation retrieval offers a powerful means for quantitatively monitoring the tc induced rainfall at regional scales some recent studies showed that the latest gpm based near real time precipitation estimates gnpes generally perform better than those trmm based estimates in measuring tc induced rainfall fang et al 2019 gebregiorgis et al 2018 liu 2016 wang et al 2017a moreover the post real time gauge adjusted gpm precipitation products e g imerg final and gsmap gauge are normally superior to the near real time satellite only ones e g imerg early and gsmap nrt at daily or longer time scales huang et al 2019 zhang et al 2019 yu et al 2021 in fact the performance of gpm estimates of heavy precipitation has significant variance based on the geography of the region gnpes that without gauges calibration often perform better at the coastal plain than at high altitude which shows dependence on terrain zhou et al 2020 fang et al 2019 for the tibetan plateau specifically gnpes can effectively identify extreme precipitation events and their spatial distribution but underestimate the extreme precipitation amount lei et al 2021 lu and yong 2018 tang et al 2018 however few studies are found to assess at time scales finer than 1 day and it is found that for shorter than 6 hourly temporal resolutions the bias correction technique seems unable to bring improvements especially for extremely heavy rainfall events mastrantonas et al 2019 therefore as the first step it is essential to comprehensively investigate the potentials of gnpes in monitoring the torrential rains induced by tcs with a short duration nevertheless literature surveys suggest relevant studies are still lacking in addition the dual frequency precipitation radar dpr onboard the gpm core observatory satellite can offer three dimensional information of rainfall structure with higher precision wu et al 2021 have compared the radar data from dpr and ground s band radar to further understand the precipitation microphysics of the landing lekima however they did not directly display the dpr precipitation estimates in this study dpr precipitation estimates are used to reveal the vertical precipitation in the storm center of landed typhoon for the satellite quantitative precipitation estimation and hydrology community it is an interesting but challenging work to detect the inner structure of tc induced rainfall by some new technological means such as dpr which will provide the impetus for more research and development in this study six latest gnpes were utilized to explore the characteristics of spatiotemporal distribution and the inner structure of torrential rains induced by typhoon lekima at the coastal regions of eastern china the selected multi satellite precipitation products were statistically investigated at the hourly 0 1 0 1 latitude longitude gridded scale in detail the objective of this study is to evaluate the data quality of currently mainstream near real time gpm retrievals and reveal the spatiotemporal pattern of lekima induced rainfall specifically efforts are mainly focused on 1 what is the error characteristic of these six near real time gpm products in detecting typhoon induced rainfall and how much do they differ 2 can the rain total of landed typhoon be worked out by merging these gnpes 3 whether we can clearly see the vertical precipitation profile for storm center areas via the active radar signals from the newest dpr 4 what implications do results concluded from this study have on future gpm development 2 study area datasets and methodology 2 1 study area the rain belt induced by typhoon lekima with broad coverage of approximately 2 68 106 km2 swept along the coastal regions of eastern china from south to north thus we selected a rectangular domain at the longitude of 105 e 150 e and latitude of 27 n 54 n as our study area see fig 2 which can give a full view of the typhoon rain belt covering both land and ocean besides the 250 m resolution elevation datasets from shuttle radar topography mission are used to show the land topography in this area jarvis et al 2008 data source https srtm csi cgiar org wp content uploads files 250m here our analyses mainly focused on coastlands with dense populations and developed economy including the lower yangtze plain the north china plain and the northeast china plain which are suffered from severe torrential rains during the period of typhoon lekima what is worth mentioning these areas are well equipped with extraordinarily dense observation networks of rain gauges operated by the china meteorological administration that can provide reliable ground verification for the satellite precipitation estimates tang et al 2020 2 2 datasets 2 2 1 satellite precipitation estimates in this study six latest gnpes i e imerg early imerg late gsmap now gsmap nrt gsmap mvk and cmorph rt and the newest gpm dpr data were employed for detecting the torrential rains induced by typhoon lekima these satellite based precipitation datasets are summarized in table 1 in practice there are some other available near real time mainstream precipitation datasets e g tmpa 3b42rt and persiann ccs that seem suitable to be considered however as a trmm based representative product tmpa 3b42rt had completed the transition to gpm based imerg suite by the end of 2019 https gpm nasa gov media 292 while persiann ccs was excluded here because of its relatively poor performance in monitoring the heavy rainfall yong et al 2016 in addition those gauge adjusted satellite datasets e g imerg final and gpcp and assimilation based reanalysis products e g era interim and jra 55 were not included as well since our study mainly focused on investigating the monitoring capacity of the purely satellite derived precipitation estimates with low latency for tc induced rainfall the two imerg products imerg early and imerg late used in this study are provided by nasa as part of the gpm mission the imerg series have excellent spatiotemporal resolutions 30 min 0 1 0 1 with quasi global coverage of 90 n 90 s except for those snowy icy covered surfaces outside the latitude band 60 n 60 s peng et al 2020 huffman et al 2019 to strive for better data quality the imerg system intends to intercalibrate merge and interpolate data from as many source inputs as it can obtain including dpr data passive microwave pmw estimates microwave calibrated ir estimates and potentially other precipitation estimators huffman et al 2019 with regards to the algorithm imerg successfully integrates the merits of three trmm based mainstream satellite precipitation systems namely tmpa huffman et al 2007 cmorph joyce et al 2004 and the persiann hong et al 2004 hsu et al 1997 the imerg system produces two types of near real time precipitation products among which imerg early can give faster estimates within a relatively short time approximately 4 h while imerg late can offer better estimates after more satellite data have arrived about 14 h the main difference between imerg early and imerg late is that the former only relies on a forward propagation to extrapolate the pwm retrievals while the latter has both forward and backward propagation allowing interpolation https gpm nasa gov data directory thus imerg late can achieve the transmissions of lagging data that were not available for imerg early in its additional latency of about 10 h huffman et al 2019 in this study we adopted the latest released version 6 of imerg the three gsmap products gsmap now gsmap nrt and gsmap mvk are developed by the precipitation measuring mission science team of jaxa the gsmap group aims to develop novel dpr compatible microwave radiometer precipitation retrieval algorithms and generate a quasi global precipitation dataset with high precision kubota et al 2020 the gsmap data suite comes at a 1 h temporal resolution and a grid of 0 1 0 1 covering the globe 60 s 60 n the gsmap system combines precipitation retrievals from gpm and other polar satellites and interpolates them with cloud moving vector derived from ir images of geostationary satellites kubota et al 2007 ushio et al 2009 it is worth noting that gsmap now is the quasi global satellite precipitation estimate with the fastest accessible at present it employed almost all the passive microwave observations that are available within a half hour after observation and applied a half hour extrapolation of rainfall map toward future direction by using cloud moving vector from the geostationary satellite this allows data producers to estimate real time hourly rainfall maps at every half hour besides the gsmap system also generated other two near real time precipitation estimates gsmap nrt and gsmap mvk among them gsmap nrt uses relatively fewer pmw inputs available within 3 h and a forward only cloud advection technique while gsmap mvk merges more accessible satellite data with both forward and backward propagation schemes hence these two products seem to be corresponding to imerg early and imerg late mentioned above respectively the latest version 6 of gsmap now and version 7 of gsmap nrt and gsmap mvk are used in our analyses the real time cpc morphing technique cmorph rt is produced by the climate prediction center cpc of the american national oceanic and atmospheric administration noaa the cmorph system propagates the pmw input data using the motion vector matrix calculated from continuous two ir images joyce and xie 2011 usually ir data will not be incorporated into the final estimates unless the gap between the two pmw observations is longer than 90 min because the ir based estimates normally outperform that of pmw under longer propagation periods xie et al 2017 in practice both cmorph and gsmap adopt similar morphing algorithms to derive cloud motion vectors nevertheless gsmap employs a new kalman filter approach to assimilate and refine the ir based rain rates while cmorph only uses ir data to propagate mw derived precipitation features in most circumstances the newest version 0 x of cmroph rt was used in this study 2 2 2 gpm based dpr data the dual frequency precipitation radar dpr of gpm was jointly developed by jaxa and japan national institute of communication technology nict it is composed of two radars ku band precipitation radar at 13 6 ghz and ka band radar at 35 5 ghz which provide three scanning modes including normal scan ns ku band match scan ms ka band and high sensitive scan hs ka band on each scanning orbit hou et al 2014 relative to the original trmm based precipitation radar pr dpr is expected to further advance the precipitation measuring precision from space since it increases the sensitivity of precipitation detection decreases the retrieval uncertainty due to the raindrop size distribution dsd variation enlarges the scanning coverage 65 n 65 s and generates better estimates of the phase transition height skofronick jackson et al 2017 wilson et al 2011 currently the dpr algorithm has been upgraded in the newest verison 6 in that all beam directions of kupr and kapr were adjusted for better matching with the nominal footprint locations iguchi et al 2018 this might make further improvements for heavy rain events particularly the latest version 6 of level 2 dpr provides high resolution three dimensional rain echoes information which was applied to expose and analyze the vertical precipitation characteristics of typhoon storms in our study 2 2 3 ground references the gridded hourly merged precipitation analysis mpa dataset version 1 0 developed by the national meteorological information center of the china meteorological administration is used as the reference data which combines gauge observations from over 30 000 automatic weather stations with cmorph product yu et al 2015 the probability density function pdf matching and optimal interpolation oi method are employed for generating the merged mpa precipitation dataset at an hourly 0 1 0 1 latitude longitude resolution shen et al 2013 indicate that the merged mpa product generally outperforms other operational precipitation products over mainland china especially for the gridded regions containing automatic weather stations hence then we extracted those grid cells with at least two gauges in our evaluation for ensuring the reliability of validation results and these extracted mpa grids are used as the ground reference for scatterplots and statistical metrics additionally the hourly precipitation observations of 51 rain gauges in dongying city were provided by the meteorological bureau of shandong province the ground precipitation of dongying city during the lekima s period from august 10 to august 13 is averaged from these gauge data for special and higher precision reference within the extreme rainstorm central area 2 3 methodology 2 3 1 statistical metrics to quantitatively compare and validate the data accuracy of six gnpes against ground references we use several representative statistical metrics in our evaluation including pearson correlation coefficient cc root mean square error rmse mean error me relative bias bias mean absolute error mae absolute bias abias and contingency table based detection of rainy events i e probability of detection pod false alarm ratio far and critical success index csi the calculation formulae of these statistical metrics and their corresponding perfect values are summarized in table 2 considering that me and bias can only scale the average difference between remotely sensed estimates and observations we chose mae and abias to quantify the absolute error magnitude because positive and negative differences may cancel each other to some degree in the realistic assessment additionally pod measures the likelihood of satellite retrievals to detect a rainy event when it occurs in fact while far indicates the likelihood that a rainy event does not occur when satellite estimates rain the csi metric demonstrates the comprehensive capability of satellite estimates to detect precipitation occurrence more detailed explanations for the nine statistical metrics used can be found in yong et al 2010 and tang et al 2020 2 3 2 data preprocessing as can be seen from table 1 the data format and spatiotemporal resolution of eight different precipitation datasets are non uniform therefore the first step in data processing is to unify the resolution of them to match that of the ground reference except for the gsmap suite other three satellite precipitation datasets i e imerg early imerg late and cmorph rt were aggregated and or resampled to the hourly 0 1 0 1 resolution in this study specifically to precisely resample the cmorph rt estimates the bilinear interpolation algorithm was applied to compute the precipitation value for each targeted 0 1 0 1 grid cell by interpolating those values of its adjacent four 8 km 8 km grids as for the ground reference we extracted those mpa grids with at least two gauges to be specific an average of 27 6 grids were extracted the extraction was done hourly thus there is still an abundant amount of grids 38920 37187 40231 41998 43817 and 34 754 for gsmap now gsmap nrt gsmap mkv imerg early imerg late and cmorph rt respectively to investigate the rmse and bias distribution of these six gnpes at different precipitation intensities extracted mpa grids are binned into different categories according to their precipitation values as shown in fig 6 the x value of the edge points of these bins on the x axis is a power of 2 and the exponent of them increases as a geometric series with a common ratio of 0 25 i e 2 2 875 2 2 625 2 2 850 25 875 to make all bins on the logarithmic coordinate axis have an equivalent interval in the gpm data system the dpr precipitation dataset used in this study is one of the level 2 single orbit precipitation products which is derived from the gpm level 1 radar products it has not been spatiotemporally resampled as an end user level precipitation product thus extra treatments are needed before analyzing and data visualization horizontally dpr ns data provides a 245 km swath that consists of 49 beams each beam corresponds to a footprint which size is about 5 km in diameter above each footprint there are numbers 176 for 2a dpr ns of range bins with each height of 125 m therefore three dimensional precipitation data of 2a dpr is approximate 5 km 5 km 125 m in resolution however one should note that each scan beam from the footprint on the ellipsoid to dpr in space is not absolutely perpendicular to the ellipsoid of the earth see fig 3 hence there are deformations of the original data array in both horizontal and vertical directions in this study we interpolated the original dpr data into a three dimensional array with each grid of 5 km 5 km in horizontal and 5 km 125 m in vertical relative to the local ellipsoid surface before that positions of original range bins in a three dimensional rectangular coordinate system are needed therefore we first calculated the height and the horizontal offset for each range bin to explain it better fig 3 shows the relationships of the parameters for dpr data preprocessing the height and the horizontal offset relative to the ellipsoid surface of each range bin can be computed by the following equations 1 heigh t n binellipsoid n b i n s i z e e o f f s e t c o s zangle 2 hoffse t n binellipsoid n b i n s i z e e o f f s e t s i n zangle where height n is the vertical distance from the center of range bin n to the ellipsoid hoffset n is the horizontal offset distance between centers of range bin and that of the footprint binellipsoid is a constant range bin number 176 of the one that crosses the surface of the ellipsoid binsize is the height 125 m of each range bin eoffset is the distance from the center of the binellipsoid range bin to the surface of the ellipsoid along the beam direction and zangle is the zenith angle of each dpr beam with the height and the offset the precipitation value for each target array bin was spatially interpolated from that of the adjacent range bins with inverse distance weighted algorithms 3 results and discussion 3 1 comparison and validation of satellite precipitation estimates fig 4 shows the spatial distributions of accumulated precipitation amount derived from six gnpes on the 0 1 0 1 resolution grid during the period of typhoon lekima from august 10 to august 13 generally these six precipitation products all display a similar spatial pattern at a large scale in that the typhoon induced rain belt extended along the east coast of china from south to north besides one can see that the storm center firstly moved toward the northwest after typhoon landing and then turned to the northeast direction the moving track exhibits a typical semi arc outline which is closely related to the motion characteristic of tcs in the northern hemisphere with respect to physical mechanisms such phenomenon might be attributed to the combined effects of both the impetus of horizontal coriolis force and the resistance of subtropical high kim and seo 2016 liang et al 2017 wang et al 2017a b as for the areal distribution of heavy rains especially for surrounding the bohai gulf see the highlight spots in each plot of fig 4 the left four precipitation estimates i e gsmap nrt gsmap mvk imerg early and imerg late have more similar spatial patterns this consistency may be associated with partial overlaps of the imerg and gsmap systems in data inputs and retrieval algorithms specifically they share the same infrared ir data and a part of passive microwave pmw data furthermore both of them use the atmospheric moving vector from two successive ir images to propagate the rainy area from microwave radiometry and then employed the kalman filter model to update the precipitation rate for accurately representing the temporal variation of precipitation systems ushio et al 2009 zhang et al 2019 additionally it is clear that gsmap now systematically underestimated heavy rainfall fig 4c while an opposite overestimation occurred for cmorph rt fig 4f this arises because gsmap now only used limited satellite inputs available within a half hour particularly lacking for many data from pmw sensors on the contrary cmoprh rt mainly depends on the pmw based data in its retrieval algorithm which substantially differs from those estimates relying on merging ir and pmw observations to quantitatively understand the retrieval accuracy of these gnpes at the storm center an average of the rainfall observations from 51 local gauges which are maintained by the meteorological bureau of shandong province is computed in the dongying representative grid located between 118 e 119 e and 37 n 38 n results indicate the total rainfall amount of dongying city during the typhoon period from local time august 10 to august 13 the same below reached 342 mm among the six precipitation datasets imerg late has the closest estimation of 274 mm while gsmap now shows the lowest value of 102 mm fig 4c and e with regards to the other four products i e gsmap nrt gsmap mvk imerg early and cmorph rt the corresponding values are 234 mm 238 mm 202 mm and 241 mm respectively fig 4a b d and f specifically the corresponding result from mpa no extraction here is 276 mm which falls between the results from the gnpes and local gauges this can be expected since mpa is a merged product of automatic gauges and satellite retrievals having seen that all datasets underestimate the storm that occurred at dongying city we suggest that the current satellite precipitation estimates might have the intrinsic feature of overall underestimation at higher rain rates especially for typhoon rainfall yong et al 2016 which is probably associated with the weak linkage between the cloud top temperature and the convective storms hamada et al 2014 tian et al 2009 moreover we found that the improvement from imerg early to imerg late seems to be better than that from gsmap nrt to gsmap mvk when comparing both spatial patterns and extreme rainfall despite that gsmap mvk has longer latency 3 days for precipitation estimation relative to imerg late 14 h this implies that the algorithm of backward propagation in imerg late run is superior to that used in the gsmap system to further compare and validate the retrieval accuracy of these gnpes we adopted the widely used gridded gauge product of merged precipitation analysis mpa 0 1 0 1 1 h as the ground reference to perform the evaluation during the typhoon period over mainland china in practice we only selected those grid boxes that contained at least two gauges in our calculations so as to ensure the credibility of assessment results scatterplots of hourly comparison of six satellite precipitation estimates versus the ground reference are shown in fig 5 and detailed statistical results are listed in table 3 the hourly scatterplots indicate that both gsmap and imerg product suites generally underestimate the rainfall while cmorph rt has an opposite overestimation as expected the worst performance is found in the gsmap now estimates with the lowest cc and largest negative errors the severe underestimation of gsmap now can be attributed to the deficiency of various pmw inputs while the overestimation of cmorph might be associated with its primary dependency on pmw echoes sungmin et al 2017 this is consistent with the conclusions derived from fig 4 two types of near real time estimates of both gsmap nrt and mvk and imerg early and late demonstrate similar distributions of scattered points and those estimates with longer latency are apparently superior to their corresponding prophase products respectively additionally we note that cmorph rt generally has a better convergence feature and can effectively control the outliers especially at medium low rain rates relative to other estimates comparing fig 5f and other plots but it does not exhibit the best performance as expected contrarily it has the largest absolute errors e g mae abias and rmse and the lowest probability of detection in six evaluated gnpes in terms of the nine statistical metrics used in our evaluation no satellite precipitation product can comprehensively outperform the others all the gnpes have satisfactory and similar pod and there is still room for further improvements on far that is associated with csi however despite showing high pod gsmap now and imerg early still have significant negative bias with regard to fig 6 b we suppose the universal underestimates of them at high precipitation intensity 4 mm h 1 make a major impact which is unfavorable in tc induced precipitation events to better satisfy the needs of heavy rainfall detection the current gpm based satellite precipitation estimates have enlarged their monitoring range of the rainfall intensity hou et al 2014 based on the sufficient rainfall pairs of satellite estimates versus ground observations we further investigated the distribution characteristics of error and bias of six evaluated satellite products at different rain rates fig 6 generally speaking there is a clear power function relationship between rmse and logarithm of rain rates suggesting that the errors of satellite retrievals have a stronger dependency on the rainfall intensity fig 6a such systematic error features closely related to the rainfall intensity should therefore be noticed for the future development of gpm algorithms in addition fig 6b shows that all the six gnpes tend to overestimate rainfall at lower rain rates while underestimating at high ones among these gnpes cmorph rt evidently exhibits a relative overestimation against other satellite estimates at the total range of rain rates although such relative overestimation can partly alleviate the negative biases of satellite retrievals at higher rain rates 8 mm h 1 it further aggravates the positive biases at lower ones 2 mm h 1 as a result it is likely that the pmw based algorithm in cmorph rt cannot substantially improve the retrieval accuracy of satellite precipitation as for the other five products imerg late looks better at the medium high rain rates and the others have similar performance 3 2 process analysis of typhoon rainfall to look further into the variation process of lekima induced storms we investigated the spatiotemporal distributions of daily rainfall in detail during the typhoon period from august 10 to 13 the spatial distributions of daily cumulative rainfall amount averaged from all satellite products are plotted on the left column of fig 7 while the time series of the hourly rainfall intensity of six gnpes and their averages for each day are manifested on the right column to better illustrate the temporal distributions of heavy rainfall we only calculated the hourly precipitation amounts of multiple precipitation datasets over those regions with storm events 50 mm d 1 in regard to the space precipitation distributions on the left half of fig 7 the precipitation of typhoon lekima mainly occurred in the first two days august 10 and august 11 of the study period and manifest the largest coverage on august 11 spatially first day precipitation mainly distributed around the landing spot while the precipitation on the second day was concentrated in the bohai gulf the rain belt had an accelerated stretching with the northeastward turn of lekima suggesting a suitable moisture transport condition which enables this long distance rain belt zhou and wu 2019 interestingly not only lekima took advantage of this moisture channel typhoon krosa appear on the bottom of fig 7g may have used it as well which gives reason to the slight rising tendency on august 13 fig 7h the precipitation time series in fig 7 indicate continuously stable torrential rainfall from 0 00 a m august 10 to 14 00 p m august 12 local time then the tc induced storm started to fade and light rainfall continuously remained for several days based on these time series one can notice a precipitation window in the morning from 5 00 a m to 10 00 a m local time in which all satellite precipitation products tend to give higher estimation and correspondingly exhibit apparent similar storm centers in space during the entire study period the total amount of precipitation 93 2 billion m3 over mainland china is approximately equal to 2 5 times the maximum capacity of the three gorges dam reflecting a strong impact brought by typhoon lekima generally both gsmap now and imerg early have larger amplitudes of fluctuation with significant instability throughout the study period while gsmap nrt gsmap mvk and imerg late show a relatively stable performance as aforementioned above cmorph rt displays a distinct overestimation throughout the whole raining process fig 8 compares the time series of typhoon precipitation amounts computed by these six gnpes over mainland china and dongying city respectively in terms of the entire mainland china it is clear that a precipitation peak occurred on august 11 fig 8a which corresponds to the peak value of the precipitation series at dongying city fig 8b but the extreme heavy precipitation at dongying city showed a faster tendency during the period of rising and declining in this case imerg late imerg early gsmap mvk and gsmap nrt turn out to have a similar performance with strong instability among all six gnpes cmorph rt seems more smoothly and has the best consistency with the averaged value while gsmap now completely missed the peak value with relatively the worst performance besides we note that the scanning track of gpm core satellite passed across the dongying city at about 12 58 17 p m local time on august 10 fig 8a at that moment a peak value was captured by imerg late see fig 8b considering the common underestimation of satellite retrievals in extreme precipitation estimates and the high data accuracy of dpr and gmi we concluded that the instruments aboard on gpm core satellite have effectively improved the detection ability of extreme events hou et al 2014 skofronick jackson et al 2016 thus the imerg late combining both dpr and gmi data may have relatively better potentials in monitoring the extreme rainfall events 3 3 vertical detection of typhoon rainfall to clearly see the inner structure of such extreme rainfall events we further analyzed the vertical precipitation information provided by gpm dpr with the gpm data package named as 2a gpm dpr v8 fig 9 a shows the scanning orbit including three scan types i e ns ms and hs of dual frequency precipitation radar aboard the gpm core observatory from 12 56 53 p m to 13 00 23p m local time on august 11 2019 when typhoon lekima was passing the territory of shandong province due to the ongoing algorithm update the type of ms see yellow circles in the left insert of fig 9a lacks vertical data in the current level 2 dataset of gpm dpr while missing values are stored in the output fields of hs data red circles therefore here we adopted the normal scan ns blue circles of ku band with a swath width of 245 km to interpret the three dimensional precipitation information of typhoon rainfall the distributions of vertical precipitation rates detected by kupr from the ground surface to rain top and horizontal ones averaged from 2 km to 4 km height are displayed in fig 9b and c respectively from fig 9b one can clearly see the vertical profile of typhoon rainfall associated with different precipitation intensities combined with the horizontal distribution in fig 9c we can quantitatively identify the three dimensional precipitation structure of storm centers located within the scanning orbit of gpm dpr comparing the two profiles the main plot and the subplot in fig 9c that are shown in perpendicular directions it is found that the horizontal storm centers agree well with the vertical distribution of high rain rates thus the columnar structure but with a relatively thin top and thick bottom of typhoon storms can be clearly exposed by gpm dpr in three dimensions as can be seen from fig 9c there are three main storm zones located in the western part of shandong province during the visiting time of gpm dpr among them the middle one with the largest rain rates appears around the maintain tai where the complex mountainous topography seems to further strengthen the local storm intensity it implies that the orographic effect may be closely associated with the occurrence of the storm center in summary our analyses indicate that gpm dpr can accurately capture the three dimensional structure of typhoon rainfall despite its longer revisiting period and narrower swath width in the design framework of gpm dpr is taken as an important calibration standard for other pmw and ir sensors on the constellation satellites tapiador et al 2012 hou et al 2014 yong et al 2015 but in practice the other two scan types of dpr i e ms and hs have not been sufficiently utilized in the gpm retrieval system since it takes time to develop new algorithms applicable to the full swath and to adjust the necessary parameters to ensure the quality of the precipitation products as documented in iguchi et al 2018 in particular no data from the high sensitive scan of ka band is used in the current operational level 2 and 3 products of gpm looking into the future development of gpm we suggest that all the three scan types of dpr should be combined together to generate a more accurate calibration standard for the gpm constellation so as to substantially improve the retrieval quality of gnpes especially for extreme rainfall events 4 conclusion in this study we investigate the potentials and limits of six gpm based near real time precipitation estimates in monitoring the super typhoon rainfall and demonstrate the spatiotemporal characteristics of the extreme precipitation induced by typhoon lekima the six selected gnpes were comprehensively intercompared and evaluated against ground observations and particularly the three dimensional precipitation structure for typhoon storms was systematically detected by the newest dpr of gpm the main conclusions are summarized as follows 1 spatially the long extended rain belt of typhoon lekima affects a large area along the chinese eastern coast of approximately 2 68 106 km2 it created two concentrated rainstorm centers distributed around the landing spot and shandong province respectively the total amount of precipitation reached approximately 93 2 billion m3 over the entire study area in terms of precipitation time series intense precipitation remains continuously and peak in the morning on august 11 before it began to fade after the noon of august 12 specifically we found an interesting precipitation window from about 5 00 a m to 10 00 a m local time in which all satellite precipitation products tended to give higher rainfall estimates this implies that other typhoon induced storms are easier to happen during this period under similar extreme weather conditions which could provide some important reference information for local mountain torrents warnings 2 during the study period gsmap now and cmorph rt show respectively underestimation and overestimation compared with the others while gsmap nrt gsmap mvk and imerg late give relatively consistent estimates especially for high intensity precipitation among six gnpes those estimates with longer latency generally perform better in heavy rain monitoring which partly benefit from more abundant inputs from pmw sensors however six gnpes still show instability particularly during the monitoring of intense precipitation of which there is still room for further improvement 3 in statistical evaluation despite all six gnpes perform well in pods 92 relatively low ccs between six gnpes and ground references are still unsatisfactory this indicates that near real time tc induced precipitation estimation at fine spatiotemporal resolution still faces considerable uncertainty aside from the inherent random error we notice a series of systematic errors related to the precipitation intensities six gnpes tend to show underestimation at higher rain rates 4 mm h 1 and overestimation at lower ones 2 mm h 1 this results in a common negative bias except for cmorph rt of which the algorithm mainly employs pmw data despite that however we cannot assert which product suite is distinctly superior to the others based on the indices they all own specific skills on satellite based precipitation retrievals we suggest that the aforementioned systematic error may be a potential pathway to achieve more accuracy in future works 4 rely on the advanced gpm dpr we demonstrate a three dimensional view inside the lekima induced rain storms instead of heavy rainfall over a broad area the instantaneous field of view shows some concentrated intense precipitation regions there several adjacent but independent rain columns are proved to exist in which the precipitation intensity reached 121 mm h 1 hence these rain columns are probably the key for the monitoring of extremely heavy precipitation at a fine spatial scale which should be taken into consideration henceforward we believe this information will enrich the perception of regional rainstorms credit authorship contribution statement weiqing qi conceptualization methodology software formal analysis bin yong writing review editing project administration funding acquisition jonathan j gourley declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we appreciate the extensive efforts from the developers of the satellite and ground precipitation products that make these datasets available the study is funded by the national natural science foundation of china 92047301 and 51979073 
4022,as the fifth largest super tropical cyclone landed on mainland china in history typhoon lekima occurred in august 2019 caused at least 71 deaths 14 million disaster victims and cost rmb 65 37 billion in damages here we use six latest gpm based near real time satellite precipitation estimates imerg early imerg late gsmap now gsmap nrt gsmap mvk and cmorph rt to quantify the spatiotemporal pattern of typhoon rainfall and meanwhile the potentials of these satellite precipitation products in detecting heavy storms are systematically investigated retrieval results indicate that the expansive rain belt of typhoon lekima brought approximately 93 2 billion m3 water in total onto the chinese mainland during the typhoon period and the precipitation process maintained higher intensities on the earlier two days august 10 and 11 specifically it is found that a precipitation window with higher precipitation intensities appeared between 5 00 a m and 10 00 a m implying that a greater probability of rainstorms may occur during this period moreover at the storm center around the dongying city of shandong province the dual frequency precipitation radar of gpm gpm dpr successfully revealed the existence of precipitation columns with the peak value of 121 mm h 1 which seem to play a key role in the regional torrential rainfall additionally our evaluation shows imerg late and cmorph rt perform better under higher rain rates relative to other satellite precipitation estimates this can be primarily attributed to their sufficient inputs from pmw sensors and respectively the former benefits well from both dpr and gmi while the latter significantly reduces its ir inputs this study illustrates an example of monitoring the extreme heavy precipitation storms by the latest gpm based near real time satellite precipitation estimates and highlights future possible improvements for algorithm developers keywords gpm satellite precipitation estimates typhoon lekima imerg gsmap mainland china 1 introduction tropical cyclones tcs and their associated torrential rains are the deadliest and most destructive natural hazards on earth especially for those coastal areas emanuel 2005 liu et al 2019 patricola and wehner 2018 as a supper tropical cyclone originated from the western north pacific typhoon lekima is one of the costliest natural disasters in china causing 14 million victims at least 71 deaths and costing 65 37 billion in damages fig 1 a and b it landed on wenling city of zhejiang province at 1 45 a m local time utc 8 similarly hereafter on august 10 2019 fig 1c then slowly moved toward the north along the east coast of china and finally dissipated in the bohai gulf on august 13 this typhoon lingered over the land for 44 h and brought about a record breaking rainfall total the land area covered by torrential rains beyond 100 mm was approximately 361 000 km2 while even that beyond 250 mm reached 66 000 km2 particularly typhoon lekima resulted in unprecedented rainstorm disasters in shandong province where the disaster affected population was over 5 million taking the national weather station of shikou as an example the total accumulative precipitation for three days reached 463 mm far exceeding the historical maximum https en wikipedia org wiki typhoon lekima as the earth s atmosphere warms the translation speed of tcs is found to decrease globally by 10 per cent over the period 1949 2016 kossin 2018 the total amount of rainfall associated with tcs over a given region is proportional to the rainfall intensity and the inverse of tc translation speed zhang et al 2020 as expected the amount of tc related rainfall may increase under climate warming due to the increasing duration of tcs passing through a specific region this suggests greater disaster risks in response to more intense rainfall may be potentially elevated in the future elsner et al 2008 mendelsohn et al 2012 therefore quantitatively understanding the changing characteristics of tc induced rainfall is rather important for preventing the threats of tcs and the associated flood risks at coastal regions lai et al 2020 reul et al 2017 however precisely measuring precipitation at a large scale is still a challenging task owing to the broad coverage and high spatiotemporal variability of precipitation itself min et al 2011 particularly it is mostly infeasible to entirely monitor tc induced rainfall with conventional rain gauge networks and ground radars which cannot capture the precipitation information on the sea surface satellite based remote sensing provides an effective way to measure the large scale areal rainfall induced by tcs with fine resolution and quasi global coverage from space peng et al 2020 over the past few decades satellite based precipitation estimations have experienced rapid developments skofronick jackson et al 2017 at present the latest multi satellite precipitation estimates have transited from the tropical rainfall measuring mission trmm to global precipitation measurement gpm mission which is cooperatively deployed by the national aeronautics and space administration nasa and the japan aerospace exploration agency jaxa hou et al 2014 yong et al 2015 the gpm is an international network of satellites that provide the next generation global observation of rain and snow to advance our understanding of earth s water and energy cycle one chief science objective of gpm is to further extend capabilities in monitoring and predicting tcs and other extreme weather events https gpm nasa gov missions gpm the gpm based multi satellite precipitation retrieval offers a powerful means for quantitatively monitoring the tc induced rainfall at regional scales some recent studies showed that the latest gpm based near real time precipitation estimates gnpes generally perform better than those trmm based estimates in measuring tc induced rainfall fang et al 2019 gebregiorgis et al 2018 liu 2016 wang et al 2017a moreover the post real time gauge adjusted gpm precipitation products e g imerg final and gsmap gauge are normally superior to the near real time satellite only ones e g imerg early and gsmap nrt at daily or longer time scales huang et al 2019 zhang et al 2019 yu et al 2021 in fact the performance of gpm estimates of heavy precipitation has significant variance based on the geography of the region gnpes that without gauges calibration often perform better at the coastal plain than at high altitude which shows dependence on terrain zhou et al 2020 fang et al 2019 for the tibetan plateau specifically gnpes can effectively identify extreme precipitation events and their spatial distribution but underestimate the extreme precipitation amount lei et al 2021 lu and yong 2018 tang et al 2018 however few studies are found to assess at time scales finer than 1 day and it is found that for shorter than 6 hourly temporal resolutions the bias correction technique seems unable to bring improvements especially for extremely heavy rainfall events mastrantonas et al 2019 therefore as the first step it is essential to comprehensively investigate the potentials of gnpes in monitoring the torrential rains induced by tcs with a short duration nevertheless literature surveys suggest relevant studies are still lacking in addition the dual frequency precipitation radar dpr onboard the gpm core observatory satellite can offer three dimensional information of rainfall structure with higher precision wu et al 2021 have compared the radar data from dpr and ground s band radar to further understand the precipitation microphysics of the landing lekima however they did not directly display the dpr precipitation estimates in this study dpr precipitation estimates are used to reveal the vertical precipitation in the storm center of landed typhoon for the satellite quantitative precipitation estimation and hydrology community it is an interesting but challenging work to detect the inner structure of tc induced rainfall by some new technological means such as dpr which will provide the impetus for more research and development in this study six latest gnpes were utilized to explore the characteristics of spatiotemporal distribution and the inner structure of torrential rains induced by typhoon lekima at the coastal regions of eastern china the selected multi satellite precipitation products were statistically investigated at the hourly 0 1 0 1 latitude longitude gridded scale in detail the objective of this study is to evaluate the data quality of currently mainstream near real time gpm retrievals and reveal the spatiotemporal pattern of lekima induced rainfall specifically efforts are mainly focused on 1 what is the error characteristic of these six near real time gpm products in detecting typhoon induced rainfall and how much do they differ 2 can the rain total of landed typhoon be worked out by merging these gnpes 3 whether we can clearly see the vertical precipitation profile for storm center areas via the active radar signals from the newest dpr 4 what implications do results concluded from this study have on future gpm development 2 study area datasets and methodology 2 1 study area the rain belt induced by typhoon lekima with broad coverage of approximately 2 68 106 km2 swept along the coastal regions of eastern china from south to north thus we selected a rectangular domain at the longitude of 105 e 150 e and latitude of 27 n 54 n as our study area see fig 2 which can give a full view of the typhoon rain belt covering both land and ocean besides the 250 m resolution elevation datasets from shuttle radar topography mission are used to show the land topography in this area jarvis et al 2008 data source https srtm csi cgiar org wp content uploads files 250m here our analyses mainly focused on coastlands with dense populations and developed economy including the lower yangtze plain the north china plain and the northeast china plain which are suffered from severe torrential rains during the period of typhoon lekima what is worth mentioning these areas are well equipped with extraordinarily dense observation networks of rain gauges operated by the china meteorological administration that can provide reliable ground verification for the satellite precipitation estimates tang et al 2020 2 2 datasets 2 2 1 satellite precipitation estimates in this study six latest gnpes i e imerg early imerg late gsmap now gsmap nrt gsmap mvk and cmorph rt and the newest gpm dpr data were employed for detecting the torrential rains induced by typhoon lekima these satellite based precipitation datasets are summarized in table 1 in practice there are some other available near real time mainstream precipitation datasets e g tmpa 3b42rt and persiann ccs that seem suitable to be considered however as a trmm based representative product tmpa 3b42rt had completed the transition to gpm based imerg suite by the end of 2019 https gpm nasa gov media 292 while persiann ccs was excluded here because of its relatively poor performance in monitoring the heavy rainfall yong et al 2016 in addition those gauge adjusted satellite datasets e g imerg final and gpcp and assimilation based reanalysis products e g era interim and jra 55 were not included as well since our study mainly focused on investigating the monitoring capacity of the purely satellite derived precipitation estimates with low latency for tc induced rainfall the two imerg products imerg early and imerg late used in this study are provided by nasa as part of the gpm mission the imerg series have excellent spatiotemporal resolutions 30 min 0 1 0 1 with quasi global coverage of 90 n 90 s except for those snowy icy covered surfaces outside the latitude band 60 n 60 s peng et al 2020 huffman et al 2019 to strive for better data quality the imerg system intends to intercalibrate merge and interpolate data from as many source inputs as it can obtain including dpr data passive microwave pmw estimates microwave calibrated ir estimates and potentially other precipitation estimators huffman et al 2019 with regards to the algorithm imerg successfully integrates the merits of three trmm based mainstream satellite precipitation systems namely tmpa huffman et al 2007 cmorph joyce et al 2004 and the persiann hong et al 2004 hsu et al 1997 the imerg system produces two types of near real time precipitation products among which imerg early can give faster estimates within a relatively short time approximately 4 h while imerg late can offer better estimates after more satellite data have arrived about 14 h the main difference between imerg early and imerg late is that the former only relies on a forward propagation to extrapolate the pwm retrievals while the latter has both forward and backward propagation allowing interpolation https gpm nasa gov data directory thus imerg late can achieve the transmissions of lagging data that were not available for imerg early in its additional latency of about 10 h huffman et al 2019 in this study we adopted the latest released version 6 of imerg the three gsmap products gsmap now gsmap nrt and gsmap mvk are developed by the precipitation measuring mission science team of jaxa the gsmap group aims to develop novel dpr compatible microwave radiometer precipitation retrieval algorithms and generate a quasi global precipitation dataset with high precision kubota et al 2020 the gsmap data suite comes at a 1 h temporal resolution and a grid of 0 1 0 1 covering the globe 60 s 60 n the gsmap system combines precipitation retrievals from gpm and other polar satellites and interpolates them with cloud moving vector derived from ir images of geostationary satellites kubota et al 2007 ushio et al 2009 it is worth noting that gsmap now is the quasi global satellite precipitation estimate with the fastest accessible at present it employed almost all the passive microwave observations that are available within a half hour after observation and applied a half hour extrapolation of rainfall map toward future direction by using cloud moving vector from the geostationary satellite this allows data producers to estimate real time hourly rainfall maps at every half hour besides the gsmap system also generated other two near real time precipitation estimates gsmap nrt and gsmap mvk among them gsmap nrt uses relatively fewer pmw inputs available within 3 h and a forward only cloud advection technique while gsmap mvk merges more accessible satellite data with both forward and backward propagation schemes hence these two products seem to be corresponding to imerg early and imerg late mentioned above respectively the latest version 6 of gsmap now and version 7 of gsmap nrt and gsmap mvk are used in our analyses the real time cpc morphing technique cmorph rt is produced by the climate prediction center cpc of the american national oceanic and atmospheric administration noaa the cmorph system propagates the pmw input data using the motion vector matrix calculated from continuous two ir images joyce and xie 2011 usually ir data will not be incorporated into the final estimates unless the gap between the two pmw observations is longer than 90 min because the ir based estimates normally outperform that of pmw under longer propagation periods xie et al 2017 in practice both cmorph and gsmap adopt similar morphing algorithms to derive cloud motion vectors nevertheless gsmap employs a new kalman filter approach to assimilate and refine the ir based rain rates while cmorph only uses ir data to propagate mw derived precipitation features in most circumstances the newest version 0 x of cmroph rt was used in this study 2 2 2 gpm based dpr data the dual frequency precipitation radar dpr of gpm was jointly developed by jaxa and japan national institute of communication technology nict it is composed of two radars ku band precipitation radar at 13 6 ghz and ka band radar at 35 5 ghz which provide three scanning modes including normal scan ns ku band match scan ms ka band and high sensitive scan hs ka band on each scanning orbit hou et al 2014 relative to the original trmm based precipitation radar pr dpr is expected to further advance the precipitation measuring precision from space since it increases the sensitivity of precipitation detection decreases the retrieval uncertainty due to the raindrop size distribution dsd variation enlarges the scanning coverage 65 n 65 s and generates better estimates of the phase transition height skofronick jackson et al 2017 wilson et al 2011 currently the dpr algorithm has been upgraded in the newest verison 6 in that all beam directions of kupr and kapr were adjusted for better matching with the nominal footprint locations iguchi et al 2018 this might make further improvements for heavy rain events particularly the latest version 6 of level 2 dpr provides high resolution three dimensional rain echoes information which was applied to expose and analyze the vertical precipitation characteristics of typhoon storms in our study 2 2 3 ground references the gridded hourly merged precipitation analysis mpa dataset version 1 0 developed by the national meteorological information center of the china meteorological administration is used as the reference data which combines gauge observations from over 30 000 automatic weather stations with cmorph product yu et al 2015 the probability density function pdf matching and optimal interpolation oi method are employed for generating the merged mpa precipitation dataset at an hourly 0 1 0 1 latitude longitude resolution shen et al 2013 indicate that the merged mpa product generally outperforms other operational precipitation products over mainland china especially for the gridded regions containing automatic weather stations hence then we extracted those grid cells with at least two gauges in our evaluation for ensuring the reliability of validation results and these extracted mpa grids are used as the ground reference for scatterplots and statistical metrics additionally the hourly precipitation observations of 51 rain gauges in dongying city were provided by the meteorological bureau of shandong province the ground precipitation of dongying city during the lekima s period from august 10 to august 13 is averaged from these gauge data for special and higher precision reference within the extreme rainstorm central area 2 3 methodology 2 3 1 statistical metrics to quantitatively compare and validate the data accuracy of six gnpes against ground references we use several representative statistical metrics in our evaluation including pearson correlation coefficient cc root mean square error rmse mean error me relative bias bias mean absolute error mae absolute bias abias and contingency table based detection of rainy events i e probability of detection pod false alarm ratio far and critical success index csi the calculation formulae of these statistical metrics and their corresponding perfect values are summarized in table 2 considering that me and bias can only scale the average difference between remotely sensed estimates and observations we chose mae and abias to quantify the absolute error magnitude because positive and negative differences may cancel each other to some degree in the realistic assessment additionally pod measures the likelihood of satellite retrievals to detect a rainy event when it occurs in fact while far indicates the likelihood that a rainy event does not occur when satellite estimates rain the csi metric demonstrates the comprehensive capability of satellite estimates to detect precipitation occurrence more detailed explanations for the nine statistical metrics used can be found in yong et al 2010 and tang et al 2020 2 3 2 data preprocessing as can be seen from table 1 the data format and spatiotemporal resolution of eight different precipitation datasets are non uniform therefore the first step in data processing is to unify the resolution of them to match that of the ground reference except for the gsmap suite other three satellite precipitation datasets i e imerg early imerg late and cmorph rt were aggregated and or resampled to the hourly 0 1 0 1 resolution in this study specifically to precisely resample the cmorph rt estimates the bilinear interpolation algorithm was applied to compute the precipitation value for each targeted 0 1 0 1 grid cell by interpolating those values of its adjacent four 8 km 8 km grids as for the ground reference we extracted those mpa grids with at least two gauges to be specific an average of 27 6 grids were extracted the extraction was done hourly thus there is still an abundant amount of grids 38920 37187 40231 41998 43817 and 34 754 for gsmap now gsmap nrt gsmap mkv imerg early imerg late and cmorph rt respectively to investigate the rmse and bias distribution of these six gnpes at different precipitation intensities extracted mpa grids are binned into different categories according to their precipitation values as shown in fig 6 the x value of the edge points of these bins on the x axis is a power of 2 and the exponent of them increases as a geometric series with a common ratio of 0 25 i e 2 2 875 2 2 625 2 2 850 25 875 to make all bins on the logarithmic coordinate axis have an equivalent interval in the gpm data system the dpr precipitation dataset used in this study is one of the level 2 single orbit precipitation products which is derived from the gpm level 1 radar products it has not been spatiotemporally resampled as an end user level precipitation product thus extra treatments are needed before analyzing and data visualization horizontally dpr ns data provides a 245 km swath that consists of 49 beams each beam corresponds to a footprint which size is about 5 km in diameter above each footprint there are numbers 176 for 2a dpr ns of range bins with each height of 125 m therefore three dimensional precipitation data of 2a dpr is approximate 5 km 5 km 125 m in resolution however one should note that each scan beam from the footprint on the ellipsoid to dpr in space is not absolutely perpendicular to the ellipsoid of the earth see fig 3 hence there are deformations of the original data array in both horizontal and vertical directions in this study we interpolated the original dpr data into a three dimensional array with each grid of 5 km 5 km in horizontal and 5 km 125 m in vertical relative to the local ellipsoid surface before that positions of original range bins in a three dimensional rectangular coordinate system are needed therefore we first calculated the height and the horizontal offset for each range bin to explain it better fig 3 shows the relationships of the parameters for dpr data preprocessing the height and the horizontal offset relative to the ellipsoid surface of each range bin can be computed by the following equations 1 heigh t n binellipsoid n b i n s i z e e o f f s e t c o s zangle 2 hoffse t n binellipsoid n b i n s i z e e o f f s e t s i n zangle where height n is the vertical distance from the center of range bin n to the ellipsoid hoffset n is the horizontal offset distance between centers of range bin and that of the footprint binellipsoid is a constant range bin number 176 of the one that crosses the surface of the ellipsoid binsize is the height 125 m of each range bin eoffset is the distance from the center of the binellipsoid range bin to the surface of the ellipsoid along the beam direction and zangle is the zenith angle of each dpr beam with the height and the offset the precipitation value for each target array bin was spatially interpolated from that of the adjacent range bins with inverse distance weighted algorithms 3 results and discussion 3 1 comparison and validation of satellite precipitation estimates fig 4 shows the spatial distributions of accumulated precipitation amount derived from six gnpes on the 0 1 0 1 resolution grid during the period of typhoon lekima from august 10 to august 13 generally these six precipitation products all display a similar spatial pattern at a large scale in that the typhoon induced rain belt extended along the east coast of china from south to north besides one can see that the storm center firstly moved toward the northwest after typhoon landing and then turned to the northeast direction the moving track exhibits a typical semi arc outline which is closely related to the motion characteristic of tcs in the northern hemisphere with respect to physical mechanisms such phenomenon might be attributed to the combined effects of both the impetus of horizontal coriolis force and the resistance of subtropical high kim and seo 2016 liang et al 2017 wang et al 2017a b as for the areal distribution of heavy rains especially for surrounding the bohai gulf see the highlight spots in each plot of fig 4 the left four precipitation estimates i e gsmap nrt gsmap mvk imerg early and imerg late have more similar spatial patterns this consistency may be associated with partial overlaps of the imerg and gsmap systems in data inputs and retrieval algorithms specifically they share the same infrared ir data and a part of passive microwave pmw data furthermore both of them use the atmospheric moving vector from two successive ir images to propagate the rainy area from microwave radiometry and then employed the kalman filter model to update the precipitation rate for accurately representing the temporal variation of precipitation systems ushio et al 2009 zhang et al 2019 additionally it is clear that gsmap now systematically underestimated heavy rainfall fig 4c while an opposite overestimation occurred for cmorph rt fig 4f this arises because gsmap now only used limited satellite inputs available within a half hour particularly lacking for many data from pmw sensors on the contrary cmoprh rt mainly depends on the pmw based data in its retrieval algorithm which substantially differs from those estimates relying on merging ir and pmw observations to quantitatively understand the retrieval accuracy of these gnpes at the storm center an average of the rainfall observations from 51 local gauges which are maintained by the meteorological bureau of shandong province is computed in the dongying representative grid located between 118 e 119 e and 37 n 38 n results indicate the total rainfall amount of dongying city during the typhoon period from local time august 10 to august 13 the same below reached 342 mm among the six precipitation datasets imerg late has the closest estimation of 274 mm while gsmap now shows the lowest value of 102 mm fig 4c and e with regards to the other four products i e gsmap nrt gsmap mvk imerg early and cmorph rt the corresponding values are 234 mm 238 mm 202 mm and 241 mm respectively fig 4a b d and f specifically the corresponding result from mpa no extraction here is 276 mm which falls between the results from the gnpes and local gauges this can be expected since mpa is a merged product of automatic gauges and satellite retrievals having seen that all datasets underestimate the storm that occurred at dongying city we suggest that the current satellite precipitation estimates might have the intrinsic feature of overall underestimation at higher rain rates especially for typhoon rainfall yong et al 2016 which is probably associated with the weak linkage between the cloud top temperature and the convective storms hamada et al 2014 tian et al 2009 moreover we found that the improvement from imerg early to imerg late seems to be better than that from gsmap nrt to gsmap mvk when comparing both spatial patterns and extreme rainfall despite that gsmap mvk has longer latency 3 days for precipitation estimation relative to imerg late 14 h this implies that the algorithm of backward propagation in imerg late run is superior to that used in the gsmap system to further compare and validate the retrieval accuracy of these gnpes we adopted the widely used gridded gauge product of merged precipitation analysis mpa 0 1 0 1 1 h as the ground reference to perform the evaluation during the typhoon period over mainland china in practice we only selected those grid boxes that contained at least two gauges in our calculations so as to ensure the credibility of assessment results scatterplots of hourly comparison of six satellite precipitation estimates versus the ground reference are shown in fig 5 and detailed statistical results are listed in table 3 the hourly scatterplots indicate that both gsmap and imerg product suites generally underestimate the rainfall while cmorph rt has an opposite overestimation as expected the worst performance is found in the gsmap now estimates with the lowest cc and largest negative errors the severe underestimation of gsmap now can be attributed to the deficiency of various pmw inputs while the overestimation of cmorph might be associated with its primary dependency on pmw echoes sungmin et al 2017 this is consistent with the conclusions derived from fig 4 two types of near real time estimates of both gsmap nrt and mvk and imerg early and late demonstrate similar distributions of scattered points and those estimates with longer latency are apparently superior to their corresponding prophase products respectively additionally we note that cmorph rt generally has a better convergence feature and can effectively control the outliers especially at medium low rain rates relative to other estimates comparing fig 5f and other plots but it does not exhibit the best performance as expected contrarily it has the largest absolute errors e g mae abias and rmse and the lowest probability of detection in six evaluated gnpes in terms of the nine statistical metrics used in our evaluation no satellite precipitation product can comprehensively outperform the others all the gnpes have satisfactory and similar pod and there is still room for further improvements on far that is associated with csi however despite showing high pod gsmap now and imerg early still have significant negative bias with regard to fig 6 b we suppose the universal underestimates of them at high precipitation intensity 4 mm h 1 make a major impact which is unfavorable in tc induced precipitation events to better satisfy the needs of heavy rainfall detection the current gpm based satellite precipitation estimates have enlarged their monitoring range of the rainfall intensity hou et al 2014 based on the sufficient rainfall pairs of satellite estimates versus ground observations we further investigated the distribution characteristics of error and bias of six evaluated satellite products at different rain rates fig 6 generally speaking there is a clear power function relationship between rmse and logarithm of rain rates suggesting that the errors of satellite retrievals have a stronger dependency on the rainfall intensity fig 6a such systematic error features closely related to the rainfall intensity should therefore be noticed for the future development of gpm algorithms in addition fig 6b shows that all the six gnpes tend to overestimate rainfall at lower rain rates while underestimating at high ones among these gnpes cmorph rt evidently exhibits a relative overestimation against other satellite estimates at the total range of rain rates although such relative overestimation can partly alleviate the negative biases of satellite retrievals at higher rain rates 8 mm h 1 it further aggravates the positive biases at lower ones 2 mm h 1 as a result it is likely that the pmw based algorithm in cmorph rt cannot substantially improve the retrieval accuracy of satellite precipitation as for the other five products imerg late looks better at the medium high rain rates and the others have similar performance 3 2 process analysis of typhoon rainfall to look further into the variation process of lekima induced storms we investigated the spatiotemporal distributions of daily rainfall in detail during the typhoon period from august 10 to 13 the spatial distributions of daily cumulative rainfall amount averaged from all satellite products are plotted on the left column of fig 7 while the time series of the hourly rainfall intensity of six gnpes and their averages for each day are manifested on the right column to better illustrate the temporal distributions of heavy rainfall we only calculated the hourly precipitation amounts of multiple precipitation datasets over those regions with storm events 50 mm d 1 in regard to the space precipitation distributions on the left half of fig 7 the precipitation of typhoon lekima mainly occurred in the first two days august 10 and august 11 of the study period and manifest the largest coverage on august 11 spatially first day precipitation mainly distributed around the landing spot while the precipitation on the second day was concentrated in the bohai gulf the rain belt had an accelerated stretching with the northeastward turn of lekima suggesting a suitable moisture transport condition which enables this long distance rain belt zhou and wu 2019 interestingly not only lekima took advantage of this moisture channel typhoon krosa appear on the bottom of fig 7g may have used it as well which gives reason to the slight rising tendency on august 13 fig 7h the precipitation time series in fig 7 indicate continuously stable torrential rainfall from 0 00 a m august 10 to 14 00 p m august 12 local time then the tc induced storm started to fade and light rainfall continuously remained for several days based on these time series one can notice a precipitation window in the morning from 5 00 a m to 10 00 a m local time in which all satellite precipitation products tend to give higher estimation and correspondingly exhibit apparent similar storm centers in space during the entire study period the total amount of precipitation 93 2 billion m3 over mainland china is approximately equal to 2 5 times the maximum capacity of the three gorges dam reflecting a strong impact brought by typhoon lekima generally both gsmap now and imerg early have larger amplitudes of fluctuation with significant instability throughout the study period while gsmap nrt gsmap mvk and imerg late show a relatively stable performance as aforementioned above cmorph rt displays a distinct overestimation throughout the whole raining process fig 8 compares the time series of typhoon precipitation amounts computed by these six gnpes over mainland china and dongying city respectively in terms of the entire mainland china it is clear that a precipitation peak occurred on august 11 fig 8a which corresponds to the peak value of the precipitation series at dongying city fig 8b but the extreme heavy precipitation at dongying city showed a faster tendency during the period of rising and declining in this case imerg late imerg early gsmap mvk and gsmap nrt turn out to have a similar performance with strong instability among all six gnpes cmorph rt seems more smoothly and has the best consistency with the averaged value while gsmap now completely missed the peak value with relatively the worst performance besides we note that the scanning track of gpm core satellite passed across the dongying city at about 12 58 17 p m local time on august 10 fig 8a at that moment a peak value was captured by imerg late see fig 8b considering the common underestimation of satellite retrievals in extreme precipitation estimates and the high data accuracy of dpr and gmi we concluded that the instruments aboard on gpm core satellite have effectively improved the detection ability of extreme events hou et al 2014 skofronick jackson et al 2016 thus the imerg late combining both dpr and gmi data may have relatively better potentials in monitoring the extreme rainfall events 3 3 vertical detection of typhoon rainfall to clearly see the inner structure of such extreme rainfall events we further analyzed the vertical precipitation information provided by gpm dpr with the gpm data package named as 2a gpm dpr v8 fig 9 a shows the scanning orbit including three scan types i e ns ms and hs of dual frequency precipitation radar aboard the gpm core observatory from 12 56 53 p m to 13 00 23p m local time on august 11 2019 when typhoon lekima was passing the territory of shandong province due to the ongoing algorithm update the type of ms see yellow circles in the left insert of fig 9a lacks vertical data in the current level 2 dataset of gpm dpr while missing values are stored in the output fields of hs data red circles therefore here we adopted the normal scan ns blue circles of ku band with a swath width of 245 km to interpret the three dimensional precipitation information of typhoon rainfall the distributions of vertical precipitation rates detected by kupr from the ground surface to rain top and horizontal ones averaged from 2 km to 4 km height are displayed in fig 9b and c respectively from fig 9b one can clearly see the vertical profile of typhoon rainfall associated with different precipitation intensities combined with the horizontal distribution in fig 9c we can quantitatively identify the three dimensional precipitation structure of storm centers located within the scanning orbit of gpm dpr comparing the two profiles the main plot and the subplot in fig 9c that are shown in perpendicular directions it is found that the horizontal storm centers agree well with the vertical distribution of high rain rates thus the columnar structure but with a relatively thin top and thick bottom of typhoon storms can be clearly exposed by gpm dpr in three dimensions as can be seen from fig 9c there are three main storm zones located in the western part of shandong province during the visiting time of gpm dpr among them the middle one with the largest rain rates appears around the maintain tai where the complex mountainous topography seems to further strengthen the local storm intensity it implies that the orographic effect may be closely associated with the occurrence of the storm center in summary our analyses indicate that gpm dpr can accurately capture the three dimensional structure of typhoon rainfall despite its longer revisiting period and narrower swath width in the design framework of gpm dpr is taken as an important calibration standard for other pmw and ir sensors on the constellation satellites tapiador et al 2012 hou et al 2014 yong et al 2015 but in practice the other two scan types of dpr i e ms and hs have not been sufficiently utilized in the gpm retrieval system since it takes time to develop new algorithms applicable to the full swath and to adjust the necessary parameters to ensure the quality of the precipitation products as documented in iguchi et al 2018 in particular no data from the high sensitive scan of ka band is used in the current operational level 2 and 3 products of gpm looking into the future development of gpm we suggest that all the three scan types of dpr should be combined together to generate a more accurate calibration standard for the gpm constellation so as to substantially improve the retrieval quality of gnpes especially for extreme rainfall events 4 conclusion in this study we investigate the potentials and limits of six gpm based near real time precipitation estimates in monitoring the super typhoon rainfall and demonstrate the spatiotemporal characteristics of the extreme precipitation induced by typhoon lekima the six selected gnpes were comprehensively intercompared and evaluated against ground observations and particularly the three dimensional precipitation structure for typhoon storms was systematically detected by the newest dpr of gpm the main conclusions are summarized as follows 1 spatially the long extended rain belt of typhoon lekima affects a large area along the chinese eastern coast of approximately 2 68 106 km2 it created two concentrated rainstorm centers distributed around the landing spot and shandong province respectively the total amount of precipitation reached approximately 93 2 billion m3 over the entire study area in terms of precipitation time series intense precipitation remains continuously and peak in the morning on august 11 before it began to fade after the noon of august 12 specifically we found an interesting precipitation window from about 5 00 a m to 10 00 a m local time in which all satellite precipitation products tended to give higher rainfall estimates this implies that other typhoon induced storms are easier to happen during this period under similar extreme weather conditions which could provide some important reference information for local mountain torrents warnings 2 during the study period gsmap now and cmorph rt show respectively underestimation and overestimation compared with the others while gsmap nrt gsmap mvk and imerg late give relatively consistent estimates especially for high intensity precipitation among six gnpes those estimates with longer latency generally perform better in heavy rain monitoring which partly benefit from more abundant inputs from pmw sensors however six gnpes still show instability particularly during the monitoring of intense precipitation of which there is still room for further improvement 3 in statistical evaluation despite all six gnpes perform well in pods 92 relatively low ccs between six gnpes and ground references are still unsatisfactory this indicates that near real time tc induced precipitation estimation at fine spatiotemporal resolution still faces considerable uncertainty aside from the inherent random error we notice a series of systematic errors related to the precipitation intensities six gnpes tend to show underestimation at higher rain rates 4 mm h 1 and overestimation at lower ones 2 mm h 1 this results in a common negative bias except for cmorph rt of which the algorithm mainly employs pmw data despite that however we cannot assert which product suite is distinctly superior to the others based on the indices they all own specific skills on satellite based precipitation retrievals we suggest that the aforementioned systematic error may be a potential pathway to achieve more accuracy in future works 4 rely on the advanced gpm dpr we demonstrate a three dimensional view inside the lekima induced rain storms instead of heavy rainfall over a broad area the instantaneous field of view shows some concentrated intense precipitation regions there several adjacent but independent rain columns are proved to exist in which the precipitation intensity reached 121 mm h 1 hence these rain columns are probably the key for the monitoring of extremely heavy precipitation at a fine spatial scale which should be taken into consideration henceforward we believe this information will enrich the perception of regional rainstorms credit authorship contribution statement weiqing qi conceptualization methodology software formal analysis bin yong writing review editing project administration funding acquisition jonathan j gourley declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we appreciate the extensive efforts from the developers of the satellite and ground precipitation products that make these datasets available the study is funded by the national natural science foundation of china 92047301 and 51979073 
4023,three years of observations of groundwater elevations ocean tides surge and waves and rainfall are used to study coastal groundwater driven flooding along the ocean side of a barrier island increases in surge and wave driven water levels setup during 26 ocean storms with little rainfall including the passage of 3 hurricanes caused o 1 m increases in groundwater heads under the dunes on the ocean side of the island nearly double previously reported magnitudes the inland propagation of the resulting pulses in groundwater levels is consistent with an analytical model without recharge based on shallow aquifer theory nash sutcliffe model efficiencies of 0 7 maximum water table level estimates within 0 1 m of observations infiltration of precipitation results in approximately a threefold increase in the groundwater level relative to the amount of rainfall the analytical model with recharge driven with estimated ocean shoreline water levels based on the 36 hr averaged offshore tide surge and wave height and measured precipitation predicts the maximum water table height within 0 15 m of that observed across the barrier island during hurricane matthew which was the only wave event during the 3 yr data set with more than 0 1 m rainfall citizen science reports from a smartphone app iflood are used to evaluate the regional application of the model twenty five ocean side reports associated with 7 ocean storms 6 of which had minimal rainfall between sept 2019 and feb 2020 showed flooding on natural permeable land surfaces along 70 km of the northern outer banks barrier island from corolla to rodanthe nc the analytical model with recharge predicts flooding that is consistent with the timing and location for 19 of the 25 reports applying the model regionally suggests that more than 10 of the land area on the ocean side of the northern outer banks would be inundated by coastal groundwater even in the absence of rainfall for an ocean storm that generates a 2 25 m increase in the shoreline water level keywords coastal hydrogeology flooding land sea connection storms compound events citizen science 1 introduction nearly 1 5 million people inhabit barrier islands along the u s atlantic and gulf coasts with a population density approximately three times greater than that of coastal states zhang and leatherman 2011 which is increasing along with the associated infrastructure elko et al 2015 the low elevations close to mean sea level msl and high density of infrastructure make coastal counties susceptible to devastating environmental and economic impacts from flooding in unconfined coastal aquifers the average water table usually is higher than msl and lies within a few meters of the land surface in low relief regions glover 1959 rotzoll and fletcher 2013 befus et al 2020 although groundwater can cause flooding if the water table exceeds the land surface groundwater processes typically are neglected in flood hazard mapping and management policies morris et al 2007 rotzoll and fletcher 2013 abboud et al 2018 as of 2019 the u s national flood insurance program was 20 billion dollars in debt horn and webel 2019 sea level rise and the increasing strength and duration of large wave and surge events ocean storms are predicted to double the frequency of flooding and to expand the spatial extent of flood impacts woodruff et al 2013 moftakhari et al 2015 vitousek et al 2017 patricola and wehner 2018 befus et al 2020 knutson et al 2020 sweet et al 2020 compound flooding driven by multiple hazards such as rain and storm surge can magnify the duration and extent of flood impacts wahl et al 2015 bevacqua et al 2019 developing flood predictions that integrate oceanographic meteorological and hydrogeological processes has been identified as a research need for managing storm hazards and impacts elko et al 2019 increasing ocean storms that cause groundwater driven flooding may require new management strategies because traditional ocean driven flood mitigation structures such as jetties and sea walls are ineffectual against increases in the water table however although several studies have analyzed impacts of sea level rise on regional groundwater inundation and flooding rotzoll and fletcher 2013 befus et al 2020 regional effects of transient ocean storms are less well understood prior studies of wave and surge driven groundwater responses have focused on moderate wave conditions li et al 2004 trglavcnik et al 2018 rotzoll and el kadi 2008 during ocean storm events the elevation of the coastal water table fluctuates in response to changes in the wave tide and surge driven changes in the ocean water level nielsen 1990 cartwright et al 2004 anderson and lauer 2008 abarca et al 2013 the resulting ocean storm pulse increases the elevation of the coastal water table and this bulge of high groundwater continues to propagate inland after the ocean water levels have subsided li et al 2004 rotzoll and el kadi 2008 ocean storm pulses have larger amplitudes and longer fluctuation periods than water table oscillations driven by wind waves or tides and thus can penetrate farther into the aquifer nielsen 1990 li et al 2004 as the ocean storm signal propagates inland the amplitude of the fluctuation attenuates at a rate controlled by the hydrogeologic properties and structural composition of the aquifer li et al 2004 rotzoll and el kadi 2008 an analytical solution pulse model assuming a vertical beach face and a homogeneous isotropic uniform depth aquifer reproduced the behavior of a surge and wave induced groundwater fluctuation in a sandy aquifer in a coastal barrier island cartwright et al 2004 li et al 2004 however the analytical model was developed and calibrated for a single event and thus the model skill for multiple events and its applicability to other sites is uncertain for example leakage to the surface aquifer from a confined aquifer can result in non uniform propagation of the storm pulse with smaller than predicted amplitude relative to the shoreline fluctuation trglavcnik et al 2018 when rainfall is coincident with emergent groundwater from the land surface the duration of the flood tends to last longer than runoff or overwash driven flooding alone macdonald et al 2008 befus et al 2020 the water table rises in response to infiltration from precipitation by an amount inversely dependent on the effective porosity of the aquifer meinzer 1923 crosbie et al 2005 cobby et al 2009 zhang et al 2017 smail et al 2019 antecedent conditions that result in an elevated water table reduce the aquifer infiltration capacity for subsequent events rotzoll and fletcher 2013 here three years of continuous observations section 2 including 26 ocean storms with minimal rainfall are used to evaluate the analytical storm pulse model section 3 for the groundwater level in an unconfined surface aquifer driven by changes in the shoreline water level the observed groundwater increases under the dune following large offshore wave events without precipitation significant wave height hs 5 m are o 1 m nearly double the amplitude measured in prior studies li et al 2004 rotzoll and el kadi 2008 trglavcnik et al 2018 and similar in magnitude to the sea level rise slr driven groundwater increase predicted over the next hundred years 0 4 1 3 m of slr predicted by 2100 off the coast of nc sweet et al 2017 the analytical model is shown to predict the maximum ocean storm driven groundwater levels within about 0 1 m and the timing of maximum groundwater levels within about 1 day using an estimated effective porosity an analytical groundwater flooding model including the storm pulse and recharge is evaluated with measurements during the passage of hurricane matthew which had wave heights 5 5 m surge 1 0 m and precipitation 0 2 m flood reports submitted to iflood section 4 1 a citizen science phone application are used to conduct a hindcast assessment of the analytical groundwater flooding model along a 70 km region of the outer banks between corolla and rodanthe nc section 4 2 the analytical flooding model is used to predict regions of groundwater flood vulnerability on the ocean side of the outer banks caused by an increase in the shoreline water level consistent with a hurricane or large nor easter section 4 3 offshore wave heights and precipitation amounts that drive the analytical model are among the most ubiquitous measurements collected in global coastal observational arrays consequently the framework presented here could be used to study regional groundwater driven flooding in other low lying coastal environments where the aquifer properties are roughly uniform 2 field measurements although this study is conducted on the north carolina outer banks the results are applicable to many other coastal areas sandy coasts account for about 33 and sandy barrier islands account for 7 of global coastlines stutz and pilkey 2011 vousdoukas et al 2020 furthermore large sections of the u s atlantic and gulf coasts have coastal plain geology similar to the nc outer banks usgs 2017 for which the regional aquifer structure often can be approximated as homogeneous despite smaller scale heterogeneity similar to prior studies examining groundwater inundation driven by sea level rise rotzoll and fletcher 2013 befus et al 2020 2 1 site description the north carolina outer banks is a 320 km long chain of barrier islands extending south from the virginia north carolina state line to bogue inlet the islands are up to 3 km wide and have ocean shoreline dunes from less than 1 to 12 m high elko et al 2002 the north carolina outer banks is part of the north carolina coastal plain aquifer system and the shallow geology is a 50 70 m thick quaternary sequence that fills the albemarle embayment winner and coble 1996 lautier 2009 the surficial aquifer typically is comprised of 70 sand winner and coble 1996 a network of paleo channels that were backfilled with younger pleistocene sediments also weaves through the quartenary sequence riggs et al 1995 lazarus and murray 2011 the paleo channels contain muddy estuarine sediment sand and fluvial gravel lazarus and murray 2011 branches of the paleo roanoke albemarle fluvial system have been recorded at the shoreface in duck kitty hawk kill devil hills and nags head riggs et al 1995 boss et al 2002 lazarus and murray 2011 the surficial aquifer is underlain by a series of discontinuous clay and silt beds that comprise the yorktown confining unit which is estimated to occur 15 20 m below navd88 approximately mean sea level winner and coble 1996 mallinson et al 2010 similar to many barrier island areas land use is primarily single family residential with houses on stilts 65 total land with lot coverage 33 or shared open use common vacant or public 24 total land area with primarily pervious surfaces in addition topographic relief is low especially in developed areas and surface runoff is expected to be minimal in september 2014 19 groundwater wells were installed at 8 locations along a 550 m long transect across the barrier island extending from the ocean dune to the sound at the u s army corps of engineers coastal hydraulics laboratory field research facility frf http www frf usace army mil in duck nc fig 1 the property is bordered on the west by currituck sound and on the east by the atlantic ocean on the ocean side of the island the beach is backed by 7 m high vegetated dunes sediment samples collected during construction of the frf facility meisburger et al 1989 and during installation of the groundwater wells suggest that the surficial aquifer is composed of medium quartz sand mean diameter 0 25 mm and shell hash prior studies suggest the uppermost confining layer is roughly 15 to 30 m below navd88 meisburger et al 1989 manahan et al 1998 however a confining unit was not encountered during drilling with boreholes extending from 15 under the dune to 26 m near the sound below navd88 slug tests hvorslev 1951 bouwer and rice 1976 brown et al 1995 butler et al 1996 performed at 16 of the wells spanning the island suggest that the hydraulic conductivity is approximately k 13 0 4 4 m d consistent with an estimate of 14 9 m d obtained during drilling of a test water supply well about 2 miles south of the study site manahan et al 1998 based on these observations the aquifer is assumed to be approximately uniform across the island 2 2 observations the cross shore positions x positive toward the sound of the well locations are defined relative to the well closest to the dune face each well was composed of 0 05 m diameter pvc pipe with no 10 perforated screen at the bottom surrounded by gravel pack topped with a bentonite seal at the six mid island locations fig 1c 95 x 450 m wells extended to 9 to 10 m below navd88 with 8 to 9 m long screens near the ocean fig 1b red and black circles and sound fig 1b orange circle wells fig 1c extended to about 1 m below navd88 with 0 6 m long screens fig 1c conductivity temperature depth ctd sensors at about mid screen elevation in each well were sampled at 10 min intervals salinities were less than 1 psu except in the well closest to the ocean x0 following large ocean storms when saline ocean water penetrated under the dune fig 1c x0 water density was calculated from the measured salinity temperature and pressure fofonoff and millard 1983 measurements collected by slowly lowering a ctd within each well showed that density was approximately vertically uniform the sensors were vented to the atmosphere so that pressure measurements were not influenced by fluctuations in barometric pressure sensor elevations were estimated using differential gps measurements of the well cap and simultaneous water level measurements from a standard meter and pressure and water density measurements from the in situ sensors annual re estimates show 0 02 m drift water table elevations were estimated from the pressure measurements converted to head h as post et al 2007 equation 5 1 h p ρ f g z s where p pa is the measured pressure ρ f kg m3 is the density of freshwater g m s2 is the gravitational constant and zs m is the elevation of the sensor relative to navd88 assuming a reference level zr of 0 navd88 the largest deviations from 1 owing to density differences post et al 2007 equation 12 at x0 are less than 0 01 m ocean water levels were measured every 6 min with a noaa tide gauge id 8651371 in about 6 m depth at the end of the frf pier tides were semi diurnal with range 1 m and storm surge was up to 1 m significant wave heights hs 4 times the standard deviation of sea surface elevation fluctuations in the frequency range from 0 05 to 0 30 hz recorded every 30 min in 26 m water depth ndbc station 44100 ranged from near 0 to 6 m fig 2 a with an average of about 1 m breaking wave driven setup longuet higgins and stewart 1964 of the shoreline water levels is estimated to be 0 2 times the offshore significant wave height guza and thornton 1981 nielsen 1988 raubenheimer et al 2001 roughly consistent with observations from a lidar on the dune about 300 m north of the wells shoreline water levels are estimated as the sum of the ocean water level including tides and surge and the setup ocean storms are defined as events with combined 36 hr averaged de tided shoreline water level exceeding 0 65 m above navd88 twenty seven ocean storm events were observed during the 3 year data record including 4 hurricanes that passed offshore of duck nc joaquin oct 2015 cyan box fig 2 matthew oct 2016 magenta box fig 2 and jose and maria sept 2017 yellow and orange boxes fig 2 respectively precipitation fig 2b was recorded every 10 min using a set of 3 rain gauges data from the precipitation gauges is uncertain during extreme rainfall rates 0 03 m hr which only occurred once in the observation period during hurricane matthew oct 2016 with the exception of hurricane matthew there was 0 1 m rainfall during the ocean storms tidal effects were negligible in the sound but winds can drive rapid 1 2 m changes in the sound water level mulligan et al 2014 low sound water levels typically occur during the winter months caldwell 2001 and often are coincident with high ocean water levels driven by winter storms under calm conditions the ocean side groundwater heads increase landward fig 1d and fig 2c blue and green curves are higher than red and black curves e g may july 2015 and the water table is highest 160 m inland from the dune fig 1c d the average head gradient between the center of the island and the ocean well x0 is 0 0015 m m fig 1d however during storms surge setup and wave infiltration result in the groundwater head at the wells closest to the ocean exceeding the head levels at the inland wells fig 2c shaded grey areas and fig 3 the bulge of high groundwater attenuates as it propagates inland fig 3b solid curves the two storms that resulted in the highest groundwater levels at x0 were hurricane joaquin cyan box fig 2 and hurricane matthew magenta box fig 2 a nor easter preceded hurricane joaquin and caused sustained elevated offshore wave heights soon after the nor easter hurricane joaquin developed in the atlantic and generated a second series of large waves that reached maximum heights of 4 7 m in 26 m water depth on october 5 2015 head levels increased 1 6 1 4 1 2 0 9 m above pre storm levels during hurricane joaquin at x 0 25 90 and 160 m respectively fig 2c and 0 5 m at x 310 m not shown when the high water levels from hurricane joaquin propagated inland the water table came within approximately 1 m of the ground surface at x95 and x160 following hurricane joaquin the water table at x160 took approximately two weeks to return to within a standard deviation of the average level the time delays between the occurrences of maximum water levels at each well location indicate an inland propagation rate of the storm driven groundwater bulge of about 60 m day during hurricane matthew infiltration from heavy precipitation 0 2 m fema 2018 table 3 and increasing ocean water levels both contributed to the increase in the water table instead of a delayed response in the time of arrival of the maximum water level a near simultaneous 0 6 to 0 9 m increase in groundwater level occurred at all well locations fig 2 following the heavy precipitation 3 analytical model 3 1 groundwater pulse theory evaluation propagation of the storm driven groundwater pulse is simulated using an analytical solution referred to subsequently as the analytical model no recharge li et al 2004 for darcian groundwater flow assuming a gaussian shoreline fluctuation pulse and applying a linearization based on the assumption that the amplitude of the water table fluctuation is small relative to the depth of the aquifer see appendix here the propagation is driven equation a1 with the head fluctuations at the x0 well rather than with the shoreline fluctuations to avoid errors resulting from uncertainty in the cross shore position of the shoreline which changes with changing ocean water levels on the sloping beach with evolving beach topography during storms up to 4 m erosion during a single event with seasons the mean shoreline position can vary 10 s of meters as the beach accretes during the summer and erodes during the winter and with long term trends the dune eroded more than 10 m landward during the observation period the model is solved numerically using global adaptive quadrature with an absolute error tolerance of 1e 12 m and a time step of 0 01 days tests with smaller time steps were conducted to ensure the solution was robust errors from the numerical integration scheme do not contribute significantly to the model uncertainty 0 001 m the fits between the water table levels for the 26 observed storm pulses with minimal rainfall and a gaussian shape had correlations r2 0 9 although 5 storms were negatively skewed and 10 storms were positively skewed with 5 skewness magnitudes 0 3 data from the four wells closest to the ocean x0 x160 during the 26 storms with minimal rainfall are included in the evaluation of the pulse theory the best fit diffusivity for storm pulses is d 3500 m2 d which is within a factor 2 of the diffusivity based on the estimated hydrologic parameters hydraulic conductivity 10 k 30 m d specific yield sy 0 3 and the aquifer depth 15 z 30 m the analytical model without recharge reproduces the observed surge and wave driven changes in the water table well to very well based on the nash sutcliffe efficiency nse nash and sutcliffe 1970 coefficients table 1 the model agreement with the observations often is worse at x0 than at x30 or x95 owing to greater deviations from a gaussian fit compare solid with dashed curves in fig 3 which shows an example for a single storm differences between the observed and theoretical groundwater levels are larger after the storm peak table 1 nse are larger for the entire event than for just the rising portion and fig 3 at least partly because deviations from a gaussian are larger during the waning ocean storm the root mean square error rmse between the analytical and observed maximum water table which is used to estimate regional flood occurrences is 0 1 m at all locations for all storms and the estimated timing of the maximum water level is correct to within 0 5 days the inland amplitude decay and phase evolution of the ocean storm pulse fluctuations are used to examine the model data agreement further the non dimensional model equation a3 is solved numerically for 0 x 1 5 with 0 01 resolution analytical estimates fig 4 solid curves of the bulge properties α and δϕ as a function of inland distance x are obtained from the magnitude and time of the maximum of the non dimensional gaussian pulse at each cross shore position equation a3 observational estimates of the non dimensional amplitude attenuation phase lag and distance fig 4 symbols are estimated from equations a4 a7 with a aj tp t and bj determined from the best fits of the measured groundwater levels h to gaussian curves equation a2 the agreement between the model and observed non dimensional amplitude attenuation α and phase lag δϕ correlations r2 0 73 and 0 71 respectively is insensitive to cross shore distance fig 4 consistent with the assumption that the aquifer at duck is approximately homogeneous and isotropic li et al 2004 3 2 precipitation response the change in the water table from precipitation driven recharge scales with the effective porosity ne for sand porosity n is estimated to range from 0 36 to 0 43 and n 0 4 for grab samples collected in the intertidal zone at duck to estimate the value of the effective porosity the groundwater data on the sound side of the island x310 to x550 fig 1 where ocean driven groundwater fluctuations typically are negligible under low wave conditions are used to determine the water table response to precipitation events rainfall events separated by dry periods longer than 2 days between oct 2014 and oct 2016 with cumulative precipitation 0 02 m are included in the analysis the water table increase is approximately three times the amount of rainfall at all sites fig 5 for x 310 400 and 450 m corresponding to an effective porosity ne of about 0 33 roughly consistent with porosity estimates for sand the analytical model with recharge reproduces the maximum water table levels during hurricane matthew assuming 0 2 m rainfall within about 0 15 m and the time of maximum water table level within 0 2 days 4 flooding on the north carolina outer banks 4 1 iflood citizen science app a citizen science phone application app iflood was released in september 2019 to collect flood information including location depth recent rainfall and photographs on the north carolina outer banks fig 6 here the flood reports are used to validate the combined pulse and recharge flooding model equation a8 for the outer banks region when a flood report is submitted the gps position of the phone and the position of a drop pin that can be moved manually on the map screen are recorded fig 6 the user can send a photograph of the flood answer survey questions about the flood depth location and recent rainfall and provide additional comments with the data stored on a cloud based firebase server the app was advertised on town social media pages in local newsletters and on an nsf repository for citizen science projects and was presented at an obx green drinks chapter meeting when possible the approximate position of the reported location was validated by comparing images in google earth street view with the photograph submitted to the app reports with unrealistic locations e g several reports submitted to iflood had locations in the middle of the atlantic were eliminated during the quality control process about half the reports were submitted by town managers and research partners at the usace frf between september 2019 and february 2020 34 quality controlled reports associated with at least 7 storms including hurricane dorian in sept 2019 indicated flooding between corolla and rodanthe nc fig 7 oceanside flooding occurred up to 5 days after storms with ocean surge up to 1 0 m significant wave heights in 26 m depth from 3 5 to 7 0 m and cumulative daily rainfall ranging from negligible to 0 15 m fig 8 purple box dates before december 2019 the most reports 16 associated with a single event occurred following hurricane dorian fig 8 sound water level changes may have contributed to flooding on the sound side of the barrier island fig 8 orange box after december 2019 there were no sound water level measurements during this period and thus the 6 sound side flood reports were not analyzed three additional flood reports were excluded because the report photo suggested that the flooding resulted primarily from ponding on impermeable surfaces e g roadways 4 2 regional flood hindcasts the location and timing of the remaining 25 ocean side flood reports are compared with the analytical estimates of the groundwater rain induced flooding 2 examples are shown in fig 9 the analytical model with recharge is driven with precipitation measured at the frf assuming all land surfaces are pervious and the approximate ocean shoreline water level estimated as the 36 hr running average of the sum of the offshore tide surge and shoreline setup the cross shore distance x is measured from the estimated dune position and the land surface elevation is determined from a 5x5 m digital elevation model dem measured by the joint airborne lidar bathymetry technical center of expertise jabltcx in fall 2019 the pre storm water table at the dune x0 is estimated to be 0 3 m based on the in situ observations roughly consistent with the overheight expected for a 1 m amplitude semi diurnal tide on a 0 1 slope nielsen 1990 raubenheimer et al 1999 inland of the shoreline the pre storm water table is estimated using the annual average gradient 0 0015 m m between the x0 and x160 wells the diffusivity is assumed to be uniform throughout the surface aquifer see discussion each storm event is simulated separately because the model has less skill at predicting post storm recovery and is invalid after the water table exceeds the land surface based on the aquifer recovery times in the duck field observations the groundwater levels typically return to near those expected without a storm within 2 weeks so estimating storms separately during some closely spaced events would have higher uncertainties than considered in the hindcast evaluation the uncertainty of the analytical model with recharge is estimated as 0 3 m and includes uncertainty for the maximum water table elevation driven by a rise in shoreline water level rmse error 0 1 m uncertainty of the pre storm water table position 0 05 m standard deviation of the mean water table position observed at the dune well x0 which had the highest variance in water level and uncertainty in the land surface position based on the vertical resolution of the lidar measurement 0 15 m the analytical model with recharge predicts a flood i e the predicted water table exceeds the land surface within the model uncertainty of 0 3 m that is consistent with the report timing 1 day and location for 19 of the 25 flood reports for storms with and without precipitation fig 10 data points are in or above the pink shaded region the one day window was selected for validation because flooding may have occurred prior to the time the report was submitted and cumulative precipitation is applied to the analytical model with recharge at the end of each day all reports that are not predicted as flooding events by the analytical model with recharge were made following hurricane dorian which was the only event with heavy precipitation total rainfall 0 17 m during the regional study dark blue squares fig 10 making it difficult to evaluate the model s performance for combined surge and rain processes three of the dorian reports with predicted water table position 0 5 m were located 200 m inland where uncertainty may be larger and a 4th report had an unusually high land surface elevation predicted water table position 1 3 m surface ponding associated with precipitation that is decoupled from the groundwater behavior i e infiltration limited may explain the discrepancy between the observed and predicted flooding during hurricane dorian for most of the events the surge driven pulse dominates the groundwater response specifically the pulse hindcasts suggest up to 0 5 m ocean driven groundwater increases for no rain gray symbols fig 10 compare the initial with final groundwater position and roughly 0 6 m ocean driven increases during light typically 0 02 m fig 8 rain events light blue symbols fig 10 hindcast water table increases of up to 0 7 m with less than 0 1 m increase owing to recharge additionally inaccuracy in the report locations uncertainty in the initial water table configuration and errors in the land surface elevation also could contribute to model data discrepancies see discussion 4 3 regional flood vulnerability forecasts the analytical model is applied to two hypothetical storms with 7 day periods time coefficient b 0 3 equations a1 and a2 including a moderate storm with a 0 90 m increase in the shoreline water level amplitude a 0 90 which was the average for the observed storms and an extreme storm during which the shoreline water level increased 2 25 m to assess the vulnerability of the outer banks to flooding during future storms ocean storms of greater or equal magnitude to the moderate case have occurred 313 times between 2009 and 2019 while wave heights consistent with the extreme storm case have only occurred once during that interval in both cases it is assumed that there is no wave overtopping of the dune the analytical model is applied to every grid cell in the jabltcx dem extending to the lesser of the midpoint of the barrier island or 600 m inland for each cross island transect beyond 600 m the fluctuation in the water table associated with the change in the offshore water level is negligible 0 1 m the amount of rainfall needed to flood each grid cell is determined from the effective porosity and the difference between the maximum water table elevation and the land surface assuming the land surface is pervious variation in land surface type was not considered but will influence only recharge not the wave and surge driven increases in the water table see section 5 2 flooding is assumed to be constrained to the area within the grid cell and does not affect adjacent cells in the extreme storm case over 10 of the land area is flooded as a result of the increased shoreline water level and resulting propagation of the groundwater pulse fig 11 a b a large band of flooding occurs along the nc 12 highway where the low elevation of the roadway coincides with large increases in the water table owing to the proximity of the shoreline fig 11b inland flooding is patchier and coincides with regions of low ground elevation for the moderate storm case 1 6 of the land area is flooded owing to the groundwater pulse fig 11c the locations of flood reports coincide with areas predicted to have high flood vulnerability for these storm cases fig 11 as a result of low land elevations northern duck and rodanthe are predicted to have the highest vulnerability to coastal groundwater flooding most of the barrier would be flooded if precipitation amounts were 0 8 m fig 11 all except black areas the groundwater pulse amplitude scales linearly with the shoreline fluctuation amplitude equation a1 and thus increasing wave height or storm surge increases flooding proportionally in contrast the groundwater pulse amplitude scales with the square root of the storm duration equation a1 and thus flooding is relatively insensitive to storm period doubling the storm duration results in 1 change in the flooded area 5 discussion 5 1 model assumptions and limitations errors in the modeled maximum water table partly may be a consequence of neglecting overland flows during heavy rainfall the model does not account for surface subsurface exchange and is not valid after the water table exceeds the land surface additionally the model reproduces the maximum water table height more accurately than it reproduces the timing of flooding timing errors may result from neglecting the asymmetries in the rise and fall of the shoreline water levels if the shoreline rises faster than it falls the pulse period and thus pulse amplitude attenuation and phase lag with inland distance fig 4 would be under estimated and flooding would occur earlier than predicted timing errors also may result from modeling the rainfall as an instantaneous increase in the water table level rather than accounting for the time history of rainfall induced infiltration broadbridge and white 1988 and of the groundwater drainage recovery following the precipitation variation in land surface type also could influence recharge patterns and was not considered it might be possible to reduce timing errors by including recharge effects in areas with extensive historical monitoring although the analytical model assumes that the diffusivity of the surface aquifer is spatially uniform the presence of paleochannels suggests that there is some heterogeneity in the alongshore direction browder and mcninch 2006 mallinson et al 2010 lazarus and murray 2011 which can introduce errors in the predicted water level and cause deviations from the simple one dimensional framework the diffusivity affects both the steady state pre storm head gradient and the amplitude attenuation of the pulse for example an increase in the hydraulic conductivity or the aquifer depth would decrease the pre storm head gradient but also would increase the maximum fluctuation amplitude at a given location because the storm pulse will attenuate less quickly with inland distance fig 4 ln α increases with decreasing x which is inversely proportional to d kz sy equation a7 thus a 50 change in aquifer diffusivity is expected to cause 5 change in the maximum water table elevation however alongshore variation in the diffusivity could result in alongshore flows and gradients that are not included in the cross island system considered here vertical variation in the location of the confining bed can influence the cross shore structure of the water table anderson et al 2000 but these variations are expected to be small relative to the groundwater level changes resulting from the storm pulses connections between the surface aquifer and subsurface confined aquifers also would result in deviations from the storm pulse solution trefry and bekele 2004 trglavcnik et al 2018 the skill of the analytical model with recharge at predicting flooding consistent with the iflood reports suggests that aquifer heterogeneity has a relatively small effect on the pulse propagation on the ocean side of the barrier island it also was assumed that there was a constant head gradient prior to the storm and that the groundwater divide is mid island and does not vary with time sound side flooding was not considered in this analysis owing to the lack of sound water level measurements increases in the sound water levels likely produce inland propagating groundwater bulges similar to those on the ocean side as well as overtopping shorelines and inundating low lying sound side neighborhoods however changes in the sound water level are better approximated as a step function rapid increase with a slow decline than a gaussian caldwell 2001 in areas where the island width is narrower than the damping distance of the pulse the sound driven pulse will interact with the ocean driven pulse to create more complex fluctuations in the water table similar to interactions between tidal fluctuations that have been observed across narrow barriers huang et al 2015 colyar 2016 li et al 2000 in regions where sound water levels are available it would be possible to develop an analytical model for flooding across the entire barrier island that incorporates sound and ocean water level fluctuations as well as rainfall rotzoll et al 2008 5 2 relative importance of precipitation and shoreline driven changes in the groundwater level during the three year in situ observation period there was only one instance when cumulative rainfall during a storm event exceeded 0 1 m hurricane matthew precipitation 0 2 m based on the estimated effective porosity this precipitation would cause a corresponding increase in the groundwater head of about 0 6 m over the same period there were 18 times when increased shoreline water levels driven by waves and surge increased the water table under the dune 0 6 m suggesting that along the north carolina coast the wave and surge driven processes are a more persistent challenge for managing coastal groundwater hazards than rainfall however recharge elevates the water table across the entire island assuming a pervious land surface while the wave and surge driven water table increases are largest within several hundred meters of the ocean dune therefore rainfall likely plays a larger role in driving groundwater flooding on the sound side of the island where the wave and surge signal has attenuated and land surface elevations are lower the water table is closer to the land surface and a smaller increase in the water table is needed to cause flooding recharge and wave and surge driven increases in the water table were treated as additive in the analytical model with recharge equation a8 this approach reproduced the maximum water level observed during hurricane matthew however storms with both heavy rain and large increases in the shoreline water level generate a different cross island head gradient than ocean storms with no precipitation which may impact recovery times additionally only rainfall during large offshore waves and surge is considered here if a large rainstorm precedes a large wave event the wave and surge driven response might be weaker if the pre storm water table remains significantly elevated above msl furthermore surge driven increases in the water table may inhibit the recovery of the rainfall driven increases bevacqua et al 2019 future work should consider how timing of rain and shoreline water level increases impact the groundwater response and how compound rain and shoreline water level increases affect recovery time additionally groundwater driven increases in the water table are only one mechanism of flooding in coastal zones rainfall can cause flooding independently of groundwater as a result of surface ponding and runoff variation in land surface coverage will affect these processes and areas with high impervious surface coverage are most susceptible to flooding driven by precipitation data collected through the iflood app could be incorporated into studies about the effects of impervious surfaces on flooding patterns flooding also can occur via inundation from the ocean if sea levels are elevated enough to overtop the dune although no incidences of ocean side inundation occurred within the study area roadways were inundated farther south near ocracoke and landfall of a major hurricane could cause overtopping and inundation even when groundwater is not the primary driver of the flood the position of the water table will affect flood recovery times and thus understanding compound effects between these different mechanisms will be important for managing coastal flood hazards 5 3 management of groundwater flooding on the outer banks the results suggest that the storm driven groundwater pulse could flood more than 10 of the ocean side of the outer banks during an event with a 2 25 m increase in shoreline water level e g 1 00 m storm surge and 6 25 m waves without precipitation fig 11 this estimate is conservative because the initial water table distribution was designed to represent the aquifer under calm ocean conditions the extent of flooding across the barrier would be more severe if the water table had not recovered from a prior storm or rainfall additionally groundwater driven flooding is likely to increase as the water table increases with rising sea levels bjerklie et al 2012 global sea level is predicted to rise between 0 5 and 1 4 m by 2100 and sea level rise along the atlantic coast is predicted to outpace the global estimate sweet et al 2017 sweet et al 2020 consequently owing to sea level rise and the increasing intensity and duration of north atlantic storms patricola and wehner 2018 knutson et al 2020 coastal groundwater driven flooding is expected to present a persistent coastal management challenge structural protections such as seawalls jetties and dikes have been the preferred approach to coastal flood prevention dugan et al 2008 gittman et al 2015 although these protections are effective at mitigating surface water inundation driven by surge waves and tides they do not impede flooding driven by groundwater rotzoll and fletcher 2013 additionally the presence of hardened structures can block the groundwater discharging to the ocean prolonging the post storm recovery of the water table lee et al 2019 flood recovery time is important for assessing the duration of impairment of infrastructure and the vulnerability to future flooding chisolm and matthews 2012 lu et al 2015 abboud et al 2018 and should be addressed in future studies by understanding the processes contributing to flooding coastal managers can assess the effectiveness of different flood mitigation strategies in the town of nags head the iflood project has reinforced the importance of groundwater levels for flood management groundwater flooding is an emerging issue the town has focused on in recent years and several groundwater surface water management projects are being implemented to reduce the frequency and extent of flooding in the town including a groundwater pumping system used to reduce the water table level in advance of major storms 5 4 use of phone apps for research and increasing community awareness iflood reports extended the scope of the study from a single site to a 70 km stretch of the outer banks between duck and rodanthe nc although survey responses and photos are used to exclude cases with surface ponding on impermeable surfaces in some cases the ground surface is difficult to determine in addition the phone gps did not always update automatically and sometimes it was necessary to use the photo to refine the report location in cases where photos were not submitted by the user it was more difficult to evaluate the reliability of the flood report however the flooding reports and photos provided by the application users enabled evaluation of the model for a large region of the outer banks the iflood interface was designed to be simple i e minimal buttons and menus and accessible large font screen reader compatible to reduce barriers to participation and to help minimize likelihood of accidental submission of inaccurate data the town managers and usace frf personnel were active users of the app and provided a reliable source of flood reports nags head was the region with the highest number of flood reports submitted to iflood and was one of the partners involved in designing and advertising the iflood app working directly with the town offices enhanced both the quantity and quality of the data received through the app additionally the citizen science app increased community awareness of coastal flooding issues and helped town managers identify regions in their communities where there are recurrent flooding issues the app also enables citizens of the outer banks to understand the risks associated with living in a flood vulnerable environment and to engage with a persistent issue in their communities approximately 70 residents attended a public presentation regarding groundwater induced flooding and the app which has been installed over 100 times by users presumed to be local residents similar citizen science approaches could be applied to address other issues related to coastal flooding and the town of nags head plans to use iflood as a reference to expand the methods the town uses to engage its citizenry and to bring awareness to emerging issues 6 conclusions three years of groundwater level measurements spanning the 550 m wide barrier island near duck nc were used to evaluate an analytical model to predict the response of the water table to surge wave setup and precipitation during coastal storms the groundwater elevation near the ocean increased more than 1 m during storms with large waves and surge nearly double the magnitude observed in prior studies resulting in inland directed head gradients the bulge of groundwater moved inland causing up to a 0 5 m increase in groundwater levels 310 m inland from the dune a linear analytical theory li et al 2004 without recharge for the propagation of storm pulses in shallow aquifers reproduces the amplitude attenuation and phase change observed across the island for 26 storm events with minimal rainfall nash sutcliffe efficiency coefficients are greater than 0 7 and errors in the modeled maximum water table are less than 0 1 m from the dune to 160 m inland infiltration of precipitation results in approximately a threefold increase in the groundwater level relative to the amount of rainfall the model with recharge reproduces the maximum water table levels within 0 15 m for the single ocean storm with significant rainfall hurricane matthew oct 2016 citizen science reports of flooding submitted with a smartphone app iflood were used to evaluate a regional application of the analytical model with recharge along 70 km of the outer banks of north carolina between sept 2019 and feb 2020 25 reports on the ocean side of the island associated with 7 storms showed flooding on natural pervious land surfaces between corolla and rodanthe nc flooding occurred after storms with large ocean surge and waves with and without significant rainfall the analytical model with recharge predicted flooding events that were consistent with the timing and location for 19 of these reports additionally the iflood app provides a new tool for evaluating groundwater flooding processes across the north carolina outer banks and is a framework that can be modified to address a broader range of scientific objectives e g the role of land surface coverage on flooding sound driven flooding processes the analytical model provides a simple and computationally efficient framework for predicting flooding risk along the ocean side of the barrier island for a hypothetical storm with a 2 25 m increase in shoreline water level the analytical model suggests that more than 10 of the ocean side of the outer banks could be inundated by coastal groundwater flooding in the absence of rainfall precipitation would increase the flooding extent credit authorship contribution statement rachel housego funding acquisition conceptualization methodology formal analysis visualization writing original draft britt raubenheimer funding acquisition conceptualization methodology supervision writing review editing steve elgar funding acquisition conceptualization methodology supervision writing review editing sandy cross conceptualization methodology investigation christian legner conceptualization methodology investigation david ryan conceptualization methodology investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank the usace chl field research facility for ocean and meteorological observations levi gorrell fred marin emmett krupczak heidi wadman jesse mcninch and pat dickhudt for assistance deploying and maintaining the groundwater wells and kent hathaway for assistance with precipitation data we also thank the users of the iflood app who contributed flood reports to this project and we thank two anonymous reviewers for their insightful comments that greatly improved the manuscript funding was provided by the u s coastal research program the national science foundation a national science foundation graduate research fellowship the woods hole oceanographic isp program and a vannevar bush faculty fellowship appendix a analytical groundwater pulse model the spatial and temporal evolutions of the storm driven groundwater pulse are simulated using the analytical solution li et al 2004 a1 h x t 2 a b t ε t p exp b ε t p 2 e r f c x d t ε d ε where h is the groundwater level m x is the cross shore position m positive inland from the x0 well t is time d after the start of the storm defined as the local minima in head level at x0 preceding the storm a is the amplitude of the x0 fluctuation m b is a time factor d 2 b 1 2 represents the duration of the elevated water level at x0 tp is the time of the storm peak at x0 relative to the preceding local minima and d is aquifer diffusivity m2 d the analytical solution assumes a homogeneous and isotropic aquifer consistent with the results of the slug tests that were performed across the barrier island the analytical solution also assumes a shallow aquifer unidirectional horizontal flow negligible capillary effects small pulse amplitude relative to aquifer depth and a vertical beach in addition to time series comparisons the analytical solution is evaluated by comparison with the observed amplitude aj and time of peak water level tp j the local maxima in head after time t0 which ranged from 1 to 9 d at inland locations j the observed 36 hr averaged groundwater fluctuation hj at each location is fit using least squares to a pulse function a2 h j t h 0 j a j exp b j t t p j where h 0 j is the pre storm head level and aj and b j are the pulse amplitude and time factors respectively only the increasing portion of the groundwater level time series is used in the fit because the temporal asymmetry of the draining relative to the filling of the unconfined aquifer often is not consistent with the gaussian pulse assumed by the analytical solution cartwright and gibbes 2011 the resulting squared correlations r2 for the fits are greater than 0 9 for all storms at all locations hurricane matthew is excluded from the pulse propagation analysis because groundwater changes owing to rainfall of 0 2 m obscured the groundwater fluctuation driven by the increase in shoreline water level to estimate analytically the pulse amplitude and time lag as a function of inland position equation a1 is non dimensionalized as a3 h x t 2 t ε exp ε 2 e r f c x t ε d ε in which the non dimensional amplitude attenuation α time lag δϕ time t and cross shore location x at inland locations j computed relative to the x0 well are given by li et al 2004 a4 α a j a δ ϕ t p j t p b a 5 t t t p b a 6 x x 2 d b 1 2 a 7 the aquifer diffusivity is estimated by determining the value that yields the best fit of the analytical solution equation a1 to the observed water table fluctuation and to the observed non dimensional amplitude attenuation and phase lag equations a4 and a5 as a function of non dimensional distance equation a7 for the 26 storm events without heavy rainfall both estimates give similar values for d the effects of rainfall are accounted for in the pulse model assuming linear superposition to yield the analytical model with recharge a8 h x t h 0 j 2 a b t ε t p exp b ε t p 2 e r f c x 2 d t ε d ε r n e where the amount of rainfall during the storm r is assumed spatially uniform and ne is the effective porosity estimated from observations 
4023,three years of observations of groundwater elevations ocean tides surge and waves and rainfall are used to study coastal groundwater driven flooding along the ocean side of a barrier island increases in surge and wave driven water levels setup during 26 ocean storms with little rainfall including the passage of 3 hurricanes caused o 1 m increases in groundwater heads under the dunes on the ocean side of the island nearly double previously reported magnitudes the inland propagation of the resulting pulses in groundwater levels is consistent with an analytical model without recharge based on shallow aquifer theory nash sutcliffe model efficiencies of 0 7 maximum water table level estimates within 0 1 m of observations infiltration of precipitation results in approximately a threefold increase in the groundwater level relative to the amount of rainfall the analytical model with recharge driven with estimated ocean shoreline water levels based on the 36 hr averaged offshore tide surge and wave height and measured precipitation predicts the maximum water table height within 0 15 m of that observed across the barrier island during hurricane matthew which was the only wave event during the 3 yr data set with more than 0 1 m rainfall citizen science reports from a smartphone app iflood are used to evaluate the regional application of the model twenty five ocean side reports associated with 7 ocean storms 6 of which had minimal rainfall between sept 2019 and feb 2020 showed flooding on natural permeable land surfaces along 70 km of the northern outer banks barrier island from corolla to rodanthe nc the analytical model with recharge predicts flooding that is consistent with the timing and location for 19 of the 25 reports applying the model regionally suggests that more than 10 of the land area on the ocean side of the northern outer banks would be inundated by coastal groundwater even in the absence of rainfall for an ocean storm that generates a 2 25 m increase in the shoreline water level keywords coastal hydrogeology flooding land sea connection storms compound events citizen science 1 introduction nearly 1 5 million people inhabit barrier islands along the u s atlantic and gulf coasts with a population density approximately three times greater than that of coastal states zhang and leatherman 2011 which is increasing along with the associated infrastructure elko et al 2015 the low elevations close to mean sea level msl and high density of infrastructure make coastal counties susceptible to devastating environmental and economic impacts from flooding in unconfined coastal aquifers the average water table usually is higher than msl and lies within a few meters of the land surface in low relief regions glover 1959 rotzoll and fletcher 2013 befus et al 2020 although groundwater can cause flooding if the water table exceeds the land surface groundwater processes typically are neglected in flood hazard mapping and management policies morris et al 2007 rotzoll and fletcher 2013 abboud et al 2018 as of 2019 the u s national flood insurance program was 20 billion dollars in debt horn and webel 2019 sea level rise and the increasing strength and duration of large wave and surge events ocean storms are predicted to double the frequency of flooding and to expand the spatial extent of flood impacts woodruff et al 2013 moftakhari et al 2015 vitousek et al 2017 patricola and wehner 2018 befus et al 2020 knutson et al 2020 sweet et al 2020 compound flooding driven by multiple hazards such as rain and storm surge can magnify the duration and extent of flood impacts wahl et al 2015 bevacqua et al 2019 developing flood predictions that integrate oceanographic meteorological and hydrogeological processes has been identified as a research need for managing storm hazards and impacts elko et al 2019 increasing ocean storms that cause groundwater driven flooding may require new management strategies because traditional ocean driven flood mitigation structures such as jetties and sea walls are ineffectual against increases in the water table however although several studies have analyzed impacts of sea level rise on regional groundwater inundation and flooding rotzoll and fletcher 2013 befus et al 2020 regional effects of transient ocean storms are less well understood prior studies of wave and surge driven groundwater responses have focused on moderate wave conditions li et al 2004 trglavcnik et al 2018 rotzoll and el kadi 2008 during ocean storm events the elevation of the coastal water table fluctuates in response to changes in the wave tide and surge driven changes in the ocean water level nielsen 1990 cartwright et al 2004 anderson and lauer 2008 abarca et al 2013 the resulting ocean storm pulse increases the elevation of the coastal water table and this bulge of high groundwater continues to propagate inland after the ocean water levels have subsided li et al 2004 rotzoll and el kadi 2008 ocean storm pulses have larger amplitudes and longer fluctuation periods than water table oscillations driven by wind waves or tides and thus can penetrate farther into the aquifer nielsen 1990 li et al 2004 as the ocean storm signal propagates inland the amplitude of the fluctuation attenuates at a rate controlled by the hydrogeologic properties and structural composition of the aquifer li et al 2004 rotzoll and el kadi 2008 an analytical solution pulse model assuming a vertical beach face and a homogeneous isotropic uniform depth aquifer reproduced the behavior of a surge and wave induced groundwater fluctuation in a sandy aquifer in a coastal barrier island cartwright et al 2004 li et al 2004 however the analytical model was developed and calibrated for a single event and thus the model skill for multiple events and its applicability to other sites is uncertain for example leakage to the surface aquifer from a confined aquifer can result in non uniform propagation of the storm pulse with smaller than predicted amplitude relative to the shoreline fluctuation trglavcnik et al 2018 when rainfall is coincident with emergent groundwater from the land surface the duration of the flood tends to last longer than runoff or overwash driven flooding alone macdonald et al 2008 befus et al 2020 the water table rises in response to infiltration from precipitation by an amount inversely dependent on the effective porosity of the aquifer meinzer 1923 crosbie et al 2005 cobby et al 2009 zhang et al 2017 smail et al 2019 antecedent conditions that result in an elevated water table reduce the aquifer infiltration capacity for subsequent events rotzoll and fletcher 2013 here three years of continuous observations section 2 including 26 ocean storms with minimal rainfall are used to evaluate the analytical storm pulse model section 3 for the groundwater level in an unconfined surface aquifer driven by changes in the shoreline water level the observed groundwater increases under the dune following large offshore wave events without precipitation significant wave height hs 5 m are o 1 m nearly double the amplitude measured in prior studies li et al 2004 rotzoll and el kadi 2008 trglavcnik et al 2018 and similar in magnitude to the sea level rise slr driven groundwater increase predicted over the next hundred years 0 4 1 3 m of slr predicted by 2100 off the coast of nc sweet et al 2017 the analytical model is shown to predict the maximum ocean storm driven groundwater levels within about 0 1 m and the timing of maximum groundwater levels within about 1 day using an estimated effective porosity an analytical groundwater flooding model including the storm pulse and recharge is evaluated with measurements during the passage of hurricane matthew which had wave heights 5 5 m surge 1 0 m and precipitation 0 2 m flood reports submitted to iflood section 4 1 a citizen science phone application are used to conduct a hindcast assessment of the analytical groundwater flooding model along a 70 km region of the outer banks between corolla and rodanthe nc section 4 2 the analytical flooding model is used to predict regions of groundwater flood vulnerability on the ocean side of the outer banks caused by an increase in the shoreline water level consistent with a hurricane or large nor easter section 4 3 offshore wave heights and precipitation amounts that drive the analytical model are among the most ubiquitous measurements collected in global coastal observational arrays consequently the framework presented here could be used to study regional groundwater driven flooding in other low lying coastal environments where the aquifer properties are roughly uniform 2 field measurements although this study is conducted on the north carolina outer banks the results are applicable to many other coastal areas sandy coasts account for about 33 and sandy barrier islands account for 7 of global coastlines stutz and pilkey 2011 vousdoukas et al 2020 furthermore large sections of the u s atlantic and gulf coasts have coastal plain geology similar to the nc outer banks usgs 2017 for which the regional aquifer structure often can be approximated as homogeneous despite smaller scale heterogeneity similar to prior studies examining groundwater inundation driven by sea level rise rotzoll and fletcher 2013 befus et al 2020 2 1 site description the north carolina outer banks is a 320 km long chain of barrier islands extending south from the virginia north carolina state line to bogue inlet the islands are up to 3 km wide and have ocean shoreline dunes from less than 1 to 12 m high elko et al 2002 the north carolina outer banks is part of the north carolina coastal plain aquifer system and the shallow geology is a 50 70 m thick quaternary sequence that fills the albemarle embayment winner and coble 1996 lautier 2009 the surficial aquifer typically is comprised of 70 sand winner and coble 1996 a network of paleo channels that were backfilled with younger pleistocene sediments also weaves through the quartenary sequence riggs et al 1995 lazarus and murray 2011 the paleo channels contain muddy estuarine sediment sand and fluvial gravel lazarus and murray 2011 branches of the paleo roanoke albemarle fluvial system have been recorded at the shoreface in duck kitty hawk kill devil hills and nags head riggs et al 1995 boss et al 2002 lazarus and murray 2011 the surficial aquifer is underlain by a series of discontinuous clay and silt beds that comprise the yorktown confining unit which is estimated to occur 15 20 m below navd88 approximately mean sea level winner and coble 1996 mallinson et al 2010 similar to many barrier island areas land use is primarily single family residential with houses on stilts 65 total land with lot coverage 33 or shared open use common vacant or public 24 total land area with primarily pervious surfaces in addition topographic relief is low especially in developed areas and surface runoff is expected to be minimal in september 2014 19 groundwater wells were installed at 8 locations along a 550 m long transect across the barrier island extending from the ocean dune to the sound at the u s army corps of engineers coastal hydraulics laboratory field research facility frf http www frf usace army mil in duck nc fig 1 the property is bordered on the west by currituck sound and on the east by the atlantic ocean on the ocean side of the island the beach is backed by 7 m high vegetated dunes sediment samples collected during construction of the frf facility meisburger et al 1989 and during installation of the groundwater wells suggest that the surficial aquifer is composed of medium quartz sand mean diameter 0 25 mm and shell hash prior studies suggest the uppermost confining layer is roughly 15 to 30 m below navd88 meisburger et al 1989 manahan et al 1998 however a confining unit was not encountered during drilling with boreholes extending from 15 under the dune to 26 m near the sound below navd88 slug tests hvorslev 1951 bouwer and rice 1976 brown et al 1995 butler et al 1996 performed at 16 of the wells spanning the island suggest that the hydraulic conductivity is approximately k 13 0 4 4 m d consistent with an estimate of 14 9 m d obtained during drilling of a test water supply well about 2 miles south of the study site manahan et al 1998 based on these observations the aquifer is assumed to be approximately uniform across the island 2 2 observations the cross shore positions x positive toward the sound of the well locations are defined relative to the well closest to the dune face each well was composed of 0 05 m diameter pvc pipe with no 10 perforated screen at the bottom surrounded by gravel pack topped with a bentonite seal at the six mid island locations fig 1c 95 x 450 m wells extended to 9 to 10 m below navd88 with 8 to 9 m long screens near the ocean fig 1b red and black circles and sound fig 1b orange circle wells fig 1c extended to about 1 m below navd88 with 0 6 m long screens fig 1c conductivity temperature depth ctd sensors at about mid screen elevation in each well were sampled at 10 min intervals salinities were less than 1 psu except in the well closest to the ocean x0 following large ocean storms when saline ocean water penetrated under the dune fig 1c x0 water density was calculated from the measured salinity temperature and pressure fofonoff and millard 1983 measurements collected by slowly lowering a ctd within each well showed that density was approximately vertically uniform the sensors were vented to the atmosphere so that pressure measurements were not influenced by fluctuations in barometric pressure sensor elevations were estimated using differential gps measurements of the well cap and simultaneous water level measurements from a standard meter and pressure and water density measurements from the in situ sensors annual re estimates show 0 02 m drift water table elevations were estimated from the pressure measurements converted to head h as post et al 2007 equation 5 1 h p ρ f g z s where p pa is the measured pressure ρ f kg m3 is the density of freshwater g m s2 is the gravitational constant and zs m is the elevation of the sensor relative to navd88 assuming a reference level zr of 0 navd88 the largest deviations from 1 owing to density differences post et al 2007 equation 12 at x0 are less than 0 01 m ocean water levels were measured every 6 min with a noaa tide gauge id 8651371 in about 6 m depth at the end of the frf pier tides were semi diurnal with range 1 m and storm surge was up to 1 m significant wave heights hs 4 times the standard deviation of sea surface elevation fluctuations in the frequency range from 0 05 to 0 30 hz recorded every 30 min in 26 m water depth ndbc station 44100 ranged from near 0 to 6 m fig 2 a with an average of about 1 m breaking wave driven setup longuet higgins and stewart 1964 of the shoreline water levels is estimated to be 0 2 times the offshore significant wave height guza and thornton 1981 nielsen 1988 raubenheimer et al 2001 roughly consistent with observations from a lidar on the dune about 300 m north of the wells shoreline water levels are estimated as the sum of the ocean water level including tides and surge and the setup ocean storms are defined as events with combined 36 hr averaged de tided shoreline water level exceeding 0 65 m above navd88 twenty seven ocean storm events were observed during the 3 year data record including 4 hurricanes that passed offshore of duck nc joaquin oct 2015 cyan box fig 2 matthew oct 2016 magenta box fig 2 and jose and maria sept 2017 yellow and orange boxes fig 2 respectively precipitation fig 2b was recorded every 10 min using a set of 3 rain gauges data from the precipitation gauges is uncertain during extreme rainfall rates 0 03 m hr which only occurred once in the observation period during hurricane matthew oct 2016 with the exception of hurricane matthew there was 0 1 m rainfall during the ocean storms tidal effects were negligible in the sound but winds can drive rapid 1 2 m changes in the sound water level mulligan et al 2014 low sound water levels typically occur during the winter months caldwell 2001 and often are coincident with high ocean water levels driven by winter storms under calm conditions the ocean side groundwater heads increase landward fig 1d and fig 2c blue and green curves are higher than red and black curves e g may july 2015 and the water table is highest 160 m inland from the dune fig 1c d the average head gradient between the center of the island and the ocean well x0 is 0 0015 m m fig 1d however during storms surge setup and wave infiltration result in the groundwater head at the wells closest to the ocean exceeding the head levels at the inland wells fig 2c shaded grey areas and fig 3 the bulge of high groundwater attenuates as it propagates inland fig 3b solid curves the two storms that resulted in the highest groundwater levels at x0 were hurricane joaquin cyan box fig 2 and hurricane matthew magenta box fig 2 a nor easter preceded hurricane joaquin and caused sustained elevated offshore wave heights soon after the nor easter hurricane joaquin developed in the atlantic and generated a second series of large waves that reached maximum heights of 4 7 m in 26 m water depth on october 5 2015 head levels increased 1 6 1 4 1 2 0 9 m above pre storm levels during hurricane joaquin at x 0 25 90 and 160 m respectively fig 2c and 0 5 m at x 310 m not shown when the high water levels from hurricane joaquin propagated inland the water table came within approximately 1 m of the ground surface at x95 and x160 following hurricane joaquin the water table at x160 took approximately two weeks to return to within a standard deviation of the average level the time delays between the occurrences of maximum water levels at each well location indicate an inland propagation rate of the storm driven groundwater bulge of about 60 m day during hurricane matthew infiltration from heavy precipitation 0 2 m fema 2018 table 3 and increasing ocean water levels both contributed to the increase in the water table instead of a delayed response in the time of arrival of the maximum water level a near simultaneous 0 6 to 0 9 m increase in groundwater level occurred at all well locations fig 2 following the heavy precipitation 3 analytical model 3 1 groundwater pulse theory evaluation propagation of the storm driven groundwater pulse is simulated using an analytical solution referred to subsequently as the analytical model no recharge li et al 2004 for darcian groundwater flow assuming a gaussian shoreline fluctuation pulse and applying a linearization based on the assumption that the amplitude of the water table fluctuation is small relative to the depth of the aquifer see appendix here the propagation is driven equation a1 with the head fluctuations at the x0 well rather than with the shoreline fluctuations to avoid errors resulting from uncertainty in the cross shore position of the shoreline which changes with changing ocean water levels on the sloping beach with evolving beach topography during storms up to 4 m erosion during a single event with seasons the mean shoreline position can vary 10 s of meters as the beach accretes during the summer and erodes during the winter and with long term trends the dune eroded more than 10 m landward during the observation period the model is solved numerically using global adaptive quadrature with an absolute error tolerance of 1e 12 m and a time step of 0 01 days tests with smaller time steps were conducted to ensure the solution was robust errors from the numerical integration scheme do not contribute significantly to the model uncertainty 0 001 m the fits between the water table levels for the 26 observed storm pulses with minimal rainfall and a gaussian shape had correlations r2 0 9 although 5 storms were negatively skewed and 10 storms were positively skewed with 5 skewness magnitudes 0 3 data from the four wells closest to the ocean x0 x160 during the 26 storms with minimal rainfall are included in the evaluation of the pulse theory the best fit diffusivity for storm pulses is d 3500 m2 d which is within a factor 2 of the diffusivity based on the estimated hydrologic parameters hydraulic conductivity 10 k 30 m d specific yield sy 0 3 and the aquifer depth 15 z 30 m the analytical model without recharge reproduces the observed surge and wave driven changes in the water table well to very well based on the nash sutcliffe efficiency nse nash and sutcliffe 1970 coefficients table 1 the model agreement with the observations often is worse at x0 than at x30 or x95 owing to greater deviations from a gaussian fit compare solid with dashed curves in fig 3 which shows an example for a single storm differences between the observed and theoretical groundwater levels are larger after the storm peak table 1 nse are larger for the entire event than for just the rising portion and fig 3 at least partly because deviations from a gaussian are larger during the waning ocean storm the root mean square error rmse between the analytical and observed maximum water table which is used to estimate regional flood occurrences is 0 1 m at all locations for all storms and the estimated timing of the maximum water level is correct to within 0 5 days the inland amplitude decay and phase evolution of the ocean storm pulse fluctuations are used to examine the model data agreement further the non dimensional model equation a3 is solved numerically for 0 x 1 5 with 0 01 resolution analytical estimates fig 4 solid curves of the bulge properties α and δϕ as a function of inland distance x are obtained from the magnitude and time of the maximum of the non dimensional gaussian pulse at each cross shore position equation a3 observational estimates of the non dimensional amplitude attenuation phase lag and distance fig 4 symbols are estimated from equations a4 a7 with a aj tp t and bj determined from the best fits of the measured groundwater levels h to gaussian curves equation a2 the agreement between the model and observed non dimensional amplitude attenuation α and phase lag δϕ correlations r2 0 73 and 0 71 respectively is insensitive to cross shore distance fig 4 consistent with the assumption that the aquifer at duck is approximately homogeneous and isotropic li et al 2004 3 2 precipitation response the change in the water table from precipitation driven recharge scales with the effective porosity ne for sand porosity n is estimated to range from 0 36 to 0 43 and n 0 4 for grab samples collected in the intertidal zone at duck to estimate the value of the effective porosity the groundwater data on the sound side of the island x310 to x550 fig 1 where ocean driven groundwater fluctuations typically are negligible under low wave conditions are used to determine the water table response to precipitation events rainfall events separated by dry periods longer than 2 days between oct 2014 and oct 2016 with cumulative precipitation 0 02 m are included in the analysis the water table increase is approximately three times the amount of rainfall at all sites fig 5 for x 310 400 and 450 m corresponding to an effective porosity ne of about 0 33 roughly consistent with porosity estimates for sand the analytical model with recharge reproduces the maximum water table levels during hurricane matthew assuming 0 2 m rainfall within about 0 15 m and the time of maximum water table level within 0 2 days 4 flooding on the north carolina outer banks 4 1 iflood citizen science app a citizen science phone application app iflood was released in september 2019 to collect flood information including location depth recent rainfall and photographs on the north carolina outer banks fig 6 here the flood reports are used to validate the combined pulse and recharge flooding model equation a8 for the outer banks region when a flood report is submitted the gps position of the phone and the position of a drop pin that can be moved manually on the map screen are recorded fig 6 the user can send a photograph of the flood answer survey questions about the flood depth location and recent rainfall and provide additional comments with the data stored on a cloud based firebase server the app was advertised on town social media pages in local newsletters and on an nsf repository for citizen science projects and was presented at an obx green drinks chapter meeting when possible the approximate position of the reported location was validated by comparing images in google earth street view with the photograph submitted to the app reports with unrealistic locations e g several reports submitted to iflood had locations in the middle of the atlantic were eliminated during the quality control process about half the reports were submitted by town managers and research partners at the usace frf between september 2019 and february 2020 34 quality controlled reports associated with at least 7 storms including hurricane dorian in sept 2019 indicated flooding between corolla and rodanthe nc fig 7 oceanside flooding occurred up to 5 days after storms with ocean surge up to 1 0 m significant wave heights in 26 m depth from 3 5 to 7 0 m and cumulative daily rainfall ranging from negligible to 0 15 m fig 8 purple box dates before december 2019 the most reports 16 associated with a single event occurred following hurricane dorian fig 8 sound water level changes may have contributed to flooding on the sound side of the barrier island fig 8 orange box after december 2019 there were no sound water level measurements during this period and thus the 6 sound side flood reports were not analyzed three additional flood reports were excluded because the report photo suggested that the flooding resulted primarily from ponding on impermeable surfaces e g roadways 4 2 regional flood hindcasts the location and timing of the remaining 25 ocean side flood reports are compared with the analytical estimates of the groundwater rain induced flooding 2 examples are shown in fig 9 the analytical model with recharge is driven with precipitation measured at the frf assuming all land surfaces are pervious and the approximate ocean shoreline water level estimated as the 36 hr running average of the sum of the offshore tide surge and shoreline setup the cross shore distance x is measured from the estimated dune position and the land surface elevation is determined from a 5x5 m digital elevation model dem measured by the joint airborne lidar bathymetry technical center of expertise jabltcx in fall 2019 the pre storm water table at the dune x0 is estimated to be 0 3 m based on the in situ observations roughly consistent with the overheight expected for a 1 m amplitude semi diurnal tide on a 0 1 slope nielsen 1990 raubenheimer et al 1999 inland of the shoreline the pre storm water table is estimated using the annual average gradient 0 0015 m m between the x0 and x160 wells the diffusivity is assumed to be uniform throughout the surface aquifer see discussion each storm event is simulated separately because the model has less skill at predicting post storm recovery and is invalid after the water table exceeds the land surface based on the aquifer recovery times in the duck field observations the groundwater levels typically return to near those expected without a storm within 2 weeks so estimating storms separately during some closely spaced events would have higher uncertainties than considered in the hindcast evaluation the uncertainty of the analytical model with recharge is estimated as 0 3 m and includes uncertainty for the maximum water table elevation driven by a rise in shoreline water level rmse error 0 1 m uncertainty of the pre storm water table position 0 05 m standard deviation of the mean water table position observed at the dune well x0 which had the highest variance in water level and uncertainty in the land surface position based on the vertical resolution of the lidar measurement 0 15 m the analytical model with recharge predicts a flood i e the predicted water table exceeds the land surface within the model uncertainty of 0 3 m that is consistent with the report timing 1 day and location for 19 of the 25 flood reports for storms with and without precipitation fig 10 data points are in or above the pink shaded region the one day window was selected for validation because flooding may have occurred prior to the time the report was submitted and cumulative precipitation is applied to the analytical model with recharge at the end of each day all reports that are not predicted as flooding events by the analytical model with recharge were made following hurricane dorian which was the only event with heavy precipitation total rainfall 0 17 m during the regional study dark blue squares fig 10 making it difficult to evaluate the model s performance for combined surge and rain processes three of the dorian reports with predicted water table position 0 5 m were located 200 m inland where uncertainty may be larger and a 4th report had an unusually high land surface elevation predicted water table position 1 3 m surface ponding associated with precipitation that is decoupled from the groundwater behavior i e infiltration limited may explain the discrepancy between the observed and predicted flooding during hurricane dorian for most of the events the surge driven pulse dominates the groundwater response specifically the pulse hindcasts suggest up to 0 5 m ocean driven groundwater increases for no rain gray symbols fig 10 compare the initial with final groundwater position and roughly 0 6 m ocean driven increases during light typically 0 02 m fig 8 rain events light blue symbols fig 10 hindcast water table increases of up to 0 7 m with less than 0 1 m increase owing to recharge additionally inaccuracy in the report locations uncertainty in the initial water table configuration and errors in the land surface elevation also could contribute to model data discrepancies see discussion 4 3 regional flood vulnerability forecasts the analytical model is applied to two hypothetical storms with 7 day periods time coefficient b 0 3 equations a1 and a2 including a moderate storm with a 0 90 m increase in the shoreline water level amplitude a 0 90 which was the average for the observed storms and an extreme storm during which the shoreline water level increased 2 25 m to assess the vulnerability of the outer banks to flooding during future storms ocean storms of greater or equal magnitude to the moderate case have occurred 313 times between 2009 and 2019 while wave heights consistent with the extreme storm case have only occurred once during that interval in both cases it is assumed that there is no wave overtopping of the dune the analytical model is applied to every grid cell in the jabltcx dem extending to the lesser of the midpoint of the barrier island or 600 m inland for each cross island transect beyond 600 m the fluctuation in the water table associated with the change in the offshore water level is negligible 0 1 m the amount of rainfall needed to flood each grid cell is determined from the effective porosity and the difference between the maximum water table elevation and the land surface assuming the land surface is pervious variation in land surface type was not considered but will influence only recharge not the wave and surge driven increases in the water table see section 5 2 flooding is assumed to be constrained to the area within the grid cell and does not affect adjacent cells in the extreme storm case over 10 of the land area is flooded as a result of the increased shoreline water level and resulting propagation of the groundwater pulse fig 11 a b a large band of flooding occurs along the nc 12 highway where the low elevation of the roadway coincides with large increases in the water table owing to the proximity of the shoreline fig 11b inland flooding is patchier and coincides with regions of low ground elevation for the moderate storm case 1 6 of the land area is flooded owing to the groundwater pulse fig 11c the locations of flood reports coincide with areas predicted to have high flood vulnerability for these storm cases fig 11 as a result of low land elevations northern duck and rodanthe are predicted to have the highest vulnerability to coastal groundwater flooding most of the barrier would be flooded if precipitation amounts were 0 8 m fig 11 all except black areas the groundwater pulse amplitude scales linearly with the shoreline fluctuation amplitude equation a1 and thus increasing wave height or storm surge increases flooding proportionally in contrast the groundwater pulse amplitude scales with the square root of the storm duration equation a1 and thus flooding is relatively insensitive to storm period doubling the storm duration results in 1 change in the flooded area 5 discussion 5 1 model assumptions and limitations errors in the modeled maximum water table partly may be a consequence of neglecting overland flows during heavy rainfall the model does not account for surface subsurface exchange and is not valid after the water table exceeds the land surface additionally the model reproduces the maximum water table height more accurately than it reproduces the timing of flooding timing errors may result from neglecting the asymmetries in the rise and fall of the shoreline water levels if the shoreline rises faster than it falls the pulse period and thus pulse amplitude attenuation and phase lag with inland distance fig 4 would be under estimated and flooding would occur earlier than predicted timing errors also may result from modeling the rainfall as an instantaneous increase in the water table level rather than accounting for the time history of rainfall induced infiltration broadbridge and white 1988 and of the groundwater drainage recovery following the precipitation variation in land surface type also could influence recharge patterns and was not considered it might be possible to reduce timing errors by including recharge effects in areas with extensive historical monitoring although the analytical model assumes that the diffusivity of the surface aquifer is spatially uniform the presence of paleochannels suggests that there is some heterogeneity in the alongshore direction browder and mcninch 2006 mallinson et al 2010 lazarus and murray 2011 which can introduce errors in the predicted water level and cause deviations from the simple one dimensional framework the diffusivity affects both the steady state pre storm head gradient and the amplitude attenuation of the pulse for example an increase in the hydraulic conductivity or the aquifer depth would decrease the pre storm head gradient but also would increase the maximum fluctuation amplitude at a given location because the storm pulse will attenuate less quickly with inland distance fig 4 ln α increases with decreasing x which is inversely proportional to d kz sy equation a7 thus a 50 change in aquifer diffusivity is expected to cause 5 change in the maximum water table elevation however alongshore variation in the diffusivity could result in alongshore flows and gradients that are not included in the cross island system considered here vertical variation in the location of the confining bed can influence the cross shore structure of the water table anderson et al 2000 but these variations are expected to be small relative to the groundwater level changes resulting from the storm pulses connections between the surface aquifer and subsurface confined aquifers also would result in deviations from the storm pulse solution trefry and bekele 2004 trglavcnik et al 2018 the skill of the analytical model with recharge at predicting flooding consistent with the iflood reports suggests that aquifer heterogeneity has a relatively small effect on the pulse propagation on the ocean side of the barrier island it also was assumed that there was a constant head gradient prior to the storm and that the groundwater divide is mid island and does not vary with time sound side flooding was not considered in this analysis owing to the lack of sound water level measurements increases in the sound water levels likely produce inland propagating groundwater bulges similar to those on the ocean side as well as overtopping shorelines and inundating low lying sound side neighborhoods however changes in the sound water level are better approximated as a step function rapid increase with a slow decline than a gaussian caldwell 2001 in areas where the island width is narrower than the damping distance of the pulse the sound driven pulse will interact with the ocean driven pulse to create more complex fluctuations in the water table similar to interactions between tidal fluctuations that have been observed across narrow barriers huang et al 2015 colyar 2016 li et al 2000 in regions where sound water levels are available it would be possible to develop an analytical model for flooding across the entire barrier island that incorporates sound and ocean water level fluctuations as well as rainfall rotzoll et al 2008 5 2 relative importance of precipitation and shoreline driven changes in the groundwater level during the three year in situ observation period there was only one instance when cumulative rainfall during a storm event exceeded 0 1 m hurricane matthew precipitation 0 2 m based on the estimated effective porosity this precipitation would cause a corresponding increase in the groundwater head of about 0 6 m over the same period there were 18 times when increased shoreline water levels driven by waves and surge increased the water table under the dune 0 6 m suggesting that along the north carolina coast the wave and surge driven processes are a more persistent challenge for managing coastal groundwater hazards than rainfall however recharge elevates the water table across the entire island assuming a pervious land surface while the wave and surge driven water table increases are largest within several hundred meters of the ocean dune therefore rainfall likely plays a larger role in driving groundwater flooding on the sound side of the island where the wave and surge signal has attenuated and land surface elevations are lower the water table is closer to the land surface and a smaller increase in the water table is needed to cause flooding recharge and wave and surge driven increases in the water table were treated as additive in the analytical model with recharge equation a8 this approach reproduced the maximum water level observed during hurricane matthew however storms with both heavy rain and large increases in the shoreline water level generate a different cross island head gradient than ocean storms with no precipitation which may impact recovery times additionally only rainfall during large offshore waves and surge is considered here if a large rainstorm precedes a large wave event the wave and surge driven response might be weaker if the pre storm water table remains significantly elevated above msl furthermore surge driven increases in the water table may inhibit the recovery of the rainfall driven increases bevacqua et al 2019 future work should consider how timing of rain and shoreline water level increases impact the groundwater response and how compound rain and shoreline water level increases affect recovery time additionally groundwater driven increases in the water table are only one mechanism of flooding in coastal zones rainfall can cause flooding independently of groundwater as a result of surface ponding and runoff variation in land surface coverage will affect these processes and areas with high impervious surface coverage are most susceptible to flooding driven by precipitation data collected through the iflood app could be incorporated into studies about the effects of impervious surfaces on flooding patterns flooding also can occur via inundation from the ocean if sea levels are elevated enough to overtop the dune although no incidences of ocean side inundation occurred within the study area roadways were inundated farther south near ocracoke and landfall of a major hurricane could cause overtopping and inundation even when groundwater is not the primary driver of the flood the position of the water table will affect flood recovery times and thus understanding compound effects between these different mechanisms will be important for managing coastal flood hazards 5 3 management of groundwater flooding on the outer banks the results suggest that the storm driven groundwater pulse could flood more than 10 of the ocean side of the outer banks during an event with a 2 25 m increase in shoreline water level e g 1 00 m storm surge and 6 25 m waves without precipitation fig 11 this estimate is conservative because the initial water table distribution was designed to represent the aquifer under calm ocean conditions the extent of flooding across the barrier would be more severe if the water table had not recovered from a prior storm or rainfall additionally groundwater driven flooding is likely to increase as the water table increases with rising sea levels bjerklie et al 2012 global sea level is predicted to rise between 0 5 and 1 4 m by 2100 and sea level rise along the atlantic coast is predicted to outpace the global estimate sweet et al 2017 sweet et al 2020 consequently owing to sea level rise and the increasing intensity and duration of north atlantic storms patricola and wehner 2018 knutson et al 2020 coastal groundwater driven flooding is expected to present a persistent coastal management challenge structural protections such as seawalls jetties and dikes have been the preferred approach to coastal flood prevention dugan et al 2008 gittman et al 2015 although these protections are effective at mitigating surface water inundation driven by surge waves and tides they do not impede flooding driven by groundwater rotzoll and fletcher 2013 additionally the presence of hardened structures can block the groundwater discharging to the ocean prolonging the post storm recovery of the water table lee et al 2019 flood recovery time is important for assessing the duration of impairment of infrastructure and the vulnerability to future flooding chisolm and matthews 2012 lu et al 2015 abboud et al 2018 and should be addressed in future studies by understanding the processes contributing to flooding coastal managers can assess the effectiveness of different flood mitigation strategies in the town of nags head the iflood project has reinforced the importance of groundwater levels for flood management groundwater flooding is an emerging issue the town has focused on in recent years and several groundwater surface water management projects are being implemented to reduce the frequency and extent of flooding in the town including a groundwater pumping system used to reduce the water table level in advance of major storms 5 4 use of phone apps for research and increasing community awareness iflood reports extended the scope of the study from a single site to a 70 km stretch of the outer banks between duck and rodanthe nc although survey responses and photos are used to exclude cases with surface ponding on impermeable surfaces in some cases the ground surface is difficult to determine in addition the phone gps did not always update automatically and sometimes it was necessary to use the photo to refine the report location in cases where photos were not submitted by the user it was more difficult to evaluate the reliability of the flood report however the flooding reports and photos provided by the application users enabled evaluation of the model for a large region of the outer banks the iflood interface was designed to be simple i e minimal buttons and menus and accessible large font screen reader compatible to reduce barriers to participation and to help minimize likelihood of accidental submission of inaccurate data the town managers and usace frf personnel were active users of the app and provided a reliable source of flood reports nags head was the region with the highest number of flood reports submitted to iflood and was one of the partners involved in designing and advertising the iflood app working directly with the town offices enhanced both the quantity and quality of the data received through the app additionally the citizen science app increased community awareness of coastal flooding issues and helped town managers identify regions in their communities where there are recurrent flooding issues the app also enables citizens of the outer banks to understand the risks associated with living in a flood vulnerable environment and to engage with a persistent issue in their communities approximately 70 residents attended a public presentation regarding groundwater induced flooding and the app which has been installed over 100 times by users presumed to be local residents similar citizen science approaches could be applied to address other issues related to coastal flooding and the town of nags head plans to use iflood as a reference to expand the methods the town uses to engage its citizenry and to bring awareness to emerging issues 6 conclusions three years of groundwater level measurements spanning the 550 m wide barrier island near duck nc were used to evaluate an analytical model to predict the response of the water table to surge wave setup and precipitation during coastal storms the groundwater elevation near the ocean increased more than 1 m during storms with large waves and surge nearly double the magnitude observed in prior studies resulting in inland directed head gradients the bulge of groundwater moved inland causing up to a 0 5 m increase in groundwater levels 310 m inland from the dune a linear analytical theory li et al 2004 without recharge for the propagation of storm pulses in shallow aquifers reproduces the amplitude attenuation and phase change observed across the island for 26 storm events with minimal rainfall nash sutcliffe efficiency coefficients are greater than 0 7 and errors in the modeled maximum water table are less than 0 1 m from the dune to 160 m inland infiltration of precipitation results in approximately a threefold increase in the groundwater level relative to the amount of rainfall the model with recharge reproduces the maximum water table levels within 0 15 m for the single ocean storm with significant rainfall hurricane matthew oct 2016 citizen science reports of flooding submitted with a smartphone app iflood were used to evaluate a regional application of the analytical model with recharge along 70 km of the outer banks of north carolina between sept 2019 and feb 2020 25 reports on the ocean side of the island associated with 7 storms showed flooding on natural pervious land surfaces between corolla and rodanthe nc flooding occurred after storms with large ocean surge and waves with and without significant rainfall the analytical model with recharge predicted flooding events that were consistent with the timing and location for 19 of these reports additionally the iflood app provides a new tool for evaluating groundwater flooding processes across the north carolina outer banks and is a framework that can be modified to address a broader range of scientific objectives e g the role of land surface coverage on flooding sound driven flooding processes the analytical model provides a simple and computationally efficient framework for predicting flooding risk along the ocean side of the barrier island for a hypothetical storm with a 2 25 m increase in shoreline water level the analytical model suggests that more than 10 of the ocean side of the outer banks could be inundated by coastal groundwater flooding in the absence of rainfall precipitation would increase the flooding extent credit authorship contribution statement rachel housego funding acquisition conceptualization methodology formal analysis visualization writing original draft britt raubenheimer funding acquisition conceptualization methodology supervision writing review editing steve elgar funding acquisition conceptualization methodology supervision writing review editing sandy cross conceptualization methodology investigation christian legner conceptualization methodology investigation david ryan conceptualization methodology investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank the usace chl field research facility for ocean and meteorological observations levi gorrell fred marin emmett krupczak heidi wadman jesse mcninch and pat dickhudt for assistance deploying and maintaining the groundwater wells and kent hathaway for assistance with precipitation data we also thank the users of the iflood app who contributed flood reports to this project and we thank two anonymous reviewers for their insightful comments that greatly improved the manuscript funding was provided by the u s coastal research program the national science foundation a national science foundation graduate research fellowship the woods hole oceanographic isp program and a vannevar bush faculty fellowship appendix a analytical groundwater pulse model the spatial and temporal evolutions of the storm driven groundwater pulse are simulated using the analytical solution li et al 2004 a1 h x t 2 a b t ε t p exp b ε t p 2 e r f c x d t ε d ε where h is the groundwater level m x is the cross shore position m positive inland from the x0 well t is time d after the start of the storm defined as the local minima in head level at x0 preceding the storm a is the amplitude of the x0 fluctuation m b is a time factor d 2 b 1 2 represents the duration of the elevated water level at x0 tp is the time of the storm peak at x0 relative to the preceding local minima and d is aquifer diffusivity m2 d the analytical solution assumes a homogeneous and isotropic aquifer consistent with the results of the slug tests that were performed across the barrier island the analytical solution also assumes a shallow aquifer unidirectional horizontal flow negligible capillary effects small pulse amplitude relative to aquifer depth and a vertical beach in addition to time series comparisons the analytical solution is evaluated by comparison with the observed amplitude aj and time of peak water level tp j the local maxima in head after time t0 which ranged from 1 to 9 d at inland locations j the observed 36 hr averaged groundwater fluctuation hj at each location is fit using least squares to a pulse function a2 h j t h 0 j a j exp b j t t p j where h 0 j is the pre storm head level and aj and b j are the pulse amplitude and time factors respectively only the increasing portion of the groundwater level time series is used in the fit because the temporal asymmetry of the draining relative to the filling of the unconfined aquifer often is not consistent with the gaussian pulse assumed by the analytical solution cartwright and gibbes 2011 the resulting squared correlations r2 for the fits are greater than 0 9 for all storms at all locations hurricane matthew is excluded from the pulse propagation analysis because groundwater changes owing to rainfall of 0 2 m obscured the groundwater fluctuation driven by the increase in shoreline water level to estimate analytically the pulse amplitude and time lag as a function of inland position equation a1 is non dimensionalized as a3 h x t 2 t ε exp ε 2 e r f c x t ε d ε in which the non dimensional amplitude attenuation α time lag δϕ time t and cross shore location x at inland locations j computed relative to the x0 well are given by li et al 2004 a4 α a j a δ ϕ t p j t p b a 5 t t t p b a 6 x x 2 d b 1 2 a 7 the aquifer diffusivity is estimated by determining the value that yields the best fit of the analytical solution equation a1 to the observed water table fluctuation and to the observed non dimensional amplitude attenuation and phase lag equations a4 and a5 as a function of non dimensional distance equation a7 for the 26 storm events without heavy rainfall both estimates give similar values for d the effects of rainfall are accounted for in the pulse model assuming linear superposition to yield the analytical model with recharge a8 h x t h 0 j 2 a b t ε t p exp b ε t p 2 e r f c x 2 d t ε d ε r n e where the amount of rainfall during the storm r is assumed spatially uniform and ne is the effective porosity estimated from observations 
4024,compound impacts on water level caused by seiche and high flow in freshwater coastal rivers can result in extreme flood risks a seiche is an oscillation in the lake caused by strong wind or rapid change of atmospheric pressure seiching and high flow can be statistically dependent therefore a copula based joint distribution is used to investigate their compound effects on flooding in a freshwater coastal river a hydrodynamic model is used to predict inundation areas for developing flood probability maps this two fold approach allows the development of a joint probability based flood map resulting from seiche and high flow the methodology is applied to the buffalo river buffalo new york draining into lake erie which is subject to significant seiching results show that seiches can have an impact on flooding and the compounding effects of seiche and high flow can increase the inundation area the study also shows that the present federal emergency management agency fema 100 year flood scenario for the study site is equivalent to compound 100 year high flow and 10 year seiche and the 100 year high flow and corresponding most probable water level slightly larger than the long term average lake level is approximately 7 times more likely to occur than the fema scenario the analysis framework can provide insight into the compounding effects of seiche and high flow on inundation and on the probability of occurrence of such events for overall flood engineering in a freshwater coastal river keywords compound flooding conditional probability copula freshwater coastal river seiche 1 introduction coastal rivers and cities are exposed to flood risks due to extreme hydrological oceanographic and meteorological processes kron 2013 rueda et al 2016 compound flooding is an event that results from multiple drivers and their interactions leonard et al 2014 zscheischler et al 2018 for example it has been observed that low lying coastal cities are vulnerable to flooding due to the combined effect of heavy rainfall and storm tide shen et al 2019 xu et al 2019 studies have been conducted to examine the joint occurrence of different stressors leading to compound flooding in marine systems such as sea level rise fluvial flooding nonstationary climate risks storm surge and astronomical tides bevacqua et al 2019 hawkes et al 2002 moftakhari et al 2017 saharia and sarma 2018 sarhadi et al 2018 wahl et al 2015 in coastal freshwater systems however the processes that can lead to flooding are heavy rainfall possibly with snowmelt and wind setup or seiches and this situation is much less studied a seiche is an oscillation in a partially enclosed body of water that can be observed on lakes reservoirs ponds bays harbors and seas noaa 2018 strong wind and rapid change of atmospheric pressure are typical causes of a seiche other causes can include earthquakes tsunamis and underwater internal waves chapman and giese 1990 cossu et al 2017 giese et al 1982 noaa 2018 lake seiche has been observed at different locations around the world and the first scientific study of this phenomenon was carried out in 1893 by forel and von zeppelin in lake constance which borders germany austria and switzerland kirillin et al 2015 other lakes that are well known for seiches include lake wakatipu in new zealand lake victoria in tanzania uganda and kenya lake baikal in russia lake chapala in mexico lake geneva in switzerland and france and the great lakes of north america cueva et al 2019 farhadzadeh 2017 fish 1957 heath et al 1975 lemmin et al 2005 smirnov et al 2014 trebitz 2006 in the great lakes the frequency and intensity of seiches are expected to increase due to climate change baule et al 2014 and this is a motivation for better understanding the role seiches play in coastal flooding in freshwater systems compound effects on flooding in a freshwater coastal river depend on multiple statistically dependent variables therefore a conventional univariate statistical analysis cannot give accurate information regarding the multivariate nature of these events bevacqua et al 2017 if there is a significant correlation between variables even if it is weak then a joint probability distribution should be conducted as also argued by xu et al 2019 previous studies have evaluated compound flood risks in a coastal environment using joint probability analysis with monte carlo simulation bayesian networks or other statistical methods such as threshold excess point process and conditional methods hawkes et al 2002 leonard et al 2014 zheng et al 2014 for example couasnon et al 2018 built a bayesian network for a coastal watershed their study demonstrated that accounting for multivariate dependence is critical for the accurate representation of flood risk in coastal catchments prone to compound events however the methods used in previous studies such as monte carlo simulation can be very time consuming since many simulations are necessary also a bayesian network approach requires greater statistical expertise jonas et al 2013 other methods e g threshold excess point process and conditional methods assume that in some joint tail region one component is either asymptotically dependent or completely independent of the other component zheng et al 2014 alternatively approaches using copula functions have become increasingly popular as a means of describing the dependence between random variables wang et al 2018 xu et al 2019 a copula is a multivariate cumulative distribution function used to describe the statistical relationship between random variables and to evaluate their joint probability sklar 1973 copulas are considered to be a powerful approach in simplifying multivariate stochastic analysis using distribution functions xu et al 2014 the main benefit of using copula functions is that it allows independent investigation of the marginal properties and dependence structure of each of the random variables grimaldi and serinaldi 2006 copula functions are increasingly used to evaluate compound flooding due to the flexible selection of different marginal distributions to construct the joint distribution function xu et al 2019 zhang et al 2013 for example chowdhary 2010 evaluated the relative performance of various copulas and methods of parameter estimation for multivariate extreme flow and rainfall processes and developed a copula based approach that can advantageously use all available multivariate data in limited hydrological data situations lian et al 2013 used a copula to study the joint impact of rainfall and tidal level on flood risk in a coastal city leonard et al 2014 implemented copula and a compound event framework to understand statistically dependent events storm surge and rainfall bevacqua et al 2017 studied the impact of compound floods as a function of sea and river levels using a pair copula conceptual model that allows for the quantification of the risk through uncertainty analysis for present day and future climate kang et al 2019 built a non stationary copula model based on the change in marginal distribution of hydrological variables and the dependence structure for bivariate flood frequency analysis assessment of the joint impact of extreme rainfall and storm surge and importance of the changing environment on the risk of flooding in coastal areas were also successfully evaluated using copulas xu et al 2014 zellou and rahali 2019 in addition jane et al 2020 showed a framework using dependence analysis bivariate copula analysis and trivariate analysis for assessing the compound flooding based on the statistically significant correlation between extreme rainfall seawater level and groundwater level in coastal areas of south florida that study suggests that the output of the bivariate and trivariate analysis can be used as boundary conditions for coupled hydrologic and hydraulic models for assessing flood risk although the joint probability of heavy rainfall and high tides in marine systems has been analyzed to the best of our knowledge compound flooding in freshwater coastal systems due to seiche and river streamflow has not been studied it is important to understand the combined effects of seiche generated water level downstream and river streamflow upstream as both are critical boundary conditions for flood modeling and forecasting also previous studies mostly focused on the joint probability of storm surge and rainfall but lacked quantification of their combined effects on flooding xu et al 2019 this study fills the research gap by investigating the joint impact of high streamflow and wind seiche processes leading to compound flooding in a freshwater coastal system using a combined statistical and hydrodynamic modeling approach the goal of this study is to characterize the combined effects of seiche and high streamflow discharge on flooding in a freshwater coastal river the buffalo river buffalo new york us is taken as a case study since lake erie which forms the downstream boundary of the river is subject to frequent seiches and adequate data are available for statistical relevance the copula joint distribution is introduced to determine the conditional probability of streamflow discharge and seiche water level at the upstream and downstream boundaries of the river respectively the hydrologic engineering center s river analysis system hec ras model is used to simulate river water levels and flooded areas and the hydraulic performance graph hpg is used to visualize the backwater profile in the river channel under different boundary conditions the framework used here based on copula hydrodynamic model and hpg can be used for other freshwater coastal rivers to understand the compound effects of seiche and high discharge on flooding 2 methodology the methodological framework is shown in fig 1 two logical pathways are shown the seiche driven events are based on the data acquired from frequencies of the lake s seiching modes by farhadzadeh 2017 from the seiche data the annual maximum seiche events were selected the streamflow driven events are based on annual maximum discharge data from united states geological survey usgs stations described below details about data collection are discussed in section 2 2 along the left hand side of fig 1 calculations start with creating marginal distributions of seiche water levels and river discharges and then the joint probability of different discharge values for given different water levels is carried out after considering the non parametric correlation coefficient to investigate dependency this scenario is referred to herein as seiche driven the right hand side follows an alternative approach in which marginal distributions for annual maximum discharge are first evaluated and the probability of different downstream water levels is then considered the joint distribution is carried out similarly for water level and annual maximum discharge values after considering the non parametric correlation coefficient this scenario is referred to as streamflow driven the non parametric dependence measurement i e kendall s tau is used to investigate the functional association among the variables under consideration in seiche driven and streamflow driven scenarios the calculated kendall s tau values are 0 13 and 0 22 respectively representing significance at a confidence level of 95 these results indicate that there is a significant weak correlation between the two variables for both scenarios and therefore a bivariate joint probability distribution based on copula functions is conducted in either approach copula analysis is carried out by constructing marginal and joint probability distribution functions and fitting the data to select the best models see below the first step is creating the marginal distributions for the water level and river discharge as described in section 2 3 1 the copula functions are created from the marginal distributions which are based on selecting the best fit distributions for the data sets used in this study as shown in fig 1 conditional probabilities for water level and high discharge are calculated using these copula functions the preferred approach from the seiche driven or streamflow driven scenarios can be selected based on the flooding severity depending on the upstream and downstream boundary conditions of the river in general it is important to consider both the streamflow and seiche driven scenarios as both can lead to significant flooding therefore the copula analysis along with the probability framework is carried out for both scenarios the copula joint distribution coupled with the probability based framework is useful to quantify the conditional probability of compounding boundary conditions the hec ras model is then used to predict inundation areas that result from different combinations of upstream and downstream boundary conditions the hec ras model results are also used to create the hpg which can be used to conveniently look up water levels under those boundary conditions 2 1 study area the buffalo river is located in western new york state it drains an 1158 km2 area and discharges into the eastern end of lake erie at the city of buffalo fig 2 lake erie is the shallowest of the great lakes and is well known for low frequency seiches noaa 2018 notable events include a 6 7 m seiche event in 1844 that breached a 4 3 m seawall and resulted in the drowning of at least 78 people in buffalo noaa 2018 in 2008 flooding was reported in buffalo due to a powerful storm that created up to 5 m high waves and a storm surge of about 3 m noaa 2018 recently on november 15th 2020 a 2 15 m high seiche was observed in buffalo due to an intense storm over lake erie twc 2020 the river section considered in this study is the 10 km long downstream section flowing immediately into lake erie environ et al 2011 this river section is also known as the buffalo river area of concern aoc ijc 1988 and is regularly dredged by the us army corps of engineers for navigation much of the river in this area has been channelized with vertical sheet metal on the banks resulting in unnaturally high stream bank elevations this feature comes into play when assessing the relative importance of discharge and downstream lake elevation on flooding as described below the aoc includes the 2 3 km 1 4 miles length of the buffalo ship canal environ et al 2011 three tributaries cayuga creek buffalo creek and cazenovia creek join to form the river and each one is gauged by the usgs in fig 2 b the usgs station 04215900 at lake erie buffalo new york and the noaa buffalo station 9063020 are both numbered 1 they are the same station cazenovia creek station at ebenezer 04215500 is numbered 2 buffalo creek station at gardenville 04214500 is numbered 3 and cayuga creek station near lancaster 04215000 is numbered 4 the median discharge and average depth of the buffalo river are 15 m3 s and 6 m respectively and the discharge is highly variable saharia et al 2019 reverse direction flows driven by lake erie water level changes are frequently observed in the river 2 2 data collection lake erie seiche data were acquired for years 1975 to 2017 from an analysis based on noaa data from the buffalo station 9063020 at the eastern end of lake erie this noaa lake station along with the usgs lake station 04215900 is shown in fig 2 as the lake erie station because of the common location the details of the methodology of identifying the frequencies of the lake s seiching modes and the energy corresponding to the low frequency fluctuations are provided by farhadzadeh 2017 the seiche water level data were chosen as the daily maxima based on hourly data the igld85 datum considered for lake erie is 173 5 m noaa 2016 and all water level data used in this study are reported with respect to this datum the long term mean water level considered for lake erie is 0 75 m usace 2016 from the acquired seiche data at the buffalo station the annual maximum seiche events were selected streamflow discharge values were obtained for the same period from each of the three tributaries mentioned above the discharge at the head of the study river reach was calculated as the sum of the three tributaries with each adjusted for the additional drainage area between the gauge and the upstream boundary of the model domain irvine et al 2005 for the streamflow driven scenario annual maximum discharge data were obtained from these usgs stations from 1960 to 2019 an overview of the water level and discharge data for the buffalo river is shown in table 1 since two separate analyses were considered for seiche events and annual peak discharge event boundary conditions i e the two scenarios in fig 1 the maximum available data for each scenario were used the annual maximum discharges for the buffalo river were determined at the river upstream boundary of the model domain and corresponding water levels at lake erie were obtained from the usgs station at lake erie site 1 in fig 2 2 3 copula analysis 2 3 1 marginal and joint distribution the highest accuracy for the constructed copula functions can be obtained by selecting marginal and joint distributions that provide the best fits to the data in this study r language packages fitdistrplus with modified programs to include pearson 3 type distribution copula and vinecopula were used for the selection of the marginal distributions and to obtain the joint distributions the candidate marginal distributions considered were the normal norm two parameter lognormal ln generalized extreme value gev frechet or extreme value 2 ev2 gamma or pearson type 3 p3 and the log pearson type 3 lp3 which are commonly used to describe statistical variations of hydrological parameters laio et al 2009 to obtain a joint cumulative distribution function according to sklar s theorem sklar 1973 if u f x x and v f y y represent the marginal cumulative distribution functions of variables x and y respectively the joint copula function c can be defined as 1 f x y c u v c f x x f y y the candidate bivariate copula functions commonly used for compound flooding include clayton copula gumbel copula frank copula joe copula gaussian copula and student s t copula genest and rivest 1993 huard et al 2006 lian et al 2013 xu et al 2019 table 2 shows the cumulative distribution expressions of each copula function where θ refers to the parameter of the copula function c and u and v represent the marginal cumulative distribution functions for two variables r and s i e river flow and seiche water level respectively in the gaussian copula ρ is the linear correlation coefficient between 1 u and 1 v where 1 is the inverse function of the standard normal distribution function similarly in the student s t copula α is the degree of freedom and ρ is the linear correlation coefficient between t α 1 u and t α 1 v where t α 1 is the inverse function of the distribution function t α 2 3 2 goodness of fit the model selection criteria are based on the akaike information criterion aic corrected akaike information criterion aicc bayesian information criterion bic log likelihood loglik and the anderson darling criterion adc to select the marginal distribution aic aicc and adc are used and for joint distribution loglik aic and bic are used based on recommendations from previous studies which are shown to be suitable for prediction and cross validation and allows consistent estimation of the underlying data generating process laio et al 2009 wang et al 2010 wang et al 2018 for a sample of n data and approximating model m j g j x ϑ the likelihood function evaluated at the point ϑ ϑ can be expressed as laio et al 2009 2 l j ϑ i 1 n g j x i ϑ 3 loglik l n l j ϑ 4 aic j 2 l n l j ϑ 2 p j 5 aicc j 2 l n l j ϑ 2 p j n n p j 1 6 bic j 2 l n l j ϑ l n n p j 7a adc j 0 0403 0 116 δ ad j ξ j β j η ij 0 861 i f 1 2 ξ j δ ad j 7b adc j 0 0403 0 116 0 2 ξ j β j η ij 0 861 δ ad j 0 2 ξ j ξ j i f 1 2 ξ j δ ad j where p j is the number of estimated parameters of the j th operational model δ ad j is the discrepancy measure and ξ j β j η ij are distribution dependent coefficients tabulated by laio 2004 2 3 3 conditional probability copulas generally generate a semi interval e g s s 2 r r 2 for each dependent variable in order to find a complete interval for a dependent variable equation 8a is used for the seiche driven scenario and 8b is used for the discharge driven scenario 8a p r r 0 s 1 s s 2 f s 2 f s 1 f r 0 s 2 f r 0 s 1 8b p s s 0 r 1 r r 2 f r 2 f r 1 f s 0 r 2 f s 0 r 1 where r 0 and s 0 are specific river discharge and seiche water level values respectively f s 2 and f s 1 are the marginal distributions of seiche water levels and f r 2 and f r 1 are the marginal distributions of river discharges f r 0 s 1 f r 0 s 2 f s 0 r 2 and f s 0 r 1 are the joint distributions 2 4 hec ras model a hec ras model of the buffalo river developed by limnotech environ et al 2011 was used to simulate river hydraulics and flooding the model was originally used to conduct hydraulic investigations including flood evaluations and remedial options in support of the great lakes national program office glnpo legacy act process us epa 2020 this model can be used for flood evaluation under different seiche conditions as the lake erie water surface elevation is used as the downstream boundary condition it was assumed that variations in water level occur on a long enough time scale that the steady state assumption for hec ras is valid the hec ras model was used to generate the hpg a convenient plot to summarize the water level at a given location for all possible upstream and downstream boundary conditions the hpg comprises hydraulic performance curves hpc showing the backwater relationship assuming a constant average slope between upstream and downstream water depths as a function of channel discharge yen and gonzález castro 2000 3 results and discussion 3 1 marginal distributions marginal distribution fitting tests for seiche driven and streamflow driven event scenarios are shown in table 3 the best marginal distribution models are selected based on the lowest value of aic aicc bic and adc boldface in table 3 in the seiche driven scenario the pearson type 3 distribution provides the best fit to the data for the seiche water level marginal distribution while the lognormal distribution provides the best fit for the river discharge distribution in the streamflow driven scenario the lognormal distribution is selected for both the river discharge and downstream water level 3 2 joint distributions the best joint distribution models are selected using the highest loglik and lowest aic and bic values boldface in table 4 joe and kurowicka 2011 in the seiche driven scenario the frank copula is found to provide the best fit for annual maximum seiche water level and corresponding river discharge see table 4 in the streamflow driven scenario the clayton copula is found to provide the best fit for annual maximum river discharges and corresponding downstream water levels a comparison of empirical and theoretical frequencies is shown in fig 3 for both scenarios in both cases there is a reasonable fit with root mean square error rmse values of 0 0647 and 0 0604 for the seiche driven and streamflow driven cases respectively the joint cumulative distributions are shown in fig 4 using the frank copula for the seiche driven scenario fig 4 a and the clayton copula for the streamflow driven scenario fig 4 b from fig 4 a it can be seen that most of the seiche water level data are in the range of 1 5 m to 2 5 m 3 3 conditional probability of seiche driven scenarios fig 5 shows the probability of seiche water level and river discharge interval occurring jointly the seiche water level intervals are from 1 5 m to 4 m the lower limit is chosen based on results in fig 4 a showing most of the seiche water levels to be above this value and the higher limit is based on the largest seiche observed at this site which is the previously mentioned event in 1844 when a 4 3 m high seawall was breached noaa 2018 the interval width for flow is 20 m3 s and the largest interval is up to 285 305 m3 s when the conditional probability drops below 1 for all scenarios 305 m3 s represents a 1 5 year return period flood based on a frequency analysis of the annual maximum discharges for the buffalo river the seiche water level of 1 5 m shows the highest probability of occurrence 27 2 for the discharge interval of 5 to 25 m3 s as the river discharge increases the conditional probability decreases it is worth noting that the median daily discharge of the river is approximately 15 m3 s falling into the highest probability 5 25 m3 s interval the conditional probability of discharge occurring in the 285 305 m3 s interval under the 1 5 m seiche water level decreases to 0 57 as seiche water level increases the values of conditional probability generally decrease because the probability of a higher water level is smaller it is observed that when the seiche water level is at 3 or 4 m the conditional probability is 0 12 or 0 002 respectively for the 5 to 25 m3 s interval and decreases further with higher discharge the ratio of the conditional probability between the 5 25 m3 s and 285 305 m3 s intervals under different seiche scenarios is shown in table 5 the ratio decreases as the seiche water level increases indicating that the probability of high river discharge i e 285 305 m3 s compared to that of normal river discharge i e 5 25 m3 s actually increases as the seiche water level increases the ratio drops greatly from 47 5 to 39 5 when the water level increases from 1 5 m to 2 m when the water level is higher than 2 m further changes become small this finding implies that although normal discharge is always the most probable higher discharge becomes relatively more probable as seiche occurs likely because the heavy wind on lake erie that caused a seiche could also be related to storms in the buffalo river watershed 3 4 conditional probability of streamflow driven scenarios fig 6 shows the results for different high discharges between 200 m3 s and 1000 m3 s 200 m3 s and 1000 m3 s represent the lowest annual peak flow and the 100 year flood flow respectively for the buffalo river a unimodal shape for conditional probability is observed for all discharges and the selected downstream water level intervals the peak for all different discharge scenarios is observed at the 0 75 to 1 m water level interval with the long term average lake level being 0 75 m the peak probability value decreases from 22 6 to 0 84 as discharge increases from 200 m3 s to 1000 m3 s the highest water level interval considered in fig 6 is 2 75 to 3 m since the 100 year seiche water level is 2 76 m the conditional probabilities of the 2 75 to 3 m water level interval are 0 66 0 62 0 12 and 0 03 under 200 400 800 and 1000 m3 s discharges respectively similar to the seiche driven scenarios since each curve shows the probability of two events occurring jointly the curve for a larger discharge e g 1000 m3 s generally is lower than that for a smaller discharge 3 5 flood map flood maps produced by the fema are based on hydraulic modeling to produce water levels along a river reach the hydraulic modeling in turn depends on discharge and water level at the upstream and downstream boundaries respectively flood insurance rates are then determined as a function of whether a structure is within the 100 year floodplain which is normally based on the discharge the fema map for the buffalo river is based on the 100 year discharge and a downstream water level of 2 22 m this water level represents an extreme lake level approximately 1 5 m higher than the long term average of 0 75 m it may be supposed that using an extreme water level should provide a conservative or worst case scenario for flooding prediction here we investigate the impact of conditional probabilities on the predicted flood areas for a 100 year event the copula based methodology incorporates the joint distribution for both the upstream discharge and downstream water level boundary conditions rather than a flood map based on the marginal distribution of the discharge data only fig 7 represents the inundation areas under four scenarios a long term average lake level s 0 75 m and median discharge r 15 m3 s b 10 year flood flow r 736 m3 s and 100 year seiche s 2 76 m c 100 year flood flow r 1056 m3 s and 10 year seiche s 2 22 m and d 100 year flood flow r 1056 m3 s and 100 year seiche s 2 76 m table 6 it should be noted that the fema 100 year flood map is generated using conditions almost equivalent to scenario c from the conditional probability analysis described in section 3 4 the most probable downstream water level interval under the 100 year flow should be 0 75 1 m which is more probable than a higher water level interval like the 10 year seiche equivalent with the interval width of 0 25 m for copula computation the 2 1 2 35 m interval and the 2 63 2 88 m interval are used for a 10 year seiche and a 100 year seiche respectively p r 1056 0 75 s 1 p r 1056 2 1 s 2 35 is approximately equal to 7 meaning the 100 year flood flow and the most probable water level slightly larger than the long term average lake level is approximately 7 times more likely to occur than the fema scenario similarly p r 1056 0 75 s 1 p r 736 2 63 s 2 88 3 and p r 1056 0 75 s 1 p r 1056 2 63 s 2 88 20 which indicates that the 100 year flood flow and the most probable water level is likely to occur 3 and 20 times more frequently than cases b and d respectively from fig 7 it is observed that most of the flooding occurs upstream of the study area when comparing cases 7 b 10 year flood flow and 100 year seiche and 7 c 100 year flood flow and 10 year seiche the 7 c scenario is associated with more upstream flooding therefore in the case of the buffalo river the streamflow driven scenario should be considered for flood analysis and flooding is much more of a concern in upstream areas rather than downstream it is also observed from fig 9 that due to the high downstream bank elevation a seiche is less of a concern for flooding the seiche driven scenario may still be used to look into seiche event conditional probability for the range of available data but not for the flood analysis where high flood flow data corresponding to seiche events are unavailable fig 8 shows the flood inundation area as a function of the seiche water level and discharge the affected inundation area is 2 4 km2 for a 100 year flood with long term average lake level similarly an inundation area of 0 25 km2 is associated with the 100 year seiche water level 2 76 m with the median flow in other words an increase of 860 in inundation area is caused by the 100 year flood with long term average lake level compared with the 100 year seiche with the median flow generally high discharge has a stronger impact on the inundation area than a seiche with the same return period a seiche of 2 m can cause only 0 03 km2 of inundation if the median flow is present in the river however with a 2 year flood a 2 m seiche can cause 0 57 km2 inundation an increase in the inundation area of 1800 similarly a 2 year flood with an average lake level has an inundation area of 0 26 km2 but if the same 2 year flood compounds with a 100 year seiche then the inundation area increases by 230 to 0 86 km2 the fema scenario in fig 7 c along with the 100 year seiche 10 year flood in fig 7 b and 100 year seiche 100 year flood scenario in fig 7 d are shown in fig 8 with inundation area on the vertical axis the figure shows that the inundation area for the fema scenario is 2 85 km2 for the 100 year seiche and 100 year flood scenario and 100 year seiche and 10 year flood the inundation areas are 3 1 km2 and 1 95 km2 respectively the fema scenario is thus seen to produce a lower water level compared to the 100 year seiche 100 year flood scenario from the copula analysis the most probable flood scenario for the 100 year flood flow is with the water level in the 0 75 1 m range therefore from fig 8 the most probable 100 year flood flow with the 0 75 1 m water level flood will cause an inundation of 2 4 2 5 km2 compared to 2 85 km2 in the fema scenario 3 6 hydraulic performance graph hpg the hydraulic performance curves hpcs for discharges ranging from 15 m3 s to 1000 m3 s are shown in fig 9 the hpg provides a convenient way to look up water level at the upstream boundary as in fig 9 or at any given location can be created separately under all combinations of compound flood scenarios the igld85 datum is used in fig 9 which represents a low water level the hpcs are bounded by the 45 degree straight line on the right labelled as the z line the z line represents a horizontal water surface for which there is no flow the n line represents the locus of normal flow profiles and it divides the hpcs into two regions the region between the n line and z line contains the pairs of upstream and downstream water levels corresponding to all possible m1 type profiles whereas the region between the vertical axis and the n line contains the pairs of water levels corresponding to all m2 type profiles yen and gonzález castro 2000 fig 9 shows that there will always be an m1 type profile in the river for discharges less than 400 m3 s while for discharges larger than 800 m3 s the profile will always be m2 type for a 600 m3 s discharge the profile switches from m2 to m1 when the downstream water level is at 1 5 m with a corresponding upstream water level of 2 2 m the flow profile analysis enables engineers to learn beforehand the possible flow profiles associated with the downstream seiche and upstream flow boundary conditions it is also useful to learn about these flow profiles before constructing any weirs dams or control structures in the river m1 profiles are considered common water surface profiles where mild slope streams enter a pool while m2 profiles occur at a sudden drop of the channel or the channel outlet into a lake if the slope becomes steeper chaudhry 2008 though the flow profile depends on the channel slope it is observed from this study that the seiche and upstream flow boundary conditions can alter the river flow profile the upstream and downstream bank elevations also are marked in fig 9 note that much of the buffalo river has hard siding installed with unnaturally high stream bank elevations it is observed from the hpcs that as discharge increases from 600 m3 s to 1000 m3 s it is more likely that water surface elevation will overtop the upstream bank first this effect also is evident in fig 7 4 conclusions the compound flooding due to seiche i e high downstream water level and high discharge can have an enormous impact on a community near a coastal freshwater river this study assessed these effects on flooding in a freshwater coastal river using copula probability and a hydrodynamic model the probability based framework proposed in this study can be applied to quantify the conditional probability of compounding boundary conditions for any freshwater coastal river the following conclusions are made i this study provides a framework for determining the probability of occurrence of a set of upstream and downstream boundary conditions for a hydrodynamic model which can be used for creating flood maps for a freshwater coastal river this proposed copula based framework provides insight into the compounding effects of seiches and high discharge on inundation and the probability of occurrence of such events it is shown that seiches can have an impact on flooding in a freshwater coastal river and the compounding effects of seiche and high discharge can increase the inundation area ii the streamflow driven scenario is considered over the seiche driven scenario for the buffalo river as flooding is much more of a concern upstream than downstream because of the artificially high downstream bank height in general however both streamflow and seiche driven scenarios should be considered since the seiche driven scenario can be very important if the downstream bank is not high enough iii the fema 100 year flood map is probably safe against flooding of the buffalo river as the likeliness of occurrence of the 100 year flood flow with the most probable water level is 7 times that of the fema 100 year flood iv seiche driven and streamflow driven scenarios can be associated with different types of backwater profiles in a river for the buffalo river streamflow driven scenarios with river discharge greater than 800 m3 s will always be associated with an m2 type profile in the case of seiche driven scenarios with river discharges less than 400 m3 s the profile is always m1 type the hpg can be used to assess these profiles and conveniently present water level at any given location under all possible combinations of the compound floods v it should be noted that the conditional probabilities from the streamflow driven and seiche driven are not directly comparable due to the different forms of computation equations 8a and 8b respectively both computations depend on choices of intervals s in 8a and r in 8b so the conditional probabilities from the two scenarios are neither similar nor comparable moreover the present framework considers these two scenarios separately future work is needed to integrate them in order to obtain a more comprehensive and accurate flood frequency and risk analysis credit authorship contribution statement angshuman m saharia conceptualization methodology formal analysis investigation writing original draft writing review editing visualization zhenduo zhu conceptualization methodology writing original draft writing review editing supervision joseph f atkinson conceptualization methodology writing original draft writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement a m saharia was supported by the new york state energy research and development authority project 105162 we would like to acknowledge dr ali farhadzadeh for providing the seiche data and the united states army corps of engineers for providing the hec ras model we would also like to thank dr leizhi wang and dr erdinc sogut for helping us preparing the data the opinions and findings presented in this paper are solely those of the authors and do not represent the opinions of any state and federal agency mentioned in the manuscript 
4024,compound impacts on water level caused by seiche and high flow in freshwater coastal rivers can result in extreme flood risks a seiche is an oscillation in the lake caused by strong wind or rapid change of atmospheric pressure seiching and high flow can be statistically dependent therefore a copula based joint distribution is used to investigate their compound effects on flooding in a freshwater coastal river a hydrodynamic model is used to predict inundation areas for developing flood probability maps this two fold approach allows the development of a joint probability based flood map resulting from seiche and high flow the methodology is applied to the buffalo river buffalo new york draining into lake erie which is subject to significant seiching results show that seiches can have an impact on flooding and the compounding effects of seiche and high flow can increase the inundation area the study also shows that the present federal emergency management agency fema 100 year flood scenario for the study site is equivalent to compound 100 year high flow and 10 year seiche and the 100 year high flow and corresponding most probable water level slightly larger than the long term average lake level is approximately 7 times more likely to occur than the fema scenario the analysis framework can provide insight into the compounding effects of seiche and high flow on inundation and on the probability of occurrence of such events for overall flood engineering in a freshwater coastal river keywords compound flooding conditional probability copula freshwater coastal river seiche 1 introduction coastal rivers and cities are exposed to flood risks due to extreme hydrological oceanographic and meteorological processes kron 2013 rueda et al 2016 compound flooding is an event that results from multiple drivers and their interactions leonard et al 2014 zscheischler et al 2018 for example it has been observed that low lying coastal cities are vulnerable to flooding due to the combined effect of heavy rainfall and storm tide shen et al 2019 xu et al 2019 studies have been conducted to examine the joint occurrence of different stressors leading to compound flooding in marine systems such as sea level rise fluvial flooding nonstationary climate risks storm surge and astronomical tides bevacqua et al 2019 hawkes et al 2002 moftakhari et al 2017 saharia and sarma 2018 sarhadi et al 2018 wahl et al 2015 in coastal freshwater systems however the processes that can lead to flooding are heavy rainfall possibly with snowmelt and wind setup or seiches and this situation is much less studied a seiche is an oscillation in a partially enclosed body of water that can be observed on lakes reservoirs ponds bays harbors and seas noaa 2018 strong wind and rapid change of atmospheric pressure are typical causes of a seiche other causes can include earthquakes tsunamis and underwater internal waves chapman and giese 1990 cossu et al 2017 giese et al 1982 noaa 2018 lake seiche has been observed at different locations around the world and the first scientific study of this phenomenon was carried out in 1893 by forel and von zeppelin in lake constance which borders germany austria and switzerland kirillin et al 2015 other lakes that are well known for seiches include lake wakatipu in new zealand lake victoria in tanzania uganda and kenya lake baikal in russia lake chapala in mexico lake geneva in switzerland and france and the great lakes of north america cueva et al 2019 farhadzadeh 2017 fish 1957 heath et al 1975 lemmin et al 2005 smirnov et al 2014 trebitz 2006 in the great lakes the frequency and intensity of seiches are expected to increase due to climate change baule et al 2014 and this is a motivation for better understanding the role seiches play in coastal flooding in freshwater systems compound effects on flooding in a freshwater coastal river depend on multiple statistically dependent variables therefore a conventional univariate statistical analysis cannot give accurate information regarding the multivariate nature of these events bevacqua et al 2017 if there is a significant correlation between variables even if it is weak then a joint probability distribution should be conducted as also argued by xu et al 2019 previous studies have evaluated compound flood risks in a coastal environment using joint probability analysis with monte carlo simulation bayesian networks or other statistical methods such as threshold excess point process and conditional methods hawkes et al 2002 leonard et al 2014 zheng et al 2014 for example couasnon et al 2018 built a bayesian network for a coastal watershed their study demonstrated that accounting for multivariate dependence is critical for the accurate representation of flood risk in coastal catchments prone to compound events however the methods used in previous studies such as monte carlo simulation can be very time consuming since many simulations are necessary also a bayesian network approach requires greater statistical expertise jonas et al 2013 other methods e g threshold excess point process and conditional methods assume that in some joint tail region one component is either asymptotically dependent or completely independent of the other component zheng et al 2014 alternatively approaches using copula functions have become increasingly popular as a means of describing the dependence between random variables wang et al 2018 xu et al 2019 a copula is a multivariate cumulative distribution function used to describe the statistical relationship between random variables and to evaluate their joint probability sklar 1973 copulas are considered to be a powerful approach in simplifying multivariate stochastic analysis using distribution functions xu et al 2014 the main benefit of using copula functions is that it allows independent investigation of the marginal properties and dependence structure of each of the random variables grimaldi and serinaldi 2006 copula functions are increasingly used to evaluate compound flooding due to the flexible selection of different marginal distributions to construct the joint distribution function xu et al 2019 zhang et al 2013 for example chowdhary 2010 evaluated the relative performance of various copulas and methods of parameter estimation for multivariate extreme flow and rainfall processes and developed a copula based approach that can advantageously use all available multivariate data in limited hydrological data situations lian et al 2013 used a copula to study the joint impact of rainfall and tidal level on flood risk in a coastal city leonard et al 2014 implemented copula and a compound event framework to understand statistically dependent events storm surge and rainfall bevacqua et al 2017 studied the impact of compound floods as a function of sea and river levels using a pair copula conceptual model that allows for the quantification of the risk through uncertainty analysis for present day and future climate kang et al 2019 built a non stationary copula model based on the change in marginal distribution of hydrological variables and the dependence structure for bivariate flood frequency analysis assessment of the joint impact of extreme rainfall and storm surge and importance of the changing environment on the risk of flooding in coastal areas were also successfully evaluated using copulas xu et al 2014 zellou and rahali 2019 in addition jane et al 2020 showed a framework using dependence analysis bivariate copula analysis and trivariate analysis for assessing the compound flooding based on the statistically significant correlation between extreme rainfall seawater level and groundwater level in coastal areas of south florida that study suggests that the output of the bivariate and trivariate analysis can be used as boundary conditions for coupled hydrologic and hydraulic models for assessing flood risk although the joint probability of heavy rainfall and high tides in marine systems has been analyzed to the best of our knowledge compound flooding in freshwater coastal systems due to seiche and river streamflow has not been studied it is important to understand the combined effects of seiche generated water level downstream and river streamflow upstream as both are critical boundary conditions for flood modeling and forecasting also previous studies mostly focused on the joint probability of storm surge and rainfall but lacked quantification of their combined effects on flooding xu et al 2019 this study fills the research gap by investigating the joint impact of high streamflow and wind seiche processes leading to compound flooding in a freshwater coastal system using a combined statistical and hydrodynamic modeling approach the goal of this study is to characterize the combined effects of seiche and high streamflow discharge on flooding in a freshwater coastal river the buffalo river buffalo new york us is taken as a case study since lake erie which forms the downstream boundary of the river is subject to frequent seiches and adequate data are available for statistical relevance the copula joint distribution is introduced to determine the conditional probability of streamflow discharge and seiche water level at the upstream and downstream boundaries of the river respectively the hydrologic engineering center s river analysis system hec ras model is used to simulate river water levels and flooded areas and the hydraulic performance graph hpg is used to visualize the backwater profile in the river channel under different boundary conditions the framework used here based on copula hydrodynamic model and hpg can be used for other freshwater coastal rivers to understand the compound effects of seiche and high discharge on flooding 2 methodology the methodological framework is shown in fig 1 two logical pathways are shown the seiche driven events are based on the data acquired from frequencies of the lake s seiching modes by farhadzadeh 2017 from the seiche data the annual maximum seiche events were selected the streamflow driven events are based on annual maximum discharge data from united states geological survey usgs stations described below details about data collection are discussed in section 2 2 along the left hand side of fig 1 calculations start with creating marginal distributions of seiche water levels and river discharges and then the joint probability of different discharge values for given different water levels is carried out after considering the non parametric correlation coefficient to investigate dependency this scenario is referred to herein as seiche driven the right hand side follows an alternative approach in which marginal distributions for annual maximum discharge are first evaluated and the probability of different downstream water levels is then considered the joint distribution is carried out similarly for water level and annual maximum discharge values after considering the non parametric correlation coefficient this scenario is referred to as streamflow driven the non parametric dependence measurement i e kendall s tau is used to investigate the functional association among the variables under consideration in seiche driven and streamflow driven scenarios the calculated kendall s tau values are 0 13 and 0 22 respectively representing significance at a confidence level of 95 these results indicate that there is a significant weak correlation between the two variables for both scenarios and therefore a bivariate joint probability distribution based on copula functions is conducted in either approach copula analysis is carried out by constructing marginal and joint probability distribution functions and fitting the data to select the best models see below the first step is creating the marginal distributions for the water level and river discharge as described in section 2 3 1 the copula functions are created from the marginal distributions which are based on selecting the best fit distributions for the data sets used in this study as shown in fig 1 conditional probabilities for water level and high discharge are calculated using these copula functions the preferred approach from the seiche driven or streamflow driven scenarios can be selected based on the flooding severity depending on the upstream and downstream boundary conditions of the river in general it is important to consider both the streamflow and seiche driven scenarios as both can lead to significant flooding therefore the copula analysis along with the probability framework is carried out for both scenarios the copula joint distribution coupled with the probability based framework is useful to quantify the conditional probability of compounding boundary conditions the hec ras model is then used to predict inundation areas that result from different combinations of upstream and downstream boundary conditions the hec ras model results are also used to create the hpg which can be used to conveniently look up water levels under those boundary conditions 2 1 study area the buffalo river is located in western new york state it drains an 1158 km2 area and discharges into the eastern end of lake erie at the city of buffalo fig 2 lake erie is the shallowest of the great lakes and is well known for low frequency seiches noaa 2018 notable events include a 6 7 m seiche event in 1844 that breached a 4 3 m seawall and resulted in the drowning of at least 78 people in buffalo noaa 2018 in 2008 flooding was reported in buffalo due to a powerful storm that created up to 5 m high waves and a storm surge of about 3 m noaa 2018 recently on november 15th 2020 a 2 15 m high seiche was observed in buffalo due to an intense storm over lake erie twc 2020 the river section considered in this study is the 10 km long downstream section flowing immediately into lake erie environ et al 2011 this river section is also known as the buffalo river area of concern aoc ijc 1988 and is regularly dredged by the us army corps of engineers for navigation much of the river in this area has been channelized with vertical sheet metal on the banks resulting in unnaturally high stream bank elevations this feature comes into play when assessing the relative importance of discharge and downstream lake elevation on flooding as described below the aoc includes the 2 3 km 1 4 miles length of the buffalo ship canal environ et al 2011 three tributaries cayuga creek buffalo creek and cazenovia creek join to form the river and each one is gauged by the usgs in fig 2 b the usgs station 04215900 at lake erie buffalo new york and the noaa buffalo station 9063020 are both numbered 1 they are the same station cazenovia creek station at ebenezer 04215500 is numbered 2 buffalo creek station at gardenville 04214500 is numbered 3 and cayuga creek station near lancaster 04215000 is numbered 4 the median discharge and average depth of the buffalo river are 15 m3 s and 6 m respectively and the discharge is highly variable saharia et al 2019 reverse direction flows driven by lake erie water level changes are frequently observed in the river 2 2 data collection lake erie seiche data were acquired for years 1975 to 2017 from an analysis based on noaa data from the buffalo station 9063020 at the eastern end of lake erie this noaa lake station along with the usgs lake station 04215900 is shown in fig 2 as the lake erie station because of the common location the details of the methodology of identifying the frequencies of the lake s seiching modes and the energy corresponding to the low frequency fluctuations are provided by farhadzadeh 2017 the seiche water level data were chosen as the daily maxima based on hourly data the igld85 datum considered for lake erie is 173 5 m noaa 2016 and all water level data used in this study are reported with respect to this datum the long term mean water level considered for lake erie is 0 75 m usace 2016 from the acquired seiche data at the buffalo station the annual maximum seiche events were selected streamflow discharge values were obtained for the same period from each of the three tributaries mentioned above the discharge at the head of the study river reach was calculated as the sum of the three tributaries with each adjusted for the additional drainage area between the gauge and the upstream boundary of the model domain irvine et al 2005 for the streamflow driven scenario annual maximum discharge data were obtained from these usgs stations from 1960 to 2019 an overview of the water level and discharge data for the buffalo river is shown in table 1 since two separate analyses were considered for seiche events and annual peak discharge event boundary conditions i e the two scenarios in fig 1 the maximum available data for each scenario were used the annual maximum discharges for the buffalo river were determined at the river upstream boundary of the model domain and corresponding water levels at lake erie were obtained from the usgs station at lake erie site 1 in fig 2 2 3 copula analysis 2 3 1 marginal and joint distribution the highest accuracy for the constructed copula functions can be obtained by selecting marginal and joint distributions that provide the best fits to the data in this study r language packages fitdistrplus with modified programs to include pearson 3 type distribution copula and vinecopula were used for the selection of the marginal distributions and to obtain the joint distributions the candidate marginal distributions considered were the normal norm two parameter lognormal ln generalized extreme value gev frechet or extreme value 2 ev2 gamma or pearson type 3 p3 and the log pearson type 3 lp3 which are commonly used to describe statistical variations of hydrological parameters laio et al 2009 to obtain a joint cumulative distribution function according to sklar s theorem sklar 1973 if u f x x and v f y y represent the marginal cumulative distribution functions of variables x and y respectively the joint copula function c can be defined as 1 f x y c u v c f x x f y y the candidate bivariate copula functions commonly used for compound flooding include clayton copula gumbel copula frank copula joe copula gaussian copula and student s t copula genest and rivest 1993 huard et al 2006 lian et al 2013 xu et al 2019 table 2 shows the cumulative distribution expressions of each copula function where θ refers to the parameter of the copula function c and u and v represent the marginal cumulative distribution functions for two variables r and s i e river flow and seiche water level respectively in the gaussian copula ρ is the linear correlation coefficient between 1 u and 1 v where 1 is the inverse function of the standard normal distribution function similarly in the student s t copula α is the degree of freedom and ρ is the linear correlation coefficient between t α 1 u and t α 1 v where t α 1 is the inverse function of the distribution function t α 2 3 2 goodness of fit the model selection criteria are based on the akaike information criterion aic corrected akaike information criterion aicc bayesian information criterion bic log likelihood loglik and the anderson darling criterion adc to select the marginal distribution aic aicc and adc are used and for joint distribution loglik aic and bic are used based on recommendations from previous studies which are shown to be suitable for prediction and cross validation and allows consistent estimation of the underlying data generating process laio et al 2009 wang et al 2010 wang et al 2018 for a sample of n data and approximating model m j g j x ϑ the likelihood function evaluated at the point ϑ ϑ can be expressed as laio et al 2009 2 l j ϑ i 1 n g j x i ϑ 3 loglik l n l j ϑ 4 aic j 2 l n l j ϑ 2 p j 5 aicc j 2 l n l j ϑ 2 p j n n p j 1 6 bic j 2 l n l j ϑ l n n p j 7a adc j 0 0403 0 116 δ ad j ξ j β j η ij 0 861 i f 1 2 ξ j δ ad j 7b adc j 0 0403 0 116 0 2 ξ j β j η ij 0 861 δ ad j 0 2 ξ j ξ j i f 1 2 ξ j δ ad j where p j is the number of estimated parameters of the j th operational model δ ad j is the discrepancy measure and ξ j β j η ij are distribution dependent coefficients tabulated by laio 2004 2 3 3 conditional probability copulas generally generate a semi interval e g s s 2 r r 2 for each dependent variable in order to find a complete interval for a dependent variable equation 8a is used for the seiche driven scenario and 8b is used for the discharge driven scenario 8a p r r 0 s 1 s s 2 f s 2 f s 1 f r 0 s 2 f r 0 s 1 8b p s s 0 r 1 r r 2 f r 2 f r 1 f s 0 r 2 f s 0 r 1 where r 0 and s 0 are specific river discharge and seiche water level values respectively f s 2 and f s 1 are the marginal distributions of seiche water levels and f r 2 and f r 1 are the marginal distributions of river discharges f r 0 s 1 f r 0 s 2 f s 0 r 2 and f s 0 r 1 are the joint distributions 2 4 hec ras model a hec ras model of the buffalo river developed by limnotech environ et al 2011 was used to simulate river hydraulics and flooding the model was originally used to conduct hydraulic investigations including flood evaluations and remedial options in support of the great lakes national program office glnpo legacy act process us epa 2020 this model can be used for flood evaluation under different seiche conditions as the lake erie water surface elevation is used as the downstream boundary condition it was assumed that variations in water level occur on a long enough time scale that the steady state assumption for hec ras is valid the hec ras model was used to generate the hpg a convenient plot to summarize the water level at a given location for all possible upstream and downstream boundary conditions the hpg comprises hydraulic performance curves hpc showing the backwater relationship assuming a constant average slope between upstream and downstream water depths as a function of channel discharge yen and gonzález castro 2000 3 results and discussion 3 1 marginal distributions marginal distribution fitting tests for seiche driven and streamflow driven event scenarios are shown in table 3 the best marginal distribution models are selected based on the lowest value of aic aicc bic and adc boldface in table 3 in the seiche driven scenario the pearson type 3 distribution provides the best fit to the data for the seiche water level marginal distribution while the lognormal distribution provides the best fit for the river discharge distribution in the streamflow driven scenario the lognormal distribution is selected for both the river discharge and downstream water level 3 2 joint distributions the best joint distribution models are selected using the highest loglik and lowest aic and bic values boldface in table 4 joe and kurowicka 2011 in the seiche driven scenario the frank copula is found to provide the best fit for annual maximum seiche water level and corresponding river discharge see table 4 in the streamflow driven scenario the clayton copula is found to provide the best fit for annual maximum river discharges and corresponding downstream water levels a comparison of empirical and theoretical frequencies is shown in fig 3 for both scenarios in both cases there is a reasonable fit with root mean square error rmse values of 0 0647 and 0 0604 for the seiche driven and streamflow driven cases respectively the joint cumulative distributions are shown in fig 4 using the frank copula for the seiche driven scenario fig 4 a and the clayton copula for the streamflow driven scenario fig 4 b from fig 4 a it can be seen that most of the seiche water level data are in the range of 1 5 m to 2 5 m 3 3 conditional probability of seiche driven scenarios fig 5 shows the probability of seiche water level and river discharge interval occurring jointly the seiche water level intervals are from 1 5 m to 4 m the lower limit is chosen based on results in fig 4 a showing most of the seiche water levels to be above this value and the higher limit is based on the largest seiche observed at this site which is the previously mentioned event in 1844 when a 4 3 m high seawall was breached noaa 2018 the interval width for flow is 20 m3 s and the largest interval is up to 285 305 m3 s when the conditional probability drops below 1 for all scenarios 305 m3 s represents a 1 5 year return period flood based on a frequency analysis of the annual maximum discharges for the buffalo river the seiche water level of 1 5 m shows the highest probability of occurrence 27 2 for the discharge interval of 5 to 25 m3 s as the river discharge increases the conditional probability decreases it is worth noting that the median daily discharge of the river is approximately 15 m3 s falling into the highest probability 5 25 m3 s interval the conditional probability of discharge occurring in the 285 305 m3 s interval under the 1 5 m seiche water level decreases to 0 57 as seiche water level increases the values of conditional probability generally decrease because the probability of a higher water level is smaller it is observed that when the seiche water level is at 3 or 4 m the conditional probability is 0 12 or 0 002 respectively for the 5 to 25 m3 s interval and decreases further with higher discharge the ratio of the conditional probability between the 5 25 m3 s and 285 305 m3 s intervals under different seiche scenarios is shown in table 5 the ratio decreases as the seiche water level increases indicating that the probability of high river discharge i e 285 305 m3 s compared to that of normal river discharge i e 5 25 m3 s actually increases as the seiche water level increases the ratio drops greatly from 47 5 to 39 5 when the water level increases from 1 5 m to 2 m when the water level is higher than 2 m further changes become small this finding implies that although normal discharge is always the most probable higher discharge becomes relatively more probable as seiche occurs likely because the heavy wind on lake erie that caused a seiche could also be related to storms in the buffalo river watershed 3 4 conditional probability of streamflow driven scenarios fig 6 shows the results for different high discharges between 200 m3 s and 1000 m3 s 200 m3 s and 1000 m3 s represent the lowest annual peak flow and the 100 year flood flow respectively for the buffalo river a unimodal shape for conditional probability is observed for all discharges and the selected downstream water level intervals the peak for all different discharge scenarios is observed at the 0 75 to 1 m water level interval with the long term average lake level being 0 75 m the peak probability value decreases from 22 6 to 0 84 as discharge increases from 200 m3 s to 1000 m3 s the highest water level interval considered in fig 6 is 2 75 to 3 m since the 100 year seiche water level is 2 76 m the conditional probabilities of the 2 75 to 3 m water level interval are 0 66 0 62 0 12 and 0 03 under 200 400 800 and 1000 m3 s discharges respectively similar to the seiche driven scenarios since each curve shows the probability of two events occurring jointly the curve for a larger discharge e g 1000 m3 s generally is lower than that for a smaller discharge 3 5 flood map flood maps produced by the fema are based on hydraulic modeling to produce water levels along a river reach the hydraulic modeling in turn depends on discharge and water level at the upstream and downstream boundaries respectively flood insurance rates are then determined as a function of whether a structure is within the 100 year floodplain which is normally based on the discharge the fema map for the buffalo river is based on the 100 year discharge and a downstream water level of 2 22 m this water level represents an extreme lake level approximately 1 5 m higher than the long term average of 0 75 m it may be supposed that using an extreme water level should provide a conservative or worst case scenario for flooding prediction here we investigate the impact of conditional probabilities on the predicted flood areas for a 100 year event the copula based methodology incorporates the joint distribution for both the upstream discharge and downstream water level boundary conditions rather than a flood map based on the marginal distribution of the discharge data only fig 7 represents the inundation areas under four scenarios a long term average lake level s 0 75 m and median discharge r 15 m3 s b 10 year flood flow r 736 m3 s and 100 year seiche s 2 76 m c 100 year flood flow r 1056 m3 s and 10 year seiche s 2 22 m and d 100 year flood flow r 1056 m3 s and 100 year seiche s 2 76 m table 6 it should be noted that the fema 100 year flood map is generated using conditions almost equivalent to scenario c from the conditional probability analysis described in section 3 4 the most probable downstream water level interval under the 100 year flow should be 0 75 1 m which is more probable than a higher water level interval like the 10 year seiche equivalent with the interval width of 0 25 m for copula computation the 2 1 2 35 m interval and the 2 63 2 88 m interval are used for a 10 year seiche and a 100 year seiche respectively p r 1056 0 75 s 1 p r 1056 2 1 s 2 35 is approximately equal to 7 meaning the 100 year flood flow and the most probable water level slightly larger than the long term average lake level is approximately 7 times more likely to occur than the fema scenario similarly p r 1056 0 75 s 1 p r 736 2 63 s 2 88 3 and p r 1056 0 75 s 1 p r 1056 2 63 s 2 88 20 which indicates that the 100 year flood flow and the most probable water level is likely to occur 3 and 20 times more frequently than cases b and d respectively from fig 7 it is observed that most of the flooding occurs upstream of the study area when comparing cases 7 b 10 year flood flow and 100 year seiche and 7 c 100 year flood flow and 10 year seiche the 7 c scenario is associated with more upstream flooding therefore in the case of the buffalo river the streamflow driven scenario should be considered for flood analysis and flooding is much more of a concern in upstream areas rather than downstream it is also observed from fig 9 that due to the high downstream bank elevation a seiche is less of a concern for flooding the seiche driven scenario may still be used to look into seiche event conditional probability for the range of available data but not for the flood analysis where high flood flow data corresponding to seiche events are unavailable fig 8 shows the flood inundation area as a function of the seiche water level and discharge the affected inundation area is 2 4 km2 for a 100 year flood with long term average lake level similarly an inundation area of 0 25 km2 is associated with the 100 year seiche water level 2 76 m with the median flow in other words an increase of 860 in inundation area is caused by the 100 year flood with long term average lake level compared with the 100 year seiche with the median flow generally high discharge has a stronger impact on the inundation area than a seiche with the same return period a seiche of 2 m can cause only 0 03 km2 of inundation if the median flow is present in the river however with a 2 year flood a 2 m seiche can cause 0 57 km2 inundation an increase in the inundation area of 1800 similarly a 2 year flood with an average lake level has an inundation area of 0 26 km2 but if the same 2 year flood compounds with a 100 year seiche then the inundation area increases by 230 to 0 86 km2 the fema scenario in fig 7 c along with the 100 year seiche 10 year flood in fig 7 b and 100 year seiche 100 year flood scenario in fig 7 d are shown in fig 8 with inundation area on the vertical axis the figure shows that the inundation area for the fema scenario is 2 85 km2 for the 100 year seiche and 100 year flood scenario and 100 year seiche and 10 year flood the inundation areas are 3 1 km2 and 1 95 km2 respectively the fema scenario is thus seen to produce a lower water level compared to the 100 year seiche 100 year flood scenario from the copula analysis the most probable flood scenario for the 100 year flood flow is with the water level in the 0 75 1 m range therefore from fig 8 the most probable 100 year flood flow with the 0 75 1 m water level flood will cause an inundation of 2 4 2 5 km2 compared to 2 85 km2 in the fema scenario 3 6 hydraulic performance graph hpg the hydraulic performance curves hpcs for discharges ranging from 15 m3 s to 1000 m3 s are shown in fig 9 the hpg provides a convenient way to look up water level at the upstream boundary as in fig 9 or at any given location can be created separately under all combinations of compound flood scenarios the igld85 datum is used in fig 9 which represents a low water level the hpcs are bounded by the 45 degree straight line on the right labelled as the z line the z line represents a horizontal water surface for which there is no flow the n line represents the locus of normal flow profiles and it divides the hpcs into two regions the region between the n line and z line contains the pairs of upstream and downstream water levels corresponding to all possible m1 type profiles whereas the region between the vertical axis and the n line contains the pairs of water levels corresponding to all m2 type profiles yen and gonzález castro 2000 fig 9 shows that there will always be an m1 type profile in the river for discharges less than 400 m3 s while for discharges larger than 800 m3 s the profile will always be m2 type for a 600 m3 s discharge the profile switches from m2 to m1 when the downstream water level is at 1 5 m with a corresponding upstream water level of 2 2 m the flow profile analysis enables engineers to learn beforehand the possible flow profiles associated with the downstream seiche and upstream flow boundary conditions it is also useful to learn about these flow profiles before constructing any weirs dams or control structures in the river m1 profiles are considered common water surface profiles where mild slope streams enter a pool while m2 profiles occur at a sudden drop of the channel or the channel outlet into a lake if the slope becomes steeper chaudhry 2008 though the flow profile depends on the channel slope it is observed from this study that the seiche and upstream flow boundary conditions can alter the river flow profile the upstream and downstream bank elevations also are marked in fig 9 note that much of the buffalo river has hard siding installed with unnaturally high stream bank elevations it is observed from the hpcs that as discharge increases from 600 m3 s to 1000 m3 s it is more likely that water surface elevation will overtop the upstream bank first this effect also is evident in fig 7 4 conclusions the compound flooding due to seiche i e high downstream water level and high discharge can have an enormous impact on a community near a coastal freshwater river this study assessed these effects on flooding in a freshwater coastal river using copula probability and a hydrodynamic model the probability based framework proposed in this study can be applied to quantify the conditional probability of compounding boundary conditions for any freshwater coastal river the following conclusions are made i this study provides a framework for determining the probability of occurrence of a set of upstream and downstream boundary conditions for a hydrodynamic model which can be used for creating flood maps for a freshwater coastal river this proposed copula based framework provides insight into the compounding effects of seiches and high discharge on inundation and the probability of occurrence of such events it is shown that seiches can have an impact on flooding in a freshwater coastal river and the compounding effects of seiche and high discharge can increase the inundation area ii the streamflow driven scenario is considered over the seiche driven scenario for the buffalo river as flooding is much more of a concern upstream than downstream because of the artificially high downstream bank height in general however both streamflow and seiche driven scenarios should be considered since the seiche driven scenario can be very important if the downstream bank is not high enough iii the fema 100 year flood map is probably safe against flooding of the buffalo river as the likeliness of occurrence of the 100 year flood flow with the most probable water level is 7 times that of the fema 100 year flood iv seiche driven and streamflow driven scenarios can be associated with different types of backwater profiles in a river for the buffalo river streamflow driven scenarios with river discharge greater than 800 m3 s will always be associated with an m2 type profile in the case of seiche driven scenarios with river discharges less than 400 m3 s the profile is always m1 type the hpg can be used to assess these profiles and conveniently present water level at any given location under all possible combinations of the compound floods v it should be noted that the conditional probabilities from the streamflow driven and seiche driven are not directly comparable due to the different forms of computation equations 8a and 8b respectively both computations depend on choices of intervals s in 8a and r in 8b so the conditional probabilities from the two scenarios are neither similar nor comparable moreover the present framework considers these two scenarios separately future work is needed to integrate them in order to obtain a more comprehensive and accurate flood frequency and risk analysis credit authorship contribution statement angshuman m saharia conceptualization methodology formal analysis investigation writing original draft writing review editing visualization zhenduo zhu conceptualization methodology writing original draft writing review editing supervision joseph f atkinson conceptualization methodology writing original draft writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement a m saharia was supported by the new york state energy research and development authority project 105162 we would like to acknowledge dr ali farhadzadeh for providing the seiche data and the united states army corps of engineers for providing the hec ras model we would also like to thank dr leizhi wang and dr erdinc sogut for helping us preparing the data the opinions and findings presented in this paper are solely those of the authors and do not represent the opinions of any state and federal agency mentioned in the manuscript 
