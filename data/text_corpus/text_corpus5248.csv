index,text
26240,land use and hydrology are interdependent so that land use modeling could benefit from hydrologic modeling this study aims to integrate spatial predictions of hydrologic variables as provided by a hydrologic model into a land use model for a rapidly urbanizing catchment in india the benefits of this integration are quantified by comparing predictions of a land use model that uses a basic set of explanatory variables to a land use model that additionally uses the modeled hydrologic variables our results indicate that the integration of the hydrologic variables improved the model accuracy indicated by overall accuracy 3 and 4 percentage points pp class specific user and producer accuracies up to 8 pp and figure of merit 4 and 5 3 pp when compared with land use classifications at two points in time moreover the land use patterns show that the integration of the hydrologic variables helped to avoid allocation errors keywords land use modeling hydrologic modeling land use cover change lucc clue s india 1 introduction integrated environmental modeling approaches are in need to analyze and solve increasingly complex real world problems kelly et al 2013 laniak et al 2013 particularly for disciplines like land use science and hydrology which are interdependent and for which processes act on similar scales model integration coupling or close exchange seem indispensable however the linkage between the two modeling communities is surprisingly weak on the one hand land use information is an integral part of most hydrologic models mostly land use maps derived from satellite data e g baker and miller 2013 wagner et al 2013 or acquired from an agency e g ghaffari et al 2010 are used as an input for hydrologic models if at all outputs from land use models are used for hydrologic simulations of scenarios fohrer et al 2002 niehoff et al 2002 wagner et al 2016 weber et al 2001 even though land use models provide more accurate land use scenarios in space and time simple representations of land use change are still implemented e g by changing one land use or a percentage of one land use to another one li et al 2007 trang et al 2017 on the other hand hydrology is less prominent in land use change models mostly hydrology is represented by the distance to water bodies huang and cai 2007 trisurat et al 2010 xu et al 2013 sometimes precipitation patterns are used henríquez dole et al 2018 lima et al 2011 sohl et al 2007 and rarely other proxies for water availability e g a wetness index kim et al 2014 are employed as static variables this limitation is possibly due to the fact that hydrologic variables require a certain amount of preprocessing interpolation derivation from satellite data if no freely available products e g trmm precipitation patterns modis evapotranspiration are used hydrologic models can provide spatially distributed output variables at a high spatial resolution such variables have proven their potential for land use change prediction wagner and waske 2016 and are therefore promising for an integration into a land use model a variety of land use models exists which build on different approaches that can be classified from spatial vs non spatial dynamic vs static agent based vs pixel based inductive vs deductive to global vs regional mas et al 2014 verburg et al 2006 these models are used for different purposes including empirical statistical stochastic optimization process based and integrated modeling approaches lambin et al 2000 several land use models provide spatially distributed outputs e g proland möller and weinmann 2001 sleuth clarke and gaydos 1998 and clue verburg et al 2002 the latter is one of the most popular and well documented land use models different versions of the model clue clue s dyna clue veldkamp and fresco 1996 verburg et al 1999 2002 verburg and overmars 2009 allow for its application on different scales and promote its application in many different regions and environments worldwide e g in argentina lima et al 2011 china luo et al 2010 thailand trisurat et al 2010 and europe verburg et al 2010 the clue model uses an inductive modeling approach i e model parameters are based on a statistical analysis of the underlying biophysical and socio economic variables the clue s model version is designed for modeling the regional scale at a fine resolution verburg et al 2002 so that it is applicable on the catchment scale therefore it is particularly suitable for an integration of outputs from hydrologic models so far hydrologic variables such as distance to water bodies trisurat et al 2010 verburg et al 2004a xu et al 2013 groundwater luo et al 2010 verburg et al 2004a and precipitation patterns henríquez dole et al 2018 lima et al 2011 wassenaar et al 2007 have been included in clue s modeling studies but other bio physical variables e g derivatives of elevation models soil attributes and socio economic variables e g population density are more commonly used e g henríquez dole et al 2018 verburg et al 2004a wassenaar et al 2007 we hypothesize that the prediction accuracy of land use models can be improved with the help of spatially distributed predictions from a hydrologic model to this end we i integrate outputs from a hydrologic model into a land use model and ii evaluate the benefits of this integration we build a land use model for a study area in india that is characterized by a rapid land use change models with and without hydrologic variables are evaluated by comparing simulated land use maps to land use classifications of the past moreover spatial patterns derived for an urbanization scenario are compared to assess the capability of the models to represent possible future land use distributions 2 materials and methods 2 1 study area and land use change the indian catchment of the mula and mutha rivers experiences rapid land use change it is located in the western ghats upstream of the city of pune in the state of maharashtra butsch et al 2017 elevation ranges between 550 m a s l in pune and 1300 m a s l on the top ridges of the western ghats fig 1 the climate is tropical wet and dry with an annual mean temperature of 25 c measured at the weather station maintained by the indian meteorological department imd in pune id 430630 rainfall is mainly restricted to the monsoon months june to october and shows a strong decrease from west to east 3500 mm 750 mm annual rainfall gadgil 2002 gunnell 1997 with increasing distance from the western ghats escarpment wagner et al 2012 land use is dominated by semi natural vegetation 70 7 in 2009 10 which are the classes grassland shrubland and forest that form a continuum in the study area wagner et al 2013 agricultural classes rice wheat rotation sugarcane and other crops account for 13 5 of the catchment area and urban areas for 10 1 in 2009 10 a classification based assessment of land use changes between 1989 90 and 2009 10 showed that urban area 5 1 percentage points pp and agricultural areas 3 7 pp expanded while semi natural areas decreased 9 1 pp the area covered by water increased slightly 0 3 pp to 5 7 of the catchment area due to additional and expanded reservoirs wagner et al 2013 2 2 explanatory variables we used two sets of variables as an input to the land use model the basic set is composed of socio economic and bio physical variables that are freely available for the study area upper part of table 1 these variables include population density distance to roads distance to rivers elevation slope aspect and soil type most of these variables are static only population density is available for two time steps and is therefore considered a dynamic variable in the modeling approach the basic set is complemented by a set of variables simulated by the hydrologic model swat arnold et al 1998 for the study area wagner et al 2013 due to the limited availability of environmental data in india the swat model has been chosen as it has originally been developed to operate in large ungauged catchments arnold et al 1998 and has proven useful under conditions of limited data availability ndomba et al 2008 stehr et al 2008 the model is capable of representing water fluxes in the study area as shown by the evaluation with daily rainy season discharge at the two river gauges that are less affected by dam management nash sutcliffe efficiencies between 0 67 and 0 69 further details on model setup and model evaluation are available in wagner et al 2011 and wagner et al 2012 the soil and water assessment tool swat is a semi distributed hydrologic model that is based on the concept of hydrologic response units hrus to achieve a spatially distributed model output we used a fully distributed hru setup so that the model output of each hydrologic response unit was mapped to its location wagner and waske 2016 twelve spatially distributed hydrologic variables were derived lower part of table 1 the hydrologic variables are available for two time steps the first is based on averaged outputs of a model run from 1989 to 1999 and the land use of 1989 90 and the second is the average of the outputs of a model run from 2000 to 2008 with the land use of 2000 01 hence the hydrologic variables are included as dynamic variables in the modeling approach we used a threshold of 0 7 for pearson s correlation coefficient r to exclude collinear variables baumann et al 2011 dormann et al 2013 to this end we calculated r between all variable pairs from a variable pair with an absolute value of r greater than 0 7 we removed the variable that is less suitable to explain the land use pattern i e we keep the variable that leads to a better logistic regression model with only one explanatory variable evaluated by the relative operating characteristic wagner and waske 2016 2 3 clue s model the conversion of land use and its effects at small regional extent modeling framework clue s verburg et al 2002 dynamically simulates competition between different land use types to model land use change clue s has a demand module representing aggregated non spatial land use changes and an allocation module that allocates these demands in space the allocation module is based on probability maps decision rules and land use conversion elasticities the probability maps for each land use class are derived through logistic regression for each land use class c the probability p i for each pixel i for the occurrence of this class is described as a function of the explanatory variables x n i as follows 1 l o g p i 1 p i β 0 β 1 x 1 i β 2 x 2 i β n x n i where β n are the regression coefficients for the variables x n i and n is the number of explanatory variables all non collinear variables are used in this approach but non significant variables that do not improve the model performance are removed from the logistic regression models data samples were used to calibrate and validate the logistic regression models based on the 2009 10 land use map and the independent explanatory variables from 2000 01 2nd time step we used the 2009 10 land use map to set up the logistic regression models as the small land use classes like sugarcane cover a larger area as well as to generate models that are most suitable for future simulations for each land use a stratified random sample of 20 of all 30 m 30 m pixels with this land use was extracted from a binary land use map for this class no spatially adjacent pixels were considered in this sample to minimize the influence of spatial autocorrelation the sample was equally split in two halves one was used for calibration of the logistic regression models and the other one was used for spatial validation in addition the derived logistic regression models were applied to the explanatory variables from 1989 90 1st time step and were temporally validated with the land use of 2000 01 the relative elasticity for change is set for each land use class in accordance to the likeliness of a conversion of the class in an urbanizing study area it is unlikely that urban areas will be converted to other land uses and therefore urban elasticity is the highest in our parameterization table 2 moreover agricultural areas require some investment and do therefore have the second highest elasticity values within the agricultural classes the cash crop sugarcane has the highest 0 5 and the mixed crop class the lowest elasticity 0 3 the semi natural classes have the lowest elasticities table 2 focusing on land based land use changes we excluded water transitions from the model by including a decision rule that does not allow transitions from or to water the probability maps elasticities and decision rules are combined to determine the land use allocation this allocation procedure is iterated until the demand for each land use class is met a maximum difference max diff of 10 pixels per land use class and an average difference ave diff of 10 pixels between allocated and demanded area is allowed table 2 we used the clue s implementation in the r package lulcc moulds 2017 moulds et al 2015 in each iteration suitability is increased or decreased depending on the difference between demanded and allocated area as well as the scale f parameter table 2 we used the default jitter f value that controls the perturbation of pixel suitabilities at the start of each iteration to limit the influence of nominal suitability differences on the model solution the applied parameterization table 2 was suitable to reach a solution within a maximum number of 5000 iterations the land use map of the cropping year 1989 90 was used as a base map in the modeling approach we simulated the years 2000 01 and 2009 10 using the aggregated demands from the land use maps and a future simulation for the year 2029 30 using a linear extrapolation of the land use demands of the past the linear extrapolation results in increases of urban areas to 15 2 of the catchment area and agricultural areas 17 2 whereas semi natural areas decrease to 62 3 changes in water areas were not considered 5 3 among the semi natural areas forest areas increase 29 4 and shrubland 21 9 and grassland 11 0 decrease 2 4 evaluation we compare two main clue s parameterizations one is based on the basic set of socio economic and bio physical variables basic model and the other additionally uses the output variables from the hydrologic model enhanced model moreover we assess the effect of updating the explanatory variables by running the enhanced model without an update of these variables two points in time are available for model evaluation 2009 10 which has been used for calibrating the logistic regression models is referred to as calibration time whereas 2000 01 is referred to as validation time first the logistic regression models are compared using the relative operating characteristic roc pontius and schneider 2001 the roc is based on a curve of the rate of true positives versus the rate of false positives for a range of threshold values to classify the probabilities into two classes the area under this curve is the roc statistic which ranges from 0 5 random separation to 1 perfect discrimination moreover the odds ratio defined as exp β n for the n th explanatory variable in a logistic regression model is used to characterize the land use distribution in the study area for metric variables odds ratios below 1 indicate that the probability of occurrence of the land use class will decrease with an increase in the explanatory variable odds ratios above 1 indicate that the probability for this land use will increase with an increase in the explanatory variable the magnitude of the odds ratio is scaled to the magnitude of the explanatory variable i e small values of the variable result in very large or very small odds ratios second all pixels of the simulated land use maps are compared to the land use classifications with the help of a confusion matrix and the percentage of correctly simulated change and persistence moreover the figure of merit that is the ratio of correctly simulated change and the total change is calculated klug et al 1992 pontius et al 2011 third the simulated maps are visually compared to the available land use classifications in addition future simulations for 2029 30 are evaluated all calculations and analyses were carried out in r r core team 2016 and with the help of the r packages raster hijmans 2016 lulcc moulds 2017 and rocr sing et al 2005 3 results 3 1 evaluation of the logistic regression models the logistic regression models for the enhanced model show that most of the available explanatory variables have been included for at least one of the land use classes only three of the twelve available hydrologic variables surface runoff groundwater recharge and water in the shallow aquifer returning to the root zone were not included in any model this is possibly due to the interrelation of the hydrologic variables which has led to an exclusion of collinear variables as well as to no significant improvement of the logistic regression models when the variable was included between eight and eleven significant variables were considered in the logistic regression model per land use class table 3 the effect of the spatial variables as indicated by the odds ratios are mostly in agreement with general expectations e g with an increasing distance to roads the probability for urban land use decreases whereas it increases for all other land uses if the steepness of slopes increases by 1 then the probability for agricultural land use classes decreases pronouncedly by 11 4 12 5 while in contrast it decreases by only 0 3 for shrubland with an increase of water stress days the probability for urban land use increases odds ratio 1 the occurrence of mixed cropland sugarcane and grassland are associated with higher soil water contents odds ratios 1 in areas with higher evapotranspiration the occurrence of forest and rice is more probable odds ratios 1 whereas grassland is less probable odds ratio 1 certainly some factors are associated with the specific characteristics of the study area expectations are met when an increase in population density yields a higher probability for urban areas odds ratio 1 and a lower probability for rice grassland and shrubland odds ratios 1 however the logistic regression results also show that an increase in population density results in a slightly higher probability for forests and mixed cropland odds ratios 1 this counterintuitive effect can be explained by mixed cropland areas and forests or park areas classified as forests adjacent to settlement areas the quality of the logistic regression models is generally good for the evaluation in 2009 10 only shrubland and grassland show roc values below 0 7 which is suggested by wu et al 2009 as a threshold for reliable precision the roc values of all other logistic regression models are clearly above this threshold ranging between 0 81 and 0 94 table 3 the model is robust in space as the small differences between calibration and spatial validation values show roc val2009 10 and roc val 2009 10 the performance even improves for some classes when the model is evaluated with the 2000 01 land use roc val 2000 01 this improvement may be attributed to the fact that the logistic regression models were set up with the hydrologic variables based on a model run with the 2000 01 land use the integration of hydrologic variables mostly improved the logistic regression models the roc val 2000 01 value was changed by 0 01 to 0 13 fig 2 when compared to logistic regression models that purely relied on the basic set of socio economic and bio physical variables upper part in table 1 the highest gain was achieved for the semi natural classes 0 06 to 0 13 naturally the basic logistic regression models used less variables 5 7 but only two for grassland and rice used all seven basic explanatory variables however the gain in performance is not directly related to the number of variables included in the logistic regression model e g rice 7 vs 11 variables with a small deterioration shrubland 5 vs 9 variables with a pronounced improvement fig 2 but to the information content of the explanatory variables for the specific land use class 3 2 evaluation of the clue s models the performance of the clue s models is evaluated using a confusion matrix comparing clue s simulations and land use classifications for 2000 01 and 2009 10 in general the performance was better in 2000 01 60 63 as compared to the performance in 2009 10 50 54 table 4 this can be attributed to the slightly better performance of the logistic regression models in 2000 01 table 3 as well as to the higher similarity of the base map for the clue s model 1989 90 classification and the 2000 01 classification this is mainly a result of the shorter temporal difference between the two classifications and consequently fewer land use changes the overall accuracy oa is on a relatively low level 50 63 the number of land use classes as well as the confusion between the semi natural classes forest shrubland and grassland that are a continuum might have contributed to these low values depending on water availability and timing of the satellite image shrubland might have been classified as grassland in the one or forest in the other classification wagner et al 2013 if these pseudo changes are accounted for i e confusion between shrubland and forest as well as shrubland and grassland are disregarded the performance improves pronouncedly oa nature 71 80 table 4 moreover if the agricultural classes were aggregated into one class the overall accuracy further improves oa nature crops 74 84 looking at the individual land use classes producer and user accuracies indicate that forest 67 79 and urban areas 55 63 are better represented than the other classes the agricultural classes in particular have low accuracies 6 38 however the accuracy for aggregated agricultural classes is much better 43 64 showing that there is a pronounced confusion between the different agricultural classes the overall accuracy is higher in 2000 01 which can mainly be attributed to correctly simulated persistence 58 5 and 59 3 the evaluation in 2009 10 shows that the model is also able to simulate change correctly when compared to 2000 01 there is more change and less persistence between 1989 90 and 2009 10 consequently the percentage of correctly simulated change increases while the percentage of correctly simulated persistence decreases table 4 underlining that the model is able to represent land use change as well as persistence at both time steps the enhanced clue s model shows a slightly better performance when compared to the model that only uses the basic set of variables 3 and 4 percentage points increase in oa in 2000 01 and 2009 10 respectively in particular the improvement in the figure of merit underlines the usefulness of the hydrologic variable set 4 and 5 3 pp in 2000 01 and 2009 10 respectively the increase in model performance can mainly be attributed to a better representation of the semi natural classes 1 pp up to 6 pp in pa ua whereas the accuracy of the agricultural classes does either not change or the improvement is mostly small table 4 the accuracy of the urban class in 2009 10 is much better 8 pp when using the model with hydrologic variables but the improvement in 2000 01 is relatively small 1 pp this class specific improvement has contributed to the more accurate representation of changed pixels in 2009 10 as urbanization is the main driver of changes in the study area the simulated land use maps for 2000 01 and 2009 10 show that general characteristics of the study area are represented in both models fig 3 these are the urban growth in the east of the catchment agricultural land use at the valley bottoms near the rivers and semi natural land use dominating the west of the catchment with a continuum from grassland to shrubland to forest from lower to higher elevations however simulations by the basic model show the influence of the explanatory variables used e g impact of elevation on forest areas in the mid northern part figs 1 and 3 whereas the patterns simulated by the model that uses all variables cannot as easily be explained by one or two explanatory variables furthermore the urban expansion is better represented by the enhanced model e g the growth along the national highway 4 to mumbai in the north eastern part of the catchment in 2009 10 figs 3 and 4 in addition the basic model simulates urban areas in some parts of the biodiversity rich western ghats in 2009 10 which are obvious allocation errors in 2000 01 and 2009 10 the enhanced model improves the basic model prediction by 2 5 pp and 4 2 pp net gain in fig 4 the simulation for 2029 30 provides a land use allocation for a future scenario the applied scenario is very simple as the demands were derived by linear extrapolation of past land use change and it is possibly not accurate with regard to the 29 4 forest areas which were larger in 2009 10 due to an earlier satellite scene nearer to the end of the monsoon season wagner et al 2013 nevertheless the pattern simulated by the enhanced clue s model looks more reasonable particularly with regard to urban growth and the location of agricultural areas which are less likely in the biodiversity rich western part of the catchment fig 3 4 discussion the model performance judged by the roc value shows that the logistic regression models were above the threshold of random separation 0 5 and with the exception of the models for grassland and shrubland were well above the threshold for reliable precision of 0 7 as suggested by wu et al 2009 the relatively low values of overall accuracy can be attributed to confusion within the semi natural classes and within the agricultural classes as the overall accuracy improves substantially if the agricultural classes are aggregated and the confusion within the semi natural classes is accounted for 21 pp and 24 pp in 2000 01 and 2009 10 respectively the catchment is dominated by small scale agriculture fields typically smaller than 1 ha so that the spatial resolution affects the model performance near misses in allocation accuracy can be accounted for by decreasing the spatial resolution pontius et al 2008 2011 the figure of merit improves to 24 2 if the resolution is 16 times decreased 480 m resolution and to 28 7 if it is decreased 64 times 1920 m resolution hence the model provides more accurate results on a coarser scale while still being sufficient for planning purposes the evaluation of the logistic regression models as well as of the clue s model simulations shows that the inclusion of hydrologic variables improved the simulation of land use changes the figure of merit that pontius et al 2011 suggest for the evaluation of land use change modeling underlines the better performance of the enhanced model even if the improvements were small e g in overall accuracy the effect can consistently be observed for all land use classes at one time step at least fig 2 and table 4 however it has to be noted that the gain in prediction accuracy has been achieved after a considerable hydrologic modeling effort if a hydrologic model is not available it is certainly faster to model land use changes without using hydrologic variables and accept a lower model performance nevertheless a model run without an update of the hydrologic variables shows that the inclusion of hydrologic variables could also be recommended if these are only available for one time step as the model performance is improved table 4 therefore spatially distributed hydrologic variables from other sources that require less processing and modeling efforts e g interpolated or remotely sensed precipitation patterns may be used our findings confirm the conclusion drawn by wagner and waske 2016 that hydrologic modeling results are useful for land use modeling like most model input data the land use classifications that are used for model calibration and validation are not free of errors the averaged overall accuracy per cropping year varies between 62 and up to more than 90 particularly accuracies for grassland shrubland and mixed cropland are relatively low wagner et al 2013 while this has an effect on the land use allocation by the models the relative improvement from the basic to the enhanced model is a reliable result as the land use classifications are consistently used for calibration and validation and for both model setups this improvement is underlined by the evaluation of the scenario simulation for 2029 30 based on our knowledge of the study area urban areas are clearly misplaced by the basic model in the biodiversity rich western ghats fig 3 whereas the enhanced model provides a more reasonable land use distribution this can be explained by the improved allocation of the semi natural land use classes by the enhanced model fig 2 that dominate the western part of the catchment as one of the key applications for models is the evaluation of possible future scenarios henríquez dole et al 2018 palmate et al 2017 verburg et al 2004b our results show that the inclusion of hydrologic variables in the modeling approach can help to avoid allocation errors and provide better scenario predictions this was already the case for a simple scenario that was defined by linear extrapolation of past trends more complex scenarios can be derived by defining the land use demands in clue s with the help of a model that accounts for macro economic demographic and technology developments as well as relevant economic policies luo et al 2010 however an accurate spatial allocation of land use change is crucial for both simple and complex scenario outlines in summary our results indicate that a closer exchange between the hydrologic and land use change modeling communities seems beneficial to both hydrologists and land use scientists wagner et al 2017 have shown that hydrologic modeling benefits from dynamic land use updates which may be provided by land use models e g mehdi et al 2015 wagner et al 2016 vice versa our results show that land use models can benefit from hydrologic modeling in addition a bi directional linkage of these models would allow for accounting for feedback effects verburg et al 2006 veldkamp and lambin 2001 as well as for a more consistent simulation of climate change impacts on hydrology which are so far mostly assessed without accounting for a consistent development of land use changes e g mango et al 2011 wagner et al 2015 5 conclusions spatially distributed hydrologic variables as they are available from hydrologic models can be used to improve the performance of land use models in this study all performance indices consistently showed that the land use model that was enhanced with hydrologic explanatory variables outperformed the basic land use model for the urbanizing mula and mutha rivers catchment in india to a certain extent moreover future simulations showed that obvious allocation errors could be avoided when using the enhanced model in addition we found that an improvement in model performance is already achieved if hydrologic variables are integrated at one time step hence even if dynamic variables are not available as e g provided by a hydrologic model it may be worthwhile to integrate spatially distributed hydrologic variables in this regard precipitation or evapotranspiration patterns that may be derived from satellite data can be interpolated from field data or are readily available from data archives e g trmm precipitation patterns modis evapotranspiration can be tested in future studies we realize that not everyone will view our results as compelling as we do for the following reasons the present study area that is subject to limited data availability might not be ideal to draw general conclusions moreover the overall improvement even though consistently observed may be regarded as too small so that other researchers may draw the conclusion that the inclusion of hydrologic variables is not worthwhile our approach should therefore be tested in study areas with sufficient data availability as well as in other climatic regions we believe that a stronger linkage and exchange between hydrologic and land use change models is beneficial as it could improve both hydrologic and land use modeling results at least to a certain extent therefore a closer linkage between the two modeling communities is recommended this would provide a basis for accounting for feedback effects and would yield a more integrated modeling approach to analyze and solve increasingly complex real world problems software and data availability we use the freely available open source hydrologic model swat arnold et al 1998 available from http swat tamu edu to produce spatially distributed hydrologic variables for the studied catchment wagner et al 2013 data sources for all utilized explanatory variables for land use change are provided in table 1 all calculations and analyses are carried out in r r core team 2016 and with the help of the r packages raster hijmans 2016 lulcc moulds 2017 and rocr sing et al 2005 which are available from https cran r project org r and the swat model run on microsoft windows and linux computers with no special hardware requirements please contact the corresponding author for any further information at pwagner hydrology uni kiel de acknowledgements we are thankful to shamita kumar and erach bharucha from the institute of environment education research at bharati vidyapeeth university pune who supported our research in the study area in many ways and from the very beginning we thank the editor and three anonymous reviewers for their constructive comments 
26240,land use and hydrology are interdependent so that land use modeling could benefit from hydrologic modeling this study aims to integrate spatial predictions of hydrologic variables as provided by a hydrologic model into a land use model for a rapidly urbanizing catchment in india the benefits of this integration are quantified by comparing predictions of a land use model that uses a basic set of explanatory variables to a land use model that additionally uses the modeled hydrologic variables our results indicate that the integration of the hydrologic variables improved the model accuracy indicated by overall accuracy 3 and 4 percentage points pp class specific user and producer accuracies up to 8 pp and figure of merit 4 and 5 3 pp when compared with land use classifications at two points in time moreover the land use patterns show that the integration of the hydrologic variables helped to avoid allocation errors keywords land use modeling hydrologic modeling land use cover change lucc clue s india 1 introduction integrated environmental modeling approaches are in need to analyze and solve increasingly complex real world problems kelly et al 2013 laniak et al 2013 particularly for disciplines like land use science and hydrology which are interdependent and for which processes act on similar scales model integration coupling or close exchange seem indispensable however the linkage between the two modeling communities is surprisingly weak on the one hand land use information is an integral part of most hydrologic models mostly land use maps derived from satellite data e g baker and miller 2013 wagner et al 2013 or acquired from an agency e g ghaffari et al 2010 are used as an input for hydrologic models if at all outputs from land use models are used for hydrologic simulations of scenarios fohrer et al 2002 niehoff et al 2002 wagner et al 2016 weber et al 2001 even though land use models provide more accurate land use scenarios in space and time simple representations of land use change are still implemented e g by changing one land use or a percentage of one land use to another one li et al 2007 trang et al 2017 on the other hand hydrology is less prominent in land use change models mostly hydrology is represented by the distance to water bodies huang and cai 2007 trisurat et al 2010 xu et al 2013 sometimes precipitation patterns are used henríquez dole et al 2018 lima et al 2011 sohl et al 2007 and rarely other proxies for water availability e g a wetness index kim et al 2014 are employed as static variables this limitation is possibly due to the fact that hydrologic variables require a certain amount of preprocessing interpolation derivation from satellite data if no freely available products e g trmm precipitation patterns modis evapotranspiration are used hydrologic models can provide spatially distributed output variables at a high spatial resolution such variables have proven their potential for land use change prediction wagner and waske 2016 and are therefore promising for an integration into a land use model a variety of land use models exists which build on different approaches that can be classified from spatial vs non spatial dynamic vs static agent based vs pixel based inductive vs deductive to global vs regional mas et al 2014 verburg et al 2006 these models are used for different purposes including empirical statistical stochastic optimization process based and integrated modeling approaches lambin et al 2000 several land use models provide spatially distributed outputs e g proland möller and weinmann 2001 sleuth clarke and gaydos 1998 and clue verburg et al 2002 the latter is one of the most popular and well documented land use models different versions of the model clue clue s dyna clue veldkamp and fresco 1996 verburg et al 1999 2002 verburg and overmars 2009 allow for its application on different scales and promote its application in many different regions and environments worldwide e g in argentina lima et al 2011 china luo et al 2010 thailand trisurat et al 2010 and europe verburg et al 2010 the clue model uses an inductive modeling approach i e model parameters are based on a statistical analysis of the underlying biophysical and socio economic variables the clue s model version is designed for modeling the regional scale at a fine resolution verburg et al 2002 so that it is applicable on the catchment scale therefore it is particularly suitable for an integration of outputs from hydrologic models so far hydrologic variables such as distance to water bodies trisurat et al 2010 verburg et al 2004a xu et al 2013 groundwater luo et al 2010 verburg et al 2004a and precipitation patterns henríquez dole et al 2018 lima et al 2011 wassenaar et al 2007 have been included in clue s modeling studies but other bio physical variables e g derivatives of elevation models soil attributes and socio economic variables e g population density are more commonly used e g henríquez dole et al 2018 verburg et al 2004a wassenaar et al 2007 we hypothesize that the prediction accuracy of land use models can be improved with the help of spatially distributed predictions from a hydrologic model to this end we i integrate outputs from a hydrologic model into a land use model and ii evaluate the benefits of this integration we build a land use model for a study area in india that is characterized by a rapid land use change models with and without hydrologic variables are evaluated by comparing simulated land use maps to land use classifications of the past moreover spatial patterns derived for an urbanization scenario are compared to assess the capability of the models to represent possible future land use distributions 2 materials and methods 2 1 study area and land use change the indian catchment of the mula and mutha rivers experiences rapid land use change it is located in the western ghats upstream of the city of pune in the state of maharashtra butsch et al 2017 elevation ranges between 550 m a s l in pune and 1300 m a s l on the top ridges of the western ghats fig 1 the climate is tropical wet and dry with an annual mean temperature of 25 c measured at the weather station maintained by the indian meteorological department imd in pune id 430630 rainfall is mainly restricted to the monsoon months june to october and shows a strong decrease from west to east 3500 mm 750 mm annual rainfall gadgil 2002 gunnell 1997 with increasing distance from the western ghats escarpment wagner et al 2012 land use is dominated by semi natural vegetation 70 7 in 2009 10 which are the classes grassland shrubland and forest that form a continuum in the study area wagner et al 2013 agricultural classes rice wheat rotation sugarcane and other crops account for 13 5 of the catchment area and urban areas for 10 1 in 2009 10 a classification based assessment of land use changes between 1989 90 and 2009 10 showed that urban area 5 1 percentage points pp and agricultural areas 3 7 pp expanded while semi natural areas decreased 9 1 pp the area covered by water increased slightly 0 3 pp to 5 7 of the catchment area due to additional and expanded reservoirs wagner et al 2013 2 2 explanatory variables we used two sets of variables as an input to the land use model the basic set is composed of socio economic and bio physical variables that are freely available for the study area upper part of table 1 these variables include population density distance to roads distance to rivers elevation slope aspect and soil type most of these variables are static only population density is available for two time steps and is therefore considered a dynamic variable in the modeling approach the basic set is complemented by a set of variables simulated by the hydrologic model swat arnold et al 1998 for the study area wagner et al 2013 due to the limited availability of environmental data in india the swat model has been chosen as it has originally been developed to operate in large ungauged catchments arnold et al 1998 and has proven useful under conditions of limited data availability ndomba et al 2008 stehr et al 2008 the model is capable of representing water fluxes in the study area as shown by the evaluation with daily rainy season discharge at the two river gauges that are less affected by dam management nash sutcliffe efficiencies between 0 67 and 0 69 further details on model setup and model evaluation are available in wagner et al 2011 and wagner et al 2012 the soil and water assessment tool swat is a semi distributed hydrologic model that is based on the concept of hydrologic response units hrus to achieve a spatially distributed model output we used a fully distributed hru setup so that the model output of each hydrologic response unit was mapped to its location wagner and waske 2016 twelve spatially distributed hydrologic variables were derived lower part of table 1 the hydrologic variables are available for two time steps the first is based on averaged outputs of a model run from 1989 to 1999 and the land use of 1989 90 and the second is the average of the outputs of a model run from 2000 to 2008 with the land use of 2000 01 hence the hydrologic variables are included as dynamic variables in the modeling approach we used a threshold of 0 7 for pearson s correlation coefficient r to exclude collinear variables baumann et al 2011 dormann et al 2013 to this end we calculated r between all variable pairs from a variable pair with an absolute value of r greater than 0 7 we removed the variable that is less suitable to explain the land use pattern i e we keep the variable that leads to a better logistic regression model with only one explanatory variable evaluated by the relative operating characteristic wagner and waske 2016 2 3 clue s model the conversion of land use and its effects at small regional extent modeling framework clue s verburg et al 2002 dynamically simulates competition between different land use types to model land use change clue s has a demand module representing aggregated non spatial land use changes and an allocation module that allocates these demands in space the allocation module is based on probability maps decision rules and land use conversion elasticities the probability maps for each land use class are derived through logistic regression for each land use class c the probability p i for each pixel i for the occurrence of this class is described as a function of the explanatory variables x n i as follows 1 l o g p i 1 p i β 0 β 1 x 1 i β 2 x 2 i β n x n i where β n are the regression coefficients for the variables x n i and n is the number of explanatory variables all non collinear variables are used in this approach but non significant variables that do not improve the model performance are removed from the logistic regression models data samples were used to calibrate and validate the logistic regression models based on the 2009 10 land use map and the independent explanatory variables from 2000 01 2nd time step we used the 2009 10 land use map to set up the logistic regression models as the small land use classes like sugarcane cover a larger area as well as to generate models that are most suitable for future simulations for each land use a stratified random sample of 20 of all 30 m 30 m pixels with this land use was extracted from a binary land use map for this class no spatially adjacent pixels were considered in this sample to minimize the influence of spatial autocorrelation the sample was equally split in two halves one was used for calibration of the logistic regression models and the other one was used for spatial validation in addition the derived logistic regression models were applied to the explanatory variables from 1989 90 1st time step and were temporally validated with the land use of 2000 01 the relative elasticity for change is set for each land use class in accordance to the likeliness of a conversion of the class in an urbanizing study area it is unlikely that urban areas will be converted to other land uses and therefore urban elasticity is the highest in our parameterization table 2 moreover agricultural areas require some investment and do therefore have the second highest elasticity values within the agricultural classes the cash crop sugarcane has the highest 0 5 and the mixed crop class the lowest elasticity 0 3 the semi natural classes have the lowest elasticities table 2 focusing on land based land use changes we excluded water transitions from the model by including a decision rule that does not allow transitions from or to water the probability maps elasticities and decision rules are combined to determine the land use allocation this allocation procedure is iterated until the demand for each land use class is met a maximum difference max diff of 10 pixels per land use class and an average difference ave diff of 10 pixels between allocated and demanded area is allowed table 2 we used the clue s implementation in the r package lulcc moulds 2017 moulds et al 2015 in each iteration suitability is increased or decreased depending on the difference between demanded and allocated area as well as the scale f parameter table 2 we used the default jitter f value that controls the perturbation of pixel suitabilities at the start of each iteration to limit the influence of nominal suitability differences on the model solution the applied parameterization table 2 was suitable to reach a solution within a maximum number of 5000 iterations the land use map of the cropping year 1989 90 was used as a base map in the modeling approach we simulated the years 2000 01 and 2009 10 using the aggregated demands from the land use maps and a future simulation for the year 2029 30 using a linear extrapolation of the land use demands of the past the linear extrapolation results in increases of urban areas to 15 2 of the catchment area and agricultural areas 17 2 whereas semi natural areas decrease to 62 3 changes in water areas were not considered 5 3 among the semi natural areas forest areas increase 29 4 and shrubland 21 9 and grassland 11 0 decrease 2 4 evaluation we compare two main clue s parameterizations one is based on the basic set of socio economic and bio physical variables basic model and the other additionally uses the output variables from the hydrologic model enhanced model moreover we assess the effect of updating the explanatory variables by running the enhanced model without an update of these variables two points in time are available for model evaluation 2009 10 which has been used for calibrating the logistic regression models is referred to as calibration time whereas 2000 01 is referred to as validation time first the logistic regression models are compared using the relative operating characteristic roc pontius and schneider 2001 the roc is based on a curve of the rate of true positives versus the rate of false positives for a range of threshold values to classify the probabilities into two classes the area under this curve is the roc statistic which ranges from 0 5 random separation to 1 perfect discrimination moreover the odds ratio defined as exp β n for the n th explanatory variable in a logistic regression model is used to characterize the land use distribution in the study area for metric variables odds ratios below 1 indicate that the probability of occurrence of the land use class will decrease with an increase in the explanatory variable odds ratios above 1 indicate that the probability for this land use will increase with an increase in the explanatory variable the magnitude of the odds ratio is scaled to the magnitude of the explanatory variable i e small values of the variable result in very large or very small odds ratios second all pixels of the simulated land use maps are compared to the land use classifications with the help of a confusion matrix and the percentage of correctly simulated change and persistence moreover the figure of merit that is the ratio of correctly simulated change and the total change is calculated klug et al 1992 pontius et al 2011 third the simulated maps are visually compared to the available land use classifications in addition future simulations for 2029 30 are evaluated all calculations and analyses were carried out in r r core team 2016 and with the help of the r packages raster hijmans 2016 lulcc moulds 2017 and rocr sing et al 2005 3 results 3 1 evaluation of the logistic regression models the logistic regression models for the enhanced model show that most of the available explanatory variables have been included for at least one of the land use classes only three of the twelve available hydrologic variables surface runoff groundwater recharge and water in the shallow aquifer returning to the root zone were not included in any model this is possibly due to the interrelation of the hydrologic variables which has led to an exclusion of collinear variables as well as to no significant improvement of the logistic regression models when the variable was included between eight and eleven significant variables were considered in the logistic regression model per land use class table 3 the effect of the spatial variables as indicated by the odds ratios are mostly in agreement with general expectations e g with an increasing distance to roads the probability for urban land use decreases whereas it increases for all other land uses if the steepness of slopes increases by 1 then the probability for agricultural land use classes decreases pronouncedly by 11 4 12 5 while in contrast it decreases by only 0 3 for shrubland with an increase of water stress days the probability for urban land use increases odds ratio 1 the occurrence of mixed cropland sugarcane and grassland are associated with higher soil water contents odds ratios 1 in areas with higher evapotranspiration the occurrence of forest and rice is more probable odds ratios 1 whereas grassland is less probable odds ratio 1 certainly some factors are associated with the specific characteristics of the study area expectations are met when an increase in population density yields a higher probability for urban areas odds ratio 1 and a lower probability for rice grassland and shrubland odds ratios 1 however the logistic regression results also show that an increase in population density results in a slightly higher probability for forests and mixed cropland odds ratios 1 this counterintuitive effect can be explained by mixed cropland areas and forests or park areas classified as forests adjacent to settlement areas the quality of the logistic regression models is generally good for the evaluation in 2009 10 only shrubland and grassland show roc values below 0 7 which is suggested by wu et al 2009 as a threshold for reliable precision the roc values of all other logistic regression models are clearly above this threshold ranging between 0 81 and 0 94 table 3 the model is robust in space as the small differences between calibration and spatial validation values show roc val2009 10 and roc val 2009 10 the performance even improves for some classes when the model is evaluated with the 2000 01 land use roc val 2000 01 this improvement may be attributed to the fact that the logistic regression models were set up with the hydrologic variables based on a model run with the 2000 01 land use the integration of hydrologic variables mostly improved the logistic regression models the roc val 2000 01 value was changed by 0 01 to 0 13 fig 2 when compared to logistic regression models that purely relied on the basic set of socio economic and bio physical variables upper part in table 1 the highest gain was achieved for the semi natural classes 0 06 to 0 13 naturally the basic logistic regression models used less variables 5 7 but only two for grassland and rice used all seven basic explanatory variables however the gain in performance is not directly related to the number of variables included in the logistic regression model e g rice 7 vs 11 variables with a small deterioration shrubland 5 vs 9 variables with a pronounced improvement fig 2 but to the information content of the explanatory variables for the specific land use class 3 2 evaluation of the clue s models the performance of the clue s models is evaluated using a confusion matrix comparing clue s simulations and land use classifications for 2000 01 and 2009 10 in general the performance was better in 2000 01 60 63 as compared to the performance in 2009 10 50 54 table 4 this can be attributed to the slightly better performance of the logistic regression models in 2000 01 table 3 as well as to the higher similarity of the base map for the clue s model 1989 90 classification and the 2000 01 classification this is mainly a result of the shorter temporal difference between the two classifications and consequently fewer land use changes the overall accuracy oa is on a relatively low level 50 63 the number of land use classes as well as the confusion between the semi natural classes forest shrubland and grassland that are a continuum might have contributed to these low values depending on water availability and timing of the satellite image shrubland might have been classified as grassland in the one or forest in the other classification wagner et al 2013 if these pseudo changes are accounted for i e confusion between shrubland and forest as well as shrubland and grassland are disregarded the performance improves pronouncedly oa nature 71 80 table 4 moreover if the agricultural classes were aggregated into one class the overall accuracy further improves oa nature crops 74 84 looking at the individual land use classes producer and user accuracies indicate that forest 67 79 and urban areas 55 63 are better represented than the other classes the agricultural classes in particular have low accuracies 6 38 however the accuracy for aggregated agricultural classes is much better 43 64 showing that there is a pronounced confusion between the different agricultural classes the overall accuracy is higher in 2000 01 which can mainly be attributed to correctly simulated persistence 58 5 and 59 3 the evaluation in 2009 10 shows that the model is also able to simulate change correctly when compared to 2000 01 there is more change and less persistence between 1989 90 and 2009 10 consequently the percentage of correctly simulated change increases while the percentage of correctly simulated persistence decreases table 4 underlining that the model is able to represent land use change as well as persistence at both time steps the enhanced clue s model shows a slightly better performance when compared to the model that only uses the basic set of variables 3 and 4 percentage points increase in oa in 2000 01 and 2009 10 respectively in particular the improvement in the figure of merit underlines the usefulness of the hydrologic variable set 4 and 5 3 pp in 2000 01 and 2009 10 respectively the increase in model performance can mainly be attributed to a better representation of the semi natural classes 1 pp up to 6 pp in pa ua whereas the accuracy of the agricultural classes does either not change or the improvement is mostly small table 4 the accuracy of the urban class in 2009 10 is much better 8 pp when using the model with hydrologic variables but the improvement in 2000 01 is relatively small 1 pp this class specific improvement has contributed to the more accurate representation of changed pixels in 2009 10 as urbanization is the main driver of changes in the study area the simulated land use maps for 2000 01 and 2009 10 show that general characteristics of the study area are represented in both models fig 3 these are the urban growth in the east of the catchment agricultural land use at the valley bottoms near the rivers and semi natural land use dominating the west of the catchment with a continuum from grassland to shrubland to forest from lower to higher elevations however simulations by the basic model show the influence of the explanatory variables used e g impact of elevation on forest areas in the mid northern part figs 1 and 3 whereas the patterns simulated by the model that uses all variables cannot as easily be explained by one or two explanatory variables furthermore the urban expansion is better represented by the enhanced model e g the growth along the national highway 4 to mumbai in the north eastern part of the catchment in 2009 10 figs 3 and 4 in addition the basic model simulates urban areas in some parts of the biodiversity rich western ghats in 2009 10 which are obvious allocation errors in 2000 01 and 2009 10 the enhanced model improves the basic model prediction by 2 5 pp and 4 2 pp net gain in fig 4 the simulation for 2029 30 provides a land use allocation for a future scenario the applied scenario is very simple as the demands were derived by linear extrapolation of past land use change and it is possibly not accurate with regard to the 29 4 forest areas which were larger in 2009 10 due to an earlier satellite scene nearer to the end of the monsoon season wagner et al 2013 nevertheless the pattern simulated by the enhanced clue s model looks more reasonable particularly with regard to urban growth and the location of agricultural areas which are less likely in the biodiversity rich western part of the catchment fig 3 4 discussion the model performance judged by the roc value shows that the logistic regression models were above the threshold of random separation 0 5 and with the exception of the models for grassland and shrubland were well above the threshold for reliable precision of 0 7 as suggested by wu et al 2009 the relatively low values of overall accuracy can be attributed to confusion within the semi natural classes and within the agricultural classes as the overall accuracy improves substantially if the agricultural classes are aggregated and the confusion within the semi natural classes is accounted for 21 pp and 24 pp in 2000 01 and 2009 10 respectively the catchment is dominated by small scale agriculture fields typically smaller than 1 ha so that the spatial resolution affects the model performance near misses in allocation accuracy can be accounted for by decreasing the spatial resolution pontius et al 2008 2011 the figure of merit improves to 24 2 if the resolution is 16 times decreased 480 m resolution and to 28 7 if it is decreased 64 times 1920 m resolution hence the model provides more accurate results on a coarser scale while still being sufficient for planning purposes the evaluation of the logistic regression models as well as of the clue s model simulations shows that the inclusion of hydrologic variables improved the simulation of land use changes the figure of merit that pontius et al 2011 suggest for the evaluation of land use change modeling underlines the better performance of the enhanced model even if the improvements were small e g in overall accuracy the effect can consistently be observed for all land use classes at one time step at least fig 2 and table 4 however it has to be noted that the gain in prediction accuracy has been achieved after a considerable hydrologic modeling effort if a hydrologic model is not available it is certainly faster to model land use changes without using hydrologic variables and accept a lower model performance nevertheless a model run without an update of the hydrologic variables shows that the inclusion of hydrologic variables could also be recommended if these are only available for one time step as the model performance is improved table 4 therefore spatially distributed hydrologic variables from other sources that require less processing and modeling efforts e g interpolated or remotely sensed precipitation patterns may be used our findings confirm the conclusion drawn by wagner and waske 2016 that hydrologic modeling results are useful for land use modeling like most model input data the land use classifications that are used for model calibration and validation are not free of errors the averaged overall accuracy per cropping year varies between 62 and up to more than 90 particularly accuracies for grassland shrubland and mixed cropland are relatively low wagner et al 2013 while this has an effect on the land use allocation by the models the relative improvement from the basic to the enhanced model is a reliable result as the land use classifications are consistently used for calibration and validation and for both model setups this improvement is underlined by the evaluation of the scenario simulation for 2029 30 based on our knowledge of the study area urban areas are clearly misplaced by the basic model in the biodiversity rich western ghats fig 3 whereas the enhanced model provides a more reasonable land use distribution this can be explained by the improved allocation of the semi natural land use classes by the enhanced model fig 2 that dominate the western part of the catchment as one of the key applications for models is the evaluation of possible future scenarios henríquez dole et al 2018 palmate et al 2017 verburg et al 2004b our results show that the inclusion of hydrologic variables in the modeling approach can help to avoid allocation errors and provide better scenario predictions this was already the case for a simple scenario that was defined by linear extrapolation of past trends more complex scenarios can be derived by defining the land use demands in clue s with the help of a model that accounts for macro economic demographic and technology developments as well as relevant economic policies luo et al 2010 however an accurate spatial allocation of land use change is crucial for both simple and complex scenario outlines in summary our results indicate that a closer exchange between the hydrologic and land use change modeling communities seems beneficial to both hydrologists and land use scientists wagner et al 2017 have shown that hydrologic modeling benefits from dynamic land use updates which may be provided by land use models e g mehdi et al 2015 wagner et al 2016 vice versa our results show that land use models can benefit from hydrologic modeling in addition a bi directional linkage of these models would allow for accounting for feedback effects verburg et al 2006 veldkamp and lambin 2001 as well as for a more consistent simulation of climate change impacts on hydrology which are so far mostly assessed without accounting for a consistent development of land use changes e g mango et al 2011 wagner et al 2015 5 conclusions spatially distributed hydrologic variables as they are available from hydrologic models can be used to improve the performance of land use models in this study all performance indices consistently showed that the land use model that was enhanced with hydrologic explanatory variables outperformed the basic land use model for the urbanizing mula and mutha rivers catchment in india to a certain extent moreover future simulations showed that obvious allocation errors could be avoided when using the enhanced model in addition we found that an improvement in model performance is already achieved if hydrologic variables are integrated at one time step hence even if dynamic variables are not available as e g provided by a hydrologic model it may be worthwhile to integrate spatially distributed hydrologic variables in this regard precipitation or evapotranspiration patterns that may be derived from satellite data can be interpolated from field data or are readily available from data archives e g trmm precipitation patterns modis evapotranspiration can be tested in future studies we realize that not everyone will view our results as compelling as we do for the following reasons the present study area that is subject to limited data availability might not be ideal to draw general conclusions moreover the overall improvement even though consistently observed may be regarded as too small so that other researchers may draw the conclusion that the inclusion of hydrologic variables is not worthwhile our approach should therefore be tested in study areas with sufficient data availability as well as in other climatic regions we believe that a stronger linkage and exchange between hydrologic and land use change models is beneficial as it could improve both hydrologic and land use modeling results at least to a certain extent therefore a closer linkage between the two modeling communities is recommended this would provide a basis for accounting for feedback effects and would yield a more integrated modeling approach to analyze and solve increasingly complex real world problems software and data availability we use the freely available open source hydrologic model swat arnold et al 1998 available from http swat tamu edu to produce spatially distributed hydrologic variables for the studied catchment wagner et al 2013 data sources for all utilized explanatory variables for land use change are provided in table 1 all calculations and analyses are carried out in r r core team 2016 and with the help of the r packages raster hijmans 2016 lulcc moulds 2017 and rocr sing et al 2005 which are available from https cran r project org r and the swat model run on microsoft windows and linux computers with no special hardware requirements please contact the corresponding author for any further information at pwagner hydrology uni kiel de acknowledgements we are thankful to shamita kumar and erach bharucha from the institute of environment education research at bharati vidyapeeth university pune who supported our research in the study area in many ways and from the very beginning we thank the editor and three anonymous reviewers for their constructive comments 
26241,in the arid areas of sub saharan africa perennial challenges of water scarcity and food insecurity are exacerbated by climate change and variability the development of robust strategies to cope with the region s climatic challenges requires thorough consideration of uncertainty and risk in decision making we demonstrate the use of probabilistic decision analysis to compare intervention options to prevent reservoir sedimentation in burkina faso to illustrate this approach we developed a causal impact pathway model based on the local knowledge of expert stakeholders input parameters were described by probability distributions derived from estimated confidence intervals the model was run in a monte carlo simulation to generate the range of plausible decision outcomes quantified as the net present value and the annual cash flow we used partial least squares regression analysis to identify the parameters that most affected projected intervention outcomes and we computed the expected value of perfect information evpi to highlight critical uncertainties numerical results show that the preferred intervention to secure agricultural production is a combination of dredging rock dams and a buffer scheme around the reservoir the evpi calculation reveals an information value for the profit per ton of vegetables indicating that more information on this variable would be useful for supporting the decision however without the need for follow up analysis the results show high probability of benefits given the combined interventions which given the current state of information should be preferred over inaction keywords monte carlo simulation decision analysis uncertainty assessment reservoir sedimentation burkina faso 1 introduction harsh climatic conditions and population growth are major challenges to food security in sub saharan africa ssa omisore 2017 in arid and semi arid regions across ssa farmers face highly fluctuating water supply a situation that will likely be exacerbated by climate change wood et al 2014 at the same time water demand for food production is expected to rise as populations grow amisigo et al 2015 world bank 2017 these issues are of particular concern to the upper volta river basin the region is considered highly sensitive to environmental changes and rainfall variability amisigo et al 2015 and agriculture is dominated by small scale rainfed production with very few farmers having access to irrigation less than 1 of agricultural land is irrigated bharati et al 2008 as a consequence agricultural productivity is very low in burkina faso these conditions are the root cause of widespread rural poverty sanfo and gérard 2012 to cope with the local challenges many communities governments and ngos have constructed small scale reservoirs for irrigation in rural areas more than 2000 of these structures have been built in the upper volta basin cecchi et al 2008 they provide seasonal water storage for small scale irrigation during the cropping season bharati et al 2008 water for livestock and an opportunity for fish farming venot and cecchi 2011 they act as a buffer against extreme weather events boelee et al 2013 and are considered instrumental for local food security and livelihoods palmieri et al 2001 wisser et al 2010 poussin et al 2015 however the performance of many of these reservoirs has fallen short of expectations barbier et al 2011 and many are subject to degradation and poor maintenance venot and hirvonen 2013 one of the major problems is sedimentation caused by soil erosion within the reservoir catchment which can damage the irrigation system in the short term kondolf et al 2014 and eventually fill in the reservoir completely rendering the infrastructure useless schmengler 2011 chitata et al 2014 kondolf et al 2014 rehabilitation of a reservoir damaged by sedimentation is costly at best and sometimes not possible at all kondolf et al 2014 possible intervention points for managing sedimentation are the initial design of the reservoir management of the agricultural activities and the establishment of structures in the riparian areas kondolf et al 2014 sedimentation is a major investment risk since it limits the time horizon over which communities can benefit from a reservoir this highlights the importance of appropriate management strategies through which the productive lifetime of these structures can be greatly extended palmieri et al 2001 however the best way to manage sedimentation is often not directly apparent to communities and governments due to uncertainty regarding the costs and benefits and the poor understanding of sediment generating processes and their response to management actions schleiss et al 2016 to choose appropriate strategies many policy makers development practitioners and ngos need scientific support predicting sediment yield and accumulation through time is very difficult morris and fan 1998 the universal soil loss equation usle wischmeier and smith 1978 later modified to the revised universal soil loss equation rusle renard et al 1997 has been widely applied for this purpose at the watershed scale griffin et al 1988 jain et al 2001 but it suffers from high uncertainty in factors influencing reservoir sedimentation salas and shin 1999 limitations in data availability among other factors can lead to high uncertainty in model results bayesian frameworks have been used to link model calibration and uncertainty assessment the most common approaches include the bayesian monte carlo method qian et al 2003 markov chain monte carlo kattwinkel and reichert 2017 and the generalized likelihood uncertainty estimation glue pseudo bayesian method zheng and keller 2007 which are used among other applications to establish uncertainty bounds for simulated flows fonseca et al 2014 chaudhary and hantush 2017 presented a novel approach that combines a bayesian monte carlo simulation with a maximum likelihood estimation yet such advanced treatments of uncertainty have largely been restricted to uncertainties about classic hydrological parameters whereas the success of watershed interventions often depends on a host of additional factors e g in the social and economic domains which can have a major impact on success or failure of innovations comprehensive consideration of all relevant factors is required here we present the use of decision centered models to address risks and uncertainties in sedimentation management decisions the approach embraces complexity makes recommendations that account for the imperfect state of available knowledge and identifies critical uncertainties that decision supporting research should address luedeling and shepherd 2016 decision centered models can be collaboratively developed between analysts stakeholders and decision makers through participatory processes where all important factors involved in a decision are gathered and synthesized into an ex ante impact projection model luedeling et al 2015 tools that determine the value of information can be used to identify the most critical knowledge gaps from the perspective of a decision maker aiming to optimize overall desired outcomes luedeling and goehring 2017 such modeling techniques can prioritize the knowledge gaps that should most urgently be narrowed in order to reduce uncertainty about the decision or inform the design and prioritization of future research hubbard 2014 rosenstock et al 2014 strong et al 2014 luedeling et al 2015 collecting additional information on such high value variables and using this information to update the decision model allows decision makers to iteratively improve their ability to anticipate decision outcomes and identify the preferred option when sufficient data is available the coupling with a watershed hydrological transport model might be considered research into sedimentation control in small reservoirs has largely been based on disciplinary analyses but it has not yet been able to capture many important uncertainties related to the social and natural systems on which reservoirs depend we use the specific example of a small reservoir that serves the communities of lagdwenda in the northern volta basin tenkodogo district bougou province burkina faso to demonstrate the application of decision analysis tools for sustainable management of small reservoirs sedimentation is the main operational concern affecting the reservoir it impacts the reliability of irrigation systems and is a major threat for the resilience of the local communities to all types of climatic shocks sedimentation in the reservoir results from a number of known factors such as among others poorly planned grazing of river banks or conversion of natural vegetation we demonstrate tools that can support the difficult task of deciding which interventions to choose if any to mitigate the problems of sedimentation due to the absence of riparian vegetation we make use of a causal impact pathway model constructed and parameterized based on the knowledge of local expert stakeholders we use monte carlo simulations to compare the ranges of plausible outcomes for several locally recognized interventions buffer strips rock dams dredging and combinations of these such an exercise typically involves synergies and trade offs between interventions which have been shown to affect the achievement of environmental targets at large scales gao and bryan 2017 by evaluating model outputs we seek to identify the parameters that most affect projected intervention outcomes and to highlight critical uncertainties 2 materials and methods 2 1 the reservoir of lagdwenda the reservoir of lagdwenda is located in the northern volta basin in tenkodogo district bougou province burkina faso the site is semi arid with a dry season from october to mid may and a rainy season from mid may to october average annual rainfall varies between 800 and 900 mm the warmest period is from march to may and a relatively cooler period from june to february with an annual average temperature of 29 c the reservoir of lagdwenda fig 1 had a capacity of 63 000 cubic meters in 2002 year of construction and benefited more than 7 000 people in 2005 the main use of the reservoir is irrigation for rice and vegetable production downstream from the reservoir a formal irrigation scheme has been developed fig 1a in addition farmers have established an informal cropping area upstream of the reservoir fig 1a which violates key recommendations on reservoir protection schleiss et al 2016 and contributes to sedimentation an important secondary use of the reservoir is water provision for livestock and animals in the riparian area which also contributes to sedimentation reservoir size as well as the types of crops that are cultivated vary markedly between the wet and the dry season fig 1b with the reservoir reaching its maximum extent of 55 ha at the end of the wet season when farmers practice paddy rice cultivation during the dry season farmers grow mixed vegetables and some cereals sedimentation control interventions are urgently needed and local decision makers are looking for cost effective ways to restore reservoir functions and ensure their provision over the long term 2 2 overview of the approach the method proposed in this paper provides a new approach to support practical decisions on agricultural systems in the face of risk and imperfect information it is inspired by the applied information economics aie approach developed by hubbard decision research hubbard 2014 this decision analysis approach which has been widely used in business decision support and a number of other contexts e g luedeling et al 2015 wafula et al 2018 employs participatory processes to explore in detail the consequences of a particular decision rather than aiming to precisely predict results for all available decision options which is usually impossible for even moderately complex systems aie attempts to capture the state of knowledge on all processes and input variables e g in the form of probability distributions and translate these into probabilistic simulations that predict the full range of plausible outcomes from these outputs critical knowledge gaps can be derived measurements can be undertaken to narrow these gaps and the model can successively be updated until confident decision support is possible building on the aie approach we conducted quantitative ex ante impact analyses for several decision options using monte carlo simulations to account for risks and uncertainties the methodology combines participatory approaches and modeling techniques as a first step a decision centered model is collaboratively developed between analysts main stakeholders and decision makers during a workshop model development seeks to capture all important factors for the decision regardless of whether they can easily be measured or modeled after synthesizing these variables into a model the state of knowledge on all variables is quantified through the use of probability distributions when no information is available on particular variables values are elicited from participants before providing these estimates participants are subjected to calibration training hubbard 2014 to improve their ability to estimate their state of uncertainty such training has been shown to increase people s capacity to provide accurate estimates by reducing errors of judgment lichtenstein et al 1982 all estimates are consolidated into one single probability distribution for each model parameter luedeling et al 2015 in this way uncertainty is explicitly represented as probabilities of different possible states of the world pannell and glenn 2000 a description of the process can be found in hubbard and millar 2014 basically the principle is to combine methods from decision theory economics and actuarial science in order to improve on human expert judgments in a second step once numbers are available the model is run in order to convert probabilistic inputs into probabilistic outputs which express the range of plausible decision results that can be expected we then use the expected value of perfect information evpi to determine the most critical knowledge gaps oakley et al 2010 the variables with the highest information value can be interpreted as priorities for measurements to be undertaken to reduce uncertainty around the decision rosenstock et al 2014 the evpi can thus be used to inform the design and prioritization of future research strong et al 2014 and may help reduce the range of plausible outcomes 2 3 analysis protocol 2 3 1 step 1 selecting experts the design of an efficient sedimentation management intervention for the reservoir of lagdwenda requires assessment of multiple uncertain quantities and risks beyond the lack of well established knowledge on the natural and anthropogenic origins of sedimentation the issue is very often context specific to gather appropriate information we relied on experts knowledge about various ways to manage sedimentation and for identifying parameters of interest such as benefits costs and risks therefore the first stage of the protocol focuses on the delicate process of selecting the most relevant experts the selection process started five months before the decision workshop with a field visit of the area in which we met the local communities and their representatives we also participated in a stakeholder workshop organized in the province by the local office of snv netherlands development organization we used the event as an opportunity to establish direct contacts with officers from the ministries of agriculture and environment as well as local ngos and to get a better overview of local experts and relevant stakeholders we collected names and details of potential participants and worked closely with snv and the agricultural officer of tenkodogo province to maintain connections with the local community representatives the list of potential invitees to a decision analysis workshop was then reduced using selection criteria e g those who have relevant expertise for the specific context of the lagdwenda reservoir from these we selected a group of eight national level and local experts who were agricultural specialists donors policy makers and the local communities 2 3 2 step 2 eliciting model structure the process to elicit model structures through experts has several steps first experts are invited to participate in a decision workshop the information collected in the participatory analysis of the decision problem is assembled into a conceptual graphical model this is constructed as a decision s impact pathway with causal relationships based on experts expectations gathered during brainstorming sessions the conceptual model development aims to capture the big picture of the decision by gathering all system dynamics and relevant issues without taking constraints of measurement into account to elicit more details we followed the four stage procedure fig 2 outlined by whitney et al 2018 in the first stage of the procedure the decision about sedimentation control was broken down by the entire group into specific sub questions in the second stage participants were split into working groups to address the different questions both individually and within their groups we used participatory techniques to avoid problems of variation among experts bolger and wright 2017 for example individual outputs were peer reviewed by the other members of the group after which the outputs were revised until a consensus was reached in the third stage the models produced in working groups were unified into consolidated models one for each of the initial sub questions in the fourth stage the consolidated sub models were combined into one single conceptual model the final conceptual model represented the impact pathway of the management decision that could be formally modeled and simulated 2 3 3 step 3 calibrating experts parameters of the model are catalogued and grouped into two categories cf fig 3 the first category gathers parameters that can be documented by existing academic or technical sources e g databases reports literature the second category consists of all parameters for which no such sources exist and that should be estimated these data are simply too costly and could take too much time to obtain through survey or field studies to account for this in the lagdwenda case we relied on experts knowledge to assess the value of these parameters but also the uncertainty around these values it should be noted here that this methodology can be applied regardless of whether these uncertainties result from lack of theoretically attainable knowledge or parameter uncertainties such as future rainfall amounts that cannot currently be known precisely elicitation techniques are a well recognized form of knowledge generation in situations where sampling efforts would be impractical or too expensive samantha et al 2009 and formal procedures for eliciting and encoding have been adopted and tested for application in conservation science martin et al 2012 expert knowledge can be valuable for decision support provided it is combined with explicit consideration of uncertainty fred et al 2017 if uncertainty is ignored however expert knowledge can manifest as spurious opinions which can undermine any well intentioned decision analysis process morgan 2014 it is therefore crucial to elicit this information rigorously in order to get valid estimates this requires recognition and correction for several biases that can affect people s judgement lichtenstein et al 1982 soll and klayman 2004 in order to avoid such biases we train experts in techniques that have been shown to improve people s ability to estimate their own uncertainty and thereby reduce errors of judgement this is a crucial step in the elicitation process fig 3 all experts are required to undergo calibration training which teaches them how to make estimates as reliably as possible the training consists of a series of procedures grounded on research findings in cognitive psychology through these procedures participants learn how to assess their state of uncertainty and reduce errors of judgement through exercises that reveal to them their personal biases overconfidence or underconfidence to this end they compare their performance in responding to trivia questions to the correct answers to these questions rather than providing best guesses participants are requested to provide two numbers for which they are 90 sure that the correct answer is between these numbers perfectly calibrated estimators should get 90 of their range estimates correct once exposed to their biases most people are initially overconfident experts are instructed in a set of mental techniques that has been shown to improve people s ability to provide accurate estimates more information on these procedures can be found in hubbard 2014 2 3 4 step 4 estimation and simulation calibrated experts were trained to use conscious estimation procedures to provide subjective probability distributions for uncertain variables in the decision model this is usually done by eliciting confidence intervals defined by their upper and lower bounds that have a 90 chance of containing the value of interest selecting a distribution is not always easy for experts who often default to a normal uniform or triangular distribution to help with this common distribution shapes were displayed during the estimation process when multiple experts estimate the same quantities a subsequent process to reconcile different estimates is needed a general conclusion from the literature on how to combine the diverse elicited values is that averaging is often a preferred strategy aidan et al 2015 since we had a small expert group we were able to aggregate individual assessments by consensus the resulting conceptual model was then reformulated as a set of equations that reflected as much as possible the experts and analysts understanding of the decision this mathematical model was coded as a function in r programming language r core team 2017 all formulas and scripts are available in the supplementary materials as well as in a separate data repository luedeling et al 2018 the model was then parameterized either with hard data or calibrated estimates and run 10 000 times as a probabilistic monte carlo simulation this number of runs was sufficient for generating smooth outcome distributions for all cases which was verified by visual inspection each run provided one possible outcome the totality of all model runs generated a probability distribution that illustrates the plausible outcomes given the experts current state of uncertainty 2 3 5 step 5 sensitivity analysis and refinement of the model the output of a monte carlo simulation often directly reveals a clearly preferable option e g a specific intervention in a group of possible interventions however the value of expected outcomes can remain unclear when uncertainty about input values is high sensitivity analysis can identify variables that outcome projections respond to we used partial least squares pls regression analysis in particular its variable importance in the projection vip metric for identifying the variables that most affected the decision outcomes projected by the simulation wold 1995 luedeling and gassner 2012 we preferred this method over more systematic sensitivity analysis methods such as the efast gao et al 2016 or morris gao and bryan 2016 methods because it determines sensitivity to input variables based on the outputs of the monte carlo analysis rather than requiring computationally expensive additional simulation runs for monte carlo simulation and sensitivity analysis we used the decisionsupport package luedeling and goehring 2017 in r in cases where the outputs of the monte carlo simulation clearly identify one decision option as preferable over the alternatives the current state of knowledge is sufficient for issuing a recommendation on how the decision should be taken when no option emerges as clearly preferable decision critical uncertainties can be identified using the expected value of perfect information evpi the evpi is the difference between the value of a decision made with perfect information and the value of a decision made with information that is currently available it can be interpreted as a rational willingness to pay to gain access to perfect information rather than referring to the absolute value of the decision outcome the evpi is concerned only with whether this value is positive or negative this is the only criterion that matters to a rational decision maker and additional information only needs to be collected on variables that could potentially lead to a change in the sign of the decision outcome evpi analysis identifies such variables and assigns a value to the possible information gains that could arise from additional research on them as a first step in the evpi computation procedure we used spearman s rank correlation test to check whether each of the input variables was correlated with projected outcomes if this was not the case the evpi for such variables was set to zero for all other variables the relationship between input and output variables was identified by first sorting the array of output values produced by the monte carlo simulation according to values of the respective input variable the resulting set of values was then smoothed using a second order low pass butterworth filter proakis and manolakis 1992 with a critical frequency of one divided by one tenth of the number of values in the monte carlo output smoothing is necessary at this stage to separate the signal emerging from the variable under scrutiny from the substantial noise caused by variation in all other variables which vary randomly within the monte carlo simulation the evpi was then calculated as the sum of all outputs with a sign that did not correspond to the sign of the expected value multiplied by the probability assigned to this outcome wafula et al 2018 measurements of input variables with the highest evpi which can be used to update the decision model help to narrow uncertainty about how the decision should be taken the process is repeated until the best option is determined 3 chapter 3 results 3 1 the decision model 3 1 1 scoping and design in july 2016 eight experts see acknowledgments were consulted in a four day workshop where they collaborated to produce graphical models of expected decision impact pathways the workshop began with framing the decision to be modeled the overall context was defined in plenary discussions after which the group of participants was split into working groups participants were asked to consider the whole impact pathway and break it down into several stages as a second step the team identified the most relevant interventions for sedimentation management in order to support the process ten interventions based on recommendations from international experts and lessons learned from other studies kondolf and al 2014 were proposed and debated by the experts see supplementary information these were intended to stimulate the discussion experts of the modeling team were free to define other sediment control interventions ultimately they identified three possible interventions dredging along the main stream inlet allowing water to flow to agricultural fields west of the reservoir and reduce sediment build up the intervention consists of dredging 3 m deep for 2 km along the main stream inlet building permeable rock dams also known as check dams along the reservoir s tributaries reducing flow velocities and the erosive potential of water these are low dams of loose stone retained by mesh wire that prevent large quantities of sediment from being deposited in the reservoir these would be constructed every 5 km along the stream network upstream of the reservoir a spacing that has frequently been used for similar interventions in this region a buffer protection scheme around the reservoir and stream inlets preventing sedimentation from agriculture around the reservoir and reducing deposits of sediments coming from the surrounding catchment the protection is composed of 3 buffer strips of 75 100 m each the first strip is made of stone barriers contour bounding with stabilizing plants grasses the second strip consists of vegetables mixed with shrubs for firewood the third zone is a mix of crops with fruit trees graphic representations of all interventions are shown in fig 4 we carried out comprehensive investigations of costs benefits and risks associated with each intervention causal relationships between variables were taken into account 3 1 2 benefits costs and trade offs formally we defined a benefit as an economic surplus e g net revenue from agricultural production generated by an intervention or a combination of intervention options in comparison to the baseline case current situation broadly speaking water for irrigation and viability of the irrigation water supply system were regarded as the main benefits of sedimentation control water for irrigation because sediments accumulate in the reservoir the dam gradually loses its capacity to store water we modeled the avoided decline in irrigable area area in both upstream and downstream irrigation schemes that can be irrigated given the water stock in the reservoir as a benefit for the different scenarios viability of the irrigation water supply system the main irrigation scheme of lagdwenda is located downstream from the dam water supply is achieved through a system of pipes underneath the dam s barrier sediments regularly disrupt the functioning of this system blocking the pipes and preventing water from flowing into the agricultural area interventions that reduce sedimentation prevent the obstruction of irrigation pipes that supply this downstream irrigation scheme changes in land use trade offs were expected among land uses when implementing the buffer intervention in the current situation baseline case communities of lagdwenda grow rice and vegetables in an informal irrigation scheme located upstream close to the shore of the reservoir near the main inlet the buffer protection scheme intervention consists of three buffer strips of 75 100 m each this would result in taking this area out of cultivation on the other hand two buffers of the scheme are expected to be partially cultivated vegetables fruits and cereals 3 1 3 risks and uncertainties the model seeks to take into account all risks either natural or anthropogenic that may impact the project along its different stages to this end two categories of risks were considered ex ante risks and ex post risks ex ante risks impact the probability that an intervention is completed which affects intervention costs when the project is implemented the full cost of the intervention applies while a reduced sunk cost applies otherwise we considered three ex ante risks the lack of community involvement the lack of institutional involvement and the lack of donor involvement ex post risks impact the effectiveness of the intervention which affects the benefits ex post risks can be natural social or technical we considered three ex post risks natural hazards poor maintenance and poor design additional risk factors especially risks arising from knowledge limitations are implicitly captured by the model s probabilistic inputs for instance the risk of changes to the future sediment load of the inlet streams due to climate change was not explicitly expressed but covered by experts providing wide confidence intervals for future sedimentation rates consideration of risks and uncertainties enables a risk adjusted cost benefit analysis to inform decision making the decision model that emerged integrates all benefits costs and risks into estimates of the net present value of each option fig 5 3 1 4 decision model code we translated information on costs benefits and risks obtained from the expert workshop into mathematical equations code was developed by an expert panel of three decision analysts d lanzanova c whitney and e luedeling assumptions model inputs and the process definitions were formulated beforehand formally this phase included four steps step 1 specification of input variables based on the conceptual model fig 5 we stated the appropriate input information to run the model either estimated by the experts or computer generated as well as the output results fig 6 all input variables were estimated by experts except some general rather specific parameters such as the project time horizon the coefficient of variation or the discount factor supplementary material section 1 4 time series of intermediate variables were generated from these input parameters in order to introduce variability in estimates and randomness in risk realization final outputs of monte carlo simulation were obtained using the decisonsupport package for r see step 3 for details on process functions step 2 definition of assumptions we made several assumptions regarding costs land management representation of the sedimentation processes and intervention effectiveness total costs for an intervention depend on the realization of ex ante risks as well as the type of intervention itself generally if an ex ante risk occurs the project is not implemented and only study costs apply specifically some ex ante risks could be irrelevant e g risk of non involvement of donors for dredging and are not considered in that case supplementary material section 2 1 1 crop land allocation in the irrigation scheme downstream is assumed to remain unchanged following an intervention potential behavioral adjustments by farmers e g new cropping choice in reaction to a change in the water resource available are not considered the effect of sedimentation on water storage capacity is modeled as a decline in irrigable area over time the total irrigable area area that can be irrigated given the water stock in the reservoir follows a sigmoid function it is likely to be the largest in the first two years before it gradually decreases until half of the area is able to receive irrigation water supplementary material section 2 3 5 the effect of sedimentation on the functioning of the irrigation system is modeled as a reduction in the irrigated area due to an obstruction of pipes by sediments that prevent the scheme from being watered as for the water storage the decline in the irrigated area follows a sigmoid function blockages are likely to be rare for a few years but gradually become more frequent until the irrigation pipes are no longer operational supplementary material section 2 3 6 interventions mitigate the sedimentation effects both regarding the water storage capacity and the functioning of the irrigation system formally the impact of an intervention is modeled as delays in the decrease of the reservoir capacity to store water or in the decline of the irrigated area because of clogged pipes as well as in the chance of the pipes being cleared supplementary material section 2 3 5 and 2 3 6 step 3 selection of functional specifications as introduced in fig 6 we used several functions from the r decisionsupport package luedeling and goehring 2017 the chance event function was used for random simulation of ex ante risks as impacts on the implementation of interventions and of ex post risks as impacts on the benefits supplementary material section 2 1 the value varier vv function was used to introduce variation in time series of variables that are assumed to vary over time the function was applied to ex ante risks and for simulation of common random draws for all intervention model runs supplementary material section 2 2 the gompertz yield function was used to simulate the loss in water storage capacity irrigable area the loss of irrigated area because of the obstruction of pipes as well as the delays in these two sedimentation outcomes as a result of the implementation of an intervention it was also applied for other minor benefits such as mitigation of the decline in fish in the reservoir supplementary material sections 2 3 5 and 2 3 6 the discount function was used to calculate the net present value which is the sum of the discounted values of the time series of net benefits supplementary material sections 2 3 6 1 the decisionsupport function was used to perform the welfare decision analysis via a monte carlo simulation from input variables and to analyze the value of information from these variables supplementary material sections 3 1 step 4 validation of the model acceptance of the model assumptions process flow choice of specifications and input parameters implies a validation of the decision analysts model to the extent possible feedback on the emerging code was elicited from the experts involved in building the conceptual model the complete model code as well as a detailed explanation of its components can be found in the supplementary materials 3 2 simulation results 3 2 1 projected intervention outcomes and synergies net present values projected for the various options varied widely fig 7 reflecting high uncertainty about many input variables however some indications about overall risks and expected benefit levels could be obtained all intervention options and all their combinations had positive expected values indicating that all options promised greater benefits than inaction though all options also incurred a risk of negative net outcomes among single interventions dredging appeared to have the lowest potential for benefits but also the lowest risk of negative outcomes followed by rock dams fig 7 due to relatively high up front costs buffer strips had the greatest potential for net losses but they also promised the highest returns among the three options an intervention that combines all three options looks most promising in terms of expected value risk of losses and potential returns a careful examination of the simulation values table 1 provides more detailed insights even though dredging alone was found to be a viable low risk low return option it was inferior in all respects all npv quantiles as well as the risk of losses to an intervention that combined dredging with rock dams a similar picture emerged for rock dams implemented in isolation which promised lower returns and greater risks than a combination of rock dams and dredging both rock dams and dredging implemented alone can thus be excluded as candidates for the optimal sediment management strategy regardless of the decision maker s perception of risk however combining interventions rather than implementing only single ones may generate synergies and thus promise greater benefits and lower risks than single interventions table 1 a decision maker s perception of an investment depends both on its risk return characteristics and on the investor s degree of risk aversion the selection of an optimal intervention is therefore related to the preferences of the decision maker the exception to this rule is when an option is strongly dominant in all aspects but this does not apply here among all intervention options the combination of dredging and buffer strips and the combination of all three options appear to be most efficient associating dredging and buffer strips looks slightly less risky but the combination of the three options promises a higher median return and a greater expected value the group of experts also preferred this option therefore we will only present results for this option below 3 2 2 projected intervention outcomes and value of information our decision analysis approach produces two outputs related to the return on investment the probability distribution for the net present value npv and the annual cash flow fig 8 a and b we also provide information on the most influential uncertainties regarding the overall magnitude of the npv the vip statistic of partial least squares pls regression and regarding the emerging decision recommendation the evpi these outputs are presented for the combined intervention consisting of dredging rock dams and buffer strips fig 8 monte carlo simulation revealed a wide range of plausible outcomes for the intervention s npv positive outcomes are likely 80 0 but results also showed a significant chance of loss 20 0 the total net present value over 30 years is likely to be between 64 thousand and 338 thousand usd the 5th and 95th percentiles of the distribution with a mean value of 102 thousand usd fig 8a the cash flow analysis illustrated that substantial initial investments are needed fig 8b for implementing the intervention accordingly the expected cash flow in year 1 was negative with a 90 confidence interval between 300 and 53 thousand usd from year three cash flow analysis shows predominantly positive annual net revenue prospects ranging between 5 and 24 thousand usd the cash flow stabilized around its highest level median of 17 thousand usd towards the end of the time series emphasizing the viability of this intervention as an effective long term strategy annual benefits appeared quite predictable with a fairly narrow distribution and little variation over time 3 2 3 important uncertainties the sensitivity analysis implemented by pls regression indicated that a number of input variables had important effects on the npv fig 8c a total of 15 variables had vip scores exceeding 0 8 a threshold that is often interpreted as signifying importance eriksson et al 2001 the most influential variable was the profit on a ton of vegetables in the downstream irrigation scheme followed by the discount rate fig 8c the expected value of perfect information evpi can be expressed in monetary terms as the decision maker s willingness to pay to gain access to perfect information hubbard 2014 decision analysis typically reveals that the decision recommendation can only be influenced by a very small number of uncertain variables with many others affecting the projected npv but not its sign e g wafula et al 2018 this however is the only important criterion to a decision maker choosing the optimal option in the present case only a single variable the profitability of vegetable production in the downstream irrigation scheme had a non zero evpi fig 8d even for this variable the evpi was only around 1 100 usd which is low compared to the overall value of the intervention this implies that even with the initial state of knowledge a relatively confident recommendation can be made but that a small investment in obtaining more information on the economics of vegetable production downstream from the reservoir would be justified by increasing certainty about the decision 4 discussion here we have demonstrated the application of decision analysis techniques to support practical decisions in the face of risk and uncertainty the approach provides customized analysis for a particular decision context howard and abbas 2016 although the approach is widely applicable to other decision contexts a different set of variables would likely emerge as important for decison models of other reservoirs in the case of lagdwenda the profit per ton of vegetable and the yields of the different crops offered the most critical information to inform decision making this information especially concerning yields is highly context specific in comparison with the physical empirical models that are commonly used to evaluate intervention impacts on sedimentation which are usually deterministic and restricted to consideration of physical system dimensions uusitalo et al 2015 our modeling approach has two major advantages first it allows doing justice to the considerable importance of political and social factors that are often major determinants of intervention impacts holzkämper et al 2012 second it recognizes that uncertainty is present at every step of an environmental management analysis refsgaard et al 2007 allowing incorporation of such uncertainties into probabilistic models the extent to which a strategy is preferred over another depends on many factors including both its costs investments implementation and its benefits which in the case of lagdwenda are mainly the value of the agricultural output over a period of time in our case 30 years costs are generally based on technical information such that can be provided by engineers whereas benefits depend on a number of uncertain agricultural and economic factors e g profit per ha discount rate the use of the holistic modeling techniques described here can help decision makers consider the uncertainties instead of making decisions based only on the available technical information despite being considered the most effective technical solution to prevent sedimentation kondolf et al 2014 palmieri et al 2001 schmengler 2011 buffer strips were not the dominant option mainly because of the high initial costs of implementation this illustrates the discrepancy between the technical optimum and the best economic option for solving a problem all intervention options and all their combinations had positive expected values indicating that all options promised greater benefits than inaction though all options also incurred a risk of negative net outcomes in the context of lagdwenda sedimentation can be controlled most effectively when several interventions are implemented simultaneously synergies are generated through the interactions of the different interventions and the extra costs are more than offset by the benefits of the reduction in sedimentation this is explained by the non linear impacts of siltation on farmers irrigation system sediments that originate from erosion of the reservoir shores and from the main inlets interact with each other and result in amplified effects e g threshold effects in the clogging of irrigation pipes which makes them inoperable after a certain amount of sedimentation assessment of the value of information was useful in identifying and addressing critical uncertainties in the model the evpi helps to focus research and decrease overall uncertainty about which decision option to choose this capability makes the evpi a useful addition to a wide range of decision processes in the case of lagdwenda uncertainties arise predominantly regarding the value of benefits fig 8 the two most important uncertainties are the profit per ton of vegetables with a positive information value and the discount rate many of the important parameters such as yield and profit depend mainly on exogenous factors e g price macroeconomic policy and evolution of inflation consequently it could be challenging or impossible to gather reliable information on them especially for a longer time horizon such as the one used in this model the uncertainties exposed by the vip analysis may offer insights into where decision makers may want to conduct further technical research but such a decision should take external constraints into account through the use of the evpi analysis we were able to determine decision critical uncertainties the reduction of which could help to narrow uncertainty about how the decision should be taken evpi fig 8d values are low and only the profit per ton of vegetables has a non zero value this means that uncertainty could be reduced by taking measurements on the profits from crop production however this may not even be necessary since the low evpi and the low chance of loss 20 indicate that the combined intervention should be preferred over inaction this demonstrates how decision supporting research does not have to eliminate all uncertainty but can focus on a few key pieces of information 5 conclusion sedimentation in lagdwenda s reservoir impacts the reliability of irrigation and thereby the livelihoods of local people a problem that is common for small scale reservoirs in the upper volta this problem requires a sediment management strategy that is appropriate to the local context development of such a strategy is hindered by data scarcity for many important variables decision analysis approaches allow comprehensive ex ante assessment of the effectiveness of intervention options through collaborative development of impact pathway models data limitations are addressed through probabilistic simulation for which all variables are expressed as probability distributions and decision critical knowledge gaps are highlighted by sensitivity analysis and value of information analysis a combination of all three candidate interventions dredging rock dams and buffer strips emerged as the most effective management strategy with a relatively low chance of losses and long lasting net benefits for local communities the magnitude of net benefits depended on several uncertain variables but only a single variable the profitability of vegetable production in the downstream irrigation scheme had positive information value in consequence a relatively confident recommendation can be provided to decision makers even in the face of multiple uncertainties in addition to this the analysis revealed that most of the residual uncertainty about whether the intervention is worth doing can be addressed through limited measurements on just one variable which is probably quite easy to measure coupling local knowledge systems with rigorous simulation techniques our methodology provides actionable information for robust decision making the model is grounded on the knowledge of local experts and stakeholders who provided a unique understanding of the socio ecological system that could not have been obtained with traditional disciplinary approaches declaration of interest none acknowledgements this research was undertaken within the cgiar research program on water land and ecosystems research project on targeting agricultural innovations and ecosystem services in the northern volta river basin tai with support from cgiar fund donors http www cgiar org about us our funders the authors are grateful to the members of the panel of experts daouda sorgho lagdwenda farmers association sorgho salif local water committee of lagdwenda ismaël paré provincial department of agriculture and hydraulic infrastructures modi diallo provincial department of environment green economy and climate change sambyamba séraphin zongo nakambé water agency barnabé romuald konseiga ecr construction company mohamed wendegoudi ouédraogo voluntary association for the promotion of leadership health and development ajvls and mansour boundaogo snv world appendix a supplementary data the following is the supplementary data to this article data profile data profile burkina vignette revision html v4 burkina vignette revision html v4 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 01 016 
26241,in the arid areas of sub saharan africa perennial challenges of water scarcity and food insecurity are exacerbated by climate change and variability the development of robust strategies to cope with the region s climatic challenges requires thorough consideration of uncertainty and risk in decision making we demonstrate the use of probabilistic decision analysis to compare intervention options to prevent reservoir sedimentation in burkina faso to illustrate this approach we developed a causal impact pathway model based on the local knowledge of expert stakeholders input parameters were described by probability distributions derived from estimated confidence intervals the model was run in a monte carlo simulation to generate the range of plausible decision outcomes quantified as the net present value and the annual cash flow we used partial least squares regression analysis to identify the parameters that most affected projected intervention outcomes and we computed the expected value of perfect information evpi to highlight critical uncertainties numerical results show that the preferred intervention to secure agricultural production is a combination of dredging rock dams and a buffer scheme around the reservoir the evpi calculation reveals an information value for the profit per ton of vegetables indicating that more information on this variable would be useful for supporting the decision however without the need for follow up analysis the results show high probability of benefits given the combined interventions which given the current state of information should be preferred over inaction keywords monte carlo simulation decision analysis uncertainty assessment reservoir sedimentation burkina faso 1 introduction harsh climatic conditions and population growth are major challenges to food security in sub saharan africa ssa omisore 2017 in arid and semi arid regions across ssa farmers face highly fluctuating water supply a situation that will likely be exacerbated by climate change wood et al 2014 at the same time water demand for food production is expected to rise as populations grow amisigo et al 2015 world bank 2017 these issues are of particular concern to the upper volta river basin the region is considered highly sensitive to environmental changes and rainfall variability amisigo et al 2015 and agriculture is dominated by small scale rainfed production with very few farmers having access to irrigation less than 1 of agricultural land is irrigated bharati et al 2008 as a consequence agricultural productivity is very low in burkina faso these conditions are the root cause of widespread rural poverty sanfo and gérard 2012 to cope with the local challenges many communities governments and ngos have constructed small scale reservoirs for irrigation in rural areas more than 2000 of these structures have been built in the upper volta basin cecchi et al 2008 they provide seasonal water storage for small scale irrigation during the cropping season bharati et al 2008 water for livestock and an opportunity for fish farming venot and cecchi 2011 they act as a buffer against extreme weather events boelee et al 2013 and are considered instrumental for local food security and livelihoods palmieri et al 2001 wisser et al 2010 poussin et al 2015 however the performance of many of these reservoirs has fallen short of expectations barbier et al 2011 and many are subject to degradation and poor maintenance venot and hirvonen 2013 one of the major problems is sedimentation caused by soil erosion within the reservoir catchment which can damage the irrigation system in the short term kondolf et al 2014 and eventually fill in the reservoir completely rendering the infrastructure useless schmengler 2011 chitata et al 2014 kondolf et al 2014 rehabilitation of a reservoir damaged by sedimentation is costly at best and sometimes not possible at all kondolf et al 2014 possible intervention points for managing sedimentation are the initial design of the reservoir management of the agricultural activities and the establishment of structures in the riparian areas kondolf et al 2014 sedimentation is a major investment risk since it limits the time horizon over which communities can benefit from a reservoir this highlights the importance of appropriate management strategies through which the productive lifetime of these structures can be greatly extended palmieri et al 2001 however the best way to manage sedimentation is often not directly apparent to communities and governments due to uncertainty regarding the costs and benefits and the poor understanding of sediment generating processes and their response to management actions schleiss et al 2016 to choose appropriate strategies many policy makers development practitioners and ngos need scientific support predicting sediment yield and accumulation through time is very difficult morris and fan 1998 the universal soil loss equation usle wischmeier and smith 1978 later modified to the revised universal soil loss equation rusle renard et al 1997 has been widely applied for this purpose at the watershed scale griffin et al 1988 jain et al 2001 but it suffers from high uncertainty in factors influencing reservoir sedimentation salas and shin 1999 limitations in data availability among other factors can lead to high uncertainty in model results bayesian frameworks have been used to link model calibration and uncertainty assessment the most common approaches include the bayesian monte carlo method qian et al 2003 markov chain monte carlo kattwinkel and reichert 2017 and the generalized likelihood uncertainty estimation glue pseudo bayesian method zheng and keller 2007 which are used among other applications to establish uncertainty bounds for simulated flows fonseca et al 2014 chaudhary and hantush 2017 presented a novel approach that combines a bayesian monte carlo simulation with a maximum likelihood estimation yet such advanced treatments of uncertainty have largely been restricted to uncertainties about classic hydrological parameters whereas the success of watershed interventions often depends on a host of additional factors e g in the social and economic domains which can have a major impact on success or failure of innovations comprehensive consideration of all relevant factors is required here we present the use of decision centered models to address risks and uncertainties in sedimentation management decisions the approach embraces complexity makes recommendations that account for the imperfect state of available knowledge and identifies critical uncertainties that decision supporting research should address luedeling and shepherd 2016 decision centered models can be collaboratively developed between analysts stakeholders and decision makers through participatory processes where all important factors involved in a decision are gathered and synthesized into an ex ante impact projection model luedeling et al 2015 tools that determine the value of information can be used to identify the most critical knowledge gaps from the perspective of a decision maker aiming to optimize overall desired outcomes luedeling and goehring 2017 such modeling techniques can prioritize the knowledge gaps that should most urgently be narrowed in order to reduce uncertainty about the decision or inform the design and prioritization of future research hubbard 2014 rosenstock et al 2014 strong et al 2014 luedeling et al 2015 collecting additional information on such high value variables and using this information to update the decision model allows decision makers to iteratively improve their ability to anticipate decision outcomes and identify the preferred option when sufficient data is available the coupling with a watershed hydrological transport model might be considered research into sedimentation control in small reservoirs has largely been based on disciplinary analyses but it has not yet been able to capture many important uncertainties related to the social and natural systems on which reservoirs depend we use the specific example of a small reservoir that serves the communities of lagdwenda in the northern volta basin tenkodogo district bougou province burkina faso to demonstrate the application of decision analysis tools for sustainable management of small reservoirs sedimentation is the main operational concern affecting the reservoir it impacts the reliability of irrigation systems and is a major threat for the resilience of the local communities to all types of climatic shocks sedimentation in the reservoir results from a number of known factors such as among others poorly planned grazing of river banks or conversion of natural vegetation we demonstrate tools that can support the difficult task of deciding which interventions to choose if any to mitigate the problems of sedimentation due to the absence of riparian vegetation we make use of a causal impact pathway model constructed and parameterized based on the knowledge of local expert stakeholders we use monte carlo simulations to compare the ranges of plausible outcomes for several locally recognized interventions buffer strips rock dams dredging and combinations of these such an exercise typically involves synergies and trade offs between interventions which have been shown to affect the achievement of environmental targets at large scales gao and bryan 2017 by evaluating model outputs we seek to identify the parameters that most affect projected intervention outcomes and to highlight critical uncertainties 2 materials and methods 2 1 the reservoir of lagdwenda the reservoir of lagdwenda is located in the northern volta basin in tenkodogo district bougou province burkina faso the site is semi arid with a dry season from october to mid may and a rainy season from mid may to october average annual rainfall varies between 800 and 900 mm the warmest period is from march to may and a relatively cooler period from june to february with an annual average temperature of 29 c the reservoir of lagdwenda fig 1 had a capacity of 63 000 cubic meters in 2002 year of construction and benefited more than 7 000 people in 2005 the main use of the reservoir is irrigation for rice and vegetable production downstream from the reservoir a formal irrigation scheme has been developed fig 1a in addition farmers have established an informal cropping area upstream of the reservoir fig 1a which violates key recommendations on reservoir protection schleiss et al 2016 and contributes to sedimentation an important secondary use of the reservoir is water provision for livestock and animals in the riparian area which also contributes to sedimentation reservoir size as well as the types of crops that are cultivated vary markedly between the wet and the dry season fig 1b with the reservoir reaching its maximum extent of 55 ha at the end of the wet season when farmers practice paddy rice cultivation during the dry season farmers grow mixed vegetables and some cereals sedimentation control interventions are urgently needed and local decision makers are looking for cost effective ways to restore reservoir functions and ensure their provision over the long term 2 2 overview of the approach the method proposed in this paper provides a new approach to support practical decisions on agricultural systems in the face of risk and imperfect information it is inspired by the applied information economics aie approach developed by hubbard decision research hubbard 2014 this decision analysis approach which has been widely used in business decision support and a number of other contexts e g luedeling et al 2015 wafula et al 2018 employs participatory processes to explore in detail the consequences of a particular decision rather than aiming to precisely predict results for all available decision options which is usually impossible for even moderately complex systems aie attempts to capture the state of knowledge on all processes and input variables e g in the form of probability distributions and translate these into probabilistic simulations that predict the full range of plausible outcomes from these outputs critical knowledge gaps can be derived measurements can be undertaken to narrow these gaps and the model can successively be updated until confident decision support is possible building on the aie approach we conducted quantitative ex ante impact analyses for several decision options using monte carlo simulations to account for risks and uncertainties the methodology combines participatory approaches and modeling techniques as a first step a decision centered model is collaboratively developed between analysts main stakeholders and decision makers during a workshop model development seeks to capture all important factors for the decision regardless of whether they can easily be measured or modeled after synthesizing these variables into a model the state of knowledge on all variables is quantified through the use of probability distributions when no information is available on particular variables values are elicited from participants before providing these estimates participants are subjected to calibration training hubbard 2014 to improve their ability to estimate their state of uncertainty such training has been shown to increase people s capacity to provide accurate estimates by reducing errors of judgment lichtenstein et al 1982 all estimates are consolidated into one single probability distribution for each model parameter luedeling et al 2015 in this way uncertainty is explicitly represented as probabilities of different possible states of the world pannell and glenn 2000 a description of the process can be found in hubbard and millar 2014 basically the principle is to combine methods from decision theory economics and actuarial science in order to improve on human expert judgments in a second step once numbers are available the model is run in order to convert probabilistic inputs into probabilistic outputs which express the range of plausible decision results that can be expected we then use the expected value of perfect information evpi to determine the most critical knowledge gaps oakley et al 2010 the variables with the highest information value can be interpreted as priorities for measurements to be undertaken to reduce uncertainty around the decision rosenstock et al 2014 the evpi can thus be used to inform the design and prioritization of future research strong et al 2014 and may help reduce the range of plausible outcomes 2 3 analysis protocol 2 3 1 step 1 selecting experts the design of an efficient sedimentation management intervention for the reservoir of lagdwenda requires assessment of multiple uncertain quantities and risks beyond the lack of well established knowledge on the natural and anthropogenic origins of sedimentation the issue is very often context specific to gather appropriate information we relied on experts knowledge about various ways to manage sedimentation and for identifying parameters of interest such as benefits costs and risks therefore the first stage of the protocol focuses on the delicate process of selecting the most relevant experts the selection process started five months before the decision workshop with a field visit of the area in which we met the local communities and their representatives we also participated in a stakeholder workshop organized in the province by the local office of snv netherlands development organization we used the event as an opportunity to establish direct contacts with officers from the ministries of agriculture and environment as well as local ngos and to get a better overview of local experts and relevant stakeholders we collected names and details of potential participants and worked closely with snv and the agricultural officer of tenkodogo province to maintain connections with the local community representatives the list of potential invitees to a decision analysis workshop was then reduced using selection criteria e g those who have relevant expertise for the specific context of the lagdwenda reservoir from these we selected a group of eight national level and local experts who were agricultural specialists donors policy makers and the local communities 2 3 2 step 2 eliciting model structure the process to elicit model structures through experts has several steps first experts are invited to participate in a decision workshop the information collected in the participatory analysis of the decision problem is assembled into a conceptual graphical model this is constructed as a decision s impact pathway with causal relationships based on experts expectations gathered during brainstorming sessions the conceptual model development aims to capture the big picture of the decision by gathering all system dynamics and relevant issues without taking constraints of measurement into account to elicit more details we followed the four stage procedure fig 2 outlined by whitney et al 2018 in the first stage of the procedure the decision about sedimentation control was broken down by the entire group into specific sub questions in the second stage participants were split into working groups to address the different questions both individually and within their groups we used participatory techniques to avoid problems of variation among experts bolger and wright 2017 for example individual outputs were peer reviewed by the other members of the group after which the outputs were revised until a consensus was reached in the third stage the models produced in working groups were unified into consolidated models one for each of the initial sub questions in the fourth stage the consolidated sub models were combined into one single conceptual model the final conceptual model represented the impact pathway of the management decision that could be formally modeled and simulated 2 3 3 step 3 calibrating experts parameters of the model are catalogued and grouped into two categories cf fig 3 the first category gathers parameters that can be documented by existing academic or technical sources e g databases reports literature the second category consists of all parameters for which no such sources exist and that should be estimated these data are simply too costly and could take too much time to obtain through survey or field studies to account for this in the lagdwenda case we relied on experts knowledge to assess the value of these parameters but also the uncertainty around these values it should be noted here that this methodology can be applied regardless of whether these uncertainties result from lack of theoretically attainable knowledge or parameter uncertainties such as future rainfall amounts that cannot currently be known precisely elicitation techniques are a well recognized form of knowledge generation in situations where sampling efforts would be impractical or too expensive samantha et al 2009 and formal procedures for eliciting and encoding have been adopted and tested for application in conservation science martin et al 2012 expert knowledge can be valuable for decision support provided it is combined with explicit consideration of uncertainty fred et al 2017 if uncertainty is ignored however expert knowledge can manifest as spurious opinions which can undermine any well intentioned decision analysis process morgan 2014 it is therefore crucial to elicit this information rigorously in order to get valid estimates this requires recognition and correction for several biases that can affect people s judgement lichtenstein et al 1982 soll and klayman 2004 in order to avoid such biases we train experts in techniques that have been shown to improve people s ability to estimate their own uncertainty and thereby reduce errors of judgement this is a crucial step in the elicitation process fig 3 all experts are required to undergo calibration training which teaches them how to make estimates as reliably as possible the training consists of a series of procedures grounded on research findings in cognitive psychology through these procedures participants learn how to assess their state of uncertainty and reduce errors of judgement through exercises that reveal to them their personal biases overconfidence or underconfidence to this end they compare their performance in responding to trivia questions to the correct answers to these questions rather than providing best guesses participants are requested to provide two numbers for which they are 90 sure that the correct answer is between these numbers perfectly calibrated estimators should get 90 of their range estimates correct once exposed to their biases most people are initially overconfident experts are instructed in a set of mental techniques that has been shown to improve people s ability to provide accurate estimates more information on these procedures can be found in hubbard 2014 2 3 4 step 4 estimation and simulation calibrated experts were trained to use conscious estimation procedures to provide subjective probability distributions for uncertain variables in the decision model this is usually done by eliciting confidence intervals defined by their upper and lower bounds that have a 90 chance of containing the value of interest selecting a distribution is not always easy for experts who often default to a normal uniform or triangular distribution to help with this common distribution shapes were displayed during the estimation process when multiple experts estimate the same quantities a subsequent process to reconcile different estimates is needed a general conclusion from the literature on how to combine the diverse elicited values is that averaging is often a preferred strategy aidan et al 2015 since we had a small expert group we were able to aggregate individual assessments by consensus the resulting conceptual model was then reformulated as a set of equations that reflected as much as possible the experts and analysts understanding of the decision this mathematical model was coded as a function in r programming language r core team 2017 all formulas and scripts are available in the supplementary materials as well as in a separate data repository luedeling et al 2018 the model was then parameterized either with hard data or calibrated estimates and run 10 000 times as a probabilistic monte carlo simulation this number of runs was sufficient for generating smooth outcome distributions for all cases which was verified by visual inspection each run provided one possible outcome the totality of all model runs generated a probability distribution that illustrates the plausible outcomes given the experts current state of uncertainty 2 3 5 step 5 sensitivity analysis and refinement of the model the output of a monte carlo simulation often directly reveals a clearly preferable option e g a specific intervention in a group of possible interventions however the value of expected outcomes can remain unclear when uncertainty about input values is high sensitivity analysis can identify variables that outcome projections respond to we used partial least squares pls regression analysis in particular its variable importance in the projection vip metric for identifying the variables that most affected the decision outcomes projected by the simulation wold 1995 luedeling and gassner 2012 we preferred this method over more systematic sensitivity analysis methods such as the efast gao et al 2016 or morris gao and bryan 2016 methods because it determines sensitivity to input variables based on the outputs of the monte carlo analysis rather than requiring computationally expensive additional simulation runs for monte carlo simulation and sensitivity analysis we used the decisionsupport package luedeling and goehring 2017 in r in cases where the outputs of the monte carlo simulation clearly identify one decision option as preferable over the alternatives the current state of knowledge is sufficient for issuing a recommendation on how the decision should be taken when no option emerges as clearly preferable decision critical uncertainties can be identified using the expected value of perfect information evpi the evpi is the difference between the value of a decision made with perfect information and the value of a decision made with information that is currently available it can be interpreted as a rational willingness to pay to gain access to perfect information rather than referring to the absolute value of the decision outcome the evpi is concerned only with whether this value is positive or negative this is the only criterion that matters to a rational decision maker and additional information only needs to be collected on variables that could potentially lead to a change in the sign of the decision outcome evpi analysis identifies such variables and assigns a value to the possible information gains that could arise from additional research on them as a first step in the evpi computation procedure we used spearman s rank correlation test to check whether each of the input variables was correlated with projected outcomes if this was not the case the evpi for such variables was set to zero for all other variables the relationship between input and output variables was identified by first sorting the array of output values produced by the monte carlo simulation according to values of the respective input variable the resulting set of values was then smoothed using a second order low pass butterworth filter proakis and manolakis 1992 with a critical frequency of one divided by one tenth of the number of values in the monte carlo output smoothing is necessary at this stage to separate the signal emerging from the variable under scrutiny from the substantial noise caused by variation in all other variables which vary randomly within the monte carlo simulation the evpi was then calculated as the sum of all outputs with a sign that did not correspond to the sign of the expected value multiplied by the probability assigned to this outcome wafula et al 2018 measurements of input variables with the highest evpi which can be used to update the decision model help to narrow uncertainty about how the decision should be taken the process is repeated until the best option is determined 3 chapter 3 results 3 1 the decision model 3 1 1 scoping and design in july 2016 eight experts see acknowledgments were consulted in a four day workshop where they collaborated to produce graphical models of expected decision impact pathways the workshop began with framing the decision to be modeled the overall context was defined in plenary discussions after which the group of participants was split into working groups participants were asked to consider the whole impact pathway and break it down into several stages as a second step the team identified the most relevant interventions for sedimentation management in order to support the process ten interventions based on recommendations from international experts and lessons learned from other studies kondolf and al 2014 were proposed and debated by the experts see supplementary information these were intended to stimulate the discussion experts of the modeling team were free to define other sediment control interventions ultimately they identified three possible interventions dredging along the main stream inlet allowing water to flow to agricultural fields west of the reservoir and reduce sediment build up the intervention consists of dredging 3 m deep for 2 km along the main stream inlet building permeable rock dams also known as check dams along the reservoir s tributaries reducing flow velocities and the erosive potential of water these are low dams of loose stone retained by mesh wire that prevent large quantities of sediment from being deposited in the reservoir these would be constructed every 5 km along the stream network upstream of the reservoir a spacing that has frequently been used for similar interventions in this region a buffer protection scheme around the reservoir and stream inlets preventing sedimentation from agriculture around the reservoir and reducing deposits of sediments coming from the surrounding catchment the protection is composed of 3 buffer strips of 75 100 m each the first strip is made of stone barriers contour bounding with stabilizing plants grasses the second strip consists of vegetables mixed with shrubs for firewood the third zone is a mix of crops with fruit trees graphic representations of all interventions are shown in fig 4 we carried out comprehensive investigations of costs benefits and risks associated with each intervention causal relationships between variables were taken into account 3 1 2 benefits costs and trade offs formally we defined a benefit as an economic surplus e g net revenue from agricultural production generated by an intervention or a combination of intervention options in comparison to the baseline case current situation broadly speaking water for irrigation and viability of the irrigation water supply system were regarded as the main benefits of sedimentation control water for irrigation because sediments accumulate in the reservoir the dam gradually loses its capacity to store water we modeled the avoided decline in irrigable area area in both upstream and downstream irrigation schemes that can be irrigated given the water stock in the reservoir as a benefit for the different scenarios viability of the irrigation water supply system the main irrigation scheme of lagdwenda is located downstream from the dam water supply is achieved through a system of pipes underneath the dam s barrier sediments regularly disrupt the functioning of this system blocking the pipes and preventing water from flowing into the agricultural area interventions that reduce sedimentation prevent the obstruction of irrigation pipes that supply this downstream irrigation scheme changes in land use trade offs were expected among land uses when implementing the buffer intervention in the current situation baseline case communities of lagdwenda grow rice and vegetables in an informal irrigation scheme located upstream close to the shore of the reservoir near the main inlet the buffer protection scheme intervention consists of three buffer strips of 75 100 m each this would result in taking this area out of cultivation on the other hand two buffers of the scheme are expected to be partially cultivated vegetables fruits and cereals 3 1 3 risks and uncertainties the model seeks to take into account all risks either natural or anthropogenic that may impact the project along its different stages to this end two categories of risks were considered ex ante risks and ex post risks ex ante risks impact the probability that an intervention is completed which affects intervention costs when the project is implemented the full cost of the intervention applies while a reduced sunk cost applies otherwise we considered three ex ante risks the lack of community involvement the lack of institutional involvement and the lack of donor involvement ex post risks impact the effectiveness of the intervention which affects the benefits ex post risks can be natural social or technical we considered three ex post risks natural hazards poor maintenance and poor design additional risk factors especially risks arising from knowledge limitations are implicitly captured by the model s probabilistic inputs for instance the risk of changes to the future sediment load of the inlet streams due to climate change was not explicitly expressed but covered by experts providing wide confidence intervals for future sedimentation rates consideration of risks and uncertainties enables a risk adjusted cost benefit analysis to inform decision making the decision model that emerged integrates all benefits costs and risks into estimates of the net present value of each option fig 5 3 1 4 decision model code we translated information on costs benefits and risks obtained from the expert workshop into mathematical equations code was developed by an expert panel of three decision analysts d lanzanova c whitney and e luedeling assumptions model inputs and the process definitions were formulated beforehand formally this phase included four steps step 1 specification of input variables based on the conceptual model fig 5 we stated the appropriate input information to run the model either estimated by the experts or computer generated as well as the output results fig 6 all input variables were estimated by experts except some general rather specific parameters such as the project time horizon the coefficient of variation or the discount factor supplementary material section 1 4 time series of intermediate variables were generated from these input parameters in order to introduce variability in estimates and randomness in risk realization final outputs of monte carlo simulation were obtained using the decisonsupport package for r see step 3 for details on process functions step 2 definition of assumptions we made several assumptions regarding costs land management representation of the sedimentation processes and intervention effectiveness total costs for an intervention depend on the realization of ex ante risks as well as the type of intervention itself generally if an ex ante risk occurs the project is not implemented and only study costs apply specifically some ex ante risks could be irrelevant e g risk of non involvement of donors for dredging and are not considered in that case supplementary material section 2 1 1 crop land allocation in the irrigation scheme downstream is assumed to remain unchanged following an intervention potential behavioral adjustments by farmers e g new cropping choice in reaction to a change in the water resource available are not considered the effect of sedimentation on water storage capacity is modeled as a decline in irrigable area over time the total irrigable area area that can be irrigated given the water stock in the reservoir follows a sigmoid function it is likely to be the largest in the first two years before it gradually decreases until half of the area is able to receive irrigation water supplementary material section 2 3 5 the effect of sedimentation on the functioning of the irrigation system is modeled as a reduction in the irrigated area due to an obstruction of pipes by sediments that prevent the scheme from being watered as for the water storage the decline in the irrigated area follows a sigmoid function blockages are likely to be rare for a few years but gradually become more frequent until the irrigation pipes are no longer operational supplementary material section 2 3 6 interventions mitigate the sedimentation effects both regarding the water storage capacity and the functioning of the irrigation system formally the impact of an intervention is modeled as delays in the decrease of the reservoir capacity to store water or in the decline of the irrigated area because of clogged pipes as well as in the chance of the pipes being cleared supplementary material section 2 3 5 and 2 3 6 step 3 selection of functional specifications as introduced in fig 6 we used several functions from the r decisionsupport package luedeling and goehring 2017 the chance event function was used for random simulation of ex ante risks as impacts on the implementation of interventions and of ex post risks as impacts on the benefits supplementary material section 2 1 the value varier vv function was used to introduce variation in time series of variables that are assumed to vary over time the function was applied to ex ante risks and for simulation of common random draws for all intervention model runs supplementary material section 2 2 the gompertz yield function was used to simulate the loss in water storage capacity irrigable area the loss of irrigated area because of the obstruction of pipes as well as the delays in these two sedimentation outcomes as a result of the implementation of an intervention it was also applied for other minor benefits such as mitigation of the decline in fish in the reservoir supplementary material sections 2 3 5 and 2 3 6 the discount function was used to calculate the net present value which is the sum of the discounted values of the time series of net benefits supplementary material sections 2 3 6 1 the decisionsupport function was used to perform the welfare decision analysis via a monte carlo simulation from input variables and to analyze the value of information from these variables supplementary material sections 3 1 step 4 validation of the model acceptance of the model assumptions process flow choice of specifications and input parameters implies a validation of the decision analysts model to the extent possible feedback on the emerging code was elicited from the experts involved in building the conceptual model the complete model code as well as a detailed explanation of its components can be found in the supplementary materials 3 2 simulation results 3 2 1 projected intervention outcomes and synergies net present values projected for the various options varied widely fig 7 reflecting high uncertainty about many input variables however some indications about overall risks and expected benefit levels could be obtained all intervention options and all their combinations had positive expected values indicating that all options promised greater benefits than inaction though all options also incurred a risk of negative net outcomes among single interventions dredging appeared to have the lowest potential for benefits but also the lowest risk of negative outcomes followed by rock dams fig 7 due to relatively high up front costs buffer strips had the greatest potential for net losses but they also promised the highest returns among the three options an intervention that combines all three options looks most promising in terms of expected value risk of losses and potential returns a careful examination of the simulation values table 1 provides more detailed insights even though dredging alone was found to be a viable low risk low return option it was inferior in all respects all npv quantiles as well as the risk of losses to an intervention that combined dredging with rock dams a similar picture emerged for rock dams implemented in isolation which promised lower returns and greater risks than a combination of rock dams and dredging both rock dams and dredging implemented alone can thus be excluded as candidates for the optimal sediment management strategy regardless of the decision maker s perception of risk however combining interventions rather than implementing only single ones may generate synergies and thus promise greater benefits and lower risks than single interventions table 1 a decision maker s perception of an investment depends both on its risk return characteristics and on the investor s degree of risk aversion the selection of an optimal intervention is therefore related to the preferences of the decision maker the exception to this rule is when an option is strongly dominant in all aspects but this does not apply here among all intervention options the combination of dredging and buffer strips and the combination of all three options appear to be most efficient associating dredging and buffer strips looks slightly less risky but the combination of the three options promises a higher median return and a greater expected value the group of experts also preferred this option therefore we will only present results for this option below 3 2 2 projected intervention outcomes and value of information our decision analysis approach produces two outputs related to the return on investment the probability distribution for the net present value npv and the annual cash flow fig 8 a and b we also provide information on the most influential uncertainties regarding the overall magnitude of the npv the vip statistic of partial least squares pls regression and regarding the emerging decision recommendation the evpi these outputs are presented for the combined intervention consisting of dredging rock dams and buffer strips fig 8 monte carlo simulation revealed a wide range of plausible outcomes for the intervention s npv positive outcomes are likely 80 0 but results also showed a significant chance of loss 20 0 the total net present value over 30 years is likely to be between 64 thousand and 338 thousand usd the 5th and 95th percentiles of the distribution with a mean value of 102 thousand usd fig 8a the cash flow analysis illustrated that substantial initial investments are needed fig 8b for implementing the intervention accordingly the expected cash flow in year 1 was negative with a 90 confidence interval between 300 and 53 thousand usd from year three cash flow analysis shows predominantly positive annual net revenue prospects ranging between 5 and 24 thousand usd the cash flow stabilized around its highest level median of 17 thousand usd towards the end of the time series emphasizing the viability of this intervention as an effective long term strategy annual benefits appeared quite predictable with a fairly narrow distribution and little variation over time 3 2 3 important uncertainties the sensitivity analysis implemented by pls regression indicated that a number of input variables had important effects on the npv fig 8c a total of 15 variables had vip scores exceeding 0 8 a threshold that is often interpreted as signifying importance eriksson et al 2001 the most influential variable was the profit on a ton of vegetables in the downstream irrigation scheme followed by the discount rate fig 8c the expected value of perfect information evpi can be expressed in monetary terms as the decision maker s willingness to pay to gain access to perfect information hubbard 2014 decision analysis typically reveals that the decision recommendation can only be influenced by a very small number of uncertain variables with many others affecting the projected npv but not its sign e g wafula et al 2018 this however is the only important criterion to a decision maker choosing the optimal option in the present case only a single variable the profitability of vegetable production in the downstream irrigation scheme had a non zero evpi fig 8d even for this variable the evpi was only around 1 100 usd which is low compared to the overall value of the intervention this implies that even with the initial state of knowledge a relatively confident recommendation can be made but that a small investment in obtaining more information on the economics of vegetable production downstream from the reservoir would be justified by increasing certainty about the decision 4 discussion here we have demonstrated the application of decision analysis techniques to support practical decisions in the face of risk and uncertainty the approach provides customized analysis for a particular decision context howard and abbas 2016 although the approach is widely applicable to other decision contexts a different set of variables would likely emerge as important for decison models of other reservoirs in the case of lagdwenda the profit per ton of vegetable and the yields of the different crops offered the most critical information to inform decision making this information especially concerning yields is highly context specific in comparison with the physical empirical models that are commonly used to evaluate intervention impacts on sedimentation which are usually deterministic and restricted to consideration of physical system dimensions uusitalo et al 2015 our modeling approach has two major advantages first it allows doing justice to the considerable importance of political and social factors that are often major determinants of intervention impacts holzkämper et al 2012 second it recognizes that uncertainty is present at every step of an environmental management analysis refsgaard et al 2007 allowing incorporation of such uncertainties into probabilistic models the extent to which a strategy is preferred over another depends on many factors including both its costs investments implementation and its benefits which in the case of lagdwenda are mainly the value of the agricultural output over a period of time in our case 30 years costs are generally based on technical information such that can be provided by engineers whereas benefits depend on a number of uncertain agricultural and economic factors e g profit per ha discount rate the use of the holistic modeling techniques described here can help decision makers consider the uncertainties instead of making decisions based only on the available technical information despite being considered the most effective technical solution to prevent sedimentation kondolf et al 2014 palmieri et al 2001 schmengler 2011 buffer strips were not the dominant option mainly because of the high initial costs of implementation this illustrates the discrepancy between the technical optimum and the best economic option for solving a problem all intervention options and all their combinations had positive expected values indicating that all options promised greater benefits than inaction though all options also incurred a risk of negative net outcomes in the context of lagdwenda sedimentation can be controlled most effectively when several interventions are implemented simultaneously synergies are generated through the interactions of the different interventions and the extra costs are more than offset by the benefits of the reduction in sedimentation this is explained by the non linear impacts of siltation on farmers irrigation system sediments that originate from erosion of the reservoir shores and from the main inlets interact with each other and result in amplified effects e g threshold effects in the clogging of irrigation pipes which makes them inoperable after a certain amount of sedimentation assessment of the value of information was useful in identifying and addressing critical uncertainties in the model the evpi helps to focus research and decrease overall uncertainty about which decision option to choose this capability makes the evpi a useful addition to a wide range of decision processes in the case of lagdwenda uncertainties arise predominantly regarding the value of benefits fig 8 the two most important uncertainties are the profit per ton of vegetables with a positive information value and the discount rate many of the important parameters such as yield and profit depend mainly on exogenous factors e g price macroeconomic policy and evolution of inflation consequently it could be challenging or impossible to gather reliable information on them especially for a longer time horizon such as the one used in this model the uncertainties exposed by the vip analysis may offer insights into where decision makers may want to conduct further technical research but such a decision should take external constraints into account through the use of the evpi analysis we were able to determine decision critical uncertainties the reduction of which could help to narrow uncertainty about how the decision should be taken evpi fig 8d values are low and only the profit per ton of vegetables has a non zero value this means that uncertainty could be reduced by taking measurements on the profits from crop production however this may not even be necessary since the low evpi and the low chance of loss 20 indicate that the combined intervention should be preferred over inaction this demonstrates how decision supporting research does not have to eliminate all uncertainty but can focus on a few key pieces of information 5 conclusion sedimentation in lagdwenda s reservoir impacts the reliability of irrigation and thereby the livelihoods of local people a problem that is common for small scale reservoirs in the upper volta this problem requires a sediment management strategy that is appropriate to the local context development of such a strategy is hindered by data scarcity for many important variables decision analysis approaches allow comprehensive ex ante assessment of the effectiveness of intervention options through collaborative development of impact pathway models data limitations are addressed through probabilistic simulation for which all variables are expressed as probability distributions and decision critical knowledge gaps are highlighted by sensitivity analysis and value of information analysis a combination of all three candidate interventions dredging rock dams and buffer strips emerged as the most effective management strategy with a relatively low chance of losses and long lasting net benefits for local communities the magnitude of net benefits depended on several uncertain variables but only a single variable the profitability of vegetable production in the downstream irrigation scheme had positive information value in consequence a relatively confident recommendation can be provided to decision makers even in the face of multiple uncertainties in addition to this the analysis revealed that most of the residual uncertainty about whether the intervention is worth doing can be addressed through limited measurements on just one variable which is probably quite easy to measure coupling local knowledge systems with rigorous simulation techniques our methodology provides actionable information for robust decision making the model is grounded on the knowledge of local experts and stakeholders who provided a unique understanding of the socio ecological system that could not have been obtained with traditional disciplinary approaches declaration of interest none acknowledgements this research was undertaken within the cgiar research program on water land and ecosystems research project on targeting agricultural innovations and ecosystem services in the northern volta river basin tai with support from cgiar fund donors http www cgiar org about us our funders the authors are grateful to the members of the panel of experts daouda sorgho lagdwenda farmers association sorgho salif local water committee of lagdwenda ismaël paré provincial department of agriculture and hydraulic infrastructures modi diallo provincial department of environment green economy and climate change sambyamba séraphin zongo nakambé water agency barnabé romuald konseiga ecr construction company mohamed wendegoudi ouédraogo voluntary association for the promotion of leadership health and development ajvls and mansour boundaogo snv world appendix a supplementary data the following is the supplementary data to this article data profile data profile burkina vignette revision html v4 burkina vignette revision html v4 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 01 016 
26242,the study is focused on modelling uncertainty propagation from gis data sources and on assessing their influence on landslide susceptibility modelling a complete set of tools was developed and written in c programming language python and based on nvidia cuda technology for terrain analysis these tools are using monte carlo simulations to generate noise in elevation values and spatial delineation of landslides bodies the uncertainty propagation is assessed using pixel based cumulative probabilities statistics at the pixel level thus for each pixel from the landslide susceptibility map an estimation of landslide susceptibility uncertainty was obtained and spatially visualised the results show that weight of evidence is a robust method and is not significantly influenced by small scale variations in the primary topographic attributes the toolbox and the source code are available under the mit license keywords landslide probability estimation uncertainty propagation gpu c 1 introduction understanding the spatial distribution of natural phenomena is challenging and highly open to uncertainties which may occur randomly locally or large scale the random uncertainties are related with the precision of the instruments used to map the landslides the local systematic are related with specific space time characteristics and the large scale ones are related with the spatial discretization of the phenomena and data harmonization all these uncertainties were tackled by various researchers in the last 30 years with a increasing trend in the last decade steger et al 2016 steger et al 2017 wu et al 2015 some of the approaches were related with the quality of the spatial location of the mapped landslides and their impact in the final landslide susceptibility map zêzere et al 2009 carrara 1993 guzzetti 2005 other approaches were focused on the impact of the elevation precision from digital elevation models on the terrain modelling qin et al 2013 schlögel et al 2018 or on the effects of their spatial resolution arnone et al 2016 claessens et al 2005 schlögel et al 2018 into the main landslide predisposing factors random simulations for positional accuracy of landslide bodies was recently approached by steger et al 2016 steger et al 2017 but without considering for the random errors from elevation sources a more complex approach with simulations from positional accuracy of landslide bodies terrain attributes and categorial data using a bootstrap technique was accomplished by rossi and reichenbach 2016 but without modelling the spatial autocorrelation modelling these spatial uncertainties requires computational capacity for the manipulation of high resolution datasets it is even more computational demanding when uncertainty modelling or coupled models are used leading the scientists to develop software capable of high speed processing of geo spatial data carlotto da silva and grzybowski 2018 de souza rosa gomes et al 2014 le et al 2015 vacondio et al 2017 xia and liang 2016 the increasing trend in the acquisition of highly detailed spatial resolution datasets such as lidar and ultra high aerial images led to an increased demand for computing power although parallel processing via multiple cpus central processing unit and cores is available on mid range laptops and pc s the time necessary to process these highly detailed datasets is not always optimal as terrain modelling based on high resolution datasets comprising billions of pixels is very time consuming scientists have focused on building frameworks or algorithms that make use of the computation power of gpu s graphics processing unit which are a good alternative for high performance computers as a ratio of computation power and costs these studies are focused mostly on parallel computation in hydrology eränen et al 2014 hutchinson and gallant 2000 lukač žalik 2013 ortega and rueda 2010 sten et al 2016 yıldırım et al 2015 zhan and qin 2011 zhao and khalili 2012 on solar radiation estimation from lidar datasets lukač žalik 2013 or soil erosion modelling sten et al 2016 and the list can continue several studies have been focused on developing simple tools for terrain analyses cheng et al 2012 stpiczyński et al 2015 yıldırım et al 2015 or on extracting contour lines from digital elevation models xie 2012 coll and guerrieri 2017 the parallel processing on graphics cards unit proved to be very effective for very demanding geo computation tasks like spatial simulations uncertainty propagation and even basic geomorphometry analyses on large scale datasets lukač žalik 2013 ortega and rueda 2010 stpiczyński et al 2015 tang and feng 2017 this study aims on assessing the cumulative effect of the uncertainties from landslide inventory digital elevation models and their derived products into landslide susceptibility maps the main objective was to assess how much the random and local systematic uncertainties have an impact on the final quality of the landslide susceptibility the second objective was to develop a tool that can be used to reproduce the same analysis on various regions of the world and that can help scientists to have an estimate of the uncertainties from their landslide susceptibility maps 2 materials and methods 2 1 regional setting the study area is that of breaza town located in the curvature subcarpathians romania composed of ten settlements spread over an area of about 50 km2 fig 1 in romania breaza is recognized as an area prone to landslide activity over the last decades as these destroyed several roads and houses the overall scenery is made up of hills 400 m high in the south and about 800 m in the north western part with an average slope gradient of about 20 the area is split in half by the prahova river distinguishing a more active right side in terms of geology the area overlaps a syncline with a south east north west orientation another important parameter is the area s lithology rather heterogeneous i e layers of clay and marl frequently interrupted by sandstone conglomerates gypsum gravel and sand damian et al 2003 all these lithologies are cut by a dense stream network values from 0 3 to 1 km sqkm with complex gullies and torrential channels and by a complex fault and strike slip fault network in the last 25 years prahova river has cut a deep and steep channel that has played an important role on the activity of the landslides located on the terrace scarps the prahova river and valley are also undergoing complex engineering works to prepare the terrain for the future bucuresti brasov highway a part of the river is now underground and the main channel has been deflected from the old river bed owing to these engineering works the relationship between the landslides and river erosion is expected to no longer be valid over the centuries the natural vegetation has almost entirely been removed and has been replaced by meadows and orchards mainly apple and prunes zenaida chitu 2010 the orchards are mainly located on the landslides and the low rainfall interception rate combined with favourable lithology makes them highly susceptible to landslide occurrence similar conditions are found in the meadows where the infiltration rate is sometimes favoured by the presence of domestic animals the climate conditions are favourable for landslide occurrence with intense precipitation spread during spring and autumn the rainfall threshold that triggers landslides in this area is about 100 mm in 24 h sandric 2008 or 300 mm for a longer period that causes deep seated landslides zenaida chitu 2010 z chitu et al 2016 a complete landslide inventory was built in 2009 sandric and chitu 2009 and has been updated every year up to 2017 the classification system for the landslide inventory is based on the one of cruden varnes cruden and varnes 1996 over 90 of the landslides are deep seated rotational slides and the rest are formed by translational slides and earth flows for the present study only the deep seated rotational slides have been considered the number of the landslides considered in this study is 310 most of them are located on marl and clay and a mixture of them form hill slopes with slope gradients between 10 and 25 the data set used in the present study table 1 was manually digitised from topographical maps geological maps and ortho images the land cover was classified according to a user defined classification system which was created to best represent its contribution as a predisposing factor a part of the study area is covered with geological maps at a scale of 25 000 and a part at a scale of 50 000 therefore boundary adjustments and field observations were made to ensure a homogeneous spatial distribution of the lithological units the most frequently used factors for landslide susceptibility are the first and second derivatives of digital elevation models dems lithology land use and land cover dems represent the probable spatial distribution of the elevation on a pixel basis it does not represent actual elevation values and thus all data derived from these dems including those obtained from drones or lidar are prone to errors current technologies such as lidar insar and closed range photogrammetry have reduced these uncertainties but these are not suitable when working at the regional scale 2 2 landslide susceptibility assessment the weight of evidence wofe method is based on bayesian conditional probability theory with the main difference that the odds obtained from bayes probability theory are log transformed bonham carter 1994 bonham carter et al 1989 regmi et al 2010 the transformation makes it easier to understand the contribution of each factor to the evolution of the process the results with negative values represent non favourable factors and the results with positive weights represent favourable factors bonham carter 1994 regmi et al 2010 wofe is based on knowledge obtained from various sources of information and thus the wofe analysis as all data driven methods is more exposed to errors and uncertainties than other methods wofe uses ground truth data about the presence and absence of the phenomena with explanatory variables known as evidence to calculate the landslide susceptibility values on a pixel basis the known locations of the natural phenomena can be recorded as point data or polygon data in the case of point data they are mainly placed on the scarp of the landslide where the conditions are more closed to the initial state the main concern with the point data is related with the spatial discretization of the polygonal shape to a dimensionless representation in the case of polygon data the location is represented by the body of the landslide both cases are equally prone to uncertainties in bayesian inference wofe uses a ratio between the presence absence of phenomena and the presence absence of the evidence because polygon data involve a much larger area for the presence of phenomena it covers more possible number of cases in which landslides may have occurred the representation of the landslide body as polygons at least have the following uncertainties sandric 2008 misinterpretation of aerial satellite imagery leading the wrong delineation of the landslide body precision of landslide body delineation in the field is related with the expert experience and the topographical equipment precision this plays an important role in prior conditional and posterior probabilities calculus on very high resolution datasets a conceptual model used for assessing uncertainty propagation in landslide susceptibility is presented below in fig 2 2 3 generation of noisy dems assuming that neither the elevation values nor the mapped landslides are not error free p f fisher and tate 2006 p fisher et al 2004 an uncertainty propagation model was created and implemented as python script in arcgis for desktop using the arcpy api esri 2013 the conceptual model fig 3 is based on monte carlo simulations to generate noise in elevation and in landslide locations because the noise is generated under the normal distribution assumption a statistical test like shapiro wilk or kolmogorov smirnov is recommended to be used to check if the distribution of the user s data is normally distributed if the data is not normally distributed a transformation test like box cox csillik et al 2015 is required using the mean and standard deviation of the errors a random normally distributed value is generated for each pixel this noise is spatially smoothed and after that is added back to the original digital elevation model thus a new simulated and probable elevation dataset is obtained temme et al 2009 karssenberg and de jong 2005 by smoothing the elevation noise the dem artefacts tarekegn and sayama 2013 from the new digital elevation model are removed and the second order terrain derivatives preserve their shapes fig 8 if the noise is added directly to the original elevations then all the terrain derivatives become too noisy and hence impossible to use fig 8 letters a and b our tool offers a noise factor parameter with a recommended value between 4 and 7 for a range between 0 and 10 where 0 is the highest noise and 10 is the lowest noise 2 4 uncertainty propagation in landslide location the source for these uncertainties can be random local or large scale systematic the random uncertainties are related with the precision of the instruments used to map the landslides the local systematic are related with specific space time characteristics and the large scale ones are related with the spatial discretization of the phenomena and data harmonization all these uncertainties were tackled by various researchers in the last 30 years with an increasing trend in the last decade steger et al 2016 steger et al 2017 wu et al 2015 uncertainties are also associated with the incorrect classification of landslide types the mapping of landslides that do not exist especially when the mapping is done by visual interpretation of aerial images the accuracy of the digital elevation models used for terrain analyses and the errors from predisposing factor mapping such as land cover and lithology an important source of uncertainties in landslide susceptibility analysis is also played by the conversions between vector and raster data sets and choosing the appropriate method is recommended arnone et al 2016 all these uncertainties together play an important role in the final susceptibility map thus studies on how the uncertainties propagate in the final results are required in order to better estimate the marginal landslide susceptibility values schlögel et al 2018 rossi and reichenbach 2016 steger et al 2016 steger et al 2017 fig 4 shows the uncertainty propagation model used for generation of noisy landslides the basic idea behind this model is to decompose each landslide at the vertex level and then randomly move each vertex within an estimated mapping error brown and heuvelink 2007 the mapping error must be estimated in distance units and must be recorded from these values the mean and standard deviation values are calculated and used to generate noise the noise is added to the original locations of the vertexes and thus the vertexes are moved randomly generating new landslide locations brown and heuvelink 2007 sandric 2008 steger et al 2016 steger et al 2017 see fig 5 2 5 uncertainty propagation modelling weight of evidence the wofe with uncertainty propagation is based on the bayesian conditional probability theory bonham carter et al 1989 bonham carter 1994 with small adjustments the equations used for uncertainty propagation in wofe are presented below 1 m i n m a x p l n m i n m a x l n t s where p ln is the prior probability that a landslide will occur in certain area ln is the total area or the total number of landslides for n simulation fn are the predisposing factors and ts is the total study area and remains constant over all the simulations 2 m i n m a x p f n l n m i n m a x f n l n f n where p fn ln represents the conditional probability for n simulation and is calculated as the ratio of the overlapping area between the landslides and each factor with each simulation the landslide area and the factor area are changed and thus the conditional probability is changed 3 m i n m a x p l n f n m i n m a x p l n p f n l n p t n where p ln fn is the posterior probability which is the probability of a landslide occurring when a factor is present p fn ln is the conditional probability and p tn is the total probability for each simulation the correlation between the presence and absence of the predictive factors and the landslide presence is evaluated with the negative and positive weights their variances the contrast and studentized contrast bonham carter et al 1989 1988 a negative weight indicates the absence of a predictive factor and a positive weight indicates the presence of the predictive factor a negative contrast indicates a negative association between the predictive factor and the landslide presence and a positive contrast indicates positive association between them the studentized contrast is a measure of the uncertainty of the weights and can be used to understand if the contrast is significantly different from 0 bonham carter et al 1989 a contrast close to 0 indicates the absence of negative or positive association between the predictive factor and landslides 4 m i n m a x w n m i n m a x log p f n l n p f n l n 5 m i n m a x w n m i n m a x log p f n l n p f n l n 6 m i n m a x c n m i n m a x w n w n where wn is the negative weight wn is the positive weight and cn is the contrast for n simulation 7 m i n m a x c s n m i n m a x c n c n σ where csn is the studentized contrast for n simulation and cnσ is the standard deviation for cn 8 m i n m a x c n σ m i n m a x s 2 w n s 2 w n where s2 wn and s2 wn are the variances of negative and positive weights 9 m i n m x s 2 w n m i n m a x 1 f n l n 1 f n l n 10 m i n m x s 2 w n m i n m a x 1 f n l n 1 f n l n the susceptibility map is calculated as the sum of the contrast from all the factors after all simulations are complete each susceptibility map is normalized and statistical analyses for the entire stack of maps are performed extracting mean minimum maximum range and standard deviation per pixel the final landslide susceptibility maps are represented by these maps instead of just one map the minimum and maximum values represent the lower and upper boundaries for the landslide susceptibility and the range and standard deviations represent its sensitivity in areas where the range and standard deviation values are high the landslide susceptibility value is very sensitive as compared with areas where the range and standard deviation are lower and thus the estimated susceptibility is more trustable 3 results and discussion 3 1 model application to speed up the terrain analysis georsgpu software based on nvidia cuda technology was used the performance tests for extracting topographic parameters from dems showed significant higher speeds of execution in the favour of gpu fig 6 with values ranging from 4 times faster for big datasets up to 125 times faster for small datasets these differences are explained by the time necessary to read the dems from the hard disk all the performance tests were assessed using the time expressed in seconds necessary to compute one primary topographic parameter at the time like slope of the terrain all the primary topographic parameters were calculated to obtain an objective assessment execution times for the individual code sections were measured using nvidia visual profiler nvidia n d and the std chrono high resolution clock cppreference com n d overall measurements were performed using the measure command windows powershell cmdlet and include the load time execution time and the time necessary to save the result the tests were made against the widely used proprietary and open source software available on the market because the performance tests are made against cpu computing time the results are presented just as cpu versus gpu without discussing the difference between the cpu software used in comparisons the comparison between cpu and gpu was made against the fastest time recorded by either of the cpu software used to calculate each primary topographic parameter by doing this we eliminate the differences between the performances recorded by each widely used open source or proprietary solutions existent on the market and we ensure an objective assessment for cpu versus gpu performance fig 7 presents the difference in seconds between cpu and gpu execution time for 5000 simulations 500 simulations for each noise factor a base digital elevation model was interpolated from contour lines and elevation points using the anudem method hutchinson et al 2011 the elevation errors were calculated by cross checking the elevation points collected in the field with the base dem all the elevation points were collected with a trimble geoxh 2008 dgps differential global positioning systems with a horizontal and vertical accuracy of less than 20 cm the mean and standard deviation values for breaza town are 4 50 m and 3 67 m all the points were equally dispersed over the entire study area and no association between them and certain terrain features was identified five thousand five hundred noisy dems were generated using the conceptual model presented in fig 3 five hundred for each noise factor between 0 and 10 and for each dem a wofe analysis was performed in fig 8 several dems and its derivatives are presented for four different noise values 0 1 5 and 10 the noise values of 0 and 1 indicates a very high level of noise introduced in the base digital elevation model the slope gradient and plan curvature obtained from this dem shows the lack of spatial autocorrelation when too much noise is used most visible in the plan curvature by gradually increase of noise value meaning in this case less noise added to the base dem the spatial autocorrelation becomes stable from a value of 5 up to a value of 10 there are no significant changes on the result 3 2 landslide susceptibility for breaza town for the town breaza uncertainty propagation in the wofe analysis was tested with the following combinations of predisposing factors lithology land cover slope and terrain curvatures plan and profile the first and second derivatives of dem were classified using equal intervals with an interval value very narrow the use of very narrow intervals helps catch the smallest variations in sensitivity of the landslide susceptibility predisposing factors a dem noise value of 5 was considered optimal the noise factor controls the smoothness of the simulated elevation model and thus controls how much noise is further propagated into the analysis the lower the value the higher the noise and vice versa a noise value of 5 was considered optimal because higher noise values didn t have any significant influences on the result sandric 2008 micu et al 2017 although no simulations were performed on the land use land cover and lithology their contribution as predisposing factors could still be assessed by using the landslide simulations therefore for each simulated landslide new weights were calculated for each class from these predisposing factors for the slope classification an equal interval value of 3 was considered as the optimal interval in slope change not to small and not to large and 17 classes were obtained lower and higher intervals lead to very noisy slope contributions without any statically significant correlation with the landslides for the terrain curvature values with an equal interval of 0 5 radians were selected and distributed between an open interval of 3 radians because the model is based on the generation of noise from a normal distribution the shapiro wilk normality test shapiro and wilk 1965 was applied to both elevation and landslide errors the results showed a normal distribution for a confidence interval of 95 three landslide susceptibility maps fig 9 and fig 10 were obtained for the city of breaza showing the maximum minimum and average susceptibility value per pixel as expected the lowest values are recorded in flat areas with sand and gravels located on the top of prahova river bed or terraces medium and high susceptibility areas are present on gentle to steep slopes with orchards bare soil pastures and lithological units composed from clay marls and their mixture from all simulations a map showing the amount of difference between the maximum and the minimum susceptibility per pixel was obtained this map clearly identifies areas located mostly on the terraces and river valley as having the highest sensitivity to elevation changes and to landslide mapping errors in fig 11 fan charts are used to visualize the propagation of elevation and landslide uncertainty in the contribution of each landslide predisposing factor in each fan chart the contrast boundaries given by quartiles are used to understand the sensitivity of each factor very large boundaries indicate that the factor is very sensitive to changes in local elevation and vice versa also changes between positive and negative contrast values indicate that the factor is sensitive to local elevation changes surprisingly the terrain curvature has the smallest sensitivity to elevation uncertainties all the classes obtained for the terrain curvature plan or profile had a very clear positive contribution to landslide susceptibility only high values of convexity were recorded and they had a negative contribution for the landslide presence steger et al 2016 steger et al 2017 as expected the slope contribution to landslide susceptibility is between 7 and 30 and is very clearly distributed as positive or negative weights without any case were these signs are switched also the highest sensitivity is present only on steep slopes with values over 35 rossi and reichenbach 2016 camilo et al 2017 zêzere et al 2009 the lithology factor has positive weights as expected on clay marls and their mixture the weights and contrasts for the lithological units have not been modified across the uncertainty propagation analysis the land use and land cover factor has recorded positive weights as expected in orchards and meadows and negative values in forests the oscillations of land use and land cover classes remained almost constant across the entire classes with the exceptions for bare soil meadows and gardens for these classes the contrast marginal values were higher but still within the same sign the lack of association between the curvature of the slope and the presence of the landslides could be explained by the fact that most landslides are spread on the entire slope and are thus overlapping on both curvature types guzzetti et al 2006 steger et al 2016 although no simulations were carried out for land use land cover and lithology these predisposing factors were affected by the simulations for the landslide inventory the most affected classes were bare soil and meadows for vegetation with a range of about 0 2 between the highest and lowest probability values cai et al 2017 gullà et al 2008 on the lithological part the most sensitive ones were those with a very high positive or negative contrast this is easily explained by the landslide bodies simulations damian et al 2003 we consider that the models presented in the current paper can be used globally without specific restrictions it offers a good estimate of how the uncertainty of the landslide susceptibility is spatially distributed the main disadvantage is given by the lack of simulations into the lithology and land use land cover factors these issues are not related with just the mapping errors but with the contextual classification of these factors 4 conclusions modelling uncertainty propagation from terrain analyses and landslide bodies brings a more realistic estimate of the spatial distribution of landslide susceptibility it makes possible to understand the boundaries for susceptibility and thus to plan better for mitigation measures using very high noise values for simulations of digital elevation models completely had removed the spatial autocorrelation and led to unrealistic first and second order terrain derivatives like plan and profile curvatures on the other hand very low noise values add to much spatial autocorrelation and decreases uncertainty propagation a noise factor between 4 and 7 had led to the best results using nvidia cuda technology for data processing on gpu had led to a high increase in the speed of execution for terrain modelling allowing us to use a high number of simulations and thus to have a better estimate of how uncertainties propagates in landslide susceptibility mapping acknowledgements the study was financed by national research council romania pd118 2010 post doctoral research project modelling the uncertainty from spatial temporal data for geomorphological hazards assessment and by the project gpu framework for geospatial analysis young researchers grant icub university of bucharest 15569 01 07 2016 code and sample tools are available at https github com sandricionut landslide analysis and at https github com cristianionita georsgpu 
26242,the study is focused on modelling uncertainty propagation from gis data sources and on assessing their influence on landslide susceptibility modelling a complete set of tools was developed and written in c programming language python and based on nvidia cuda technology for terrain analysis these tools are using monte carlo simulations to generate noise in elevation values and spatial delineation of landslides bodies the uncertainty propagation is assessed using pixel based cumulative probabilities statistics at the pixel level thus for each pixel from the landslide susceptibility map an estimation of landslide susceptibility uncertainty was obtained and spatially visualised the results show that weight of evidence is a robust method and is not significantly influenced by small scale variations in the primary topographic attributes the toolbox and the source code are available under the mit license keywords landslide probability estimation uncertainty propagation gpu c 1 introduction understanding the spatial distribution of natural phenomena is challenging and highly open to uncertainties which may occur randomly locally or large scale the random uncertainties are related with the precision of the instruments used to map the landslides the local systematic are related with specific space time characteristics and the large scale ones are related with the spatial discretization of the phenomena and data harmonization all these uncertainties were tackled by various researchers in the last 30 years with a increasing trend in the last decade steger et al 2016 steger et al 2017 wu et al 2015 some of the approaches were related with the quality of the spatial location of the mapped landslides and their impact in the final landslide susceptibility map zêzere et al 2009 carrara 1993 guzzetti 2005 other approaches were focused on the impact of the elevation precision from digital elevation models on the terrain modelling qin et al 2013 schlögel et al 2018 or on the effects of their spatial resolution arnone et al 2016 claessens et al 2005 schlögel et al 2018 into the main landslide predisposing factors random simulations for positional accuracy of landslide bodies was recently approached by steger et al 2016 steger et al 2017 but without considering for the random errors from elevation sources a more complex approach with simulations from positional accuracy of landslide bodies terrain attributes and categorial data using a bootstrap technique was accomplished by rossi and reichenbach 2016 but without modelling the spatial autocorrelation modelling these spatial uncertainties requires computational capacity for the manipulation of high resolution datasets it is even more computational demanding when uncertainty modelling or coupled models are used leading the scientists to develop software capable of high speed processing of geo spatial data carlotto da silva and grzybowski 2018 de souza rosa gomes et al 2014 le et al 2015 vacondio et al 2017 xia and liang 2016 the increasing trend in the acquisition of highly detailed spatial resolution datasets such as lidar and ultra high aerial images led to an increased demand for computing power although parallel processing via multiple cpus central processing unit and cores is available on mid range laptops and pc s the time necessary to process these highly detailed datasets is not always optimal as terrain modelling based on high resolution datasets comprising billions of pixels is very time consuming scientists have focused on building frameworks or algorithms that make use of the computation power of gpu s graphics processing unit which are a good alternative for high performance computers as a ratio of computation power and costs these studies are focused mostly on parallel computation in hydrology eränen et al 2014 hutchinson and gallant 2000 lukač žalik 2013 ortega and rueda 2010 sten et al 2016 yıldırım et al 2015 zhan and qin 2011 zhao and khalili 2012 on solar radiation estimation from lidar datasets lukač žalik 2013 or soil erosion modelling sten et al 2016 and the list can continue several studies have been focused on developing simple tools for terrain analyses cheng et al 2012 stpiczyński et al 2015 yıldırım et al 2015 or on extracting contour lines from digital elevation models xie 2012 coll and guerrieri 2017 the parallel processing on graphics cards unit proved to be very effective for very demanding geo computation tasks like spatial simulations uncertainty propagation and even basic geomorphometry analyses on large scale datasets lukač žalik 2013 ortega and rueda 2010 stpiczyński et al 2015 tang and feng 2017 this study aims on assessing the cumulative effect of the uncertainties from landslide inventory digital elevation models and their derived products into landslide susceptibility maps the main objective was to assess how much the random and local systematic uncertainties have an impact on the final quality of the landslide susceptibility the second objective was to develop a tool that can be used to reproduce the same analysis on various regions of the world and that can help scientists to have an estimate of the uncertainties from their landslide susceptibility maps 2 materials and methods 2 1 regional setting the study area is that of breaza town located in the curvature subcarpathians romania composed of ten settlements spread over an area of about 50 km2 fig 1 in romania breaza is recognized as an area prone to landslide activity over the last decades as these destroyed several roads and houses the overall scenery is made up of hills 400 m high in the south and about 800 m in the north western part with an average slope gradient of about 20 the area is split in half by the prahova river distinguishing a more active right side in terms of geology the area overlaps a syncline with a south east north west orientation another important parameter is the area s lithology rather heterogeneous i e layers of clay and marl frequently interrupted by sandstone conglomerates gypsum gravel and sand damian et al 2003 all these lithologies are cut by a dense stream network values from 0 3 to 1 km sqkm with complex gullies and torrential channels and by a complex fault and strike slip fault network in the last 25 years prahova river has cut a deep and steep channel that has played an important role on the activity of the landslides located on the terrace scarps the prahova river and valley are also undergoing complex engineering works to prepare the terrain for the future bucuresti brasov highway a part of the river is now underground and the main channel has been deflected from the old river bed owing to these engineering works the relationship between the landslides and river erosion is expected to no longer be valid over the centuries the natural vegetation has almost entirely been removed and has been replaced by meadows and orchards mainly apple and prunes zenaida chitu 2010 the orchards are mainly located on the landslides and the low rainfall interception rate combined with favourable lithology makes them highly susceptible to landslide occurrence similar conditions are found in the meadows where the infiltration rate is sometimes favoured by the presence of domestic animals the climate conditions are favourable for landslide occurrence with intense precipitation spread during spring and autumn the rainfall threshold that triggers landslides in this area is about 100 mm in 24 h sandric 2008 or 300 mm for a longer period that causes deep seated landslides zenaida chitu 2010 z chitu et al 2016 a complete landslide inventory was built in 2009 sandric and chitu 2009 and has been updated every year up to 2017 the classification system for the landslide inventory is based on the one of cruden varnes cruden and varnes 1996 over 90 of the landslides are deep seated rotational slides and the rest are formed by translational slides and earth flows for the present study only the deep seated rotational slides have been considered the number of the landslides considered in this study is 310 most of them are located on marl and clay and a mixture of them form hill slopes with slope gradients between 10 and 25 the data set used in the present study table 1 was manually digitised from topographical maps geological maps and ortho images the land cover was classified according to a user defined classification system which was created to best represent its contribution as a predisposing factor a part of the study area is covered with geological maps at a scale of 25 000 and a part at a scale of 50 000 therefore boundary adjustments and field observations were made to ensure a homogeneous spatial distribution of the lithological units the most frequently used factors for landslide susceptibility are the first and second derivatives of digital elevation models dems lithology land use and land cover dems represent the probable spatial distribution of the elevation on a pixel basis it does not represent actual elevation values and thus all data derived from these dems including those obtained from drones or lidar are prone to errors current technologies such as lidar insar and closed range photogrammetry have reduced these uncertainties but these are not suitable when working at the regional scale 2 2 landslide susceptibility assessment the weight of evidence wofe method is based on bayesian conditional probability theory with the main difference that the odds obtained from bayes probability theory are log transformed bonham carter 1994 bonham carter et al 1989 regmi et al 2010 the transformation makes it easier to understand the contribution of each factor to the evolution of the process the results with negative values represent non favourable factors and the results with positive weights represent favourable factors bonham carter 1994 regmi et al 2010 wofe is based on knowledge obtained from various sources of information and thus the wofe analysis as all data driven methods is more exposed to errors and uncertainties than other methods wofe uses ground truth data about the presence and absence of the phenomena with explanatory variables known as evidence to calculate the landslide susceptibility values on a pixel basis the known locations of the natural phenomena can be recorded as point data or polygon data in the case of point data they are mainly placed on the scarp of the landslide where the conditions are more closed to the initial state the main concern with the point data is related with the spatial discretization of the polygonal shape to a dimensionless representation in the case of polygon data the location is represented by the body of the landslide both cases are equally prone to uncertainties in bayesian inference wofe uses a ratio between the presence absence of phenomena and the presence absence of the evidence because polygon data involve a much larger area for the presence of phenomena it covers more possible number of cases in which landslides may have occurred the representation of the landslide body as polygons at least have the following uncertainties sandric 2008 misinterpretation of aerial satellite imagery leading the wrong delineation of the landslide body precision of landslide body delineation in the field is related with the expert experience and the topographical equipment precision this plays an important role in prior conditional and posterior probabilities calculus on very high resolution datasets a conceptual model used for assessing uncertainty propagation in landslide susceptibility is presented below in fig 2 2 3 generation of noisy dems assuming that neither the elevation values nor the mapped landslides are not error free p f fisher and tate 2006 p fisher et al 2004 an uncertainty propagation model was created and implemented as python script in arcgis for desktop using the arcpy api esri 2013 the conceptual model fig 3 is based on monte carlo simulations to generate noise in elevation and in landslide locations because the noise is generated under the normal distribution assumption a statistical test like shapiro wilk or kolmogorov smirnov is recommended to be used to check if the distribution of the user s data is normally distributed if the data is not normally distributed a transformation test like box cox csillik et al 2015 is required using the mean and standard deviation of the errors a random normally distributed value is generated for each pixel this noise is spatially smoothed and after that is added back to the original digital elevation model thus a new simulated and probable elevation dataset is obtained temme et al 2009 karssenberg and de jong 2005 by smoothing the elevation noise the dem artefacts tarekegn and sayama 2013 from the new digital elevation model are removed and the second order terrain derivatives preserve their shapes fig 8 if the noise is added directly to the original elevations then all the terrain derivatives become too noisy and hence impossible to use fig 8 letters a and b our tool offers a noise factor parameter with a recommended value between 4 and 7 for a range between 0 and 10 where 0 is the highest noise and 10 is the lowest noise 2 4 uncertainty propagation in landslide location the source for these uncertainties can be random local or large scale systematic the random uncertainties are related with the precision of the instruments used to map the landslides the local systematic are related with specific space time characteristics and the large scale ones are related with the spatial discretization of the phenomena and data harmonization all these uncertainties were tackled by various researchers in the last 30 years with an increasing trend in the last decade steger et al 2016 steger et al 2017 wu et al 2015 uncertainties are also associated with the incorrect classification of landslide types the mapping of landslides that do not exist especially when the mapping is done by visual interpretation of aerial images the accuracy of the digital elevation models used for terrain analyses and the errors from predisposing factor mapping such as land cover and lithology an important source of uncertainties in landslide susceptibility analysis is also played by the conversions between vector and raster data sets and choosing the appropriate method is recommended arnone et al 2016 all these uncertainties together play an important role in the final susceptibility map thus studies on how the uncertainties propagate in the final results are required in order to better estimate the marginal landslide susceptibility values schlögel et al 2018 rossi and reichenbach 2016 steger et al 2016 steger et al 2017 fig 4 shows the uncertainty propagation model used for generation of noisy landslides the basic idea behind this model is to decompose each landslide at the vertex level and then randomly move each vertex within an estimated mapping error brown and heuvelink 2007 the mapping error must be estimated in distance units and must be recorded from these values the mean and standard deviation values are calculated and used to generate noise the noise is added to the original locations of the vertexes and thus the vertexes are moved randomly generating new landslide locations brown and heuvelink 2007 sandric 2008 steger et al 2016 steger et al 2017 see fig 5 2 5 uncertainty propagation modelling weight of evidence the wofe with uncertainty propagation is based on the bayesian conditional probability theory bonham carter et al 1989 bonham carter 1994 with small adjustments the equations used for uncertainty propagation in wofe are presented below 1 m i n m a x p l n m i n m a x l n t s where p ln is the prior probability that a landslide will occur in certain area ln is the total area or the total number of landslides for n simulation fn are the predisposing factors and ts is the total study area and remains constant over all the simulations 2 m i n m a x p f n l n m i n m a x f n l n f n where p fn ln represents the conditional probability for n simulation and is calculated as the ratio of the overlapping area between the landslides and each factor with each simulation the landslide area and the factor area are changed and thus the conditional probability is changed 3 m i n m a x p l n f n m i n m a x p l n p f n l n p t n where p ln fn is the posterior probability which is the probability of a landslide occurring when a factor is present p fn ln is the conditional probability and p tn is the total probability for each simulation the correlation between the presence and absence of the predictive factors and the landslide presence is evaluated with the negative and positive weights their variances the contrast and studentized contrast bonham carter et al 1989 1988 a negative weight indicates the absence of a predictive factor and a positive weight indicates the presence of the predictive factor a negative contrast indicates a negative association between the predictive factor and the landslide presence and a positive contrast indicates positive association between them the studentized contrast is a measure of the uncertainty of the weights and can be used to understand if the contrast is significantly different from 0 bonham carter et al 1989 a contrast close to 0 indicates the absence of negative or positive association between the predictive factor and landslides 4 m i n m a x w n m i n m a x log p f n l n p f n l n 5 m i n m a x w n m i n m a x log p f n l n p f n l n 6 m i n m a x c n m i n m a x w n w n where wn is the negative weight wn is the positive weight and cn is the contrast for n simulation 7 m i n m a x c s n m i n m a x c n c n σ where csn is the studentized contrast for n simulation and cnσ is the standard deviation for cn 8 m i n m a x c n σ m i n m a x s 2 w n s 2 w n where s2 wn and s2 wn are the variances of negative and positive weights 9 m i n m x s 2 w n m i n m a x 1 f n l n 1 f n l n 10 m i n m x s 2 w n m i n m a x 1 f n l n 1 f n l n the susceptibility map is calculated as the sum of the contrast from all the factors after all simulations are complete each susceptibility map is normalized and statistical analyses for the entire stack of maps are performed extracting mean minimum maximum range and standard deviation per pixel the final landslide susceptibility maps are represented by these maps instead of just one map the minimum and maximum values represent the lower and upper boundaries for the landslide susceptibility and the range and standard deviations represent its sensitivity in areas where the range and standard deviation values are high the landslide susceptibility value is very sensitive as compared with areas where the range and standard deviation are lower and thus the estimated susceptibility is more trustable 3 results and discussion 3 1 model application to speed up the terrain analysis georsgpu software based on nvidia cuda technology was used the performance tests for extracting topographic parameters from dems showed significant higher speeds of execution in the favour of gpu fig 6 with values ranging from 4 times faster for big datasets up to 125 times faster for small datasets these differences are explained by the time necessary to read the dems from the hard disk all the performance tests were assessed using the time expressed in seconds necessary to compute one primary topographic parameter at the time like slope of the terrain all the primary topographic parameters were calculated to obtain an objective assessment execution times for the individual code sections were measured using nvidia visual profiler nvidia n d and the std chrono high resolution clock cppreference com n d overall measurements were performed using the measure command windows powershell cmdlet and include the load time execution time and the time necessary to save the result the tests were made against the widely used proprietary and open source software available on the market because the performance tests are made against cpu computing time the results are presented just as cpu versus gpu without discussing the difference between the cpu software used in comparisons the comparison between cpu and gpu was made against the fastest time recorded by either of the cpu software used to calculate each primary topographic parameter by doing this we eliminate the differences between the performances recorded by each widely used open source or proprietary solutions existent on the market and we ensure an objective assessment for cpu versus gpu performance fig 7 presents the difference in seconds between cpu and gpu execution time for 5000 simulations 500 simulations for each noise factor a base digital elevation model was interpolated from contour lines and elevation points using the anudem method hutchinson et al 2011 the elevation errors were calculated by cross checking the elevation points collected in the field with the base dem all the elevation points were collected with a trimble geoxh 2008 dgps differential global positioning systems with a horizontal and vertical accuracy of less than 20 cm the mean and standard deviation values for breaza town are 4 50 m and 3 67 m all the points were equally dispersed over the entire study area and no association between them and certain terrain features was identified five thousand five hundred noisy dems were generated using the conceptual model presented in fig 3 five hundred for each noise factor between 0 and 10 and for each dem a wofe analysis was performed in fig 8 several dems and its derivatives are presented for four different noise values 0 1 5 and 10 the noise values of 0 and 1 indicates a very high level of noise introduced in the base digital elevation model the slope gradient and plan curvature obtained from this dem shows the lack of spatial autocorrelation when too much noise is used most visible in the plan curvature by gradually increase of noise value meaning in this case less noise added to the base dem the spatial autocorrelation becomes stable from a value of 5 up to a value of 10 there are no significant changes on the result 3 2 landslide susceptibility for breaza town for the town breaza uncertainty propagation in the wofe analysis was tested with the following combinations of predisposing factors lithology land cover slope and terrain curvatures plan and profile the first and second derivatives of dem were classified using equal intervals with an interval value very narrow the use of very narrow intervals helps catch the smallest variations in sensitivity of the landslide susceptibility predisposing factors a dem noise value of 5 was considered optimal the noise factor controls the smoothness of the simulated elevation model and thus controls how much noise is further propagated into the analysis the lower the value the higher the noise and vice versa a noise value of 5 was considered optimal because higher noise values didn t have any significant influences on the result sandric 2008 micu et al 2017 although no simulations were performed on the land use land cover and lithology their contribution as predisposing factors could still be assessed by using the landslide simulations therefore for each simulated landslide new weights were calculated for each class from these predisposing factors for the slope classification an equal interval value of 3 was considered as the optimal interval in slope change not to small and not to large and 17 classes were obtained lower and higher intervals lead to very noisy slope contributions without any statically significant correlation with the landslides for the terrain curvature values with an equal interval of 0 5 radians were selected and distributed between an open interval of 3 radians because the model is based on the generation of noise from a normal distribution the shapiro wilk normality test shapiro and wilk 1965 was applied to both elevation and landslide errors the results showed a normal distribution for a confidence interval of 95 three landslide susceptibility maps fig 9 and fig 10 were obtained for the city of breaza showing the maximum minimum and average susceptibility value per pixel as expected the lowest values are recorded in flat areas with sand and gravels located on the top of prahova river bed or terraces medium and high susceptibility areas are present on gentle to steep slopes with orchards bare soil pastures and lithological units composed from clay marls and their mixture from all simulations a map showing the amount of difference between the maximum and the minimum susceptibility per pixel was obtained this map clearly identifies areas located mostly on the terraces and river valley as having the highest sensitivity to elevation changes and to landslide mapping errors in fig 11 fan charts are used to visualize the propagation of elevation and landslide uncertainty in the contribution of each landslide predisposing factor in each fan chart the contrast boundaries given by quartiles are used to understand the sensitivity of each factor very large boundaries indicate that the factor is very sensitive to changes in local elevation and vice versa also changes between positive and negative contrast values indicate that the factor is sensitive to local elevation changes surprisingly the terrain curvature has the smallest sensitivity to elevation uncertainties all the classes obtained for the terrain curvature plan or profile had a very clear positive contribution to landslide susceptibility only high values of convexity were recorded and they had a negative contribution for the landslide presence steger et al 2016 steger et al 2017 as expected the slope contribution to landslide susceptibility is between 7 and 30 and is very clearly distributed as positive or negative weights without any case were these signs are switched also the highest sensitivity is present only on steep slopes with values over 35 rossi and reichenbach 2016 camilo et al 2017 zêzere et al 2009 the lithology factor has positive weights as expected on clay marls and their mixture the weights and contrasts for the lithological units have not been modified across the uncertainty propagation analysis the land use and land cover factor has recorded positive weights as expected in orchards and meadows and negative values in forests the oscillations of land use and land cover classes remained almost constant across the entire classes with the exceptions for bare soil meadows and gardens for these classes the contrast marginal values were higher but still within the same sign the lack of association between the curvature of the slope and the presence of the landslides could be explained by the fact that most landslides are spread on the entire slope and are thus overlapping on both curvature types guzzetti et al 2006 steger et al 2016 although no simulations were carried out for land use land cover and lithology these predisposing factors were affected by the simulations for the landslide inventory the most affected classes were bare soil and meadows for vegetation with a range of about 0 2 between the highest and lowest probability values cai et al 2017 gullà et al 2008 on the lithological part the most sensitive ones were those with a very high positive or negative contrast this is easily explained by the landslide bodies simulations damian et al 2003 we consider that the models presented in the current paper can be used globally without specific restrictions it offers a good estimate of how the uncertainty of the landslide susceptibility is spatially distributed the main disadvantage is given by the lack of simulations into the lithology and land use land cover factors these issues are not related with just the mapping errors but with the contextual classification of these factors 4 conclusions modelling uncertainty propagation from terrain analyses and landslide bodies brings a more realistic estimate of the spatial distribution of landslide susceptibility it makes possible to understand the boundaries for susceptibility and thus to plan better for mitigation measures using very high noise values for simulations of digital elevation models completely had removed the spatial autocorrelation and led to unrealistic first and second order terrain derivatives like plan and profile curvatures on the other hand very low noise values add to much spatial autocorrelation and decreases uncertainty propagation a noise factor between 4 and 7 had led to the best results using nvidia cuda technology for data processing on gpu had led to a high increase in the speed of execution for terrain modelling allowing us to use a high number of simulations and thus to have a better estimate of how uncertainties propagates in landslide susceptibility mapping acknowledgements the study was financed by national research council romania pd118 2010 post doctoral research project modelling the uncertainty from spatial temporal data for geomorphological hazards assessment and by the project gpu framework for geospatial analysis young researchers grant icub university of bucharest 15569 01 07 2016 code and sample tools are available at https github com sandricionut landslide analysis and at https github com cristianionita georsgpu 
26243,we evaluated whether spatially referenced regression on watershed attributes sparrow models calibrated for two adjacent usa regions could be applied at the local scale to support management decisions for streams in tennessee nutrient source apportionment of load is important for this local scale application and demands careful consideration of uncertainty in the calibrated coefficients we used gauss newton regression to test the published sparrow models for constancy of coefficient estimates between calibration sites on streams within n 59 versus outside n 327 tennessee and concluded source apportionment was unbiased for tennessee streams the sparrow models were then applied without re calibration to predict stream loads and source apportionment for tennessee streams and to build tools for displaying model results and evaluating source change scenarios this approach may inform the adaptation of other regional scale regression models for use to address water resource management issues in smaller scale watersheds keywords watershed models nutrient source apportionment decision support nutrient change scenario nitrogen phosphorus software availability name of software tennessee usa 2002 sparrow phosphorus model tennessee usa 2002 sparrow nitrogen model developers anne hoos sherry wang gregory schwarz contact address anne hoos u s geological survey lower mississippi gulf water science center 640 grassmere park suite 100 nashville tn 37211 tel 1 615 837 4760 fax 1 615 837 4700 email abhoos usgs gov software requirements microsoft windows and sas base sas sas stat and sas iml or sas university edition program language sas macro language with statistical procedures written in sas iml availability free download of sparrow source code and national model files on https water usgs gov nawqa sparrow sparrow mod html free download of tennessee 2002 sparrow phosphorus and nitrogen model files from roland 2019 model predictions of stream loads and source apportionments can be viewed using web based mapping and charting tools at https sparrow wim usgs gov sparrow tennessee google chrome compatible 1 introduction increased nutrient inputs to the environment during the last century have increased nutrient loading to many streams lakes and estuaries and may cause overgrowth of algae eutrophication and adverse effects on ecological conditions and beneficial uses the state of tennessee usa plans to address excess nutrients through its statewide nutrient reduction framework tennessee department of environment and conservation tdec 2015 priority for nutrient reduction measures is given to watersheds from which contribution to stream nitrogen and phosphorus load from anthropogenic sources is high relative to background sources implementation of tennessee s nutrient reduction framework therefore requires for each watershed in tennessee estimates of stream nutrient loads and source apportionment i e the relative contribution of nutrient inputs from different sources in an ideal world water quality managers make decisions about controlling nutrient inputs to an individual watershed or stream using local observations within the watershed in reality however water quality managers lack sufficient local information and must develop control approaches that are based on model extrapolated values the importance of source apportionment for a local scale application favors selection of a model that tracks source apportionment through both landscape and stream transport includes uncertainty analysis for the model coefficients relating source input to export and optimizes precision for those coefficient estimates examples of watershed models that track source apportionment include the process based models swat soil water assessment tool arnold et al 1990 and hype hydrologic predictions for the environment lindstrom et al 2010 and the statistical models sparrow spatially referenced regression on watershed attributes schwarz et al 2006 and pol flow de wit 2000 statistical models have the advantage of direct evaluation of coefficient uncertainty whereas coefficient uncertainty analysis for process based models requires post model analysis such as markov chain monte carlo sampling gallagher and doherty 2007 joseph and guillaume 2013 checchi et al 2007 the sparrow model approach is well suited to meet the objectives of this application sparrow is a hybrid statistical and process based mass balance model spatially explicit along a detailed stream network that uses nonlinear least squares regression to relate observations of stream nutrient loads at monitoring stations to predictor variables representing nutrient sources and upland and channel features that affect the rate of constituent delivery to streams and through the stream network the estimated coefficients describe the marginal effect of nutrient source inputs on stream nutrient loads and therefore can be used to predict changes from nutrient source change scenarios standard error of the coefficient estimates and statistical significance of each coefficient are provided as calibration output and allow the user to evaluate whether a coefficient is statistically distinguishable from zero 0 in this way the user can identify the simplest and most parsimonious model and avoid overparameterization schwarz et al 2006 sparrow has traditionally been used to model mean annual transport and the limitation which stands for any static model of a single calibration observation from each load monitoring site has favored extending sparrow model domains to large regions with many monitoring sites rather than a smaller for example tennessee only domain a larger model domain is also favored for improved precision of coefficient estimates as a larger domain translates to a wider range in sources and transport factors that in turn affords greater precision of estimated coefficients and source apportionment schwarz et al 2006 2011 although semi independent calibration over a small number of watersheds calibration sites might provide a better fit and therefore a more predictive model measured in terms of standard fit statistics a comparison of model predictions at some sequestered sites will generally show that such an approach does not perform well in extrapolation furthermore the small scale parameterization approach is not appropriate for this application because it cannot precisely determine the importance of causal factors that are homogeneous over a small region but may show greater variability over a larger scale for example atmospheric deposition of nitrogen without proper characterization of stream load response to variation in atmospheric deposition the primary objective of accurate source apportionment cannot be met a larger number of calibration sites also affords exploration of a larger number of predictor variables on the other hand a potential disadvantage of using a model with a larger calibration domain than the focus area tennessee watersheds area is that the model coefficients may be biased for a subregion within the larger region and thus may produce biased predictions of load and source apportionment in those particular subregions and under certain nutrient management scenarios the larger the calibration domain the more likely the possibility of subregion bias schwarz et al 2011 this analysis addresses the concern of possible subregion bias and thus biased predictions for a focus area by evaluating a set of regional sparrow models for constancy of coefficients between the focus area and the areas of the model domain beyond the focus area we apply a series of gauss newton regression analyses and hypothesis tests to determine if the coefficients from the regional model are constant between these subregions and therefore justify use of the regional model in informing management decisions in the focus area the regional models are then used to estimate stream nutrient loads and source apportionment for all streams in tennessee watersheds we provide a web based tool that displays stream nutrient loads and source apportionment as maps and charts for 371 watershed units 10 digit hydrologic units or huc10 units in tennessee model input files and output files that support the findings in this paper are available from roland 2019 2 study area the set of streams for which model predictions are required comprises all streams in tennessee as well as streams in adjacent states that drain toward tennessee shaded areas in fig 1 termed the tennessee watersheds area predictions are required for huc10 units with an average drainage area of about 500 km2 the tennessee watersheds area consists of predominantly forested land 53 percent with agricultural land and urban land composing 30 and 8 percent respectively the greatest intensity of row crop agriculture and fertilizer use is in the western part of the area relatively flat terrain in the middle and eastern parts of the area support some row crop and pasture land much of the land in the eastern part of the area is steeply sloping and forested phosphate rich limestone outcrops in middle tennessee contribute phosphorus to streams through natural weathering and erosion ore grade deposits of phosphate minerals were mined in this area until 1991 and runoff from mined lands may also contribute phosphorus to streams estimates of the contribution of phosphorus from surficial geologic materials are needed to differentiate the effects of natural or background sources of phosphorus from human activities garcía et al 2011 denton et al 2001 3 material and methods 3 1 previously published regional sparrow nutrient models the u s geological survey usgs has calibrated a set of regional scale sparrow models that provide estimates of stream nutrient loads and source apportionment for both nitrogen and phosphorus and for all watersheds in tennessee as well as most watersheds in the conterminous u s preston et al 2011 saleh and domagalski 2015 two of the published regional scale sparrow models include in their model domain different subsets of the streams in tennessee fig 2 the mississippi atchafalaya river basin marb model robertson and saad 2013 covers most of the area of tennessee the south atlantic gulf drainages and tennessee river basin sagt model garcía et al 2011 hoos and mcmahon 2009 includes the tennessee and conasauga river basins in tennessee about half of the area of tennessee but not the cumberland and barren river basins and the west tennessee tributaries figs 1 and 2 the large size of the marb and sagt models 3 200 000 and 780 000 km2 respectively relative to the area of interest for this application 190 000 km2 for tennessee watersheds has both advantages and disadvantages as described in section 1 neither the marb nor the sagt model domain fully encompass the tennessee watersheds area fig 2 although the marb domain comes close extending simulations to adjacent watersheds outside the calibration domain is required for either model however as the amount of overlap with the tennessee watersheds area is much greater for marb the area of required extrapolation is much smaller model input data used to calibrate the marb and sagt sparrow models of 2002 stream nutrient load are documented in robertson and saad 2013 hoos et al 2008 terziotti et al 2010 and garcía et al 2011 the digital network of stream reach segments and associated catchments used as the data framework for the sagt and marb models is the mrb e2rf1ws network brakebill and terziotti 2011 derived from the u s environmental protection agency 1 500 000 scale reach file 1 rf1 with enhancements to support national and regional scale water quality modeling nolan et al 2002 the marb and sagt sparrow phosphorus models were calibrated with overlapping sets of monitoring data 34 monitoring sites in the tennessee river basin in common and use different predictor variables to explain spatial variability in 2002 phosphorus loads and to predict source apportionment compared in table 1 the marb model explains variability in 2002 phosphorus load with 17 predictor variables 7 termed source variables represent specific sources of phosphorus 7 termed source to water transport variables describe the rate at which phosphorus mass is transported from source to stream channel and 3 variables termed in channel attenuation variables determine fraction of phosphorus mass that is transported versus stored or removed in the stream channel the sagt model explains variability in mean annual phosphorus load using some of the same source predictors point sources urban land agricultural land and agricultural livestock but uses a different approach to represent background sources and does not include a variable for channel erosion the standard error of the coefficient table 1 quantifies the sampling error which is the amount of error in the coefficient value caused by using a random sample of stream load observations the calibration sites rather than the entire population of stream loads to estimate the value the errors are generally comparable between the two models and less than 40 percent the exceptions are errors of 48 percent for soil ph and 58 percent for time of travel in streams in the sagt model the greater precision in marb coefficient estimates is due to the larger calibration set and is an advantage for applications that involve source apportionment and source change scenarios schwarz et al 2011 the marb and sagt models use different sets of predictor variables to explain spatial variability in nitrogen loads and predict source contributions to streams compared in table 2 the marb model explains variability in nitrogen load with 15 predictor variables 6 source variables 7 source to water transport variables and 2 in channel attenuation variables the sagt model explains variability in mean annual nitrogen load using essentially the same source predictors as the marb model but differs in variables related to processes controlling nitrogen mass transport from source to stream channel standard errors of the coefficient are generally larger for the sagt model due in part to the smaller sagt calibration set the large percent standard error greater than 40 percent for coefficients of the source to water transport variables that characterize the discrete spatial distribution of hydrologic landscape regions reflects the confined spatial distribution of these variables such subregion level discrete landscape variables may however be an advantage in this application in which model accuracy in a specific subregion tennessee watersheds area is of paramount interest 3 2 tests of constancy of coefficient estimates and of residual variance across subregions of the sagt model area we use two gauss newton regression gnr tests davidson and mckinnon 1993 to determine constancy of coefficients of the sagt regional model across two subregions of its domain the subregion of tennessee watersheds compared to the subregion of the remaining model domain the tests use an approach similar to the chow test for constancy but are adapted for nonlinear models and heteroscedasticity of residuals davidson and mckinnon 1993 the regional model calibration results that are evaluated in the gnr tests include the model residuals expressed in natural logarithm space and the gradients representing the partial derivatives of the predicted natural logarithm of load at monitored reaches conditioned on upstream monitored load with respect to each model coefficient conditioned prediction refers to resetting predicted load to measured load at calibration stations so that predictions reflect monitored information at all upstream stations the model residuals and the gradients are provided as standard output from the sparrow model the gradients are the non linear analog of the prediction variables for a linear model but unlike the linear case can only be evaluated with knowledge of a set of estimated coefficients only the gradients associated with coefficients that are unconstrained in the fitting process are used under the null hypothesis that the joint model is properly specified by a single set of coefficients applicable to both subregions the residuals of the model are independent of the gradients and thus uncorrelated with any transformation of the gradients for any one subregion conversely if the coefficients differ between subregions we expect the gradients associated with one of the subregions of the model to be correlated with the residuals the first test for constancy of coefficients between subregions denoted gnr test a is implemented by performing a linear regression of model residuals dependent variable on predictor variables that include the set of gradients for each calibration site as well as a transformed set of the same gradients the transformed set of gradients consists of zero values for sites in one subregion and gradient values for sites in the other it being arbitrary as to which subregion is selected for zeroing of values the second set of gradients allows for the estimation of a set of differential coefficients that effectively gives the model the ability to estimate separate model coefficients for each subregion the null hypothesis that coefficients are constant across both subregions is rejected if an f test rejects the null hypothesis that the linear coefficients associated with the transformed gradients are jointly zero the degrees of freedom associated with the numerator of the f test are the number of unconstrained coefficients estimated in the model the degrees of freedom for the denominator are the number of observations in the model minus the number of coefficients estimated in the linear regression that is twice the number of unconstrained coefficients in the model the test is based on the f distribution although the test is technically valid only asymptotically as the number of observations in both subregions goes to infinity in applying this test it is assumed that the model residuals are homoscedastic additional description of the gnr test a is given in appendix a the assumption of homoscedastic distribution of model residuals for gnr test a is of special concern for a sparrow analysis in that the prediction of load in real space requires a bias retransformation factor the value of which depends on the distribution of the model residuals if the model residuals have a different distribution between the two subregions and specifically have a different variance then not only is the premise of the test for constant coefficients described above invalid but the use of a single retransformation factor in obtaining unbiased predictions for both subregions is untenable to address the issue of potential heteroscedasticity affecting the interpretability of the test for constant coefficients we perform an alternative test suggested by davidson and mackinnon 1993 that is robust to heteroscedasticity if heteroscedasticity is present the standard coefficient covariance matrix can be biased potentially biasing any test statistic derived from it an unbiased covariance matrix can be derived by accounting for the heteroscedasticity of the residuals however this requires knowledge of the residual variances which are typically unknown the test suggested by davidson and mackinnon denoted as gnr test b is motivated by an observation made by white 1980 that under minimal qualifying conditions an asymptotically valid test statistic can be derived using an observation s squared estimated residual in place of its unknown variance the derivation of the test statistic for gnr test b is described in appendix a under the null hypothesis that coefficients are constant across all observations in the model areas the test statistic is asymptotically distributed as chi square with degrees of freedom given by the number of unconstrained estimated coefficients in the sparrow model heteroscedasticity of the residuals between the two subregions raises an additional concern in evaluating a regional scale model for a local application that being the effect of residual variance on prediction bias the sparrow model is calibrated in natural logarithm space and to derive predictions in real space it is necessary to apply a retransformation bias adjustment factor this factor is estimated as the average of the exponentially transformed model residuals corrected for leverage effects to produce residuals of equal variance and under the assumption that the true residuals are homoscedastic if residuals are not homoscedastic then using the same retransformation bias adjustment factor for all prediction locations leads to bias in particular locations with low residual variance should have a smaller bias adjustment factor than locations having a larger variance thus using a single retransformation bias adjustment factor for all locations induces an upward bias on predictions in low residual variance locations and vice versa in high variance locations the test for heteroscedasticity employed in this analysis focuses attention on differences in residual variance between the tennessee watersheds area subregion and the rest of the regional model domain the test is implemented by performing a linear regression in which the squared values of the model residuals from the regional model are regressed on an intercept and a dichotomous variable that takes the value one 1 if the observation pertains to the tennessee watersheds area subregion and zero 0 otherwise under the null hypothesis that residual variance is constant across the two regions the test is a standard t test for significance of the coefficient associated with the dichotomous variable the tests are applied to calibration results from alternate versions termed joint sagt tennessee models of the sagt phosphorus and nitrogen models these alternate versions have been calibrated using the published set of predictors tables 1 and 2 and using the calibration sites from the sagt model domain as well as calibration sites in the cumberland river basin and west tennessee for a total of 386 sites the calibration set from the joint models is grouped into two samples 59 sites in the tennessee watersheds area subregion 1 and 327 sites in the rest of the sagt calibration domain subregion 2 for analysis using the gnr tests fig 3 model input data for streams and watershed in the joint sagt tennessee model that were not included in the original model the cumberland and barren river basins and west tennessee tributaries fig 1 are taken from the data set used to calibrate the marb sparrow model and documented in robertson and saad 2013 with exceptions noted in appendix b additional details of data assembly are described in roland 2019 4 results and discussion 4 1 selecting between marb and sagt regional models for simulating phosphorus and nitrogen load in the tennessee watersheds area root mean square error rmse of the model residual variance for the marb and sagt model calibration sets is 75 percent and 58 percent for phosphorus and 57 and 33 percent for nitrogen respectively tables 1 and 2 of paramount importance for the local scale application is the bias and variance for the subset of monitoring sites in the tennessee watersheds area table 3 for phosphorus both marb and sagt model residuals have an overall negative bias overprediction for the set of monitoring sites in tennessee mean of model residuals in natural logarithm loge space is 0 29 and 0 11 for marb and sagt respectively variance of loge residuals measured as rmse is 96 and 51 percent for marb and sagt respectively sagt phosphorus predictions are therefore more accurate and precise than marb phosphorus predictions for monitoring sites in the tennessee watersheds area one explanation for the superior prediction performance by the sagt phosphorus model is that the sagt specification table 1 includes factors missing from the marb model that help explain spatial variability of phosphorus load in tennessee streams the sagt phosphorus model includes predictor variables that represent contribution to stream load from natural weathering and erosion of phosphatic limestone and from mined land table 1 a variable characterizing contribution of phosphatic limestone to stream load was tested in the marb model but was not statistically significant and therefore not included in the final model dale robertson usgs written communication 2012 its lack of significance in that model may have been due to its importance in explaining load variation for only a relatively small subset middle tennessee of the large marb observation set source apportionment of stream phosphorus load into background versus anthropogenic sources a key objective for the tennessee nutrient reduction framework differs markedly between the two regional model specifications the term background as defined for the nutrient reduction framework refers to naturally occurring factors as well as to sources like atmospheric deposition that cannot be controlled by watershed specific actions the sagt phosphorus model attributes a much larger portion of stream load mean value 45 percent to background sources compared to the marb phosphorus model mean value 4 and 11 percent for parent rock minerals and forested land and wetlands respectively table 4 mean bias of nitrogen model residuals for monitoring sites in the tennessee watersheds area is similar in magnitude but opposite in direction for marb and sagt models table 3 the marb model has an overall bias towards overprediction 0 14 and the sagt model an overall bias towards underprediction 0 12 mean variance measured as rmse is 45 percent for both models similar bias and variance suggest that the sagt and marb model specifications are equally well suited for predicting nitrogen load at tennessee monitoring sites and thus tennessee streams source apportionment of stream nitrogen load from background versus anthropogenic sources is similar between the two regional model specifications in contrast to apportionment of phosphorus load the sagt nitrogen model attributes 59 percent on average to the background source atmospheric deposition and the marb nitrogen model attributes 52 percent table 4 without strong argument to select one over the other based on model error or source apportionment we move forward with the sagt nitrogen model based on alignment of selection for nitrogen and phosphorus in other words we select the sagt model for nitrogen because the sagt model was selected for phosphorus 4 2 gauss newton regression testing for constancy of coefficients in sagt model predictions for tennessee watersheds we use the two gnr tests proposed by davidson and mackinnon 1993 and the test for constancy of residual variance to determine if there is sufficient evidence that sagt model predictions of stream nutrient loads in the tennessee watersheds area are theoretically unbiased in large samples for the phosphorus model the p value of the f test statistic from both gnr tests a and b is greater than 0 05 implying failure to reject the null hypothesis that the sagt phosphorus model coefficients are constant across the two subregions table 5 this result is interpreted to mean that the sagt phosphorus model specification and coefficient estimates can be used without re calibration to produce unbiased predictions of phosphorus load for streams throughout the tennessee watersheds area for the nitrogen model in contrast the p value of the f test statistic from gnr test a is 0 05 implying that the sagt nitrogen model coefficients are not constant across the two subregions the p values of the test statistic from gnr test b however shows no evidence to reject the null hypothesis that coefficients are constant across the two subregions davidson and mackinnon 1993 note that the heteroscedasticity robust test tends to reject the null hypothesis more frequently than it should so the evidence for retaining the assumption that coefficients are constant for the nitrogen model is quite strong had the null hypothesis been rejected for either phosphorus or nitrogen we would then re calibrate a sparrow model using the sites in the tennessee watersheds area plus selected sites from the remainder of the calibration domain and possibly with additional predictor variables and then test again for constancy of coefficients alternatively we could adopt the methodology described in schwarz et al 2011 to identify which model coefficients show evidence of non constancy and estimate a model which allows for regional differences in those specific coefficients such an approach conserves on degrees of freedom allowing observations from the combined regions to be used to improve the precision of the coefficient estimates for those coefficients that are deemed constant the results of the test for heteroscedasticity in residuals between the tennessee watersheds area subregion and the rest of the regional model domain reported in table 5 show no evidence of heteroscedasticity in the phosphorus model p value 0 36 but the t statistic for the nitrogen model p value 0 048 is marginally significant at the 0 05 level the sign of the t statistic for the nitrogen model is positive indicating that residual variance is larger for locations in the tennessee watersheds as compared to the watersheds in the rest of the sagt domain the evidence of heteroscedasticity in residual variance for the nitrogen model and the absence of evidence from the heteroscedasticity robust test that the coefficients of that model vary across subregions implies predictions of loads for tennessee streams using the sagt model retransformation bias adjustment factor could be biased low or high to correct for this a separate adjustment factor was estimated for streams in the tennessee subregion based only on leverage adjusted residuals for the monitoring sites in that subregion additional information about these adjustment factors for tennessee streams is described in appendix c 4 3 using the sagt sparrow model to estimate 2002 stream loads and source apportionment of phosphorus and nitrogen in tennessee watersheds the gnr tests demonstrate that the previously calibrated and published sagt phosphorus and nitrogen models can produce unbiased load predictions for tennessee streams without re calibration we therefore applied the sagt models to input data for all tennessee streams to estimate 2002 phosphorus and nitrogen load and source apportionment for each stream reach in the tennessee watersheds area the input data were combined from the sagt model data sets for streams in the tennessee and conasauga river basins and the marb model data sets for all other streams in tennessee as described in appendix b the additional steps of calculating retransformation bias adjustment factor were taken for nitrogen model predictions to correct for heteroscedasticity of the nitrogen model residuals between the tennessee watersheds area and the rest of the sagt calibration domain predictions aggregated from reach level up to river basin level are reported in table 6 phosphorus yield load per upstream area delivered to the outlet of the major river basins is 0 70 kg per hectare per year kg ha yr overall for tennessee watersheds and ranges from 0 39 to 2 04 kg ha yr across the major river basins estimates of nitrogen yield load per upstream area delivered to the outlet of the major river basins is 4 97 kg ha yr overall and ranges from 4 39 to 7 24 kg ha yr across the major river basins the much larger phosphorus and nitrogen yield from the west tennessee tributaries compared to the rest of the model area is partly due to the greater intensity of row crop agriculture and fertilizer use in these watersheds and also may be partly due to the absence of large reservoirs from these watersheds that could trap particulate nutrient load above the river basin outlet the phosphorus background source phosphate in parent rock minerals apportionment is largest for the cumberland and tennessee river basins 55 4 and 47 4 percent respectively table 6 the enrichment factor reported in table 6 is calculated as the proportion of total load to background load equivalent to 100 background source percent and is therefore lowest for the cumberland and tennessee river basins enrichment factor is an important metric in the decision process proposed in the tennessee nutrient reduction framework for identifying the need for reduction measures accuracy of model predictions of background source apportionment is therefore of paramount importance for supporting the framework tdec 2015 5 conclusions we demonstrate a series of statistical tests and decision making to address concerns of subregional bias when applying regional scale statistical models to a specific focus area the regional scale models marb and sagt nitrogen and phosphorus sparrow models have been calibrated using monitoring sites that represent a wide range of watershed and water quality conditions and under the assumption that the estimated coefficients are the same for all locations in the region schwarz et al 2011 based on a comparison of residual variance for monitoring sites within the tennessee watersheds area as alternatively derived using the sagt and marb models the marb model was rejected as viable for providing unbiased predictions for tennessee watersheds subsequent application of the gauss newton regression tests shows the sagt phosphorus and nitrogen model coefficients can be applied to predict loads in tennessee watersheds however a test of the constancy of residual variance for the nitrogen model shows it is not appropriate to apply the sagt retransformation bias adjustments to obtain predictions for these watersheds consequently the retransformation bias adjustment factor for tennessee watersheds is recomputed using only residuals pertaining to the tennessee monitoring sites predictions of 2002 stream load and source apportionment from the sagt phosphorus and nitrogen models are aggregated from reach level up to huc10 units to support decision making for the tennessee nutrient reduction framework the statistical tests and decision rules applied in this study may find increasing utility as more regional sparrow models are developed and it becomes necessary to evaluate their relevance for application in specific areas of interest the application of these tests is not confined to sparrow models of course and could be applied to assess prediction bias of any large scale nonlinear least squares regression model for a subregion of interest software availability the predictions of 2002 stream nutrient load and source apportionment for each stream reach in the tennessee watersheds area are included in the tennessee sparrow model files available from roland 2019 the model files can be used to evaluate source change scenarios by altering values for one or more source variables and re computing stream load predictions aggregated up to huc10 and huc8 units are presented in map and chart displays available on https sparrow wim usgs gov sparrow tennessee that allow the user to quickly evaluate nutrient load source apportionment and enrichment factor for each unit declaration of interests none acknowledgements this work was supported by the tennessee department of environment and conservation division of water resources and by the u s geological survey any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government appendix a additional description of tests of constancy of coefficient estimates the following describes the tests for constancy of coefficients used to validate the appropriate model to generate predictions for the tennessee watersheds the tests are described in greater detail in davidson and mackinnon 1993 the test for constancy of coefficients throughout the observations of the joint sagt tennessee model is based on the ordinary least squares estimation of the following linear model 1 u g α d d g β ε where u is an n 1 vector of residuals from the estimation of the joint sparrow model using all available sites with n being the number of sites used in estimation g is an n k matrix of gradients of the sparrow model see schwarz et al 2006 for the method used to compute the gradients of a sparrow model at the n monitoring sites with respect to the k unconstrained model coefficients conditioned on upstream monitored loads and evaluated at the nonlinear least squares coefficient estimates d is an n 1 vector consisting of elements that are either 1 if the observation pertains to the tennessee subregion or 0 if otherwise d is the n n diagonal matrix operator that forms a diagonal matrix from its n 1 vector argument α and β are each k 1 vectors of coefficients to be estimated and ε is an n 1 vector of residuals note that a sparrow model is calibrated in natural logarithm space so the residual vector u representing the dependent variable in the linear model in equation 1 is given by the natural logarithm of observed load at a monitoring site minus the predicted natural logarithm of load at the same site location conditioned on the observed values of load upstream of the site see schwarz et al 2006 under the null hypothesis that the model is properly specified by a common set of coefficients for the entire study area the β coefficients are all zero thus the applied test evaluates the joint significance of the ols estimated coefficients β ˆ the numerator for the f statistic evaluating this test is given by the difference between the explained sum of squares of the calibrated model given in equation 1 and a model in which β is constrained to equal 0 normalized by the number of degrees of freedom affected by the constraint k and the denominator of the statistic is the mean squared error of equation 1 regression s 2 ε ˆ ε ˆ n 2 k the sufficient condition for convergence in fitting the sparrow model using nonlinear least squares is g u 0 therefore g is uncorrelated with u and the explained sum of squares of the linear model in equation 1 with β constrained to 0 is zero making the difference in the explained sum of squares equal to just the explained sum of squares of the calibrated model in equation 1 the explained sum of squares for the ols calibrated model in equation 1 can be derived as follows consider pre multiplying both sides of equation 1 by the idempotent matrix m g i g g g 1 g this is equivalent to converting the dependent variable into the residual from regressing u on the gradients g and similarly converting the matrix d d g into a matrix of residuals determined by regressing each column of d d g on the gradients g because m g is idempotent the product m g g is the n k zero matrix as explained above u is uncorrelated with the gradients meaning g can explain no variation in u so that the residuals from such a regression are exactly equal to u that is m g u u thus we have 2 m g u u m g g α m g d d g β r e s i d u a l s r β r e s i d u a l s where r m g d d g is the matrix of residuals from regressing the columns of d d g on the gradients g the implication of equation 2 is that the explained sum of squares for equation 1 is equivalent to the explained sum of squares of regressing u on the residuals r given these insights the ols estimate of the coefficient vector β is β ˆ r r 1 r u and the predicted value of u u ˆ r r r 1 r u making the explained sum of squares equal to u r r r 1 r r r r 1 r u u r r r 1 r u therefore the f statistic for evaluating the joint significance of the β ˆ estimated coefficients is 3 f u r r r 1 r u k s 2 this statistic being distributed under the null hypothesis β 0 according to the f distribution with k degrees of freedom in the numerator and n 2 k degrees of freedom in the denominator provided the elements of u are independent homoscedastic and normally distributed in large samples as n goes to infinity and if u is independent and homoscedastic with variance under the null hypothesis of σ ε 2 then r u n goes to a k element multivariate normal distribution with zero mean vector and an asymptotic covariance matrix given by σ ε 2 v r 1 where v r plim n r r n assuming such a matrix exists thus in large samples even if u is not normally distributed the standardized k 1 vector s 2 r r 1 2 r u goes to a vector of k independent standard normal variates the sum of squares of which is u r r r 1 r u s 2 has a limiting chi square distribution with k degrees of freedom the test for constancy derived above denoted gnr test a is predicated on the assumption that the elements of u are independent and homoscedastic we now relax the assumption of homoscedasticity and assume instead that the covariance matrix of u is ω a n n diagonal matrix with unequal values along the diagonal under these conditions the vector r ω r 1 2 r u is asymptotically distributed as a k dimensional set of independent standard normal variates and the sum of squares of this vector given by u r r ω r 1 r u has a limiting chi square distribution with k degrees of freedom under the null hypothesis ω is unknown but white 1980 has shown that r ω r n can be consistently estimated by r d u d u r n if each of the diagonal elements of ω are bounded in the positive domain this implies the statistic u r r d u d u r 1 r u has a limiting chi square distribution with k degrees of freedom this heteroscedasticity robust test for constancy of coefficients is denoted gnr test b appendix b assembly of input data sets to extend the model domain for the sagt phosphorus and nitrogen models to adjacent watersheds in tennessee data for the sagt models predictor variables for stream reaches in the cumberland and barren river basins and west tennessee tributaries were obtained either from the marb data set if available or from additional data sets assembled for this purpose and described in table a1 table a1 assembly of additional input data sets for evaluating sparrow phosphorus and nitrogen models for tennessee table a1 model input data data source for simulations background contribution of phosphorus allocated the datalayer for mineral content of soil and parent rock indicated by stream bed phosphorus levels fig 5 in terziotti et al 2010 to the mrb e2rf1ws catchment data set a set a cap equal to the maximum value 7 313 parts per million in the calibration domain to avoid simulations that are outside the range of calibration in addition for catchments in the inner nashville basin applied a maximum threshold of 1 012 5 ppm to the input term to reflect the documented absence of phosphate bearing minerals in soils in the inner part of the nashville basin physiographic regionb phosphate mining set as value of 0 phosphate mines sparse in watersheds outside the sagt model domain ph allocated the datalayer ph low from statsgoc to the mrb e2rf1ws catchment data set atmospheric deposition of nitrogen allocated the datalayer wet deposition of inorganic nitrogen to the mrb e2rf1ws catchment data set reservoir hydraulic loading rate used estimates from the erf1 2 hydrologic data set nolan et al 2002 hydrologic network used the mrb e2rf1ws hydrologic network brakebill and terziotti 2011 point sources wastewater discharge from permitted facilities estimates for some catchments were changed from published estimates to reflect corrections provided by tdec to annual load estimates or locations for wastewater dischargesd huc10 assignment assignments for catchments within the tennessee state boundary were provided by vicki steed tdec division of water resources for catchments outside of tennessee but within the tennessee model area allocated the water boundary datasete to the mrb e2rf1ws flowline data set f data for model variables not described in the table were taken from the marb model dataset sagt south atlantic gulf drainages and tennessee river basin model documented in hoos et al 2008 and garcía et al 2011 marb mississippi atchafalaya river basin model documented in robertson and saad 2013 tdec tennessee department of environment and conservation a the attribute data set was georeferenced and allocated to the mrb rf1 catchment dataset using the zonalmean function from the arc info grid module environmental systems research institute 2011 b based on information from springer and elder 1980 c state soil geographic statsgo data base u s department of agriculture 1994 d vicki steed tdec division of water resources written communication may 2012 e water boundary dataset geodatabase medium resolution was downloaded for tennessee and each adjacent state from http nhd usgs gov data html f the water boundary dataset geodatabase for tennessee and each adjacent state was converted to a shapefile and allocated to the mrb e2rf1 flowline dataset using the intersect function from the arcmap toolbox environmental systems research institute 2011 in cases of multiple huc10s assigned to a single flowline used the calculated length of flowline within each huc10 to assign primary huc10 for the catchment flowline appendix c correction to model predictions for heteroscedasticity additional steps were required for the prediction of nitrogen load to correct for heteroscedasticity of model residuals between the tennessee watersheds area versus the rest of the sagt calibration domain predictions were adjusted as follows 1 compute the sagt model weighted residual error loge conditioned on upstream monitored loads for each of the 55 sites in the tennessee watersheds area weighted residual error for the 37 sites that were included in the published sagt nitrogen model is provided in the published model output roland 2019 for the 18 sites outside the sagt model domain cumberland and barren river basins west tennessee tributaries the model residual error was produced by an additional execution of the published sagt nitrogen model that requested calculation of loge residual for the 18 sites but assigned 0 zero weight to the site load for model calibration this approach produces residuals of the published model for sites outside the model domain only if as in this case such sites are in watersheds that are independent or downstream from the sagt model domain and thus do not act as conditioning upstream monitored for sites in the original model domain which would alter the estimated model coefficients 2 exponentially transform the model weighted residual error and compute the mean and variance of exponentiated weighted error across the 55 sites mean exp weighted error tenn and var exp weighted error tenn respectively 3 use these values in place of mean exp weighted error the retransformation bias adjustment factor and var exp weighted error from the published sagt model in final calculations of nitrogen load for tennessee streams to produce load predictions without bootstrap estimated uncertainty substitute the tenn values for mean exp weighted error and var exp weighted error in the summary betaest file and in the boot betaest all file these two files are then used in conjunction with the published sagt model to predict load the bootstrap estimated uncertainty for load predictions including load by source requires randomly generated values of the adjustment factor as well as an estimate of the variance of the exponentiated residuals schwarz et al 2006 rather than generate separate random adjustment factors for the bootstrap analysis for tennessee locations the bootstrap factors for the published sagt model are rescaled according to the ratio of the tennessee based to sagt based adjustment factors derived from the non linear least squares residuals the variance of the exponentiated leverage adjusted residuals used to estimate uncertainty in tennessee streams like the retransformation bias adjustment factor is based on residuals exclusively from the monitoring sites in the tennessee watersheds to produce bootstrap estimated uncertainty for load predictions revise the boot betaest all file by first computing the ratio of mean exp weighted error tenn to the nonlinear least squares mean exp weighted error for the published sagt model reported in the first line of the boot betaest all file and then multiplying all values in the mean exp weighted error column in the file provided from successive bootstrap iterations of the published model by that ratio and retain the revised column in the boot betaest all file the revised boot betaest all file is then used in conjunction with the published sagt nitrogen model to predict load and bootstrap estimated uncertainty 
26243,we evaluated whether spatially referenced regression on watershed attributes sparrow models calibrated for two adjacent usa regions could be applied at the local scale to support management decisions for streams in tennessee nutrient source apportionment of load is important for this local scale application and demands careful consideration of uncertainty in the calibrated coefficients we used gauss newton regression to test the published sparrow models for constancy of coefficient estimates between calibration sites on streams within n 59 versus outside n 327 tennessee and concluded source apportionment was unbiased for tennessee streams the sparrow models were then applied without re calibration to predict stream loads and source apportionment for tennessee streams and to build tools for displaying model results and evaluating source change scenarios this approach may inform the adaptation of other regional scale regression models for use to address water resource management issues in smaller scale watersheds keywords watershed models nutrient source apportionment decision support nutrient change scenario nitrogen phosphorus software availability name of software tennessee usa 2002 sparrow phosphorus model tennessee usa 2002 sparrow nitrogen model developers anne hoos sherry wang gregory schwarz contact address anne hoos u s geological survey lower mississippi gulf water science center 640 grassmere park suite 100 nashville tn 37211 tel 1 615 837 4760 fax 1 615 837 4700 email abhoos usgs gov software requirements microsoft windows and sas base sas sas stat and sas iml or sas university edition program language sas macro language with statistical procedures written in sas iml availability free download of sparrow source code and national model files on https water usgs gov nawqa sparrow sparrow mod html free download of tennessee 2002 sparrow phosphorus and nitrogen model files from roland 2019 model predictions of stream loads and source apportionments can be viewed using web based mapping and charting tools at https sparrow wim usgs gov sparrow tennessee google chrome compatible 1 introduction increased nutrient inputs to the environment during the last century have increased nutrient loading to many streams lakes and estuaries and may cause overgrowth of algae eutrophication and adverse effects on ecological conditions and beneficial uses the state of tennessee usa plans to address excess nutrients through its statewide nutrient reduction framework tennessee department of environment and conservation tdec 2015 priority for nutrient reduction measures is given to watersheds from which contribution to stream nitrogen and phosphorus load from anthropogenic sources is high relative to background sources implementation of tennessee s nutrient reduction framework therefore requires for each watershed in tennessee estimates of stream nutrient loads and source apportionment i e the relative contribution of nutrient inputs from different sources in an ideal world water quality managers make decisions about controlling nutrient inputs to an individual watershed or stream using local observations within the watershed in reality however water quality managers lack sufficient local information and must develop control approaches that are based on model extrapolated values the importance of source apportionment for a local scale application favors selection of a model that tracks source apportionment through both landscape and stream transport includes uncertainty analysis for the model coefficients relating source input to export and optimizes precision for those coefficient estimates examples of watershed models that track source apportionment include the process based models swat soil water assessment tool arnold et al 1990 and hype hydrologic predictions for the environment lindstrom et al 2010 and the statistical models sparrow spatially referenced regression on watershed attributes schwarz et al 2006 and pol flow de wit 2000 statistical models have the advantage of direct evaluation of coefficient uncertainty whereas coefficient uncertainty analysis for process based models requires post model analysis such as markov chain monte carlo sampling gallagher and doherty 2007 joseph and guillaume 2013 checchi et al 2007 the sparrow model approach is well suited to meet the objectives of this application sparrow is a hybrid statistical and process based mass balance model spatially explicit along a detailed stream network that uses nonlinear least squares regression to relate observations of stream nutrient loads at monitoring stations to predictor variables representing nutrient sources and upland and channel features that affect the rate of constituent delivery to streams and through the stream network the estimated coefficients describe the marginal effect of nutrient source inputs on stream nutrient loads and therefore can be used to predict changes from nutrient source change scenarios standard error of the coefficient estimates and statistical significance of each coefficient are provided as calibration output and allow the user to evaluate whether a coefficient is statistically distinguishable from zero 0 in this way the user can identify the simplest and most parsimonious model and avoid overparameterization schwarz et al 2006 sparrow has traditionally been used to model mean annual transport and the limitation which stands for any static model of a single calibration observation from each load monitoring site has favored extending sparrow model domains to large regions with many monitoring sites rather than a smaller for example tennessee only domain a larger model domain is also favored for improved precision of coefficient estimates as a larger domain translates to a wider range in sources and transport factors that in turn affords greater precision of estimated coefficients and source apportionment schwarz et al 2006 2011 although semi independent calibration over a small number of watersheds calibration sites might provide a better fit and therefore a more predictive model measured in terms of standard fit statistics a comparison of model predictions at some sequestered sites will generally show that such an approach does not perform well in extrapolation furthermore the small scale parameterization approach is not appropriate for this application because it cannot precisely determine the importance of causal factors that are homogeneous over a small region but may show greater variability over a larger scale for example atmospheric deposition of nitrogen without proper characterization of stream load response to variation in atmospheric deposition the primary objective of accurate source apportionment cannot be met a larger number of calibration sites also affords exploration of a larger number of predictor variables on the other hand a potential disadvantage of using a model with a larger calibration domain than the focus area tennessee watersheds area is that the model coefficients may be biased for a subregion within the larger region and thus may produce biased predictions of load and source apportionment in those particular subregions and under certain nutrient management scenarios the larger the calibration domain the more likely the possibility of subregion bias schwarz et al 2011 this analysis addresses the concern of possible subregion bias and thus biased predictions for a focus area by evaluating a set of regional sparrow models for constancy of coefficients between the focus area and the areas of the model domain beyond the focus area we apply a series of gauss newton regression analyses and hypothesis tests to determine if the coefficients from the regional model are constant between these subregions and therefore justify use of the regional model in informing management decisions in the focus area the regional models are then used to estimate stream nutrient loads and source apportionment for all streams in tennessee watersheds we provide a web based tool that displays stream nutrient loads and source apportionment as maps and charts for 371 watershed units 10 digit hydrologic units or huc10 units in tennessee model input files and output files that support the findings in this paper are available from roland 2019 2 study area the set of streams for which model predictions are required comprises all streams in tennessee as well as streams in adjacent states that drain toward tennessee shaded areas in fig 1 termed the tennessee watersheds area predictions are required for huc10 units with an average drainage area of about 500 km2 the tennessee watersheds area consists of predominantly forested land 53 percent with agricultural land and urban land composing 30 and 8 percent respectively the greatest intensity of row crop agriculture and fertilizer use is in the western part of the area relatively flat terrain in the middle and eastern parts of the area support some row crop and pasture land much of the land in the eastern part of the area is steeply sloping and forested phosphate rich limestone outcrops in middle tennessee contribute phosphorus to streams through natural weathering and erosion ore grade deposits of phosphate minerals were mined in this area until 1991 and runoff from mined lands may also contribute phosphorus to streams estimates of the contribution of phosphorus from surficial geologic materials are needed to differentiate the effects of natural or background sources of phosphorus from human activities garcía et al 2011 denton et al 2001 3 material and methods 3 1 previously published regional sparrow nutrient models the u s geological survey usgs has calibrated a set of regional scale sparrow models that provide estimates of stream nutrient loads and source apportionment for both nitrogen and phosphorus and for all watersheds in tennessee as well as most watersheds in the conterminous u s preston et al 2011 saleh and domagalski 2015 two of the published regional scale sparrow models include in their model domain different subsets of the streams in tennessee fig 2 the mississippi atchafalaya river basin marb model robertson and saad 2013 covers most of the area of tennessee the south atlantic gulf drainages and tennessee river basin sagt model garcía et al 2011 hoos and mcmahon 2009 includes the tennessee and conasauga river basins in tennessee about half of the area of tennessee but not the cumberland and barren river basins and the west tennessee tributaries figs 1 and 2 the large size of the marb and sagt models 3 200 000 and 780 000 km2 respectively relative to the area of interest for this application 190 000 km2 for tennessee watersheds has both advantages and disadvantages as described in section 1 neither the marb nor the sagt model domain fully encompass the tennessee watersheds area fig 2 although the marb domain comes close extending simulations to adjacent watersheds outside the calibration domain is required for either model however as the amount of overlap with the tennessee watersheds area is much greater for marb the area of required extrapolation is much smaller model input data used to calibrate the marb and sagt sparrow models of 2002 stream nutrient load are documented in robertson and saad 2013 hoos et al 2008 terziotti et al 2010 and garcía et al 2011 the digital network of stream reach segments and associated catchments used as the data framework for the sagt and marb models is the mrb e2rf1ws network brakebill and terziotti 2011 derived from the u s environmental protection agency 1 500 000 scale reach file 1 rf1 with enhancements to support national and regional scale water quality modeling nolan et al 2002 the marb and sagt sparrow phosphorus models were calibrated with overlapping sets of monitoring data 34 monitoring sites in the tennessee river basin in common and use different predictor variables to explain spatial variability in 2002 phosphorus loads and to predict source apportionment compared in table 1 the marb model explains variability in 2002 phosphorus load with 17 predictor variables 7 termed source variables represent specific sources of phosphorus 7 termed source to water transport variables describe the rate at which phosphorus mass is transported from source to stream channel and 3 variables termed in channel attenuation variables determine fraction of phosphorus mass that is transported versus stored or removed in the stream channel the sagt model explains variability in mean annual phosphorus load using some of the same source predictors point sources urban land agricultural land and agricultural livestock but uses a different approach to represent background sources and does not include a variable for channel erosion the standard error of the coefficient table 1 quantifies the sampling error which is the amount of error in the coefficient value caused by using a random sample of stream load observations the calibration sites rather than the entire population of stream loads to estimate the value the errors are generally comparable between the two models and less than 40 percent the exceptions are errors of 48 percent for soil ph and 58 percent for time of travel in streams in the sagt model the greater precision in marb coefficient estimates is due to the larger calibration set and is an advantage for applications that involve source apportionment and source change scenarios schwarz et al 2011 the marb and sagt models use different sets of predictor variables to explain spatial variability in nitrogen loads and predict source contributions to streams compared in table 2 the marb model explains variability in nitrogen load with 15 predictor variables 6 source variables 7 source to water transport variables and 2 in channel attenuation variables the sagt model explains variability in mean annual nitrogen load using essentially the same source predictors as the marb model but differs in variables related to processes controlling nitrogen mass transport from source to stream channel standard errors of the coefficient are generally larger for the sagt model due in part to the smaller sagt calibration set the large percent standard error greater than 40 percent for coefficients of the source to water transport variables that characterize the discrete spatial distribution of hydrologic landscape regions reflects the confined spatial distribution of these variables such subregion level discrete landscape variables may however be an advantage in this application in which model accuracy in a specific subregion tennessee watersheds area is of paramount interest 3 2 tests of constancy of coefficient estimates and of residual variance across subregions of the sagt model area we use two gauss newton regression gnr tests davidson and mckinnon 1993 to determine constancy of coefficients of the sagt regional model across two subregions of its domain the subregion of tennessee watersheds compared to the subregion of the remaining model domain the tests use an approach similar to the chow test for constancy but are adapted for nonlinear models and heteroscedasticity of residuals davidson and mckinnon 1993 the regional model calibration results that are evaluated in the gnr tests include the model residuals expressed in natural logarithm space and the gradients representing the partial derivatives of the predicted natural logarithm of load at monitored reaches conditioned on upstream monitored load with respect to each model coefficient conditioned prediction refers to resetting predicted load to measured load at calibration stations so that predictions reflect monitored information at all upstream stations the model residuals and the gradients are provided as standard output from the sparrow model the gradients are the non linear analog of the prediction variables for a linear model but unlike the linear case can only be evaluated with knowledge of a set of estimated coefficients only the gradients associated with coefficients that are unconstrained in the fitting process are used under the null hypothesis that the joint model is properly specified by a single set of coefficients applicable to both subregions the residuals of the model are independent of the gradients and thus uncorrelated with any transformation of the gradients for any one subregion conversely if the coefficients differ between subregions we expect the gradients associated with one of the subregions of the model to be correlated with the residuals the first test for constancy of coefficients between subregions denoted gnr test a is implemented by performing a linear regression of model residuals dependent variable on predictor variables that include the set of gradients for each calibration site as well as a transformed set of the same gradients the transformed set of gradients consists of zero values for sites in one subregion and gradient values for sites in the other it being arbitrary as to which subregion is selected for zeroing of values the second set of gradients allows for the estimation of a set of differential coefficients that effectively gives the model the ability to estimate separate model coefficients for each subregion the null hypothesis that coefficients are constant across both subregions is rejected if an f test rejects the null hypothesis that the linear coefficients associated with the transformed gradients are jointly zero the degrees of freedom associated with the numerator of the f test are the number of unconstrained coefficients estimated in the model the degrees of freedom for the denominator are the number of observations in the model minus the number of coefficients estimated in the linear regression that is twice the number of unconstrained coefficients in the model the test is based on the f distribution although the test is technically valid only asymptotically as the number of observations in both subregions goes to infinity in applying this test it is assumed that the model residuals are homoscedastic additional description of the gnr test a is given in appendix a the assumption of homoscedastic distribution of model residuals for gnr test a is of special concern for a sparrow analysis in that the prediction of load in real space requires a bias retransformation factor the value of which depends on the distribution of the model residuals if the model residuals have a different distribution between the two subregions and specifically have a different variance then not only is the premise of the test for constant coefficients described above invalid but the use of a single retransformation factor in obtaining unbiased predictions for both subregions is untenable to address the issue of potential heteroscedasticity affecting the interpretability of the test for constant coefficients we perform an alternative test suggested by davidson and mackinnon 1993 that is robust to heteroscedasticity if heteroscedasticity is present the standard coefficient covariance matrix can be biased potentially biasing any test statistic derived from it an unbiased covariance matrix can be derived by accounting for the heteroscedasticity of the residuals however this requires knowledge of the residual variances which are typically unknown the test suggested by davidson and mackinnon denoted as gnr test b is motivated by an observation made by white 1980 that under minimal qualifying conditions an asymptotically valid test statistic can be derived using an observation s squared estimated residual in place of its unknown variance the derivation of the test statistic for gnr test b is described in appendix a under the null hypothesis that coefficients are constant across all observations in the model areas the test statistic is asymptotically distributed as chi square with degrees of freedom given by the number of unconstrained estimated coefficients in the sparrow model heteroscedasticity of the residuals between the two subregions raises an additional concern in evaluating a regional scale model for a local application that being the effect of residual variance on prediction bias the sparrow model is calibrated in natural logarithm space and to derive predictions in real space it is necessary to apply a retransformation bias adjustment factor this factor is estimated as the average of the exponentially transformed model residuals corrected for leverage effects to produce residuals of equal variance and under the assumption that the true residuals are homoscedastic if residuals are not homoscedastic then using the same retransformation bias adjustment factor for all prediction locations leads to bias in particular locations with low residual variance should have a smaller bias adjustment factor than locations having a larger variance thus using a single retransformation bias adjustment factor for all locations induces an upward bias on predictions in low residual variance locations and vice versa in high variance locations the test for heteroscedasticity employed in this analysis focuses attention on differences in residual variance between the tennessee watersheds area subregion and the rest of the regional model domain the test is implemented by performing a linear regression in which the squared values of the model residuals from the regional model are regressed on an intercept and a dichotomous variable that takes the value one 1 if the observation pertains to the tennessee watersheds area subregion and zero 0 otherwise under the null hypothesis that residual variance is constant across the two regions the test is a standard t test for significance of the coefficient associated with the dichotomous variable the tests are applied to calibration results from alternate versions termed joint sagt tennessee models of the sagt phosphorus and nitrogen models these alternate versions have been calibrated using the published set of predictors tables 1 and 2 and using the calibration sites from the sagt model domain as well as calibration sites in the cumberland river basin and west tennessee for a total of 386 sites the calibration set from the joint models is grouped into two samples 59 sites in the tennessee watersheds area subregion 1 and 327 sites in the rest of the sagt calibration domain subregion 2 for analysis using the gnr tests fig 3 model input data for streams and watershed in the joint sagt tennessee model that were not included in the original model the cumberland and barren river basins and west tennessee tributaries fig 1 are taken from the data set used to calibrate the marb sparrow model and documented in robertson and saad 2013 with exceptions noted in appendix b additional details of data assembly are described in roland 2019 4 results and discussion 4 1 selecting between marb and sagt regional models for simulating phosphorus and nitrogen load in the tennessee watersheds area root mean square error rmse of the model residual variance for the marb and sagt model calibration sets is 75 percent and 58 percent for phosphorus and 57 and 33 percent for nitrogen respectively tables 1 and 2 of paramount importance for the local scale application is the bias and variance for the subset of monitoring sites in the tennessee watersheds area table 3 for phosphorus both marb and sagt model residuals have an overall negative bias overprediction for the set of monitoring sites in tennessee mean of model residuals in natural logarithm loge space is 0 29 and 0 11 for marb and sagt respectively variance of loge residuals measured as rmse is 96 and 51 percent for marb and sagt respectively sagt phosphorus predictions are therefore more accurate and precise than marb phosphorus predictions for monitoring sites in the tennessee watersheds area one explanation for the superior prediction performance by the sagt phosphorus model is that the sagt specification table 1 includes factors missing from the marb model that help explain spatial variability of phosphorus load in tennessee streams the sagt phosphorus model includes predictor variables that represent contribution to stream load from natural weathering and erosion of phosphatic limestone and from mined land table 1 a variable characterizing contribution of phosphatic limestone to stream load was tested in the marb model but was not statistically significant and therefore not included in the final model dale robertson usgs written communication 2012 its lack of significance in that model may have been due to its importance in explaining load variation for only a relatively small subset middle tennessee of the large marb observation set source apportionment of stream phosphorus load into background versus anthropogenic sources a key objective for the tennessee nutrient reduction framework differs markedly between the two regional model specifications the term background as defined for the nutrient reduction framework refers to naturally occurring factors as well as to sources like atmospheric deposition that cannot be controlled by watershed specific actions the sagt phosphorus model attributes a much larger portion of stream load mean value 45 percent to background sources compared to the marb phosphorus model mean value 4 and 11 percent for parent rock minerals and forested land and wetlands respectively table 4 mean bias of nitrogen model residuals for monitoring sites in the tennessee watersheds area is similar in magnitude but opposite in direction for marb and sagt models table 3 the marb model has an overall bias towards overprediction 0 14 and the sagt model an overall bias towards underprediction 0 12 mean variance measured as rmse is 45 percent for both models similar bias and variance suggest that the sagt and marb model specifications are equally well suited for predicting nitrogen load at tennessee monitoring sites and thus tennessee streams source apportionment of stream nitrogen load from background versus anthropogenic sources is similar between the two regional model specifications in contrast to apportionment of phosphorus load the sagt nitrogen model attributes 59 percent on average to the background source atmospheric deposition and the marb nitrogen model attributes 52 percent table 4 without strong argument to select one over the other based on model error or source apportionment we move forward with the sagt nitrogen model based on alignment of selection for nitrogen and phosphorus in other words we select the sagt model for nitrogen because the sagt model was selected for phosphorus 4 2 gauss newton regression testing for constancy of coefficients in sagt model predictions for tennessee watersheds we use the two gnr tests proposed by davidson and mackinnon 1993 and the test for constancy of residual variance to determine if there is sufficient evidence that sagt model predictions of stream nutrient loads in the tennessee watersheds area are theoretically unbiased in large samples for the phosphorus model the p value of the f test statistic from both gnr tests a and b is greater than 0 05 implying failure to reject the null hypothesis that the sagt phosphorus model coefficients are constant across the two subregions table 5 this result is interpreted to mean that the sagt phosphorus model specification and coefficient estimates can be used without re calibration to produce unbiased predictions of phosphorus load for streams throughout the tennessee watersheds area for the nitrogen model in contrast the p value of the f test statistic from gnr test a is 0 05 implying that the sagt nitrogen model coefficients are not constant across the two subregions the p values of the test statistic from gnr test b however shows no evidence to reject the null hypothesis that coefficients are constant across the two subregions davidson and mackinnon 1993 note that the heteroscedasticity robust test tends to reject the null hypothesis more frequently than it should so the evidence for retaining the assumption that coefficients are constant for the nitrogen model is quite strong had the null hypothesis been rejected for either phosphorus or nitrogen we would then re calibrate a sparrow model using the sites in the tennessee watersheds area plus selected sites from the remainder of the calibration domain and possibly with additional predictor variables and then test again for constancy of coefficients alternatively we could adopt the methodology described in schwarz et al 2011 to identify which model coefficients show evidence of non constancy and estimate a model which allows for regional differences in those specific coefficients such an approach conserves on degrees of freedom allowing observations from the combined regions to be used to improve the precision of the coefficient estimates for those coefficients that are deemed constant the results of the test for heteroscedasticity in residuals between the tennessee watersheds area subregion and the rest of the regional model domain reported in table 5 show no evidence of heteroscedasticity in the phosphorus model p value 0 36 but the t statistic for the nitrogen model p value 0 048 is marginally significant at the 0 05 level the sign of the t statistic for the nitrogen model is positive indicating that residual variance is larger for locations in the tennessee watersheds as compared to the watersheds in the rest of the sagt domain the evidence of heteroscedasticity in residual variance for the nitrogen model and the absence of evidence from the heteroscedasticity robust test that the coefficients of that model vary across subregions implies predictions of loads for tennessee streams using the sagt model retransformation bias adjustment factor could be biased low or high to correct for this a separate adjustment factor was estimated for streams in the tennessee subregion based only on leverage adjusted residuals for the monitoring sites in that subregion additional information about these adjustment factors for tennessee streams is described in appendix c 4 3 using the sagt sparrow model to estimate 2002 stream loads and source apportionment of phosphorus and nitrogen in tennessee watersheds the gnr tests demonstrate that the previously calibrated and published sagt phosphorus and nitrogen models can produce unbiased load predictions for tennessee streams without re calibration we therefore applied the sagt models to input data for all tennessee streams to estimate 2002 phosphorus and nitrogen load and source apportionment for each stream reach in the tennessee watersheds area the input data were combined from the sagt model data sets for streams in the tennessee and conasauga river basins and the marb model data sets for all other streams in tennessee as described in appendix b the additional steps of calculating retransformation bias adjustment factor were taken for nitrogen model predictions to correct for heteroscedasticity of the nitrogen model residuals between the tennessee watersheds area and the rest of the sagt calibration domain predictions aggregated from reach level up to river basin level are reported in table 6 phosphorus yield load per upstream area delivered to the outlet of the major river basins is 0 70 kg per hectare per year kg ha yr overall for tennessee watersheds and ranges from 0 39 to 2 04 kg ha yr across the major river basins estimates of nitrogen yield load per upstream area delivered to the outlet of the major river basins is 4 97 kg ha yr overall and ranges from 4 39 to 7 24 kg ha yr across the major river basins the much larger phosphorus and nitrogen yield from the west tennessee tributaries compared to the rest of the model area is partly due to the greater intensity of row crop agriculture and fertilizer use in these watersheds and also may be partly due to the absence of large reservoirs from these watersheds that could trap particulate nutrient load above the river basin outlet the phosphorus background source phosphate in parent rock minerals apportionment is largest for the cumberland and tennessee river basins 55 4 and 47 4 percent respectively table 6 the enrichment factor reported in table 6 is calculated as the proportion of total load to background load equivalent to 100 background source percent and is therefore lowest for the cumberland and tennessee river basins enrichment factor is an important metric in the decision process proposed in the tennessee nutrient reduction framework for identifying the need for reduction measures accuracy of model predictions of background source apportionment is therefore of paramount importance for supporting the framework tdec 2015 5 conclusions we demonstrate a series of statistical tests and decision making to address concerns of subregional bias when applying regional scale statistical models to a specific focus area the regional scale models marb and sagt nitrogen and phosphorus sparrow models have been calibrated using monitoring sites that represent a wide range of watershed and water quality conditions and under the assumption that the estimated coefficients are the same for all locations in the region schwarz et al 2011 based on a comparison of residual variance for monitoring sites within the tennessee watersheds area as alternatively derived using the sagt and marb models the marb model was rejected as viable for providing unbiased predictions for tennessee watersheds subsequent application of the gauss newton regression tests shows the sagt phosphorus and nitrogen model coefficients can be applied to predict loads in tennessee watersheds however a test of the constancy of residual variance for the nitrogen model shows it is not appropriate to apply the sagt retransformation bias adjustments to obtain predictions for these watersheds consequently the retransformation bias adjustment factor for tennessee watersheds is recomputed using only residuals pertaining to the tennessee monitoring sites predictions of 2002 stream load and source apportionment from the sagt phosphorus and nitrogen models are aggregated from reach level up to huc10 units to support decision making for the tennessee nutrient reduction framework the statistical tests and decision rules applied in this study may find increasing utility as more regional sparrow models are developed and it becomes necessary to evaluate their relevance for application in specific areas of interest the application of these tests is not confined to sparrow models of course and could be applied to assess prediction bias of any large scale nonlinear least squares regression model for a subregion of interest software availability the predictions of 2002 stream nutrient load and source apportionment for each stream reach in the tennessee watersheds area are included in the tennessee sparrow model files available from roland 2019 the model files can be used to evaluate source change scenarios by altering values for one or more source variables and re computing stream load predictions aggregated up to huc10 and huc8 units are presented in map and chart displays available on https sparrow wim usgs gov sparrow tennessee that allow the user to quickly evaluate nutrient load source apportionment and enrichment factor for each unit declaration of interests none acknowledgements this work was supported by the tennessee department of environment and conservation division of water resources and by the u s geological survey any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government appendix a additional description of tests of constancy of coefficient estimates the following describes the tests for constancy of coefficients used to validate the appropriate model to generate predictions for the tennessee watersheds the tests are described in greater detail in davidson and mackinnon 1993 the test for constancy of coefficients throughout the observations of the joint sagt tennessee model is based on the ordinary least squares estimation of the following linear model 1 u g α d d g β ε where u is an n 1 vector of residuals from the estimation of the joint sparrow model using all available sites with n being the number of sites used in estimation g is an n k matrix of gradients of the sparrow model see schwarz et al 2006 for the method used to compute the gradients of a sparrow model at the n monitoring sites with respect to the k unconstrained model coefficients conditioned on upstream monitored loads and evaluated at the nonlinear least squares coefficient estimates d is an n 1 vector consisting of elements that are either 1 if the observation pertains to the tennessee subregion or 0 if otherwise d is the n n diagonal matrix operator that forms a diagonal matrix from its n 1 vector argument α and β are each k 1 vectors of coefficients to be estimated and ε is an n 1 vector of residuals note that a sparrow model is calibrated in natural logarithm space so the residual vector u representing the dependent variable in the linear model in equation 1 is given by the natural logarithm of observed load at a monitoring site minus the predicted natural logarithm of load at the same site location conditioned on the observed values of load upstream of the site see schwarz et al 2006 under the null hypothesis that the model is properly specified by a common set of coefficients for the entire study area the β coefficients are all zero thus the applied test evaluates the joint significance of the ols estimated coefficients β ˆ the numerator for the f statistic evaluating this test is given by the difference between the explained sum of squares of the calibrated model given in equation 1 and a model in which β is constrained to equal 0 normalized by the number of degrees of freedom affected by the constraint k and the denominator of the statistic is the mean squared error of equation 1 regression s 2 ε ˆ ε ˆ n 2 k the sufficient condition for convergence in fitting the sparrow model using nonlinear least squares is g u 0 therefore g is uncorrelated with u and the explained sum of squares of the linear model in equation 1 with β constrained to 0 is zero making the difference in the explained sum of squares equal to just the explained sum of squares of the calibrated model in equation 1 the explained sum of squares for the ols calibrated model in equation 1 can be derived as follows consider pre multiplying both sides of equation 1 by the idempotent matrix m g i g g g 1 g this is equivalent to converting the dependent variable into the residual from regressing u on the gradients g and similarly converting the matrix d d g into a matrix of residuals determined by regressing each column of d d g on the gradients g because m g is idempotent the product m g g is the n k zero matrix as explained above u is uncorrelated with the gradients meaning g can explain no variation in u so that the residuals from such a regression are exactly equal to u that is m g u u thus we have 2 m g u u m g g α m g d d g β r e s i d u a l s r β r e s i d u a l s where r m g d d g is the matrix of residuals from regressing the columns of d d g on the gradients g the implication of equation 2 is that the explained sum of squares for equation 1 is equivalent to the explained sum of squares of regressing u on the residuals r given these insights the ols estimate of the coefficient vector β is β ˆ r r 1 r u and the predicted value of u u ˆ r r r 1 r u making the explained sum of squares equal to u r r r 1 r r r r 1 r u u r r r 1 r u therefore the f statistic for evaluating the joint significance of the β ˆ estimated coefficients is 3 f u r r r 1 r u k s 2 this statistic being distributed under the null hypothesis β 0 according to the f distribution with k degrees of freedom in the numerator and n 2 k degrees of freedom in the denominator provided the elements of u are independent homoscedastic and normally distributed in large samples as n goes to infinity and if u is independent and homoscedastic with variance under the null hypothesis of σ ε 2 then r u n goes to a k element multivariate normal distribution with zero mean vector and an asymptotic covariance matrix given by σ ε 2 v r 1 where v r plim n r r n assuming such a matrix exists thus in large samples even if u is not normally distributed the standardized k 1 vector s 2 r r 1 2 r u goes to a vector of k independent standard normal variates the sum of squares of which is u r r r 1 r u s 2 has a limiting chi square distribution with k degrees of freedom the test for constancy derived above denoted gnr test a is predicated on the assumption that the elements of u are independent and homoscedastic we now relax the assumption of homoscedasticity and assume instead that the covariance matrix of u is ω a n n diagonal matrix with unequal values along the diagonal under these conditions the vector r ω r 1 2 r u is asymptotically distributed as a k dimensional set of independent standard normal variates and the sum of squares of this vector given by u r r ω r 1 r u has a limiting chi square distribution with k degrees of freedom under the null hypothesis ω is unknown but white 1980 has shown that r ω r n can be consistently estimated by r d u d u r n if each of the diagonal elements of ω are bounded in the positive domain this implies the statistic u r r d u d u r 1 r u has a limiting chi square distribution with k degrees of freedom this heteroscedasticity robust test for constancy of coefficients is denoted gnr test b appendix b assembly of input data sets to extend the model domain for the sagt phosphorus and nitrogen models to adjacent watersheds in tennessee data for the sagt models predictor variables for stream reaches in the cumberland and barren river basins and west tennessee tributaries were obtained either from the marb data set if available or from additional data sets assembled for this purpose and described in table a1 table a1 assembly of additional input data sets for evaluating sparrow phosphorus and nitrogen models for tennessee table a1 model input data data source for simulations background contribution of phosphorus allocated the datalayer for mineral content of soil and parent rock indicated by stream bed phosphorus levels fig 5 in terziotti et al 2010 to the mrb e2rf1ws catchment data set a set a cap equal to the maximum value 7 313 parts per million in the calibration domain to avoid simulations that are outside the range of calibration in addition for catchments in the inner nashville basin applied a maximum threshold of 1 012 5 ppm to the input term to reflect the documented absence of phosphate bearing minerals in soils in the inner part of the nashville basin physiographic regionb phosphate mining set as value of 0 phosphate mines sparse in watersheds outside the sagt model domain ph allocated the datalayer ph low from statsgoc to the mrb e2rf1ws catchment data set atmospheric deposition of nitrogen allocated the datalayer wet deposition of inorganic nitrogen to the mrb e2rf1ws catchment data set reservoir hydraulic loading rate used estimates from the erf1 2 hydrologic data set nolan et al 2002 hydrologic network used the mrb e2rf1ws hydrologic network brakebill and terziotti 2011 point sources wastewater discharge from permitted facilities estimates for some catchments were changed from published estimates to reflect corrections provided by tdec to annual load estimates or locations for wastewater dischargesd huc10 assignment assignments for catchments within the tennessee state boundary were provided by vicki steed tdec division of water resources for catchments outside of tennessee but within the tennessee model area allocated the water boundary datasete to the mrb e2rf1ws flowline data set f data for model variables not described in the table were taken from the marb model dataset sagt south atlantic gulf drainages and tennessee river basin model documented in hoos et al 2008 and garcía et al 2011 marb mississippi atchafalaya river basin model documented in robertson and saad 2013 tdec tennessee department of environment and conservation a the attribute data set was georeferenced and allocated to the mrb rf1 catchment dataset using the zonalmean function from the arc info grid module environmental systems research institute 2011 b based on information from springer and elder 1980 c state soil geographic statsgo data base u s department of agriculture 1994 d vicki steed tdec division of water resources written communication may 2012 e water boundary dataset geodatabase medium resolution was downloaded for tennessee and each adjacent state from http nhd usgs gov data html f the water boundary dataset geodatabase for tennessee and each adjacent state was converted to a shapefile and allocated to the mrb e2rf1 flowline dataset using the intersect function from the arcmap toolbox environmental systems research institute 2011 in cases of multiple huc10s assigned to a single flowline used the calculated length of flowline within each huc10 to assign primary huc10 for the catchment flowline appendix c correction to model predictions for heteroscedasticity additional steps were required for the prediction of nitrogen load to correct for heteroscedasticity of model residuals between the tennessee watersheds area versus the rest of the sagt calibration domain predictions were adjusted as follows 1 compute the sagt model weighted residual error loge conditioned on upstream monitored loads for each of the 55 sites in the tennessee watersheds area weighted residual error for the 37 sites that were included in the published sagt nitrogen model is provided in the published model output roland 2019 for the 18 sites outside the sagt model domain cumberland and barren river basins west tennessee tributaries the model residual error was produced by an additional execution of the published sagt nitrogen model that requested calculation of loge residual for the 18 sites but assigned 0 zero weight to the site load for model calibration this approach produces residuals of the published model for sites outside the model domain only if as in this case such sites are in watersheds that are independent or downstream from the sagt model domain and thus do not act as conditioning upstream monitored for sites in the original model domain which would alter the estimated model coefficients 2 exponentially transform the model weighted residual error and compute the mean and variance of exponentiated weighted error across the 55 sites mean exp weighted error tenn and var exp weighted error tenn respectively 3 use these values in place of mean exp weighted error the retransformation bias adjustment factor and var exp weighted error from the published sagt model in final calculations of nitrogen load for tennessee streams to produce load predictions without bootstrap estimated uncertainty substitute the tenn values for mean exp weighted error and var exp weighted error in the summary betaest file and in the boot betaest all file these two files are then used in conjunction with the published sagt model to predict load the bootstrap estimated uncertainty for load predictions including load by source requires randomly generated values of the adjustment factor as well as an estimate of the variance of the exponentiated residuals schwarz et al 2006 rather than generate separate random adjustment factors for the bootstrap analysis for tennessee locations the bootstrap factors for the published sagt model are rescaled according to the ratio of the tennessee based to sagt based adjustment factors derived from the non linear least squares residuals the variance of the exponentiated leverage adjusted residuals used to estimate uncertainty in tennessee streams like the retransformation bias adjustment factor is based on residuals exclusively from the monitoring sites in the tennessee watersheds to produce bootstrap estimated uncertainty for load predictions revise the boot betaest all file by first computing the ratio of mean exp weighted error tenn to the nonlinear least squares mean exp weighted error for the published sagt model reported in the first line of the boot betaest all file and then multiplying all values in the mean exp weighted error column in the file provided from successive bootstrap iterations of the published model by that ratio and retain the revised column in the boot betaest all file the revised boot betaest all file is then used in conjunction with the published sagt nitrogen model to predict load and bootstrap estimated uncertainty 
26244,within river basins water resources competition often exists between agricultural municipal and industrial sectors particularly in semi arid regions where surface water and groundwater are managed conjunctively to sustain urban areas and food production there is a need for physically based modeling tools to assist with identifying successful water management strategies in these basins this paper presents an updated version of swat modflow that allows application to large agro urban river basins in semi arid regions code changes include linkage between modflow pumping cells and swat hrus for groundwater irrigation joint groundwater and surface water irrigation routines and the use of modflow psb to handle the large array of groundwater sources sinks that exist in a highly managed river basin model performance is demonstrated for the 72 000 km2 south platte river basin colorado usa the model can be used in agro urban river basins worldwide to assess water resources supply under a variety of scenarios keywords hydrological modeling swat modflow large scale watershed river basin surface water groundwater interaction 1 introduction a significant portion of the world s population lives in semi arid and arid regions with over half of the population living in urban areas united nations 2014 this disproportionate distribution of people and allotment of water resources present a challenge in dry regions and mandate the implementation of strategies such as water reuse and desalination of salty water in such places to secure adequate water supplies to support growing populations shirazi et al 2018 moreover often there is an aggressive competition within a single river basin from the municipal agricultural industrial environmental and recreational sectors over the use of the limited supply of water competition between urban and agricultural demand occurs worldwide florke et al 2018 in the western united states chile and mexico increasing population has led to the transfer of water rights from irrigated agriculture to municipalities via agricultural lands dry up or water leasing programs meinzen dick and appasamy 2002 doherty and smith 2012 groundwater in rural areas is particularly vulnerable as the transfer of surface water rights to urban areas increases reliance on groundwater resources leading to a decrease in groundwater levels and overall groundwater storage knapp 2003 also removing surface water irrigation decreases seepage from earthen irrigation canals and deep percolation from applied surface water irrigation thereby removing a source of groundwater and leading to additional groundwater storage depletion in such a complex water resources network wherein both surface water and groundwater resources are managed conjunctively to satisfy all social sectors physically based distributed hydrological models can be used to quantify water availability under current and future conditions and determine appropriate integrated water management policies hydrological models typically are developed based on i surface runoff models that consider groundwater in a simplistic manner such as the hydrologiska byråns vattenbalansavdelning hbv bergstrom and forsman 1973 bergstrom 1992 the sacramento soil moisture accounting model sac sma burnash et al 1973 topmodel beven and kirby 1979 the variable infiltration capacity vic liang et al 1994 the hydrologic modeling system hec hms william et al 1995 u s army corps of engineers 2016 the soil and water assessment tool swat arnold et al 1998 the soil and water integrated model swim krysanova et al 2000 the hydrology laboratory research modeling system hl rms koren et al 2004 and the water global assessment and prognosis watergap verzano 2009 or ii groundwater models that consider surface water in a simplistic manner such as the modular finite difference flow model modflow harbaugh 2005 the microcomputer package for multiple aquifer groundwater flow modeling microfem diodato 2000 the object oriented quasi three dimensional regional groundwater model zoomq3d jackson 2001 the soilvision systems ltd finite element seepage analysis program svflux thode and fredlund 2013 and the finite element heat and mass transfer code fehm zyvoloski et al 2015 such analysis to quantify water supply for management purposes and vulnerability assessments in river basins can result in unrealistic inferences and subsequent ineffective decisions therefore detailed representation of both surface water and groundwater processes and also their interaction must be included in recent years a third category of hydrological models has emerged in which surface water and groundwater processes are linked some of these models solve the groundwater and surface water equations simultaneously in a single software package such as the catchment hydrology model cathy paniconi and wood 1993 the integrated hydrology model inhm vanderkwaak and loague 2001 hydrogeosphere hgs therrien et al 2010 opengeosys kolditz et al 2012 the pcraster global water balance model pcr globwb mod sutanudjaja et al 2014 and the parallel flow model parflow maxwell et al 2016 while others couple two or more different modeling codes to simulate the groundwater and surface water interactions such as mike she refsgaard and storm 1995 dhi 2017 swatmod sophocleous et al 1999 modhms hydrogeologic 2006 the grid based water flow and balance simulation model wasim eth schulla and jasper 2007 the coupled groundwater and surface water flow model gsflow markstrom et al 2008 the finite element subsurface flow system feflow dhi wasy gmbh 2016 and swat modflow kim et al 2008 guzman et al 2015 bailey et al 2016 several of these models have been applied at the river basin and even continental scale therrien et al 2010 maxwell et al 2016 although the vast majority of model applications have been at the small regional scale and largely restricted to either theoretical studies or studies aimed at specific governmental municipalities with the latter often remaining unpublished guzman et al 2015 barthel and banzhaf 2016 the development of a versatile integrated hydrological modeling code that accounts for all major water pathways and transfers in an agro urban system at a large geographic scale river basins such as in the updated version of coupled swat modflow presented in this study is essential for quantifying and managing water resources only at this scale can anthropogenic social and managerial factors along with complexity and heterogeneity of the system be reflected in simulations irvine et al 2012 barthel and banzhaf 2016 all previous versions and applications of swat modflow e g sophocleous et al 1999 sophocleous and perkins 2000 menking et al 2003 galbiati et al 2006 kim et al 2008 luo and sophocleous et al 2011 guzman et al 2015 bailey et al 2016 have been applied to small watersheds or been used to estimate specific water balance components runoff recharge groundwater surface water exchange rates none have been applied to large river basins of mixed agro urban land use types with the accompanying water transfer complexity e g groundwater pumped for irrigation surface water diverted for irrigation seepage from canals seepage from artificial recharge ponds etc the overall objective of this paper is to present an integrated hydrologic modeling code that accounts not only for surface water and groundwater hydrologic processes and their interaction but also the management schemes that transfer water between the domains in a semi arid heavily managed agro urban large river basin specifically this study i develops an integrated hydrologic modeling code that accounts for groundwater and surface water processes and exchanges in large regional scale managed river basins and ii demonstrates the use and performance of the integrated model in the economically diverse south platte river basin sprb a 72 000 km2 river basin located primarily in the state of colorado usa although the model is based on the available swat modflow modeling code bailey et al 2016 it has several key advances including linkage between modflow pumping and swat hru applied irrigation quantifying the irrigation amount based on both surface water canal diversions or groundwater pumping ability to store large arrays for linking modflow grids and swat watersheds with thousands of grid cells and hrus respectively and using the modflow psb package that partitions groundwater stresses into specific surface water and groundwater water budget terms application to the sprb is an ideal test for the model in that total volume of surface water diversions in the sprb is about twice the primary surface water supply i e snowmelt runoff indicating a significant reliance on groundwater recharge to surface water dozier et al 2017 diverted surface water recharges the aquifer which later discharges to the stream repeating multiple times as surface water flows towards the outlet of the river basin waskom 2013 the surface water and alluvial groundwater in the sprb are in close interaction and are considered as a single resource of water by colorado water law in general the results of this model demonstrate the applicability of integrated hydrological modeling for developing an improved understanding of linked groundwater and surface water systems and can be used in other studies to identify water management solutions 2 swat modflow modeling code for large scale river basins this section outlines the modification of the swat modflow modeling code bailey et al 2016 for application to semi arid agro urban large scale river basins theoretical descriptions of swat modflow and swat modflow are provided followed by a description of modifications and enhancements to swat modflow 2 1 swat the soil and water assessment tool swat arnold et al 1998 2012a is a physically based quasi distributed model that operates on a daily time step it is designed to simulate the movement of water sediment nutrient and pesticide within a watershed and to predict the effects of climate change and best management practices on the quantity and quality of water at the watershed scale the model divides the watershed into subbasins with each subbasin divided into hydrologic response units hrus i e unique combinations of land use soil and management the overall hydrologic balance such as partitioning of precipitation snowmelt water irrigation water between surface runoff and infiltration redistribution of water within the soil profile interception of precipitation and evapotranspiration are simulated for each hru outputs from hrus are lumped and directed to the subbasin stream for routing through the stream network to the outlet of the watershed swat has been used worldwide to address hydrologic and environmental problems however its application in assessing groundwater processes quantities and interaction with surface water is limited as a quasi distributed model swat does not represent the heterogeneity of an aquifer such as spatially varying hydraulic conductivity and specific yield nor the system response hydraulic head moreover swat is limited in simulating groundwater discharge to streams and stream seepage to the aquifer because it compares shallow aquifer depth with a threshold to estimate the river recharge and does not consider the river bottom elevation and aquifer depth gassman et al 2007 kim et al 2008 arnold et al 2012b gayathri et al 2015 2 2 modflow modflow harbaugh 2005 is a public domain numerical groundwater modeling code developed by the u s geological survey usgs the model is written in fortran and solves the groundwater flow equation using the finite difference method one of the most recent versions is modflow nwt niswonger et al 2011 an algorithmic reformulation of modflow 2005 that uses the newton raphson method this new algorithm performs well in highly nonlinear problems such as unconfined groundwater systems and the process of drying and rewetting of grid cells hunt and feinstein 2012 modflow simulates a variety of hydrologic processes in steady and transient states for different types of aquifers interactions between the land surface and groundwater and between surface water and groundwater are simulated using a variety of boundary condition packages including the recharge well drain lake reservoir and streamflow routing packages 2 3 swat modflow the coupled swat modflow model bailey et al 2016 links the swat2012 and modflow nwt model codes the groundwater module inside the swat code is replaced by modflow making a single executable fortran code and allowing for daily interactions between the two models without the need for writing and reading model data the linkage between swat and modflow is based on mapping schemes that pass hru based variables e g recharge from the soil zone and subbasin based variables stream stage to the modflow grid and grid based variables e g water table elevation rate of water exchange between groundwater and the stream network to swat hrus and subbasin channels the hru based recharge is mapped to modflow s recharge package and the stream aquifer water exchange is simulated by the river package the geographic relation between the hrus and grid cells and between the river cells and subbasin streams is quantified using geoprocessing routines with the information stored in text files that are read in at the beginning of the swat modflow simulation prior to intersecting with the modflow grid cells the hrus are split into geographically defined disaggregated hrus dhrus 2 4 modified swat modflow model for agro urban river basins this section describes modifications to the original swat modflow code to allow for application to basin scale agro urban watershed systems the overall flow of data within the code is presented in fig 1 specific modifications to the swat modflow code include i transfer of groundwater from the aquifer to irrigated fields by linking modflow pumping cells to swat hrus designated by 1 in fig 1 and explained in detail in the last paragraph of this section ii working with the modflow psb capability brown and caldwell 2017 zeiler et al 2017 in which the stresses are partitioned into multiple input files this capability is essential for including all the groundwater sources sinks existing in an agro urban river basin and for linking the soil percolation from swat hrus to the correct recharge grid designated by 2 in fig 1 and explained in detail in the last paragraph of this section iii modification of swat s auto irrigation algorithms to allow surface water irrigation to supplement groundwater irrigation i e if groundwater irrigation from pumping wells is not sufficient to meet crop water demands then water will be diverted from the nearest subbasin stream iv modification of swat modflow subroutines that handle linking between grid cells and hrus to enable application to large watershed systems for large watersheds wherein modflow grids can have hundreds of thousands of grid cells and swat can have tens of thousands of hrus extremely large arrays have resulted in insufficient memory errors when attempting to apply the original swat modflow code the current change allows arrays to be allocated more efficiently thereby enabling application to large systems such as the sprb the code first reads in swat inputs modflow inputs and information for mapping swat hru and subbasin variables to the modflow grid and vice versa compared to the original swat modflow code one more text file is needed that lists modflow grid cells that provide irrigation water and their associated swat subbasins and hrus swatmf irrigate txt fig 1 to enable linking for transferring pumped groundwater to the ground surface swat runs through a year loop and then a day loop with subbasin calculations performed for each day for each subbasin the hru calculations are performed including land surface hydrology irrigation application and soil crop hydrologic processes percolation from the bottom of the soil profile and subbasin channel stage are then mapped to the modflow grid cells and river cells respectively whereupon modflow runs using the partition stress boundary psb capability and then maps groundwater surface water exchange rates groundwater irrigation depths and water table elevation to swat subbasin channels and hrus respectively water entering each subbasin stream via surface runoff swat soil lateral flow swat or groundwater flow modflow is then routed through the watershed stream network for the day as with the original version of swat modflow swat is linked with modflow nwt however the psb capability is implemented into the code which enables tracking of separate stress components without lumping them into a single modflow package the psb capability was originally developed for modflow cdss banta 2011 a version of modflow 2005 designed to support groundwater models for colorado s decision support systems cdss 2017 the psb capability was subsequently incorporated into modflow nwt as part of the south platte decision support system spdss groundwater model update brown and caldwell 2017 zeiler et al 2017 the capability facilitates groundwater flow modeling in aquifer systems with a large variety of groundwater sources and sinks of similar type using the psb capability each stress boundary package e g recharge package well package can be partitioned into a selected set of packages with volumetric flow rates for each individual stress listed in a separate input file for example the well package can be partitioned into municipal pumping agricultural pumping groundwater injection etc and the recharge package can be partitioned into reservoir seepage recharge pond seepage rainfall recharge and irrigation recharge the water budget component of each stress partition is tracked separately in the water budget tables printed in the modflow output file packages supported by the psb capability include recharge rch river riv well wel drain drn drain return drt evapotranspiration evt evapotranspiration segments ets and general head boundary ghb within the swat modflow code swat hru soil percolation rates are mapped to the modflow grid for rainfall and irrigation recharge designated by 2 in fig 1 and modflow agricultural pumping rates are mapped to swat hrus for groundwater irrigation designated by 1 in fig 1 when mapping rainfall and irrigation recharge from swat hrus to modflow grid cells and pumped irrigation water from modflow to swat hrus the appropriate stress grid must be specified so as not to over write cell by cell values for other stresses irrigation water can be supplied by surface water via irrigation canals and or by groundwater via pumping wells groundwater pumped using the agricultural pumping stress of the well package can be mapped to swat hrus pumped groundwater volumes are converted to applied irrigation depths and provided to hrus for irrigation on the following day using the spatial area of the hru using the auto irrigation algorithms of swat surface water irrigation can be supplied by the nearest subbasin channel representing surface water diverted from the stream via irrigation canals the hru receiving irrigation water from each modflow pumping cell is specified in a list in the swatmf irrigate txt input file see fig 1 the user also specifies the runoff ratio i e percent of irrigation water that runs off the field as tailwater for groundwater irrigation in each sub basin however there are many fields that use canal water instead of groundwater for irrigational purposes the swat auto irrigation subroutines were modified to include surface water from a specified subbasin channel after pumping water is applied so that the full specified depth of irrigation is met 3 model application to the south platte river basin 3 1 area of study 3 1 1 geography and demographics the south platte river basin sprb has a spatial area of approximately 72 000 km2 colorado s water supply future 2011 with 79 of the area in colorado encompassing 17 colorado counties and the remaining area in nebraska 15 and wyoming 6 dennehy 1991 fig 2 a the south platte river 720 km in length davitt 2011 originates from the mountains to the southwest of denver with numerous tributaries joining as it flows northeast across the high plains of colorado the river crosses the colorado nebraska state line and eventually discharge to the north platte river colorado water conservation board 2015 fig 2a the sprb is the most populous basin in colorado west sage water consultants 2015 the total population of the basin within all three states in 2010 was approximately 3 4 million of which 95 percent reside in colorado the population is expected to double by 2050 dennehy et al 1995 waskom 2013 with dramatic growth in the urban and mountainous regions and static or declining rates in agricultural communities dennehy et al 1993 population growth is the biggest reason for the need for additional water supply in this region west sage water consultants 2015 3 1 2 climate the basin has a diverse hydrology pattern with periodic droughts and a climate that depends strongly on elevation davitt 2011 the topographic elevation in the basin ranges from about 4300 m in the rocky mountains in the west to about 850 m in the eastern plains fig 2c due to the wide temperature ranges and irregular seasonal and annual precipitation the climate is classified as continental type waskom 2013 the average annual precipitation ranges 0 25 0 5 m per year in the plains in the east to as high as 1 m per year near the continental divide where snow accumulates during the winter months davitt 2011 major precipitation events occur mid winter and spring in the mountainous part while the foothills receive most rainfall during the spring and early summer months spring storms are important in the mountains foothills and eastern plains for water supply the difference between a wet year and dry year often is due to the occurrence or absence of a few major storms waskom 2013 temperature increases from the mountainous region on the west to the foothills and plains on the east average monthly temperature varies between 35 and 38 degrees celsius oc dennehy et al 1993 warm summer temperatures low relative humidity high solar radiation and wind induce a high rate of evapotranspiration in the basin averaging between 1 and 1 5 m of potential or reference et for the eastern plains waskom 2013 in recent decades the average yearly temperature increased by 1 c in the last 30 years and 1 5 c in the last 50 years across colorado and an additional warming of 1 5 3 c is expected by 2050 colorado water conservation board 2015 the impact of this changing climate may be manifest in altered river flows and groundwater recharge reduction due to changes in timing and magnitude of rain and snowfall crop water use and evaporation rate west sage water consultants 2015 3 1 3 land use according to the 2007 united states census the sprb contains 7 of the 10 top value agricultural producing counties in colorado based on the national land cover dataset in 2011 homer et al 2015 land use and land cover of the basin is classified into rangeland 48 percent agricultural land 30 percent forest land 13 percent urban or built up land 6 percent and other lands 3 percent including water barren lands tundra and perennial snow and ice fig 2b the western portions of the basin are mostly forested while the high plains region is mainly grassland and planted or cultivated land colorado water conservation board 2015 irrigated lands through the basin have encountered a reduction from a peak of slightly over 400 000 ha in the mid 1970s to approximately 330 000 ha in 2013 waskom 2013 according to state projections the sprb could lose 35 of today s irrigated land by 2050 colorado s water supply future 2011 a significant reason for the decrease in irrigated lands is 1 urban growth along the front range and 2 the purchase of senior agricultural surface water rights and agricultural land dry up waskom 2013 3 1 4 water resources the alluvial groundwater system of the south platte river basin covers approximately 10 400 km2 fig 3 b based on a colorado geological survey in 2003 the aquifer is mainly composed of silt sand and gravel deposits of alluvial and aeolian origin with considerable heterogeneity hydraulic conductivity k values range from 30 to 610 m day cdm smith 2013 saturated aquifer thickness varies from 6 to 13 m at the upstream extent near denver to more than 61 m adjacent to the colorado nebraska border cdm smith 2013 waskom 2013 the unconfined alluvial aquifer is hydraulically connected with the south platte river along its main stem and major perennial tributaries see fig 3a for river network map groundwater discharge to the river channel creates baseflow for the river and is recharged by precipitation leakage from streams reservoirs and ditches and by percolation of applied irrigation water dennehy et al 1995 recharge from precipitation in the sprb ranges from approximately 15 of total precipitation along the foothills to 2 in the lower basin waskom 2013 the sprb likely faces a severe water supply gap in upcoming years an inverse relationship exists between consumed groundwater and surface water with groundwater used during dry periods when surface water is limited in the agricultural municipal and environmental sectors waskom 2013 conjunctive use of groundwater and surface water presents an efficient solution to future water needs however other challenges e g using groundwater without injuring senior water rights also may arise west sage water consultants 2015 this large economically diverse semi arid basin with large temperature ranges irregular seasonal and annual precipitation dennehy et al 1995 and 150 years of water management history is an ideal region to test the modified swat modflow model 3 2 swat model for the south platte river basin 3 2 1 model construction a swat model for the sprb was built using arcswat soil and water assessment tool 2015 the national elevation dataset ned from the u s geological survey at a 90 m resolution with burned in hydrography from high resolution nhdplus data moore and dewald 2016 statsgo soil data soil survey staff et al 2016 and the national land cover dataset in 2011 homer et al 2015 are used to obtain topography soil and land use types respectively for weather inputs such as precipitation wind relative humidity maximum and minimum air temperatures and solar radiation 80 weather stations are employed from different sources such as climate stations from ghcnd menne et al 2012 snotel snow telemetry 2017 and local entities such as coagmet andales et al 2014 and the northern colorado water conservancy district northern colorado water conservancy district 2017 to account for the influence of elevation on rainfall rates elevation bands are applied within the swat model in this study the watershed is divided into 194 subbasins with areas ranging from approximately 0 13 to 1300 km2 each subbasin is further subdivided into hrus defined as unique combinations of soil land cover and slope within the subbasin this configuration resulted in 1994 hrus 3 2 2 model calibration to quantify water supply using the swat model the model is calibrated by comparing model results with naturalized flow with data obtained from streamflow gages located in the mouth of canyons along the front range of the sprb the time series of data are obtained from both the usgs and the colorado division of water resources cdwr naturalized flow is determined by excluding human use and management it is described by 1 n f m f d f r f t b where nf is the naturalized flow mf is the measured gaged flow at the watershed outlet df is the total diverted flow rf is the total released flow and tb is trans basin streamflow added before the stream reaches the outlet calibration of the swat model is performed at eight outlets associated with the eight largest high elevation rivers for the periods of 1997 2015 on a daily time step with 3 years for a warm up period the location of these gages is shown in fig 3a the largest catchment area is located along south platte river at waterton station outlet 164 with an area of 6794 km2 and the smallest is located at builder creek near orodell outlet 120 with an area of 264 km2 the dynamically dimensioned search dds algorithm is used for model calibration this optimization algorithm was developed by tolson and shoemaker 2007 for automatic calibration of complex water shed models and is written in matlab to reach the goal of finding a proper global optimal solution the dds algorithm first samples the parameter space globally and as the number of iterations comes closer to the maximum allowable number defined by the user the algorithm automatically tunes the scale of the search focusing on regions of the parameter space where better results were generated to find the most optimal parameter set this transformation is adjusted by decreasing the number of varying model parameters to make a new search neighborhood tolson and shoemaker 2007 in this study the number of iterations is limited to 3000 for 33 model parameters table 1 the parameters selected for calibration and their ranges were selected based on several previous studies that conducted sensitivity analysis for the swat model in the same region ahmadi et al 2014 the nash sutcliffe coefficient of efficiency nse is used as the objective function as recommended by asce asce task committee 1993 for continuous hydrograph modeling additionally the goodness of model performance is assessed using relative error re and percent bias moriasi et al 2007 3 3 modflow model for the south platte river basin the modflow model of the sprb alluvial groundwater flow system was developed in recent years as part of the state of colorado s south platte decision support system project cdm smith 2013 brown and caldwell 2017 the model was originally developed for the 1950 2006 time period cdm smith 2013 but was extended through 2012 brown and caldwell 2017 using modflow nwt the modflow model is constructed using a grid cell size of 1000 foot by 1000 foot 304 8 m 304 8 m dividing the alluvial aquifer system into 655 rows and 848 columns the active model domain consists of 69 895 cells and is defined as areas with a saturated thickness of 3 m or more and with production wells with yields greater than 11 5 m3 hr the model domain is shown by the alluvial aquifer boundary in fig 3b the model accounts for all major sources and sinks to the alluvial aquifer including recharges from precipitation surface water and groundwater irrigation canal and reservoir seepage well pumping for irrigation and municipalities stream gains and losses lateral boundary inflows and outflows alluvial underflow fluxes evaporation and phreatophyte evapotranspiration cdm smith 2013 precipitation recharges and lateral boundary fluxes from unconsolidated material beyond the active grid cells are prepared in modflow recharge package rch format while well package wel includes groundwater pumping streamflow augmentation bedrock and alluvial underflow fluxes recharge ponds rate and canal seepage the modflow evapotranspiration segment package ets includes input files from alfalfa and sub irrigated meadow et phreatophyte vegetation et occurs when the water table rises up to the phreatophyte plants root zone and is assumed to be constant through time model calibration was achieved by refining aquifer properties with groundwater head streamflow and stream gains and losses used as calibration targets 3 4 coupled swat modflow model for the south platte river basin the coupled swat modflow sprb model is run for the period 1997 2012 initial cell by cell groundwater levels are obtained by using the estimated head values from modflow model for the stress period prior to the starting date of the coupled model december 1996 as vertical aquifer heterogeneity is neglected in the modflow model due to the use of a single layer for the areas with clay lenses interbedded in the sandy material the hydraulic conductivity were manually adjusted to provide an acceptable match between simulated and observed groundwater head values the inflows and outflows to the model and the allocations between swat and modflow are laid out schematically in fig 4 alluvial aquifer inflow occurs in the main stem of the south platte river in the area upgradient of the main tributaries due to fractures of weathered bedrock and from the underlying denver basin bedrock aquifer fig 3b aquifer outflow occurs near the outlet of the south platte river to account for the policy of well augmentation after the year 2006 the volumes of water diverted to managed recharge ponds and allowed to seep into the aquifer are included as a groundwater source in the modflow model the main water balance components handled by swat model are aquifer recharge surface water inflow and outflow and surface water discharges through different water user sectors domestic industrial and agriculture aquifer recharges consist of both precipitation and portion of irrigation water that percolates to the water table fig 5 demonstrates the gis coverage needed to facilitate the linking between swat and modflow the modflow grid cells and all pumping wells within the alluvial aquifer are shown in fig 5a fig 5b e shows the detailed linkage process for swat subbasin 90 fig 5b shows the delineation of the hrus in the subbasin with fig 5c showing the individual polygons resulting from intersecting the modflow grid cells with the disaggregated hrus this intersection determines the spatial relationship between the dhrus and the grid cells for passing swat recharge to modflow and modflow water table elevation to swat fig 5d shows the subbasin channel and the intersected river cells during the simulation the stream aquifer water exchange rate will be summed for all river cells in this subbasin and provided to swat s subbasin channel for routing finally fig 5e shows the modflow cells with pumping wells the volume of pumped groundwater from these cells is applied as irrigation water to swat hrus during the simulation for all the hrus in agricultural areas of sprb fields obtain irrigation water via either groundwater pumps or irrigation canals to demonstrate the usefulness of the model and the key features of the updated swat modflow modeling code two additional irrigation scenarios are run 3 5 results and discussion 3 5 1 streamflow at canyon outlets the observed and simulated streamflow at the 8 mouth of canyon sites are shown in fig 6 with performance statistics tabulated in table 2 as per general performance rating recommended by moriasi et al 2007 for nse and by adjusting the proposed ranges to daily values of this study one can conclude that outlets 136 75 51 105 and 120 are categorized as very good and outlet 124 as good the results for outlets 164 and 151 are satisfactory for these two outlets results cannot be improved because only one set of parameters is used for the entire basin 3 5 2 downstream flow streamflow is compared with observed streamflow within the basin at 5 different stream locations fig 2a along the south platte river fig 7 these streamflow measurements are influenced heavily by water management schemes e g reservoir releases canal diversions etc corresponding flow duration curves for both simulated and observed streamflow are also plotted in fig 7 results from the calibrated swat model also are shown to shown the improvement in streamflow prediction from the swat modflow model the swat modflow model shows a good fit in the upstream areas fig 7 a b the model performance in simulating average to high magnitude flows is satisfactory note the log scale of the flow rates for the flow duration curve charts thus the model performs well for the majority 80 of flows experienced the flows of high magnitude and therefore is a good simulator of the timing and magnitudes of water volumes passing through gage sites the one notable exception is the gage in subbasin 29 fig 7e which overestimates flow particularly for the drought years of 2002 2004 this subbasin however is in the far east region of the river basin where the flow is influenced by man made diversions and return flows the first four presented subbasins for which the coupled model performs well encompass the main agro urban region of the river basin the water yield in this subbasin is mostly dominated by lateral flow and groundwater return flow fig 8 groundwater in all other subbasins has a high contribution to water yield fig 8 by means of the flow duration curves fig 7 one can observe that the coupled swat modflow model has a better performance in simulating stream flow in comparison with swat model itself particularly for low flows this is likely due to the simplistic treatment of groundwater flow and resulting baseflow in the original swat model 3 5 3 basin water balance the average annual water budget for the entire river basin is shown in fig 9 with flux values mm normalized by dividing by the area of the basin well pumping is the largest stress on the south platte river basin alluvial aquifer the use of the psb package enabled better tracking of the water budget components water yield to the river is dominated by groundwater return flow 173 mm followed by lateral flow 19 mm and surface runoff 8 mm as such groundwater accounts for 87 of water yield the groundwater balance is effected principally by groundwater return flows 173 mm seepage from canals and reservoirs 110 mm lateral flow from surrounding areas 102 mm and pumping for irrigation 88 the amount of river seepage 22 mm is almost as much as what is diverted for surface water irrigation 32 mm this water balance can help with understanding patterns and magnitudes of hydrological processes and water transfer in the basin leading to strategies for managing water balance components 3 5 4 groundwater head model comparison with observed water table elevation is shown in fig 10 for both the original modflow model and the coupled swat modflow model water table elevation hydrographs for observation wells throughout the sprb alluvial aquifer are shown with mean absolute error mae values for both models reported in table 3 the observed values are obtained from monitoring wells with adequate data within the modeling period 1997 2012 available from the cdwr visual inspection of the graphs shows the better performance of the swat modflow model than the modflow model with results from the coupled model often able to track the pattern and magnitude of groundwater level fluctuations from the start of the coupled model 1997 comparison of mae between the models shows that the coupled model improves results for 70 of the locations however there are still significant residual between observed and simulated values in some parts of the basin this could be due to uncertainties affiliated with using a grid based model of large watersheds in modflow the pumping wells are assumed to be in the center of the cells in which they are located and thus for the cells in which monitoring well location is at a significant distance from the cell centroid the results cannot be compared precisely moreover more discrepancies between observed and simulated groundwater levels occur for monitoring wells located far from the main stem of the south platte river likely due to lack of information in some of the tributaries of surface water and ungaged surface water inflow another possible reason is uncertainties within the spatial variability of inputs the modflow model uses one layer for the entire thickness of the aquifer and therefore vertical heterogeneity in aquifer material and associated properties e g hydraulic conductivity is ignored for example the models under predict the elevation of the water table in the lasalle gilcrest area orange polygon in fig 10 map w87 chart in fig 10 this area has extensive clay lenses interbedded in the sandy material throughout the aquifer stratigraphy causing high water tables as this vertical heterogeneity is neglected in the model this behavior cannot be simulated correctly for the purpose of this study which assesses water resources for the entire sprb local assessments are not essential as the results aim to be used to quantify spatial water resources vulnerability in the basin and needs a broad overview to the water resources demands and supplies 3 5 5 impact of irrigation one of the key features of the updated swat modflow model presented in this paper is the linkage between modflow agricultural pumping cells and swat hrus for groundwater irrigation this modification is tested by looking at the changes in groundwater water table elevation head the changes in groundwater return flow and the changes in streamflow discharge under different scenarios of irrigation the first scenario is the baseline simulation with both surface water irrigation and groundwater irrigation the second scenario explores the basin hydrologic system in which no irrigation occurs the third scenario explores the basin hydrologic system in which irrigation water is supplied only by surface water and hence no agricultural pumping is simulated results are shown in figs 11 and 12 as expected groundwater head increases significantly in the absence of agricultural pumping maximum increase of 33 4 m spatial average increase of 2 7 m fig 11a1 11a2 as a result of the higher groundwater levels and thus groundwater head gradients the flux of groundwater return flows is also higher fig 11b1 11b2 this is also seen in fig 12 which shows an increase of 51 mm in groundwater return flow to streams increase of 30 from the baseline value of 173 mm to observe the effects of irrigation on streamflow discharge the average daily hydrographs of streamflow for the entire basin is plotted for all irrigation scenarios fig 11c1 11c2 compare to the baseline simulation the two irrigation scenarios experienced much more baseflow due to the added groundwater return flows from the increased groundwater head for the scenario with no irrigation scenario 2 the hydrographs have a longer recession time as surface water runoff lags due to the lack of concentrated inputs of surface water irrigation volumes 4 summary and conclusions the swat modflow code bailey et al 2016 was modified for application to large scale agro urban river basins with model use and performance demonstrated for the south platte river basin in northeastern colorado usa the modeling code is designed to handle water management schemes in large river basins such as conjunctive use of surface water and groundwater for irrigation all major water transfer pathways pumping injection into aquifer bedrock inflow canal seepage stream aquifer water exchange are included in either the swat model or the modflow model with daily interactions between the models occurring for soil recharge to the water table pumped groundwater applied as irrigation water and stream aquifer water exchange rates for better representation of the groundwater and surface water stressors the water budget scheme of the basin is presented and two limited irrigation scenarios show the impact of irrigation on water balance components in the river basin the model was run for the 1997 2012 period and by tested against groundwater elevation and streamflow discharges at monitoring wells and stream gages respectively located throughout the basin the results of the coupled swat modflow model are satisfactory in regards to simulating streamflow and groundwater elevations the presented model can be applied for management purposes enabling the water resources managers to quantify spatial groundwater vulnerability in large complex managed basins software availability the main swat modflow model comprising compiled executable source code tutorials and an example data set is available at https swat tamu edu software swat modflow for the modified version of the modeling code used in this study please contact ryan bailey at rtbailey colostate edu acknowledgments this work was supported by a grant from the agriculture and food research initiative of the usda national institute of food and agriculture nifa grant number 2012 67003 19904 we also thank three anonymous reviewers whose comments helped to improve the contents and presentation of information within this paper 
26244,within river basins water resources competition often exists between agricultural municipal and industrial sectors particularly in semi arid regions where surface water and groundwater are managed conjunctively to sustain urban areas and food production there is a need for physically based modeling tools to assist with identifying successful water management strategies in these basins this paper presents an updated version of swat modflow that allows application to large agro urban river basins in semi arid regions code changes include linkage between modflow pumping cells and swat hrus for groundwater irrigation joint groundwater and surface water irrigation routines and the use of modflow psb to handle the large array of groundwater sources sinks that exist in a highly managed river basin model performance is demonstrated for the 72 000 km2 south platte river basin colorado usa the model can be used in agro urban river basins worldwide to assess water resources supply under a variety of scenarios keywords hydrological modeling swat modflow large scale watershed river basin surface water groundwater interaction 1 introduction a significant portion of the world s population lives in semi arid and arid regions with over half of the population living in urban areas united nations 2014 this disproportionate distribution of people and allotment of water resources present a challenge in dry regions and mandate the implementation of strategies such as water reuse and desalination of salty water in such places to secure adequate water supplies to support growing populations shirazi et al 2018 moreover often there is an aggressive competition within a single river basin from the municipal agricultural industrial environmental and recreational sectors over the use of the limited supply of water competition between urban and agricultural demand occurs worldwide florke et al 2018 in the western united states chile and mexico increasing population has led to the transfer of water rights from irrigated agriculture to municipalities via agricultural lands dry up or water leasing programs meinzen dick and appasamy 2002 doherty and smith 2012 groundwater in rural areas is particularly vulnerable as the transfer of surface water rights to urban areas increases reliance on groundwater resources leading to a decrease in groundwater levels and overall groundwater storage knapp 2003 also removing surface water irrigation decreases seepage from earthen irrigation canals and deep percolation from applied surface water irrigation thereby removing a source of groundwater and leading to additional groundwater storage depletion in such a complex water resources network wherein both surface water and groundwater resources are managed conjunctively to satisfy all social sectors physically based distributed hydrological models can be used to quantify water availability under current and future conditions and determine appropriate integrated water management policies hydrological models typically are developed based on i surface runoff models that consider groundwater in a simplistic manner such as the hydrologiska byråns vattenbalansavdelning hbv bergstrom and forsman 1973 bergstrom 1992 the sacramento soil moisture accounting model sac sma burnash et al 1973 topmodel beven and kirby 1979 the variable infiltration capacity vic liang et al 1994 the hydrologic modeling system hec hms william et al 1995 u s army corps of engineers 2016 the soil and water assessment tool swat arnold et al 1998 the soil and water integrated model swim krysanova et al 2000 the hydrology laboratory research modeling system hl rms koren et al 2004 and the water global assessment and prognosis watergap verzano 2009 or ii groundwater models that consider surface water in a simplistic manner such as the modular finite difference flow model modflow harbaugh 2005 the microcomputer package for multiple aquifer groundwater flow modeling microfem diodato 2000 the object oriented quasi three dimensional regional groundwater model zoomq3d jackson 2001 the soilvision systems ltd finite element seepage analysis program svflux thode and fredlund 2013 and the finite element heat and mass transfer code fehm zyvoloski et al 2015 such analysis to quantify water supply for management purposes and vulnerability assessments in river basins can result in unrealistic inferences and subsequent ineffective decisions therefore detailed representation of both surface water and groundwater processes and also their interaction must be included in recent years a third category of hydrological models has emerged in which surface water and groundwater processes are linked some of these models solve the groundwater and surface water equations simultaneously in a single software package such as the catchment hydrology model cathy paniconi and wood 1993 the integrated hydrology model inhm vanderkwaak and loague 2001 hydrogeosphere hgs therrien et al 2010 opengeosys kolditz et al 2012 the pcraster global water balance model pcr globwb mod sutanudjaja et al 2014 and the parallel flow model parflow maxwell et al 2016 while others couple two or more different modeling codes to simulate the groundwater and surface water interactions such as mike she refsgaard and storm 1995 dhi 2017 swatmod sophocleous et al 1999 modhms hydrogeologic 2006 the grid based water flow and balance simulation model wasim eth schulla and jasper 2007 the coupled groundwater and surface water flow model gsflow markstrom et al 2008 the finite element subsurface flow system feflow dhi wasy gmbh 2016 and swat modflow kim et al 2008 guzman et al 2015 bailey et al 2016 several of these models have been applied at the river basin and even continental scale therrien et al 2010 maxwell et al 2016 although the vast majority of model applications have been at the small regional scale and largely restricted to either theoretical studies or studies aimed at specific governmental municipalities with the latter often remaining unpublished guzman et al 2015 barthel and banzhaf 2016 the development of a versatile integrated hydrological modeling code that accounts for all major water pathways and transfers in an agro urban system at a large geographic scale river basins such as in the updated version of coupled swat modflow presented in this study is essential for quantifying and managing water resources only at this scale can anthropogenic social and managerial factors along with complexity and heterogeneity of the system be reflected in simulations irvine et al 2012 barthel and banzhaf 2016 all previous versions and applications of swat modflow e g sophocleous et al 1999 sophocleous and perkins 2000 menking et al 2003 galbiati et al 2006 kim et al 2008 luo and sophocleous et al 2011 guzman et al 2015 bailey et al 2016 have been applied to small watersheds or been used to estimate specific water balance components runoff recharge groundwater surface water exchange rates none have been applied to large river basins of mixed agro urban land use types with the accompanying water transfer complexity e g groundwater pumped for irrigation surface water diverted for irrigation seepage from canals seepage from artificial recharge ponds etc the overall objective of this paper is to present an integrated hydrologic modeling code that accounts not only for surface water and groundwater hydrologic processes and their interaction but also the management schemes that transfer water between the domains in a semi arid heavily managed agro urban large river basin specifically this study i develops an integrated hydrologic modeling code that accounts for groundwater and surface water processes and exchanges in large regional scale managed river basins and ii demonstrates the use and performance of the integrated model in the economically diverse south platte river basin sprb a 72 000 km2 river basin located primarily in the state of colorado usa although the model is based on the available swat modflow modeling code bailey et al 2016 it has several key advances including linkage between modflow pumping and swat hru applied irrigation quantifying the irrigation amount based on both surface water canal diversions or groundwater pumping ability to store large arrays for linking modflow grids and swat watersheds with thousands of grid cells and hrus respectively and using the modflow psb package that partitions groundwater stresses into specific surface water and groundwater water budget terms application to the sprb is an ideal test for the model in that total volume of surface water diversions in the sprb is about twice the primary surface water supply i e snowmelt runoff indicating a significant reliance on groundwater recharge to surface water dozier et al 2017 diverted surface water recharges the aquifer which later discharges to the stream repeating multiple times as surface water flows towards the outlet of the river basin waskom 2013 the surface water and alluvial groundwater in the sprb are in close interaction and are considered as a single resource of water by colorado water law in general the results of this model demonstrate the applicability of integrated hydrological modeling for developing an improved understanding of linked groundwater and surface water systems and can be used in other studies to identify water management solutions 2 swat modflow modeling code for large scale river basins this section outlines the modification of the swat modflow modeling code bailey et al 2016 for application to semi arid agro urban large scale river basins theoretical descriptions of swat modflow and swat modflow are provided followed by a description of modifications and enhancements to swat modflow 2 1 swat the soil and water assessment tool swat arnold et al 1998 2012a is a physically based quasi distributed model that operates on a daily time step it is designed to simulate the movement of water sediment nutrient and pesticide within a watershed and to predict the effects of climate change and best management practices on the quantity and quality of water at the watershed scale the model divides the watershed into subbasins with each subbasin divided into hydrologic response units hrus i e unique combinations of land use soil and management the overall hydrologic balance such as partitioning of precipitation snowmelt water irrigation water between surface runoff and infiltration redistribution of water within the soil profile interception of precipitation and evapotranspiration are simulated for each hru outputs from hrus are lumped and directed to the subbasin stream for routing through the stream network to the outlet of the watershed swat has been used worldwide to address hydrologic and environmental problems however its application in assessing groundwater processes quantities and interaction with surface water is limited as a quasi distributed model swat does not represent the heterogeneity of an aquifer such as spatially varying hydraulic conductivity and specific yield nor the system response hydraulic head moreover swat is limited in simulating groundwater discharge to streams and stream seepage to the aquifer because it compares shallow aquifer depth with a threshold to estimate the river recharge and does not consider the river bottom elevation and aquifer depth gassman et al 2007 kim et al 2008 arnold et al 2012b gayathri et al 2015 2 2 modflow modflow harbaugh 2005 is a public domain numerical groundwater modeling code developed by the u s geological survey usgs the model is written in fortran and solves the groundwater flow equation using the finite difference method one of the most recent versions is modflow nwt niswonger et al 2011 an algorithmic reformulation of modflow 2005 that uses the newton raphson method this new algorithm performs well in highly nonlinear problems such as unconfined groundwater systems and the process of drying and rewetting of grid cells hunt and feinstein 2012 modflow simulates a variety of hydrologic processes in steady and transient states for different types of aquifers interactions between the land surface and groundwater and between surface water and groundwater are simulated using a variety of boundary condition packages including the recharge well drain lake reservoir and streamflow routing packages 2 3 swat modflow the coupled swat modflow model bailey et al 2016 links the swat2012 and modflow nwt model codes the groundwater module inside the swat code is replaced by modflow making a single executable fortran code and allowing for daily interactions between the two models without the need for writing and reading model data the linkage between swat and modflow is based on mapping schemes that pass hru based variables e g recharge from the soil zone and subbasin based variables stream stage to the modflow grid and grid based variables e g water table elevation rate of water exchange between groundwater and the stream network to swat hrus and subbasin channels the hru based recharge is mapped to modflow s recharge package and the stream aquifer water exchange is simulated by the river package the geographic relation between the hrus and grid cells and between the river cells and subbasin streams is quantified using geoprocessing routines with the information stored in text files that are read in at the beginning of the swat modflow simulation prior to intersecting with the modflow grid cells the hrus are split into geographically defined disaggregated hrus dhrus 2 4 modified swat modflow model for agro urban river basins this section describes modifications to the original swat modflow code to allow for application to basin scale agro urban watershed systems the overall flow of data within the code is presented in fig 1 specific modifications to the swat modflow code include i transfer of groundwater from the aquifer to irrigated fields by linking modflow pumping cells to swat hrus designated by 1 in fig 1 and explained in detail in the last paragraph of this section ii working with the modflow psb capability brown and caldwell 2017 zeiler et al 2017 in which the stresses are partitioned into multiple input files this capability is essential for including all the groundwater sources sinks existing in an agro urban river basin and for linking the soil percolation from swat hrus to the correct recharge grid designated by 2 in fig 1 and explained in detail in the last paragraph of this section iii modification of swat s auto irrigation algorithms to allow surface water irrigation to supplement groundwater irrigation i e if groundwater irrigation from pumping wells is not sufficient to meet crop water demands then water will be diverted from the nearest subbasin stream iv modification of swat modflow subroutines that handle linking between grid cells and hrus to enable application to large watershed systems for large watersheds wherein modflow grids can have hundreds of thousands of grid cells and swat can have tens of thousands of hrus extremely large arrays have resulted in insufficient memory errors when attempting to apply the original swat modflow code the current change allows arrays to be allocated more efficiently thereby enabling application to large systems such as the sprb the code first reads in swat inputs modflow inputs and information for mapping swat hru and subbasin variables to the modflow grid and vice versa compared to the original swat modflow code one more text file is needed that lists modflow grid cells that provide irrigation water and their associated swat subbasins and hrus swatmf irrigate txt fig 1 to enable linking for transferring pumped groundwater to the ground surface swat runs through a year loop and then a day loop with subbasin calculations performed for each day for each subbasin the hru calculations are performed including land surface hydrology irrigation application and soil crop hydrologic processes percolation from the bottom of the soil profile and subbasin channel stage are then mapped to the modflow grid cells and river cells respectively whereupon modflow runs using the partition stress boundary psb capability and then maps groundwater surface water exchange rates groundwater irrigation depths and water table elevation to swat subbasin channels and hrus respectively water entering each subbasin stream via surface runoff swat soil lateral flow swat or groundwater flow modflow is then routed through the watershed stream network for the day as with the original version of swat modflow swat is linked with modflow nwt however the psb capability is implemented into the code which enables tracking of separate stress components without lumping them into a single modflow package the psb capability was originally developed for modflow cdss banta 2011 a version of modflow 2005 designed to support groundwater models for colorado s decision support systems cdss 2017 the psb capability was subsequently incorporated into modflow nwt as part of the south platte decision support system spdss groundwater model update brown and caldwell 2017 zeiler et al 2017 the capability facilitates groundwater flow modeling in aquifer systems with a large variety of groundwater sources and sinks of similar type using the psb capability each stress boundary package e g recharge package well package can be partitioned into a selected set of packages with volumetric flow rates for each individual stress listed in a separate input file for example the well package can be partitioned into municipal pumping agricultural pumping groundwater injection etc and the recharge package can be partitioned into reservoir seepage recharge pond seepage rainfall recharge and irrigation recharge the water budget component of each stress partition is tracked separately in the water budget tables printed in the modflow output file packages supported by the psb capability include recharge rch river riv well wel drain drn drain return drt evapotranspiration evt evapotranspiration segments ets and general head boundary ghb within the swat modflow code swat hru soil percolation rates are mapped to the modflow grid for rainfall and irrigation recharge designated by 2 in fig 1 and modflow agricultural pumping rates are mapped to swat hrus for groundwater irrigation designated by 1 in fig 1 when mapping rainfall and irrigation recharge from swat hrus to modflow grid cells and pumped irrigation water from modflow to swat hrus the appropriate stress grid must be specified so as not to over write cell by cell values for other stresses irrigation water can be supplied by surface water via irrigation canals and or by groundwater via pumping wells groundwater pumped using the agricultural pumping stress of the well package can be mapped to swat hrus pumped groundwater volumes are converted to applied irrigation depths and provided to hrus for irrigation on the following day using the spatial area of the hru using the auto irrigation algorithms of swat surface water irrigation can be supplied by the nearest subbasin channel representing surface water diverted from the stream via irrigation canals the hru receiving irrigation water from each modflow pumping cell is specified in a list in the swatmf irrigate txt input file see fig 1 the user also specifies the runoff ratio i e percent of irrigation water that runs off the field as tailwater for groundwater irrigation in each sub basin however there are many fields that use canal water instead of groundwater for irrigational purposes the swat auto irrigation subroutines were modified to include surface water from a specified subbasin channel after pumping water is applied so that the full specified depth of irrigation is met 3 model application to the south platte river basin 3 1 area of study 3 1 1 geography and demographics the south platte river basin sprb has a spatial area of approximately 72 000 km2 colorado s water supply future 2011 with 79 of the area in colorado encompassing 17 colorado counties and the remaining area in nebraska 15 and wyoming 6 dennehy 1991 fig 2 a the south platte river 720 km in length davitt 2011 originates from the mountains to the southwest of denver with numerous tributaries joining as it flows northeast across the high plains of colorado the river crosses the colorado nebraska state line and eventually discharge to the north platte river colorado water conservation board 2015 fig 2a the sprb is the most populous basin in colorado west sage water consultants 2015 the total population of the basin within all three states in 2010 was approximately 3 4 million of which 95 percent reside in colorado the population is expected to double by 2050 dennehy et al 1995 waskom 2013 with dramatic growth in the urban and mountainous regions and static or declining rates in agricultural communities dennehy et al 1993 population growth is the biggest reason for the need for additional water supply in this region west sage water consultants 2015 3 1 2 climate the basin has a diverse hydrology pattern with periodic droughts and a climate that depends strongly on elevation davitt 2011 the topographic elevation in the basin ranges from about 4300 m in the rocky mountains in the west to about 850 m in the eastern plains fig 2c due to the wide temperature ranges and irregular seasonal and annual precipitation the climate is classified as continental type waskom 2013 the average annual precipitation ranges 0 25 0 5 m per year in the plains in the east to as high as 1 m per year near the continental divide where snow accumulates during the winter months davitt 2011 major precipitation events occur mid winter and spring in the mountainous part while the foothills receive most rainfall during the spring and early summer months spring storms are important in the mountains foothills and eastern plains for water supply the difference between a wet year and dry year often is due to the occurrence or absence of a few major storms waskom 2013 temperature increases from the mountainous region on the west to the foothills and plains on the east average monthly temperature varies between 35 and 38 degrees celsius oc dennehy et al 1993 warm summer temperatures low relative humidity high solar radiation and wind induce a high rate of evapotranspiration in the basin averaging between 1 and 1 5 m of potential or reference et for the eastern plains waskom 2013 in recent decades the average yearly temperature increased by 1 c in the last 30 years and 1 5 c in the last 50 years across colorado and an additional warming of 1 5 3 c is expected by 2050 colorado water conservation board 2015 the impact of this changing climate may be manifest in altered river flows and groundwater recharge reduction due to changes in timing and magnitude of rain and snowfall crop water use and evaporation rate west sage water consultants 2015 3 1 3 land use according to the 2007 united states census the sprb contains 7 of the 10 top value agricultural producing counties in colorado based on the national land cover dataset in 2011 homer et al 2015 land use and land cover of the basin is classified into rangeland 48 percent agricultural land 30 percent forest land 13 percent urban or built up land 6 percent and other lands 3 percent including water barren lands tundra and perennial snow and ice fig 2b the western portions of the basin are mostly forested while the high plains region is mainly grassland and planted or cultivated land colorado water conservation board 2015 irrigated lands through the basin have encountered a reduction from a peak of slightly over 400 000 ha in the mid 1970s to approximately 330 000 ha in 2013 waskom 2013 according to state projections the sprb could lose 35 of today s irrigated land by 2050 colorado s water supply future 2011 a significant reason for the decrease in irrigated lands is 1 urban growth along the front range and 2 the purchase of senior agricultural surface water rights and agricultural land dry up waskom 2013 3 1 4 water resources the alluvial groundwater system of the south platte river basin covers approximately 10 400 km2 fig 3 b based on a colorado geological survey in 2003 the aquifer is mainly composed of silt sand and gravel deposits of alluvial and aeolian origin with considerable heterogeneity hydraulic conductivity k values range from 30 to 610 m day cdm smith 2013 saturated aquifer thickness varies from 6 to 13 m at the upstream extent near denver to more than 61 m adjacent to the colorado nebraska border cdm smith 2013 waskom 2013 the unconfined alluvial aquifer is hydraulically connected with the south platte river along its main stem and major perennial tributaries see fig 3a for river network map groundwater discharge to the river channel creates baseflow for the river and is recharged by precipitation leakage from streams reservoirs and ditches and by percolation of applied irrigation water dennehy et al 1995 recharge from precipitation in the sprb ranges from approximately 15 of total precipitation along the foothills to 2 in the lower basin waskom 2013 the sprb likely faces a severe water supply gap in upcoming years an inverse relationship exists between consumed groundwater and surface water with groundwater used during dry periods when surface water is limited in the agricultural municipal and environmental sectors waskom 2013 conjunctive use of groundwater and surface water presents an efficient solution to future water needs however other challenges e g using groundwater without injuring senior water rights also may arise west sage water consultants 2015 this large economically diverse semi arid basin with large temperature ranges irregular seasonal and annual precipitation dennehy et al 1995 and 150 years of water management history is an ideal region to test the modified swat modflow model 3 2 swat model for the south platte river basin 3 2 1 model construction a swat model for the sprb was built using arcswat soil and water assessment tool 2015 the national elevation dataset ned from the u s geological survey at a 90 m resolution with burned in hydrography from high resolution nhdplus data moore and dewald 2016 statsgo soil data soil survey staff et al 2016 and the national land cover dataset in 2011 homer et al 2015 are used to obtain topography soil and land use types respectively for weather inputs such as precipitation wind relative humidity maximum and minimum air temperatures and solar radiation 80 weather stations are employed from different sources such as climate stations from ghcnd menne et al 2012 snotel snow telemetry 2017 and local entities such as coagmet andales et al 2014 and the northern colorado water conservancy district northern colorado water conservancy district 2017 to account for the influence of elevation on rainfall rates elevation bands are applied within the swat model in this study the watershed is divided into 194 subbasins with areas ranging from approximately 0 13 to 1300 km2 each subbasin is further subdivided into hrus defined as unique combinations of soil land cover and slope within the subbasin this configuration resulted in 1994 hrus 3 2 2 model calibration to quantify water supply using the swat model the model is calibrated by comparing model results with naturalized flow with data obtained from streamflow gages located in the mouth of canyons along the front range of the sprb the time series of data are obtained from both the usgs and the colorado division of water resources cdwr naturalized flow is determined by excluding human use and management it is described by 1 n f m f d f r f t b where nf is the naturalized flow mf is the measured gaged flow at the watershed outlet df is the total diverted flow rf is the total released flow and tb is trans basin streamflow added before the stream reaches the outlet calibration of the swat model is performed at eight outlets associated with the eight largest high elevation rivers for the periods of 1997 2015 on a daily time step with 3 years for a warm up period the location of these gages is shown in fig 3a the largest catchment area is located along south platte river at waterton station outlet 164 with an area of 6794 km2 and the smallest is located at builder creek near orodell outlet 120 with an area of 264 km2 the dynamically dimensioned search dds algorithm is used for model calibration this optimization algorithm was developed by tolson and shoemaker 2007 for automatic calibration of complex water shed models and is written in matlab to reach the goal of finding a proper global optimal solution the dds algorithm first samples the parameter space globally and as the number of iterations comes closer to the maximum allowable number defined by the user the algorithm automatically tunes the scale of the search focusing on regions of the parameter space where better results were generated to find the most optimal parameter set this transformation is adjusted by decreasing the number of varying model parameters to make a new search neighborhood tolson and shoemaker 2007 in this study the number of iterations is limited to 3000 for 33 model parameters table 1 the parameters selected for calibration and their ranges were selected based on several previous studies that conducted sensitivity analysis for the swat model in the same region ahmadi et al 2014 the nash sutcliffe coefficient of efficiency nse is used as the objective function as recommended by asce asce task committee 1993 for continuous hydrograph modeling additionally the goodness of model performance is assessed using relative error re and percent bias moriasi et al 2007 3 3 modflow model for the south platte river basin the modflow model of the sprb alluvial groundwater flow system was developed in recent years as part of the state of colorado s south platte decision support system project cdm smith 2013 brown and caldwell 2017 the model was originally developed for the 1950 2006 time period cdm smith 2013 but was extended through 2012 brown and caldwell 2017 using modflow nwt the modflow model is constructed using a grid cell size of 1000 foot by 1000 foot 304 8 m 304 8 m dividing the alluvial aquifer system into 655 rows and 848 columns the active model domain consists of 69 895 cells and is defined as areas with a saturated thickness of 3 m or more and with production wells with yields greater than 11 5 m3 hr the model domain is shown by the alluvial aquifer boundary in fig 3b the model accounts for all major sources and sinks to the alluvial aquifer including recharges from precipitation surface water and groundwater irrigation canal and reservoir seepage well pumping for irrigation and municipalities stream gains and losses lateral boundary inflows and outflows alluvial underflow fluxes evaporation and phreatophyte evapotranspiration cdm smith 2013 precipitation recharges and lateral boundary fluxes from unconsolidated material beyond the active grid cells are prepared in modflow recharge package rch format while well package wel includes groundwater pumping streamflow augmentation bedrock and alluvial underflow fluxes recharge ponds rate and canal seepage the modflow evapotranspiration segment package ets includes input files from alfalfa and sub irrigated meadow et phreatophyte vegetation et occurs when the water table rises up to the phreatophyte plants root zone and is assumed to be constant through time model calibration was achieved by refining aquifer properties with groundwater head streamflow and stream gains and losses used as calibration targets 3 4 coupled swat modflow model for the south platte river basin the coupled swat modflow sprb model is run for the period 1997 2012 initial cell by cell groundwater levels are obtained by using the estimated head values from modflow model for the stress period prior to the starting date of the coupled model december 1996 as vertical aquifer heterogeneity is neglected in the modflow model due to the use of a single layer for the areas with clay lenses interbedded in the sandy material the hydraulic conductivity were manually adjusted to provide an acceptable match between simulated and observed groundwater head values the inflows and outflows to the model and the allocations between swat and modflow are laid out schematically in fig 4 alluvial aquifer inflow occurs in the main stem of the south platte river in the area upgradient of the main tributaries due to fractures of weathered bedrock and from the underlying denver basin bedrock aquifer fig 3b aquifer outflow occurs near the outlet of the south platte river to account for the policy of well augmentation after the year 2006 the volumes of water diverted to managed recharge ponds and allowed to seep into the aquifer are included as a groundwater source in the modflow model the main water balance components handled by swat model are aquifer recharge surface water inflow and outflow and surface water discharges through different water user sectors domestic industrial and agriculture aquifer recharges consist of both precipitation and portion of irrigation water that percolates to the water table fig 5 demonstrates the gis coverage needed to facilitate the linking between swat and modflow the modflow grid cells and all pumping wells within the alluvial aquifer are shown in fig 5a fig 5b e shows the detailed linkage process for swat subbasin 90 fig 5b shows the delineation of the hrus in the subbasin with fig 5c showing the individual polygons resulting from intersecting the modflow grid cells with the disaggregated hrus this intersection determines the spatial relationship between the dhrus and the grid cells for passing swat recharge to modflow and modflow water table elevation to swat fig 5d shows the subbasin channel and the intersected river cells during the simulation the stream aquifer water exchange rate will be summed for all river cells in this subbasin and provided to swat s subbasin channel for routing finally fig 5e shows the modflow cells with pumping wells the volume of pumped groundwater from these cells is applied as irrigation water to swat hrus during the simulation for all the hrus in agricultural areas of sprb fields obtain irrigation water via either groundwater pumps or irrigation canals to demonstrate the usefulness of the model and the key features of the updated swat modflow modeling code two additional irrigation scenarios are run 3 5 results and discussion 3 5 1 streamflow at canyon outlets the observed and simulated streamflow at the 8 mouth of canyon sites are shown in fig 6 with performance statistics tabulated in table 2 as per general performance rating recommended by moriasi et al 2007 for nse and by adjusting the proposed ranges to daily values of this study one can conclude that outlets 136 75 51 105 and 120 are categorized as very good and outlet 124 as good the results for outlets 164 and 151 are satisfactory for these two outlets results cannot be improved because only one set of parameters is used for the entire basin 3 5 2 downstream flow streamflow is compared with observed streamflow within the basin at 5 different stream locations fig 2a along the south platte river fig 7 these streamflow measurements are influenced heavily by water management schemes e g reservoir releases canal diversions etc corresponding flow duration curves for both simulated and observed streamflow are also plotted in fig 7 results from the calibrated swat model also are shown to shown the improvement in streamflow prediction from the swat modflow model the swat modflow model shows a good fit in the upstream areas fig 7 a b the model performance in simulating average to high magnitude flows is satisfactory note the log scale of the flow rates for the flow duration curve charts thus the model performs well for the majority 80 of flows experienced the flows of high magnitude and therefore is a good simulator of the timing and magnitudes of water volumes passing through gage sites the one notable exception is the gage in subbasin 29 fig 7e which overestimates flow particularly for the drought years of 2002 2004 this subbasin however is in the far east region of the river basin where the flow is influenced by man made diversions and return flows the first four presented subbasins for which the coupled model performs well encompass the main agro urban region of the river basin the water yield in this subbasin is mostly dominated by lateral flow and groundwater return flow fig 8 groundwater in all other subbasins has a high contribution to water yield fig 8 by means of the flow duration curves fig 7 one can observe that the coupled swat modflow model has a better performance in simulating stream flow in comparison with swat model itself particularly for low flows this is likely due to the simplistic treatment of groundwater flow and resulting baseflow in the original swat model 3 5 3 basin water balance the average annual water budget for the entire river basin is shown in fig 9 with flux values mm normalized by dividing by the area of the basin well pumping is the largest stress on the south platte river basin alluvial aquifer the use of the psb package enabled better tracking of the water budget components water yield to the river is dominated by groundwater return flow 173 mm followed by lateral flow 19 mm and surface runoff 8 mm as such groundwater accounts for 87 of water yield the groundwater balance is effected principally by groundwater return flows 173 mm seepage from canals and reservoirs 110 mm lateral flow from surrounding areas 102 mm and pumping for irrigation 88 the amount of river seepage 22 mm is almost as much as what is diverted for surface water irrigation 32 mm this water balance can help with understanding patterns and magnitudes of hydrological processes and water transfer in the basin leading to strategies for managing water balance components 3 5 4 groundwater head model comparison with observed water table elevation is shown in fig 10 for both the original modflow model and the coupled swat modflow model water table elevation hydrographs for observation wells throughout the sprb alluvial aquifer are shown with mean absolute error mae values for both models reported in table 3 the observed values are obtained from monitoring wells with adequate data within the modeling period 1997 2012 available from the cdwr visual inspection of the graphs shows the better performance of the swat modflow model than the modflow model with results from the coupled model often able to track the pattern and magnitude of groundwater level fluctuations from the start of the coupled model 1997 comparison of mae between the models shows that the coupled model improves results for 70 of the locations however there are still significant residual between observed and simulated values in some parts of the basin this could be due to uncertainties affiliated with using a grid based model of large watersheds in modflow the pumping wells are assumed to be in the center of the cells in which they are located and thus for the cells in which monitoring well location is at a significant distance from the cell centroid the results cannot be compared precisely moreover more discrepancies between observed and simulated groundwater levels occur for monitoring wells located far from the main stem of the south platte river likely due to lack of information in some of the tributaries of surface water and ungaged surface water inflow another possible reason is uncertainties within the spatial variability of inputs the modflow model uses one layer for the entire thickness of the aquifer and therefore vertical heterogeneity in aquifer material and associated properties e g hydraulic conductivity is ignored for example the models under predict the elevation of the water table in the lasalle gilcrest area orange polygon in fig 10 map w87 chart in fig 10 this area has extensive clay lenses interbedded in the sandy material throughout the aquifer stratigraphy causing high water tables as this vertical heterogeneity is neglected in the model this behavior cannot be simulated correctly for the purpose of this study which assesses water resources for the entire sprb local assessments are not essential as the results aim to be used to quantify spatial water resources vulnerability in the basin and needs a broad overview to the water resources demands and supplies 3 5 5 impact of irrigation one of the key features of the updated swat modflow model presented in this paper is the linkage between modflow agricultural pumping cells and swat hrus for groundwater irrigation this modification is tested by looking at the changes in groundwater water table elevation head the changes in groundwater return flow and the changes in streamflow discharge under different scenarios of irrigation the first scenario is the baseline simulation with both surface water irrigation and groundwater irrigation the second scenario explores the basin hydrologic system in which no irrigation occurs the third scenario explores the basin hydrologic system in which irrigation water is supplied only by surface water and hence no agricultural pumping is simulated results are shown in figs 11 and 12 as expected groundwater head increases significantly in the absence of agricultural pumping maximum increase of 33 4 m spatial average increase of 2 7 m fig 11a1 11a2 as a result of the higher groundwater levels and thus groundwater head gradients the flux of groundwater return flows is also higher fig 11b1 11b2 this is also seen in fig 12 which shows an increase of 51 mm in groundwater return flow to streams increase of 30 from the baseline value of 173 mm to observe the effects of irrigation on streamflow discharge the average daily hydrographs of streamflow for the entire basin is plotted for all irrigation scenarios fig 11c1 11c2 compare to the baseline simulation the two irrigation scenarios experienced much more baseflow due to the added groundwater return flows from the increased groundwater head for the scenario with no irrigation scenario 2 the hydrographs have a longer recession time as surface water runoff lags due to the lack of concentrated inputs of surface water irrigation volumes 4 summary and conclusions the swat modflow code bailey et al 2016 was modified for application to large scale agro urban river basins with model use and performance demonstrated for the south platte river basin in northeastern colorado usa the modeling code is designed to handle water management schemes in large river basins such as conjunctive use of surface water and groundwater for irrigation all major water transfer pathways pumping injection into aquifer bedrock inflow canal seepage stream aquifer water exchange are included in either the swat model or the modflow model with daily interactions between the models occurring for soil recharge to the water table pumped groundwater applied as irrigation water and stream aquifer water exchange rates for better representation of the groundwater and surface water stressors the water budget scheme of the basin is presented and two limited irrigation scenarios show the impact of irrigation on water balance components in the river basin the model was run for the 1997 2012 period and by tested against groundwater elevation and streamflow discharges at monitoring wells and stream gages respectively located throughout the basin the results of the coupled swat modflow model are satisfactory in regards to simulating streamflow and groundwater elevations the presented model can be applied for management purposes enabling the water resources managers to quantify spatial groundwater vulnerability in large complex managed basins software availability the main swat modflow model comprising compiled executable source code tutorials and an example data set is available at https swat tamu edu software swat modflow for the modified version of the modeling code used in this study please contact ryan bailey at rtbailey colostate edu acknowledgments this work was supported by a grant from the agriculture and food research initiative of the usda national institute of food and agriculture nifa grant number 2012 67003 19904 we also thank three anonymous reviewers whose comments helped to improve the contents and presentation of information within this paper 
