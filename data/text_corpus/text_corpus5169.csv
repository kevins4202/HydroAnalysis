index,text
25845,a key issue in optimization model development is the selection of spatial and temporal scale representing the system this study proposes a framework for reasoning about scale in this context drawing on a review of studies applying multi objective optimization for water management involving environmental flows we suggest that scale is determined by the management problem constrained by data availability computational and model capabilities there is therefore an inherent trade off between problem perception and available modelling capability which can either be resolved by obtaining data needed or tailoring analysis to the data available in the interest of fostering transparency in this trade off process this paper outlines phases of model development associated decisions and available options and scale implications of each decision the problem perception phase collects system information about objectives limiting conditions and management options the problem formulation phase collects and uses data information and methods about system structure and behaviour graphical abstract image 1 keywords multi scale analysis environmental flows multi objective optimization water management trade off analysis 1 introduction water management is challenged by socio economic e g rising demand sectoral competition and climate change pressures e g droughts extreme events eea 2017 grizzetti et al 2017 tonkin et al 2019 threatening water security kennen stein and webb 2018 and river biodiversity vörösmarty et al 2010 despite increasing awareness of river ecosystems needs arthington et al 2018 water allocation goals typically still aim to provide water to people when and where they most need it and not when and where it would naturally be available daniell and barreteau 2014 however addressing the challenges of climate change and increasing demand will require a range of strategic actions including those that directly protect and restore the environment pittock and lankford 2010 thompson et al 2014 liu liu and yang 2016 salik et al 2016 failing to adequately incorporate ecosystem values and underestimating the potential cross scale impacts of water use and climate change on freshwater ecosystems mccluney et al 2014 fails to acknowledge the benefits that freshwater systems generate for the wider community richter 2009 the implementation of environmental flows is one action that is already applied mendoza and martins 2006 le quesne kendy and weston 2010 poff et al 2010 king et al 2015 horne o donnell and tharme 2017 to better protect freshwater and related ecosystems from modifications caused by river regulation e g dams weirs diversion channels poff et al 1997 arthington 2012 and high intensity use eea 2012 the approach to implementing environmental flows and the accompanying water management decisions varies according to governance level spatial extent and temporal scale of the desired outcome broad scale long term environmental flows e flows management typically employs a top down approach by imposing limits to additional hydrological alteration e g caps on water abstraction license conditions for water users environmental water rights see horne et al 2018 whereas a bottom up strategy e g conditions on storage operators environmental reserve established legally that considers ecologically relevant components of the flow regime and their ranges is implemented at finer scales and generally prioritizes short term effects pahl wostl et al 2013 gopal 2016 horne webb et al 2017 current incorporation of e flows within integrated water resource management iwrm expresses environmental water requirements as quantity quality and timing of water flows in the short term at point scale to limit impact propagation towards broader spatial scales in the long term vörösmarty et al 2013 evers 2016 arthington et al 2018 as a consequence water governance seeks to implement enhanced management and infrastructure systems that can regulate river flow at multiple spatial and or temporal levels daniell and barreteau 2014 stewardson et al 2017 in the light of changing consumptive water needs scale specific investigation tools are often used to inform successful river management volk et al 2008 case study level applications show that some management problems envisage several objectives and hence multi objective optimization can be used to address water management needs at different spatial scales such as hydropower facility reservoir reach sub basin and basin and different temporal horizons e g shang 2015 yin et al 2015 fallah mehdipour bozorg haddad and loáiciga 2018 the optimization of a set of desired objectives related to water abstraction or release e g species survival hydropower production domestic supply irrigation seeks to find optimal solutions these solutions are searched across a range of criteria that allow the identification of trade offs and synergies and as a result the definition of compromises among conflicting goals horne et al 2016 cord et al 2017 gunantara 2018 the opportunity to explore compromise solutions might better support decision making processes than single objective modelling as it has been shown in other resource allocation problems e g lautenbach et al 2013 kaya et al 2016 kaim et al 2018 however modelling these decisions in water management is made challenging by the fragmentation and hierarchy of hydrological scales moss and newig 2010 a key obstacle is related to the consideration of the different scale specific hydrological and ecological characteristics and processes volk and ewert 2011 davies et al 2014 thorp 2014 indeed the effective representation of connections e g ecological hydrological and geomorphological on each temporal and spatial scale of the river network remains a core challenge in e flow assessments poff tharme and arthington 2017 another problem is related to the reference hydrological scales used in the classification of river spatial extent the spatial mismatch between physical and socio political boundaries poses a challenge for the definition and implementation of management objectives moss and newig 2010 daniell and barreteau 2014 van den belt and blake 2015 opperman et al 2018 lastly chosen e flow parameters can be employed for studies at small scales and can show effects in the short term e g population size but can also be ecologically relevant for wider areas e g basin scale and support processes that manifest at longer temporal scales e g nutrient cycling poff tharme and arthington 2017 this requires the consideration of a range of flow events e g pulses 30 day minimum flow and diverse processes e g water production sediment delivery and vegetation dynamics ecological stages land cover influence gurnell et al 2016 opperman et al 2018 in this study we present a framework that describes the conceptual and operational steps of optimization model development to support e flows and the related spatial and temporal scale considerations the framework draws on a review of the state of art in this field of water research clarity about the role of scale improves our ability to model across scales and as a consequence provide more reliable predictions of decision outcomes at the scales of interest the paper first introduces water management decisions and their translation into optimization models see box 1 for the definition of terms and provides the outline of the proposed framework showing the stages of optimization problem development i e problem perception phase and problem formulation phase section 2 the framework mapping the scale related decisions and options linked to each development phase is further described with reference to results from the review of selected studies in section 3 section 4 discusses the need for clarity of problem definition strategies to implement desired assessment scales and explicit discussion of trade offs in problem development lastly in section 5 we provide recommendations to foster transparency throughout the optimization problem development phases 2 a framework for incorporating scale within optimization modelling to support e flows water management decisions an optimization approach offers the opportunity to explore compromise solutions to support decisions about scarce water resources horne et al 2016 it can be used to support environmental water management decisions while meeting conflicting water use objectives e g hydropower generation domestic supply industrial supply irrigation water environmental water objectives drive management actions that can be implemented at broader e g control of diversion or finer target scales e g need to control reservoir releases the timeframe of implementation also varies based on the management decision water resources management and in particular e flows sit within an adaptive management framework that reflects these different temporal and spatial scales webb et al 2017 the selection of objectives and high level policy decisions are made at a longer time scale and often for larger catchments or whole basins see horne and konrad 2017 however implementation decisions are made at a shorter time scale and often for a specific site or location optimization to support these decisions therefore also lends itself to be framed within an adaptive management framework providing the structure and technical capacity to support trade offs and decision making at different scales fig 1 each stage of the adaptive management cycle has its own technical challenges similarly the translation of management decisions into an optimization procedure needs to consider a range of factors to ensure the context and system is realistically represented table 1 uses a number of examples to demonstrate the importance of the type of management approach being considered the columns in table 1 for informing the approach to optimization model development for instance the decision to set a cap on abstraction can be tied to optimization at basin scale considering an annual or seasonal time frame the optimization of release timing at seasonal monthly or daily scale in response to the need to meet downstream ecological needs target ecological indicators will be preferred for management decisions at smaller spatial scales e g reaches or sub basins to match species ecological response timeframes and local hydrological conditions at sub daily scale it could be applied to reduce hydropeaking impacts at target locations the specific decision context dictates the target scales however translation of real world management problems into a modelling framework presents some inherent challenges either related to data availability modelling or computational ability the water management analyst dealing with optimization model development hence faces a range of trade offs in model representation in particular linked with choices of scale associated with the targeted problem and resulting modelled representation any optimization model development procedure to support e flows decisions and water resource management will need to explicitly consider the implication and magnitude of these trade offs for the spatial and temporal scales of the assessment to foster transparency and understandability a general optimization process showed in fig 2 left hand side first involves problem identification or contextualization and subsequently requires input parameters definition and optimization environment creation see maier et al 2014 for in depth overview as a first step the system domain is defined by the water management problem and decisions which underpin the relevant objectives constraints and scenarios of the targeted spatial and temporal scales of assessment fig 2 right hand side once defined the system characteristics hydrological data and other relevant information e g ecological are gathered to meet the requirements for representation at the targeted scales given that optimization assessments need to inform a decision making process hence the output the final scales of the assessment should appropriately match decision conditions and scales trade offs in system representation arise when moving from problem perception phase to problem formulation phase as a consequence see section 2 2 specifically the trade off can be resolved either by seeking additional information required to implement or by altering the problem perception to suit the information available the precise process of achieving a trade off is not well understood and a variety of approaches and intermediate solutions may be possible fu guillaume and jakeman 2015 fig 2 together with tables 3 7 in section 3 provide a framework in support of model development in the interest of fostering transparency in the trade off process around decision making and option selection during these two distinct phases of optimization model development 2 1 data collection the proposed framework see tables 3 7 in section 3 for assessing scale within optimization modelling to support e flows was developed through a detailed review of existing literature that applied optimization in this context we analysed existing literature and the options presented for each modelling element in the framework fig 2 the targeted spatial and temporal scales and the assets considered data collection for the analysis was carried out by performing a literature search the focus was set on studies that applied optimization of water diversion or impoundment to environmental water management decisions while meeting human water needs at different spatial and temporal scales keyword combinations were used in the web of science search engine i e multi objective optimization multi criteria optimization optimization environmental flows e flows to generate the initial set of literature the collected studies were filtered for water management and the final selection was based on the criterion that they had to address both ecological and societal water use studies were excluded mainly due to their character e g framework review or because of the study objective e g focused on land use in a few cases studies focusing only on a single objective function but considering both needs i e ecological and anthropogenic have been included in the analysis due to their compliance with the aim of the review and to stimulate discussion a final collection of 27 case studies applying optimization procedures at different targeted scales was analysed see references in table a1 in the annex the overall objective of the review process was to highlight existing decisions and options for each phase of model development and to feed into the guidance framework for scale implications of modelling decisions 2 2 definitions of scales in multi objective optimization procedures for water management defining comprehensible scales and their consistent use is still a key issue in systems modelling iwanaga et al 2021 the interdisciplinary nature of water resource management exacerbates this with different spatial and temporal boundaries related to the multiple aspects of water management i e administrative hydrologic management etc moss and newig 2010 daniell and barreteau 2014 gleeson and paszkowski 2014 as policy decisions can be defined based on model outputs dabiri and blaschke 2019 distinguished between the policy and the modelling scales and associated the latter with the dimension at which the data is acquired or derived and in strict connection with the mathematical expression similarly moss and newig 2010 distinguish the hydrological and the political scales as central dimensions for water management modelling on the other hand in landscape ecology scales are usually associated with patch extent or duration and grain or resolution withers and meentemeyer 1999 most studies related to socio environmental modelling consider the extent and resolution to define spatial and temporal scales moss and newig 2010 daniell and barreteau 2014 gleeson and paszkowski 2014 dabiri and blaschke 2019 iwanaga et al 2021 both spatial and temporal scale resolution is linked with data grain size or cell size represent the smallest features of the spatial scale particularly if the modelling is spatially explicit while time steps represent the levels of the temporal scale e g hours days in this study we consider these notions to define spatial and temporal scales for optimization modelling for water management see box 1 studies optimizing water management usually indicate the targeted area for the assessment table 2 shows the spatial scale definitions we retrieved from the analysed studies for each we provided a description of the features of the considered scales while these definitions were linked with the focused assessment area and thus presumably belong to the problem perception phase we found an ambiguity in the use of the terms sub basin multi reach and river section scale in fact they seem to be used interchangeably and possibly relate to modeller s understanding of the system however this seems to be in accordance with the conclusions of gleeson and paszkowski 2014 who found that hydrological scales definitions are not used consistently among researchers we use the definitions provided in table 2 as mean of comparison throughout the paper 3 lessons from the literature scales in multi objective optimization procedures for water management environmental water management problems in regulated rivers can represent different issues related to the delivery of e flows for example e flows can be incorporated into an existing operational plan or infrastructure operation can be modified to reduce flow alteration see table 1 in section 2 modelling these management problems requires the definition of the targeted area and the available information during the problem perception phase section 3 1 and the selection of the modelling approach in the problem formulation phase section 3 2 both phases are exposed to scale issues related with the data resolution the temporal horizon for the operation plan and spatial boundaries of the system box 2 and box 3 describe two example case studies in the following sections we elaborate on the framework by drawing on the considered literature to discuss the different stages within each phase with the aim of understanding the trade offs between the management problem scales and the modelling problem scales 3 1 problem perception phase 3 1 1 physical system the concept of system is expanded in water management to include the geographical temporal and the socio economic setting of the applied optimization procedure the physical system can be defined in terms of the spatial area including that involved in the generation of the water flow and the structural limits of the studied facility e g a reservoir and the temporal window of effect fig 3 illustrates systematically the spatial and temporal scales that interest water management problems and highlights some of the major factors that have scale implications based on the reviewed papers the definition of spatial area and temporal window of effect provides the physical temporal target reference for the following problem formulation phase here we split the decision related to physical system perception into multiple decisions related to the flow alteration infrastructure the type and number of flow altering infrastructures and its operations the definition of environmental assets and the definition of the management horizon see table 3 temporal scales tend to be fairly well defined by flow alteration type impoundment diversions the management horizon and the points of interest and hence spatial scale points of interest include flow altering infrastructure which affects how that infrastructure is operated as well as e flow target locations e g river reaches environmental assets optimization assessments are developed to reflect operational schemes of impoundment and diversion structures at a range of management horizons considering all the resulting options related to the planning horizon the selected facilities and the spatial range of their impact inevitably leads to a series of possible context infrastructure combinations in this case system conceptualization benefits from the visualization of connections between assets especially in large highly regulated river systems as in transboundary river basins e g schlüter et al 2005 martin et al 2017 such visualization enables the definition of points where water movement is related to different causes e g supply inflow storage expressed as point sources e g tributaries releasing points e g dams hydraulic structures and gauging stations facilitating optimization procedure development the wide variety of possible network configurations means that the targeted hydrological scale can range spatially from reach or river sections e g mullick babel and perret 2013 fleifle et al 2014 to sub basins and multi reach systems e g xevi and khan 2005 shiau and wu 2013 or an entire basin e g suen and eheart 2006 shiau and chou 2016 the consideration of the number of assets and their location as well as the scale of effect influences the final size of the spatial domain fig 4 illustrates the different targeted assessment scales as emerged from the analysed studies a key challenge in the problem formulation phase is articulating the target for environmental outcomes environmental assets can include not only in river values but also attributes of wetlands and floodplains e g szemis maier and dandy 2012 2014 szemis dandy and maier 2013 the environmental objective can be represented in several ways for example as the provision of habitat or as the provision of ecosystem services this clear articulation of environmental outcomes as opposed to hydrological indicators has been more evident in australian case studies and management contexts it is acknowledged that this need to define a priori the targeted environmental assets during the optimization model procedure is a significant challenge however it represents good practice for system definition lastly management context decisions relate to operational horizon or release schedules infrastructure operational horizon can be tailored both at sub daily or daily scale as this supports the identification of the best option based on hourly flows or how much water is to be allocated the management horizon should also be consistent with the frequency of need to update the management plan we identified studies using management horizon that were monthly seasonal single and multi year when targeting single or multi year management horizon water releases are assessed for different single years differentiating by wet normal dry allowing to implement the best releases or abstraction operations based on the yearly hydrological conditions type e g steinschneider et al 2014 chen and olden 2017 dai et al 2017 lewis and randall 2017 policy testing could require the definition of multiple alternative management horizons conception of alternative legislative contexts can consider the prioritization of different combinations of objectives e g shiau and wu 2013 3 1 2 management objectives the definition of optimization objectives reflects a range of management objectives or goals that can then be assessed for compromises in water allocations or other water release variables see table 4 there is a range of different formulations of system objectives e g maximization satisfaction of consumptive demand or minimization of shortfalls optimization of structural performance the maximization of economic benefit or minimization of the hydrological disturbance the way the objectives are expressed is linked to the spatial extent but can reflect end user needs for example the need for controlling floods is more pressing at the basin scale and can be managed by considering the difference between inflows and outflows e g porse sandoval solis and lane 2015 shiau and chou 2016 studies aiming at maximizing water supply seek to ensure water supply maintenance over time by adjusting to flow fluctuation rather than aiming to abstract the greatest possible amount of water at a single time step the operational scheme of the facility i e impoundment or diversion affects the approach for the definition of supply reliability targeted reservoir releases for downstream ecological needs are sought in the case of impoundment in such cases water collection represents the prioritized supply method for human use and optimization objectives aim to maximize the collection capacity of the reservoir water abstraction optimization on the other hand focuses on the withdrawal of water from the flowing river e g diversion an alternative for assessments targeting large basins that encompass several abstraction points is to define a supply objective for each abstraction point in the considered system before defining the cumulative objective hydropower generation objectives are typically considered for assessments targeting reservoir e g shiau and wu 2013 wang et al 2015 fallah mehdipour bozorg haddad and loáiciga 2018 or basin scales e g paredes arquiola et al 2013 shiau and chou 2016 hassanjabbar saghafian and jamali 2018 hydropower production optimization objectives require the consideration of infrastructure operations and the infrastructure capacity in energy generation when optimization objectives are focused on the economic aspect of hydropower generation from a reservoir metrics such as net benefit or revenues are considered definition of environmental objectives within the optimization procedure is connected to the environmental water management decisions see section 2 and usually considers the natural hydrograph or specific water volumes for ecological processes compliance of the regulated hydrograph with the natural discharge is based on the consideration of the natural flow regime as a pristine hydrological reference acreman 2016 despite increasing awareness of the need to advance the natural flow regime paradigm whether or not species can adapt or are already adapted to flow alteration caused by man made infrastructures e g dams remains difficult to assess and needs an expanded e flow science foundation poff 2018 this leaves the natural flow regime alteration reduction as the easiest choice for many optimization assessments wang et al 2015 moreover this approach does not explicitly prioritize specific species over others as in the ecological flow regime paradigm e g suen and eheart 2006 within the optimization procedure gauge data at reference points can set the target conditions of the ideal flow regime e g torabi haghighi and kløve 2015 shiau and chou 2016 for example minimized the differences between the monthly flow hydrograph and the monthly discharge similarly schlüter et al 2005 minimized water flow changes across several intake points however the use of gauge data should be based on appropriate considerations regarding the location of the gauging station and the river section it is related to e g drainage area or length of river segment as this could affect the resulting scale of the assessment as alternative to real flow data and to the flow alteration reduction approach simple algorithms such as those in the global environmental flow calculator gefc can rapidly calculate e flow requirements for the main rivers worldwide e g hassanjabbar saghafian and jamali 2018 this information can be then used within the optimization problem for developing targeted releases or designer flows the designer flows approach is gaining momentum for preservation of river ecosystems poff and olden 2017 and has been embraced for example by chen and olden 2017 to prioritize native over non native species in regulated rivers 3 1 3 limiting conditions decisions about the range of limiting conditions to consider for the targeted assessment system can be distinguished based on their nature 1 physical environmental conditions which refer to the environmental status of the system e g conservation of mass 2 supply related linked to the magnitude timing and type of demand 3 infrastructure related that are influenced by the design or operational capacity of the flow modification structure e g dam hydropower plant and 4 regulative which are defined based on policies or normative requirements see table 4 physical environmental limiting conditions reflect a certain environmental availability of water within the considered system and are usually described using a water balance equation or hydrological model our analysis showed that physical environmental limitations are directly linked to the scale of the assessment the location of the facility i e dam reservoir hydropower plant and weir within the assessed area e g basin sub basin reach influences the definition of the reference flow conditions and the number of inflow points the targeted scale of the assessment is physically defined by the input location receiving the flow and an output location releasing the flow following the course of the river continuity equations are often used to capture and assure the balance between the inflows and the outflows e g xu et al 2017 hassanjabbar saghafian and jamali 2018 the definition of the continuity equation requires the consideration of the dynamics of inflows hence of both location and timing for example the water quantity in a reservoir dam at a certain point in time that depends on the considered timescale is a function of the water contained in the reservoir dam at the previous time step e g day hour and of the outflow and inflow water quantity at the current time step e g chen and olden 2017 the water budget within a reservoir also needs to account for losses due to evaporation e g porse sandoval solis and lane 2015 this is particularly relevant if the system is exposed to severe temperature fluctuations dry conditions flows to and from groundwater systems and the hyporheic zone may also be relevant limiting conditions can also reflect water or energy delivery requirements to meet sectoral needs e g domestic industrial agricultural infrastructure operations optimization requires consideration of structural limitations on infrastructure capacity and releases the number of infrastructure facilities and their management influences required scale and the corresponding constraints minimum maximum reservoir storage capacity or in and outflow volumes are frequently implemented for water impoundment management for example to avoid reservoir wall overtopping this suits a daily or sub daily scale optimization through the definition of the minimum and maximum allowable volume fluctuations e g chen and olden 2017 with respect to demand magnitude and risk of downstream bankfull flows or floods e g xu et al 2017 water use agreements treaty stipulations and legal water rights can appear as limiting conditions depending on how the river network intersects with national or other jurisdictional borders e g porse sandoval solis and lane 2015 wang et al 2015 quality standards e g for irrigation drinking water are also common 3 2 problem formulation phase 3 2 1 hydrological state and indicators the decisions within the problem formulation phase specifically account for model data and computational limitations contrasting with the ideal problem perception that stakeholders might prefer in absence of these limitations in this phase the definition of environmental water requirements establishes limits to the modification of water flows we identified a series of crucial decisions related to the setting of environmental water requirements the consideration of the preferred e flow assessment approach the inventory of the available sources of information environmental water requirements establishment and the location of the gauging stations and selection of the hydrological metric see table 5 for summary environmental water requirements definition through empirical estimation of e flow ranges is an option at finer scales e g reach and on short term planning e g seasonal when direct data e g species habitat level data is accessible these ranges reflect hydrological or habitat needs e g mullick babel and perret 2013 of key species and can be defined through hydro ecological models or regression techniques for example regression based approaches to define fish flow relationships for native and non native species preferences e g chen and olden 2017 or by using the physical habitat simulation models e g phabsim bovee et al 1998 to retrieve minimum e flows requirements for phenological stages e g shang 2015 mixed assessment approaches are more complex to implement as exploit multi disciplinary instruments based on collaborative interactions between scientists management analysts and stakeholders e g porse sandoval solis and lane 2015 once the preferred approach is identified multiple methods can be applied to obtain the necessary eco hydrological information literature review and experts involvement in the definition of water requirements for targeted species can be used for modelling and optimization of spatially complex systems e g involving non linear relationships and multiple predictors as alternatives to massive data collection participatory workshops to set hydrological thresholds are underpinned by knowledge coming from different sources e g paredes arquiola et al 2013 xevi and khan 2005 possibly measured at different scales in different locations and hence require a more careful statement of the final scale of applicability of the assessment another option is the use of existing e flow calculation software packages see section 3 1 2 however the modelling process can affect the spatial and temporal resolution of their output data and thus the final scale boundaries to define the reference hydrological conditions and the monitoring of the targeted environmental assets historical and actual data from gauging stations are used potentially with hydrological model simulations flow data includes inflow data to reservoirs or dams when studies focus on optimizing release timing e g shiau and wu 2013 whilst the number and location of gauging stations vary based on the study site type and the general purpose of the assessment observations from gauging stations located downstream of the reservoir are useful for the assessment of water release alterations in single e g yin yang and petts 2012 or multiple reservoirs in series e g dai et al 2017 moreover analyses for multiple reaches benefit from a sound gauging station network at the rivers and their tributaries as they enable the analysis of the variability of historical flows e g fleifle et al 2014 while optimizing reservoir or dam series requires reporting or modelling of dam outflows e g yin yang and petts 2012 shiau and wu 2013 our analysis showed that among the considered flow components flow magnitude class parameters are widely used as hydrological indicators of ecosystem health within optimization studies as they reflect conditions that shape habitat availability and suitability for species richter et al 1996 poff and zimmerman 2010 rolls leigh and sheldon 2012 rolls and bond 2017 measures of the magnitude of monthly and annual flow conditions e g median value of the mean monthly flow minimum monthly flow are used to describe the prevailing behaviour of the flow across the year or uncover major hydro climatic cycles among different years e g average yearly flow but are unable to deliver sufficient information of local characteristics e g reach level behaviour in this case disaggregating of monthly average flows into site specific minimum monthly flows allows the consideration of the hydrological spatial variability at a sub regional scale e g paredes arquiola et al 2013 the water impoundment planning horizon e g wang et al 2015 or the characterization of a multi reach system s behaviour e g shiau and wu 2013 can drive the choice of the selection of indicators defining the timespan and intensity in water flows e g for low flow conditions similarly baseflow indicators often subdivided into wet dry and extreme baseflow are linked to reservoir outflow or diversion scheduling e g yin yang and petts 2012 yin yang and liu 2014 yin et al 2015 dai et al 2017 water quality indicators i e temperature dissolved compounds oxygen are less frequently considered when addressing environmental flows problems e g fleifle et al 2014 xu et al 2017 nevertheless these indicators are usually associated to the flow parameters to the extent of being affected by changes in the regime 3 2 2 objective functions and decision variables the previous problem perception phase creates the conditions for the translation of assessment objectives into objective functions the general optimization problem is defined by the equation f x that we seek to minimize or maximize in which x is the decision variable in question or vector of decision variables in addition to deriving from the management objective objective functions can differ considerably depending on data availability and the type of flow alteration type e g run of river hydropower storage based power generation see table 6 selection of optimization objectives remains highly dependent on analyst choice and revolves around two main options on one hand a higher number of objectives i e more than one can favour a more comprehensive representation of the system while promoting an increased understanding of existing trade offs on the other hand due to the structure of the applied technique the optimization of multiple objectives is often hampered by limited computational capacity or difficult visualization of complex results lautenbach et al 2013 despite the existence of optimization tools able to model a higher number of objectives see reed et al 2013 studies tend to keep the number of simultaneous objectives low e g 4 as well as considering few decision variables see section 3 2 4 in this case the assignment of different weights to decision variables e g schlüter et al 2005 xevi and khan 2005 or the judicious use of constraints can reflect a range of stakeholders preferences or policy decisions while at the same time reducing the computational effort further discussion on the number of objectives is presented in section 3 2 3 and 3 2 4 the availability of exact and updated water consumption data for the targeted infrastructure can be challenging to obtain expressing water supply objectives as the minimization of shortage indices e g long term total shortage ratio mean annual deficit duration maximum 1 day shortage ratio allows the indirect consideration of demand by relying on daily reservoir releases shiau and wu 2013 finer scale representation of water supply objectives e g water demand type at river network nodes i e intake points e g schlüter et al 2005 allows a more refined optimization for complex reach systems an alternative approach uses a composite function e g an index composed of different indicators for water use purposes such as domestic industrial and agriculture supply e g suen and eheart 2006 shares of abstracted water can sometimes be retrieved from regional and local databases which may need to be downscaled or extrapolated to areas of interest the most straightforward way to optimize power production is through the maximization of water releases or available water volume for hydropower generation e g arslan 2015 xu et al 2017 or inversely by minimizing the gap between generated hydropower and the installed capacity during operational periods e g fallah mehdipour bozorg haddad and loáiciga 2018 yin et al 2015 for instance aimed at maximizing the mean annual revenue of hydropower generation concerning specific degrees of flow regime alteration likewise economic objectives can be also set for studies targeting irrigation water demand e g xevi and khan 2005 lewis and randall 2017 in section 3 2 1 we discussed hydrological indicators used to define ecological needs here we present ways to employ those indicators within the optimization model environmental outcomes can be directly used as objective functions in fact e flows objectives within the optimization problem are commonly expressed as specific share of incoming flow usually expressed as volume that reflect environmental requirements e g arslan 2015 xu et al 2017 at the scale of river sections habitat level data availability allows optimizing specific river flow conditions for the benefit of target species chen and olden 2017 depending on the targeted ecological endpoint data collection and hence function definition can be more or less straightforward to perform reduction of the proportional deficit between a prescribed point diversion and the river regime e g chen and olden 2017 suits assessments of finer scale hydrological systems such as rivers and river sections this also applies for assessments at reservoir scale aiming at ensuring continuity between water inflows and outflows e g yin yang and petts 2012 shiau and wu 2013 steinschneider et al 2014 lastly the fitness of certain solutions to the objective function for the environmental water requirements can be conceptualized based on the assumptions of the analyst in relation to ecological response functions fu and guillaume 2014 for example suen and eheart 2006 considered the intermediate disturbance hypothesis assumption as basis for the definition of the fitness function for six eco hydrological indicators to maintain the livelihood of aquatic ecosystems 3 2 3 constraint functions the general objective function presented in section 3 2 1 is usually subject to some constraints in the general case f x is subject to g x 0 in which g x represents the constraint function constraint functions can significantly influence the optimization outcomes allowing the output of more realistic results with respect to the considered system scale and other factors strauch et al 2019 in mathematical optimization approaches whereas they commonly represent decision maker preferences rather than physical laws in simulation based optimization clarkin et al 2018 for the general definition of constraints and their effect on the objective function see coello et al 2007 constraint definition can be a modelling intensive phase if the system considers a high number of input points diversion points and facilities if data used in the optimization problem is not yet spatially explicit i e georeferenced spatial boundaries are usually represented by considering intake and outtake points location while consumptive requirements can also be set as objectives e g by defining a minimization function aiming at minimizing the gap between the target consumptive amount and the optimized amount the translation of consumptive requirements into constraint functions requires knowledge of the nature of demand stable demands over time are easily expressed by estimating an amount of water that captures all the possible consumptive uses in the considered system however this choice will be more suitable for short time frames or long term averages for example management plans for maintaining the native ecological communities in river sections chen and olden 2017 alternatively differentiating among demand types by setting a minimum water supply ratio can ensure compliance of reservoir operation with specific supply objectives for example for irrigation purposes e g wang et al 2015 on the other hand a series of unpredictable factors e g climate social behaviour and daily patterns can also make the demand level uncertain in this case defining a reliable quantity of stored water for consumptive use or energy generation allows satisfying fluctuating needs over a longer period in this case a minimum storage constraint or supply reliability constraint may be used the latter in the case of municipal supply can be also considered as objective depending on the problem structure e g yin yang and petts 2012 hydropower plant optimization objectives are frequently constrained by capacity thresholds limiting the range of decision variables such as the control gate operations turbine release ramping power tunnel and grid capacities defining power output limitations e g steinschneider et al 2014 dai et al 2017 optimization process related constraints have the purpose of facilitating the search phase by setting specific conditions that will influence the fitness value based on the degree of violation e g dai et al 2017 penalty functions are an example of constraint handling techniques where a constraint function is transformed into a penalty that is directly added to the objective function coello lamont and veldhuizen 2007 ruhul masoud and yao 2012 for example penalties can be set based on the frequency of falling outside of the target range for each e flow parameter e g wang et al 2015 however the values of the penalties should not be set to very large values to avoid interfering with the identification of the ideal fitness values dai et al 2017 lastly constraints can also reflect additional objectives thus reducing the number of objectives e g to a single objective e g torabi haghighi and kløve 2015 wang et al 2015 but this does not necessarily mean that problem size would be reduced conversely constraints can also be turned into objectives thus increasing their number and eventually leading to many objective problems however kasprzyk et al 2016 in their study of many objective problems for water management showed that a higher number of objectives can be paradoxically easier to solve 3 2 4 solution methods how a water allocation optimization problem is addressed across the different scales depends on its overall complexity there is no direct relationship between scale and solution method as too many factors influence the selection of one technique over another moreover problems can be approached with different degrees of complexity even if the considered assessment scale is fine e g a single facility however since water allocation optimization is based on the mathematical conceptualization of the problem e g linear nonlinear discrete and continuous knowledge about differences in solution approaches can contribute to the understanding of possible solving strategies for the considered scale system based on components e g indicator types for objectives nature for constraints to illustrate the decision about the solution method we distinguish between deterministic or mathematical programming and meta heuristic optimization our analysis showed that oftentimes water allocation problems are formulated as multidimensional convex objective functions constrained by a series of rules since constraints influence the geometry of the feasible solution space the solution can be found through the process of eliminating problem variables cavazzuti 2013 for example linear programming based algorithms have been used for solving broad scale optimization problems of system types involving dams and large reservoirs showing a convexity both in the objective function and in the constraint functions e g xevi and khan 2005 steinschneider et al 2014 porse sandoval solis and lane 2015 chen and olden 2017 problems envisaging variables with a high degree of nonlinearity e g evapotranspiration soil infiltration can be solved by elimination based nonlinear programming algorithms e g schlüter et al 2005 arslan 2015 in the case of broad scale optimization problems considering quadratic equations envisaging the relationship between streamflow and net economic benefit sequential quadratic programming can iteratively search for the optimal solution e g mullick babel and perret 2013 when continuous function variables show discrete or integer values mixed integer linear programming is preferred instead wang et al 2015 used this technique to optimize large scale reservoir operations carrying a binary value in the reservoir outflow parameter metaheuristic optimization algorithms can handle problems characterized by a high number of objectives coello lamont and veldhuizen 2007 maier et al 2019 this could be the case of multi purpose or multi reach optimization problems as a sub group of metaheuristics evolutionary algorithms provide good chances of approximating a globally optimal solution quite rapidly shahin 2008 cavazzuti 2013 by generating initial random sets of variables and then by exploiting operators such as selection mutation and cross over to produce better solutions at each generation for example fleifle et al 2014 solved the minimization problem for the wastewater treatment costs and maximized water quality in a river section evolutionary techniques such as the non sorted genetic algorithm nsga are commonly applied for handling both basin and multi reach scale optimization problems e g suen and eheart 2006 dai et al 2017 martin et al 2017 xu et al 2017 3 2 5 optimization scenarios the definition of optimization scenarios is included in the problem formulation phase as it relates closely to the practicalities of providing useful information in the face of data model and computational limitations in principle a given problem formulation would ideally have a general solution but in practice it needs to be embedded in a specific context and multiple variants of problem formulations may be possible the context represents both environmental operational and management conditions scenarios hence provide the opportunity to assess alternatives based on system behaviour under possible circumstances e g on the effects of different release schemes on hydrological variability or seasonal conditions on planned abstractions this could contribute to reduce uncertainty about a specific management decision or to explore potential management decisions under a range of operational ecological and hydrological conditions for example lewis and randall 2017 considered dry normal and wet hydrological conditions porse et al 2015 considered different e flow allocation targets to assess the trade off with water supply wang et al 2015 formulated scenarios representing combinations of objectives and constraints while the reliability of optimization outcomes can be also linked with robustness and accuracy of output data it also depends on prior knowledge about the considered system which is itself based on the overall system understanding sanchis martínez and blasco 2008 this means that some degree of conceptual bias arises from our lack of understanding of relationships between components the size and type of investigated system influences the scenarios that have to be evaluated because different needs and thus ways to think objectives can exist within that system domain for example if the system is large e g river basin sub basin multiple needs often need to be addressed due to the presence of different social groups and economic activities policy requirements e g porse sandoval solis and lane 2015 or just the presence of multiple abstraction points e g paredes arquiola et al 2013 scenarios can be expressed differently for single facility systems at the reservoir scale alternatives could be represented by the compromises between the amount of released and impounded water flow concerning natural flow variability or e flow requirements scenarios depicting trade offs between a series of off stream e g irrigation and instream benefits e g fishery can be assessed with and without e flows as a constraint mullick babel and perret 2013 to promote the incorporation of e flows within a water management plan 4 discussion 4 1 need for clarity of problem definition complex environmental water allocation problems can be optimized for a range of regulated system types e g river basins reservoirs reaches hydropower plants considering conflicting water management objectives i e aquatic ecosystems livelihood and human supply overall the definition of system scales and conceptualization within optimization procedures reflects a well known problem oriented perspective on the river system van den belt and blake 2015 opperman et al 2018 intended to meet the functions required for management purposes and therefore requiring transparent documentation of the management problem the availability of optimization models that can be applied simultaneously to multiple scales is still limited studies would rather formulate the problem for one target area at a time hence the applicability of an optimization framework is generally only suitable to the specific case study or systems with similar relevant features e g the presence of a hydropower generator e g yin yang and liu 2014 in general this results in a limited reproducibility of a scale specific optimization assessment for environmental water management which could hinder the interpretation of results by decision makers this review and the resulting framework therefore highlight the need both for clear problem definition and efforts to develop the tools necessary to address multi scale problems as defined 4 2 need for strategies to implement desired assessment scales the size i e temporal and spatial scale of the assessment is intrinsically connected with the range of information needed for the development of the optimization procedure optimization of large systems e g basins transboundary rivers and long planning horizons e g multi year planning requires more complex decision making about suitable options as information could be nested and hence more challenging to obtain problems involving larger systems may be divided into smaller components by subdividing the system into shorter time frames or sub areas this operation when possible may reduce both computational and modelling effort conversely smaller systems e g river sections reaches modelling require less difficult option selection but could still be as challenging as more demanding solution approaches e g modelling ability might be needed however mismatches between the scales of involved factors e g management scale hydrological scale during modelling are frequent as scales are defined based on different needs i e administrative modelling overall this can compound the difficulty of defining absolute assessment scales because of the many factors involved see fig 3 section 3 it may be hence more appropriate to speak of the targeted system boundaries rather than scales more generally van den belt and blake 2015 moreover improved knowledge of the system connections i e river system at the basin scale would also be helpful to better understand the effects of local scale flow regulation structures this is especially meaningful if the final aim is to balance water needs as part of a wider system i e basin shiau and wu 2013 4 3 need to make explicit trade offs in model development decisions and option selection during optimization problem definition are usually nonlinear with respect to targeted assessment scales as some trade offs in data availability and modelling requirements need to be accounted for this is due to the fact that the relationship between scale and available options is not one to one the development of optimization procedures to solve water management problems requires the simultaneous consideration of multiple factors to representatively recreate the real context or system the targeted scale from the management perspective e g basin on which a certain environmental goal applies e g good ecological status the number of involved infrastructures and their location the location of gauging and monitoring stations within the management area and the possibility for the considered system to cross geopolitical borders whilst the use of simulation data e g synthetic hydrograph can address the problem of input hydrological information the main challenge for model development remains and revolves around the need to gather sufficient information to be able to represent the targeted system or to adapt the assessment scale to the data available i e reducing the problem size into smaller problems or nested systems failing to clearly describe the optimization problem context e g physical system management horizon and objectives reduces the understanding of how to represent trade offs and results in a less transparent treatment of scale and therefore the ability to model across scales 4 4 need for increased modelling capacity solving water management optimization problems at different scales presents some challenges in relation to the nature of the decision variables the increasing number of objectives and the nature of the functions reed et al 2013 whilst the fact that initial accessible information i e in the problem perception phase linking flows infrastructure operations and environmental outcomes is not readily available in a format suited to optimization horne et al 2016 a major impediment is represented by limited modelling capacity when dealing with complex real world problems this could drive to over simplification and thus reduced reliability in optimization outcomes on the one hand a solution to over simplification could be the use of more sophisticated algorithms able to deal with a higher number of objectives as many objective optimization algorithms are able to deal with up to 15 objectives chand and wagner 2015 though this would inevitably lead to increase in needed computational effort on the other hand consideration of the more appropriate approach i e robust or evolutionary based on the temporal horizon of the problem e g infrastructure scheduling management planning could reduce the overall uncertainty as it would account for the level of decision making incorporation grossmann et al 2016 lastly improving the flexibility in optimization problem structure e g by finding a benchmark model structure to be applicable for different scales e g shiau and wu 2013 could help discover nested trade offs within the same study system or similar systems thus by fostering comparison 5 outlook and recommendations using optimization procedures in water management the need for stating clearer reference boundaries in study descriptions has already been identified by gleeson and paszkowski 2014 we consider this even more significant for optimization problems particularly concerning decision making transparency throughout model development around the final assessment scales clear definition of targeted and modelled spatial and temporal scales within optimization procedures for environmental water allocation could support the identification of potential minimum thresholds i e scale at which e flow management should be implemented however this process requires an increased understanding of how modelling limitations relate to option selection we believe that unravelling the relationship between existing options between the problem formulation phase and the modelling phase provides a useful pathway for improving the take up of results at the right management level and increasing our ability to model across scales the first step in this process would be clear communication of the optimization problem statement throughout the two phases see section 5 1 this may also include discussion of how the problem design can be altered to increase understandability which can also improve the understanding of system trade offs seppelt lautenbach and volk 2013 5 1 towards increased transparency recommendations for optimization problem development the framework provided in section 3 mapped the crucial decisions and options related to each phase of model development the problem perception phase and the problem formulation phase and the implications for the temporal and spatial scales of each stage in this section by building on the aforementioned framework we propose recommendations for model development under the form of essential questions that need to be addressed this questionnaire presented in table 8 assists system conceptualization and serves to check information availability by doing so it supports clarity in problem translation from the problem formulation to the modelling phase we believe that making the role of information availability explicit throughout model development will support system understanding and further foster transparency around the trade off process in model development and system scale representation when defining an optimization model for water management problems 6 conclusions this review paper analysed the implications of decisions and related options throughout the optimization model development stages for the final temporal and spatial scale of the assessment we first explored the main decisions that have to be made by distinguishing two distinct phases in optimization problem development problem perception and problem formulation we found that most decisions have strong links with the spatial and temporal scales of the assessment that need to be accounted for successively we mapped options related to each decision i e related to the physical system assessment objectives the hydrological state and indicators objective and constraint functions solution methods and optimization scenario and provided scale specific considerations for option selection overall given that water management problems involve a large number of factors to consider e g operations schemes supply competition changing environmental conditions the decision making supported by optimization techniques is influenced by a series of challenges related to data availability and modelling capability this consequently affects decision making about options which resolves in tailoring the optimization model to the available data and modelling ability retrieving additional data required or subdividing the problem further research focused on clarifying the underlying influences between options concerning scale would provide an enhanced insight into the relationship between options and improve the process of option selection besides it would enable the integration of instruments that can improve reliability and comparability in optimization outcomes moreover while exploring how trade offs across scales are incorporated into the optimization process is more challenging for the application of optimization algorithms it is also potentially most useful to an environmental water manager as a foundation for these goals we provided recommendations for model development by focusing on key questions related to each decision with the intent of fostering transparency around decision making and options selection during both problem development phases declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this paper is an output from the euro flow project which received funding from the european union s horizon 2020 research and innovation programme under the marie skłodowska curie grant agreement no 765553 joseph guillaume received funding from an australian research council discovery early career researcher award project no de190100317 avril horne received funding from australian research council discovery early career researcher award project no de180100550 the authors would like to thank the editor and the three anonymous reviewers for suggesting substantial improvements to the manuscript annex table a1 summary of reviewed studies legend no info mp mathematical programming s stochastic mag d magnitude of daily and sub daily flows mag m magnitude of monthly and yearly flows mag dur ext magnitude and duration of extreme water conditions freq dur pulses frequency and duration of high and low pulses tim timing of annual extreme water conditions nh non hydrologic indicator g graph t table df designer flows pf pareto front continuing on the next pages table a1 reference study system location management purpose targeted scale planning period solution method hydrological indicators objectives constraints trade offs scenarios spatial temporal 3 4 arslan 2015 aksu river basin turkey energy production ecological health river sub daily mp based mag m physical environmental infrastructure related supply related ecological x chen and olden 2017 san juan river colorado river tributary us disturbance reduction ecological health river section seasonal 3 year plan mp based mag d physical environmental infrastructure related supply related g x dai et al 2017 three gorges gezhouba reservoirs yangtze river china energy production ecological health multi reservoir seasonal s mag d physical environmental infrastructure related g x fallah mehdipour bozorg haddad and loáiciga 2018 karoon iv dam on karoon river iran energy production ecological health reservoir daily mp based s physical environmental infrastructure related g fleifle et al 2014 el qalaa river nile river egypt functional purpose ecological health sub basin seasonal s nh physical environmental supply related ecological g torabi haghighi and kløve 2015 bakhtegan catchment iran disturbance reduction river basin monthly intra annual mp based mag m supply related ecological g x hassanjabbar saghafian and jamali 2018 karkheh basin iran iraq border energy production disturbance reduction multi reservoir monthly annual s mag d mag dur ext freq dur pulses physical environmental infrastructure related supply related x lewis and randall 2017 murrumbidgee river irrigation area australia functional purpose ecological health river basin monthly annual s mag m physical environmental infrastructure related supply related ecological g x martin et al 2017 goulburn broken river catchment murray darling basin australia functional purpose sub basin daily s mag m g mullick babel and perret 2013 teesta river bangladesh functional purpose river section monthly annual mp based mag m physical environmental ecological t x paredes arquiola et al 2013 duero river basin spain consumptive use ecological health river basin monthly annual mag m supply related g porse sandoval solis and lane 2015 luis l leon reservoir big bend region of the rio grande bravo mexico us ecological health reservoir monthly mp based mag d mag m freq dur pulses physical environmental infrastructure related supply related df schlüter et al 2005 amudarya river basin central asia consumptive use disturbance reduction multi reach monthly annual mp based mag m physical environmental infrastructure related supply related ecological x shang 2015 ertix river ebinur lake xinjiang china consumptive use ecological health river section lake monthly mp based mag m infrastructure related g shiau and chou 2016 hsintien creek taiwan consumptive use energy production safety disturbance reduction river basin daily s mag m mag dur ext nh physical environmental infrastructure related t x shiau and wu 2013 feitsui reservoir taiwan consumptive use energy production safety disturbance reduction multi reach multi reservoir sub daily annual multi annual s mag d mag dur ext rat freq change physical environmental infrastructure related g x szemis et al 2012 murray darlingriver australia reservoir monthly multi annual s mag d freq dur pulses physical environmental infrastructure related df x szemis et al 2013 murray darlingriver australia reservoir monthly multi annual s mag d freq dur pulses physical environmental infrastructure related df x szemis et al 2014 murray darlingriver australia reservoir monthly multi annual s mag d freq dur pulses physical environmental infrastructure related df x steinschneider et al 2014 connecticut river new england us disturbance reduction river basin daily annual mp based mag d mag m physical environmental infrastructure related supply related ecological pf x suen and eheart 2006 dahan river basin taiwan consumptive use energy production ecological health river basin monthly s freq dur pulses tim ext physical environmental infrastructure related pf wang et al 2015 philpott dam on smith river us consumptive use energy production disturbance reduction reservoir daily monthly mp based mag m mag dur ext physical environmental infrastructure related supply related process based g x xevi and khan 2005 berembed weir murrumbidgee river australia consumptive use multi reach monthly seasonal mp based mag m physical environmental infrastructure related ecological t x xu et al 2017 han river yangtze river tributary china consumptive use energy production disturbance reduction ecological health river daily s nh physical environmental infrastructure related supply related ecological df yin yang and petts 2012 tanghe reservoir on the tang river china disturbance reduction reservoir daily annual s mag d freq dur pulses rat freq change physical environmental supply related df yin yang and liu 2014 wangkuai reservoir hai river basin china disturbance reduction reservoir monthly annual s mag d freq dur pulses physical environmental infrastructure related supply related process based df x yin et al 2015 wangkuai reservoir hai river basin china energy production reservoir monthly annual s mag d infrastructure related supply related ecological g t 
25845,a key issue in optimization model development is the selection of spatial and temporal scale representing the system this study proposes a framework for reasoning about scale in this context drawing on a review of studies applying multi objective optimization for water management involving environmental flows we suggest that scale is determined by the management problem constrained by data availability computational and model capabilities there is therefore an inherent trade off between problem perception and available modelling capability which can either be resolved by obtaining data needed or tailoring analysis to the data available in the interest of fostering transparency in this trade off process this paper outlines phases of model development associated decisions and available options and scale implications of each decision the problem perception phase collects system information about objectives limiting conditions and management options the problem formulation phase collects and uses data information and methods about system structure and behaviour graphical abstract image 1 keywords multi scale analysis environmental flows multi objective optimization water management trade off analysis 1 introduction water management is challenged by socio economic e g rising demand sectoral competition and climate change pressures e g droughts extreme events eea 2017 grizzetti et al 2017 tonkin et al 2019 threatening water security kennen stein and webb 2018 and river biodiversity vörösmarty et al 2010 despite increasing awareness of river ecosystems needs arthington et al 2018 water allocation goals typically still aim to provide water to people when and where they most need it and not when and where it would naturally be available daniell and barreteau 2014 however addressing the challenges of climate change and increasing demand will require a range of strategic actions including those that directly protect and restore the environment pittock and lankford 2010 thompson et al 2014 liu liu and yang 2016 salik et al 2016 failing to adequately incorporate ecosystem values and underestimating the potential cross scale impacts of water use and climate change on freshwater ecosystems mccluney et al 2014 fails to acknowledge the benefits that freshwater systems generate for the wider community richter 2009 the implementation of environmental flows is one action that is already applied mendoza and martins 2006 le quesne kendy and weston 2010 poff et al 2010 king et al 2015 horne o donnell and tharme 2017 to better protect freshwater and related ecosystems from modifications caused by river regulation e g dams weirs diversion channels poff et al 1997 arthington 2012 and high intensity use eea 2012 the approach to implementing environmental flows and the accompanying water management decisions varies according to governance level spatial extent and temporal scale of the desired outcome broad scale long term environmental flows e flows management typically employs a top down approach by imposing limits to additional hydrological alteration e g caps on water abstraction license conditions for water users environmental water rights see horne et al 2018 whereas a bottom up strategy e g conditions on storage operators environmental reserve established legally that considers ecologically relevant components of the flow regime and their ranges is implemented at finer scales and generally prioritizes short term effects pahl wostl et al 2013 gopal 2016 horne webb et al 2017 current incorporation of e flows within integrated water resource management iwrm expresses environmental water requirements as quantity quality and timing of water flows in the short term at point scale to limit impact propagation towards broader spatial scales in the long term vörösmarty et al 2013 evers 2016 arthington et al 2018 as a consequence water governance seeks to implement enhanced management and infrastructure systems that can regulate river flow at multiple spatial and or temporal levels daniell and barreteau 2014 stewardson et al 2017 in the light of changing consumptive water needs scale specific investigation tools are often used to inform successful river management volk et al 2008 case study level applications show that some management problems envisage several objectives and hence multi objective optimization can be used to address water management needs at different spatial scales such as hydropower facility reservoir reach sub basin and basin and different temporal horizons e g shang 2015 yin et al 2015 fallah mehdipour bozorg haddad and loáiciga 2018 the optimization of a set of desired objectives related to water abstraction or release e g species survival hydropower production domestic supply irrigation seeks to find optimal solutions these solutions are searched across a range of criteria that allow the identification of trade offs and synergies and as a result the definition of compromises among conflicting goals horne et al 2016 cord et al 2017 gunantara 2018 the opportunity to explore compromise solutions might better support decision making processes than single objective modelling as it has been shown in other resource allocation problems e g lautenbach et al 2013 kaya et al 2016 kaim et al 2018 however modelling these decisions in water management is made challenging by the fragmentation and hierarchy of hydrological scales moss and newig 2010 a key obstacle is related to the consideration of the different scale specific hydrological and ecological characteristics and processes volk and ewert 2011 davies et al 2014 thorp 2014 indeed the effective representation of connections e g ecological hydrological and geomorphological on each temporal and spatial scale of the river network remains a core challenge in e flow assessments poff tharme and arthington 2017 another problem is related to the reference hydrological scales used in the classification of river spatial extent the spatial mismatch between physical and socio political boundaries poses a challenge for the definition and implementation of management objectives moss and newig 2010 daniell and barreteau 2014 van den belt and blake 2015 opperman et al 2018 lastly chosen e flow parameters can be employed for studies at small scales and can show effects in the short term e g population size but can also be ecologically relevant for wider areas e g basin scale and support processes that manifest at longer temporal scales e g nutrient cycling poff tharme and arthington 2017 this requires the consideration of a range of flow events e g pulses 30 day minimum flow and diverse processes e g water production sediment delivery and vegetation dynamics ecological stages land cover influence gurnell et al 2016 opperman et al 2018 in this study we present a framework that describes the conceptual and operational steps of optimization model development to support e flows and the related spatial and temporal scale considerations the framework draws on a review of the state of art in this field of water research clarity about the role of scale improves our ability to model across scales and as a consequence provide more reliable predictions of decision outcomes at the scales of interest the paper first introduces water management decisions and their translation into optimization models see box 1 for the definition of terms and provides the outline of the proposed framework showing the stages of optimization problem development i e problem perception phase and problem formulation phase section 2 the framework mapping the scale related decisions and options linked to each development phase is further described with reference to results from the review of selected studies in section 3 section 4 discusses the need for clarity of problem definition strategies to implement desired assessment scales and explicit discussion of trade offs in problem development lastly in section 5 we provide recommendations to foster transparency throughout the optimization problem development phases 2 a framework for incorporating scale within optimization modelling to support e flows water management decisions an optimization approach offers the opportunity to explore compromise solutions to support decisions about scarce water resources horne et al 2016 it can be used to support environmental water management decisions while meeting conflicting water use objectives e g hydropower generation domestic supply industrial supply irrigation water environmental water objectives drive management actions that can be implemented at broader e g control of diversion or finer target scales e g need to control reservoir releases the timeframe of implementation also varies based on the management decision water resources management and in particular e flows sit within an adaptive management framework that reflects these different temporal and spatial scales webb et al 2017 the selection of objectives and high level policy decisions are made at a longer time scale and often for larger catchments or whole basins see horne and konrad 2017 however implementation decisions are made at a shorter time scale and often for a specific site or location optimization to support these decisions therefore also lends itself to be framed within an adaptive management framework providing the structure and technical capacity to support trade offs and decision making at different scales fig 1 each stage of the adaptive management cycle has its own technical challenges similarly the translation of management decisions into an optimization procedure needs to consider a range of factors to ensure the context and system is realistically represented table 1 uses a number of examples to demonstrate the importance of the type of management approach being considered the columns in table 1 for informing the approach to optimization model development for instance the decision to set a cap on abstraction can be tied to optimization at basin scale considering an annual or seasonal time frame the optimization of release timing at seasonal monthly or daily scale in response to the need to meet downstream ecological needs target ecological indicators will be preferred for management decisions at smaller spatial scales e g reaches or sub basins to match species ecological response timeframes and local hydrological conditions at sub daily scale it could be applied to reduce hydropeaking impacts at target locations the specific decision context dictates the target scales however translation of real world management problems into a modelling framework presents some inherent challenges either related to data availability modelling or computational ability the water management analyst dealing with optimization model development hence faces a range of trade offs in model representation in particular linked with choices of scale associated with the targeted problem and resulting modelled representation any optimization model development procedure to support e flows decisions and water resource management will need to explicitly consider the implication and magnitude of these trade offs for the spatial and temporal scales of the assessment to foster transparency and understandability a general optimization process showed in fig 2 left hand side first involves problem identification or contextualization and subsequently requires input parameters definition and optimization environment creation see maier et al 2014 for in depth overview as a first step the system domain is defined by the water management problem and decisions which underpin the relevant objectives constraints and scenarios of the targeted spatial and temporal scales of assessment fig 2 right hand side once defined the system characteristics hydrological data and other relevant information e g ecological are gathered to meet the requirements for representation at the targeted scales given that optimization assessments need to inform a decision making process hence the output the final scales of the assessment should appropriately match decision conditions and scales trade offs in system representation arise when moving from problem perception phase to problem formulation phase as a consequence see section 2 2 specifically the trade off can be resolved either by seeking additional information required to implement or by altering the problem perception to suit the information available the precise process of achieving a trade off is not well understood and a variety of approaches and intermediate solutions may be possible fu guillaume and jakeman 2015 fig 2 together with tables 3 7 in section 3 provide a framework in support of model development in the interest of fostering transparency in the trade off process around decision making and option selection during these two distinct phases of optimization model development 2 1 data collection the proposed framework see tables 3 7 in section 3 for assessing scale within optimization modelling to support e flows was developed through a detailed review of existing literature that applied optimization in this context we analysed existing literature and the options presented for each modelling element in the framework fig 2 the targeted spatial and temporal scales and the assets considered data collection for the analysis was carried out by performing a literature search the focus was set on studies that applied optimization of water diversion or impoundment to environmental water management decisions while meeting human water needs at different spatial and temporal scales keyword combinations were used in the web of science search engine i e multi objective optimization multi criteria optimization optimization environmental flows e flows to generate the initial set of literature the collected studies were filtered for water management and the final selection was based on the criterion that they had to address both ecological and societal water use studies were excluded mainly due to their character e g framework review or because of the study objective e g focused on land use in a few cases studies focusing only on a single objective function but considering both needs i e ecological and anthropogenic have been included in the analysis due to their compliance with the aim of the review and to stimulate discussion a final collection of 27 case studies applying optimization procedures at different targeted scales was analysed see references in table a1 in the annex the overall objective of the review process was to highlight existing decisions and options for each phase of model development and to feed into the guidance framework for scale implications of modelling decisions 2 2 definitions of scales in multi objective optimization procedures for water management defining comprehensible scales and their consistent use is still a key issue in systems modelling iwanaga et al 2021 the interdisciplinary nature of water resource management exacerbates this with different spatial and temporal boundaries related to the multiple aspects of water management i e administrative hydrologic management etc moss and newig 2010 daniell and barreteau 2014 gleeson and paszkowski 2014 as policy decisions can be defined based on model outputs dabiri and blaschke 2019 distinguished between the policy and the modelling scales and associated the latter with the dimension at which the data is acquired or derived and in strict connection with the mathematical expression similarly moss and newig 2010 distinguish the hydrological and the political scales as central dimensions for water management modelling on the other hand in landscape ecology scales are usually associated with patch extent or duration and grain or resolution withers and meentemeyer 1999 most studies related to socio environmental modelling consider the extent and resolution to define spatial and temporal scales moss and newig 2010 daniell and barreteau 2014 gleeson and paszkowski 2014 dabiri and blaschke 2019 iwanaga et al 2021 both spatial and temporal scale resolution is linked with data grain size or cell size represent the smallest features of the spatial scale particularly if the modelling is spatially explicit while time steps represent the levels of the temporal scale e g hours days in this study we consider these notions to define spatial and temporal scales for optimization modelling for water management see box 1 studies optimizing water management usually indicate the targeted area for the assessment table 2 shows the spatial scale definitions we retrieved from the analysed studies for each we provided a description of the features of the considered scales while these definitions were linked with the focused assessment area and thus presumably belong to the problem perception phase we found an ambiguity in the use of the terms sub basin multi reach and river section scale in fact they seem to be used interchangeably and possibly relate to modeller s understanding of the system however this seems to be in accordance with the conclusions of gleeson and paszkowski 2014 who found that hydrological scales definitions are not used consistently among researchers we use the definitions provided in table 2 as mean of comparison throughout the paper 3 lessons from the literature scales in multi objective optimization procedures for water management environmental water management problems in regulated rivers can represent different issues related to the delivery of e flows for example e flows can be incorporated into an existing operational plan or infrastructure operation can be modified to reduce flow alteration see table 1 in section 2 modelling these management problems requires the definition of the targeted area and the available information during the problem perception phase section 3 1 and the selection of the modelling approach in the problem formulation phase section 3 2 both phases are exposed to scale issues related with the data resolution the temporal horizon for the operation plan and spatial boundaries of the system box 2 and box 3 describe two example case studies in the following sections we elaborate on the framework by drawing on the considered literature to discuss the different stages within each phase with the aim of understanding the trade offs between the management problem scales and the modelling problem scales 3 1 problem perception phase 3 1 1 physical system the concept of system is expanded in water management to include the geographical temporal and the socio economic setting of the applied optimization procedure the physical system can be defined in terms of the spatial area including that involved in the generation of the water flow and the structural limits of the studied facility e g a reservoir and the temporal window of effect fig 3 illustrates systematically the spatial and temporal scales that interest water management problems and highlights some of the major factors that have scale implications based on the reviewed papers the definition of spatial area and temporal window of effect provides the physical temporal target reference for the following problem formulation phase here we split the decision related to physical system perception into multiple decisions related to the flow alteration infrastructure the type and number of flow altering infrastructures and its operations the definition of environmental assets and the definition of the management horizon see table 3 temporal scales tend to be fairly well defined by flow alteration type impoundment diversions the management horizon and the points of interest and hence spatial scale points of interest include flow altering infrastructure which affects how that infrastructure is operated as well as e flow target locations e g river reaches environmental assets optimization assessments are developed to reflect operational schemes of impoundment and diversion structures at a range of management horizons considering all the resulting options related to the planning horizon the selected facilities and the spatial range of their impact inevitably leads to a series of possible context infrastructure combinations in this case system conceptualization benefits from the visualization of connections between assets especially in large highly regulated river systems as in transboundary river basins e g schlüter et al 2005 martin et al 2017 such visualization enables the definition of points where water movement is related to different causes e g supply inflow storage expressed as point sources e g tributaries releasing points e g dams hydraulic structures and gauging stations facilitating optimization procedure development the wide variety of possible network configurations means that the targeted hydrological scale can range spatially from reach or river sections e g mullick babel and perret 2013 fleifle et al 2014 to sub basins and multi reach systems e g xevi and khan 2005 shiau and wu 2013 or an entire basin e g suen and eheart 2006 shiau and chou 2016 the consideration of the number of assets and their location as well as the scale of effect influences the final size of the spatial domain fig 4 illustrates the different targeted assessment scales as emerged from the analysed studies a key challenge in the problem formulation phase is articulating the target for environmental outcomes environmental assets can include not only in river values but also attributes of wetlands and floodplains e g szemis maier and dandy 2012 2014 szemis dandy and maier 2013 the environmental objective can be represented in several ways for example as the provision of habitat or as the provision of ecosystem services this clear articulation of environmental outcomes as opposed to hydrological indicators has been more evident in australian case studies and management contexts it is acknowledged that this need to define a priori the targeted environmental assets during the optimization model procedure is a significant challenge however it represents good practice for system definition lastly management context decisions relate to operational horizon or release schedules infrastructure operational horizon can be tailored both at sub daily or daily scale as this supports the identification of the best option based on hourly flows or how much water is to be allocated the management horizon should also be consistent with the frequency of need to update the management plan we identified studies using management horizon that were monthly seasonal single and multi year when targeting single or multi year management horizon water releases are assessed for different single years differentiating by wet normal dry allowing to implement the best releases or abstraction operations based on the yearly hydrological conditions type e g steinschneider et al 2014 chen and olden 2017 dai et al 2017 lewis and randall 2017 policy testing could require the definition of multiple alternative management horizons conception of alternative legislative contexts can consider the prioritization of different combinations of objectives e g shiau and wu 2013 3 1 2 management objectives the definition of optimization objectives reflects a range of management objectives or goals that can then be assessed for compromises in water allocations or other water release variables see table 4 there is a range of different formulations of system objectives e g maximization satisfaction of consumptive demand or minimization of shortfalls optimization of structural performance the maximization of economic benefit or minimization of the hydrological disturbance the way the objectives are expressed is linked to the spatial extent but can reflect end user needs for example the need for controlling floods is more pressing at the basin scale and can be managed by considering the difference between inflows and outflows e g porse sandoval solis and lane 2015 shiau and chou 2016 studies aiming at maximizing water supply seek to ensure water supply maintenance over time by adjusting to flow fluctuation rather than aiming to abstract the greatest possible amount of water at a single time step the operational scheme of the facility i e impoundment or diversion affects the approach for the definition of supply reliability targeted reservoir releases for downstream ecological needs are sought in the case of impoundment in such cases water collection represents the prioritized supply method for human use and optimization objectives aim to maximize the collection capacity of the reservoir water abstraction optimization on the other hand focuses on the withdrawal of water from the flowing river e g diversion an alternative for assessments targeting large basins that encompass several abstraction points is to define a supply objective for each abstraction point in the considered system before defining the cumulative objective hydropower generation objectives are typically considered for assessments targeting reservoir e g shiau and wu 2013 wang et al 2015 fallah mehdipour bozorg haddad and loáiciga 2018 or basin scales e g paredes arquiola et al 2013 shiau and chou 2016 hassanjabbar saghafian and jamali 2018 hydropower production optimization objectives require the consideration of infrastructure operations and the infrastructure capacity in energy generation when optimization objectives are focused on the economic aspect of hydropower generation from a reservoir metrics such as net benefit or revenues are considered definition of environmental objectives within the optimization procedure is connected to the environmental water management decisions see section 2 and usually considers the natural hydrograph or specific water volumes for ecological processes compliance of the regulated hydrograph with the natural discharge is based on the consideration of the natural flow regime as a pristine hydrological reference acreman 2016 despite increasing awareness of the need to advance the natural flow regime paradigm whether or not species can adapt or are already adapted to flow alteration caused by man made infrastructures e g dams remains difficult to assess and needs an expanded e flow science foundation poff 2018 this leaves the natural flow regime alteration reduction as the easiest choice for many optimization assessments wang et al 2015 moreover this approach does not explicitly prioritize specific species over others as in the ecological flow regime paradigm e g suen and eheart 2006 within the optimization procedure gauge data at reference points can set the target conditions of the ideal flow regime e g torabi haghighi and kløve 2015 shiau and chou 2016 for example minimized the differences between the monthly flow hydrograph and the monthly discharge similarly schlüter et al 2005 minimized water flow changes across several intake points however the use of gauge data should be based on appropriate considerations regarding the location of the gauging station and the river section it is related to e g drainage area or length of river segment as this could affect the resulting scale of the assessment as alternative to real flow data and to the flow alteration reduction approach simple algorithms such as those in the global environmental flow calculator gefc can rapidly calculate e flow requirements for the main rivers worldwide e g hassanjabbar saghafian and jamali 2018 this information can be then used within the optimization problem for developing targeted releases or designer flows the designer flows approach is gaining momentum for preservation of river ecosystems poff and olden 2017 and has been embraced for example by chen and olden 2017 to prioritize native over non native species in regulated rivers 3 1 3 limiting conditions decisions about the range of limiting conditions to consider for the targeted assessment system can be distinguished based on their nature 1 physical environmental conditions which refer to the environmental status of the system e g conservation of mass 2 supply related linked to the magnitude timing and type of demand 3 infrastructure related that are influenced by the design or operational capacity of the flow modification structure e g dam hydropower plant and 4 regulative which are defined based on policies or normative requirements see table 4 physical environmental limiting conditions reflect a certain environmental availability of water within the considered system and are usually described using a water balance equation or hydrological model our analysis showed that physical environmental limitations are directly linked to the scale of the assessment the location of the facility i e dam reservoir hydropower plant and weir within the assessed area e g basin sub basin reach influences the definition of the reference flow conditions and the number of inflow points the targeted scale of the assessment is physically defined by the input location receiving the flow and an output location releasing the flow following the course of the river continuity equations are often used to capture and assure the balance between the inflows and the outflows e g xu et al 2017 hassanjabbar saghafian and jamali 2018 the definition of the continuity equation requires the consideration of the dynamics of inflows hence of both location and timing for example the water quantity in a reservoir dam at a certain point in time that depends on the considered timescale is a function of the water contained in the reservoir dam at the previous time step e g day hour and of the outflow and inflow water quantity at the current time step e g chen and olden 2017 the water budget within a reservoir also needs to account for losses due to evaporation e g porse sandoval solis and lane 2015 this is particularly relevant if the system is exposed to severe temperature fluctuations dry conditions flows to and from groundwater systems and the hyporheic zone may also be relevant limiting conditions can also reflect water or energy delivery requirements to meet sectoral needs e g domestic industrial agricultural infrastructure operations optimization requires consideration of structural limitations on infrastructure capacity and releases the number of infrastructure facilities and their management influences required scale and the corresponding constraints minimum maximum reservoir storage capacity or in and outflow volumes are frequently implemented for water impoundment management for example to avoid reservoir wall overtopping this suits a daily or sub daily scale optimization through the definition of the minimum and maximum allowable volume fluctuations e g chen and olden 2017 with respect to demand magnitude and risk of downstream bankfull flows or floods e g xu et al 2017 water use agreements treaty stipulations and legal water rights can appear as limiting conditions depending on how the river network intersects with national or other jurisdictional borders e g porse sandoval solis and lane 2015 wang et al 2015 quality standards e g for irrigation drinking water are also common 3 2 problem formulation phase 3 2 1 hydrological state and indicators the decisions within the problem formulation phase specifically account for model data and computational limitations contrasting with the ideal problem perception that stakeholders might prefer in absence of these limitations in this phase the definition of environmental water requirements establishes limits to the modification of water flows we identified a series of crucial decisions related to the setting of environmental water requirements the consideration of the preferred e flow assessment approach the inventory of the available sources of information environmental water requirements establishment and the location of the gauging stations and selection of the hydrological metric see table 5 for summary environmental water requirements definition through empirical estimation of e flow ranges is an option at finer scales e g reach and on short term planning e g seasonal when direct data e g species habitat level data is accessible these ranges reflect hydrological or habitat needs e g mullick babel and perret 2013 of key species and can be defined through hydro ecological models or regression techniques for example regression based approaches to define fish flow relationships for native and non native species preferences e g chen and olden 2017 or by using the physical habitat simulation models e g phabsim bovee et al 1998 to retrieve minimum e flows requirements for phenological stages e g shang 2015 mixed assessment approaches are more complex to implement as exploit multi disciplinary instruments based on collaborative interactions between scientists management analysts and stakeholders e g porse sandoval solis and lane 2015 once the preferred approach is identified multiple methods can be applied to obtain the necessary eco hydrological information literature review and experts involvement in the definition of water requirements for targeted species can be used for modelling and optimization of spatially complex systems e g involving non linear relationships and multiple predictors as alternatives to massive data collection participatory workshops to set hydrological thresholds are underpinned by knowledge coming from different sources e g paredes arquiola et al 2013 xevi and khan 2005 possibly measured at different scales in different locations and hence require a more careful statement of the final scale of applicability of the assessment another option is the use of existing e flow calculation software packages see section 3 1 2 however the modelling process can affect the spatial and temporal resolution of their output data and thus the final scale boundaries to define the reference hydrological conditions and the monitoring of the targeted environmental assets historical and actual data from gauging stations are used potentially with hydrological model simulations flow data includes inflow data to reservoirs or dams when studies focus on optimizing release timing e g shiau and wu 2013 whilst the number and location of gauging stations vary based on the study site type and the general purpose of the assessment observations from gauging stations located downstream of the reservoir are useful for the assessment of water release alterations in single e g yin yang and petts 2012 or multiple reservoirs in series e g dai et al 2017 moreover analyses for multiple reaches benefit from a sound gauging station network at the rivers and their tributaries as they enable the analysis of the variability of historical flows e g fleifle et al 2014 while optimizing reservoir or dam series requires reporting or modelling of dam outflows e g yin yang and petts 2012 shiau and wu 2013 our analysis showed that among the considered flow components flow magnitude class parameters are widely used as hydrological indicators of ecosystem health within optimization studies as they reflect conditions that shape habitat availability and suitability for species richter et al 1996 poff and zimmerman 2010 rolls leigh and sheldon 2012 rolls and bond 2017 measures of the magnitude of monthly and annual flow conditions e g median value of the mean monthly flow minimum monthly flow are used to describe the prevailing behaviour of the flow across the year or uncover major hydro climatic cycles among different years e g average yearly flow but are unable to deliver sufficient information of local characteristics e g reach level behaviour in this case disaggregating of monthly average flows into site specific minimum monthly flows allows the consideration of the hydrological spatial variability at a sub regional scale e g paredes arquiola et al 2013 the water impoundment planning horizon e g wang et al 2015 or the characterization of a multi reach system s behaviour e g shiau and wu 2013 can drive the choice of the selection of indicators defining the timespan and intensity in water flows e g for low flow conditions similarly baseflow indicators often subdivided into wet dry and extreme baseflow are linked to reservoir outflow or diversion scheduling e g yin yang and petts 2012 yin yang and liu 2014 yin et al 2015 dai et al 2017 water quality indicators i e temperature dissolved compounds oxygen are less frequently considered when addressing environmental flows problems e g fleifle et al 2014 xu et al 2017 nevertheless these indicators are usually associated to the flow parameters to the extent of being affected by changes in the regime 3 2 2 objective functions and decision variables the previous problem perception phase creates the conditions for the translation of assessment objectives into objective functions the general optimization problem is defined by the equation f x that we seek to minimize or maximize in which x is the decision variable in question or vector of decision variables in addition to deriving from the management objective objective functions can differ considerably depending on data availability and the type of flow alteration type e g run of river hydropower storage based power generation see table 6 selection of optimization objectives remains highly dependent on analyst choice and revolves around two main options on one hand a higher number of objectives i e more than one can favour a more comprehensive representation of the system while promoting an increased understanding of existing trade offs on the other hand due to the structure of the applied technique the optimization of multiple objectives is often hampered by limited computational capacity or difficult visualization of complex results lautenbach et al 2013 despite the existence of optimization tools able to model a higher number of objectives see reed et al 2013 studies tend to keep the number of simultaneous objectives low e g 4 as well as considering few decision variables see section 3 2 4 in this case the assignment of different weights to decision variables e g schlüter et al 2005 xevi and khan 2005 or the judicious use of constraints can reflect a range of stakeholders preferences or policy decisions while at the same time reducing the computational effort further discussion on the number of objectives is presented in section 3 2 3 and 3 2 4 the availability of exact and updated water consumption data for the targeted infrastructure can be challenging to obtain expressing water supply objectives as the minimization of shortage indices e g long term total shortage ratio mean annual deficit duration maximum 1 day shortage ratio allows the indirect consideration of demand by relying on daily reservoir releases shiau and wu 2013 finer scale representation of water supply objectives e g water demand type at river network nodes i e intake points e g schlüter et al 2005 allows a more refined optimization for complex reach systems an alternative approach uses a composite function e g an index composed of different indicators for water use purposes such as domestic industrial and agriculture supply e g suen and eheart 2006 shares of abstracted water can sometimes be retrieved from regional and local databases which may need to be downscaled or extrapolated to areas of interest the most straightforward way to optimize power production is through the maximization of water releases or available water volume for hydropower generation e g arslan 2015 xu et al 2017 or inversely by minimizing the gap between generated hydropower and the installed capacity during operational periods e g fallah mehdipour bozorg haddad and loáiciga 2018 yin et al 2015 for instance aimed at maximizing the mean annual revenue of hydropower generation concerning specific degrees of flow regime alteration likewise economic objectives can be also set for studies targeting irrigation water demand e g xevi and khan 2005 lewis and randall 2017 in section 3 2 1 we discussed hydrological indicators used to define ecological needs here we present ways to employ those indicators within the optimization model environmental outcomes can be directly used as objective functions in fact e flows objectives within the optimization problem are commonly expressed as specific share of incoming flow usually expressed as volume that reflect environmental requirements e g arslan 2015 xu et al 2017 at the scale of river sections habitat level data availability allows optimizing specific river flow conditions for the benefit of target species chen and olden 2017 depending on the targeted ecological endpoint data collection and hence function definition can be more or less straightforward to perform reduction of the proportional deficit between a prescribed point diversion and the river regime e g chen and olden 2017 suits assessments of finer scale hydrological systems such as rivers and river sections this also applies for assessments at reservoir scale aiming at ensuring continuity between water inflows and outflows e g yin yang and petts 2012 shiau and wu 2013 steinschneider et al 2014 lastly the fitness of certain solutions to the objective function for the environmental water requirements can be conceptualized based on the assumptions of the analyst in relation to ecological response functions fu and guillaume 2014 for example suen and eheart 2006 considered the intermediate disturbance hypothesis assumption as basis for the definition of the fitness function for six eco hydrological indicators to maintain the livelihood of aquatic ecosystems 3 2 3 constraint functions the general objective function presented in section 3 2 1 is usually subject to some constraints in the general case f x is subject to g x 0 in which g x represents the constraint function constraint functions can significantly influence the optimization outcomes allowing the output of more realistic results with respect to the considered system scale and other factors strauch et al 2019 in mathematical optimization approaches whereas they commonly represent decision maker preferences rather than physical laws in simulation based optimization clarkin et al 2018 for the general definition of constraints and their effect on the objective function see coello et al 2007 constraint definition can be a modelling intensive phase if the system considers a high number of input points diversion points and facilities if data used in the optimization problem is not yet spatially explicit i e georeferenced spatial boundaries are usually represented by considering intake and outtake points location while consumptive requirements can also be set as objectives e g by defining a minimization function aiming at minimizing the gap between the target consumptive amount and the optimized amount the translation of consumptive requirements into constraint functions requires knowledge of the nature of demand stable demands over time are easily expressed by estimating an amount of water that captures all the possible consumptive uses in the considered system however this choice will be more suitable for short time frames or long term averages for example management plans for maintaining the native ecological communities in river sections chen and olden 2017 alternatively differentiating among demand types by setting a minimum water supply ratio can ensure compliance of reservoir operation with specific supply objectives for example for irrigation purposes e g wang et al 2015 on the other hand a series of unpredictable factors e g climate social behaviour and daily patterns can also make the demand level uncertain in this case defining a reliable quantity of stored water for consumptive use or energy generation allows satisfying fluctuating needs over a longer period in this case a minimum storage constraint or supply reliability constraint may be used the latter in the case of municipal supply can be also considered as objective depending on the problem structure e g yin yang and petts 2012 hydropower plant optimization objectives are frequently constrained by capacity thresholds limiting the range of decision variables such as the control gate operations turbine release ramping power tunnel and grid capacities defining power output limitations e g steinschneider et al 2014 dai et al 2017 optimization process related constraints have the purpose of facilitating the search phase by setting specific conditions that will influence the fitness value based on the degree of violation e g dai et al 2017 penalty functions are an example of constraint handling techniques where a constraint function is transformed into a penalty that is directly added to the objective function coello lamont and veldhuizen 2007 ruhul masoud and yao 2012 for example penalties can be set based on the frequency of falling outside of the target range for each e flow parameter e g wang et al 2015 however the values of the penalties should not be set to very large values to avoid interfering with the identification of the ideal fitness values dai et al 2017 lastly constraints can also reflect additional objectives thus reducing the number of objectives e g to a single objective e g torabi haghighi and kløve 2015 wang et al 2015 but this does not necessarily mean that problem size would be reduced conversely constraints can also be turned into objectives thus increasing their number and eventually leading to many objective problems however kasprzyk et al 2016 in their study of many objective problems for water management showed that a higher number of objectives can be paradoxically easier to solve 3 2 4 solution methods how a water allocation optimization problem is addressed across the different scales depends on its overall complexity there is no direct relationship between scale and solution method as too many factors influence the selection of one technique over another moreover problems can be approached with different degrees of complexity even if the considered assessment scale is fine e g a single facility however since water allocation optimization is based on the mathematical conceptualization of the problem e g linear nonlinear discrete and continuous knowledge about differences in solution approaches can contribute to the understanding of possible solving strategies for the considered scale system based on components e g indicator types for objectives nature for constraints to illustrate the decision about the solution method we distinguish between deterministic or mathematical programming and meta heuristic optimization our analysis showed that oftentimes water allocation problems are formulated as multidimensional convex objective functions constrained by a series of rules since constraints influence the geometry of the feasible solution space the solution can be found through the process of eliminating problem variables cavazzuti 2013 for example linear programming based algorithms have been used for solving broad scale optimization problems of system types involving dams and large reservoirs showing a convexity both in the objective function and in the constraint functions e g xevi and khan 2005 steinschneider et al 2014 porse sandoval solis and lane 2015 chen and olden 2017 problems envisaging variables with a high degree of nonlinearity e g evapotranspiration soil infiltration can be solved by elimination based nonlinear programming algorithms e g schlüter et al 2005 arslan 2015 in the case of broad scale optimization problems considering quadratic equations envisaging the relationship between streamflow and net economic benefit sequential quadratic programming can iteratively search for the optimal solution e g mullick babel and perret 2013 when continuous function variables show discrete or integer values mixed integer linear programming is preferred instead wang et al 2015 used this technique to optimize large scale reservoir operations carrying a binary value in the reservoir outflow parameter metaheuristic optimization algorithms can handle problems characterized by a high number of objectives coello lamont and veldhuizen 2007 maier et al 2019 this could be the case of multi purpose or multi reach optimization problems as a sub group of metaheuristics evolutionary algorithms provide good chances of approximating a globally optimal solution quite rapidly shahin 2008 cavazzuti 2013 by generating initial random sets of variables and then by exploiting operators such as selection mutation and cross over to produce better solutions at each generation for example fleifle et al 2014 solved the minimization problem for the wastewater treatment costs and maximized water quality in a river section evolutionary techniques such as the non sorted genetic algorithm nsga are commonly applied for handling both basin and multi reach scale optimization problems e g suen and eheart 2006 dai et al 2017 martin et al 2017 xu et al 2017 3 2 5 optimization scenarios the definition of optimization scenarios is included in the problem formulation phase as it relates closely to the practicalities of providing useful information in the face of data model and computational limitations in principle a given problem formulation would ideally have a general solution but in practice it needs to be embedded in a specific context and multiple variants of problem formulations may be possible the context represents both environmental operational and management conditions scenarios hence provide the opportunity to assess alternatives based on system behaviour under possible circumstances e g on the effects of different release schemes on hydrological variability or seasonal conditions on planned abstractions this could contribute to reduce uncertainty about a specific management decision or to explore potential management decisions under a range of operational ecological and hydrological conditions for example lewis and randall 2017 considered dry normal and wet hydrological conditions porse et al 2015 considered different e flow allocation targets to assess the trade off with water supply wang et al 2015 formulated scenarios representing combinations of objectives and constraints while the reliability of optimization outcomes can be also linked with robustness and accuracy of output data it also depends on prior knowledge about the considered system which is itself based on the overall system understanding sanchis martínez and blasco 2008 this means that some degree of conceptual bias arises from our lack of understanding of relationships between components the size and type of investigated system influences the scenarios that have to be evaluated because different needs and thus ways to think objectives can exist within that system domain for example if the system is large e g river basin sub basin multiple needs often need to be addressed due to the presence of different social groups and economic activities policy requirements e g porse sandoval solis and lane 2015 or just the presence of multiple abstraction points e g paredes arquiola et al 2013 scenarios can be expressed differently for single facility systems at the reservoir scale alternatives could be represented by the compromises between the amount of released and impounded water flow concerning natural flow variability or e flow requirements scenarios depicting trade offs between a series of off stream e g irrigation and instream benefits e g fishery can be assessed with and without e flows as a constraint mullick babel and perret 2013 to promote the incorporation of e flows within a water management plan 4 discussion 4 1 need for clarity of problem definition complex environmental water allocation problems can be optimized for a range of regulated system types e g river basins reservoirs reaches hydropower plants considering conflicting water management objectives i e aquatic ecosystems livelihood and human supply overall the definition of system scales and conceptualization within optimization procedures reflects a well known problem oriented perspective on the river system van den belt and blake 2015 opperman et al 2018 intended to meet the functions required for management purposes and therefore requiring transparent documentation of the management problem the availability of optimization models that can be applied simultaneously to multiple scales is still limited studies would rather formulate the problem for one target area at a time hence the applicability of an optimization framework is generally only suitable to the specific case study or systems with similar relevant features e g the presence of a hydropower generator e g yin yang and liu 2014 in general this results in a limited reproducibility of a scale specific optimization assessment for environmental water management which could hinder the interpretation of results by decision makers this review and the resulting framework therefore highlight the need both for clear problem definition and efforts to develop the tools necessary to address multi scale problems as defined 4 2 need for strategies to implement desired assessment scales the size i e temporal and spatial scale of the assessment is intrinsically connected with the range of information needed for the development of the optimization procedure optimization of large systems e g basins transboundary rivers and long planning horizons e g multi year planning requires more complex decision making about suitable options as information could be nested and hence more challenging to obtain problems involving larger systems may be divided into smaller components by subdividing the system into shorter time frames or sub areas this operation when possible may reduce both computational and modelling effort conversely smaller systems e g river sections reaches modelling require less difficult option selection but could still be as challenging as more demanding solution approaches e g modelling ability might be needed however mismatches between the scales of involved factors e g management scale hydrological scale during modelling are frequent as scales are defined based on different needs i e administrative modelling overall this can compound the difficulty of defining absolute assessment scales because of the many factors involved see fig 3 section 3 it may be hence more appropriate to speak of the targeted system boundaries rather than scales more generally van den belt and blake 2015 moreover improved knowledge of the system connections i e river system at the basin scale would also be helpful to better understand the effects of local scale flow regulation structures this is especially meaningful if the final aim is to balance water needs as part of a wider system i e basin shiau and wu 2013 4 3 need to make explicit trade offs in model development decisions and option selection during optimization problem definition are usually nonlinear with respect to targeted assessment scales as some trade offs in data availability and modelling requirements need to be accounted for this is due to the fact that the relationship between scale and available options is not one to one the development of optimization procedures to solve water management problems requires the simultaneous consideration of multiple factors to representatively recreate the real context or system the targeted scale from the management perspective e g basin on which a certain environmental goal applies e g good ecological status the number of involved infrastructures and their location the location of gauging and monitoring stations within the management area and the possibility for the considered system to cross geopolitical borders whilst the use of simulation data e g synthetic hydrograph can address the problem of input hydrological information the main challenge for model development remains and revolves around the need to gather sufficient information to be able to represent the targeted system or to adapt the assessment scale to the data available i e reducing the problem size into smaller problems or nested systems failing to clearly describe the optimization problem context e g physical system management horizon and objectives reduces the understanding of how to represent trade offs and results in a less transparent treatment of scale and therefore the ability to model across scales 4 4 need for increased modelling capacity solving water management optimization problems at different scales presents some challenges in relation to the nature of the decision variables the increasing number of objectives and the nature of the functions reed et al 2013 whilst the fact that initial accessible information i e in the problem perception phase linking flows infrastructure operations and environmental outcomes is not readily available in a format suited to optimization horne et al 2016 a major impediment is represented by limited modelling capacity when dealing with complex real world problems this could drive to over simplification and thus reduced reliability in optimization outcomes on the one hand a solution to over simplification could be the use of more sophisticated algorithms able to deal with a higher number of objectives as many objective optimization algorithms are able to deal with up to 15 objectives chand and wagner 2015 though this would inevitably lead to increase in needed computational effort on the other hand consideration of the more appropriate approach i e robust or evolutionary based on the temporal horizon of the problem e g infrastructure scheduling management planning could reduce the overall uncertainty as it would account for the level of decision making incorporation grossmann et al 2016 lastly improving the flexibility in optimization problem structure e g by finding a benchmark model structure to be applicable for different scales e g shiau and wu 2013 could help discover nested trade offs within the same study system or similar systems thus by fostering comparison 5 outlook and recommendations using optimization procedures in water management the need for stating clearer reference boundaries in study descriptions has already been identified by gleeson and paszkowski 2014 we consider this even more significant for optimization problems particularly concerning decision making transparency throughout model development around the final assessment scales clear definition of targeted and modelled spatial and temporal scales within optimization procedures for environmental water allocation could support the identification of potential minimum thresholds i e scale at which e flow management should be implemented however this process requires an increased understanding of how modelling limitations relate to option selection we believe that unravelling the relationship between existing options between the problem formulation phase and the modelling phase provides a useful pathway for improving the take up of results at the right management level and increasing our ability to model across scales the first step in this process would be clear communication of the optimization problem statement throughout the two phases see section 5 1 this may also include discussion of how the problem design can be altered to increase understandability which can also improve the understanding of system trade offs seppelt lautenbach and volk 2013 5 1 towards increased transparency recommendations for optimization problem development the framework provided in section 3 mapped the crucial decisions and options related to each phase of model development the problem perception phase and the problem formulation phase and the implications for the temporal and spatial scales of each stage in this section by building on the aforementioned framework we propose recommendations for model development under the form of essential questions that need to be addressed this questionnaire presented in table 8 assists system conceptualization and serves to check information availability by doing so it supports clarity in problem translation from the problem formulation to the modelling phase we believe that making the role of information availability explicit throughout model development will support system understanding and further foster transparency around the trade off process in model development and system scale representation when defining an optimization model for water management problems 6 conclusions this review paper analysed the implications of decisions and related options throughout the optimization model development stages for the final temporal and spatial scale of the assessment we first explored the main decisions that have to be made by distinguishing two distinct phases in optimization problem development problem perception and problem formulation we found that most decisions have strong links with the spatial and temporal scales of the assessment that need to be accounted for successively we mapped options related to each decision i e related to the physical system assessment objectives the hydrological state and indicators objective and constraint functions solution methods and optimization scenario and provided scale specific considerations for option selection overall given that water management problems involve a large number of factors to consider e g operations schemes supply competition changing environmental conditions the decision making supported by optimization techniques is influenced by a series of challenges related to data availability and modelling capability this consequently affects decision making about options which resolves in tailoring the optimization model to the available data and modelling ability retrieving additional data required or subdividing the problem further research focused on clarifying the underlying influences between options concerning scale would provide an enhanced insight into the relationship between options and improve the process of option selection besides it would enable the integration of instruments that can improve reliability and comparability in optimization outcomes moreover while exploring how trade offs across scales are incorporated into the optimization process is more challenging for the application of optimization algorithms it is also potentially most useful to an environmental water manager as a foundation for these goals we provided recommendations for model development by focusing on key questions related to each decision with the intent of fostering transparency around decision making and options selection during both problem development phases declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this paper is an output from the euro flow project which received funding from the european union s horizon 2020 research and innovation programme under the marie skłodowska curie grant agreement no 765553 joseph guillaume received funding from an australian research council discovery early career researcher award project no de190100317 avril horne received funding from australian research council discovery early career researcher award project no de180100550 the authors would like to thank the editor and the three anonymous reviewers for suggesting substantial improvements to the manuscript annex table a1 summary of reviewed studies legend no info mp mathematical programming s stochastic mag d magnitude of daily and sub daily flows mag m magnitude of monthly and yearly flows mag dur ext magnitude and duration of extreme water conditions freq dur pulses frequency and duration of high and low pulses tim timing of annual extreme water conditions nh non hydrologic indicator g graph t table df designer flows pf pareto front continuing on the next pages table a1 reference study system location management purpose targeted scale planning period solution method hydrological indicators objectives constraints trade offs scenarios spatial temporal 3 4 arslan 2015 aksu river basin turkey energy production ecological health river sub daily mp based mag m physical environmental infrastructure related supply related ecological x chen and olden 2017 san juan river colorado river tributary us disturbance reduction ecological health river section seasonal 3 year plan mp based mag d physical environmental infrastructure related supply related g x dai et al 2017 three gorges gezhouba reservoirs yangtze river china energy production ecological health multi reservoir seasonal s mag d physical environmental infrastructure related g x fallah mehdipour bozorg haddad and loáiciga 2018 karoon iv dam on karoon river iran energy production ecological health reservoir daily mp based s physical environmental infrastructure related g fleifle et al 2014 el qalaa river nile river egypt functional purpose ecological health sub basin seasonal s nh physical environmental supply related ecological g torabi haghighi and kløve 2015 bakhtegan catchment iran disturbance reduction river basin monthly intra annual mp based mag m supply related ecological g x hassanjabbar saghafian and jamali 2018 karkheh basin iran iraq border energy production disturbance reduction multi reservoir monthly annual s mag d mag dur ext freq dur pulses physical environmental infrastructure related supply related x lewis and randall 2017 murrumbidgee river irrigation area australia functional purpose ecological health river basin monthly annual s mag m physical environmental infrastructure related supply related ecological g x martin et al 2017 goulburn broken river catchment murray darling basin australia functional purpose sub basin daily s mag m g mullick babel and perret 2013 teesta river bangladesh functional purpose river section monthly annual mp based mag m physical environmental ecological t x paredes arquiola et al 2013 duero river basin spain consumptive use ecological health river basin monthly annual mag m supply related g porse sandoval solis and lane 2015 luis l leon reservoir big bend region of the rio grande bravo mexico us ecological health reservoir monthly mp based mag d mag m freq dur pulses physical environmental infrastructure related supply related df schlüter et al 2005 amudarya river basin central asia consumptive use disturbance reduction multi reach monthly annual mp based mag m physical environmental infrastructure related supply related ecological x shang 2015 ertix river ebinur lake xinjiang china consumptive use ecological health river section lake monthly mp based mag m infrastructure related g shiau and chou 2016 hsintien creek taiwan consumptive use energy production safety disturbance reduction river basin daily s mag m mag dur ext nh physical environmental infrastructure related t x shiau and wu 2013 feitsui reservoir taiwan consumptive use energy production safety disturbance reduction multi reach multi reservoir sub daily annual multi annual s mag d mag dur ext rat freq change physical environmental infrastructure related g x szemis et al 2012 murray darlingriver australia reservoir monthly multi annual s mag d freq dur pulses physical environmental infrastructure related df x szemis et al 2013 murray darlingriver australia reservoir monthly multi annual s mag d freq dur pulses physical environmental infrastructure related df x szemis et al 2014 murray darlingriver australia reservoir monthly multi annual s mag d freq dur pulses physical environmental infrastructure related df x steinschneider et al 2014 connecticut river new england us disturbance reduction river basin daily annual mp based mag d mag m physical environmental infrastructure related supply related ecological pf x suen and eheart 2006 dahan river basin taiwan consumptive use energy production ecological health river basin monthly s freq dur pulses tim ext physical environmental infrastructure related pf wang et al 2015 philpott dam on smith river us consumptive use energy production disturbance reduction reservoir daily monthly mp based mag m mag dur ext physical environmental infrastructure related supply related process based g x xevi and khan 2005 berembed weir murrumbidgee river australia consumptive use multi reach monthly seasonal mp based mag m physical environmental infrastructure related ecological t x xu et al 2017 han river yangtze river tributary china consumptive use energy production disturbance reduction ecological health river daily s nh physical environmental infrastructure related supply related ecological df yin yang and petts 2012 tanghe reservoir on the tang river china disturbance reduction reservoir daily annual s mag d freq dur pulses rat freq change physical environmental supply related df yin yang and liu 2014 wangkuai reservoir hai river basin china disturbance reduction reservoir monthly annual s mag d freq dur pulses physical environmental infrastructure related supply related process based df x yin et al 2015 wangkuai reservoir hai river basin china energy production reservoir monthly annual s mag d infrastructure related supply related ecological g t 
25846,a challenge in modern farming is to find a sustainable way of achieving sufficient production precision in dosage timing and allocation of water biocides fertilizer and other inputs is essential as are such management actions as harvesting pruning and weeding despite the increasing availability of sensor and actuator technologies decision making is still largely left to the farmer this is creating a strong demand for support in operational management this paper presents an overview of methods involving the use of technology and data to develop model based management support and automation for productive and input efficient farming for each method the main advantages and drawbacks relating to typical farm characteristics are discussed and summarized three case studies are presented to illustrate the design steps involved in developing a model observer and controller the overall design procedure is summarized in a flowchart and serves as a basic guide for method selection and model development keywords modelling observation control precision farming disturbances errors 1 introduction during the 1950s and 1960s farming was intensified in order to meet the growing demand for food in the developing world after the second world war the main mission of this green revolution was food security and its objective was to achieve sufficient production rates at affordable costs the intensification of food production was made possible by extensive research and development on high yielding crop varieties agrochemicals biocides chemical fertilizer mechanization breeding and controlled water supply the green revolution arguably saved billions of people from starvation while increasing human prosperity tremendously at the same time however it was accompanied by serious adverse consequences for human health and the environment mason 2003 innes 2013 due to the large scale use of fossil fuels fresh water fertilizer pesticides and antibiotics moreover there has been a decrease in the availability of resources including arable land oliver et al 2013a b oil reserves phosphates for fertilizer and fresh water another resource that is becoming increasingly scarce in the primary food production sector is human labour development 2019 furthermore the intensification of livestock farming using inexpensive affordable production systems is often in conflict with requirements relating to animal welfare and health berckmans 2014 combined with a rapidly growing world population which is projected to increase from 7 billion in 2011 to an estimated 9 billion by 2050 modern farming in its current form is unsustainable in terms of resource availability human health animal health and the ecological carrying capacity of the planet pimentel and giampietro 1994 a green engineering approach that can help to minimize labour input pollution waste animal discomfort and the depletion of resources dorf and bishop 2011 is needed precision farming also known as intelligent farming site specific farming or smart farming is one such approach 1 1 precision farming modern large scale farms are characterized by the uniform application of inputs for example in the field it is common practice to distribute water fertilizer and pesticides uniformly regardless of variations in soil properties crop density or crop needs in greenhouse cultivation it is common practice to maintain constant indoor temperature levels day and night in dairy farming cows are usually fed rations based on an average cow and a specific average daily production and they are milked at fixed time intervals precision farming is a means of primary food production through precisely controlled input and management actions along with precise monitoring also known as state observation which is enabled by technological solutions auernhammer 2001 day 2005 all precision farming operations input actions monitoring incorporate one or more levels of precision in terms of dosage timing or spatial allocation e g by location group or individual within the wide range of available precision farming applications three main domains of application can be distinguished these domains are described below precision agriculture pa this concerns open field systems for crops like maize grain and potatoes the objective within this domain is to increase resource efficiency in arable farming by applying inputs according to site specific crop demands oliver et al 2013a b this is accomplished through the precise management of inputs e g water fertilizer pesticides and actions e g weeding harvesting examples of pa include controlled drip irrigation prathyusha and suman 2012 automated seeding the precise application of manure and pesticides and robotic weed control slaughter et al 2008 precision horticulture ph this concerns open systems e g orchards and protected systems e g greenhouses vertical farms the objective of ph is to exercise precise control over inputs for crops e g climate and light conditioning water fertilizer actions e g pruning harvesting are performed according to the status of individual plants or fruits e g amount of leaves ripeness through technological solutions like robotic harvesting hemming et al 2014 precision livestock farming plf this concerns production systems for animals e g cattle poultry fish føre et al 2017 and algae the objective of plf is optimize resource efficiency and animal welfare berckmans 2017 inputs e g feed antibiotics veterinary treatments are applied according to the needs of individual animals examples of plf technologies include robotic cow milking livestock health monitoring berckmans 2014 automated monitoring and control of broiler growth aerts et al 2003 the feeding of individual cows halachmi et al 1998 indoor climate conditioning automated incubators for egg hatching and the camera based estimation of animal weight song et al 2018 the fine tuning of inputs based on the time dependent location specific and individual needs of crops and animals can yield considerable savings in resources the following are several examples pa precise dosage control based on crop monitoring resulted in fertilizer savings of 23 while improving grain yield by 4 zhang et al 2002 ph in greenhouse cultivation time dependent climate control based on fluctuations in outdoor climate has been associated with savings of up to 47 in heating energy van beveren et al 2015a b plf the optimization of milking intervals for individual cows has been associated with increases of up to 25 in milk production andré et al 2010 one functionality that is common to all domains of precision farming is pest management in an extension to primary food production post harvest management precision technology is employed in such operations as automated quality monitoring selection packaging and air conditioning during storage and transport of produce in addition to uniform input risk avoidance can lead to the over application of inputs variable circumstances e g weather soil properties disease load and the physical condition of animals and crops make it challenging to make precise estimates of how much input is needed and how the amount of input is linked to the risk of under application the easiest way to decrease the risk of production loss due to pests or malnutrition is to make slight increases in the minimal dosages of pesticides fertilizer and other inputs stuart et al 2014 given that risk mitigation is rarely balanced rationally kahneman 2003 however farmers tend to have excessive risk avoidance attitudes anderson and dillon 1992 uncertainty about how much input is actually needed combined with the tendency to avoid production loss risks can lead to severe over application for example worldwide irrigation efficiency is estimated to be only 37 thus implying a loss of 63 due to runoff and drainage wallace 2000 possible ecological consequences of such inefficiency include the massive use of fresh water from rivers and aquifers and the leaching of chemicals and nutrients into groundwater due to drainage 1 2 automation one way to improve labour efficiency is to automate the operational management loop also known as the cyber physical management cycle verdouw et al 2013 automation can also help to avoid unnecessary risk mitigation by human operators and it can serve as a reliable means of precision management making it possible to attain a predefined level of product quality and harvest timing as illustrated in fig 1 four stages of automation have been identified traditional management by hand manual control supervised control fully automatic control as the management loop advances towards automatic control farmers receive more support from and become more reliant on technology and automation in traditional farming systems farmers perform all management tasks themselves both physically in terms of perception and actuation and mentally e g making decisions on input management in manually controlled system farmers perform all of the decision making themselves assisted by actuation and possibly sensing technology e g soil moisture sensors irrigation devices this type of control is typical of developing countries in supervised control systems farmers are assisted by low level controllers that operate autonomously according to the settings and set points specified by the farmers e g water dispensers that keep soil water near the desired level these systems also allow farmers to utilize sensor information on system states of interest e g soil water content and to anticipate future events e g precipitation based on forecasts this type of control is typical of high tech agricultural systems in developed countries in automatically controlled systems farmers are no longer involved in the management loop examples of such systems include milking robots feeding systems and autonomous climate control systems it must be noted that supervised and automatic control are not always clearly separate classes for example in many automatically controlled systems farmers are still able to overrule automated management actions or change system settings or set points furthermore automatic control is not always preferred over supervised control for at least two reasons 1 farmers prefer to remain involved in high level management and 2 for some applications control algorithms that outperform farmers have yet to be developed 1 3 decision support decision support can be provided in three different forms observation of the current state of the system to help farmers take appropriate action computers may be used to help provide diagnoses by observing the current state of particular systems e g the climate inside a greenhouse the water level in the soil the health status of an animal prediction of how the process will respond to input and of the corresponding performance for example predictions concerning yield or energy requirements can assist in the selection of appropriate climate set points in greenhouse management control algorithms that schedule input under specific management objectives e g high yield low resource use they can be used to achieve fully automated processes or to provide advice in some respects these types of support are cumulative observations of current system states e g indoor greenhouse climate animal health status can provide the initial conditions for model predictions concerning how those states would develop under different forms of input management subsequently control algorithms employ model predictions to optimize input management fig 2 provides a closer view of the supervised control scheme depicted in fig 1 more specifically it illustrates the role of prediction observation and control advice as a form of decision support the diagram shows two feedback loops a low level management loop with input consisting of the machine settings and set points to be tracked as provided by users and a high level management loop in which users are supported in the high level management loop user support consists of automatically generated state observations predictions of system response or control advice concerning input management e g advice on climate set points decision support systems can use sensor information about current states e g the climate inside and outside a greenhouse or forecasts e g weather or market prices in order to optimize input scheduling in anticipation of future events within this framework this paper discusses methods of observation prediction and control the methods are based on a systems approach using systems models various methods are addressed separately in the following sections case studies on three different farm management applications were conducted one for each section the actual case studies are included in the supplementary material 2 building a systems model farming systems generally involve many components in complex dynamic interaction with each other thereby forming intricate interaction networks these components are subject to the influence of multiple inputs some of which are controlled while others are not a systems model creates structure by describing the components as process variables and by describing their dynamic responses to changes in input as described in section 2 1 a predictive systems model can be designed to improve input scheduling in scenario studies in which the insight obtained into the system s input response contributes to the development of practical management guidelines for example this has been done within the context of greenhouse crop cultivation vanthoor et al 2011 pest management mul et al 2017 and irrigation scheduling mondaca duarte et al 2020 as described in section 2 2 the structure of a systems model can be extended with additional equations that describe relationships between states and that measure output input and state constraints as well as performance and systematic disturbances this extended structure forms a foundation for state estimation methods and control methods as described in sections 3 and 4 2 1 predictive model this section provides a brief overview of the key elements that make up a predictive systems model such a model can be derived in several different ways depending on the type of information available a first principle model also known as a mechanistic white box or process based model is composed of underlying biological chemical or physical principles keesman 2011 examples of first principle models comprise crop and animal responses to nutrients and environment fluid dynamics e g to describe climate dynamics in greenhouses and barns or to describe fluid transport in algae reactors actuator dynamics e g in greenhouse technology irrigation and harvesters population dynamics e g for fish and pests and classical mechanics e g to describe the motion of tractors robots and drones descriptive models also known as black box or non mechanistic models are generic models that are not derived from first principles but that describe processes based on data examples of descriptive models include linear regression models neural networks and auto correlation models e g arx narx armax chen and zhao 2014 in this overview we make no assumptions concerning the type of models used for the model based observation and control methods although the models can be either mechanistic or non mechanistic they are all assumed to have structures as described in this section 2 1 1 input state dynamics farming processes are characterized by a dynamic input response for example the effect of irrigation input on crop growth is not immediate but may span several days or even weeks this makes the scheduling of input over time a non trivial problem in addition to the inputs that are controlled other inputs might not be able to be controlled but should be anticipated e g precipitation solar radiation in a predictive systems model the process dynamics and various types of input are formulated systematically one core principle of systems theory is that each system has a specific boundary input and state the system boundary is determined by defining the state variables within the system and the input variables that enter the system from outside and that affect the state dynamics a general formulation to describe the input state dynamics in a continuous form is as follows 1 d x t d t f x t u t ε t θ t in this equation x t is the state vector that changes over time t with some initial condition x 0 x 0 the state vector can contain variables like temperature and humidity although it could also include spatial information to make the model specific to a given site e g a temperature variable subdivided into temperature at various locations the time derivative of the state equals f a non linear function describing the interaction between states and how the states respond to the input the rates of change and the strengths of the interactions are represented by the values of the model parameters in vector θ the control input u t can be manipulated and it is used to control the state dynamics the external i e uncontrollable input ε t can often be observed and in some cases its dynamics can be predicted but it cannot be manipulated the final argument of function f is time t which acts as an independent variable representing changes in system response over time e g changes in biological development stages that have not already emerged from the modelled state interactions 2 1 2 model complexity organisms e g animals and crops are inherently complex within an organism physiological chemical and physical processes at the level of tissues cells and molecules form extensive interaction networks that govern input responses that are almost always non linear e g doubling a feed ration does not generally double milk production whereas physical processes e g mass and heat transfer are often relatively linear while the chemical processes underlying physiological input responses e g photosynthesis food digestion are typically non linear model complexity is a design aspect that poses an important trade off very simple models are easy to derive and they require little computational effort for control design at the same time however over simplification may introduce model errors that have a negative influence on the accuracy of predictions although the development of more advanced more complex models may improve prediction accuracy it may also require considerable experimental and field work knowledge acquisition and modelling expertise not all state estimators and control algorithms are designed to address high levels of model complexity furthermore increasing complexity usually increases computational demand another possible drawback of high model complexity has to do with the large number of parameters which increases the likelihood that the values of some parameters will be difficult to determine 2 1 3 parameter estimation when a parameter value is unknown or uncertain a common solution method is to estimate the maximum likelihood value based on available data the likelihood of a parameter vector θ is obtained by comparing the predicted model state at discrete time instances shorthand notation x θ k with a time series dataset of measured state x d a t a k in this calculation k is an index representing discrete time instances t k δ t with δ t representing the time step size and k 1 n assuming that the measurement errors are modelled by additive gaussian white noise with covariance matrix r k 2 x d a t a k x θ k v k with v k n 0 r k n denotes a normal distribution the likelihood function of parameter vector θ is then as follows 3 l θ x d a t a e x p k 1 n 1 2 δ x k t r k 1 δ x k where δ x k x d a t a k x θ k the maximum likelihood is obtained by θ m l the value of θ that maximizes θ x d a t a many optimization algorithms are available for retrieving θ m l for relatively simple models where y is a linear function of θ e g a linear regression model the maximum likelihood can be computed directly through least squares estimation in general θ m l is approximated through iterative algorithms that evaluate multiple parameter values and compare their likelihoods two classes of algorithms can be distinguished gradient based algorithms and evolutionary algorithms gradient based algorithms search the parameter space by following a path along which the objective function l has the strongest increase gradient examples include the newton raphson and the levenberg marquardt kelley 1999 algorithms the advantage of these methods is that the use of gradients reduces the number of iterations required thereby increasing computational efficiency this is a crucial advantage especially for complex models with large integration times given the need to integrate the model for each iteration in order to obtain l one possible drawback is that when multiple local optima exist there is no guarantee that the global optimum will be found evolutionary algorithms use a population of candidates for θ m l the values of which evolve through some stochastic evolutionary process this stochasticity combined with the use of multiple candidates increases the likelihood of finding the global optimum one general drawback of evolutionary algorithms is that they tend to require a relatively high number of model integrations parameter estimation is a well established discipline with many good textbooks available for interested readers 2 2 additional equations for observation and control methods this section describes additional equations that are useful for making predictive models compatible with the observation and control methods described in sections 3 and 4 2 2 1 output dynamics sensing technology enables automated and dynamic measurements of system states that are of interest it is important to note however that not all states can be measured directly for example the measurement of animal stress by sampling blood cortisol levels is an invasive method that is not very practical in such cases indirect measurements are performed the sensor measurements y are related to the state vector through the following output equation 4 y t g x t θ where g is a function depending on the state vector x and some of the parameters contained in vector θ for example an output function can relate a cow s resilience against disease to measured body temperature lying time and eating patterns van dixhoorn et al 2018 fig 3 shows a flow diagram of a system model represented by equations 1 and 4 the input state output structure makes it possible to close the management loop by applying a controller that connects the measured output to the control input 2 2 2 constraints system states may attain critical points at which the system becomes fragile meaning that its dynamic response can become highly sensitive to slight changes in input at critical points a state can shift to an undesired steady state organisms can attain a multitude of steady states e g healthy and sick vegetative and generative alive and dead fresh and spoilt in animals with low resilience an increase in stress or disease load e g from over stocking can have a major impact on health van dixhoorn et al 2018 growth and milk or egg production in crops a combination of large amounts of sun and low water supply results in wilting or even death if the interactions underlying such tipping events are not modelled explicitly it is important to identify the constraints of state and input under which a process should be operated in order to avoid them another constraint is actuation capacity which is almost always bounded for example the capacity of an air heater and the maximum rate of a harvester depend on type of equipment used and they are always limited to some level although some control algorithms assume that both positive and negative actuation is possible this is not always the case for example an irrigation system can apply water but it cannot extract it to describe the constraints on x t and u t that are needed in order to avoid unwanted steady states or the exceedance of input capacity constraints are introduced in the form of a given set b of algebraic inequalities 5 b x t u t 0 2 2 3 performance sustainable farming is characterized by inherently conflicting objectives typically high production rates vs low input use the importance of all objectives should be carefully balanced in order to arrive at suitable control advice to this end the model can be extended with a performance measure usually referred to as a performance criterion j which can be described as some function h depending on state input and time 6 j h x t u t t more specific formulations of j are presented in sections 3 and 4 to make input selection straightforward performance is usually represented by a scalar value when there are multiple performance objectives the variables corresponding to these objectives can be assigned weights according to their importance e g performance equals the production rate minus 3 times the input rate the objectives are represented mathematically by various indicators such as energy efficiency health deficiency van dixhoorn et al 2018 the animal comfort index fournel et al 2017 and the damage rate during fruit or egg transport van mourik et al 2016 2 2 4 disturbances and errors farming systems are affected by disturbances from outside the system as well as by errors from within the system which lead to uncertainty in observations and predictions consequently this may lead to severe performance loss a disturbance can be seen as an unforeseen variation or fluctuation of factors coming from outside the system that affects the dynamics of the system and the certainty with which they can be predicted dorf and bishop 2011 examples of disturbances include unexpected fluctuations in weather pest occurrence and disease load disturbances related to sensing technology include incoming sunlight and dust particles in the air sanderink et al 2017 economic disturbances e g in commodity or product prices constitute a somewhat different category which can also affect the performance j due to their often stochastic nature the uncertainty that disturbances cause is also referred to as stochastic uncertainty walker et al 2003 an error can be regarded as a factor from within the system that causes its dynamics to deviate from expectations errors related to biophysical system properties include unexpected developmental changes biological variations between individual plants and animals and spatial variations in air conditions and soil properties errors related to sensing and actuation technology include those occurring due to poor sensor or actuator calibration wear and tear signal delay jawad et al 2017 and spatial variations e g temperature sensors located in cold areas in control engineering errors in sensor signals and actuators are referred to as noise dorf and bishop 2011 for purposes of observation and control the uncertainty caused by disturbances and errors is commonly modelled as stochastic noise the following is an example of discrete time process with stochastic noise 7 x k 1 f k x k u k ε k θ w k at each time instance k the state noise w k consists of independent draws from some distribution d w k d 0 q k with q k the covariance matrix describing the statistical interdependency between individual noise signals in this example the noise is assumed to be additive because of the sign the representation of stochastic additive noise in state dynamics as well as in the output equation 8 y k g x k θ v k with v k n 0 r k is a standard way of modelling uncertainty for model based filtering and model predictive control methods like kalman filtering and lqg feedback control are based on white noise entering the system when the state noise is not white in terms of frequency but exhibits auto correlation this can be modelled by representing white noise entering the system and adding a pre filter within the system see section 3 1 that transforms the noise before it enters the state dynamics 3 state observation the ability to observe a system state e g greenhouse climate animal condition crop state is of great importance to precision management the prediction accuracy of future state trajectories depends largely on the accuracy of the current state estimate current states can be estimated with models through the use of sensing technology or through a combination of these methods several different methods are discussed in this section 3 1 data based state estimation system states can be estimated according to data streams obtained with sensor technology three common methods for this purpose are frequency based filtering soft sensing and machine learning 3 1 1 frequency based filtering one common way of filtering out sensing noise see equation 8 involves frequency based filtering if it can be safely assumed that the sensing errors are in a different frequency range than the true dynamics the errors can be filtered out based on their frequencies for example a low pass filter passes the low frequency dynamics in the sensor signal and filters out high frequency dynamics associated with sensor noise a high pass filter does the opposite a band pass filter passes signals only within a certain bandwidth for example low pass filters have been employed in order to smooth climate sensor data in greenhouses rodríguez et al 2015 a band pass filter has been employed for automated crop row location and tracking hague and tillett 2001 3 1 2 soft sensing in addition to sensing errors limited observability can occur because the states of interest cannot be measured directly or because direct measurements are too costly or time consuming in such cases indirect measurements are performed when an output function equation 4 is available and invertible the state can theoretically be estimated from the sensor measurements applying the following conversion 9 y t g x t into x t g 1 y t this method is also known as soft sensing a calibration curve that relates humidity x to measured electrical conductance y is an example of state estimation through an inverted output function when y consists of multiple sensor signals finding the relationship between the signals and the state of interest is done in a process known as sensor fusion one example of sensor fusion involves finding the relationship between soil properties using a combination of spectroscopy electromagnetic induction and ground penetrating radar mahmood et al 2012 one important challenge is to identify which data streams contain relevant information and how to combine them 3 1 3 machine learning in many cases no output equation is available measured traits such as the shape song et al 2019 colour kurtulmus et al 2011 odour mottram 2016 and behaviour berckmans 2014 of vegetables fruits or animals are usually difficult to relate mechanistically to such states as ripeness freshness condition and health data based models can be used to classify system states e g a plant inside the cropping system is either a weed or not a weed a crop is either fresh or spoilt an animal either is or is not in good health various classification models for data based machine learning have been developed including logistic regression support vector machines and linear and quadratic discriminant analysis one advantage of these models is that they do not require knowledge on the mechanics underlying specific processes at the same time however this feature also prohibits the analysis of how underlying mechanics affect the system e g for error analysis and in design studies furthermore training sets must be carefully selected and the systems should be tested on independent test sets or through cross validation in order to prevent over fitting for high dimensional data e g imaging data it is even more challenging to link states to sensor measurements one standard approach involves abstracting the data in order to obtain a lower dimensional representation in image processing this is known as feature extraction which consists of a series of image processing steps gonzalez et al 2004 the features form an abstract representation of the image data e g the colour shape and texture of tomatoes in an image which might be indicative of the ripeness stage one common approach involves using manually designed feature extractors with a machine learning approach as process based models are often incapable of estimating states from these abstract features the relationships are too complex to be modelled from first principles instead machine learning methods can unravel the relationships based on a set of training examples e g images of tomatoes with associated ripeness values one disadvantage of this approach is that the feature extractors are still designed manually recently developed deep learning methods are able to address this by presenting an end to end learning approach in which the state can be estimated directly by deep neural networks based on the raw images goodfellow et al 2016 these networks optimize both feature extraction and state estimation within a single common framework based on a large training set the deep learning approaches have been shown to outperform classical image processing in many domains including agriculture kamilaris and prenafeta boldú 2018 in this paper we focus on process based methods for additional background information on machine learning see friedman et al 2001 3 2 data assimilation sensor information can be combined with model predictions in a process known as data assimilation the reasoning behind this process is that both model predictions and measurements contain errors the merging of model and sensor information results in higher estimation accuracy than is possible with measurements or predictions alone 3 2 1 static filter one basic method of data assimilation involves estimating the state of interest by weighing the state prediction according to the model x with the measured state assuming for now that the state can be directly measured y with weighting factors based on the uncertainty with which the state is predicted σ x 2 and the uncertainty of the measurement σ y 2 this results in the following estimator gelb 1974 10 x σ y 2 x σ x 2 y σ x 2 σ y 2 the weighting factors can be interpreted intuitively for example if the measurement is highly uncertain σ y 2 is large and x therefore receives a higher weight the denominator acts as a normalization term such that all weights add up to 1 this method is suitable for estimating the state once e g when x is the outcome of a dynamic process 3 2 2 dynamic filter when the state is tracked over time the estimation problem becomes more challenging as the estimated state should be updated repeatedly according to new measurements a dynamic filter operates in a continuous loop using the measured input and output of the process to make a state estimation x ˆ t fig 4 shows a flow diagram of a dynamic state filter several dynamic filters are discussed in the following sub sections 3 2 3 kalman filter perhaps the best known model based dynamic filter is the kalman filter the design of which is based on equations 7 and 8 the assumptions for a standard kalman filter are that the state function f and output function g are linear and that state and output noise is white and normally distributed under these assumptions the filter produces a maximum likelihood state estimate x ˆ k together with its probability distribution as represented by its covariance the state estimate minimizes the expected root mean squared error between the estimated and actual state the estimated state becomes the starting point for the model prediction at the next time instance to estimate the state the algorithm weighs the measurement and its uncertainty v k against the model prediction based on the current state estimation and state noise w k in a manner similar to equation 10 in addition however it considers the uncertainty associated with the previous state estimation and updates it accordingly consequently greater uncertainty in a state estimation calls for the assignment of greater relative weight to the sensor measurement at the next time instance and vice versa this prevents unwanted bias effects for example if the model has a small positive bias each new state estimate will be slightly too high and over time the model state will tend to drift away from the true state due to the increasing discrepancy between measurements and predictions however the state uncertainty and thus the model prediction uncertainty will increase thereby reducing the weight of model predictions as a result the filter tends to drive the state estimates back towards the sensor measurements one straightforward way to estimate the covariance matrix q in equation 7 is to assess the error between model predictions and measurements over a series of time this method nevertheless requires the state to be directly measurable the covariance matrix r in equation 8 can be estimated based on the differences between output and model predictions if accurate values for state and input are known or it can be based on factory specifications about the accuracy of the sensor the reliable estimation of q and r imposes several requirements on state measurements if these requirements cannot be met autocovariance least squares methods can be employed rajamani 2007 one strong assumption on which the kalman filter algorithm is based is that the noise is white more specifically the algorithm is based on the assumption that signal errors are not auto correlated and that all frequencies are attained in a uniform manner although the invalidity of this assumption does not necessarily mean that the kalman filter will not work julier et al 2000 such issues should be approached with caution if non whiteness forms a bottleneck to filter performance pre filtering can be employed in pre filtering the model is extended with augmented model states that transform white noise into coloured noise which subsequently enters the process dynamics and output measurements salzmann et al 1991 kalman filters can be used in a wide range of farm management tasks including the estimation of greenhouse climate and crop states lópez cruz et al 2017 van mourik et al 2019 location estimations for agricultural vehicles gartley and bevly 2008 health monitoring in dairy cattle de mol et al 1999 and water level monitoring in fish farms ullah and kim 2018 state estimation by kalman filtering also forms a part of the lqg control algorithm section 4 1 4 3 2 4 extended and unscented kalman filter one key assumption is the linearity of the state dynamics and output function the extended kalman filter was designed to address non linearity by linearizing f and g at each state update grewal and andrews 2014 such linearization is required in order to compute the propagation of state uncertainty in a straightforward and computationally efficient manner the extended filter also introduces linearization errors however as well as errors relating to the assumption of symmetric error distributions the unscented kalman filter was designed to circumvent these types of errors julier et al 1995 this filter uses a sampling method that retains the non linear transformation f intact unscented by sampling the state covariance with a few sampling points i e sigma points the unscented kalman filter also contains three design parameters that can be adjusted to address state probabilities that are not normally distributed 3 2 5 particle filter all of the aforementioned kalman filters assume that the states have unimodal distributions this assumption is not always realistic consider the following example to estimate its location an autonomous vehicle uses a model based on wheel rotation speed and steering action with gps as a location sensor when the vehicle is in front of a tree it may assign high probability densities to several locations that are close to trees on the orchard map while assigning low probabilities to locations between trees this results in a multimodal density of location probability this state cannot be represented using a gaussian distribution as is the case with the kalman filter the particle filter therefore represents the state estimation with a large number of weighted particles thus allowing multi modal probability density functions this comes at the cost of computation however as it requires the transformations f and g to be computed for each particle at each state update the computational demand thus depends largely on the number of particles used and the computational demand for evaluating the functions f and g for example particle filters have been designed for localization within such repetitive environments such as orchards bayar et al 2015 and barns vroegindeweij et al 2016 3 2 6 dual estimation similar to online state estimation model parameters can be adjusted online as well the difference between this method and the parameter estimation described in section 2 1 3 is that online state estimation is performed on a single system or subject whereas parameter estimation often uses experimental data on a large number of subjects the simultaneous estimation of parameters and states is known as dual estimation liu and gupta 2007 and it has been used for estimating greenhouse climate speetjens et al 2009 and soil moisture lü et al 2011 another online adaptation method is bayesian forecasting west and harrison 2006 which estimates current states and parameters in addition to predicting future states according to bayesian principles although the basic principles are similar to those underlying kalman filtering bayesian forecasting is more extensive e g due to the use of discount factors that assign higher weight to current data than to older data one potential drawback of dual estimation stems from the additional flexibility introduced by parameter adaptation more specifically although it decreases bias it may increase variance in model predictions and controller performance up to the point of instability rohrs et al 1985 the bias variance trade off is a well known design principle in statistical learning friedman et al 2001 3 3 summary the main advantages and disadvantages of the state observation strategies discussed above are summarized in table 1 different methods are associated with different advantages relating to model requirements the necessity of addressing non linearity multimodality and non gaussian error distributions they are also associated with possible disadvantages relating to assumptions concerning error properties and computational costs the optimal choice of filter therefore depends on the particular observation problem at hand as well as on the key advantages and disadvantages and how they weigh against each other for example if a process model is non linear and exhibits a non gaussian state distribution a particle filter might be preferred if simulations are computationally demanding however the need for a more time efficient method might outweigh the choice of a particle filter 4 control design using a systems model a controller can be designed to determine the input that would optimize performance through precise timing and dosages of inputs and actions two different means of control can be distinguished feedback control in which control actions are based on current and past system states and model predictive control in which control actions are based on both current states and expected future events 4 1 feedback control the aim of feedback control is to steer the state in order to track a reference signal for example climate variables in a greenhouse should be close to a set point chosen by the grower or a vehicle should follow a set path the design of signal tracking control focuses on minimizing tracking errors the difference between a state and a desired set point attenuating disturbance and maintaining stability in the process dynamics dorf and bishop 2011 the basic structure of feedback control consists of a system that is connected to a controller through sensors and actuators the controller receives sensor information about the state or states of interest and these measurements are compared to the reference signal that the system state is intended to track the difference between the measured signal and the reference signal is used to compute the subsequent control actions this is usually done in a continuous fashion forming a closed feedback control loop fig 5 one general benefit of a feedback control loop is the ability to react directly to tracking errors a feedback controller adjusts the input based on the current state and in some cases on the past state trajectory using integrating action see section 4 1 1 it nevertheless does not anticipate future events this is done in model predictive control see section 4 2 the types of feedback control that are most relevant to farming operations are discussed below 4 1 1 proportional integral derivative control proportional integral derivative pid controllers are perhaps the most commonly used control algorithms in operational farm management examples include path tracking and suspension control yu et al 2004 for autonomous vehicles climate control in greenhouses li et al 2018 and barns niu 2014 depth control in soil measurements mouazen et al 2005 and water pressure control in irrigation systems goodchild et al 2018 in the abbreviation pid the p stands for proportional action a direct response on the tracking error the i stands for integrating action the adjustment of input based on the history of the tracking error and the d stands for derivative action the response to the trend in the tracking error a pid controller can be expressed as follows 11 u t p e t i 0 t e τ d τ d d e t d t where e t r t x ˆ t is the tracking error with the reference value r t representing the desired set point trajectory and x ˆ t representing the estimated current state the proportional action first term provides a controller input u t which is aimed at steering the system state towards the desired set point proportional action alone however may result a steady state offset for the state the integrating action middle term enables the controller to attenuate low frequency errors and disturbances that cause an offset in the state for example consider a heating system that should keep the temperature inside a greenhouse at 20 c suppose that due to an actuator error the room is not sufficiently heated and the temperature reaches only 15 c this means that the state has an offset of 5 c which may be somewhat decreased but not completely eliminated by the p action the offset will result in a steady increase in the integral term over time consequently the heating input will increase and the offset will ultimately disappear one possible disadvantage is that the integral term may respond slowly to changes in tracking error or lead to instability the derivative action last term is proportional to the changes in tracking error and it typically speeds up the system response caution is needed however as the derivative term can be highly sensitive to violently fluctuating derivatives due to noisy measurements these fluctuations might cause violent input dynamics that in turn might have a negative influence on stability actuator wear and tear and resource efficiency these fluctuations can be attenuated by first filtering the tracking error with a low pass frequency filter the trade off is that a low pass filter delays the signal in addition it is important to be careful not to filter out true signal information a controller with proportional integral or derivative action or some combination thereof can be tuned by loop shaping techniques that balance sensitivity to tracking errors with typically low frequency dynamics with robustness against input disturbances with typically high frequency dynamics using frequency analysis tools e g the bode plot and nyquist diagram bode nyquist based techniques can also be employed to design controllers with additional robustness against non linearities and modelling errors one important advantage of pid controllers is their simplicity they can be tuned according to measured input output response without the use of a process model for example this can be done for a system with single input and single output according to the ziegler nichols tuning rules one possible disadvantage of pid control is reduced performance due to the simplification of assumptions concerning the actuators in equation 11 the controller assumes that actuation can be performed either continuously or at every discrete time instance it is important to note however that this is not always the case for example it might be possible to irrigate a field only once every three days as there is only one sprinkler system that is used on multiple fields another assumption is that actuators can dose gradually in practice however most lamps fans and heaters can only be switched on or off one possible solution in the case of an on off actuator is to allow the controller to be switched on or off at a high frequency while controlling the percentage of on time with a pid controller pwm pulse width modulation for example one such controller was designed for a temperature controlled food storage room mourik et al 2010 as indicated in equation 11 u t is a symmetric function of e t the input can thus be either positive or negative depending on the sign of the tracking error in reality however input can often only be added and not subtracted as is the case for irrigation water or pesticides this can result in a problem known as wind up for example if the soil moisture level is too high a controller can do nothing but wait until enough water has evaporated or drained in the meantime however the integral term will have accumulated to a high value for this reason even after the water level has dropped the high integral value will prevent the controller from taking action such integral wind up behaviour has been well documented and various anti wind up approaches have been described in the literature azar et al 2015 equation 11 applies no constraints on the input and state a soft constraint may be imposed by choosing the values for p i and d in such a way that the input or state will seldom if ever exceed a certain maximum or minimum value it is possible to tune pid by loop shaping and not only by model free empirical tuning this can be done even for systems with multiple inputs and multiple outputs xiong et al 2007 in addition some pid design algorithms take input efficiency into account as control objective comasòlivas et al 2012 4 1 2 feedforward control given that feedback control acts upon tracking errors caused by disturbances that affected the process dynamics at some time in the past in principle it will always lag behind feedforward control acts directly upon those disturbances by measuring them online and determining the required control input based on a model feedforward control is often used in combination with feedback control one advantage of feedforward action is that it gives the controller the opportunity to react to disturbances immediately rather than awaiting a system response and then acting upon it especially for systems with a slow response e g in crop or animal development feedforward control may offer a valuable solution in disturbance attenuation one possible drawback is that the disturbances must be measured online such measurements can be costly or difficult to realize and they are subject to measurement errors in addition the influence of the disturbances on the measurements of interest must be modelled the added value of feedforward control therefore depends largely on the quality of the error response model measurement accuracy and response time 4 1 3 lqr control the linear quadratic regulator lqr is designed with the use of a linear model of the system under the assumptions that state dynamics are time invariant undisturbed without external input and linear model 1 is approximated as follows 12 d x t d t a x t b u t where the matrices a and b form a linearized version of function f the control problem is commonly formulated as minimizing the performance criterion j which indicates how well the management objectives e g tracking error and low input costs are met over a time period ranging from 0 to t 13 j x t s x t 0 t x t v x t u t w u t d t the criterion j makes it possible to design a controller that can weigh the costs of tracking errors against the costs of input use the minimization of these variables usually results in a trade off the form of j is quite specific it is quadratic i e it consists of matrix vector combinations all of which yield quadratic terms and time invariant the first term on the right represents the value associated with the state at end time t e g produce value at harvest the contribution of each state within the state vector x t is weighed by matrix s the second term is an integral containing the running costs associated with tracking errors i e deviations of x from 0 weighted with matrix v and the costs of the control input weighted with matrix w as with pid control soft constraints can be imposed on the input and state by tuning the values of v and w under the assumptions that the states can be observed and that the feedback is of the form u t k t x t with k t as the feedback gain matrix the optimal input trajectory is computed by solving the ricatti equations kalman 1960 these equations can be solved relatively quickly through computation as compared to the dynamic programming method required for non linear time variant control problems see section 4 2 3 in addition to this computational advantage another important benefit of lqr is that it is an optimal feedback controller in the sense that it has an explicit performance criterion and it achieves optimal performance one potential drawback however is that this optimum can be achieved only under quite strong assumptions linear input output response time invariance symmetric input input that can be steered continuously over time and in dosage no influence from external input and performance that is represented by quadratic functions of tracking errors and input caution is advised when modelling performance with quadratic functions although economic costs often have a linear relationship with input doubling the input doubles the input costs the relationship between set point deviations and the costs associated with spoilage or production loss may be exponential e g bacteria growth in dairy products depends exponentially on temperature phillips and griffiths 1987 the feedback mechanism in lqr offers some extent of robustness against undesired state deviations by actively steering them back towards the set point this robustness is limited however as there are no errors or disturbances in equation 12 for which the controller is explicitly designed moreover there is no integrating action as in pid control to compensate for offset in tracking error performance in practical situations is therefore heavily dependent on the validity of the assumptions examples of lqr applications include greenhouse climate control gutiérrez arias et al 2015 and dust control in animal housing liao and feddes 1993 4 1 4 lqg control linear quadratic gaussian lqg control is an extension of lqr this extension is explicitly designed to address uncertainty in state and output measurements for this the process dynamics of 12 are extended with an output equation as well as with state and output noise see also equations 7 and 8 14 d x t d t a x t b u t w t y t c x t ν t as with lqr the control action consists of state feedback u t k t x t which optimizes performance with respect to the criterion 15 j e x t s x t 0 t x t v t x t u t w t u t d t solving for the state estimate and optimal input requires solving two matrix riccati equations consisting of differential equations in continuous time and difference equations in discrete time the main differences between the lqg and lqr control problems are that in the lqg problem the performance criterion is minimized with respect to the expectancy e of the costs and the state is estimated through kalman filtering see section 3 2 3 furthermore the weights are time dependent which may facilitate the imposition of soft constraints with regard to the timing of input e g when input can be applied only at specified times input is more likely to occur during these intervals if w is small during designated time intervals and large elsewhere despite the fact that lqg addresses stochastic state and output noise it has no stability margin in other words it cannot guarantee any stable robustness against model errors in the sense that bounded input results in bounded output doyle 1978 for this reason small model error could potentially result in ever growing oscillations in input and state examples of lqg control include heating and ventilation control in greenhouses el afou et al 2013 and active suspension control for agricultural vehicles bo and fan 2004 4 1 5 threshold control some actuators cannot provide continuous dosage but can only be switched on or off in on off control also known as bang bang control the timing of switching is optimized this type of control type was developed for such purposes as the application of crop nutrients hooper 1988 one very basic but commonly used type of on off control is threshold control also known as hysteresis control in this type of control a control action is performed each time a state reaches an upper or lower boundary for example when the temperature in a food storage room gets too high a cooler switches on for some period of time when the temperature gets too low a heater turns on this method of control may result in typical saw tooth state dynamics within a hysteresis band as illustrated in fig 6 one main advantage of threshold control is its simplicity no model is required in addition a threshold controller can be developed relatively easily for systems with asymmetric actuation abilities for example an irrigation system can apply water to the soil but not extract it a threshold irrigation controller was developed that triggered irrigation events based on crop water status thompson et al 2007 threshold control is subject to several possible disadvantages if a system has a slow input response the thresholds could be violated for example if irrigation is stopped right at the moment at which the soil water reaches a threshold value according to an underground sensor water will continue to trickle down through the soil and the water content will increase a bit further furthermore threshold control does not infer high precision the state is located somewhere between two boundaries but it does not follow a precise trajectory precision can be increased by bringing the upper and lower boundaries closer together to create a narrow state bandwidth this might increase the likelihood of threshold violation however and it could cause the state to bounce between the upper and lower bounds for example with the context of heating and cooling this could cause a heater and a cooler to work against each other thereby wasting energy 4 1 6 summary several strategies are available for feedback control each with its own assumptions and properties the main advantages and disadvantages of these strategies with respect to operational farm management are summarized in table 2 as in the selection of a suitable state filter the choice of a feedback controller depends on the particular control problem at hand as well as on the key advantages and disadvantages and the trade offs between them 4 2 model predictive control when future circumstances are known or at least forecast it may be worthwhile to anticipate them through input scheduling for example if the weather will be warmer tomorrow than it is today lowering the greenhouse temperature today could save a considerable amount of heating energy while maintaining an acceptable average temperature model predictive control mpc is the class of control methods for input scheduling while taking future changes into account we start by describing the concept of finite horizon control 4 2 1 finite horizon control in the finite horizon form of model predictive control the input is scheduled for a fixed period of time 0 t this is known as open loop control in contrast to closed loop control section 4 1 as there is no feedback based on state measurements to close the management loop the control problem consists of minimizing the performance criterion for any admissible input u t the performance can be formulated as follows 16 j f x t 0 t l x t u t t d t the function f represents the costs associated with the state at end time t and function l represents the running costs associated with input and with state dynamics in addition j can be minimized under time dependent boundary conditions of input and state b x t u t t 0 the control problem of minimizing criterion j can be seen as a generalization of the lqr problem as both the system model and the performance criterion can be non linear and time varying given that the model includes external input ε t minimizing j implies that the input is optimized while anticipating future external input dynamics solving this control problem can be quite challenging in the 1950s pontryagin and bellman developed algorithms to design optimal input trajectories that minimize j under the constraint b 0 by solving the euler lagrange equations although the optimization problem can be solved analytically for some simple cases a numerical solution is usually required e g through dynamic programming see section 4 2 3 potential disadvantages of finite horizon optimal control include the fact that it is not designed to attenuate any errors or disturbances as a result the exact value of ε t is assumed to be known in advance in the absence of feedback forecast errors may cause the realized state trajectory to deviate from the predicted trajectory regardless of its potential disadvantages finite horizon optimal control is a valuable tool for determining the potential added value of precision management in terms of timing and dosage comparing the theoretical optimal performance to the performance currently obtained in practice can provide a considerable amount of information about the potential gains to be realized with precision management in greenhouse research finite horizon optimal control has been employed to investigate the energy saving possibilities of precisely controlling the timing and dosing of inputs like heating and ventilating van straten et al 2010 in the performance criterion x t represents the end state of the crop and l u represents the running costs for climate management other research applications for finite horizon optimal control include manure spreading krishnan et al 2006 robotic harvesting van henten et al 2009 and pest management vincent 1975 4 2 2 receding horizon control receding horizon control is an extension of finite horizon control in this model both the state and the prognosis on external input are updated regularly and used to compute new input schedules thereafter the time horizon is extended such that the time window across which the input is optimized shifts forward while maintaining the same length receding horizon mpc is quite popular in research on farm operations example applications include trajectory planning for moving agricultural machines coen et al 2008 greenhouse climate control el ghoumari et al 2005 irrigation mccarthy et al 2014 and agro robotics kayacan et al 2015 an extensive review on mpc applications in agriculture is provided in ding et al 2018 the updates come at a price in terms of computation as each update requires a recalculation of the optimal input given the high computational cost of solving the euler lagrange equations they may allow only a low update frequency to avoid slow computations the state dynamics can be linearized thereby yielding the aforementioned riccati equations which can be solved much faster this nevertheless comes at the expense of possible linearization errors another increasingly popular approach is explicit mpc in which the optimization problem is solved offline for a range of operating points and multi parametric programming is used to express the optimal control actions as explicit functions of the states in most cases the end results resemble a look up table although this method drastically reduces online computation requirements it does not always guarantee that all constraints have been satisfied for additional information on this point see alessio and bemporad 2009 and diangelakis et al 2019 the regular updating of open loop control is known as open loop feedback although the regular updating of states and forecasts does provide some robustness in the sense that it can correct for errors and disturbances it does not provide any integrating action as is the case with pid control for example consider a heating system that is supposed to achieve a room temperature of 20 c but that has an offset of 5 c due to actuator bias the mpc algorithm described above will not learn from any past mistakes and it will therefore continue recalculating its actions in the same way thus preserving the offset possible options for addressing model offset include i applying integrating action section 4 1 1 and ii adapting the model parameters based on output response sections 2 1 3 and 3 2 6 several methods have been developed in order to improve mpc performance one example is tube mpc langson et al 2004 in which a feedback controller is implemented to keep the state within a bounded area tube of the optimal trajectory calculated by mpc the basic mpc algorithm is designed to optimize performance in a deterministic manner without taking performance uncertainty into account by comparison stochastic mpc is a method for mitigating performance risks associated with errors and disturbances 4 2 3 stochastic model predictive control stochastic model predictive control or stochastic mpc is based on the assumption that the state dynamics are disturbed by noise equation 7 the control problem consists of optimizing the input trajectory u k with respect to the cost criterion bertsekas 1995 17 j e f x n k 0 n 1 l k x k u k ε k this criterion is similar to the one used in equation 16 with the difference that in this criterion the expectancy of the costs is minimized furthermore the formulation of j can be adapted in such a way that the variance of the costs j are included as well horwood 1996 given that a decrease in variance implies a decrease in the risk of very high costs this is also known as risk sensitive control the concept of stochastic mpc has been employed within the context of irrigation optimization zavaleta et al 1980 crop harvesting alvarez and shepp 1998 greenhouse crop production mourik et al 2016 and fish harvesting braumann 1999 one important issue in stochastic mpc is computational demand the difficulty in solving the control problem resides in the fact that there is no single optimal trajectory u k as time proceeds the realizations of noise w k will change the course of any state trajectory x k that was planned beforehand as a result for each time instance k the optimal choice of u k will depend on the particular state at that time x k such that u k u x k k optimization across all possible state realizations over time poses a computational challenge suppose that a state is discretized into m parts and time into n parts for a single state model there are thus n m possible state trajectories a basic crop model with only one state variable which is very coarsely discretized with m 10 possible states and only n 10 time instances already has 10 billion possible state trajectories a powerful method for overcoming this computational burden is dynamic programming bertsekas 1995 the method is based on the notion that the optimal control problem is solved backwards by computing the minimal costs j k x k for each time and state starting with k n therefore j n x n f n x n is solved first for all possible x n the process is then repeated for k n 1 down to 1 18 j k x k min u k ε u k x k e l k x k u k ε k j k 1 x ˆ k 1 where u k x k is the admissible region of control comparable to the previously mentioned constraint b x t u t 0 the first term on the right of equation 18 represents control costs between time instance k and k 1 and the second term represents the costs associated with the newly predicted state x ˆ k 1 which was already computed this process of backward recursion reduces the computational load from n m to only m n cost optimizations as the number of states increases however computational complexity can still increase quite rapidly if each state is discretized into m parts optimizing for a model with d states requires m d n cost optimizations in order to achieve further reductions in computational time approximative algorithms such as limited look ahead policies and rollout algorithms have been developed bertsekas 1995 in addition to high computational demand another potential disadvantage of this method is the assumption of white noise although white noise can be transformed into auto correlated noise it requires extending the number of states d and consequently the computational load 4 2 4 summary the most important advantage of mpc over feedback control is the ability to anticipate changes in external input not to be confused with disturbances in addition mpc is quite flexible as it was designed for non linear time varying systems and boundaries on input and state it is nevertheless subject to potential disadvantages as well the changes in external input must be predicted thereby introducing forecast errors that may have a negative influence on performance the control actions are based on model predictions which makes the performance more reliant on model predictions than on feedback control which increases the impact of modelling errors taken together the choice for mpc instead of a feedback or feedforward controller requires balancing their general advantages and disadvantages the main advantages and disadvantages of the mpc methods discussed in this section are summarized in table 3 5 discussion and conclusions most of the observation and control methods discussed in this overview have been designed according to a systems model a model based approach requires some level of investment in model development the benefit of such approaches is that they allow the a priori analysis of how an observer or controller will perform i e before applying it in reality and of what might be needed in order to improve the performance for example in the case study for section 3 see supplementary material increased prediction accuracy is needed in this section we discuss the relationships between the methods discussed in this paper as well as the types of tasks and skills that they can serve we then present a design procedure based on these methods 5 1 relationship between tasks methods and cognitive skills the role of farmers has evolved through advances in technology and machine intelligence in high tech farms the eyes ears and noses of farmers are replaced by sensors and cameras and their hands and tools are replaced by actuators their brains which perceive and process information in order to take operational management decisions is assisted or even replaced by machine intelligence the methods discussed in this paper can be linked to several essential cognitive skills that make up the machine intelligence required to support farmers the systems model represents the knowledge that is needed in order to fulfil the task of predicting how a system will respond to input such knowledge can be seen as a cognitive skill for model based observation and control the cognitive skills and their relationships to the types of methods discussed in this paper are summarized in table 4 multiple types of methods are available for each task as demonstrated by the illustrative case studies however despite a multitude of methods and types of methods not every management task constitutes a problem with a straightforward solution this is because the properties of the methods often do not fully match the management objectives for example the case study on feedback control indicates that lqg control unintentionally punishes good behaviour in that case by bringing the mite population below the critical level whereas a threshold controller involves the undesired trade off between respecting the state constraint and maximizing input efficiency in the mpc case study prediction uncertainty prohibited any guarantee about keeping the state constrained within acceptable bounds in general it is very rare for a method to satisfy all of the desired objectives and to comply with all constraints another reason that method selection is not a straightforward process is the fact that it is very rare for all of the assumptions on which a method is based to be realistic dynamics are rarely linear noise is seldom white and it is only in exceptional cases that perceived costs are a quadratic function of state and input although several methods have been designed under the assumption that no uncertainty exists uncertainty is a prominent characteristic of almost all farming systems in other words there is always some gap between theory and practice this does not mean however that these methods have no validity or that they will automatically yield poor performance whether a violated assumption will be a true disadvantage depends on the extent to which its violation will have a negative influence on predictions observations or control actions as well as on how these aspects will ultimately result in the loss of performance assessing the relationship between the theory practice gap and performance loss is an important frontier in the science of biosystems engineering 5 2 selection and design procedure various types of methods for each management task are displayed in table 4 each type comprises multiple methods each of which has a unique set of properties and underlying assumptions whether these aspects translate into advantages or disadvantages depends on the type of system and the circumstances under which it is operated farming systems vary widely with regard to configuration technology production process and environmental circumstances for engineers therefore selecting and designing the right methodology is likely to be a complex task one important challenge thus involves the configuration of a selection and design procedure as a form of support for engineers the outline of this overview paper suggests a configuration for a basic selection and design procedure fig 7 the first step involves building a systems model based on the available technology and system properties and subsequently designing an observer and then an automatic controller the design or choice of a model depends on relevant system characteristics e g available sensing and actuation technology external input state dynamics constraints and noise and performance objectives as well as on the requirements posed by the subsequent design of an observer and controller for example a given observer may require a linear model and a given controller may require a noise model conversely the choice of an observer depends on the type of systems model available e g in terms of accuracy or the availability of an output equation and the choice of controller depends on type of model available e g whether performance is quadratic as well as on the observer e g the states that can be observed in principle therefore the procedure for designing and selecting the right methodology is not sequential but iterative the three circles depicted in fig 7 can be linked to the various sections of this paper the systems model design steps are discussed in section 2 the observer design methods are discussed in section 3 and the control design methods are discussed in section 4 the associated advantages and disadvantages are summarized in table 1 table 2 and table 3 many other relevant methods exist that could complement the overview presented here including h 2 and h feedback control multi agent control adaptive control model selection and approximation and reinforcement learning an interesting avenue for follow up research could thus be to add to the list of methods in order to compile an elaborate yet comprehensive guide that is accessible to a broad group of engineers 6 summary this introductory overview explains the need for sustainable farming the role of precision technology in modern farming and the demand for automation and decision support within this context it clarifies the role of state observation and control methods in automation and decision support this is followed by an overview of the basic requirements of a systems model which provides the foundation for model based observation and control methods the overview subsequently shifts to a presentation of commonly used observation and control methods along with a discussion and summary of the advantages and disadvantages of each method the methods are then linked to specific management tasks and associated with the cognitive skills that are required in operational farm management finally we present a procedural outline for method selection and design which could serve as a basic guideline to support farming engineers the procedures of model design and method selection for state estimation methods feedback control and model predictive control are illustrated with case studies supplementary material the main outcomes emerging from this overview are as follows 1 prediction observation and control are essential features for operational management support in farming systems section 1 moreover the required cognitive skills that make up the machine intelligence required for automation and decision support are linked to the methods discussed in this paper section 5 1 2 each method presented in this paper has a unique set of possible advantages and disadvantages table 1 table 2 table 3 this has the following implications o farming systems are highly varied in terms of design technology location and performance objectives and these variations translate into a specific set of errors disturbances constraints and performance criteria under which each system is operated the selection of the best method or combination of methods thus requires an assessment for each particular case based on weighing the advantages and disadvantages of each candidate method o many of the advantages and disadvantages stem from a gap between reality and the theoretical assumptions underlying the methods it is quite common for one or more assumptions on disturbances dynamics performance or other aspects to deviate from reality as illustrated by the case studies thus possibly resulting in a loss of performance in practice the relationship between this theory reality gap and possible performance loss therefore constitutes an important aspect of biosystems engineering 3 in theory the procedure of designing and selecting the model observer and controller is not sequential but iterative this stems from the fact that model selection depends on observer requirements while observer selection depends on model properties similar dependencies exist between observer and controller as well as between controller and model fig 7 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank dr gjerrit meinsma twente university netherlands david katzin msc wageningen university and research netherlands dr rachel van ooteghem wageningen university and research netherlands and prof michel vellekoop university of amsterdam netherlands for useful discussions and insightful reflections appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105031 
25846,a challenge in modern farming is to find a sustainable way of achieving sufficient production precision in dosage timing and allocation of water biocides fertilizer and other inputs is essential as are such management actions as harvesting pruning and weeding despite the increasing availability of sensor and actuator technologies decision making is still largely left to the farmer this is creating a strong demand for support in operational management this paper presents an overview of methods involving the use of technology and data to develop model based management support and automation for productive and input efficient farming for each method the main advantages and drawbacks relating to typical farm characteristics are discussed and summarized three case studies are presented to illustrate the design steps involved in developing a model observer and controller the overall design procedure is summarized in a flowchart and serves as a basic guide for method selection and model development keywords modelling observation control precision farming disturbances errors 1 introduction during the 1950s and 1960s farming was intensified in order to meet the growing demand for food in the developing world after the second world war the main mission of this green revolution was food security and its objective was to achieve sufficient production rates at affordable costs the intensification of food production was made possible by extensive research and development on high yielding crop varieties agrochemicals biocides chemical fertilizer mechanization breeding and controlled water supply the green revolution arguably saved billions of people from starvation while increasing human prosperity tremendously at the same time however it was accompanied by serious adverse consequences for human health and the environment mason 2003 innes 2013 due to the large scale use of fossil fuels fresh water fertilizer pesticides and antibiotics moreover there has been a decrease in the availability of resources including arable land oliver et al 2013a b oil reserves phosphates for fertilizer and fresh water another resource that is becoming increasingly scarce in the primary food production sector is human labour development 2019 furthermore the intensification of livestock farming using inexpensive affordable production systems is often in conflict with requirements relating to animal welfare and health berckmans 2014 combined with a rapidly growing world population which is projected to increase from 7 billion in 2011 to an estimated 9 billion by 2050 modern farming in its current form is unsustainable in terms of resource availability human health animal health and the ecological carrying capacity of the planet pimentel and giampietro 1994 a green engineering approach that can help to minimize labour input pollution waste animal discomfort and the depletion of resources dorf and bishop 2011 is needed precision farming also known as intelligent farming site specific farming or smart farming is one such approach 1 1 precision farming modern large scale farms are characterized by the uniform application of inputs for example in the field it is common practice to distribute water fertilizer and pesticides uniformly regardless of variations in soil properties crop density or crop needs in greenhouse cultivation it is common practice to maintain constant indoor temperature levels day and night in dairy farming cows are usually fed rations based on an average cow and a specific average daily production and they are milked at fixed time intervals precision farming is a means of primary food production through precisely controlled input and management actions along with precise monitoring also known as state observation which is enabled by technological solutions auernhammer 2001 day 2005 all precision farming operations input actions monitoring incorporate one or more levels of precision in terms of dosage timing or spatial allocation e g by location group or individual within the wide range of available precision farming applications three main domains of application can be distinguished these domains are described below precision agriculture pa this concerns open field systems for crops like maize grain and potatoes the objective within this domain is to increase resource efficiency in arable farming by applying inputs according to site specific crop demands oliver et al 2013a b this is accomplished through the precise management of inputs e g water fertilizer pesticides and actions e g weeding harvesting examples of pa include controlled drip irrigation prathyusha and suman 2012 automated seeding the precise application of manure and pesticides and robotic weed control slaughter et al 2008 precision horticulture ph this concerns open systems e g orchards and protected systems e g greenhouses vertical farms the objective of ph is to exercise precise control over inputs for crops e g climate and light conditioning water fertilizer actions e g pruning harvesting are performed according to the status of individual plants or fruits e g amount of leaves ripeness through technological solutions like robotic harvesting hemming et al 2014 precision livestock farming plf this concerns production systems for animals e g cattle poultry fish føre et al 2017 and algae the objective of plf is optimize resource efficiency and animal welfare berckmans 2017 inputs e g feed antibiotics veterinary treatments are applied according to the needs of individual animals examples of plf technologies include robotic cow milking livestock health monitoring berckmans 2014 automated monitoring and control of broiler growth aerts et al 2003 the feeding of individual cows halachmi et al 1998 indoor climate conditioning automated incubators for egg hatching and the camera based estimation of animal weight song et al 2018 the fine tuning of inputs based on the time dependent location specific and individual needs of crops and animals can yield considerable savings in resources the following are several examples pa precise dosage control based on crop monitoring resulted in fertilizer savings of 23 while improving grain yield by 4 zhang et al 2002 ph in greenhouse cultivation time dependent climate control based on fluctuations in outdoor climate has been associated with savings of up to 47 in heating energy van beveren et al 2015a b plf the optimization of milking intervals for individual cows has been associated with increases of up to 25 in milk production andré et al 2010 one functionality that is common to all domains of precision farming is pest management in an extension to primary food production post harvest management precision technology is employed in such operations as automated quality monitoring selection packaging and air conditioning during storage and transport of produce in addition to uniform input risk avoidance can lead to the over application of inputs variable circumstances e g weather soil properties disease load and the physical condition of animals and crops make it challenging to make precise estimates of how much input is needed and how the amount of input is linked to the risk of under application the easiest way to decrease the risk of production loss due to pests or malnutrition is to make slight increases in the minimal dosages of pesticides fertilizer and other inputs stuart et al 2014 given that risk mitigation is rarely balanced rationally kahneman 2003 however farmers tend to have excessive risk avoidance attitudes anderson and dillon 1992 uncertainty about how much input is actually needed combined with the tendency to avoid production loss risks can lead to severe over application for example worldwide irrigation efficiency is estimated to be only 37 thus implying a loss of 63 due to runoff and drainage wallace 2000 possible ecological consequences of such inefficiency include the massive use of fresh water from rivers and aquifers and the leaching of chemicals and nutrients into groundwater due to drainage 1 2 automation one way to improve labour efficiency is to automate the operational management loop also known as the cyber physical management cycle verdouw et al 2013 automation can also help to avoid unnecessary risk mitigation by human operators and it can serve as a reliable means of precision management making it possible to attain a predefined level of product quality and harvest timing as illustrated in fig 1 four stages of automation have been identified traditional management by hand manual control supervised control fully automatic control as the management loop advances towards automatic control farmers receive more support from and become more reliant on technology and automation in traditional farming systems farmers perform all management tasks themselves both physically in terms of perception and actuation and mentally e g making decisions on input management in manually controlled system farmers perform all of the decision making themselves assisted by actuation and possibly sensing technology e g soil moisture sensors irrigation devices this type of control is typical of developing countries in supervised control systems farmers are assisted by low level controllers that operate autonomously according to the settings and set points specified by the farmers e g water dispensers that keep soil water near the desired level these systems also allow farmers to utilize sensor information on system states of interest e g soil water content and to anticipate future events e g precipitation based on forecasts this type of control is typical of high tech agricultural systems in developed countries in automatically controlled systems farmers are no longer involved in the management loop examples of such systems include milking robots feeding systems and autonomous climate control systems it must be noted that supervised and automatic control are not always clearly separate classes for example in many automatically controlled systems farmers are still able to overrule automated management actions or change system settings or set points furthermore automatic control is not always preferred over supervised control for at least two reasons 1 farmers prefer to remain involved in high level management and 2 for some applications control algorithms that outperform farmers have yet to be developed 1 3 decision support decision support can be provided in three different forms observation of the current state of the system to help farmers take appropriate action computers may be used to help provide diagnoses by observing the current state of particular systems e g the climate inside a greenhouse the water level in the soil the health status of an animal prediction of how the process will respond to input and of the corresponding performance for example predictions concerning yield or energy requirements can assist in the selection of appropriate climate set points in greenhouse management control algorithms that schedule input under specific management objectives e g high yield low resource use they can be used to achieve fully automated processes or to provide advice in some respects these types of support are cumulative observations of current system states e g indoor greenhouse climate animal health status can provide the initial conditions for model predictions concerning how those states would develop under different forms of input management subsequently control algorithms employ model predictions to optimize input management fig 2 provides a closer view of the supervised control scheme depicted in fig 1 more specifically it illustrates the role of prediction observation and control advice as a form of decision support the diagram shows two feedback loops a low level management loop with input consisting of the machine settings and set points to be tracked as provided by users and a high level management loop in which users are supported in the high level management loop user support consists of automatically generated state observations predictions of system response or control advice concerning input management e g advice on climate set points decision support systems can use sensor information about current states e g the climate inside and outside a greenhouse or forecasts e g weather or market prices in order to optimize input scheduling in anticipation of future events within this framework this paper discusses methods of observation prediction and control the methods are based on a systems approach using systems models various methods are addressed separately in the following sections case studies on three different farm management applications were conducted one for each section the actual case studies are included in the supplementary material 2 building a systems model farming systems generally involve many components in complex dynamic interaction with each other thereby forming intricate interaction networks these components are subject to the influence of multiple inputs some of which are controlled while others are not a systems model creates structure by describing the components as process variables and by describing their dynamic responses to changes in input as described in section 2 1 a predictive systems model can be designed to improve input scheduling in scenario studies in which the insight obtained into the system s input response contributes to the development of practical management guidelines for example this has been done within the context of greenhouse crop cultivation vanthoor et al 2011 pest management mul et al 2017 and irrigation scheduling mondaca duarte et al 2020 as described in section 2 2 the structure of a systems model can be extended with additional equations that describe relationships between states and that measure output input and state constraints as well as performance and systematic disturbances this extended structure forms a foundation for state estimation methods and control methods as described in sections 3 and 4 2 1 predictive model this section provides a brief overview of the key elements that make up a predictive systems model such a model can be derived in several different ways depending on the type of information available a first principle model also known as a mechanistic white box or process based model is composed of underlying biological chemical or physical principles keesman 2011 examples of first principle models comprise crop and animal responses to nutrients and environment fluid dynamics e g to describe climate dynamics in greenhouses and barns or to describe fluid transport in algae reactors actuator dynamics e g in greenhouse technology irrigation and harvesters population dynamics e g for fish and pests and classical mechanics e g to describe the motion of tractors robots and drones descriptive models also known as black box or non mechanistic models are generic models that are not derived from first principles but that describe processes based on data examples of descriptive models include linear regression models neural networks and auto correlation models e g arx narx armax chen and zhao 2014 in this overview we make no assumptions concerning the type of models used for the model based observation and control methods although the models can be either mechanistic or non mechanistic they are all assumed to have structures as described in this section 2 1 1 input state dynamics farming processes are characterized by a dynamic input response for example the effect of irrigation input on crop growth is not immediate but may span several days or even weeks this makes the scheduling of input over time a non trivial problem in addition to the inputs that are controlled other inputs might not be able to be controlled but should be anticipated e g precipitation solar radiation in a predictive systems model the process dynamics and various types of input are formulated systematically one core principle of systems theory is that each system has a specific boundary input and state the system boundary is determined by defining the state variables within the system and the input variables that enter the system from outside and that affect the state dynamics a general formulation to describe the input state dynamics in a continuous form is as follows 1 d x t d t f x t u t ε t θ t in this equation x t is the state vector that changes over time t with some initial condition x 0 x 0 the state vector can contain variables like temperature and humidity although it could also include spatial information to make the model specific to a given site e g a temperature variable subdivided into temperature at various locations the time derivative of the state equals f a non linear function describing the interaction between states and how the states respond to the input the rates of change and the strengths of the interactions are represented by the values of the model parameters in vector θ the control input u t can be manipulated and it is used to control the state dynamics the external i e uncontrollable input ε t can often be observed and in some cases its dynamics can be predicted but it cannot be manipulated the final argument of function f is time t which acts as an independent variable representing changes in system response over time e g changes in biological development stages that have not already emerged from the modelled state interactions 2 1 2 model complexity organisms e g animals and crops are inherently complex within an organism physiological chemical and physical processes at the level of tissues cells and molecules form extensive interaction networks that govern input responses that are almost always non linear e g doubling a feed ration does not generally double milk production whereas physical processes e g mass and heat transfer are often relatively linear while the chemical processes underlying physiological input responses e g photosynthesis food digestion are typically non linear model complexity is a design aspect that poses an important trade off very simple models are easy to derive and they require little computational effort for control design at the same time however over simplification may introduce model errors that have a negative influence on the accuracy of predictions although the development of more advanced more complex models may improve prediction accuracy it may also require considerable experimental and field work knowledge acquisition and modelling expertise not all state estimators and control algorithms are designed to address high levels of model complexity furthermore increasing complexity usually increases computational demand another possible drawback of high model complexity has to do with the large number of parameters which increases the likelihood that the values of some parameters will be difficult to determine 2 1 3 parameter estimation when a parameter value is unknown or uncertain a common solution method is to estimate the maximum likelihood value based on available data the likelihood of a parameter vector θ is obtained by comparing the predicted model state at discrete time instances shorthand notation x θ k with a time series dataset of measured state x d a t a k in this calculation k is an index representing discrete time instances t k δ t with δ t representing the time step size and k 1 n assuming that the measurement errors are modelled by additive gaussian white noise with covariance matrix r k 2 x d a t a k x θ k v k with v k n 0 r k n denotes a normal distribution the likelihood function of parameter vector θ is then as follows 3 l θ x d a t a e x p k 1 n 1 2 δ x k t r k 1 δ x k where δ x k x d a t a k x θ k the maximum likelihood is obtained by θ m l the value of θ that maximizes θ x d a t a many optimization algorithms are available for retrieving θ m l for relatively simple models where y is a linear function of θ e g a linear regression model the maximum likelihood can be computed directly through least squares estimation in general θ m l is approximated through iterative algorithms that evaluate multiple parameter values and compare their likelihoods two classes of algorithms can be distinguished gradient based algorithms and evolutionary algorithms gradient based algorithms search the parameter space by following a path along which the objective function l has the strongest increase gradient examples include the newton raphson and the levenberg marquardt kelley 1999 algorithms the advantage of these methods is that the use of gradients reduces the number of iterations required thereby increasing computational efficiency this is a crucial advantage especially for complex models with large integration times given the need to integrate the model for each iteration in order to obtain l one possible drawback is that when multiple local optima exist there is no guarantee that the global optimum will be found evolutionary algorithms use a population of candidates for θ m l the values of which evolve through some stochastic evolutionary process this stochasticity combined with the use of multiple candidates increases the likelihood of finding the global optimum one general drawback of evolutionary algorithms is that they tend to require a relatively high number of model integrations parameter estimation is a well established discipline with many good textbooks available for interested readers 2 2 additional equations for observation and control methods this section describes additional equations that are useful for making predictive models compatible with the observation and control methods described in sections 3 and 4 2 2 1 output dynamics sensing technology enables automated and dynamic measurements of system states that are of interest it is important to note however that not all states can be measured directly for example the measurement of animal stress by sampling blood cortisol levels is an invasive method that is not very practical in such cases indirect measurements are performed the sensor measurements y are related to the state vector through the following output equation 4 y t g x t θ where g is a function depending on the state vector x and some of the parameters contained in vector θ for example an output function can relate a cow s resilience against disease to measured body temperature lying time and eating patterns van dixhoorn et al 2018 fig 3 shows a flow diagram of a system model represented by equations 1 and 4 the input state output structure makes it possible to close the management loop by applying a controller that connects the measured output to the control input 2 2 2 constraints system states may attain critical points at which the system becomes fragile meaning that its dynamic response can become highly sensitive to slight changes in input at critical points a state can shift to an undesired steady state organisms can attain a multitude of steady states e g healthy and sick vegetative and generative alive and dead fresh and spoilt in animals with low resilience an increase in stress or disease load e g from over stocking can have a major impact on health van dixhoorn et al 2018 growth and milk or egg production in crops a combination of large amounts of sun and low water supply results in wilting or even death if the interactions underlying such tipping events are not modelled explicitly it is important to identify the constraints of state and input under which a process should be operated in order to avoid them another constraint is actuation capacity which is almost always bounded for example the capacity of an air heater and the maximum rate of a harvester depend on type of equipment used and they are always limited to some level although some control algorithms assume that both positive and negative actuation is possible this is not always the case for example an irrigation system can apply water but it cannot extract it to describe the constraints on x t and u t that are needed in order to avoid unwanted steady states or the exceedance of input capacity constraints are introduced in the form of a given set b of algebraic inequalities 5 b x t u t 0 2 2 3 performance sustainable farming is characterized by inherently conflicting objectives typically high production rates vs low input use the importance of all objectives should be carefully balanced in order to arrive at suitable control advice to this end the model can be extended with a performance measure usually referred to as a performance criterion j which can be described as some function h depending on state input and time 6 j h x t u t t more specific formulations of j are presented in sections 3 and 4 to make input selection straightforward performance is usually represented by a scalar value when there are multiple performance objectives the variables corresponding to these objectives can be assigned weights according to their importance e g performance equals the production rate minus 3 times the input rate the objectives are represented mathematically by various indicators such as energy efficiency health deficiency van dixhoorn et al 2018 the animal comfort index fournel et al 2017 and the damage rate during fruit or egg transport van mourik et al 2016 2 2 4 disturbances and errors farming systems are affected by disturbances from outside the system as well as by errors from within the system which lead to uncertainty in observations and predictions consequently this may lead to severe performance loss a disturbance can be seen as an unforeseen variation or fluctuation of factors coming from outside the system that affects the dynamics of the system and the certainty with which they can be predicted dorf and bishop 2011 examples of disturbances include unexpected fluctuations in weather pest occurrence and disease load disturbances related to sensing technology include incoming sunlight and dust particles in the air sanderink et al 2017 economic disturbances e g in commodity or product prices constitute a somewhat different category which can also affect the performance j due to their often stochastic nature the uncertainty that disturbances cause is also referred to as stochastic uncertainty walker et al 2003 an error can be regarded as a factor from within the system that causes its dynamics to deviate from expectations errors related to biophysical system properties include unexpected developmental changes biological variations between individual plants and animals and spatial variations in air conditions and soil properties errors related to sensing and actuation technology include those occurring due to poor sensor or actuator calibration wear and tear signal delay jawad et al 2017 and spatial variations e g temperature sensors located in cold areas in control engineering errors in sensor signals and actuators are referred to as noise dorf and bishop 2011 for purposes of observation and control the uncertainty caused by disturbances and errors is commonly modelled as stochastic noise the following is an example of discrete time process with stochastic noise 7 x k 1 f k x k u k ε k θ w k at each time instance k the state noise w k consists of independent draws from some distribution d w k d 0 q k with q k the covariance matrix describing the statistical interdependency between individual noise signals in this example the noise is assumed to be additive because of the sign the representation of stochastic additive noise in state dynamics as well as in the output equation 8 y k g x k θ v k with v k n 0 r k is a standard way of modelling uncertainty for model based filtering and model predictive control methods like kalman filtering and lqg feedback control are based on white noise entering the system when the state noise is not white in terms of frequency but exhibits auto correlation this can be modelled by representing white noise entering the system and adding a pre filter within the system see section 3 1 that transforms the noise before it enters the state dynamics 3 state observation the ability to observe a system state e g greenhouse climate animal condition crop state is of great importance to precision management the prediction accuracy of future state trajectories depends largely on the accuracy of the current state estimate current states can be estimated with models through the use of sensing technology or through a combination of these methods several different methods are discussed in this section 3 1 data based state estimation system states can be estimated according to data streams obtained with sensor technology three common methods for this purpose are frequency based filtering soft sensing and machine learning 3 1 1 frequency based filtering one common way of filtering out sensing noise see equation 8 involves frequency based filtering if it can be safely assumed that the sensing errors are in a different frequency range than the true dynamics the errors can be filtered out based on their frequencies for example a low pass filter passes the low frequency dynamics in the sensor signal and filters out high frequency dynamics associated with sensor noise a high pass filter does the opposite a band pass filter passes signals only within a certain bandwidth for example low pass filters have been employed in order to smooth climate sensor data in greenhouses rodríguez et al 2015 a band pass filter has been employed for automated crop row location and tracking hague and tillett 2001 3 1 2 soft sensing in addition to sensing errors limited observability can occur because the states of interest cannot be measured directly or because direct measurements are too costly or time consuming in such cases indirect measurements are performed when an output function equation 4 is available and invertible the state can theoretically be estimated from the sensor measurements applying the following conversion 9 y t g x t into x t g 1 y t this method is also known as soft sensing a calibration curve that relates humidity x to measured electrical conductance y is an example of state estimation through an inverted output function when y consists of multiple sensor signals finding the relationship between the signals and the state of interest is done in a process known as sensor fusion one example of sensor fusion involves finding the relationship between soil properties using a combination of spectroscopy electromagnetic induction and ground penetrating radar mahmood et al 2012 one important challenge is to identify which data streams contain relevant information and how to combine them 3 1 3 machine learning in many cases no output equation is available measured traits such as the shape song et al 2019 colour kurtulmus et al 2011 odour mottram 2016 and behaviour berckmans 2014 of vegetables fruits or animals are usually difficult to relate mechanistically to such states as ripeness freshness condition and health data based models can be used to classify system states e g a plant inside the cropping system is either a weed or not a weed a crop is either fresh or spoilt an animal either is or is not in good health various classification models for data based machine learning have been developed including logistic regression support vector machines and linear and quadratic discriminant analysis one advantage of these models is that they do not require knowledge on the mechanics underlying specific processes at the same time however this feature also prohibits the analysis of how underlying mechanics affect the system e g for error analysis and in design studies furthermore training sets must be carefully selected and the systems should be tested on independent test sets or through cross validation in order to prevent over fitting for high dimensional data e g imaging data it is even more challenging to link states to sensor measurements one standard approach involves abstracting the data in order to obtain a lower dimensional representation in image processing this is known as feature extraction which consists of a series of image processing steps gonzalez et al 2004 the features form an abstract representation of the image data e g the colour shape and texture of tomatoes in an image which might be indicative of the ripeness stage one common approach involves using manually designed feature extractors with a machine learning approach as process based models are often incapable of estimating states from these abstract features the relationships are too complex to be modelled from first principles instead machine learning methods can unravel the relationships based on a set of training examples e g images of tomatoes with associated ripeness values one disadvantage of this approach is that the feature extractors are still designed manually recently developed deep learning methods are able to address this by presenting an end to end learning approach in which the state can be estimated directly by deep neural networks based on the raw images goodfellow et al 2016 these networks optimize both feature extraction and state estimation within a single common framework based on a large training set the deep learning approaches have been shown to outperform classical image processing in many domains including agriculture kamilaris and prenafeta boldú 2018 in this paper we focus on process based methods for additional background information on machine learning see friedman et al 2001 3 2 data assimilation sensor information can be combined with model predictions in a process known as data assimilation the reasoning behind this process is that both model predictions and measurements contain errors the merging of model and sensor information results in higher estimation accuracy than is possible with measurements or predictions alone 3 2 1 static filter one basic method of data assimilation involves estimating the state of interest by weighing the state prediction according to the model x with the measured state assuming for now that the state can be directly measured y with weighting factors based on the uncertainty with which the state is predicted σ x 2 and the uncertainty of the measurement σ y 2 this results in the following estimator gelb 1974 10 x σ y 2 x σ x 2 y σ x 2 σ y 2 the weighting factors can be interpreted intuitively for example if the measurement is highly uncertain σ y 2 is large and x therefore receives a higher weight the denominator acts as a normalization term such that all weights add up to 1 this method is suitable for estimating the state once e g when x is the outcome of a dynamic process 3 2 2 dynamic filter when the state is tracked over time the estimation problem becomes more challenging as the estimated state should be updated repeatedly according to new measurements a dynamic filter operates in a continuous loop using the measured input and output of the process to make a state estimation x ˆ t fig 4 shows a flow diagram of a dynamic state filter several dynamic filters are discussed in the following sub sections 3 2 3 kalman filter perhaps the best known model based dynamic filter is the kalman filter the design of which is based on equations 7 and 8 the assumptions for a standard kalman filter are that the state function f and output function g are linear and that state and output noise is white and normally distributed under these assumptions the filter produces a maximum likelihood state estimate x ˆ k together with its probability distribution as represented by its covariance the state estimate minimizes the expected root mean squared error between the estimated and actual state the estimated state becomes the starting point for the model prediction at the next time instance to estimate the state the algorithm weighs the measurement and its uncertainty v k against the model prediction based on the current state estimation and state noise w k in a manner similar to equation 10 in addition however it considers the uncertainty associated with the previous state estimation and updates it accordingly consequently greater uncertainty in a state estimation calls for the assignment of greater relative weight to the sensor measurement at the next time instance and vice versa this prevents unwanted bias effects for example if the model has a small positive bias each new state estimate will be slightly too high and over time the model state will tend to drift away from the true state due to the increasing discrepancy between measurements and predictions however the state uncertainty and thus the model prediction uncertainty will increase thereby reducing the weight of model predictions as a result the filter tends to drive the state estimates back towards the sensor measurements one straightforward way to estimate the covariance matrix q in equation 7 is to assess the error between model predictions and measurements over a series of time this method nevertheless requires the state to be directly measurable the covariance matrix r in equation 8 can be estimated based on the differences between output and model predictions if accurate values for state and input are known or it can be based on factory specifications about the accuracy of the sensor the reliable estimation of q and r imposes several requirements on state measurements if these requirements cannot be met autocovariance least squares methods can be employed rajamani 2007 one strong assumption on which the kalman filter algorithm is based is that the noise is white more specifically the algorithm is based on the assumption that signal errors are not auto correlated and that all frequencies are attained in a uniform manner although the invalidity of this assumption does not necessarily mean that the kalman filter will not work julier et al 2000 such issues should be approached with caution if non whiteness forms a bottleneck to filter performance pre filtering can be employed in pre filtering the model is extended with augmented model states that transform white noise into coloured noise which subsequently enters the process dynamics and output measurements salzmann et al 1991 kalman filters can be used in a wide range of farm management tasks including the estimation of greenhouse climate and crop states lópez cruz et al 2017 van mourik et al 2019 location estimations for agricultural vehicles gartley and bevly 2008 health monitoring in dairy cattle de mol et al 1999 and water level monitoring in fish farms ullah and kim 2018 state estimation by kalman filtering also forms a part of the lqg control algorithm section 4 1 4 3 2 4 extended and unscented kalman filter one key assumption is the linearity of the state dynamics and output function the extended kalman filter was designed to address non linearity by linearizing f and g at each state update grewal and andrews 2014 such linearization is required in order to compute the propagation of state uncertainty in a straightforward and computationally efficient manner the extended filter also introduces linearization errors however as well as errors relating to the assumption of symmetric error distributions the unscented kalman filter was designed to circumvent these types of errors julier et al 1995 this filter uses a sampling method that retains the non linear transformation f intact unscented by sampling the state covariance with a few sampling points i e sigma points the unscented kalman filter also contains three design parameters that can be adjusted to address state probabilities that are not normally distributed 3 2 5 particle filter all of the aforementioned kalman filters assume that the states have unimodal distributions this assumption is not always realistic consider the following example to estimate its location an autonomous vehicle uses a model based on wheel rotation speed and steering action with gps as a location sensor when the vehicle is in front of a tree it may assign high probability densities to several locations that are close to trees on the orchard map while assigning low probabilities to locations between trees this results in a multimodal density of location probability this state cannot be represented using a gaussian distribution as is the case with the kalman filter the particle filter therefore represents the state estimation with a large number of weighted particles thus allowing multi modal probability density functions this comes at the cost of computation however as it requires the transformations f and g to be computed for each particle at each state update the computational demand thus depends largely on the number of particles used and the computational demand for evaluating the functions f and g for example particle filters have been designed for localization within such repetitive environments such as orchards bayar et al 2015 and barns vroegindeweij et al 2016 3 2 6 dual estimation similar to online state estimation model parameters can be adjusted online as well the difference between this method and the parameter estimation described in section 2 1 3 is that online state estimation is performed on a single system or subject whereas parameter estimation often uses experimental data on a large number of subjects the simultaneous estimation of parameters and states is known as dual estimation liu and gupta 2007 and it has been used for estimating greenhouse climate speetjens et al 2009 and soil moisture lü et al 2011 another online adaptation method is bayesian forecasting west and harrison 2006 which estimates current states and parameters in addition to predicting future states according to bayesian principles although the basic principles are similar to those underlying kalman filtering bayesian forecasting is more extensive e g due to the use of discount factors that assign higher weight to current data than to older data one potential drawback of dual estimation stems from the additional flexibility introduced by parameter adaptation more specifically although it decreases bias it may increase variance in model predictions and controller performance up to the point of instability rohrs et al 1985 the bias variance trade off is a well known design principle in statistical learning friedman et al 2001 3 3 summary the main advantages and disadvantages of the state observation strategies discussed above are summarized in table 1 different methods are associated with different advantages relating to model requirements the necessity of addressing non linearity multimodality and non gaussian error distributions they are also associated with possible disadvantages relating to assumptions concerning error properties and computational costs the optimal choice of filter therefore depends on the particular observation problem at hand as well as on the key advantages and disadvantages and how they weigh against each other for example if a process model is non linear and exhibits a non gaussian state distribution a particle filter might be preferred if simulations are computationally demanding however the need for a more time efficient method might outweigh the choice of a particle filter 4 control design using a systems model a controller can be designed to determine the input that would optimize performance through precise timing and dosages of inputs and actions two different means of control can be distinguished feedback control in which control actions are based on current and past system states and model predictive control in which control actions are based on both current states and expected future events 4 1 feedback control the aim of feedback control is to steer the state in order to track a reference signal for example climate variables in a greenhouse should be close to a set point chosen by the grower or a vehicle should follow a set path the design of signal tracking control focuses on minimizing tracking errors the difference between a state and a desired set point attenuating disturbance and maintaining stability in the process dynamics dorf and bishop 2011 the basic structure of feedback control consists of a system that is connected to a controller through sensors and actuators the controller receives sensor information about the state or states of interest and these measurements are compared to the reference signal that the system state is intended to track the difference between the measured signal and the reference signal is used to compute the subsequent control actions this is usually done in a continuous fashion forming a closed feedback control loop fig 5 one general benefit of a feedback control loop is the ability to react directly to tracking errors a feedback controller adjusts the input based on the current state and in some cases on the past state trajectory using integrating action see section 4 1 1 it nevertheless does not anticipate future events this is done in model predictive control see section 4 2 the types of feedback control that are most relevant to farming operations are discussed below 4 1 1 proportional integral derivative control proportional integral derivative pid controllers are perhaps the most commonly used control algorithms in operational farm management examples include path tracking and suspension control yu et al 2004 for autonomous vehicles climate control in greenhouses li et al 2018 and barns niu 2014 depth control in soil measurements mouazen et al 2005 and water pressure control in irrigation systems goodchild et al 2018 in the abbreviation pid the p stands for proportional action a direct response on the tracking error the i stands for integrating action the adjustment of input based on the history of the tracking error and the d stands for derivative action the response to the trend in the tracking error a pid controller can be expressed as follows 11 u t p e t i 0 t e τ d τ d d e t d t where e t r t x ˆ t is the tracking error with the reference value r t representing the desired set point trajectory and x ˆ t representing the estimated current state the proportional action first term provides a controller input u t which is aimed at steering the system state towards the desired set point proportional action alone however may result a steady state offset for the state the integrating action middle term enables the controller to attenuate low frequency errors and disturbances that cause an offset in the state for example consider a heating system that should keep the temperature inside a greenhouse at 20 c suppose that due to an actuator error the room is not sufficiently heated and the temperature reaches only 15 c this means that the state has an offset of 5 c which may be somewhat decreased but not completely eliminated by the p action the offset will result in a steady increase in the integral term over time consequently the heating input will increase and the offset will ultimately disappear one possible disadvantage is that the integral term may respond slowly to changes in tracking error or lead to instability the derivative action last term is proportional to the changes in tracking error and it typically speeds up the system response caution is needed however as the derivative term can be highly sensitive to violently fluctuating derivatives due to noisy measurements these fluctuations might cause violent input dynamics that in turn might have a negative influence on stability actuator wear and tear and resource efficiency these fluctuations can be attenuated by first filtering the tracking error with a low pass frequency filter the trade off is that a low pass filter delays the signal in addition it is important to be careful not to filter out true signal information a controller with proportional integral or derivative action or some combination thereof can be tuned by loop shaping techniques that balance sensitivity to tracking errors with typically low frequency dynamics with robustness against input disturbances with typically high frequency dynamics using frequency analysis tools e g the bode plot and nyquist diagram bode nyquist based techniques can also be employed to design controllers with additional robustness against non linearities and modelling errors one important advantage of pid controllers is their simplicity they can be tuned according to measured input output response without the use of a process model for example this can be done for a system with single input and single output according to the ziegler nichols tuning rules one possible disadvantage of pid control is reduced performance due to the simplification of assumptions concerning the actuators in equation 11 the controller assumes that actuation can be performed either continuously or at every discrete time instance it is important to note however that this is not always the case for example it might be possible to irrigate a field only once every three days as there is only one sprinkler system that is used on multiple fields another assumption is that actuators can dose gradually in practice however most lamps fans and heaters can only be switched on or off one possible solution in the case of an on off actuator is to allow the controller to be switched on or off at a high frequency while controlling the percentage of on time with a pid controller pwm pulse width modulation for example one such controller was designed for a temperature controlled food storage room mourik et al 2010 as indicated in equation 11 u t is a symmetric function of e t the input can thus be either positive or negative depending on the sign of the tracking error in reality however input can often only be added and not subtracted as is the case for irrigation water or pesticides this can result in a problem known as wind up for example if the soil moisture level is too high a controller can do nothing but wait until enough water has evaporated or drained in the meantime however the integral term will have accumulated to a high value for this reason even after the water level has dropped the high integral value will prevent the controller from taking action such integral wind up behaviour has been well documented and various anti wind up approaches have been described in the literature azar et al 2015 equation 11 applies no constraints on the input and state a soft constraint may be imposed by choosing the values for p i and d in such a way that the input or state will seldom if ever exceed a certain maximum or minimum value it is possible to tune pid by loop shaping and not only by model free empirical tuning this can be done even for systems with multiple inputs and multiple outputs xiong et al 2007 in addition some pid design algorithms take input efficiency into account as control objective comasòlivas et al 2012 4 1 2 feedforward control given that feedback control acts upon tracking errors caused by disturbances that affected the process dynamics at some time in the past in principle it will always lag behind feedforward control acts directly upon those disturbances by measuring them online and determining the required control input based on a model feedforward control is often used in combination with feedback control one advantage of feedforward action is that it gives the controller the opportunity to react to disturbances immediately rather than awaiting a system response and then acting upon it especially for systems with a slow response e g in crop or animal development feedforward control may offer a valuable solution in disturbance attenuation one possible drawback is that the disturbances must be measured online such measurements can be costly or difficult to realize and they are subject to measurement errors in addition the influence of the disturbances on the measurements of interest must be modelled the added value of feedforward control therefore depends largely on the quality of the error response model measurement accuracy and response time 4 1 3 lqr control the linear quadratic regulator lqr is designed with the use of a linear model of the system under the assumptions that state dynamics are time invariant undisturbed without external input and linear model 1 is approximated as follows 12 d x t d t a x t b u t where the matrices a and b form a linearized version of function f the control problem is commonly formulated as minimizing the performance criterion j which indicates how well the management objectives e g tracking error and low input costs are met over a time period ranging from 0 to t 13 j x t s x t 0 t x t v x t u t w u t d t the criterion j makes it possible to design a controller that can weigh the costs of tracking errors against the costs of input use the minimization of these variables usually results in a trade off the form of j is quite specific it is quadratic i e it consists of matrix vector combinations all of which yield quadratic terms and time invariant the first term on the right represents the value associated with the state at end time t e g produce value at harvest the contribution of each state within the state vector x t is weighed by matrix s the second term is an integral containing the running costs associated with tracking errors i e deviations of x from 0 weighted with matrix v and the costs of the control input weighted with matrix w as with pid control soft constraints can be imposed on the input and state by tuning the values of v and w under the assumptions that the states can be observed and that the feedback is of the form u t k t x t with k t as the feedback gain matrix the optimal input trajectory is computed by solving the ricatti equations kalman 1960 these equations can be solved relatively quickly through computation as compared to the dynamic programming method required for non linear time variant control problems see section 4 2 3 in addition to this computational advantage another important benefit of lqr is that it is an optimal feedback controller in the sense that it has an explicit performance criterion and it achieves optimal performance one potential drawback however is that this optimum can be achieved only under quite strong assumptions linear input output response time invariance symmetric input input that can be steered continuously over time and in dosage no influence from external input and performance that is represented by quadratic functions of tracking errors and input caution is advised when modelling performance with quadratic functions although economic costs often have a linear relationship with input doubling the input doubles the input costs the relationship between set point deviations and the costs associated with spoilage or production loss may be exponential e g bacteria growth in dairy products depends exponentially on temperature phillips and griffiths 1987 the feedback mechanism in lqr offers some extent of robustness against undesired state deviations by actively steering them back towards the set point this robustness is limited however as there are no errors or disturbances in equation 12 for which the controller is explicitly designed moreover there is no integrating action as in pid control to compensate for offset in tracking error performance in practical situations is therefore heavily dependent on the validity of the assumptions examples of lqr applications include greenhouse climate control gutiérrez arias et al 2015 and dust control in animal housing liao and feddes 1993 4 1 4 lqg control linear quadratic gaussian lqg control is an extension of lqr this extension is explicitly designed to address uncertainty in state and output measurements for this the process dynamics of 12 are extended with an output equation as well as with state and output noise see also equations 7 and 8 14 d x t d t a x t b u t w t y t c x t ν t as with lqr the control action consists of state feedback u t k t x t which optimizes performance with respect to the criterion 15 j e x t s x t 0 t x t v t x t u t w t u t d t solving for the state estimate and optimal input requires solving two matrix riccati equations consisting of differential equations in continuous time and difference equations in discrete time the main differences between the lqg and lqr control problems are that in the lqg problem the performance criterion is minimized with respect to the expectancy e of the costs and the state is estimated through kalman filtering see section 3 2 3 furthermore the weights are time dependent which may facilitate the imposition of soft constraints with regard to the timing of input e g when input can be applied only at specified times input is more likely to occur during these intervals if w is small during designated time intervals and large elsewhere despite the fact that lqg addresses stochastic state and output noise it has no stability margin in other words it cannot guarantee any stable robustness against model errors in the sense that bounded input results in bounded output doyle 1978 for this reason small model error could potentially result in ever growing oscillations in input and state examples of lqg control include heating and ventilation control in greenhouses el afou et al 2013 and active suspension control for agricultural vehicles bo and fan 2004 4 1 5 threshold control some actuators cannot provide continuous dosage but can only be switched on or off in on off control also known as bang bang control the timing of switching is optimized this type of control type was developed for such purposes as the application of crop nutrients hooper 1988 one very basic but commonly used type of on off control is threshold control also known as hysteresis control in this type of control a control action is performed each time a state reaches an upper or lower boundary for example when the temperature in a food storage room gets too high a cooler switches on for some period of time when the temperature gets too low a heater turns on this method of control may result in typical saw tooth state dynamics within a hysteresis band as illustrated in fig 6 one main advantage of threshold control is its simplicity no model is required in addition a threshold controller can be developed relatively easily for systems with asymmetric actuation abilities for example an irrigation system can apply water to the soil but not extract it a threshold irrigation controller was developed that triggered irrigation events based on crop water status thompson et al 2007 threshold control is subject to several possible disadvantages if a system has a slow input response the thresholds could be violated for example if irrigation is stopped right at the moment at which the soil water reaches a threshold value according to an underground sensor water will continue to trickle down through the soil and the water content will increase a bit further furthermore threshold control does not infer high precision the state is located somewhere between two boundaries but it does not follow a precise trajectory precision can be increased by bringing the upper and lower boundaries closer together to create a narrow state bandwidth this might increase the likelihood of threshold violation however and it could cause the state to bounce between the upper and lower bounds for example with the context of heating and cooling this could cause a heater and a cooler to work against each other thereby wasting energy 4 1 6 summary several strategies are available for feedback control each with its own assumptions and properties the main advantages and disadvantages of these strategies with respect to operational farm management are summarized in table 2 as in the selection of a suitable state filter the choice of a feedback controller depends on the particular control problem at hand as well as on the key advantages and disadvantages and the trade offs between them 4 2 model predictive control when future circumstances are known or at least forecast it may be worthwhile to anticipate them through input scheduling for example if the weather will be warmer tomorrow than it is today lowering the greenhouse temperature today could save a considerable amount of heating energy while maintaining an acceptable average temperature model predictive control mpc is the class of control methods for input scheduling while taking future changes into account we start by describing the concept of finite horizon control 4 2 1 finite horizon control in the finite horizon form of model predictive control the input is scheduled for a fixed period of time 0 t this is known as open loop control in contrast to closed loop control section 4 1 as there is no feedback based on state measurements to close the management loop the control problem consists of minimizing the performance criterion for any admissible input u t the performance can be formulated as follows 16 j f x t 0 t l x t u t t d t the function f represents the costs associated with the state at end time t and function l represents the running costs associated with input and with state dynamics in addition j can be minimized under time dependent boundary conditions of input and state b x t u t t 0 the control problem of minimizing criterion j can be seen as a generalization of the lqr problem as both the system model and the performance criterion can be non linear and time varying given that the model includes external input ε t minimizing j implies that the input is optimized while anticipating future external input dynamics solving this control problem can be quite challenging in the 1950s pontryagin and bellman developed algorithms to design optimal input trajectories that minimize j under the constraint b 0 by solving the euler lagrange equations although the optimization problem can be solved analytically for some simple cases a numerical solution is usually required e g through dynamic programming see section 4 2 3 potential disadvantages of finite horizon optimal control include the fact that it is not designed to attenuate any errors or disturbances as a result the exact value of ε t is assumed to be known in advance in the absence of feedback forecast errors may cause the realized state trajectory to deviate from the predicted trajectory regardless of its potential disadvantages finite horizon optimal control is a valuable tool for determining the potential added value of precision management in terms of timing and dosage comparing the theoretical optimal performance to the performance currently obtained in practice can provide a considerable amount of information about the potential gains to be realized with precision management in greenhouse research finite horizon optimal control has been employed to investigate the energy saving possibilities of precisely controlling the timing and dosing of inputs like heating and ventilating van straten et al 2010 in the performance criterion x t represents the end state of the crop and l u represents the running costs for climate management other research applications for finite horizon optimal control include manure spreading krishnan et al 2006 robotic harvesting van henten et al 2009 and pest management vincent 1975 4 2 2 receding horizon control receding horizon control is an extension of finite horizon control in this model both the state and the prognosis on external input are updated regularly and used to compute new input schedules thereafter the time horizon is extended such that the time window across which the input is optimized shifts forward while maintaining the same length receding horizon mpc is quite popular in research on farm operations example applications include trajectory planning for moving agricultural machines coen et al 2008 greenhouse climate control el ghoumari et al 2005 irrigation mccarthy et al 2014 and agro robotics kayacan et al 2015 an extensive review on mpc applications in agriculture is provided in ding et al 2018 the updates come at a price in terms of computation as each update requires a recalculation of the optimal input given the high computational cost of solving the euler lagrange equations they may allow only a low update frequency to avoid slow computations the state dynamics can be linearized thereby yielding the aforementioned riccati equations which can be solved much faster this nevertheless comes at the expense of possible linearization errors another increasingly popular approach is explicit mpc in which the optimization problem is solved offline for a range of operating points and multi parametric programming is used to express the optimal control actions as explicit functions of the states in most cases the end results resemble a look up table although this method drastically reduces online computation requirements it does not always guarantee that all constraints have been satisfied for additional information on this point see alessio and bemporad 2009 and diangelakis et al 2019 the regular updating of open loop control is known as open loop feedback although the regular updating of states and forecasts does provide some robustness in the sense that it can correct for errors and disturbances it does not provide any integrating action as is the case with pid control for example consider a heating system that is supposed to achieve a room temperature of 20 c but that has an offset of 5 c due to actuator bias the mpc algorithm described above will not learn from any past mistakes and it will therefore continue recalculating its actions in the same way thus preserving the offset possible options for addressing model offset include i applying integrating action section 4 1 1 and ii adapting the model parameters based on output response sections 2 1 3 and 3 2 6 several methods have been developed in order to improve mpc performance one example is tube mpc langson et al 2004 in which a feedback controller is implemented to keep the state within a bounded area tube of the optimal trajectory calculated by mpc the basic mpc algorithm is designed to optimize performance in a deterministic manner without taking performance uncertainty into account by comparison stochastic mpc is a method for mitigating performance risks associated with errors and disturbances 4 2 3 stochastic model predictive control stochastic model predictive control or stochastic mpc is based on the assumption that the state dynamics are disturbed by noise equation 7 the control problem consists of optimizing the input trajectory u k with respect to the cost criterion bertsekas 1995 17 j e f x n k 0 n 1 l k x k u k ε k this criterion is similar to the one used in equation 16 with the difference that in this criterion the expectancy of the costs is minimized furthermore the formulation of j can be adapted in such a way that the variance of the costs j are included as well horwood 1996 given that a decrease in variance implies a decrease in the risk of very high costs this is also known as risk sensitive control the concept of stochastic mpc has been employed within the context of irrigation optimization zavaleta et al 1980 crop harvesting alvarez and shepp 1998 greenhouse crop production mourik et al 2016 and fish harvesting braumann 1999 one important issue in stochastic mpc is computational demand the difficulty in solving the control problem resides in the fact that there is no single optimal trajectory u k as time proceeds the realizations of noise w k will change the course of any state trajectory x k that was planned beforehand as a result for each time instance k the optimal choice of u k will depend on the particular state at that time x k such that u k u x k k optimization across all possible state realizations over time poses a computational challenge suppose that a state is discretized into m parts and time into n parts for a single state model there are thus n m possible state trajectories a basic crop model with only one state variable which is very coarsely discretized with m 10 possible states and only n 10 time instances already has 10 billion possible state trajectories a powerful method for overcoming this computational burden is dynamic programming bertsekas 1995 the method is based on the notion that the optimal control problem is solved backwards by computing the minimal costs j k x k for each time and state starting with k n therefore j n x n f n x n is solved first for all possible x n the process is then repeated for k n 1 down to 1 18 j k x k min u k ε u k x k e l k x k u k ε k j k 1 x ˆ k 1 where u k x k is the admissible region of control comparable to the previously mentioned constraint b x t u t 0 the first term on the right of equation 18 represents control costs between time instance k and k 1 and the second term represents the costs associated with the newly predicted state x ˆ k 1 which was already computed this process of backward recursion reduces the computational load from n m to only m n cost optimizations as the number of states increases however computational complexity can still increase quite rapidly if each state is discretized into m parts optimizing for a model with d states requires m d n cost optimizations in order to achieve further reductions in computational time approximative algorithms such as limited look ahead policies and rollout algorithms have been developed bertsekas 1995 in addition to high computational demand another potential disadvantage of this method is the assumption of white noise although white noise can be transformed into auto correlated noise it requires extending the number of states d and consequently the computational load 4 2 4 summary the most important advantage of mpc over feedback control is the ability to anticipate changes in external input not to be confused with disturbances in addition mpc is quite flexible as it was designed for non linear time varying systems and boundaries on input and state it is nevertheless subject to potential disadvantages as well the changes in external input must be predicted thereby introducing forecast errors that may have a negative influence on performance the control actions are based on model predictions which makes the performance more reliant on model predictions than on feedback control which increases the impact of modelling errors taken together the choice for mpc instead of a feedback or feedforward controller requires balancing their general advantages and disadvantages the main advantages and disadvantages of the mpc methods discussed in this section are summarized in table 3 5 discussion and conclusions most of the observation and control methods discussed in this overview have been designed according to a systems model a model based approach requires some level of investment in model development the benefit of such approaches is that they allow the a priori analysis of how an observer or controller will perform i e before applying it in reality and of what might be needed in order to improve the performance for example in the case study for section 3 see supplementary material increased prediction accuracy is needed in this section we discuss the relationships between the methods discussed in this paper as well as the types of tasks and skills that they can serve we then present a design procedure based on these methods 5 1 relationship between tasks methods and cognitive skills the role of farmers has evolved through advances in technology and machine intelligence in high tech farms the eyes ears and noses of farmers are replaced by sensors and cameras and their hands and tools are replaced by actuators their brains which perceive and process information in order to take operational management decisions is assisted or even replaced by machine intelligence the methods discussed in this paper can be linked to several essential cognitive skills that make up the machine intelligence required to support farmers the systems model represents the knowledge that is needed in order to fulfil the task of predicting how a system will respond to input such knowledge can be seen as a cognitive skill for model based observation and control the cognitive skills and their relationships to the types of methods discussed in this paper are summarized in table 4 multiple types of methods are available for each task as demonstrated by the illustrative case studies however despite a multitude of methods and types of methods not every management task constitutes a problem with a straightforward solution this is because the properties of the methods often do not fully match the management objectives for example the case study on feedback control indicates that lqg control unintentionally punishes good behaviour in that case by bringing the mite population below the critical level whereas a threshold controller involves the undesired trade off between respecting the state constraint and maximizing input efficiency in the mpc case study prediction uncertainty prohibited any guarantee about keeping the state constrained within acceptable bounds in general it is very rare for a method to satisfy all of the desired objectives and to comply with all constraints another reason that method selection is not a straightforward process is the fact that it is very rare for all of the assumptions on which a method is based to be realistic dynamics are rarely linear noise is seldom white and it is only in exceptional cases that perceived costs are a quadratic function of state and input although several methods have been designed under the assumption that no uncertainty exists uncertainty is a prominent characteristic of almost all farming systems in other words there is always some gap between theory and practice this does not mean however that these methods have no validity or that they will automatically yield poor performance whether a violated assumption will be a true disadvantage depends on the extent to which its violation will have a negative influence on predictions observations or control actions as well as on how these aspects will ultimately result in the loss of performance assessing the relationship between the theory practice gap and performance loss is an important frontier in the science of biosystems engineering 5 2 selection and design procedure various types of methods for each management task are displayed in table 4 each type comprises multiple methods each of which has a unique set of properties and underlying assumptions whether these aspects translate into advantages or disadvantages depends on the type of system and the circumstances under which it is operated farming systems vary widely with regard to configuration technology production process and environmental circumstances for engineers therefore selecting and designing the right methodology is likely to be a complex task one important challenge thus involves the configuration of a selection and design procedure as a form of support for engineers the outline of this overview paper suggests a configuration for a basic selection and design procedure fig 7 the first step involves building a systems model based on the available technology and system properties and subsequently designing an observer and then an automatic controller the design or choice of a model depends on relevant system characteristics e g available sensing and actuation technology external input state dynamics constraints and noise and performance objectives as well as on the requirements posed by the subsequent design of an observer and controller for example a given observer may require a linear model and a given controller may require a noise model conversely the choice of an observer depends on the type of systems model available e g in terms of accuracy or the availability of an output equation and the choice of controller depends on type of model available e g whether performance is quadratic as well as on the observer e g the states that can be observed in principle therefore the procedure for designing and selecting the right methodology is not sequential but iterative the three circles depicted in fig 7 can be linked to the various sections of this paper the systems model design steps are discussed in section 2 the observer design methods are discussed in section 3 and the control design methods are discussed in section 4 the associated advantages and disadvantages are summarized in table 1 table 2 and table 3 many other relevant methods exist that could complement the overview presented here including h 2 and h feedback control multi agent control adaptive control model selection and approximation and reinforcement learning an interesting avenue for follow up research could thus be to add to the list of methods in order to compile an elaborate yet comprehensive guide that is accessible to a broad group of engineers 6 summary this introductory overview explains the need for sustainable farming the role of precision technology in modern farming and the demand for automation and decision support within this context it clarifies the role of state observation and control methods in automation and decision support this is followed by an overview of the basic requirements of a systems model which provides the foundation for model based observation and control methods the overview subsequently shifts to a presentation of commonly used observation and control methods along with a discussion and summary of the advantages and disadvantages of each method the methods are then linked to specific management tasks and associated with the cognitive skills that are required in operational farm management finally we present a procedural outline for method selection and design which could serve as a basic guideline to support farming engineers the procedures of model design and method selection for state estimation methods feedback control and model predictive control are illustrated with case studies supplementary material the main outcomes emerging from this overview are as follows 1 prediction observation and control are essential features for operational management support in farming systems section 1 moreover the required cognitive skills that make up the machine intelligence required for automation and decision support are linked to the methods discussed in this paper section 5 1 2 each method presented in this paper has a unique set of possible advantages and disadvantages table 1 table 2 table 3 this has the following implications o farming systems are highly varied in terms of design technology location and performance objectives and these variations translate into a specific set of errors disturbances constraints and performance criteria under which each system is operated the selection of the best method or combination of methods thus requires an assessment for each particular case based on weighing the advantages and disadvantages of each candidate method o many of the advantages and disadvantages stem from a gap between reality and the theoretical assumptions underlying the methods it is quite common for one or more assumptions on disturbances dynamics performance or other aspects to deviate from reality as illustrated by the case studies thus possibly resulting in a loss of performance in practice the relationship between this theory reality gap and possible performance loss therefore constitutes an important aspect of biosystems engineering 3 in theory the procedure of designing and selecting the model observer and controller is not sequential but iterative this stems from the fact that model selection depends on observer requirements while observer selection depends on model properties similar dependencies exist between observer and controller as well as between controller and model fig 7 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank dr gjerrit meinsma twente university netherlands david katzin msc wageningen university and research netherlands dr rachel van ooteghem wageningen university and research netherlands and prof michel vellekoop university of amsterdam netherlands for useful discussions and insightful reflections appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105031 
25847,this paper is the first of its kind to use machine learning algorithms in conjunction with a land use regression lur model for predicting the spatiotemporal variation of co concentrations in taiwan we used daily co concentration from 2000 to 2016 to develop model and data from 2017 to 2018 as external data to verify the model reliability location of temples was used as a predictor to account for asian culturally specific sources with the ability to capture nonlinear relationship between observations and predictions three lur based machine learning algorithms were used to estimate co concentrations including deep neural network dnn random forest rf and extreme gradient boosting xgboost the results showed that lur based machine learning model lur xgboost has the best computation efficiency and improved adjusted r2 from 0 69 to 0 85 our studies demonstrate the ability of the lur based machine learning algorithms to estimate long term spatiotemporal co concentration variations in fine resolution graphical abstract image 1 keywords carbon monoxide co land use regression lur deep neural network dnn random forest rf extreme gradient boosting xgboost 1 introduction carbon monoxide co is generated by incomplete combustion of fossil fuels such as the emission from motor vehicles bell et al 2009 while we cannot see or smell this colorless and odorless gaseous pollutant many experimental studies have shown adverse health effects of co exposure including myocardial ischemia changes in blood pressure and rhythm disturbance at low concentrations and asphyxia related deaths at high exposure concentrations chambers et al 2008 lee et al 2017 varon et al 1999 some studies further highlighted the impact of ambient co on cardiovascular disease cvd dastoorpoor et al 2019 liu et al 2018 newell et al 2018 requia et al 2018 vahedian et al 2017 it is thus crucial to predict ambient co concentrations and help policy makers better allocate resources for prevention and assess the cost effectiveness of prevention measures in order to control or further reduce the disease caused by co however the accuracy of prediction for ambient co concentrations is often questionable given that many cities have only one or a few sampling stations for better prediction it is essential to address the variations in the concentration among stations there are only few if any previous studies which covered within city variability in the level of co several estimation methods have been utilized for predicting concentrations of air pollutants in particular kriging interpolation and land use regression lur are the most commonly used approaches in air pollution studies bayraktar and turalioglu 2005 di et al 2016 jerrett et al 2005 leem et al 2006 wu et al 2018 spatial interpolation methods are often data specific or even variable specific many factors may affect the prediction performance of the methods and previous studies have shown that their effects are not consistent in contrast to kriging interpolation lur has advantages for characterizing spatial relationships between local emissions and variations in air pollution beelen et al 2013 de hoogh et al 2016 hoek et al 2008 lur usually uses potential predictor variables of geographic sources with temporal variations to develop a linear regression model between explanatory variables and target air pollutants wu et al 2017 through the stepwise variable selection procedure for building the lur model significant factors affecting the air pollution level with right direction of effect could be identified however in some situations the assumptions of linear regression may not fit the relationship between concentrations of air pollutants and the explanatory variables to solve the problems mentioned above in recent years machine learning methods have been proven of their feasibility in capturing nonlinear relationships deep neural network dnn has a high computing power and is good for solving classification and regression problems random forest rf algorithm is a kind of bagged classifier based on decision trees allowing both continuous and categorical input variables in addition it provides information on the importance of variables as well as out of bag oob errors for model evaluation the extreme gradient boosting xgboost model can avoid the overfitting problem and increase computation efficiency because the predictive and regularization terms are combined and the objective functions are simplified thus these three machine learning algorithms have been widely used to predict concentrations of air pollutants brokamp et al 2017 kaimian et al 2019 li et al 2017 pan 2018 while the reduction of variable dimension may improve the interpretability of the machine learning based models however only some decision tree based algorithms such as random forest are able to select variables based on the importance of the predictor features with the increasing number of predictor variables used for air pollution modelling those prediction model developed by machine learnings may have less interpretability and reliability due to the lack of variable selection function therefore the mixed spatial prediction models that combine the strength of lur in identifying the most dominant emission predictors and the predictability of machine learning in estimating non linear trend would be more effective than those using only lur or machine learning to better estimate co concentrations this study proposed an innovative scheme by integrating lur model with machine learning algorithms to estimate the spatial temporal variability of co concentrations in taiwan three types of machine learning algorithms were employed including dnn rf and xgboost important predictor variables selected through lur approaches were used to fit the three machine learning algorithms for developing the prediction model we believe this study is the first one to address the spatial temporal variability of co by using an integrating lur machine learning approach 2 materials and methods 2 1 study area as a part of east asia taiwan is located on the east side of china south side of japan and north side of the philippines taiwan has 14 counties and 368 townships covering a geographical area of 36 197 km2 with 23 million people on the island the population density is approximately 652 people km2 dgb 2019 because there are 22 million registered motor vehicles including motorbikes cars etc in taiwan this means a high vehicle density of 93 8 per hundred people motc 2020 needless to say traffic emissions thus become a vital factor of urban air pollution moreover the air pollutant levels in the local communities and residential areas can be further increased by various local emission sources such as incense burning in the temples cooking fumes from the chinese restaurants and industrial emissions from local factories lung et al 2014 2 2 databases we first obtained the daily concentration of co from 2000 to 2018 from 73 automatic air quality monitoring stations set up by the taiwan environmental protection administration epa fig 1 the data from 2000 to 2016 0 42 million measurements were used to develop the model while observations from 2017 to 2018 51 thousand measurements were used as the external data verification to assess model reliability to serve as meteorological factors such as temperature and relative humidity we further collected some weather data measured by the monitoring stations of the taiwan central weather bureau previous studies show that co is produced either by direct emission into the air from fossil fuel combustion or as secondary product precursors such as o3 that are released from anthropogenic and natural sources clerbaux et al 2008 myriokefalitakis et al 2016 sharma and sharma 2017 given the high co relation between co and its co pollutants such as pm10 no2 and so2 zhong et al 2017 this study also considered the measurements of each co pollutant from the epa database several geographic information system gis databases were used to obtain land use land cover variables for model development including the distributions of residential areas farms forest parks water airports and ports from the national land use inventory road patterns from the digital road network map of national highways provincial expressways county roads major roads streets and avenues and the distribution of industrial parks from the digital map of industrial parks because some studies have shown that gas cooking and burning of incense and joss money may affect co levels huboyo et al 2011 lee and wang 2004 lin et al 2008a we used the location of temples cemeteries and crematoria as indices to account for the contribution of co from incenses and joss money burning we also included the distribution of restaurants with chinese style cooking in the models the distance to the nearest power plant and that to the nearest garbage incinerator were also used as predictor variables as another prediction variable we used the data from 2000 to 2018 of surrounding greenness e g trees and vegetation which was characterized by the national aeronautics and space administration s modis moderate resolution imaging spectroradiometer normalized difference vegetation index ndvi image database all of these geo spatial variables were abstracted to a circular buffer of 50 m 150 m 250 m 500 m 750 m 1000 m 1250 m 1500 m 1750 m 2000 m 2500 m 3000 m 4000 m or 5000 m around each air quality monitoring station to represent the neighborhood land use land cover allocations yielding a total of 490 predictor variables for the model table s1 2 3 selection of variables and land use regression fig 2 shows the study framework to determine the spatial relationships between local emission sources and air pollution variations lur is widely used to estimate concentrations of ambient air pollutants beelen et al 2013 michanowicz et al 2016 wu et al 2017 we constructed a lur model using a stepwise variable selection procedure to identify the major land use variables that affected co levels the spearman correlation coefficient was used to assess the correlations between the predictor variables and co concentrations only the variables with correlation coefficients met the expected directions of effects were fitted to the initial regression model we used stepwise variable selection procedure to select the important variables with entered and removed p value criteria of 0 1and 0 3 finally variables with variance inflation factor vif 3 and consistent with the initially defined direction of effects were retained to establish the final conventional lur model chen et al 2020 in terms of spatial predictors that significantly affect the target air pollution we constructed dnn rf and xgboost models through fitting the variables that were selected by the final lur model 2 4 deep neural network dnn dnn is a supervised machine learning algorithm that is widely used to forecast air pollution levels adams and kanaroglou 2016 soh et al 2018 solaiman et al 2008 with more than one hidden layer the neural network that uses a deep learning approach is constructed a dnn is used to determine non linear relationships between predictor variables and observations the parameter settings for the proposed dnn model are shown in table s2 the activation functions that used in hidden layers and output layer were rectified linear unit relu and linear the optimizer that minimized the loss function was an adam optimizer with a stochastic gradient descent algorithm sgd and the loss function used in this study was the mean square error to avoid overfitting 1 of the dropout value was used the output layer produced predictions of co concentrations 2 5 random forest rf the rf algorithm grows multiple decision tress simultaneously splitting a randomly selected subset of candidate predictors from a training set into each tree using a bootstrapping method breiman 2001 the predictions for each tree are averaged to produce the final prediction for the model the parameter settings for the proposed rf model are shown in table s3 the number of trees and the depth to which a tree grows affect the model performance and we used the values 200 and 17 for these parameters respectively the criterion for determining the model residuals was the mean square error 2 6 extreme gradient boosting xgboost xgboost is a gradient boosting model proposed by chen and guestrin 2016 this algorithm has good predictive ability in different research domains with a lower bias and can avoid overfitting of air pollution predictions xu et al 2018 zhang and zhan 2017 the ensemble model combines multiple weak learners to construct a robust model through an additive training process a gradient descending algorithm was used to minimize the loss function the bias for the loss function was used to generate xgboost learners with different weights across the trees the prediction was then accumulated in terms of the weight of each learner table s4 shows the parameters for xgboost that were used in this study the r2 and adjusted r2 values were used to determine the model accuracy and the mean square error mse the root mean square error rmse and the mean absolute error mae were used to determine the residuals between predictions and observations to avoid overfitting we used two methods to verify the reliability of the developed models we first used 80 of the data for model training and 20 of the data for model testing the second one is the 10 fold cross validation method which used 90 of the data for model development and the remaining 10 for model validation to furtherly validate the model we used the 2017 and 2018 datasets as external data to confirm the model s reliability and robustness on the other hand season based validation with whole database stratified by season was used in the county based validation six major cities of taiwan including taipei new taipei taoyuan taichung tainan and kaohsiung cities were selected for city based validation the correlation between model predictions and in situ observations were assessed to confirm the robustness of model predictability in different seasons and locations we used arcgis 10 5 to extract land use land cover patterns lur and all statistical analyses were performed using spss 17 0 and r 3 5 2 the proposed machine learning models were schemed in python 3 7 using a jupyter notebook platform working on a computer with an amd ryzen 9 3900x 12 core processor 3 79 ghz and 32 gb of ram 2 7 prediction mapping for the spatial temporal variability of co levels the best model was used to produce prediction maps for the whole taiwan with a regular 50 m 50 m grid resolution using the spatial analyst module in arcgis 10 5 3 results 3 1 measurement of co concentrations during the study period fig 3 shows a declining trend of co concentration in taiwan during the study period 2000 2018 when comparing the variations among four seasons we found the highest co concentration in the winter and the lowest in the summer such seasonal variation of co concentrations is likely because for example the frequent occurrence of thermal inversion in the winter could cause a lower mixing layer which then reduces atmospheric dispersion and confines pollutants closer to the ground in contrast co concentrations often decrease in summer due to the photochemical activities in presence of clear days and abundant sunshine yadav et al 2019 3 2 model development using the integrated lur machine learning method table 1 shows the variables the estimated coefficients and the partial r2 values of the proposed lur model the final model included co pollutants no2 pm10 and o3 major road density within a 50 m circular buffer major road density within a 150 m circular buffer all road density within a 50 m circular buffer all residential areas within a 1500 m circular buffer and density of temples within a 150 m circular buffer the concentration of o3 had a negative correlation with the co level all the other predictors are positively correlated with co concentrations in total eight variables were selected for the lur model and to construct the other three lur based machine learning models table 2 shows the prediction performance of four models each of which is developed by using a conventional lur approach and three lur based machine learning algorithms the conventional lur approach explained 69 of the spatial temporal variability in co concentrations the other three lur based machine learning approaches explained 81 84 and 85 of the co variations using the dnn rf and xgboost algorithms respectively for the traditional lur the mse rmse and mae were 0 04 0 21 and 0 14 for the three integrated machine learning models with dnn rf and xgboost algorithms the mse values were 0 03 0 02 and 0 02 the rmse values were 0 16 0 15 and 0 14 and the mae values were 0 10 0 09 and 0 09 respectively the density scatter plots for co predictions versus observations using the three integrated machine learning models are shown in fig 4 which shows that the lur based machine learning with an xgboost outperformed all two other models including the lur based machine learning with rf and dnn to avoid overfitting we conducted an 80 20 of data for training and testing the developed model and a 10 fold cross validation the models had similar adjusted r2 values as to those for the original model regardless of the method of the testing method so there were no overfitting problems the adjusted r2 values for lur and the lur based machine learning models using the 2017 and 2018 data as external verification to assess model reliability the respective adjusted r2 values for lur and three lur based machine learning algorithms dnn rf and xgboost were 0 64 0 82 0 84 and 0 86 in 2017 and 0 61 0 79 0 81 and 0 84 in 2018 as to the efficiency it took 32 min and 18 s to train the lur based dnn 3 min and 43 s for lur based rf and 19 s for lur based xgboost the season and city based validation was further conducted for validating the lur based xgboost model the values of the adjusted r2 obtained from the four seasons and the six major cities were similar with the main model tables s5 and s6 the feature importance plots of selected variables used in random forest and xgboost are shown as figs s1 and s2 compared with the importance ranking sorted by partial r2 in lur model table 1 random forest and xgboost have used variables with similar order among top five features 3 3 spatial temporal distribution of co in taiwan we chose the lur based xgboost to produce the prediction maps because it is the best among four models fig 5 shows the prediction maps for co concentration for the four seasons of 2016 as to the spatial variation higher co levels were mostly found in the western and northern cities of taiwan indicating hot areas of higher population and traffic density for seasonal variations the winter season has the highest co levels which is consistent with the seasonal trend of co concentration shown in fig 3 the reasons might be lower troposphere and stability atmosphere in taiwan which could accumulate pollutants in cooler seasons chen et al 2004 lin et al 2008b with the characteristic of stability and relatively long lifetime co might follow the prevailing northwesterly wind via cold front of winter monsoon which contributed to long range transport from mainland china or japan lin et al 2005 2007 4 discussion this study aims to be the first of its kind to determine the spatial temporal variability of co using different integrated lur machine learning algorithms the conventional lur model has a middle high level adjusted r2 0 69 the explanatory power can be significantly improved to a high level adjusted r2 ranged from 0 81 to 0 85 when three machine learning algorithms were added to the lur model in particular the lur coupled with xgboost algorithm had the best performance consistent results in the overfitting tests and external data verification also confirmed the robustness of the explanatory power of the integrated lur machine learning models notably all three machine learning algorithms were only trained on a desktop computer and while the dnn requires a slightly longer time 32 min and 18 s for model development rf and xgboost only need less than 4 min and 19 s respectively so we don t need a server or super computer limited studies have applied lur and machine learning on co variation prediction hassanpour matikolaei et al 2019 used lur with variables which contented length of roads meteorological factors and other proximity variables to predict co hourly variation in tehran iran and the r2 value was 0 38 hassanpour matikolaei et al 2019 another study also launched in tehran compared the model performance between linear regression and neural network model the r2 for neural network and linear regression was 0 72 and 0 10 respectively shams et al 2020 the results further indicated that machine learning algorithms outperformed linear regression which was identical to our study in terms of machine learning approaches azeez et al 2019 applied artificial neural network algorithms to model co emission from traffic vehicles in malaysia this study first used correlation based feature selection method to select best model predictors then using multilayer perceptron neural network to predict co variations the results showed that the model achieved 80 6 of co variation interpretability azeez et al 2019 on the other hand a study demonstrated that random forest and bagging methods performed better than artificial neural network and support vector machine algorithms in predicting co concentrations masih 2018 in our study the proposed method combined the advantages in both lur and xgboost algorithm which could capture co variations more accurately model r2 0 85 for lur with xgboost algorithm and also identified that xgboost outperformed random forest and deep neural network algorithms as shown in table 1 traffic is the dominant factor for co concentration because 50 of nox no2 no across taiwan and 85 of nox in cities is emitted from vehicles twepa 2020 table 1 also highlights the major road density as the major factor to impact co concentration confirming the traffic to be the dominant factor for co concentration indeed previous studies also showed that co levels in areas that were 20 150 m downwind of a highway were 1 2 times higher than those in urban locations hagler et al 2010 and the concentration of co decreased from roadside to setbacks wang et al 2017 other factors may also impact co concentrations for instance the residential area accounted for 9 of the model performance in table 1 indicating that human activities also matter this is true when considering certain emission sources specific to asian culture such as temples which also impact co levels because incense combustion can significantly increase the co concentration the pm10 another factor shown in table 1 is positively correlated with co concentration because co is an important precursor gas for the formation of secondary aerosols in the atmosphere zhong et al 2017 zhou et al 2017 on the other hand the o3 is negatively correlated with co concentration because co concentration perturbs background concentrations of the oxidants such as oh h2o2 and o3 leibensperger et al 2011 this study has shown its strength by using different machine learning algorithms and then identifying the best model for predicting spatial temporal co variations for instance shi et al 2017 used in situ observations of co concentration in hong kong from 2011 to 2015 to develop lur models for annual average summertime average and winter average with model performance of adjusted r2 equal to 0 77 0 84 and 0 87 however by using the data from a longer period in conjunction with machine learning models our best model can further predict daily special temporal variation of co which is a much shorter term than shi et al 2017 with the same or higher level of model performance adjusted r2 value of 0 85 shi et al 2017 in addition this study considered as many variables as possible and used stepwise variable selection procedure to choose important variables with right direction of effect which have impact on co concentrations mixed spatial prediction models that combine the strength of lur in identifying the most contributed emission predictors and the predictability of machine learning in estimating non linear trend would be more broadly effective than techniques using pure lur or machine learning the large amount of data 0 42 million used in our study can yield a more robust result than a smaller dataset 20 thousands wang and sun 2019 for constructing machine learning models moreover the proposed lur machine learning approaches could be applied to develop prediction models for other types of air pollutants and in different geographic areas whenever the land use land cover data is available this study still has some limitations though there were some lacks of information about predictors for example traffic volume was not available in taiwan we can develop a better model if the land use inventory can re new its data more frequently in addition some studies have used satellite images to obtain the broad ground level observations di et al 2019 however it is not the case in taiwan because it is more difficult to take clear satellite images through taiwan s cloudy and rainy weather future studies may also incorporate land dynamics in air pollution model development when the land use land cover data is available 5 conclusions this study demonstrated the use of lur along with three different machine learning algorithms to boost the accuracy of predictions for daily co spatial temporal variations the results showed that lur with an xgboost algorithm wins the title of best prediction performance and is the most efficient method the proposed methods may be further applied to risk assessment and to the prediction of spatial temporal distribution of other air pollutants which needs further studies to confirm declaration of competing interest the authors declare that they have no known competing for financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is funded by the ministry of science and technology r o c most 108 2621 m 006 017 most 108 2638 b 006 001 my2 the authors are grateful to the national aeronautics and space administration nasa and to the u s geological survey usgs for data appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104996 
25847,this paper is the first of its kind to use machine learning algorithms in conjunction with a land use regression lur model for predicting the spatiotemporal variation of co concentrations in taiwan we used daily co concentration from 2000 to 2016 to develop model and data from 2017 to 2018 as external data to verify the model reliability location of temples was used as a predictor to account for asian culturally specific sources with the ability to capture nonlinear relationship between observations and predictions three lur based machine learning algorithms were used to estimate co concentrations including deep neural network dnn random forest rf and extreme gradient boosting xgboost the results showed that lur based machine learning model lur xgboost has the best computation efficiency and improved adjusted r2 from 0 69 to 0 85 our studies demonstrate the ability of the lur based machine learning algorithms to estimate long term spatiotemporal co concentration variations in fine resolution graphical abstract image 1 keywords carbon monoxide co land use regression lur deep neural network dnn random forest rf extreme gradient boosting xgboost 1 introduction carbon monoxide co is generated by incomplete combustion of fossil fuels such as the emission from motor vehicles bell et al 2009 while we cannot see or smell this colorless and odorless gaseous pollutant many experimental studies have shown adverse health effects of co exposure including myocardial ischemia changes in blood pressure and rhythm disturbance at low concentrations and asphyxia related deaths at high exposure concentrations chambers et al 2008 lee et al 2017 varon et al 1999 some studies further highlighted the impact of ambient co on cardiovascular disease cvd dastoorpoor et al 2019 liu et al 2018 newell et al 2018 requia et al 2018 vahedian et al 2017 it is thus crucial to predict ambient co concentrations and help policy makers better allocate resources for prevention and assess the cost effectiveness of prevention measures in order to control or further reduce the disease caused by co however the accuracy of prediction for ambient co concentrations is often questionable given that many cities have only one or a few sampling stations for better prediction it is essential to address the variations in the concentration among stations there are only few if any previous studies which covered within city variability in the level of co several estimation methods have been utilized for predicting concentrations of air pollutants in particular kriging interpolation and land use regression lur are the most commonly used approaches in air pollution studies bayraktar and turalioglu 2005 di et al 2016 jerrett et al 2005 leem et al 2006 wu et al 2018 spatial interpolation methods are often data specific or even variable specific many factors may affect the prediction performance of the methods and previous studies have shown that their effects are not consistent in contrast to kriging interpolation lur has advantages for characterizing spatial relationships between local emissions and variations in air pollution beelen et al 2013 de hoogh et al 2016 hoek et al 2008 lur usually uses potential predictor variables of geographic sources with temporal variations to develop a linear regression model between explanatory variables and target air pollutants wu et al 2017 through the stepwise variable selection procedure for building the lur model significant factors affecting the air pollution level with right direction of effect could be identified however in some situations the assumptions of linear regression may not fit the relationship between concentrations of air pollutants and the explanatory variables to solve the problems mentioned above in recent years machine learning methods have been proven of their feasibility in capturing nonlinear relationships deep neural network dnn has a high computing power and is good for solving classification and regression problems random forest rf algorithm is a kind of bagged classifier based on decision trees allowing both continuous and categorical input variables in addition it provides information on the importance of variables as well as out of bag oob errors for model evaluation the extreme gradient boosting xgboost model can avoid the overfitting problem and increase computation efficiency because the predictive and regularization terms are combined and the objective functions are simplified thus these three machine learning algorithms have been widely used to predict concentrations of air pollutants brokamp et al 2017 kaimian et al 2019 li et al 2017 pan 2018 while the reduction of variable dimension may improve the interpretability of the machine learning based models however only some decision tree based algorithms such as random forest are able to select variables based on the importance of the predictor features with the increasing number of predictor variables used for air pollution modelling those prediction model developed by machine learnings may have less interpretability and reliability due to the lack of variable selection function therefore the mixed spatial prediction models that combine the strength of lur in identifying the most dominant emission predictors and the predictability of machine learning in estimating non linear trend would be more effective than those using only lur or machine learning to better estimate co concentrations this study proposed an innovative scheme by integrating lur model with machine learning algorithms to estimate the spatial temporal variability of co concentrations in taiwan three types of machine learning algorithms were employed including dnn rf and xgboost important predictor variables selected through lur approaches were used to fit the three machine learning algorithms for developing the prediction model we believe this study is the first one to address the spatial temporal variability of co by using an integrating lur machine learning approach 2 materials and methods 2 1 study area as a part of east asia taiwan is located on the east side of china south side of japan and north side of the philippines taiwan has 14 counties and 368 townships covering a geographical area of 36 197 km2 with 23 million people on the island the population density is approximately 652 people km2 dgb 2019 because there are 22 million registered motor vehicles including motorbikes cars etc in taiwan this means a high vehicle density of 93 8 per hundred people motc 2020 needless to say traffic emissions thus become a vital factor of urban air pollution moreover the air pollutant levels in the local communities and residential areas can be further increased by various local emission sources such as incense burning in the temples cooking fumes from the chinese restaurants and industrial emissions from local factories lung et al 2014 2 2 databases we first obtained the daily concentration of co from 2000 to 2018 from 73 automatic air quality monitoring stations set up by the taiwan environmental protection administration epa fig 1 the data from 2000 to 2016 0 42 million measurements were used to develop the model while observations from 2017 to 2018 51 thousand measurements were used as the external data verification to assess model reliability to serve as meteorological factors such as temperature and relative humidity we further collected some weather data measured by the monitoring stations of the taiwan central weather bureau previous studies show that co is produced either by direct emission into the air from fossil fuel combustion or as secondary product precursors such as o3 that are released from anthropogenic and natural sources clerbaux et al 2008 myriokefalitakis et al 2016 sharma and sharma 2017 given the high co relation between co and its co pollutants such as pm10 no2 and so2 zhong et al 2017 this study also considered the measurements of each co pollutant from the epa database several geographic information system gis databases were used to obtain land use land cover variables for model development including the distributions of residential areas farms forest parks water airports and ports from the national land use inventory road patterns from the digital road network map of national highways provincial expressways county roads major roads streets and avenues and the distribution of industrial parks from the digital map of industrial parks because some studies have shown that gas cooking and burning of incense and joss money may affect co levels huboyo et al 2011 lee and wang 2004 lin et al 2008a we used the location of temples cemeteries and crematoria as indices to account for the contribution of co from incenses and joss money burning we also included the distribution of restaurants with chinese style cooking in the models the distance to the nearest power plant and that to the nearest garbage incinerator were also used as predictor variables as another prediction variable we used the data from 2000 to 2018 of surrounding greenness e g trees and vegetation which was characterized by the national aeronautics and space administration s modis moderate resolution imaging spectroradiometer normalized difference vegetation index ndvi image database all of these geo spatial variables were abstracted to a circular buffer of 50 m 150 m 250 m 500 m 750 m 1000 m 1250 m 1500 m 1750 m 2000 m 2500 m 3000 m 4000 m or 5000 m around each air quality monitoring station to represent the neighborhood land use land cover allocations yielding a total of 490 predictor variables for the model table s1 2 3 selection of variables and land use regression fig 2 shows the study framework to determine the spatial relationships between local emission sources and air pollution variations lur is widely used to estimate concentrations of ambient air pollutants beelen et al 2013 michanowicz et al 2016 wu et al 2017 we constructed a lur model using a stepwise variable selection procedure to identify the major land use variables that affected co levels the spearman correlation coefficient was used to assess the correlations between the predictor variables and co concentrations only the variables with correlation coefficients met the expected directions of effects were fitted to the initial regression model we used stepwise variable selection procedure to select the important variables with entered and removed p value criteria of 0 1and 0 3 finally variables with variance inflation factor vif 3 and consistent with the initially defined direction of effects were retained to establish the final conventional lur model chen et al 2020 in terms of spatial predictors that significantly affect the target air pollution we constructed dnn rf and xgboost models through fitting the variables that were selected by the final lur model 2 4 deep neural network dnn dnn is a supervised machine learning algorithm that is widely used to forecast air pollution levels adams and kanaroglou 2016 soh et al 2018 solaiman et al 2008 with more than one hidden layer the neural network that uses a deep learning approach is constructed a dnn is used to determine non linear relationships between predictor variables and observations the parameter settings for the proposed dnn model are shown in table s2 the activation functions that used in hidden layers and output layer were rectified linear unit relu and linear the optimizer that minimized the loss function was an adam optimizer with a stochastic gradient descent algorithm sgd and the loss function used in this study was the mean square error to avoid overfitting 1 of the dropout value was used the output layer produced predictions of co concentrations 2 5 random forest rf the rf algorithm grows multiple decision tress simultaneously splitting a randomly selected subset of candidate predictors from a training set into each tree using a bootstrapping method breiman 2001 the predictions for each tree are averaged to produce the final prediction for the model the parameter settings for the proposed rf model are shown in table s3 the number of trees and the depth to which a tree grows affect the model performance and we used the values 200 and 17 for these parameters respectively the criterion for determining the model residuals was the mean square error 2 6 extreme gradient boosting xgboost xgboost is a gradient boosting model proposed by chen and guestrin 2016 this algorithm has good predictive ability in different research domains with a lower bias and can avoid overfitting of air pollution predictions xu et al 2018 zhang and zhan 2017 the ensemble model combines multiple weak learners to construct a robust model through an additive training process a gradient descending algorithm was used to minimize the loss function the bias for the loss function was used to generate xgboost learners with different weights across the trees the prediction was then accumulated in terms of the weight of each learner table s4 shows the parameters for xgboost that were used in this study the r2 and adjusted r2 values were used to determine the model accuracy and the mean square error mse the root mean square error rmse and the mean absolute error mae were used to determine the residuals between predictions and observations to avoid overfitting we used two methods to verify the reliability of the developed models we first used 80 of the data for model training and 20 of the data for model testing the second one is the 10 fold cross validation method which used 90 of the data for model development and the remaining 10 for model validation to furtherly validate the model we used the 2017 and 2018 datasets as external data to confirm the model s reliability and robustness on the other hand season based validation with whole database stratified by season was used in the county based validation six major cities of taiwan including taipei new taipei taoyuan taichung tainan and kaohsiung cities were selected for city based validation the correlation between model predictions and in situ observations were assessed to confirm the robustness of model predictability in different seasons and locations we used arcgis 10 5 to extract land use land cover patterns lur and all statistical analyses were performed using spss 17 0 and r 3 5 2 the proposed machine learning models were schemed in python 3 7 using a jupyter notebook platform working on a computer with an amd ryzen 9 3900x 12 core processor 3 79 ghz and 32 gb of ram 2 7 prediction mapping for the spatial temporal variability of co levels the best model was used to produce prediction maps for the whole taiwan with a regular 50 m 50 m grid resolution using the spatial analyst module in arcgis 10 5 3 results 3 1 measurement of co concentrations during the study period fig 3 shows a declining trend of co concentration in taiwan during the study period 2000 2018 when comparing the variations among four seasons we found the highest co concentration in the winter and the lowest in the summer such seasonal variation of co concentrations is likely because for example the frequent occurrence of thermal inversion in the winter could cause a lower mixing layer which then reduces atmospheric dispersion and confines pollutants closer to the ground in contrast co concentrations often decrease in summer due to the photochemical activities in presence of clear days and abundant sunshine yadav et al 2019 3 2 model development using the integrated lur machine learning method table 1 shows the variables the estimated coefficients and the partial r2 values of the proposed lur model the final model included co pollutants no2 pm10 and o3 major road density within a 50 m circular buffer major road density within a 150 m circular buffer all road density within a 50 m circular buffer all residential areas within a 1500 m circular buffer and density of temples within a 150 m circular buffer the concentration of o3 had a negative correlation with the co level all the other predictors are positively correlated with co concentrations in total eight variables were selected for the lur model and to construct the other three lur based machine learning models table 2 shows the prediction performance of four models each of which is developed by using a conventional lur approach and three lur based machine learning algorithms the conventional lur approach explained 69 of the spatial temporal variability in co concentrations the other three lur based machine learning approaches explained 81 84 and 85 of the co variations using the dnn rf and xgboost algorithms respectively for the traditional lur the mse rmse and mae were 0 04 0 21 and 0 14 for the three integrated machine learning models with dnn rf and xgboost algorithms the mse values were 0 03 0 02 and 0 02 the rmse values were 0 16 0 15 and 0 14 and the mae values were 0 10 0 09 and 0 09 respectively the density scatter plots for co predictions versus observations using the three integrated machine learning models are shown in fig 4 which shows that the lur based machine learning with an xgboost outperformed all two other models including the lur based machine learning with rf and dnn to avoid overfitting we conducted an 80 20 of data for training and testing the developed model and a 10 fold cross validation the models had similar adjusted r2 values as to those for the original model regardless of the method of the testing method so there were no overfitting problems the adjusted r2 values for lur and the lur based machine learning models using the 2017 and 2018 data as external verification to assess model reliability the respective adjusted r2 values for lur and three lur based machine learning algorithms dnn rf and xgboost were 0 64 0 82 0 84 and 0 86 in 2017 and 0 61 0 79 0 81 and 0 84 in 2018 as to the efficiency it took 32 min and 18 s to train the lur based dnn 3 min and 43 s for lur based rf and 19 s for lur based xgboost the season and city based validation was further conducted for validating the lur based xgboost model the values of the adjusted r2 obtained from the four seasons and the six major cities were similar with the main model tables s5 and s6 the feature importance plots of selected variables used in random forest and xgboost are shown as figs s1 and s2 compared with the importance ranking sorted by partial r2 in lur model table 1 random forest and xgboost have used variables with similar order among top five features 3 3 spatial temporal distribution of co in taiwan we chose the lur based xgboost to produce the prediction maps because it is the best among four models fig 5 shows the prediction maps for co concentration for the four seasons of 2016 as to the spatial variation higher co levels were mostly found in the western and northern cities of taiwan indicating hot areas of higher population and traffic density for seasonal variations the winter season has the highest co levels which is consistent with the seasonal trend of co concentration shown in fig 3 the reasons might be lower troposphere and stability atmosphere in taiwan which could accumulate pollutants in cooler seasons chen et al 2004 lin et al 2008b with the characteristic of stability and relatively long lifetime co might follow the prevailing northwesterly wind via cold front of winter monsoon which contributed to long range transport from mainland china or japan lin et al 2005 2007 4 discussion this study aims to be the first of its kind to determine the spatial temporal variability of co using different integrated lur machine learning algorithms the conventional lur model has a middle high level adjusted r2 0 69 the explanatory power can be significantly improved to a high level adjusted r2 ranged from 0 81 to 0 85 when three machine learning algorithms were added to the lur model in particular the lur coupled with xgboost algorithm had the best performance consistent results in the overfitting tests and external data verification also confirmed the robustness of the explanatory power of the integrated lur machine learning models notably all three machine learning algorithms were only trained on a desktop computer and while the dnn requires a slightly longer time 32 min and 18 s for model development rf and xgboost only need less than 4 min and 19 s respectively so we don t need a server or super computer limited studies have applied lur and machine learning on co variation prediction hassanpour matikolaei et al 2019 used lur with variables which contented length of roads meteorological factors and other proximity variables to predict co hourly variation in tehran iran and the r2 value was 0 38 hassanpour matikolaei et al 2019 another study also launched in tehran compared the model performance between linear regression and neural network model the r2 for neural network and linear regression was 0 72 and 0 10 respectively shams et al 2020 the results further indicated that machine learning algorithms outperformed linear regression which was identical to our study in terms of machine learning approaches azeez et al 2019 applied artificial neural network algorithms to model co emission from traffic vehicles in malaysia this study first used correlation based feature selection method to select best model predictors then using multilayer perceptron neural network to predict co variations the results showed that the model achieved 80 6 of co variation interpretability azeez et al 2019 on the other hand a study demonstrated that random forest and bagging methods performed better than artificial neural network and support vector machine algorithms in predicting co concentrations masih 2018 in our study the proposed method combined the advantages in both lur and xgboost algorithm which could capture co variations more accurately model r2 0 85 for lur with xgboost algorithm and also identified that xgboost outperformed random forest and deep neural network algorithms as shown in table 1 traffic is the dominant factor for co concentration because 50 of nox no2 no across taiwan and 85 of nox in cities is emitted from vehicles twepa 2020 table 1 also highlights the major road density as the major factor to impact co concentration confirming the traffic to be the dominant factor for co concentration indeed previous studies also showed that co levels in areas that were 20 150 m downwind of a highway were 1 2 times higher than those in urban locations hagler et al 2010 and the concentration of co decreased from roadside to setbacks wang et al 2017 other factors may also impact co concentrations for instance the residential area accounted for 9 of the model performance in table 1 indicating that human activities also matter this is true when considering certain emission sources specific to asian culture such as temples which also impact co levels because incense combustion can significantly increase the co concentration the pm10 another factor shown in table 1 is positively correlated with co concentration because co is an important precursor gas for the formation of secondary aerosols in the atmosphere zhong et al 2017 zhou et al 2017 on the other hand the o3 is negatively correlated with co concentration because co concentration perturbs background concentrations of the oxidants such as oh h2o2 and o3 leibensperger et al 2011 this study has shown its strength by using different machine learning algorithms and then identifying the best model for predicting spatial temporal co variations for instance shi et al 2017 used in situ observations of co concentration in hong kong from 2011 to 2015 to develop lur models for annual average summertime average and winter average with model performance of adjusted r2 equal to 0 77 0 84 and 0 87 however by using the data from a longer period in conjunction with machine learning models our best model can further predict daily special temporal variation of co which is a much shorter term than shi et al 2017 with the same or higher level of model performance adjusted r2 value of 0 85 shi et al 2017 in addition this study considered as many variables as possible and used stepwise variable selection procedure to choose important variables with right direction of effect which have impact on co concentrations mixed spatial prediction models that combine the strength of lur in identifying the most contributed emission predictors and the predictability of machine learning in estimating non linear trend would be more broadly effective than techniques using pure lur or machine learning the large amount of data 0 42 million used in our study can yield a more robust result than a smaller dataset 20 thousands wang and sun 2019 for constructing machine learning models moreover the proposed lur machine learning approaches could be applied to develop prediction models for other types of air pollutants and in different geographic areas whenever the land use land cover data is available this study still has some limitations though there were some lacks of information about predictors for example traffic volume was not available in taiwan we can develop a better model if the land use inventory can re new its data more frequently in addition some studies have used satellite images to obtain the broad ground level observations di et al 2019 however it is not the case in taiwan because it is more difficult to take clear satellite images through taiwan s cloudy and rainy weather future studies may also incorporate land dynamics in air pollution model development when the land use land cover data is available 5 conclusions this study demonstrated the use of lur along with three different machine learning algorithms to boost the accuracy of predictions for daily co spatial temporal variations the results showed that lur with an xgboost algorithm wins the title of best prediction performance and is the most efficient method the proposed methods may be further applied to risk assessment and to the prediction of spatial temporal distribution of other air pollutants which needs further studies to confirm declaration of competing interest the authors declare that they have no known competing for financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is funded by the ministry of science and technology r o c most 108 2621 m 006 017 most 108 2638 b 006 001 my2 the authors are grateful to the national aeronautics and space administration nasa and to the u s geological survey usgs for data appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104996 
25848,integration of earth system data from various sources is a challenging task except for their qualitative heterogeneity different data records exist for describing similar earth system processes at different spatiotemporal scales data inter comparison and validation are usually performed at a single spatial or temporal scale which could hamper the identification of potential discrepancies in other scales here we propose a simple yet efficient graphical method for synthesizing and comparing observed and modelled data across a range of spatiotemporal scales instead of focusing at specific scales such as annual means or original grid resolution we examine how their statistical properties change across spatiotemporal continuum the proposed cross scale framework for integrating multi source data in earth system sciences is already developed as a stand alone r package that is freely available to download keywords dataset validation multiscale statistics earth system models earth system observations cross scale analysis multi source data 1 introduction over the last decades there is an exponential increase in the volume of earth system data consisting of not only earth system observations eso but also process based model results e g earth system models esm reanalysis products statistical machine learning algorithms etc resulting thus in the so called big data era for the earth system sciences mccabe et al 2017 the increased data availability and process understanding together with technological advancements and increased computational power lead to the development of hyper resolution esm wood et al 2011 with detailed representations of processes acting across a wide range of spatiotemporal scales mastrotheodoros et al 2020 maxwell and condon 2016 as numerical models will be soon running at a 30 m scale e g global hydrological models wood et al 2011 fatichi et al 2016 which is the resolution of terrain information globally available new challenges emerge such challenges are related to a up scaling our current process understanding from local to regional and global scales levin 1992 b evaluating datasets with high spatiotemporal resolution and c disentangling the noise from the information associated with the processes of interest sivapalan 2018 especially since strong discrepancies between different observational datasets exist like for instance various gridded data products of precipitation that have been found to differ significantly sun et al 2018 therefore methodologies that assess similarities and discrepancies between datasets or evaluate model performance are urgently needed and will be increasingly used in order to better understand model uncertainties some of which may be unavoidable and to better translate observations into abstract model representations bonan and doney 2018 most importantly while several methodologies have been developed for data exploration and model data comparisons all these efforts to date focus mainly on individual variables and spatiotemporal scales thus the challenge is how to achieve a better coupling between eso and esm on nearly all time and space scales stocker 2014 which in turn will scrutinize model limitations reveal directions for further model improvements and ultimately move towards a more predictive understanding of the earth system cross scale analysis should not be interpreted only as developing the appropriate methodological tools for model data or inter model comparison but also as the need to enhance our capability in evaluating the information content of datasets across a continuum of spatiotemporal scales rather than focusing on individual variables or specific spatiotemporal scales a better characterisation of cross scale variability of earth system datasets will allow for 1 better characterisation of the underlying processes 2 pinpointing scales that the variability of individual processes changes or interacts with other ones and 3 integrating esm and eso across a continuum of time scales here we propose a framework for jointly analysing eso and esm simulation results across a continuum of spatiotemporal scales building upon previous cross scale analyses markonis and koutsoyiannis 2013 2016 hanel et al 2017 pappas et al 2017 papalexiou et al 2020 the proposed approach offers a novel way for model data integration in earth system sciences confronting observed and simulated patterns across a continuum of scales rather than focusing on univariate goodness of fit criteria or individual scales the methodology is visualized with a graphical tool the cross scale aggregation csa plot for presentation and comparison of spatiotemporal variability including not only the variance standard deviation but also higher moments and l moments this framework is implemented in a software toolbox as an r package r core team 2019 the package is called csa and can be downloaded from cran repository or from https github com imarkonis csa the csa package supports parallel computing to maximise computational efficiency and is accompanied by simple yet robust graphical routines offering a quick and consistent data inter comparison across different spatiotemporal scales 2 methods 2 1 theoretical background a first attempt to illustrate the variability of geophysical processes across a continuum of time scales was done by the pioneering work of mitchell 1976 who made an approximation of the climatic variability spanning 13 orders of temporal magnitude following his example other researchers made more accurate estimation of climatic variability across multiple time scales using for example power spectra e g huybers and curry 2006 lovejoy 2015 or detrended fluctuation analysis approach e g koscielny bunde et al 1998 an alternative approach following the aggregated variance method beran 1994 has been also used to explore the variability of earth system processes e g markonis and koutsoyiannis 2016 pappas et al 2017 the aggregated variance method is a graphical method that examines how second order statistics i e variance standard deviation of a time series change when the time series is aggregated averaged or summed across different scales it offers a straightforward quantification of variability e g using the variance or the standard deviation as a metric of variability and thus provides a very intuitive interpretation of the emerged patterns another implementation of this technique in earth sciences is for the determination of power laws or scaling behaviour in physical processes o connell et al 2016 scaling behaviour implies that the variability of the investigated process follows a power law in different spatiotemporal scales processes characterized by intense scaling behavior present substantial clustering of values resulting both to distinct phases local means and abrupt slopes between them which is an effect of strong fluctuations across all scales mandelbrot and wallis 1968 it is also known by the names long term persistence long range dependency or long term memory the results of the aggregated variance method are usually analyzed in a two dimensional logarithmic plot where the horizontal axis corresponds to the aggregation scale and the vertical axis to the variance standard deviation fig 1 the linear slope θ of the cross scale variability continuum of the process of interest can be used to examine its scaling behaviour and quantify its strength with the hurst coefficient η 1 θ moreover η can provide insight into the vulnerability and resilience of the process of interest short term or long term persistence η 0 5 is suggestive of clustering in local minima or maxima that can be translated to slower recovery from disturbances and thus lower resilience while white noise η 0 5 implies faster fluctuation around an mean state and thus higher resilience pappas et al 2017 we have to note that there are many other methods with less bias in the estimation of h taqqu et al 1995 but recent evidence suggests that they are prone to type i error providing false positives and severely overestimating the time series variability because they assume a single scaling law markonis et al 2018 similar biases have been found in the widely used detrended fluctuation analysis method bryce and sprague 2012 we have to note though that here we focus on the pattern identification and description only and not in providing unbiased estimates of the strength of the scaling behavior if biases exist in the estimation of the slopes of the variability decay the same biases will exist in all datasets included in the graph and will not affect the inter comparison readers interested in the estimation of scaling behaviour and long term persistence can find more methodological details in the review of witt and malamud 2013 as well as in classic textbooks of beran 1994 samorodnitsky 2016 and pipiras and taqqu 2017 2 2 algorithm design the csa package is built around two key functions csa and csas for 1d and 2d aggregation respectively both functions extend the aggregated variance approach as introduced by beran 1994 by averaging the time series spatial field in increasing scales as follows 1 let x t with t 1 t be a time series and k an integer representing the scale for an increasing k create a new time series by averaging its values by 2 k n n max where n is the sample size n max is the desired sample size threshold at the final aggregation scale and the floor operator to assume the n n max is an integer 2 calculate the given statistical metric e g standard deviation of each aggregated time series in the package the available metrics are variance standard deviation skewness kurtosis coefficient of variation l scale and l moment ratios λ 2 λ 1 λ 3 λ 2 λ 4 λ 2 where λ 1 λ 2 λ 3 λ 4 correspond to first to fourth l moments respectively hosking 1990 3 plot the values of the statistical metric of interest against scale k simple linear regression or loess smoothing can then be applied to draw the aggregation curve while for variance and standard deviation there is usually a logarithmic transformation for both axes the approach is similar for 2d spatial fields but the aggregation is quadratic 2 k 2 n n max that is k 2 corresponds to 4 grid boxes k 3 to 9 etc the resulting aggregation curves in the csa plots of different datasets can then be standardized z values and merged to combine different datasets of the same or different variables fig 1 markonis and koutsoyiannis 2013 pappas et al 2017 in the csa package the algorithm is implemented in functions csa and csas for temporal and spatial domains which correspondingly use time series or raster formats building upon the raster package hijmans 2019 thus they provide the aggregation matrix of the chosen statistical metric accompanied by the csa plot with the aggregation curve this allows for further processing the results of the cross scale analysis e g estimate differences between datasets or for plotting multiple aggregation curves in joint plots taking advantage of the csa multiplot function see also section 3 it is also noteworthy that the csas function can be utilized in multi layer objects rasterbrick and rasterstack classes providing the capability for spatiotemporal analysis as well all the code of the functions that implement the algorithm can be found at https github com imarkonis csa and can be easily modified by the users to fit their specific needs 3 case study the ease of applying the csa method at different simulation results and observation records makes it very appealing it can be used to provide a first visual inspection of model data similarities and discrepancies across several spatiotemporal scales to demonstrate this we applied the methodology in five different datasets from various sources over holland three observational and two simulated datasets these are the satellite gpm imerg data product huffman et al 2015 knmi station and radar data sets as well as cnrm simulation and ncep ncar reanalysis table 1 two examples are presented analysing the variability of the aforementioned datasets across temporal and spatial domains in the first case the variance aggregation curve of each dataset is estimated and an inter comparison between the different datasets is presented each dataset comes at daily temporal resolution but different spatial resolution and hence the main daily value is estimated over the whole region producing a single time series for holland after this pre processing the csa function is applied to each dataset and then all of them are illustrated in a single csa plot for comparison using the function multi plot fig 2 looking at the joint csa plot it becomes evident that the simulation results ncep cnrm are decreasing their variability more slowly as the aggregation scale increases in comparison to the observational datasets the aggregation curve of station data remains in the middle while the satellite data product presents the most abrupt slope in addition a distinct change in slope is identified close to the scale of 100 days for cnrm simulation which is non existent in the other available time series to further assess interspecific differences between datasets the ratio of their variance can be estimated and compared fig 3 in this way it becomes clear that both simulation datasets show strong agreement with station data for scales of 2 10 days and then diverge for longer time scales in 200 300 day scales they appear to overestimate variability by almost 200 as the ratio of variance is close to 0 5 over this scale the ncep simulation convergences back to unity as presented in fig 2a suggesting a similar behavior in the interannual scales on the other hand radar and satellite products diverge in all scales with the gpm data reaching nearly double or 50 less variability compared to the station data due to short record length we cannot investigate their behavior in the interannual time scales in the second application two dimensional aggregation curves of six similar precipitation events from the satellite dataset are compared the events were randomly picked based on the arbitrary criterion that they all had mean precipitation between 10 and 11 mm day over holland for that given day fig 4 a despite their common spatial average these six events display different spatial structures as depicted in their variance csa plots fig 4b here the scales refer to the original spatial scale of gpm dataset 0 1 0 1 or 1 grid cell and due to the relatively small sample size and the quadrant increase in scale the aggregation involved only five aggregation steps from 2 to 6 thus scale 2 refers to the average of four adjacent grid cells scale 3 refers to 16 grid cells four aggregated grid cells etc more details about this case study including a fully reproducible presentation of the code used to develop it can be found at http rpubs com imarkonis csa nl 4 conclusions csa package provides a robust and intuitive way for data inter comparison and model validation we have illustrated its capabilities through a case study and highlighted its main advantages which are the ease of combining variables and datasets in a single plot and merging spatiotemporal scales towards a unified continuum fig 1 and its intuitive interpretability the csa package could support researchers over different fields in geosciences offering an intuitive way to examine processes and compare observations and model results across a continuum of time scales to this end we invite all scientists involved in modelling and or data assimilation to actively contribute to our initial step for cross scale multi source integration with their suggestions and additions for the future versions of csa declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements y m was funded by the czech science foundation grant no 20 27624y c p acknowledges the support of the swiss national science foundation snsf the stavros niarchos foundation and the eth zurich foundation grants p2ezp2 162293 and p300p2 174477 
25848,integration of earth system data from various sources is a challenging task except for their qualitative heterogeneity different data records exist for describing similar earth system processes at different spatiotemporal scales data inter comparison and validation are usually performed at a single spatial or temporal scale which could hamper the identification of potential discrepancies in other scales here we propose a simple yet efficient graphical method for synthesizing and comparing observed and modelled data across a range of spatiotemporal scales instead of focusing at specific scales such as annual means or original grid resolution we examine how their statistical properties change across spatiotemporal continuum the proposed cross scale framework for integrating multi source data in earth system sciences is already developed as a stand alone r package that is freely available to download keywords dataset validation multiscale statistics earth system models earth system observations cross scale analysis multi source data 1 introduction over the last decades there is an exponential increase in the volume of earth system data consisting of not only earth system observations eso but also process based model results e g earth system models esm reanalysis products statistical machine learning algorithms etc resulting thus in the so called big data era for the earth system sciences mccabe et al 2017 the increased data availability and process understanding together with technological advancements and increased computational power lead to the development of hyper resolution esm wood et al 2011 with detailed representations of processes acting across a wide range of spatiotemporal scales mastrotheodoros et al 2020 maxwell and condon 2016 as numerical models will be soon running at a 30 m scale e g global hydrological models wood et al 2011 fatichi et al 2016 which is the resolution of terrain information globally available new challenges emerge such challenges are related to a up scaling our current process understanding from local to regional and global scales levin 1992 b evaluating datasets with high spatiotemporal resolution and c disentangling the noise from the information associated with the processes of interest sivapalan 2018 especially since strong discrepancies between different observational datasets exist like for instance various gridded data products of precipitation that have been found to differ significantly sun et al 2018 therefore methodologies that assess similarities and discrepancies between datasets or evaluate model performance are urgently needed and will be increasingly used in order to better understand model uncertainties some of which may be unavoidable and to better translate observations into abstract model representations bonan and doney 2018 most importantly while several methodologies have been developed for data exploration and model data comparisons all these efforts to date focus mainly on individual variables and spatiotemporal scales thus the challenge is how to achieve a better coupling between eso and esm on nearly all time and space scales stocker 2014 which in turn will scrutinize model limitations reveal directions for further model improvements and ultimately move towards a more predictive understanding of the earth system cross scale analysis should not be interpreted only as developing the appropriate methodological tools for model data or inter model comparison but also as the need to enhance our capability in evaluating the information content of datasets across a continuum of spatiotemporal scales rather than focusing on individual variables or specific spatiotemporal scales a better characterisation of cross scale variability of earth system datasets will allow for 1 better characterisation of the underlying processes 2 pinpointing scales that the variability of individual processes changes or interacts with other ones and 3 integrating esm and eso across a continuum of time scales here we propose a framework for jointly analysing eso and esm simulation results across a continuum of spatiotemporal scales building upon previous cross scale analyses markonis and koutsoyiannis 2013 2016 hanel et al 2017 pappas et al 2017 papalexiou et al 2020 the proposed approach offers a novel way for model data integration in earth system sciences confronting observed and simulated patterns across a continuum of scales rather than focusing on univariate goodness of fit criteria or individual scales the methodology is visualized with a graphical tool the cross scale aggregation csa plot for presentation and comparison of spatiotemporal variability including not only the variance standard deviation but also higher moments and l moments this framework is implemented in a software toolbox as an r package r core team 2019 the package is called csa and can be downloaded from cran repository or from https github com imarkonis csa the csa package supports parallel computing to maximise computational efficiency and is accompanied by simple yet robust graphical routines offering a quick and consistent data inter comparison across different spatiotemporal scales 2 methods 2 1 theoretical background a first attempt to illustrate the variability of geophysical processes across a continuum of time scales was done by the pioneering work of mitchell 1976 who made an approximation of the climatic variability spanning 13 orders of temporal magnitude following his example other researchers made more accurate estimation of climatic variability across multiple time scales using for example power spectra e g huybers and curry 2006 lovejoy 2015 or detrended fluctuation analysis approach e g koscielny bunde et al 1998 an alternative approach following the aggregated variance method beran 1994 has been also used to explore the variability of earth system processes e g markonis and koutsoyiannis 2016 pappas et al 2017 the aggregated variance method is a graphical method that examines how second order statistics i e variance standard deviation of a time series change when the time series is aggregated averaged or summed across different scales it offers a straightforward quantification of variability e g using the variance or the standard deviation as a metric of variability and thus provides a very intuitive interpretation of the emerged patterns another implementation of this technique in earth sciences is for the determination of power laws or scaling behaviour in physical processes o connell et al 2016 scaling behaviour implies that the variability of the investigated process follows a power law in different spatiotemporal scales processes characterized by intense scaling behavior present substantial clustering of values resulting both to distinct phases local means and abrupt slopes between them which is an effect of strong fluctuations across all scales mandelbrot and wallis 1968 it is also known by the names long term persistence long range dependency or long term memory the results of the aggregated variance method are usually analyzed in a two dimensional logarithmic plot where the horizontal axis corresponds to the aggregation scale and the vertical axis to the variance standard deviation fig 1 the linear slope θ of the cross scale variability continuum of the process of interest can be used to examine its scaling behaviour and quantify its strength with the hurst coefficient η 1 θ moreover η can provide insight into the vulnerability and resilience of the process of interest short term or long term persistence η 0 5 is suggestive of clustering in local minima or maxima that can be translated to slower recovery from disturbances and thus lower resilience while white noise η 0 5 implies faster fluctuation around an mean state and thus higher resilience pappas et al 2017 we have to note that there are many other methods with less bias in the estimation of h taqqu et al 1995 but recent evidence suggests that they are prone to type i error providing false positives and severely overestimating the time series variability because they assume a single scaling law markonis et al 2018 similar biases have been found in the widely used detrended fluctuation analysis method bryce and sprague 2012 we have to note though that here we focus on the pattern identification and description only and not in providing unbiased estimates of the strength of the scaling behavior if biases exist in the estimation of the slopes of the variability decay the same biases will exist in all datasets included in the graph and will not affect the inter comparison readers interested in the estimation of scaling behaviour and long term persistence can find more methodological details in the review of witt and malamud 2013 as well as in classic textbooks of beran 1994 samorodnitsky 2016 and pipiras and taqqu 2017 2 2 algorithm design the csa package is built around two key functions csa and csas for 1d and 2d aggregation respectively both functions extend the aggregated variance approach as introduced by beran 1994 by averaging the time series spatial field in increasing scales as follows 1 let x t with t 1 t be a time series and k an integer representing the scale for an increasing k create a new time series by averaging its values by 2 k n n max where n is the sample size n max is the desired sample size threshold at the final aggregation scale and the floor operator to assume the n n max is an integer 2 calculate the given statistical metric e g standard deviation of each aggregated time series in the package the available metrics are variance standard deviation skewness kurtosis coefficient of variation l scale and l moment ratios λ 2 λ 1 λ 3 λ 2 λ 4 λ 2 where λ 1 λ 2 λ 3 λ 4 correspond to first to fourth l moments respectively hosking 1990 3 plot the values of the statistical metric of interest against scale k simple linear regression or loess smoothing can then be applied to draw the aggregation curve while for variance and standard deviation there is usually a logarithmic transformation for both axes the approach is similar for 2d spatial fields but the aggregation is quadratic 2 k 2 n n max that is k 2 corresponds to 4 grid boxes k 3 to 9 etc the resulting aggregation curves in the csa plots of different datasets can then be standardized z values and merged to combine different datasets of the same or different variables fig 1 markonis and koutsoyiannis 2013 pappas et al 2017 in the csa package the algorithm is implemented in functions csa and csas for temporal and spatial domains which correspondingly use time series or raster formats building upon the raster package hijmans 2019 thus they provide the aggregation matrix of the chosen statistical metric accompanied by the csa plot with the aggregation curve this allows for further processing the results of the cross scale analysis e g estimate differences between datasets or for plotting multiple aggregation curves in joint plots taking advantage of the csa multiplot function see also section 3 it is also noteworthy that the csas function can be utilized in multi layer objects rasterbrick and rasterstack classes providing the capability for spatiotemporal analysis as well all the code of the functions that implement the algorithm can be found at https github com imarkonis csa and can be easily modified by the users to fit their specific needs 3 case study the ease of applying the csa method at different simulation results and observation records makes it very appealing it can be used to provide a first visual inspection of model data similarities and discrepancies across several spatiotemporal scales to demonstrate this we applied the methodology in five different datasets from various sources over holland three observational and two simulated datasets these are the satellite gpm imerg data product huffman et al 2015 knmi station and radar data sets as well as cnrm simulation and ncep ncar reanalysis table 1 two examples are presented analysing the variability of the aforementioned datasets across temporal and spatial domains in the first case the variance aggregation curve of each dataset is estimated and an inter comparison between the different datasets is presented each dataset comes at daily temporal resolution but different spatial resolution and hence the main daily value is estimated over the whole region producing a single time series for holland after this pre processing the csa function is applied to each dataset and then all of them are illustrated in a single csa plot for comparison using the function multi plot fig 2 looking at the joint csa plot it becomes evident that the simulation results ncep cnrm are decreasing their variability more slowly as the aggregation scale increases in comparison to the observational datasets the aggregation curve of station data remains in the middle while the satellite data product presents the most abrupt slope in addition a distinct change in slope is identified close to the scale of 100 days for cnrm simulation which is non existent in the other available time series to further assess interspecific differences between datasets the ratio of their variance can be estimated and compared fig 3 in this way it becomes clear that both simulation datasets show strong agreement with station data for scales of 2 10 days and then diverge for longer time scales in 200 300 day scales they appear to overestimate variability by almost 200 as the ratio of variance is close to 0 5 over this scale the ncep simulation convergences back to unity as presented in fig 2a suggesting a similar behavior in the interannual scales on the other hand radar and satellite products diverge in all scales with the gpm data reaching nearly double or 50 less variability compared to the station data due to short record length we cannot investigate their behavior in the interannual time scales in the second application two dimensional aggregation curves of six similar precipitation events from the satellite dataset are compared the events were randomly picked based on the arbitrary criterion that they all had mean precipitation between 10 and 11 mm day over holland for that given day fig 4 a despite their common spatial average these six events display different spatial structures as depicted in their variance csa plots fig 4b here the scales refer to the original spatial scale of gpm dataset 0 1 0 1 or 1 grid cell and due to the relatively small sample size and the quadrant increase in scale the aggregation involved only five aggregation steps from 2 to 6 thus scale 2 refers to the average of four adjacent grid cells scale 3 refers to 16 grid cells four aggregated grid cells etc more details about this case study including a fully reproducible presentation of the code used to develop it can be found at http rpubs com imarkonis csa nl 4 conclusions csa package provides a robust and intuitive way for data inter comparison and model validation we have illustrated its capabilities through a case study and highlighted its main advantages which are the ease of combining variables and datasets in a single plot and merging spatiotemporal scales towards a unified continuum fig 1 and its intuitive interpretability the csa package could support researchers over different fields in geosciences offering an intuitive way to examine processes and compare observations and model results across a continuum of time scales to this end we invite all scientists involved in modelling and or data assimilation to actively contribute to our initial step for cross scale multi source integration with their suggestions and additions for the future versions of csa declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements y m was funded by the czech science foundation grant no 20 27624y c p acknowledges the support of the swiss national science foundation snsf the stavros niarchos foundation and the eth zurich foundation grants p2ezp2 162293 and p300p2 174477 
25849,invasive plant and environmental pests can seriously impact environment economy health and amenity it is challenging to form response policies given the diversity of pest species complex spatiotemporal interplay between arrival spread surveillance and control and limited field data when pests are rare absent models can provide useful decision support through the exploration of incursion pathways and comparison of surveillance and control strategies however increased use of quantitative models to inform pest management requires adaptable modelling frameworks the new australian priority pest and disease modelling framework appdis allows pest models to be constructed through user configuration choices for a broad range of different pest types pest populations may be defined as point incursions established populations or estimated mechanistically from environmental criteria spread occurs at multiple scales through either simple mathematical kernels or more complex spatial pathways depending on data availability and pest type useful experiments can be conducted on general surveillance specific surveillance and treatment regimes control activities are dynamically resource constrained and costed for relative comparisons in terms of benefit and cost a case study on a tramp ant incursion is provided for illustrative purposes keywords appdis aadis modelling plant pests environmental pests biosecurity 1 introduction plant and environmental pests can inflict serious damage to the economy environment human health and social amenity davis 2009 it typically falls to government to construct and fund robust policies for the early detection of and response to harmful invasive pests however it can be challenging to form cost effective policies given the inherent uncertainty of and complex spatiotemporal interplay between the arrival spread detection and control of exotic pests schmidt et al 2010 keith and spring 2013 further when a pest is rare or absent there may be limited local experience and field data to inform policies for surveillance and control eradication models can help policy makers explore potential entry points and arrival rates of invasive pests douma et al 2016 sikes et al 2018 faulkner et al 2020 camac et al 2020 potential distribution of a pest species in an environment sutherst et al 1999 phillips et al 2006 deutsch et al 2008 aurambout et al 2009 de meyer et al 2010 yang et al 2013 de villiers et al 2015 potential spread of a pest renton et al 2011 rebaudo et al 2011 adeva et al 2012 rasmussen and hamilton 2012 lustig et al 2017 cook at el 2019 briscoe et al 2019 surveillance and treatment strategies parry et al 2006 keith and spring 2013 parnell et al 2014 baxter et al 2017 the effect of resource and or cost constraints on surveillance and treatment bogich et al 2008 kompas and che 2009 hauser and mccarthy 2009 rout et al 2011 kompas et al 2016 spring et al 2017 it is however very difficult to encompass all aspects of an invasive pest incursion into a single decision support model the challenge of modelling population spread and control is magnified by the diversity of plant and environmental pests modes of dispersal and availability of data for estimating biophysical and economic relationships in detection and control a detailed spatially explicit model of an individual pest may capture life cycle and ecological specifics and take into account environmental heterogeneity but can be complex and expensive to construct and may not readily translate to other pests generalised mathematical models are simpler and cheaper to build but may not capture pest specific ecological nuances and environmental heterogeneity these challenges in pest spread modelling have resulted in a lack of general purpose modelling frameworks despite the large number of problem specific models that have been developed it has been argued that spread simulation models with the capacity to capture complex spatio temporal processes such as human assisted and vector borne spread have prohibitive time and resource costs in developing parameterizing and testing the models robinet et al 2012 this reflects an assumption that biosecurity management personnel may lack the time and or expertise to conduct such analyses most general purpose modelling frameworks for informing pest risk analysis have consequently focused on capturing simpler processes governing pest arrival and spread rafoss 2003 robinet et al 2012 kehlenbeck et al 2012 there remains a need for general purpose modelling platforms with the capacity to capture complex spatio temporal processes the australian priority pest and disease modelling framework appdis is an attempt to incorporate the key aspects of invasive pest arrival spread detection and control in a pragmatic middle ground modelling approach incorporating both generalised and pest specific techniques an appdis user can create a variety of pest specific models by supplying datasets and parameter values ie model creation is largely a configuration activity that does not require specialised mathematical reformulation and or recoding when field or environmental data is scarce or unreliable appdis can be configured to spread a pest through simple aggregative mathematical pathways alternatively data permitting appdis can be configured to spread a pest through individual data driven pathways that consider pest ecological nuances and environmental heterogeneities effective early detection surveillance can pre emptively lower a country s potential liability for incursion costs modelling approaches need to consider the likely points where a pest can establish and potential spread in relation to surveillance intensity and extent scenarios need to consider the likely success of response activities at the initial detection in order to identify the value of surveillance an appdis model allows a pest to be introduced anywhere in the study area at any point in time once established a pest population spreads over time and space according to environmental suitability via both natural and assisted spread pathways the simulated initial detection of a pest may arise from general surveillance or early detection surveillance via a permanent trapping grid appdis allows useful experimentation on the cost effectiveness of a trapping grid design via configurable trap locations spacings lure types costs and sensitivity specificity and the implications of early versus late detection containment and eradication of a pest relies upon adequate delimitation of an incursion it can be challenging to estimate the distribution of a pest in relation to presence and absence data particularly for pests with broad host ranges complex spread pathways and poor detectability there are options to either increase surveillance to better understand the extent of the incursion or to increase treatment intensity and extent in order to cover uncertainty even for well studied pests there can be gaps in the understanding of ecology surveillance efficacy and control strategies the significance of uncertainty is often not appreciated until viewed in the context of a control and containment program spatiotemporal models can be useful for testing scenarios with complex relationships that are subject to a great deal of uncertainty appdis allows useful experimentation on the cost effectiveness of delimiting surveillance and post treatment surveillance via configurable trap spacings lure types costs and sensitivity specificity and treatment via configurable treatment schedules efficacy and cost all control actions simulated by appdis have user defined durations costs and resource requirements this allows investigation into the impact of resource shortfalls on the efficacy and cost of managing an incursion a case study on the potential eradication of an established tramp ant population illustrates the steps in configuring an appdis pest model and provides some examples of model use firstly the tramp ant population is allowed to spread unchecked and emergent spread rates are compared with field observations secondly surveillance and treatment options are enabled and a sensitivity analysis is conducted on the effect of trap spacing on the cost effectiveness of eradication it is important to note that the purpose of the case study is to demonstrate configuration and use of the modelling framework and is not intended to inform policy on potential eradication of the pest in question 2 methods 2 1 the appdis modelling framework appdis is a new modelling framework that can be used to instantiate models of the spread and control of plant and environmental pests it is the plant health equivalent of the australian animal disease modelling framework aadis bradhurst et al 2015 which can be used to instantiate models of livestock disease such as foot and mouth disease bluetongue classical swine fever and african swine fever appdis pest models are stochastic discrete event simulations similar to geographic automata torrens and benenson 2005 laffan et al 2007 the study area of interest is represented by a grid delineated by lines of latitude and longitude the modelling unit of interest is a cell within the grid each cell has environmental attributes such as elevation average weekly temperature annual rainfall human population density vegetation index land use category and average weekly wind speed that can be used to estimate the spatiotemporal habitat suitability of the cell for a pest of interest the problem of modelling the incursion spread detection and control of a pest in a gridded environment is reduced to seven separate sub problems which cells are initially populated with the pest how does the within cell abundance of the pest change over time when how might the pest population spread between cells how cost effective are surveillance activities at detecting the pest how cost effective are treatment programs at controlling eradicating the pest how cost effective are post treatment surveillance activities at detecting residual pest populations how do resource constraints affect surveillance treatment and post treatment activities 2 1 1 definition of an initial pest population the grid extent and cell dimensions of an appdis model are user configurable and facilitate regional studies inside a localised grid up to national scale studies inside a much larger grid the choice of cell size will largely depend on the pest being modelled the extent of the study area and the granularity of the relevant environmental data a large cell size may not capture within cell spatial heterogeneities in vegetation land use elevation temperature etc a small cell size captures spatial temperature heterogeneities data granularity permitting but comes with a computational overhead for large grids it is advisable to restrict the total number of grid cells to under 1 048 576 so that the raster data input comma separated value csv file which is indexed row major order on cell id can be opened by a standard desktop spreadsheet program appdis provides three ways for a user to define the initial pest population in the grid point incursion one or more cells may be explicitly seeded with a pest propagule this represents an undetected post border arrival of an exotic pest for example at a port established population an established pest population can be defined via pre defined population densities or counts per cell perhaps informed by field data built in mechanistic species distribution model the location of the initial pest population can be automatically estimated by the model based on configurable ranges of environmental criteria such as temperature vegetation water sources elevation rainfall land use etc 2 1 2 within cell abundance of a pest each infested cell agent has an embedded population model that estimates the population density of a pest within a cell over time for example via logistic growth kingsland 1982 kehlenbeck et al 2012 law et al 2003 this represents how a pest population in a naive cell may initially grow exponentially but then growth will slow as the population approaches the carrying capacity of the cell roughgarden 1975 the carrying capacity of a cell is derived from user defined habitat suitability data specific to the pest being modelled this allows pest abundance to vary across the model grid based on environmental variables such as temperature elevation land use rainfall and vegetation a logistic population growth rate is unlikely to be a static value and actual population values may not be available from empirical studies appdis allows the growth rate to vary with temperature perhaps informed by laboratory data on pest development and mortality response to temperature this approach allows colder temperatures to be associated with negative growth rates and trigger seasonal declines of a population fig 1 illustrates how a logistic function can have a constant growth rate r or a variable growth rate r τ that depends on temperature τ the logistic growth model for a temperature dependent growth rate is given by equation 1 eqn 1 d t k 1 k d t 1 1 e r τ where d t pest population density on day t normalised with respect to carrying capacity k k carrying capacity of the cell normalised across all cells r τ pest population growth rate for temperature τ if the population in a cell falls below a configurable threshold it becomes quiescent and declines to extinction over a configurable period this approximates an allee effect stephens and sutherland 1999 whereby small or sparse populations represented by very low cell population densities can suffer from reduced population growth that leads to extinction although not yet investigated it would be possible for a cell agent to have multiple population models each corresponding to a distinct species this functionality could be useful for exploring interspecific mutualism with respect to presence and abundance 2 1 3 between cell spread of a pest as the within cell population density of a pest increases or decreases over time per the embedded population model the rising or falling dispersal pressure within the infested cell affects the probability of between cell spread the steady short range spread of a pest between adjoining cells is modelled by a diffusion pathway the sporadic longer range spread of a pest between cells is modelled by one or more jump pathways 2 1 3 1 diffusive spread between adjoining cells the progressive spread of a pest from an infested cell into an adjoining candidate cell is modelled with a stochastic diffusion process that considers the infested cell s pest population density the infested cell s environmental conditions e g certain wind and or temperature criteria may be required for diffusion to occur optional the environmental suitability of the candidate cell so that more suitable cells will have a higher probability of pest incursion than less suitable cells optional the elevation gradient between the centroids of the source and candidate cell optional daily decisions as to whether an infested cell diffuses into the adjoining candidate cells are made by sampling from binomial distributions of the probability of diffusion equation 2 eqn 2 p d t 1 1 p d s δ λ ε d t where pd t probability of diffusion occurring on day t pd baseline daily probability of diffusion of a viable number of pests from an infested cell into another cell configurable per land use category of the infested cell s relative suitability of the candidate cell normalised across all cells optional δ distance weight for the infested and candidate cells optional λ temperature weight of the infested cell optional ε elevation weight for the infested and candidate cells optional the optional distance weight δ is a simple relative measure of distance between the centroids of the source infested cell and the adjoining candidate cells and dampens the probability of diffusion into the north west south west north east and south east neighbours δ 0 7 as opposed to the north south west and east neighbours δ 1 0 the optional temperature weight λ is derived from the relationship between the average weekly temperature τ for the infested cell and four configured temperature thresholds for pest activity min optimal lower optimal upper and max λ 0 for τ min λ linear increase from 0 to 1 for min τ optimal lower λ 1 for optimal lower τ optimal upper λ linear decrease 1 to 0 for optimal upper τ max λ 0 for τ max the optional elevation weight ε is derived from the gradient between the centroids of the infested cell and the candidate cell it allows the user to increase decrease the probability of diffusion uphill downhill per 100 m difference in elevation the baseline daily probability of diffusion pd includes the probability of post dispersal establishment in the candidate cell a diffusion event conveys a user defined propagule from the source infested cell to the destination cell if the destination cell is naïve then it acquires an equation based population model equation 1 with the propagule as the initial population if the destination cell is already infested then the propagule is added to the population and the population model recalculated a cell can receive multiple diffusion events over the course of a simulation appdis allows environmental criteria temperature habitat suitability elevation etc to be disabled in which case diffusion is driven purely by the daily probability pd which in turn can be estimated by reverse engineering observed spread velocities of the pest 2 1 3 2 jump spread between cells invasive pest populations may spread over multiple scales whilst natural dispersal may result in short range diffusive spread less predictable mechanisms such as windborne spread and human mediated dispersal can lead to longer range jumps robinet et al 2009 gippet et al 2019 the sporadic longer range spread of a pest from an infested cell into non adjoining cells is modelled with one or more stochastic jump processes that consider the infested cell s pest population density the infested cell s environmental conditions e g certain wind and or temperature criteria may be required for a jump to occur optional the environmental suitability of the candidate destination cell optional the human population density of the infested cell optional the land use of the infested cell optional the land use of the candidate destination cell optional waterways in the infested and candidate destination cells optional daily decisions as to whether an infested cell disperses into a distant cell are made by sampling from a binomial distribution of the probability of a jump event equation 3 eqn 3 p j t 1 1 p j ω λ d t where pj t probability of a jump occurring on day t pj baseline daily probability of a jump occurring ω human population density of the infested cell normalised across all cells optional λ temperature weight of the infested cell optional the jump direction may be random influenced by the land use category of the source and destination cells or influenced by the weekly prevailing wind direction the jump distance is determined by sampling from a betapert vose 2008 distance distribution a catchment area of cells is formed at the site of the jump landing based on either a user defined moore neighbourhood range or radial distance the jump destination cell is then selected from the candidates within the catchment area either randomly or based on suitability criteria as per diffusion the baseline daily probability pj of a jump occurring includes the probability of post dispersal establishment in the candidate cell a jump event conveys a user defined propagule from the source infested cell to the destination cell if the destination cell is naïve then it acquires an equation based population model with the propagule as the initial population if the destination cell is already infested then the propagule is added to the population and the population model recalculated a cell can receive multiple jump events over the course of a simulation pj can be estimated either from expert opinion or the frequency that satellite pest colonies are observed arising unexpectedly some distance from a known infested area 2 1 4 general surveillance general surveillance by members of the public is an important means of early detection of plant and environmental pests cacho et al 2010 hester and cacho 2017 wilson et al 2004 all cells that have both a pest population and a human population are scanned daily for detections by a stochastic process that considers the infested cell s pest population density the infested cell s human population density the sensitivity of the observer the probability of a general surveillance detection event occurring on any given day is adapted from sharov et al 1998 and bogich et al 2008 and is given by equation 4 eqn 4 p t p t 1 e d t ω s e where ptp t probability of a true positive detection occurring on day t ω human population density of the infested cell normalised across all cells se sensitivity of the observer the observer sensitivity for unmanaged cells is defined separately to that for managed cells a managed cell is defined as any cell that is undergoing or has undergone delimiting surveillance or treatment the model provides the option of the first general surveillance detection occurring on a fixed day rather than on a stochastically determined day this allows useful experimentation on the impact of time to detection on incursion severity and cost fig 2 uses equation 4 with se 0 70 to illustrate how the probability of a general surveillance detection varies with respect to the normalised pest population density and the normalised human population density 2 1 5 early detection surveillance there is considerable interest in the cost effectiveness of surveillance strategies for invasive species field et al 2004 gerber et al 2005 bogich et al 2008 hauser and mccarthy 2009 kompas and che 2009 cacho et al 2010 epanchin niell et al 2014 holden et al 2016 appdis allows the user to define a permanent trapping grid of geolocated traps with specified lure types all cells that have both a pest population and a permanent trap location are scanned daily for active detections the detection of a pest population is modelled with a stochastic process that considers the infested cell s pest population density the lure type and spacing of traps in the infested cell the sensitivity of the surveillance process traps and personnel the specificity of the surveillance process traps and personnel the probability of a true positive detection occurring on day t is adapted from sharov et al 1998 and bogich et al 2008 and is given by equation 5 eqn 5 p t p t 1 e a t φ s e where ptp t probability of a true positive detection on day t a t pest area of the infested cell in hectares on day t φ trap density traps per hectare in the infested cell 10 000 trap spacing in metres 2 se sensitivity of the surveillance process traps and personnel as the pest area a t of an infested cell is not actually known as cells are atomic it is proxied by multiplying the normalised population density of the cell d t by the cell area in hectares the model also provides the option of the first early detection occurring on a fixed day rather than on a stochastically determined day this allows useful experimentation on the impact of time to detection on incursion severity and cost fig 3 uses equation 5 with se 0 96 to illustrate how the probability of early detection inside a 10 ha cell varies with the normalised pest population density and trap spacing if a surveyed cell does not yield a true positive result then it is checked for a false positive result the probability of a false positive detection occurring is given by equation 6 eqn 6 p f p 1 s p where pfp probability of a false positive detection sp specificity of the surveillance process traps and personnel if a surveyed cell does not yield a positive result then a true false negative result is assigned according to the actual absence presence of the pest in the cell 2 1 6 delimiting surveillance after a pest population has been detected in a cell the surrounding cells undergo delimiting surveillance delimiting surveillance comprises a configurable number of periodic surveillance visits delimiting surveillance operates in either moore mode where the cells in the moore neighbourhood of the detected cell are surveyed or radial mode where all cells within a configurable distance of the detected cell are surveyed the detection of a pest population through delimiting surveillance is modelled by a stochastic process that considers the surveyed cell s pest population density trap spacing in the surveyed cell the sensitivity of the surveillance process traps and personnel the specificity of the surveillance process traps and personnel the daily probability of a true positive detection is given by equation 5 if a cell does not yield a true positive result it is then checked for a false positive detection equation 6 a positive surveillance result triggers a treatment program if a cell does not yield a positive result then a true false negative result is assigned according to the actual absence presence of the pest in the cell the pest is deemed absent from a cell once a configurable number of consecutive negative surveillance results has been reached 2 1 7 treatment all cells that have yielded a positive result true or false from general surveillance early detection surveillance or delimiting surveillance undergo a treatment program a treatment program comprises a configurable number of treatments conducted at a configurable period each treatment reduces the population by a percentage amount determined stochastically between a configured minimum and maximum reduction a pest population is deemed extinct if a treatment program reduces it to below the configured minimum population size a treatment program may operate in spot mode where only the detected cell is treated moore mode where all cells in the moore neighbourhood of the detected cell are treated or radial mode where all cells within a configurable distance of the detected cell are treated 2 1 8 post treatment surveillance post treatment surveillance commences at a configurable period after the completion of the last scheduled treatment a post treatment surveillance program comprises a configurable number of periodic surveillance visits post treatment surveillance is modelled with a stochastic process that considers the surveyed cell s pest population density the trap spacing in the surveyed cell sensitivity of the surveillance process traps and personnel specificity of the surveillance process traps and personnel as per delimiting surveillance the daily probability of a true positive detection is given by equation 5 if a cell does not yield a true positive result it is then checked for a false positive detection equation 6 a positive post treatment surveillance result triggers another treatment program if a cell does not yield a positive result then a true false negative result is assigned according to the actual absence presence of the pest in the cell a cell is deemed free of the pest after a configurable number of consecutive negative surveillance results 2 1 9 resourcing the active surveillance and treatment of plant and environmental pests are typically resource constrained processes rout et al 2011 mccarthy et al 2012 an appdis resource is abstract in the sense that it is a user defined set of personnel equipment supplies required to carry out a specific job the model maintains pools for each resource type early detection surveillance delimiting surveillance treatment and post treatment surveillance the resourcing profile for each pool is configurable as to whether resource levels are fixed or vary over time when a field operation is scheduled a resource is requested from the corresponding pool if a resource is available then it is borrowed from the pool and the field operation commences if a resource is not available then the field operation is queued until such time as the required resource becomes available once a field operation has completed the resource is returned to the pool the model reports the daily resource usage for early detection surveillance delimiting surveillance treatment and post treatment surveillance resource pools can be configured to be unlimited in which case resources are always immediately granted upon request in this mode the resourcing profile of an outbreak is a model output instead of a model input that constrains the efficacy of the control program 2 1 10 implementation highlights the appdis modelling framework utilises an agent based modelling platform bradhurst 2015 which can operate in four modes contagious livestock disease vector borne livestock disease plant environmental pests and human disease when modelling the spread and control of contagious disease in livestock the agents are herds farms containers of one or more herds saleyards and abattoirs when modelling the spread and control of plant and environmental pests the agents are cells in a lattice environment when modelling the spread and control of insect vector borne livestock disease such as bluetongue the agents are herds farms saleyards abattoirs and cells when modelling the spread and control of human disease the agents are people descriptions of the vector borne livestock and human disease modes will appear in future papers the modelling behaviour livestock disease plant environmental pests or human disease of an instantiated model is purely determined by the configuration files and database loaded an appdis agent can have an embedded population model of the within agent abundance over time for example when modelling an exotic fruit fly incursion each infested cell agent has an embedded temperature dependent logistic growth model that predicts the within cell population over time an agent can also have an embedded infection model of the within agent prevalence of a pathogen in the population for example when modelling the spread of a contagious disease in feral pigs each infected cell agent has an embedded seird susceptible exposed infectious recovered deceased compartmental disease model implemented as a system of ordinary differential equations that predicts the within cell infected and infectious prevalence of the disease over time the interplay between a cell agent s population and infection models will be described in a separate paper the details of the population and infection models are private to the agent which means that alternate within cell models can be used without impacting the greater model appdis models scale well as the agents are threadless and lightweight appdis agents interact in a spatially explicit disaggregated environment comprised of threaded components that operate concurrently and independently bradhurst 2015 examples of components relevant to contagious livestock disease include local spread direct spread saleyard spread indirect spread airborne spread movement restrictions surveillance tracing vaccination stamping out and post outbreak surveillance bradhurst et al 2015 examples of components relevant to plant environmental pests include unaided diffusive spread human mediated hitchhiking spread wind assisted airborne spread early detection surveillance general surveillance delimiting surveillance treatment and post treatment surveillance all appdis components are independent and can be separately enabled disabled as the implementation of each component is private alternate components can be swapped in and out for example the implementation of a treatment component can completely change without impacting the rest of the model appdis has a concurrent software architecture that allows it to take advantage of the cheap parallelism available with multi core personal computers this together with other design efficiencies such as an in memory database and grid based spatial indexing allow appdis to efficiently conduct national scale simulations bradhurst et al 2016 further details on the underlying model and software architecture can be found in bradhurst 2015 and bradhurst et al 2016 the primary appdis outputs are csv files which can be post processed statistically appdis also provides a graphical user interface for interacting with the model and dynamic visualisation of incursions as they unfold the ability for appdis to convey incursion and management concepts visually may suit it to classroom use fig 4 is a screenshot of appdis depicting a hitchhiking escape of a tramp ant population from within the managed area the population model of any cell can be visualised for example fig 4 depicts the population of cell 70814 being knocked down over the course of a treatment program and the residual population recovering over time 2 1 11 verification and validation the appdis and aadis modelling frameworks have a common underlying software baseline bradhurst 2015 appdis thus inherits from previous aadis verification and validation activities and modelling studies bradhurst 2015 bradhurst et al 2015 bradhurst et al 2016 garner et al 2016 bradhurst et al 2019 firestone et al 2019 bradhurst et al 2021 firestone et al 2020 appdis models were instantiated for anoplolepis gracilipes yellow crazy ant and bactrocera dorsalis oriental fruit fly case studies during development of the framework a model has also been developed of the spread of disease in feral pigs the yellow crazy ant model is described in this paper and the oriental fruit fly and feral pig models will be described in separate future papers appdis validation will be an ongoing process as each new pest or pest group model instantiation will require separate validation 2 1 12 hardware and platform specifications and software availability appdis is written in java oracle 2020 and employs open source products such as sql power architect sql power group 2020 postgresql 2020 openmap bbn 2016 and log4j apache 2020 appdis runs under either linux or windows with a recommended minimum hardware configuration of a quad core processor 16 gb ram and a 1920 1080 display resolution the model is available at no cost for non commercial use under a licensing agreement with the australian department of agriculture water and the environment 2 2 case study established population of tramp ants tramp ants are a diverse group of invasive ant species that can severely impact native species and habitats agriculture forestry human health and social amenity if introduced they can rapidly establish and spread through natural and human mediated dispersal abbott 2005 hoffman 2014 an example of a tramp ant that is a concern to australia is anoplolepis gracilipes yellow crazy ant yca yca causes severe ecological damage abbott 2005 2006 and can affect the horticulture industry by farming sap sucking scale insects for honeydew this can lead to larger infestations of pests on host plants haines and haines 1978b lach and barker 2013 helms 2013 and an increase in the risk of disease being transmitted to plants through insect vectors supercolonies are formed through colony budding and the absence of intraspecific aggression o dowd et al 1999 2 2 1 model setup 2 2 1 1 study area this study area for this case study was approximately 18 724 km2 bounded by latitudes 16 450 to 17 941 and longitudes 145 090 to 146 149 a cell size of 10 ha was chosen to reflect the observation that a yca supercolony spanning an area less than 10 ha tends to be a single contiguous population whereas a supercolony spanning an area greater than 10 ha tends to be comprised of fragmented populations hoffmann 2014 appdis raster data layers were defined for land use sugar cane farms sugar cane railway corridors managed land natural areas watercourses elevation human population density yca habitat suitability land suitable sea lakes unsuitable yca densities have previously been estimated at between 0 2 million and 3 5 million per hectare haines and haines 1978a and up to 20 million per hectare abbott 2005 as the habitat suitability data layer for this study was very simple a conservative grid wide carrying capacity of 2 million yca per hectare was chosen this means that every land cell is deemed equally suitable for yca with a nominal carrying capacity of 20 million this simplistic assumption could be improved with a richer habitat suitability layer that incorporates variables such as rugosity and food sources in the determination of cell suitability which in turn would provide heterogeneity in cell carrying capacity the initial yca population fig 5 spanned 154 cells cell population densities were synthesized graduating from a population of 20 million in cells at the centre of large clusters down to 2000 in cells at the edge of clusters this resulted in an overall initial yca population of approximately 310 million across 1540 ha the initial yca population of any subsequently infested cell was an arbitrary propagule deemed to comprise 24 workers and 1 queen 2 2 1 2 within cell abundance the abundance of the yca population within an infested cell over time was represented by a deterministic logistic growth function equation 1 with a temperature independent population growth rate r τ 0 025 based on the assumption that for an ideally suitable 10 ha cell an uncontrolled yca population will take approximately 2 years to grow from a single propagule n 25 to 99 of the cell carrying capacity n 19 8m this implies that 50 of the carrying capacity is reached after 454 days natural contractions of yca populations abbott 2006 were not modelled 2 2 1 3 diffusive spread of yca between adjoining cells an appdis diffusion spread pathway was instantiated to model the steady spread of yca over time to adjoining cells the baseline daily probability of diffusion pd required for equation 2 depends on the land use category of the infested cell table 1 this allows heterogeneity in the diffusive behaviour for example diffusion in a cane farm cell where natural budding is perhaps augmented by short range movements arising from within farm activities such as harvesting is assumed to be more vigorous than diffusion in a national park cell that is primarily due to natural budding 2 2 1 4 spread between non adjoining cells due to sugar cane farming activities an appdis jump spread pathway was instantiated to model the sporadic spread of yca due to medium range hitchhiking from sugar cane farming activities jumps were parameterised to only originate from cells containing sugar cane farms and only end in cells that had either sugar cane farms or railway corridors the ability to define the baseline daily probability pj equation 3 per land use category allows heterogeneity in the jumping frequency table 2 for example jumps between cane farms brought about by harvesting activities spanning multiple farms can be defined differently to jumps from cane farms to cane railway corridors brought about by cane rail transportation seasonal variations in cane farming activities were not modelled i e the pathway represents average cane jumps over the course of a year 2 2 1 5 spread between cells due to human mediated hitchhiking an appdis jump spread pathway was instantiated to model the sporadic spread of yca via human mediated hitchhiking unrelated to cane farming activities jumps were parameterised to only involve cells with a non zero human population density table 3 although the model allows a proportion of jumps to end in non populated cells simulating for example movements into natural areas the feature was not enabled for this case study 2 2 1 6 spread between cells due to rafting an appdis jump spread pathway was instantiated to model the sporadic spread of yca due to rafting jumps were parameterised to only originate from cells containing watercourses and only end in lower elevation cells that contain watercourses table 4 2 2 1 7 general surveillance an appdis general surveillance component was instantiated per table 5 2 2 1 8 specific surveillance and treatment appdis delimiting surveillance treatment and post treatment components were instantiated per table 6 2 2 1 9 resources the appdis resources component was set to unlimited i e surveillance and treatment activities were not resource constrained 2 2 2 scenario 1 uncontrolled spread the established yca population fig 5 was allowed to spread without surveillance or treatment for 30 years and the emergent rates and extent of spread recorded the scenario was repeated 50 times 2 2 3 scenario 2 sensitivity of delimiting surveillance trap spacing the established yca population fig 5 was allowed to spread in conjunction with surveillance and treatment programs the delimiting surveillance trap spacing parameter table 6 was systematically varied between 2 and 100 m while the post treatment surveillance trap spacing was held constant at 10 m 500 iterations of the scenario were run for each trap spacing the maximum length of a scenario was limited to 15 years 5475 days 2 2 4 scenario 3 sensitivity of post treatment surveillance trap spacing the established yca population fig 5 was allowed to spread in conjunction with surveillance and treatment programs the post treatment surveillance trap spacing parameter table 6 was systematically varied between 2 and 100 m while the delimiting surveillance trap spacing was held constant at 10 m 500 iterations of the scenario were run for each trap spacing the maximum length of a scenario was limited to 15 years 5475 days 3 results 3 1 scenario 1 results uncontrolled spread table 7 provides a summary of uncontrolled yca spread over 30 years convergence estimates the percentage standard error e of the sample mean with 95 confidence for a given number of iterations equation 7 driels and shin 2004 eqn 7 e 100 z c s x x n where e percentage standard error of the sample mean zc confidence coefficient 1 96 95 sx sample standard deviation x sample mean n number of runs fig 6 provides a snippet of the yearly spread report for the case study the model outputs the population density for each active cell at the end of every year for each simulation run the model creates a pest distribution risk map that represents how often a cell was infested across all iterations of a particular scenario fig 7 presents a colour coding of cells in the study area where the most frequently infested cells are encoded in red and the least frequently infested cells in yellow 3 2 scenario 2 results sensitivity of delimiting surveillance trap spacing table 8 and figs 8 and 9 summarise the effect of delimiting surveillance trap spacing on the average cost and effectiveness of control eradication 3 3 scenario 3 results sensitivity of post outbreak surveillance trap spacing table 9 and figs 10 and 11 summarise the effect of post treatment surveillance trap spacing on the average cost and effectiveness of control eradication 4 discussion 4 1 uncontrolled spread the average yca diffusion rate over a 30 year period ranged from 68 m year in natural areas up to 132 m year in cane farming areas this is broadly in line with reported budding distances of 125 m year on average range 37 402 haines and haines 1978a and up to 182 m per year abbott 2006 note that cells may have multiple land uses e g cane managed railway managed and each cell diffuses based on its highest risk land use this can artificially boost the diffusion rate for the lower risk land use of the cell e g a managed cell with cane fields contributes correctly to the overall cane diffusion rate but over contributes to the overall managed land diffusion rate dispersion via winged flight of queens fission was not explicitly modelled as it is unclear whether this is an important means of dispersal for yca rao et al 1991 haines et al 1994 o dowd et al 1999 abbott et al 2014 hoffmann 2014 it would have been possible data permitting to include a fission jump pathway as the model supports multiple concurrent jump spread pathways longer range sporadic spread of yca via hitchhiking is more unpredictable and harder to quantify than steady diffusive spread the probability of spread via human mediated hitchhiking is influenced by an infested cell s pest population density and human population density however the frequency and distance of such jumps is largely driven by expert opinion and inference from unexpected satellite colonies for example an unexpected appearance of yca in russett park queensland 30 km from the nearest known infestation near cairns queensland was attributed to hitchhiking via the transportation of landscaping materials as illustrated in fig 7 one of the outputs of appdis is a risk map of spread driven by the number of times a cell is infested over a series of scenario runs the land uses of the resultant infested cells can be analysed to provide an estimation of the potential long term impact on agricultural residential and environmentally sensitive areas this case study strongly suggests that 30 years of uncontrolled spread of yca would lead to significant incursions into the wet tropics world heritage area the simulation produced very good convergence 2 90 of the mean number of infested cells after 50 iterations this implies there is 95 confidence of only 2 90 standard error in the distribution of the sample mean 4 2 sensitivity of surveillance trap spacing the cost of control was largely independent of delimiting surveillance trap spacings greater than 20 m but rose steeply for trap spacings less than 20 m fig 8 the cost of control was weakly dependent on post treatment surveillance trap spacings greater than 10 m and rose steeply for trap spacings less than 10 m fig 10 the effectiveness of control measured by population reduction and incursion duration was far more sensitive to post treatment surveillance trap spacing than delimiting surveillance trap spacing figs 8 and 9 shows how the yca population was reduced by 99 within 15 years for all delimiting surveillance trap spacings in contrast only post treatment surveillance trap spacings between 2 and 10 m resulted in a 99 population reduction within 15 years figs 10 and 11 the effectiveness of control decreased markedly as post treatment surveillance trap spacing increased with a trap spacing of 100 m yielding no net population reduction after 15 years this suggests that the effectiveness of post treatment surveillance is a vital aspect of pest eradication fig 10 indicates that a post treatment surveillance trap spacing of 18 m minimised the cost of control at approximately a 23 5m and resulted in an average 95 population reduction however to achieve an average 99 99 population reduction the required 2 m post treatment surveillance trap spacing would however incur a much higher cost of approximately a 163m the decrease in control effectiveness with increased post treatment surveillance trap spacing is also reflected by the average model runtime per iteration in scenario 2 where the post delimiting surveillance trap spacing was held steady at 10 m while the delimiting surveillance trap spacing was varied the average model runtime per scenario iteration was reasonably stable average 60 50 s standard deviation 9 68 table 8 in scenario 3 where the delimiting surveillance trap spacing was held steady at 10 m while the post outbreak surveillance trap spacing was varied the average model runtime per scenario iteration was strongly dependent on trap spacing ranging from 28 04 to 141 75 s this is due to the additional treatment and post treatment surveillance activities and hence simulation processing required when the surveillance strategy is less effective reflected by higher false negative results table 9 the high sensitivity of control cost effectiveness to post treatment surveillance trap spacing is perhaps because post treatment surveillance is typically conducted in cells with very small pest densities as shown in fig 3 the model s implementation of specific surveillance is highly sensitive to trap spacing at low pest population densities an incorrect determination of pest absence in a treated cell after 4 successive false negative results leads to cell populations that will recover over time in the absence of an early detection surveillance system the subsequent detection of a residual population relies on general surveillance the probability of a general surveillance detection is however greatly reduced at low pest and human population densities fig 2 the simulations produced very good convergence for the mean total cost of control 1 7 this implies 95 confidence that there is at most 1 7 standard error in the distribution of the sample mean and that 500 iterations of the scenarios were sufficient 4 3 advantages and limitations of the appdis modelling approach decision support tools that represent the spread of a pest in an environment range from simple aggregative mathematical models to complex pest specific spatial simulations aggregative mathematical models generally do not take host and environmental heterogeneity into account but are concise easy to parameterise scalable computationally efficient and may be readily extensible to other pests they can be very useful for the fast prototyping of incursion dynamics especially when data is scarce or unreliable detailed spatially explicit and pest specific simulations can capture environmental and host heterogeneities but are data dependent can be complicated to construct and parameterise may not scale well computationally and may not be readily extensible to other pests the appdis modelling framework attempts to find a pragmatic middle ground between the biological and ecological fidelity of a complex pest specific spatial model and the extensibility of a generalised mathematical model appdis is flexible in that a user can configure either simple or complex spread models in studies where field data is scarce or unreliable a simple mathematical spread model is obtained by disabling the environmental data layers and configuring an aggregative diffusion kernel based on predicted spread rates a complex spread model can be achieved by enabling environmental data layers and configuring individual spread pathways that consider heterogeneities in elevation temperature wind speed vegetation land use human population density etc once a model is spreading a pest in a way that is congruent with available field data and expert opinion a decision support tool should allow useful experimentation with surveillance and control strategies a further design tension exists between implementing detailed pest specific detection control options that may not be readily extensible to other pests and or jurisdictions and implementing generalised detection control options that may not be detailed enough for the pest under study again appdis attempts to find a pragmatic middle ground by providing detection control options that are detailed enough to be useful yet abstract enough to extend to a range of pests surveillance and treatment regimes are configurable by the user in generalised terms such as duration cost resource requirements efficacy sensitivity and specificity as the underlying pest spread mechanisms are stochastic a control policy can be trialed against a distribution of plausible incursions in this way despite inherent uncertainty in how an exotic pest population may spread confidence can be gained as to the likelihood of a particular policy to achieve the desired control eradication outcome configuring an appdis model for a pest or pest group requires personnel versed in pest ecology plant health policy and the appdis modelling platform including the assembly of supporting data parameterisation designing and running incursion scenarios and statistical interpretation of simulation results the configuration effort required when employing disaggregated data driven spread pathways is considerably more than that required for aggregative mathematical pathways an advantage of a disaggregated approach to modelling spread by simulating each spread pathway separately is that control measures can be applied to specific spread pathways for example consider a pest that spreads through a windborne pathway and a market driven pathway with a disaggregated modelling approach it is easy to test the effect of movement restrictions on the market driven pathway whilst still allowing the airborne pathway to spread the pest this is more difficult when all spread pathways are aggregated into a single mathematical spread mechanism a disadvantage of grid based modelling approaches is that point based agricultural entities such as orchards nurseries and markets are not represented it would be possible to extend appdis to include point based entities and directed spread pathways as is the case with the aadis framework however this would require further development of the framework and consultation with domain experts to ensure that entities and networks are captured in an abstract way that extends to as many pest species as possible whilst models can assist with preparedness and planning for incursions and in some cases response they can suffer silently from poor assumptions sub standard data inadequate validation and improper use flawed models have the potential to mislead rather than inform particularly when modelling outputs are detailed and appear definitive appdis is primarily a data driven model and as such relies heavily on the quality of the underlying data and parameterisation each instantiation of appdis for a new pest species or pest species group will require a separate validation process that fosters user trust in the model assumptions data parameterisation and capabilities appdis models are best suited to relative comparisons between control and resourcing strategies rather than predicting incursion outcomes in absolute terms 4 4 conclusions appdis is a general purpose plant and environmental pest modelling framework that is extensible not tied to a specific pest scalable operable regionally and nationally and flexible offering simple equation based spread pathways or complex data driven pathways that capture heterogeneity in the host environment appdis allows relative comparisons of strategies for early detection surveillance delimiting surveillance treatment and post treatment surveillance with respect to efficacy resource usage and cost the case study has demonstrated the potential for appdis to assist with decision support for both plant pests and environmental pests importantly appdis is extensible to a range of pests via user configurable parameters i e without the need for specialised mathematical reformulation and or computer programming funding the work was funded by the australian department of agriculture water and the environment via the centre of excellence for biosecurity research analysis cebra project 170606 developing models for the spread and management of national priority plant pests declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this paper is derived from research and development undertaken in 2018 and 2019 as part of cebra project 170606 developing models for the spread and management of national priority plant pests the authors would like to acknowledge the support of the australian department of agriculture water and the environment the new zealand ministry for primary industries and the centre of excellence for biosecurity risk analysis within the university of melbourne school of biosciences the authors would like to thank the wet tropics management authority dr aaron dodd and dr james camac for assistance with the data that informed the tramp ant case study 
25849,invasive plant and environmental pests can seriously impact environment economy health and amenity it is challenging to form response policies given the diversity of pest species complex spatiotemporal interplay between arrival spread surveillance and control and limited field data when pests are rare absent models can provide useful decision support through the exploration of incursion pathways and comparison of surveillance and control strategies however increased use of quantitative models to inform pest management requires adaptable modelling frameworks the new australian priority pest and disease modelling framework appdis allows pest models to be constructed through user configuration choices for a broad range of different pest types pest populations may be defined as point incursions established populations or estimated mechanistically from environmental criteria spread occurs at multiple scales through either simple mathematical kernels or more complex spatial pathways depending on data availability and pest type useful experiments can be conducted on general surveillance specific surveillance and treatment regimes control activities are dynamically resource constrained and costed for relative comparisons in terms of benefit and cost a case study on a tramp ant incursion is provided for illustrative purposes keywords appdis aadis modelling plant pests environmental pests biosecurity 1 introduction plant and environmental pests can inflict serious damage to the economy environment human health and social amenity davis 2009 it typically falls to government to construct and fund robust policies for the early detection of and response to harmful invasive pests however it can be challenging to form cost effective policies given the inherent uncertainty of and complex spatiotemporal interplay between the arrival spread detection and control of exotic pests schmidt et al 2010 keith and spring 2013 further when a pest is rare or absent there may be limited local experience and field data to inform policies for surveillance and control eradication models can help policy makers explore potential entry points and arrival rates of invasive pests douma et al 2016 sikes et al 2018 faulkner et al 2020 camac et al 2020 potential distribution of a pest species in an environment sutherst et al 1999 phillips et al 2006 deutsch et al 2008 aurambout et al 2009 de meyer et al 2010 yang et al 2013 de villiers et al 2015 potential spread of a pest renton et al 2011 rebaudo et al 2011 adeva et al 2012 rasmussen and hamilton 2012 lustig et al 2017 cook at el 2019 briscoe et al 2019 surveillance and treatment strategies parry et al 2006 keith and spring 2013 parnell et al 2014 baxter et al 2017 the effect of resource and or cost constraints on surveillance and treatment bogich et al 2008 kompas and che 2009 hauser and mccarthy 2009 rout et al 2011 kompas et al 2016 spring et al 2017 it is however very difficult to encompass all aspects of an invasive pest incursion into a single decision support model the challenge of modelling population spread and control is magnified by the diversity of plant and environmental pests modes of dispersal and availability of data for estimating biophysical and economic relationships in detection and control a detailed spatially explicit model of an individual pest may capture life cycle and ecological specifics and take into account environmental heterogeneity but can be complex and expensive to construct and may not readily translate to other pests generalised mathematical models are simpler and cheaper to build but may not capture pest specific ecological nuances and environmental heterogeneity these challenges in pest spread modelling have resulted in a lack of general purpose modelling frameworks despite the large number of problem specific models that have been developed it has been argued that spread simulation models with the capacity to capture complex spatio temporal processes such as human assisted and vector borne spread have prohibitive time and resource costs in developing parameterizing and testing the models robinet et al 2012 this reflects an assumption that biosecurity management personnel may lack the time and or expertise to conduct such analyses most general purpose modelling frameworks for informing pest risk analysis have consequently focused on capturing simpler processes governing pest arrival and spread rafoss 2003 robinet et al 2012 kehlenbeck et al 2012 there remains a need for general purpose modelling platforms with the capacity to capture complex spatio temporal processes the australian priority pest and disease modelling framework appdis is an attempt to incorporate the key aspects of invasive pest arrival spread detection and control in a pragmatic middle ground modelling approach incorporating both generalised and pest specific techniques an appdis user can create a variety of pest specific models by supplying datasets and parameter values ie model creation is largely a configuration activity that does not require specialised mathematical reformulation and or recoding when field or environmental data is scarce or unreliable appdis can be configured to spread a pest through simple aggregative mathematical pathways alternatively data permitting appdis can be configured to spread a pest through individual data driven pathways that consider pest ecological nuances and environmental heterogeneities effective early detection surveillance can pre emptively lower a country s potential liability for incursion costs modelling approaches need to consider the likely points where a pest can establish and potential spread in relation to surveillance intensity and extent scenarios need to consider the likely success of response activities at the initial detection in order to identify the value of surveillance an appdis model allows a pest to be introduced anywhere in the study area at any point in time once established a pest population spreads over time and space according to environmental suitability via both natural and assisted spread pathways the simulated initial detection of a pest may arise from general surveillance or early detection surveillance via a permanent trapping grid appdis allows useful experimentation on the cost effectiveness of a trapping grid design via configurable trap locations spacings lure types costs and sensitivity specificity and the implications of early versus late detection containment and eradication of a pest relies upon adequate delimitation of an incursion it can be challenging to estimate the distribution of a pest in relation to presence and absence data particularly for pests with broad host ranges complex spread pathways and poor detectability there are options to either increase surveillance to better understand the extent of the incursion or to increase treatment intensity and extent in order to cover uncertainty even for well studied pests there can be gaps in the understanding of ecology surveillance efficacy and control strategies the significance of uncertainty is often not appreciated until viewed in the context of a control and containment program spatiotemporal models can be useful for testing scenarios with complex relationships that are subject to a great deal of uncertainty appdis allows useful experimentation on the cost effectiveness of delimiting surveillance and post treatment surveillance via configurable trap spacings lure types costs and sensitivity specificity and treatment via configurable treatment schedules efficacy and cost all control actions simulated by appdis have user defined durations costs and resource requirements this allows investigation into the impact of resource shortfalls on the efficacy and cost of managing an incursion a case study on the potential eradication of an established tramp ant population illustrates the steps in configuring an appdis pest model and provides some examples of model use firstly the tramp ant population is allowed to spread unchecked and emergent spread rates are compared with field observations secondly surveillance and treatment options are enabled and a sensitivity analysis is conducted on the effect of trap spacing on the cost effectiveness of eradication it is important to note that the purpose of the case study is to demonstrate configuration and use of the modelling framework and is not intended to inform policy on potential eradication of the pest in question 2 methods 2 1 the appdis modelling framework appdis is a new modelling framework that can be used to instantiate models of the spread and control of plant and environmental pests it is the plant health equivalent of the australian animal disease modelling framework aadis bradhurst et al 2015 which can be used to instantiate models of livestock disease such as foot and mouth disease bluetongue classical swine fever and african swine fever appdis pest models are stochastic discrete event simulations similar to geographic automata torrens and benenson 2005 laffan et al 2007 the study area of interest is represented by a grid delineated by lines of latitude and longitude the modelling unit of interest is a cell within the grid each cell has environmental attributes such as elevation average weekly temperature annual rainfall human population density vegetation index land use category and average weekly wind speed that can be used to estimate the spatiotemporal habitat suitability of the cell for a pest of interest the problem of modelling the incursion spread detection and control of a pest in a gridded environment is reduced to seven separate sub problems which cells are initially populated with the pest how does the within cell abundance of the pest change over time when how might the pest population spread between cells how cost effective are surveillance activities at detecting the pest how cost effective are treatment programs at controlling eradicating the pest how cost effective are post treatment surveillance activities at detecting residual pest populations how do resource constraints affect surveillance treatment and post treatment activities 2 1 1 definition of an initial pest population the grid extent and cell dimensions of an appdis model are user configurable and facilitate regional studies inside a localised grid up to national scale studies inside a much larger grid the choice of cell size will largely depend on the pest being modelled the extent of the study area and the granularity of the relevant environmental data a large cell size may not capture within cell spatial heterogeneities in vegetation land use elevation temperature etc a small cell size captures spatial temperature heterogeneities data granularity permitting but comes with a computational overhead for large grids it is advisable to restrict the total number of grid cells to under 1 048 576 so that the raster data input comma separated value csv file which is indexed row major order on cell id can be opened by a standard desktop spreadsheet program appdis provides three ways for a user to define the initial pest population in the grid point incursion one or more cells may be explicitly seeded with a pest propagule this represents an undetected post border arrival of an exotic pest for example at a port established population an established pest population can be defined via pre defined population densities or counts per cell perhaps informed by field data built in mechanistic species distribution model the location of the initial pest population can be automatically estimated by the model based on configurable ranges of environmental criteria such as temperature vegetation water sources elevation rainfall land use etc 2 1 2 within cell abundance of a pest each infested cell agent has an embedded population model that estimates the population density of a pest within a cell over time for example via logistic growth kingsland 1982 kehlenbeck et al 2012 law et al 2003 this represents how a pest population in a naive cell may initially grow exponentially but then growth will slow as the population approaches the carrying capacity of the cell roughgarden 1975 the carrying capacity of a cell is derived from user defined habitat suitability data specific to the pest being modelled this allows pest abundance to vary across the model grid based on environmental variables such as temperature elevation land use rainfall and vegetation a logistic population growth rate is unlikely to be a static value and actual population values may not be available from empirical studies appdis allows the growth rate to vary with temperature perhaps informed by laboratory data on pest development and mortality response to temperature this approach allows colder temperatures to be associated with negative growth rates and trigger seasonal declines of a population fig 1 illustrates how a logistic function can have a constant growth rate r or a variable growth rate r τ that depends on temperature τ the logistic growth model for a temperature dependent growth rate is given by equation 1 eqn 1 d t k 1 k d t 1 1 e r τ where d t pest population density on day t normalised with respect to carrying capacity k k carrying capacity of the cell normalised across all cells r τ pest population growth rate for temperature τ if the population in a cell falls below a configurable threshold it becomes quiescent and declines to extinction over a configurable period this approximates an allee effect stephens and sutherland 1999 whereby small or sparse populations represented by very low cell population densities can suffer from reduced population growth that leads to extinction although not yet investigated it would be possible for a cell agent to have multiple population models each corresponding to a distinct species this functionality could be useful for exploring interspecific mutualism with respect to presence and abundance 2 1 3 between cell spread of a pest as the within cell population density of a pest increases or decreases over time per the embedded population model the rising or falling dispersal pressure within the infested cell affects the probability of between cell spread the steady short range spread of a pest between adjoining cells is modelled by a diffusion pathway the sporadic longer range spread of a pest between cells is modelled by one or more jump pathways 2 1 3 1 diffusive spread between adjoining cells the progressive spread of a pest from an infested cell into an adjoining candidate cell is modelled with a stochastic diffusion process that considers the infested cell s pest population density the infested cell s environmental conditions e g certain wind and or temperature criteria may be required for diffusion to occur optional the environmental suitability of the candidate cell so that more suitable cells will have a higher probability of pest incursion than less suitable cells optional the elevation gradient between the centroids of the source and candidate cell optional daily decisions as to whether an infested cell diffuses into the adjoining candidate cells are made by sampling from binomial distributions of the probability of diffusion equation 2 eqn 2 p d t 1 1 p d s δ λ ε d t where pd t probability of diffusion occurring on day t pd baseline daily probability of diffusion of a viable number of pests from an infested cell into another cell configurable per land use category of the infested cell s relative suitability of the candidate cell normalised across all cells optional δ distance weight for the infested and candidate cells optional λ temperature weight of the infested cell optional ε elevation weight for the infested and candidate cells optional the optional distance weight δ is a simple relative measure of distance between the centroids of the source infested cell and the adjoining candidate cells and dampens the probability of diffusion into the north west south west north east and south east neighbours δ 0 7 as opposed to the north south west and east neighbours δ 1 0 the optional temperature weight λ is derived from the relationship between the average weekly temperature τ for the infested cell and four configured temperature thresholds for pest activity min optimal lower optimal upper and max λ 0 for τ min λ linear increase from 0 to 1 for min τ optimal lower λ 1 for optimal lower τ optimal upper λ linear decrease 1 to 0 for optimal upper τ max λ 0 for τ max the optional elevation weight ε is derived from the gradient between the centroids of the infested cell and the candidate cell it allows the user to increase decrease the probability of diffusion uphill downhill per 100 m difference in elevation the baseline daily probability of diffusion pd includes the probability of post dispersal establishment in the candidate cell a diffusion event conveys a user defined propagule from the source infested cell to the destination cell if the destination cell is naïve then it acquires an equation based population model equation 1 with the propagule as the initial population if the destination cell is already infested then the propagule is added to the population and the population model recalculated a cell can receive multiple diffusion events over the course of a simulation appdis allows environmental criteria temperature habitat suitability elevation etc to be disabled in which case diffusion is driven purely by the daily probability pd which in turn can be estimated by reverse engineering observed spread velocities of the pest 2 1 3 2 jump spread between cells invasive pest populations may spread over multiple scales whilst natural dispersal may result in short range diffusive spread less predictable mechanisms such as windborne spread and human mediated dispersal can lead to longer range jumps robinet et al 2009 gippet et al 2019 the sporadic longer range spread of a pest from an infested cell into non adjoining cells is modelled with one or more stochastic jump processes that consider the infested cell s pest population density the infested cell s environmental conditions e g certain wind and or temperature criteria may be required for a jump to occur optional the environmental suitability of the candidate destination cell optional the human population density of the infested cell optional the land use of the infested cell optional the land use of the candidate destination cell optional waterways in the infested and candidate destination cells optional daily decisions as to whether an infested cell disperses into a distant cell are made by sampling from a binomial distribution of the probability of a jump event equation 3 eqn 3 p j t 1 1 p j ω λ d t where pj t probability of a jump occurring on day t pj baseline daily probability of a jump occurring ω human population density of the infested cell normalised across all cells optional λ temperature weight of the infested cell optional the jump direction may be random influenced by the land use category of the source and destination cells or influenced by the weekly prevailing wind direction the jump distance is determined by sampling from a betapert vose 2008 distance distribution a catchment area of cells is formed at the site of the jump landing based on either a user defined moore neighbourhood range or radial distance the jump destination cell is then selected from the candidates within the catchment area either randomly or based on suitability criteria as per diffusion the baseline daily probability pj of a jump occurring includes the probability of post dispersal establishment in the candidate cell a jump event conveys a user defined propagule from the source infested cell to the destination cell if the destination cell is naïve then it acquires an equation based population model with the propagule as the initial population if the destination cell is already infested then the propagule is added to the population and the population model recalculated a cell can receive multiple jump events over the course of a simulation pj can be estimated either from expert opinion or the frequency that satellite pest colonies are observed arising unexpectedly some distance from a known infested area 2 1 4 general surveillance general surveillance by members of the public is an important means of early detection of plant and environmental pests cacho et al 2010 hester and cacho 2017 wilson et al 2004 all cells that have both a pest population and a human population are scanned daily for detections by a stochastic process that considers the infested cell s pest population density the infested cell s human population density the sensitivity of the observer the probability of a general surveillance detection event occurring on any given day is adapted from sharov et al 1998 and bogich et al 2008 and is given by equation 4 eqn 4 p t p t 1 e d t ω s e where ptp t probability of a true positive detection occurring on day t ω human population density of the infested cell normalised across all cells se sensitivity of the observer the observer sensitivity for unmanaged cells is defined separately to that for managed cells a managed cell is defined as any cell that is undergoing or has undergone delimiting surveillance or treatment the model provides the option of the first general surveillance detection occurring on a fixed day rather than on a stochastically determined day this allows useful experimentation on the impact of time to detection on incursion severity and cost fig 2 uses equation 4 with se 0 70 to illustrate how the probability of a general surveillance detection varies with respect to the normalised pest population density and the normalised human population density 2 1 5 early detection surveillance there is considerable interest in the cost effectiveness of surveillance strategies for invasive species field et al 2004 gerber et al 2005 bogich et al 2008 hauser and mccarthy 2009 kompas and che 2009 cacho et al 2010 epanchin niell et al 2014 holden et al 2016 appdis allows the user to define a permanent trapping grid of geolocated traps with specified lure types all cells that have both a pest population and a permanent trap location are scanned daily for active detections the detection of a pest population is modelled with a stochastic process that considers the infested cell s pest population density the lure type and spacing of traps in the infested cell the sensitivity of the surveillance process traps and personnel the specificity of the surveillance process traps and personnel the probability of a true positive detection occurring on day t is adapted from sharov et al 1998 and bogich et al 2008 and is given by equation 5 eqn 5 p t p t 1 e a t φ s e where ptp t probability of a true positive detection on day t a t pest area of the infested cell in hectares on day t φ trap density traps per hectare in the infested cell 10 000 trap spacing in metres 2 se sensitivity of the surveillance process traps and personnel as the pest area a t of an infested cell is not actually known as cells are atomic it is proxied by multiplying the normalised population density of the cell d t by the cell area in hectares the model also provides the option of the first early detection occurring on a fixed day rather than on a stochastically determined day this allows useful experimentation on the impact of time to detection on incursion severity and cost fig 3 uses equation 5 with se 0 96 to illustrate how the probability of early detection inside a 10 ha cell varies with the normalised pest population density and trap spacing if a surveyed cell does not yield a true positive result then it is checked for a false positive result the probability of a false positive detection occurring is given by equation 6 eqn 6 p f p 1 s p where pfp probability of a false positive detection sp specificity of the surveillance process traps and personnel if a surveyed cell does not yield a positive result then a true false negative result is assigned according to the actual absence presence of the pest in the cell 2 1 6 delimiting surveillance after a pest population has been detected in a cell the surrounding cells undergo delimiting surveillance delimiting surveillance comprises a configurable number of periodic surveillance visits delimiting surveillance operates in either moore mode where the cells in the moore neighbourhood of the detected cell are surveyed or radial mode where all cells within a configurable distance of the detected cell are surveyed the detection of a pest population through delimiting surveillance is modelled by a stochastic process that considers the surveyed cell s pest population density trap spacing in the surveyed cell the sensitivity of the surveillance process traps and personnel the specificity of the surveillance process traps and personnel the daily probability of a true positive detection is given by equation 5 if a cell does not yield a true positive result it is then checked for a false positive detection equation 6 a positive surveillance result triggers a treatment program if a cell does not yield a positive result then a true false negative result is assigned according to the actual absence presence of the pest in the cell the pest is deemed absent from a cell once a configurable number of consecutive negative surveillance results has been reached 2 1 7 treatment all cells that have yielded a positive result true or false from general surveillance early detection surveillance or delimiting surveillance undergo a treatment program a treatment program comprises a configurable number of treatments conducted at a configurable period each treatment reduces the population by a percentage amount determined stochastically between a configured minimum and maximum reduction a pest population is deemed extinct if a treatment program reduces it to below the configured minimum population size a treatment program may operate in spot mode where only the detected cell is treated moore mode where all cells in the moore neighbourhood of the detected cell are treated or radial mode where all cells within a configurable distance of the detected cell are treated 2 1 8 post treatment surveillance post treatment surveillance commences at a configurable period after the completion of the last scheduled treatment a post treatment surveillance program comprises a configurable number of periodic surveillance visits post treatment surveillance is modelled with a stochastic process that considers the surveyed cell s pest population density the trap spacing in the surveyed cell sensitivity of the surveillance process traps and personnel specificity of the surveillance process traps and personnel as per delimiting surveillance the daily probability of a true positive detection is given by equation 5 if a cell does not yield a true positive result it is then checked for a false positive detection equation 6 a positive post treatment surveillance result triggers another treatment program if a cell does not yield a positive result then a true false negative result is assigned according to the actual absence presence of the pest in the cell a cell is deemed free of the pest after a configurable number of consecutive negative surveillance results 2 1 9 resourcing the active surveillance and treatment of plant and environmental pests are typically resource constrained processes rout et al 2011 mccarthy et al 2012 an appdis resource is abstract in the sense that it is a user defined set of personnel equipment supplies required to carry out a specific job the model maintains pools for each resource type early detection surveillance delimiting surveillance treatment and post treatment surveillance the resourcing profile for each pool is configurable as to whether resource levels are fixed or vary over time when a field operation is scheduled a resource is requested from the corresponding pool if a resource is available then it is borrowed from the pool and the field operation commences if a resource is not available then the field operation is queued until such time as the required resource becomes available once a field operation has completed the resource is returned to the pool the model reports the daily resource usage for early detection surveillance delimiting surveillance treatment and post treatment surveillance resource pools can be configured to be unlimited in which case resources are always immediately granted upon request in this mode the resourcing profile of an outbreak is a model output instead of a model input that constrains the efficacy of the control program 2 1 10 implementation highlights the appdis modelling framework utilises an agent based modelling platform bradhurst 2015 which can operate in four modes contagious livestock disease vector borne livestock disease plant environmental pests and human disease when modelling the spread and control of contagious disease in livestock the agents are herds farms containers of one or more herds saleyards and abattoirs when modelling the spread and control of plant and environmental pests the agents are cells in a lattice environment when modelling the spread and control of insect vector borne livestock disease such as bluetongue the agents are herds farms saleyards abattoirs and cells when modelling the spread and control of human disease the agents are people descriptions of the vector borne livestock and human disease modes will appear in future papers the modelling behaviour livestock disease plant environmental pests or human disease of an instantiated model is purely determined by the configuration files and database loaded an appdis agent can have an embedded population model of the within agent abundance over time for example when modelling an exotic fruit fly incursion each infested cell agent has an embedded temperature dependent logistic growth model that predicts the within cell population over time an agent can also have an embedded infection model of the within agent prevalence of a pathogen in the population for example when modelling the spread of a contagious disease in feral pigs each infected cell agent has an embedded seird susceptible exposed infectious recovered deceased compartmental disease model implemented as a system of ordinary differential equations that predicts the within cell infected and infectious prevalence of the disease over time the interplay between a cell agent s population and infection models will be described in a separate paper the details of the population and infection models are private to the agent which means that alternate within cell models can be used without impacting the greater model appdis models scale well as the agents are threadless and lightweight appdis agents interact in a spatially explicit disaggregated environment comprised of threaded components that operate concurrently and independently bradhurst 2015 examples of components relevant to contagious livestock disease include local spread direct spread saleyard spread indirect spread airborne spread movement restrictions surveillance tracing vaccination stamping out and post outbreak surveillance bradhurst et al 2015 examples of components relevant to plant environmental pests include unaided diffusive spread human mediated hitchhiking spread wind assisted airborne spread early detection surveillance general surveillance delimiting surveillance treatment and post treatment surveillance all appdis components are independent and can be separately enabled disabled as the implementation of each component is private alternate components can be swapped in and out for example the implementation of a treatment component can completely change without impacting the rest of the model appdis has a concurrent software architecture that allows it to take advantage of the cheap parallelism available with multi core personal computers this together with other design efficiencies such as an in memory database and grid based spatial indexing allow appdis to efficiently conduct national scale simulations bradhurst et al 2016 further details on the underlying model and software architecture can be found in bradhurst 2015 and bradhurst et al 2016 the primary appdis outputs are csv files which can be post processed statistically appdis also provides a graphical user interface for interacting with the model and dynamic visualisation of incursions as they unfold the ability for appdis to convey incursion and management concepts visually may suit it to classroom use fig 4 is a screenshot of appdis depicting a hitchhiking escape of a tramp ant population from within the managed area the population model of any cell can be visualised for example fig 4 depicts the population of cell 70814 being knocked down over the course of a treatment program and the residual population recovering over time 2 1 11 verification and validation the appdis and aadis modelling frameworks have a common underlying software baseline bradhurst 2015 appdis thus inherits from previous aadis verification and validation activities and modelling studies bradhurst 2015 bradhurst et al 2015 bradhurst et al 2016 garner et al 2016 bradhurst et al 2019 firestone et al 2019 bradhurst et al 2021 firestone et al 2020 appdis models were instantiated for anoplolepis gracilipes yellow crazy ant and bactrocera dorsalis oriental fruit fly case studies during development of the framework a model has also been developed of the spread of disease in feral pigs the yellow crazy ant model is described in this paper and the oriental fruit fly and feral pig models will be described in separate future papers appdis validation will be an ongoing process as each new pest or pest group model instantiation will require separate validation 2 1 12 hardware and platform specifications and software availability appdis is written in java oracle 2020 and employs open source products such as sql power architect sql power group 2020 postgresql 2020 openmap bbn 2016 and log4j apache 2020 appdis runs under either linux or windows with a recommended minimum hardware configuration of a quad core processor 16 gb ram and a 1920 1080 display resolution the model is available at no cost for non commercial use under a licensing agreement with the australian department of agriculture water and the environment 2 2 case study established population of tramp ants tramp ants are a diverse group of invasive ant species that can severely impact native species and habitats agriculture forestry human health and social amenity if introduced they can rapidly establish and spread through natural and human mediated dispersal abbott 2005 hoffman 2014 an example of a tramp ant that is a concern to australia is anoplolepis gracilipes yellow crazy ant yca yca causes severe ecological damage abbott 2005 2006 and can affect the horticulture industry by farming sap sucking scale insects for honeydew this can lead to larger infestations of pests on host plants haines and haines 1978b lach and barker 2013 helms 2013 and an increase in the risk of disease being transmitted to plants through insect vectors supercolonies are formed through colony budding and the absence of intraspecific aggression o dowd et al 1999 2 2 1 model setup 2 2 1 1 study area this study area for this case study was approximately 18 724 km2 bounded by latitudes 16 450 to 17 941 and longitudes 145 090 to 146 149 a cell size of 10 ha was chosen to reflect the observation that a yca supercolony spanning an area less than 10 ha tends to be a single contiguous population whereas a supercolony spanning an area greater than 10 ha tends to be comprised of fragmented populations hoffmann 2014 appdis raster data layers were defined for land use sugar cane farms sugar cane railway corridors managed land natural areas watercourses elevation human population density yca habitat suitability land suitable sea lakes unsuitable yca densities have previously been estimated at between 0 2 million and 3 5 million per hectare haines and haines 1978a and up to 20 million per hectare abbott 2005 as the habitat suitability data layer for this study was very simple a conservative grid wide carrying capacity of 2 million yca per hectare was chosen this means that every land cell is deemed equally suitable for yca with a nominal carrying capacity of 20 million this simplistic assumption could be improved with a richer habitat suitability layer that incorporates variables such as rugosity and food sources in the determination of cell suitability which in turn would provide heterogeneity in cell carrying capacity the initial yca population fig 5 spanned 154 cells cell population densities were synthesized graduating from a population of 20 million in cells at the centre of large clusters down to 2000 in cells at the edge of clusters this resulted in an overall initial yca population of approximately 310 million across 1540 ha the initial yca population of any subsequently infested cell was an arbitrary propagule deemed to comprise 24 workers and 1 queen 2 2 1 2 within cell abundance the abundance of the yca population within an infested cell over time was represented by a deterministic logistic growth function equation 1 with a temperature independent population growth rate r τ 0 025 based on the assumption that for an ideally suitable 10 ha cell an uncontrolled yca population will take approximately 2 years to grow from a single propagule n 25 to 99 of the cell carrying capacity n 19 8m this implies that 50 of the carrying capacity is reached after 454 days natural contractions of yca populations abbott 2006 were not modelled 2 2 1 3 diffusive spread of yca between adjoining cells an appdis diffusion spread pathway was instantiated to model the steady spread of yca over time to adjoining cells the baseline daily probability of diffusion pd required for equation 2 depends on the land use category of the infested cell table 1 this allows heterogeneity in the diffusive behaviour for example diffusion in a cane farm cell where natural budding is perhaps augmented by short range movements arising from within farm activities such as harvesting is assumed to be more vigorous than diffusion in a national park cell that is primarily due to natural budding 2 2 1 4 spread between non adjoining cells due to sugar cane farming activities an appdis jump spread pathway was instantiated to model the sporadic spread of yca due to medium range hitchhiking from sugar cane farming activities jumps were parameterised to only originate from cells containing sugar cane farms and only end in cells that had either sugar cane farms or railway corridors the ability to define the baseline daily probability pj equation 3 per land use category allows heterogeneity in the jumping frequency table 2 for example jumps between cane farms brought about by harvesting activities spanning multiple farms can be defined differently to jumps from cane farms to cane railway corridors brought about by cane rail transportation seasonal variations in cane farming activities were not modelled i e the pathway represents average cane jumps over the course of a year 2 2 1 5 spread between cells due to human mediated hitchhiking an appdis jump spread pathway was instantiated to model the sporadic spread of yca via human mediated hitchhiking unrelated to cane farming activities jumps were parameterised to only involve cells with a non zero human population density table 3 although the model allows a proportion of jumps to end in non populated cells simulating for example movements into natural areas the feature was not enabled for this case study 2 2 1 6 spread between cells due to rafting an appdis jump spread pathway was instantiated to model the sporadic spread of yca due to rafting jumps were parameterised to only originate from cells containing watercourses and only end in lower elevation cells that contain watercourses table 4 2 2 1 7 general surveillance an appdis general surveillance component was instantiated per table 5 2 2 1 8 specific surveillance and treatment appdis delimiting surveillance treatment and post treatment components were instantiated per table 6 2 2 1 9 resources the appdis resources component was set to unlimited i e surveillance and treatment activities were not resource constrained 2 2 2 scenario 1 uncontrolled spread the established yca population fig 5 was allowed to spread without surveillance or treatment for 30 years and the emergent rates and extent of spread recorded the scenario was repeated 50 times 2 2 3 scenario 2 sensitivity of delimiting surveillance trap spacing the established yca population fig 5 was allowed to spread in conjunction with surveillance and treatment programs the delimiting surveillance trap spacing parameter table 6 was systematically varied between 2 and 100 m while the post treatment surveillance trap spacing was held constant at 10 m 500 iterations of the scenario were run for each trap spacing the maximum length of a scenario was limited to 15 years 5475 days 2 2 4 scenario 3 sensitivity of post treatment surveillance trap spacing the established yca population fig 5 was allowed to spread in conjunction with surveillance and treatment programs the post treatment surveillance trap spacing parameter table 6 was systematically varied between 2 and 100 m while the delimiting surveillance trap spacing was held constant at 10 m 500 iterations of the scenario were run for each trap spacing the maximum length of a scenario was limited to 15 years 5475 days 3 results 3 1 scenario 1 results uncontrolled spread table 7 provides a summary of uncontrolled yca spread over 30 years convergence estimates the percentage standard error e of the sample mean with 95 confidence for a given number of iterations equation 7 driels and shin 2004 eqn 7 e 100 z c s x x n where e percentage standard error of the sample mean zc confidence coefficient 1 96 95 sx sample standard deviation x sample mean n number of runs fig 6 provides a snippet of the yearly spread report for the case study the model outputs the population density for each active cell at the end of every year for each simulation run the model creates a pest distribution risk map that represents how often a cell was infested across all iterations of a particular scenario fig 7 presents a colour coding of cells in the study area where the most frequently infested cells are encoded in red and the least frequently infested cells in yellow 3 2 scenario 2 results sensitivity of delimiting surveillance trap spacing table 8 and figs 8 and 9 summarise the effect of delimiting surveillance trap spacing on the average cost and effectiveness of control eradication 3 3 scenario 3 results sensitivity of post outbreak surveillance trap spacing table 9 and figs 10 and 11 summarise the effect of post treatment surveillance trap spacing on the average cost and effectiveness of control eradication 4 discussion 4 1 uncontrolled spread the average yca diffusion rate over a 30 year period ranged from 68 m year in natural areas up to 132 m year in cane farming areas this is broadly in line with reported budding distances of 125 m year on average range 37 402 haines and haines 1978a and up to 182 m per year abbott 2006 note that cells may have multiple land uses e g cane managed railway managed and each cell diffuses based on its highest risk land use this can artificially boost the diffusion rate for the lower risk land use of the cell e g a managed cell with cane fields contributes correctly to the overall cane diffusion rate but over contributes to the overall managed land diffusion rate dispersion via winged flight of queens fission was not explicitly modelled as it is unclear whether this is an important means of dispersal for yca rao et al 1991 haines et al 1994 o dowd et al 1999 abbott et al 2014 hoffmann 2014 it would have been possible data permitting to include a fission jump pathway as the model supports multiple concurrent jump spread pathways longer range sporadic spread of yca via hitchhiking is more unpredictable and harder to quantify than steady diffusive spread the probability of spread via human mediated hitchhiking is influenced by an infested cell s pest population density and human population density however the frequency and distance of such jumps is largely driven by expert opinion and inference from unexpected satellite colonies for example an unexpected appearance of yca in russett park queensland 30 km from the nearest known infestation near cairns queensland was attributed to hitchhiking via the transportation of landscaping materials as illustrated in fig 7 one of the outputs of appdis is a risk map of spread driven by the number of times a cell is infested over a series of scenario runs the land uses of the resultant infested cells can be analysed to provide an estimation of the potential long term impact on agricultural residential and environmentally sensitive areas this case study strongly suggests that 30 years of uncontrolled spread of yca would lead to significant incursions into the wet tropics world heritage area the simulation produced very good convergence 2 90 of the mean number of infested cells after 50 iterations this implies there is 95 confidence of only 2 90 standard error in the distribution of the sample mean 4 2 sensitivity of surveillance trap spacing the cost of control was largely independent of delimiting surveillance trap spacings greater than 20 m but rose steeply for trap spacings less than 20 m fig 8 the cost of control was weakly dependent on post treatment surveillance trap spacings greater than 10 m and rose steeply for trap spacings less than 10 m fig 10 the effectiveness of control measured by population reduction and incursion duration was far more sensitive to post treatment surveillance trap spacing than delimiting surveillance trap spacing figs 8 and 9 shows how the yca population was reduced by 99 within 15 years for all delimiting surveillance trap spacings in contrast only post treatment surveillance trap spacings between 2 and 10 m resulted in a 99 population reduction within 15 years figs 10 and 11 the effectiveness of control decreased markedly as post treatment surveillance trap spacing increased with a trap spacing of 100 m yielding no net population reduction after 15 years this suggests that the effectiveness of post treatment surveillance is a vital aspect of pest eradication fig 10 indicates that a post treatment surveillance trap spacing of 18 m minimised the cost of control at approximately a 23 5m and resulted in an average 95 population reduction however to achieve an average 99 99 population reduction the required 2 m post treatment surveillance trap spacing would however incur a much higher cost of approximately a 163m the decrease in control effectiveness with increased post treatment surveillance trap spacing is also reflected by the average model runtime per iteration in scenario 2 where the post delimiting surveillance trap spacing was held steady at 10 m while the delimiting surveillance trap spacing was varied the average model runtime per scenario iteration was reasonably stable average 60 50 s standard deviation 9 68 table 8 in scenario 3 where the delimiting surveillance trap spacing was held steady at 10 m while the post outbreak surveillance trap spacing was varied the average model runtime per scenario iteration was strongly dependent on trap spacing ranging from 28 04 to 141 75 s this is due to the additional treatment and post treatment surveillance activities and hence simulation processing required when the surveillance strategy is less effective reflected by higher false negative results table 9 the high sensitivity of control cost effectiveness to post treatment surveillance trap spacing is perhaps because post treatment surveillance is typically conducted in cells with very small pest densities as shown in fig 3 the model s implementation of specific surveillance is highly sensitive to trap spacing at low pest population densities an incorrect determination of pest absence in a treated cell after 4 successive false negative results leads to cell populations that will recover over time in the absence of an early detection surveillance system the subsequent detection of a residual population relies on general surveillance the probability of a general surveillance detection is however greatly reduced at low pest and human population densities fig 2 the simulations produced very good convergence for the mean total cost of control 1 7 this implies 95 confidence that there is at most 1 7 standard error in the distribution of the sample mean and that 500 iterations of the scenarios were sufficient 4 3 advantages and limitations of the appdis modelling approach decision support tools that represent the spread of a pest in an environment range from simple aggregative mathematical models to complex pest specific spatial simulations aggregative mathematical models generally do not take host and environmental heterogeneity into account but are concise easy to parameterise scalable computationally efficient and may be readily extensible to other pests they can be very useful for the fast prototyping of incursion dynamics especially when data is scarce or unreliable detailed spatially explicit and pest specific simulations can capture environmental and host heterogeneities but are data dependent can be complicated to construct and parameterise may not scale well computationally and may not be readily extensible to other pests the appdis modelling framework attempts to find a pragmatic middle ground between the biological and ecological fidelity of a complex pest specific spatial model and the extensibility of a generalised mathematical model appdis is flexible in that a user can configure either simple or complex spread models in studies where field data is scarce or unreliable a simple mathematical spread model is obtained by disabling the environmental data layers and configuring an aggregative diffusion kernel based on predicted spread rates a complex spread model can be achieved by enabling environmental data layers and configuring individual spread pathways that consider heterogeneities in elevation temperature wind speed vegetation land use human population density etc once a model is spreading a pest in a way that is congruent with available field data and expert opinion a decision support tool should allow useful experimentation with surveillance and control strategies a further design tension exists between implementing detailed pest specific detection control options that may not be readily extensible to other pests and or jurisdictions and implementing generalised detection control options that may not be detailed enough for the pest under study again appdis attempts to find a pragmatic middle ground by providing detection control options that are detailed enough to be useful yet abstract enough to extend to a range of pests surveillance and treatment regimes are configurable by the user in generalised terms such as duration cost resource requirements efficacy sensitivity and specificity as the underlying pest spread mechanisms are stochastic a control policy can be trialed against a distribution of plausible incursions in this way despite inherent uncertainty in how an exotic pest population may spread confidence can be gained as to the likelihood of a particular policy to achieve the desired control eradication outcome configuring an appdis model for a pest or pest group requires personnel versed in pest ecology plant health policy and the appdis modelling platform including the assembly of supporting data parameterisation designing and running incursion scenarios and statistical interpretation of simulation results the configuration effort required when employing disaggregated data driven spread pathways is considerably more than that required for aggregative mathematical pathways an advantage of a disaggregated approach to modelling spread by simulating each spread pathway separately is that control measures can be applied to specific spread pathways for example consider a pest that spreads through a windborne pathway and a market driven pathway with a disaggregated modelling approach it is easy to test the effect of movement restrictions on the market driven pathway whilst still allowing the airborne pathway to spread the pest this is more difficult when all spread pathways are aggregated into a single mathematical spread mechanism a disadvantage of grid based modelling approaches is that point based agricultural entities such as orchards nurseries and markets are not represented it would be possible to extend appdis to include point based entities and directed spread pathways as is the case with the aadis framework however this would require further development of the framework and consultation with domain experts to ensure that entities and networks are captured in an abstract way that extends to as many pest species as possible whilst models can assist with preparedness and planning for incursions and in some cases response they can suffer silently from poor assumptions sub standard data inadequate validation and improper use flawed models have the potential to mislead rather than inform particularly when modelling outputs are detailed and appear definitive appdis is primarily a data driven model and as such relies heavily on the quality of the underlying data and parameterisation each instantiation of appdis for a new pest species or pest species group will require a separate validation process that fosters user trust in the model assumptions data parameterisation and capabilities appdis models are best suited to relative comparisons between control and resourcing strategies rather than predicting incursion outcomes in absolute terms 4 4 conclusions appdis is a general purpose plant and environmental pest modelling framework that is extensible not tied to a specific pest scalable operable regionally and nationally and flexible offering simple equation based spread pathways or complex data driven pathways that capture heterogeneity in the host environment appdis allows relative comparisons of strategies for early detection surveillance delimiting surveillance treatment and post treatment surveillance with respect to efficacy resource usage and cost the case study has demonstrated the potential for appdis to assist with decision support for both plant pests and environmental pests importantly appdis is extensible to a range of pests via user configurable parameters i e without the need for specialised mathematical reformulation and or computer programming funding the work was funded by the australian department of agriculture water and the environment via the centre of excellence for biosecurity research analysis cebra project 170606 developing models for the spread and management of national priority plant pests declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this paper is derived from research and development undertaken in 2018 and 2019 as part of cebra project 170606 developing models for the spread and management of national priority plant pests the authors would like to acknowledge the support of the australian department of agriculture water and the environment the new zealand ministry for primary industries and the centre of excellence for biosecurity risk analysis within the university of melbourne school of biosciences the authors would like to thank the wet tropics management authority dr aaron dodd and dr james camac for assistance with the data that informed the tramp ant case study 
