index,text
24050,turbulence in the ocean dominates the vertical movement of heat and salt as well as chemical and biological particulates the modelling of turbulence is therefore essential to forecast the strength of the biological pump for example in which co2 is drawn out of the atmosphere and trapped in the deep ocean obtaining observations of turbulence is an expensive process and the modelling of turbulence still remains an open problem using state of the art 3d hydrodynamic models such as large eddy simulation and direct numerical simulation to understand turbulence driven by mean flow is a popular method however in this approach the turbulence creates its own mean flow contribution which in some applications results in an undesirable divergence from the prescribed mean flow here the perturbation method is introduced this technique ensures zero divergence to the prescribed mean flow results reveal the high level of accuracy this approach has in replicating the observed turbulent field when using adcp mean current data to prescribe the model mean flow it is envisaged that the user friendly nature of this method will enable non specialists to derive turbulence data when turbulence profilers are not a tractable resource this modelling approach also sets a rigid framework for the testing of turbulence closure schemes keywords turbulence modelling large eddy simulation turbulence closure scheme 1 introduction large eddy simulation les of turbulent flows is used in a wide range of fluid dynamical applications from small scale oceanic dynamics to large scale atmospheric turbulence modelling and many other applications within this scale range mcwilliams et al 1997 noh et al 2004 moeng 1984 kosović and curry 2000 the defining characteristic of les is that small scale fluctuations which act below the scale of the model resolution termed as the subgrid scale sgs are parameterised smagorinsky 1963 the resolved scale turbulent fluctuations and mean flow on the other hand are calculated directly from the fully 3d navier stokes equations this method can be very powerful when the majority of the energy containing scales are above the sgs from this method computationally expensive turbulent flow solutions can be made much more cost effective with little detriment to the solution at the current standard of computing resources les is becoming a more feasible technique where typically the standard and computationally cheap reynolds averaged navier stokes rans method is used however les in oceanic turbulence modelling in contrast to turbulence modelling in the planetary boundary layer still remains a largely under exploited tool relative to engineering applications the main problem in coastal ocean modelling is that the rans technique is cheap but it cannot accurately model turbulent fluxes and the standard les technique is not feasible for large domains a growing body of literature is emerging to solve this problem which combines the two methods detached eddy simulation spalart 2009 where one part of the ocean domain is solved by les and the other part by rans the goal is to use rans near the wall and les away from the wall zhang et al 2015 to improve computational cost while retaining reasonable accuracy similarly chalamalla et al 2017 develops the so called somar les method where an les model is nested inside a parent rans model with two way coupling this method uses a sophisticated adaptive mesh to track and resolve turbulent fluctuations such that the computational time associated with the les part is significantly reduced the les coast approach roman et al 2010 is a novel les technique whereby the eddy viscosity is split into separate directional components this allows for an anisotropic domain without an overestimation of the eddy viscosity and hence allows for a larger grid spacing in the horizontal traditionally les in the ocean is used to study effects of surface forcing on the mixed layer convection winds waves etc vreman et al 1997 skyllingstad and denbo 1995 noh et al 2011 effects of body forcing on the bottom boundary layer e g tidal forcing radhakrishnan and piomelli 2008 and effects of these processes in the presence of stratification armenio and sarkar 2002 gayen et al 2010 the reader is directed to scotti 2010 for an extensive review of the oceanic applications of les in some applications instead of using surface or body forcing it is more appropriate to prescribe the mean flow when the turbulent properties of the system are of interest for example when forcing data is not available but mean currents are known wakata et al 2017 it is also appropriate to prescribe the mean flow when validating turbulence models e g the k ɛ model launder and spalding 1974 against les models this is because the same mean flow can not be achieved by forcing both types of models with the same surface or body forcing even for simple cases like couette flow coles 1965 this is undesirable as the ultimate aim is the validate the turbulent characteristics given a particular mean flow the problem lies in the calculation of the turbulent stresses here the turbulence model and the les model differ resulting in mean flow calculations which also differ however prescribing the mean flow is not appropriate in many applications such as assessing boundary layer evolution for example bottom boundary layer thickening in the presence of tides and mixed layer deepening in the presence of winds and surface heating this is because the evolution of the mean flow is what is of interest something which cannot be investigated when prescribing the mean flow furthermore one cannot fully test the skill of the les when the mean flow calculation is bypassed one must first assess the les s capability to accurately calculate both the mean and turbulent part of the flow field before proceeding with the prescription of a mean flow for the cases when prescribing mean flow is appropriate one problem is apparent the turbulent fluxes present in the navier stokes equations give rise to an extra unwanted mean flow contribution this term takes the form u i u j and symbolizes mean flow generated by the turbulent fluctuations which is an additional mean flow term separate to the forcing if one truly wants to prescribe a mean flow this extra contribution must be considered here the perturbation method is presented this method ensures the extra mean flow contribution which is typically overlooked is not present this means that when prescribing the les with observed mean currents for example one can be sure that the turbulence produced is associated purely with the observed mean flow for the testing of turbulence models against the les one can use the perturbation method to ensure both the turbulence model and les model are forced with the exact mean flow field giving a higher control over experiments this manuscript is set out with the following format the governing equations for the perturbation method are derived given that this method bypasses testing the les s ability to calculate the mean flow we devise an experiment a full body forced les model run is completed which calculates both mean and turbulent flow fields the mean flow from this experiment is used to prescribe the perturbation method the turbulence characteristics are then compared between both methods to show the methods are equivalent in terms of turbulent flow features this will be followed by an experiment whereby the new method is forced by observed mean currents and the model turbulence data will be compared to observed turbulence data at the same site finally a popular turbulence closure scheme canuto et al 2001 is compared to the perturbation method when both models are forced with the same mean flow forcing from the observational data 2 model description before the equation set is derived for the turbulent flow it is convenient to non dimensionalise all flow variables in the usual way 1 u u u 0 x x l p p l u 0 2 where u u v w is the non dimensional form of the flow field u is the dimensional flow field u 0 is an appropriate velocity scale x x y z is a non dimensional spatial co ordinate x is the dimensional co ordinate l is an appropriate length scale p is the non dimensional pressure and p is the dimensional pressure the governing filtered equations of the total flow field can be described by the navier stokes equations stokes 1845 2 u t u u 1 r o k u p ρ 0 1 r e 2 u sgs 3 u 0 here u is the filtered les resolved velocity field r o f l u 0 is the rossby number r e u 0 l ν is the reynolds number f is the coriolis parameter k is the unit vector in the vertical and ν is background viscosity the filter imposed to arrive at eq 2 removes all linear dependence on the unresolved flow u however the classic closure problem arises as the filter imposed on the unresolved non linear term cannot remove dependence on u this extra contribution by the unresolved flow is encapsulated by the sgs term to close the equations typically a reynolds stress argument is used to relate the unresolved terms to resolvable quantities reynolds 1894 a modelled form of the sgs term is typically of the form 4 sgs 2 x j ν t u l s i j where s i j 1 2 u i x j u j x i is the rate of strain tensor and νt is an eddy viscosity normally in les a variant of the smagorinsky scheme is used to calculate the eddy viscosity term e g smagorinsky 1963 here the formulation for the eddy viscosity will be taken from mason and thomson 1992 which is widely used in the literature porté agel et al 2000 lewis 2005 polton et al 2008 5 ν t λ 2 s where s 2 s i j s i j 1 2 is the magnitude of the rate of strain tensor and λ is a length scale defined by 6 1 λ 1 λ 0 1 κ z z 0 where λ 0 c 0 δ c 0 is a constant taken to be 0 25 δ d x d y d z 1 3 is a spatial resolution length scale δ3 is the volume of a grid box κ 0 4 is the von karman constant and z 0 is roughness length prescribed to be 10 3 m results were found to be insensitive to the values chosen for z 0 and c 0 the first term on the right hand side of eq 6 dominates in the interior and the last term dominates near the boundary the flow field can be further partitioned into its mean and turbulent constituents akin to reynolds decomposition reynolds 1894 tennekes and lumley 1972 which comprise the mean and fluctuating parts 7 u x y z t u z t u x y z t here u x y z t is the total flow field u z t is the mean flow field u x y z t is the resolved turbulent velocity field x and y are horizontal axes z is height above bed and t is time as one is usually interested in horizontal average quantities to characterise the flow field it is convenient to define the partitioning in terms of a horizontal average 8 u u z t such that 9 u 0 where is a horizontal mean defined by 10 1 x y x y d x d y where xy is the horizontal area of the domain s extent it is important to note that the flow field can theoretically be decomposed in any way so long as the averaging operation is defined consistently with the decomposition 2 1 the perturbation equations our objective is to solve the turbulent constituent of the flow field only this can be achieved by subtracting the equation for the horizontally averaged flow field given by 11 u t u u 1 r o u u u p ρ 0 1 r e 2 u s g s 12 u 0 from eqs 2 and 3 respectively to yield equations 13 u t u u w u z u u u u 1 r o k u p ρ 0 1 r e 2 u s g s s g s 14 u 0 here the first term on the left hand side of eq 13 represents time evolution of the turbulence and the second term represents advection of the turbulent field by the prescribed mean flow the third term represents the injection of turbulent momentum by the velocity shear the fourth term represents the non linear advection term and the fifth term is the mean part of the fourth term which acts to ensure that no extra contribution to the mean flow can arise the sixth term is a planetary rotation term on the right hand side of eq 13 the first term represents a perturbation pressure gradient the second term represents diffusion of the turbulent field the third term represents density perturbations and finally the last term is an eddy viscosity model calculated by means of a smagorinsky scheme which is described in the previous section these equations are similar to that of the dns study of sakamoto and akitomo 2008 with the main difference being the inclusion of the fifth term on the lhs of eq 13 whereas sakamoto and akitomo 2008 omits this term a convenient aspect of the two terms which include the horizontal average operator is that their only purpose is to remove the mean part arising in their counterpart term e g the fifth term removes the mean part of the fourth term it can be shown that the only purpose of these two terms is to ensure 15 u t 0 which can be demonstrated by applying the horizontal average operator to eq 13 this means that instead of explicitly including the angle bracket terms one can simply remove the mean part which arises in the first term of eq 13 i e ensuring that eq 15 is satisfied this also has the advantage of correcting any spurious mean flow e g from numerical diffusion that might arise as a result of the time stepping scheme or the grid discretisation scheme implemented in this way one can be certain that the mean flow is truly clamped to the input mean flow this also has the advantage of being much simpler to implement into an existing les code 3 experiment 1 validation of the perturbation method 3 1 experiment design to validate the implementation of the new model equations they are first tested against an analogous traditional forcing method setup traditional les methods usually incorporate a two way interaction between the mean and turbulent constituents of the flow the proposed perturbation model equations assume a one way interaction where the mean flow forces the turbulence and not vice versa the assumption of this one way interaction is that the mean field and the turbulent field are in statistical balance therefore an appropriate experiment will involve using a steady state setup in the traditional pressure forced les model i e where the mean flow and the turbulent flow are statistically stationary this will ensure that the mean flow remains unperturbed by the turbulent field in both methods 3 2 traditional pressure forced method the traditional pressure forced method solves the filtered navier stokes equations given by eq 2 but with the inclusion of an additional pressure term which is a source of momentum given by 16 u t u u 1 r o k w p ρ 0 p ρ 0 1 r e 2 u sgs where 17 p ρ 0 is the additional pressure gradient acting as a body force on the flow field the dynamic smagorinsky model was used for the sgs term for this experiment porté agel et al 2000 3 2 1 boundary conditions and numerical configuration for the purposes of this set up and to ensure steady state p ρ 0 0 c 0 where c 5 10 4 is constant in space and time without loss of generality this pressure forcing will act only in the y direction the numerical grid will consist of 64 64 96 points over a non dimensional domain of size of 4 π 16 π 3 2 in x y z directions respectively no rotation is permitted 1 r o 0 a bulk reynolds number of r e 5000 is used and the simulation performed is classified by a friction reynolds number of r e τ 160 to aid in physical interpretation results will be displayed in dimensional units with a typical velocity and length scale of u 0 0 1 ms 1 and l 25 m implying a background viscosity of ν 5 10 4 m 2 s 1 the simulation reached steady state with a mean flow profile shown in fig 1 a and mean shear profile shown in fig 1 b this mean flow and mean shear will be used to force the perturbation method described by eq 13 here a free slip condition will be applied to the surface which will be in direct contrast to the no slip applied to the surface of the perturbation method due to stability reasons this difference will be shown to have no discernible effect away from the surface a desirable quality 3 3 results there are many quantities one can derive to compare properties of each turbulent flow field however only important quantities which characterize the amount of energy and transport in the flow namely resolved reynolds stresses turbulent kinetic energy tke and energy lost through dissipation ε will be compared note that all profiles shown in this section have been averaged over the horizontal domain and have been temporally averaged over 1400 time units once steady state has been reached after 1500 simulation time units to note it was found that the perturbation method was more stable in terms of the model time step allowing a time step 2 5 times larger it also took noticeably less time to reach steady state fig 2 a shows reynolds stress quantities u w and v w which describe the vertical fluxes of horizontal momentum though the profiles do not match exactly the difference is not particularly discernible this would indicate that should a tracer be included in each model then the vertical transport would be near identical in both cases this is for example important when considering transport of temperature and salinity fig 2 b shows the components of turbulent kinetic energy in the form of velocity variances u 2 v 2 and w 2 as the forcing is acting in the y direction v 2 contains the majority of the energy it is clear that both models are indistinguishable in the majority of the water column notably the difference only occurs in the local vicinity of the surface finally energy dissipation rate ε and tke defined by 18 ɛ ν ν t u i x j u i x j t k e 0 5 u 2 v 2 w 2 are shown in fig 3 these profiles are near identical again only diverging in the local vicinity of the surface boundary this is most important as these two metrics are generally used to characterize the turbulence of the flow field as both models give the same values in the majority of the water column one can be confident that the difference in surface boundary conditions gives no detrimental effect 4 experiment 2 forcing by observations here the skill of the perturbation method is assessed via a simple test observed mean flow will be processed and used to drive the perturbation equations eq 9 the resulting modelled turbulent field will be compared to that of the observed turbulent field observations of mean flow were provided by an acoustic doppler current profiler adcp lu and lueck 1999 mounted within the hull of the research vessel the adcp delivers high resolution vertical profiles of horizontal current velocity over the majority of the water column from approximately 7 m depth to within 3 m of the seabed data was collected in an energetic tidally forced site in liverpool bay uk this site undergoes significant semi diurnal tides with a maximum range in excess of 10 m very near to the coast liverpool bay does undergo periodic stratification due to advecting salinity gradients however the site chosen was suitably offshore to be vertically well mixed throughout this experiment hourly ctd surveys confirm that the water column was well mixed data was collected on the rv prince madog on 10th may 2009 between 07 01 and 19 30 utc at 10 min intervals the vessel was anchored at 53 37 2 n 3 55 2 w in 43 1 m of water the depth averaged mean flow was then derived and used to drive the perturbation equations eq 9 which were in turn used to generate the model turbulent field the observed turbulent field was provided by measurements of the dissipation rate of turbulent kinetic energy which was derived from shear microstructure measured using a vertically freefalling mss profiler prandke and stips 1998 for this experiment a guard was used to protect the microstructure probes which enabled the profiler to impact the seabed to collect data to within 10cm of the bottom boundary so resolving the vast majority of turbulence resulting from tidally driven shear 4 1 data processing due to the formulation of the perturbation equations mean flow should be a spatial average in the horizontal however observations of mean flow are only obtained at one point in the horizontal lat lon field therefore the data needs to be appropriately time averaged the following assumptions will be enforced in time tidal frequencies follow the m2 and m4 harmonics this will capture the main tidal oscillation and any tidal asymmetries that may arise in depth it is assumed that the current profile will match that of the classic log layer an assumption which is found to be more than reasonable jensen et al 1989 this processed mean flow will then be used to force the perturbation method the resultant turbulence characteristics namely energy dissipation rate from the model simulations will then be compared to observations of energy dissipation rate derived from the micro structure profiler to process the adcp current data to obtain u z t for the perturbation method an assumption of separability will be used for simplicity i e 19 u z t f t g z where f t will depend on the tidal harmonics and g z will depend on a classic log layer profile explicitly f t will take the form 20 f t i 1 2 a i sin i ω t b i cos i ω t here f t is a fourier series derived by the least squares regression method using the deepest observed data which was 5 m above the bed as one can see in fig 4 this simple expression captures the amplitudes to a high level of accuracy the classic log layer has the form 21 u κ log z z 0 where κ is the von karman constant taken to be 0 4 u is the friction velocity at the bed and z 0 10 3 m is a typical roughness length to ensure matching of the log layer to f t at the lowest observational point one arrives at a mean flow of the form 22 u z t f t log 5 z 0 log z z 0 though comparison of this fit with depth at each time will be omitted from this manuscript it was found to show good agreement to the data at all times indeed the simulated variance in velocity fluctuations shown later are an order of magnitude larger than the variance that exists in the deficit between the observed adcp values and the les forcing velocities this suggests that the velocity fitting is not discarding an important source of energy furthermore as commented on earlier the convenience of this form is that derivatives in z can be taken analytically and interpolation is not needed between observed time points which increases both accuracy of the solution method and the ease of implementation in the model code 4 1 1 boundary conditions and numerical configuration velocity and pressure fields were computed from eq 13 over a computational domain of 100 m 100 m horizontally and to a depth of 50 m utilising a grid of 128 128 192 this implies a resolution scale of δ x δ y 0 8 m and δz 0 25 m however the grid is stretched to allow higher resolution at the bed such that δ z 0 14 m at the bed and δ z 0 34 m at the surface horizontal periodicity is enforced at the lateral boundaries and a no slip condition is imposed on the turbulent flow at the top and bottom a sponge layer is used in the top 10m to avoid reflection of energy 4 2 results this section will be devoted to the comparison of the observed and modeled turbulent kinetic energy dissipation rate denoted by ε obs and ε mod respectively provisos need to be taken into account due to the way each variable is calculated so one should only take a qualitative view on the comparison nevertheless it will still provide a meaningful impression for the skill of the model fig 5 shows a comparison between ε obs and ε mod there are two main points about the comparison which are of note firstly the rate at which energy propagates up the water column the slope of the dashed red line is used to help gauge the upwards propagation rate one can expect these slopes to depend on the square root of the eddy viscosity simpson et al 2000 which indicates that the eddy viscosity calculated in the sgs scheme is suited for this application secondly ε mod is clearly within a definite order of magnitude compared to ε obs this can be quantitatively measured by time averaging ε obs and ε mod at each depth bin for each energy plume shown in fig 6 one sees an extremely close fit to the observations which stay well within an order of magnitude throughout the water column though there is discrepancy in the second plume in the upper water column this discrepancy is most likely due to the weak density stratification present in the upper water column something which is not accounted for in the model 5 experiment 3 turbulence closure scheme comparison there is a plethora of different turbulence closure schemes for the rans equations in the literature canuto et al 2001 mellor and yamada 1982 cheng et al 2002 commonly used in state of the art ocean models are two equation second moment closure schemes which attempt to close unresolved stress quantities such as u w and v w in terms of resolved mean quantities i e 23 u w ν t u z v w ν t v z where νt is an eddy viscosity derived from an energy and length scale argument commonly defined by 24 ν t c μ k 2 ɛ where cμ is a structure function generally formulated as a function of stability functions k is the turbulence kinetic energy and ε is the energy dissipation rate two prognostic equations are solved for k and ε for the calculation of νt at each model time step note that this is a description of the k ɛ model popularised by launder and spalding 1974 and further developed by various authors e g shih et al 1995 canuto et al 2001 for a more in depth discussion about k ɛ second order closure models see the extensive comparative review of burchard and bolding 2001 other popular models exist which include the mellor yamada style closure which derives eddy viscosity from the prognostic q 2 q 2 l equations where q is the turbulence intensity q 2 k and l is a turbulence length scale mellor and yamada 1982 and the k ω model where ω is a turbulent frequency scale kolmogorov 1962 saffman 1970 wilcox 1988 all of these equation sets can be neatly derived as a special case of the generic length scale model umlauf and burchard 2003 which has been implemented in the general ocean turbulence model gotm burchard et al 1999 the turbulence closure scheme results generated in this work will be derived from model runs using the gotm software package the myriad of closure schemes which are available have been validated by laboratory kato and phillips 1969 rohr 1985 willis and deardorff 1974 dns gerz et al 1989 and les schumann and gerz 1995 experiments the problem with this is that experiments can not be directly compared to turbulence closure scheme models directly this is due to the unpredictable mean flow generated by turbulent fluctuations furthermore when density is active the mean temperature contribution from the density perturbation field also adds an extra degree of freedom in the same way here we present a test case of the popular turbulence closure scheme of canuto et al 2001 denoted by canuto a and its ability to reproduce turbulence data derived by the les model presented in the previous section density stratification will therefore not be considered for consistency with the perturbation method a one way forcing is applied such that the mean flow is identically eq 22 this means that the mean flow will not be solved for in the turbulence closure scheme only the two prognostic equations for tke and ε will be solved this ensures that the forcing which is applied to both models is identical 5 1 results here three turbulent statistics will be compared energy dissipation rate tke and shear production defined by 25 u w u z which describes the magnitude of the input of turbulent energy from the tidal shear it must be stressed that these results are for illustrative purposes only and we make no assertion of the skill of the turbulence closure scheme in question as to do this a battery of different experiments must be undertaken fig 7 shows that the amount of tke present in canuto a is underestimated compared to the les this can be attributed to a lower level of turbulent production shown here in fig 8 as the majority of the shear is produced at the bed this would imply that the eddy viscosity near this region is likely to be under estimated the underestimation of eddy viscosity has a number of implications for example temperature and salinity diffusivity will be lower in the bottom boundary layer which could possibly result in stratification occurring at the wrong depth also modelling biological or sediment transport with an underestimated eddy viscosity could change the depth distribution properties by contrast the energy dissipation rate shows no similar behavior fig 9 in fact the results show that energy dissipation is over estimated this is surprising as one would intuitively expect that if tke was underestimated then ε would also be underestimated it does however compound the underestimation of eddy viscosity as ν t k 2 ɛ in the k ɛ model however these issues should not detract from the fact that all variables are all well within an order of magnitude of each other a highly desirable trait 6 conclusions this manuscript presents the perturbation method for les the notable characteristics of this method are that the mean flow is explicitly prescribed furthermore in contrast to traditional methods the turbulent fluxes do not act to diverge the calculated mean flow from the prescribed mean flow this latter point enables one to have a higher level of control over the model forcing which is essential for certain applications validation of this technique was completed against a traditional pressure forced large eddy simulation and the results show clearly that the proposed method works well giving near identical turbulence characteristics away from the surface where the boundary conditions were chosen to differ between methods furthermore using adcp data from a chosen site in liverpool bay the results demonstrate the high predictive power of the perturbation method in terms of both magnitude and upward transport of energy dissipation rate finally using the same processed adcp data for forcing the turbulence closure scheme of canuto et al 2001 was compared against the perturbation method to showcase the application of this new technique this method is a strong basis for turbulence closure scheme calibration turbulence parameterisations in the presence of stratification is an active area of research canuto et al 2010 but still remains a relatively unsolved problem holt and proctor 2003 mahrt 2014 scully et al 2011 having complete control over the mean shear and stratification means that one can have a greater level of confidence when finding links between the mean and turbulent components of the flow field improving turbulence closure schemes using the perturbation method could have implications for many important ocean modelling applications for example modelling of the biological pump mechanism in which planktonic organisms draw co2 out of the atmosphere and settle it to the deep sea also it could improve estimates of nutrient fluxes through the pycnocline to the surface mixed layer which is vital for the marine ecosystem population dynamics for future work the perturbation method will be used to examine various scenarios including weakly stratified flows to strong stably stratified flow fields using gotm a range of different closure schemes will be tested to assess the strengths and weaknesses of each scheme acknowledgement this work was funded by the uk natural research council under the pycnmix project ne l003325 1 
24050,turbulence in the ocean dominates the vertical movement of heat and salt as well as chemical and biological particulates the modelling of turbulence is therefore essential to forecast the strength of the biological pump for example in which co2 is drawn out of the atmosphere and trapped in the deep ocean obtaining observations of turbulence is an expensive process and the modelling of turbulence still remains an open problem using state of the art 3d hydrodynamic models such as large eddy simulation and direct numerical simulation to understand turbulence driven by mean flow is a popular method however in this approach the turbulence creates its own mean flow contribution which in some applications results in an undesirable divergence from the prescribed mean flow here the perturbation method is introduced this technique ensures zero divergence to the prescribed mean flow results reveal the high level of accuracy this approach has in replicating the observed turbulent field when using adcp mean current data to prescribe the model mean flow it is envisaged that the user friendly nature of this method will enable non specialists to derive turbulence data when turbulence profilers are not a tractable resource this modelling approach also sets a rigid framework for the testing of turbulence closure schemes keywords turbulence modelling large eddy simulation turbulence closure scheme 1 introduction large eddy simulation les of turbulent flows is used in a wide range of fluid dynamical applications from small scale oceanic dynamics to large scale atmospheric turbulence modelling and many other applications within this scale range mcwilliams et al 1997 noh et al 2004 moeng 1984 kosović and curry 2000 the defining characteristic of les is that small scale fluctuations which act below the scale of the model resolution termed as the subgrid scale sgs are parameterised smagorinsky 1963 the resolved scale turbulent fluctuations and mean flow on the other hand are calculated directly from the fully 3d navier stokes equations this method can be very powerful when the majority of the energy containing scales are above the sgs from this method computationally expensive turbulent flow solutions can be made much more cost effective with little detriment to the solution at the current standard of computing resources les is becoming a more feasible technique where typically the standard and computationally cheap reynolds averaged navier stokes rans method is used however les in oceanic turbulence modelling in contrast to turbulence modelling in the planetary boundary layer still remains a largely under exploited tool relative to engineering applications the main problem in coastal ocean modelling is that the rans technique is cheap but it cannot accurately model turbulent fluxes and the standard les technique is not feasible for large domains a growing body of literature is emerging to solve this problem which combines the two methods detached eddy simulation spalart 2009 where one part of the ocean domain is solved by les and the other part by rans the goal is to use rans near the wall and les away from the wall zhang et al 2015 to improve computational cost while retaining reasonable accuracy similarly chalamalla et al 2017 develops the so called somar les method where an les model is nested inside a parent rans model with two way coupling this method uses a sophisticated adaptive mesh to track and resolve turbulent fluctuations such that the computational time associated with the les part is significantly reduced the les coast approach roman et al 2010 is a novel les technique whereby the eddy viscosity is split into separate directional components this allows for an anisotropic domain without an overestimation of the eddy viscosity and hence allows for a larger grid spacing in the horizontal traditionally les in the ocean is used to study effects of surface forcing on the mixed layer convection winds waves etc vreman et al 1997 skyllingstad and denbo 1995 noh et al 2011 effects of body forcing on the bottom boundary layer e g tidal forcing radhakrishnan and piomelli 2008 and effects of these processes in the presence of stratification armenio and sarkar 2002 gayen et al 2010 the reader is directed to scotti 2010 for an extensive review of the oceanic applications of les in some applications instead of using surface or body forcing it is more appropriate to prescribe the mean flow when the turbulent properties of the system are of interest for example when forcing data is not available but mean currents are known wakata et al 2017 it is also appropriate to prescribe the mean flow when validating turbulence models e g the k ɛ model launder and spalding 1974 against les models this is because the same mean flow can not be achieved by forcing both types of models with the same surface or body forcing even for simple cases like couette flow coles 1965 this is undesirable as the ultimate aim is the validate the turbulent characteristics given a particular mean flow the problem lies in the calculation of the turbulent stresses here the turbulence model and the les model differ resulting in mean flow calculations which also differ however prescribing the mean flow is not appropriate in many applications such as assessing boundary layer evolution for example bottom boundary layer thickening in the presence of tides and mixed layer deepening in the presence of winds and surface heating this is because the evolution of the mean flow is what is of interest something which cannot be investigated when prescribing the mean flow furthermore one cannot fully test the skill of the les when the mean flow calculation is bypassed one must first assess the les s capability to accurately calculate both the mean and turbulent part of the flow field before proceeding with the prescription of a mean flow for the cases when prescribing mean flow is appropriate one problem is apparent the turbulent fluxes present in the navier stokes equations give rise to an extra unwanted mean flow contribution this term takes the form u i u j and symbolizes mean flow generated by the turbulent fluctuations which is an additional mean flow term separate to the forcing if one truly wants to prescribe a mean flow this extra contribution must be considered here the perturbation method is presented this method ensures the extra mean flow contribution which is typically overlooked is not present this means that when prescribing the les with observed mean currents for example one can be sure that the turbulence produced is associated purely with the observed mean flow for the testing of turbulence models against the les one can use the perturbation method to ensure both the turbulence model and les model are forced with the exact mean flow field giving a higher control over experiments this manuscript is set out with the following format the governing equations for the perturbation method are derived given that this method bypasses testing the les s ability to calculate the mean flow we devise an experiment a full body forced les model run is completed which calculates both mean and turbulent flow fields the mean flow from this experiment is used to prescribe the perturbation method the turbulence characteristics are then compared between both methods to show the methods are equivalent in terms of turbulent flow features this will be followed by an experiment whereby the new method is forced by observed mean currents and the model turbulence data will be compared to observed turbulence data at the same site finally a popular turbulence closure scheme canuto et al 2001 is compared to the perturbation method when both models are forced with the same mean flow forcing from the observational data 2 model description before the equation set is derived for the turbulent flow it is convenient to non dimensionalise all flow variables in the usual way 1 u u u 0 x x l p p l u 0 2 where u u v w is the non dimensional form of the flow field u is the dimensional flow field u 0 is an appropriate velocity scale x x y z is a non dimensional spatial co ordinate x is the dimensional co ordinate l is an appropriate length scale p is the non dimensional pressure and p is the dimensional pressure the governing filtered equations of the total flow field can be described by the navier stokes equations stokes 1845 2 u t u u 1 r o k u p ρ 0 1 r e 2 u sgs 3 u 0 here u is the filtered les resolved velocity field r o f l u 0 is the rossby number r e u 0 l ν is the reynolds number f is the coriolis parameter k is the unit vector in the vertical and ν is background viscosity the filter imposed to arrive at eq 2 removes all linear dependence on the unresolved flow u however the classic closure problem arises as the filter imposed on the unresolved non linear term cannot remove dependence on u this extra contribution by the unresolved flow is encapsulated by the sgs term to close the equations typically a reynolds stress argument is used to relate the unresolved terms to resolvable quantities reynolds 1894 a modelled form of the sgs term is typically of the form 4 sgs 2 x j ν t u l s i j where s i j 1 2 u i x j u j x i is the rate of strain tensor and νt is an eddy viscosity normally in les a variant of the smagorinsky scheme is used to calculate the eddy viscosity term e g smagorinsky 1963 here the formulation for the eddy viscosity will be taken from mason and thomson 1992 which is widely used in the literature porté agel et al 2000 lewis 2005 polton et al 2008 5 ν t λ 2 s where s 2 s i j s i j 1 2 is the magnitude of the rate of strain tensor and λ is a length scale defined by 6 1 λ 1 λ 0 1 κ z z 0 where λ 0 c 0 δ c 0 is a constant taken to be 0 25 δ d x d y d z 1 3 is a spatial resolution length scale δ3 is the volume of a grid box κ 0 4 is the von karman constant and z 0 is roughness length prescribed to be 10 3 m results were found to be insensitive to the values chosen for z 0 and c 0 the first term on the right hand side of eq 6 dominates in the interior and the last term dominates near the boundary the flow field can be further partitioned into its mean and turbulent constituents akin to reynolds decomposition reynolds 1894 tennekes and lumley 1972 which comprise the mean and fluctuating parts 7 u x y z t u z t u x y z t here u x y z t is the total flow field u z t is the mean flow field u x y z t is the resolved turbulent velocity field x and y are horizontal axes z is height above bed and t is time as one is usually interested in horizontal average quantities to characterise the flow field it is convenient to define the partitioning in terms of a horizontal average 8 u u z t such that 9 u 0 where is a horizontal mean defined by 10 1 x y x y d x d y where xy is the horizontal area of the domain s extent it is important to note that the flow field can theoretically be decomposed in any way so long as the averaging operation is defined consistently with the decomposition 2 1 the perturbation equations our objective is to solve the turbulent constituent of the flow field only this can be achieved by subtracting the equation for the horizontally averaged flow field given by 11 u t u u 1 r o u u u p ρ 0 1 r e 2 u s g s 12 u 0 from eqs 2 and 3 respectively to yield equations 13 u t u u w u z u u u u 1 r o k u p ρ 0 1 r e 2 u s g s s g s 14 u 0 here the first term on the left hand side of eq 13 represents time evolution of the turbulence and the second term represents advection of the turbulent field by the prescribed mean flow the third term represents the injection of turbulent momentum by the velocity shear the fourth term represents the non linear advection term and the fifth term is the mean part of the fourth term which acts to ensure that no extra contribution to the mean flow can arise the sixth term is a planetary rotation term on the right hand side of eq 13 the first term represents a perturbation pressure gradient the second term represents diffusion of the turbulent field the third term represents density perturbations and finally the last term is an eddy viscosity model calculated by means of a smagorinsky scheme which is described in the previous section these equations are similar to that of the dns study of sakamoto and akitomo 2008 with the main difference being the inclusion of the fifth term on the lhs of eq 13 whereas sakamoto and akitomo 2008 omits this term a convenient aspect of the two terms which include the horizontal average operator is that their only purpose is to remove the mean part arising in their counterpart term e g the fifth term removes the mean part of the fourth term it can be shown that the only purpose of these two terms is to ensure 15 u t 0 which can be demonstrated by applying the horizontal average operator to eq 13 this means that instead of explicitly including the angle bracket terms one can simply remove the mean part which arises in the first term of eq 13 i e ensuring that eq 15 is satisfied this also has the advantage of correcting any spurious mean flow e g from numerical diffusion that might arise as a result of the time stepping scheme or the grid discretisation scheme implemented in this way one can be certain that the mean flow is truly clamped to the input mean flow this also has the advantage of being much simpler to implement into an existing les code 3 experiment 1 validation of the perturbation method 3 1 experiment design to validate the implementation of the new model equations they are first tested against an analogous traditional forcing method setup traditional les methods usually incorporate a two way interaction between the mean and turbulent constituents of the flow the proposed perturbation model equations assume a one way interaction where the mean flow forces the turbulence and not vice versa the assumption of this one way interaction is that the mean field and the turbulent field are in statistical balance therefore an appropriate experiment will involve using a steady state setup in the traditional pressure forced les model i e where the mean flow and the turbulent flow are statistically stationary this will ensure that the mean flow remains unperturbed by the turbulent field in both methods 3 2 traditional pressure forced method the traditional pressure forced method solves the filtered navier stokes equations given by eq 2 but with the inclusion of an additional pressure term which is a source of momentum given by 16 u t u u 1 r o k w p ρ 0 p ρ 0 1 r e 2 u sgs where 17 p ρ 0 is the additional pressure gradient acting as a body force on the flow field the dynamic smagorinsky model was used for the sgs term for this experiment porté agel et al 2000 3 2 1 boundary conditions and numerical configuration for the purposes of this set up and to ensure steady state p ρ 0 0 c 0 where c 5 10 4 is constant in space and time without loss of generality this pressure forcing will act only in the y direction the numerical grid will consist of 64 64 96 points over a non dimensional domain of size of 4 π 16 π 3 2 in x y z directions respectively no rotation is permitted 1 r o 0 a bulk reynolds number of r e 5000 is used and the simulation performed is classified by a friction reynolds number of r e τ 160 to aid in physical interpretation results will be displayed in dimensional units with a typical velocity and length scale of u 0 0 1 ms 1 and l 25 m implying a background viscosity of ν 5 10 4 m 2 s 1 the simulation reached steady state with a mean flow profile shown in fig 1 a and mean shear profile shown in fig 1 b this mean flow and mean shear will be used to force the perturbation method described by eq 13 here a free slip condition will be applied to the surface which will be in direct contrast to the no slip applied to the surface of the perturbation method due to stability reasons this difference will be shown to have no discernible effect away from the surface a desirable quality 3 3 results there are many quantities one can derive to compare properties of each turbulent flow field however only important quantities which characterize the amount of energy and transport in the flow namely resolved reynolds stresses turbulent kinetic energy tke and energy lost through dissipation ε will be compared note that all profiles shown in this section have been averaged over the horizontal domain and have been temporally averaged over 1400 time units once steady state has been reached after 1500 simulation time units to note it was found that the perturbation method was more stable in terms of the model time step allowing a time step 2 5 times larger it also took noticeably less time to reach steady state fig 2 a shows reynolds stress quantities u w and v w which describe the vertical fluxes of horizontal momentum though the profiles do not match exactly the difference is not particularly discernible this would indicate that should a tracer be included in each model then the vertical transport would be near identical in both cases this is for example important when considering transport of temperature and salinity fig 2 b shows the components of turbulent kinetic energy in the form of velocity variances u 2 v 2 and w 2 as the forcing is acting in the y direction v 2 contains the majority of the energy it is clear that both models are indistinguishable in the majority of the water column notably the difference only occurs in the local vicinity of the surface finally energy dissipation rate ε and tke defined by 18 ɛ ν ν t u i x j u i x j t k e 0 5 u 2 v 2 w 2 are shown in fig 3 these profiles are near identical again only diverging in the local vicinity of the surface boundary this is most important as these two metrics are generally used to characterize the turbulence of the flow field as both models give the same values in the majority of the water column one can be confident that the difference in surface boundary conditions gives no detrimental effect 4 experiment 2 forcing by observations here the skill of the perturbation method is assessed via a simple test observed mean flow will be processed and used to drive the perturbation equations eq 9 the resulting modelled turbulent field will be compared to that of the observed turbulent field observations of mean flow were provided by an acoustic doppler current profiler adcp lu and lueck 1999 mounted within the hull of the research vessel the adcp delivers high resolution vertical profiles of horizontal current velocity over the majority of the water column from approximately 7 m depth to within 3 m of the seabed data was collected in an energetic tidally forced site in liverpool bay uk this site undergoes significant semi diurnal tides with a maximum range in excess of 10 m very near to the coast liverpool bay does undergo periodic stratification due to advecting salinity gradients however the site chosen was suitably offshore to be vertically well mixed throughout this experiment hourly ctd surveys confirm that the water column was well mixed data was collected on the rv prince madog on 10th may 2009 between 07 01 and 19 30 utc at 10 min intervals the vessel was anchored at 53 37 2 n 3 55 2 w in 43 1 m of water the depth averaged mean flow was then derived and used to drive the perturbation equations eq 9 which were in turn used to generate the model turbulent field the observed turbulent field was provided by measurements of the dissipation rate of turbulent kinetic energy which was derived from shear microstructure measured using a vertically freefalling mss profiler prandke and stips 1998 for this experiment a guard was used to protect the microstructure probes which enabled the profiler to impact the seabed to collect data to within 10cm of the bottom boundary so resolving the vast majority of turbulence resulting from tidally driven shear 4 1 data processing due to the formulation of the perturbation equations mean flow should be a spatial average in the horizontal however observations of mean flow are only obtained at one point in the horizontal lat lon field therefore the data needs to be appropriately time averaged the following assumptions will be enforced in time tidal frequencies follow the m2 and m4 harmonics this will capture the main tidal oscillation and any tidal asymmetries that may arise in depth it is assumed that the current profile will match that of the classic log layer an assumption which is found to be more than reasonable jensen et al 1989 this processed mean flow will then be used to force the perturbation method the resultant turbulence characteristics namely energy dissipation rate from the model simulations will then be compared to observations of energy dissipation rate derived from the micro structure profiler to process the adcp current data to obtain u z t for the perturbation method an assumption of separability will be used for simplicity i e 19 u z t f t g z where f t will depend on the tidal harmonics and g z will depend on a classic log layer profile explicitly f t will take the form 20 f t i 1 2 a i sin i ω t b i cos i ω t here f t is a fourier series derived by the least squares regression method using the deepest observed data which was 5 m above the bed as one can see in fig 4 this simple expression captures the amplitudes to a high level of accuracy the classic log layer has the form 21 u κ log z z 0 where κ is the von karman constant taken to be 0 4 u is the friction velocity at the bed and z 0 10 3 m is a typical roughness length to ensure matching of the log layer to f t at the lowest observational point one arrives at a mean flow of the form 22 u z t f t log 5 z 0 log z z 0 though comparison of this fit with depth at each time will be omitted from this manuscript it was found to show good agreement to the data at all times indeed the simulated variance in velocity fluctuations shown later are an order of magnitude larger than the variance that exists in the deficit between the observed adcp values and the les forcing velocities this suggests that the velocity fitting is not discarding an important source of energy furthermore as commented on earlier the convenience of this form is that derivatives in z can be taken analytically and interpolation is not needed between observed time points which increases both accuracy of the solution method and the ease of implementation in the model code 4 1 1 boundary conditions and numerical configuration velocity and pressure fields were computed from eq 13 over a computational domain of 100 m 100 m horizontally and to a depth of 50 m utilising a grid of 128 128 192 this implies a resolution scale of δ x δ y 0 8 m and δz 0 25 m however the grid is stretched to allow higher resolution at the bed such that δ z 0 14 m at the bed and δ z 0 34 m at the surface horizontal periodicity is enforced at the lateral boundaries and a no slip condition is imposed on the turbulent flow at the top and bottom a sponge layer is used in the top 10m to avoid reflection of energy 4 2 results this section will be devoted to the comparison of the observed and modeled turbulent kinetic energy dissipation rate denoted by ε obs and ε mod respectively provisos need to be taken into account due to the way each variable is calculated so one should only take a qualitative view on the comparison nevertheless it will still provide a meaningful impression for the skill of the model fig 5 shows a comparison between ε obs and ε mod there are two main points about the comparison which are of note firstly the rate at which energy propagates up the water column the slope of the dashed red line is used to help gauge the upwards propagation rate one can expect these slopes to depend on the square root of the eddy viscosity simpson et al 2000 which indicates that the eddy viscosity calculated in the sgs scheme is suited for this application secondly ε mod is clearly within a definite order of magnitude compared to ε obs this can be quantitatively measured by time averaging ε obs and ε mod at each depth bin for each energy plume shown in fig 6 one sees an extremely close fit to the observations which stay well within an order of magnitude throughout the water column though there is discrepancy in the second plume in the upper water column this discrepancy is most likely due to the weak density stratification present in the upper water column something which is not accounted for in the model 5 experiment 3 turbulence closure scheme comparison there is a plethora of different turbulence closure schemes for the rans equations in the literature canuto et al 2001 mellor and yamada 1982 cheng et al 2002 commonly used in state of the art ocean models are two equation second moment closure schemes which attempt to close unresolved stress quantities such as u w and v w in terms of resolved mean quantities i e 23 u w ν t u z v w ν t v z where νt is an eddy viscosity derived from an energy and length scale argument commonly defined by 24 ν t c μ k 2 ɛ where cμ is a structure function generally formulated as a function of stability functions k is the turbulence kinetic energy and ε is the energy dissipation rate two prognostic equations are solved for k and ε for the calculation of νt at each model time step note that this is a description of the k ɛ model popularised by launder and spalding 1974 and further developed by various authors e g shih et al 1995 canuto et al 2001 for a more in depth discussion about k ɛ second order closure models see the extensive comparative review of burchard and bolding 2001 other popular models exist which include the mellor yamada style closure which derives eddy viscosity from the prognostic q 2 q 2 l equations where q is the turbulence intensity q 2 k and l is a turbulence length scale mellor and yamada 1982 and the k ω model where ω is a turbulent frequency scale kolmogorov 1962 saffman 1970 wilcox 1988 all of these equation sets can be neatly derived as a special case of the generic length scale model umlauf and burchard 2003 which has been implemented in the general ocean turbulence model gotm burchard et al 1999 the turbulence closure scheme results generated in this work will be derived from model runs using the gotm software package the myriad of closure schemes which are available have been validated by laboratory kato and phillips 1969 rohr 1985 willis and deardorff 1974 dns gerz et al 1989 and les schumann and gerz 1995 experiments the problem with this is that experiments can not be directly compared to turbulence closure scheme models directly this is due to the unpredictable mean flow generated by turbulent fluctuations furthermore when density is active the mean temperature contribution from the density perturbation field also adds an extra degree of freedom in the same way here we present a test case of the popular turbulence closure scheme of canuto et al 2001 denoted by canuto a and its ability to reproduce turbulence data derived by the les model presented in the previous section density stratification will therefore not be considered for consistency with the perturbation method a one way forcing is applied such that the mean flow is identically eq 22 this means that the mean flow will not be solved for in the turbulence closure scheme only the two prognostic equations for tke and ε will be solved this ensures that the forcing which is applied to both models is identical 5 1 results here three turbulent statistics will be compared energy dissipation rate tke and shear production defined by 25 u w u z which describes the magnitude of the input of turbulent energy from the tidal shear it must be stressed that these results are for illustrative purposes only and we make no assertion of the skill of the turbulence closure scheme in question as to do this a battery of different experiments must be undertaken fig 7 shows that the amount of tke present in canuto a is underestimated compared to the les this can be attributed to a lower level of turbulent production shown here in fig 8 as the majority of the shear is produced at the bed this would imply that the eddy viscosity near this region is likely to be under estimated the underestimation of eddy viscosity has a number of implications for example temperature and salinity diffusivity will be lower in the bottom boundary layer which could possibly result in stratification occurring at the wrong depth also modelling biological or sediment transport with an underestimated eddy viscosity could change the depth distribution properties by contrast the energy dissipation rate shows no similar behavior fig 9 in fact the results show that energy dissipation is over estimated this is surprising as one would intuitively expect that if tke was underestimated then ε would also be underestimated it does however compound the underestimation of eddy viscosity as ν t k 2 ɛ in the k ɛ model however these issues should not detract from the fact that all variables are all well within an order of magnitude of each other a highly desirable trait 6 conclusions this manuscript presents the perturbation method for les the notable characteristics of this method are that the mean flow is explicitly prescribed furthermore in contrast to traditional methods the turbulent fluxes do not act to diverge the calculated mean flow from the prescribed mean flow this latter point enables one to have a higher level of control over the model forcing which is essential for certain applications validation of this technique was completed against a traditional pressure forced large eddy simulation and the results show clearly that the proposed method works well giving near identical turbulence characteristics away from the surface where the boundary conditions were chosen to differ between methods furthermore using adcp data from a chosen site in liverpool bay the results demonstrate the high predictive power of the perturbation method in terms of both magnitude and upward transport of energy dissipation rate finally using the same processed adcp data for forcing the turbulence closure scheme of canuto et al 2001 was compared against the perturbation method to showcase the application of this new technique this method is a strong basis for turbulence closure scheme calibration turbulence parameterisations in the presence of stratification is an active area of research canuto et al 2010 but still remains a relatively unsolved problem holt and proctor 2003 mahrt 2014 scully et al 2011 having complete control over the mean shear and stratification means that one can have a greater level of confidence when finding links between the mean and turbulent components of the flow field improving turbulence closure schemes using the perturbation method could have implications for many important ocean modelling applications for example modelling of the biological pump mechanism in which planktonic organisms draw co2 out of the atmosphere and settle it to the deep sea also it could improve estimates of nutrient fluxes through the pycnocline to the surface mixed layer which is vital for the marine ecosystem population dynamics for future work the perturbation method will be used to examine various scenarios including weakly stratified flows to strong stably stratified flow fields using gotm a range of different closure schemes will be tested to assess the strengths and weaknesses of each scheme acknowledgement this work was funded by the uk natural research council under the pycnmix project ne l003325 1 
24051,using a suite of observing system simulation experiments osses the utility of simulated surface water ocean topography swot observations is estimated in a high resolution 1 km ocean analysis forecasting system sampling a nature run provides observations for the osses and the realism of the nature run is established by comparison to climatological data and an independent ocean analysis forecast system each osse experiment assimilated different sets of simulated observations including traditional nadir altimeters satellite sea surface temperature sst in situ profile data and swot osse evaluation metrics include area averaged errors and wavenumber spectra with the latter providing much finer differentiation between experiments 100 m temperature sea surface height ssh and mixed layer depth mld errors across the observed wavenumber spectra were reduced by up to 20 for osses assimilating the simulated swot observations the minimum constrained wavelength was found to be 130 km when both nadir altimetry and swot observations were used the experiment using only nadir altimetry produced a value of 161 km this 31 km gain in skill of predictable scales suggests that ocean forecasts can expect substantial gains in capability when utilizing the forthcoming swot data experimentation with the analysis decorrelation length scale suggests that emerging multi scale assimilation methodologies will provide additional advancements in predictive skill keywords osse swot altimeter 3dvar mesoscale submesoscale 1 introduction numerous studies have documented the utility of altimetric observations of the ocean surface in generating mesoscale predictive skill e g smedstad et al 2003 ananda et al 2006 jacobs et al 2014a le traon et al 2015 however the current suite of nadir looking altimeters produces an ocean surface representation that is limited by spatial and temporal sampling since jason 2 at least two altimeter sensors have been in orbit at any one time with their merged observations producing two dimensional grids of sea surface height ssh that can resolve wavelengths of approximately 150 km and greater ducet et al 2000 fu and ubelmann 2014 these estimates are significantly coarser than the features present ocean prediction systems can resolve this observational deficit may soon be alleviated with the launch of the surface water ocean topography swot satellite mission in 2021 fu and ubelmann 2014 the sensor is expected to collect along and across track ssh observations at very high resolutions 1 km allowing oceanographers to study previously under observed phenomena on a global scale this observational capability poses important questions to the ocean prediction community what increases in forecast skill can be expected by assimilating these data into a high resolution ocean analysis forecasting system will the swot observations allow the assimilation system to constrain spatial scales below that which is currently achievable using a constellation of nadir altimeters the objective of this study is to determine how swot observations can change ocean predictability when compared to results derived using only currently operating nadir altimetry a number of studies have tested the usefulness of simulated swot observations for more narrowly focused hydrological and hydrographic modeling andreadis et al 2007 durand et al 2008 biancamaria et al 2010 yoon et al 2012 pedinotti et al 2014 munier et al 2015 oubanas et al 2018a 2018b carrier et al 2016 showed that within a regional ocean 4dvar data assimilation framework simulated swot observations significantly improved analysis forecast skill with respect to both the placement of mesoscale features and surface velocities the work presented here extends the resolution of the model system from 6 km to 1 km and quantifies the bulk error magnitudes and resolved spatial scales this is a critical expansion of experimentation as a horizontal model resolution of 1 km allows the simulation to explicitly resolve submesoscale processes with wavelengths o 10 km capet et al 2008 these small scale dynamics are important to accurately represent and predict in numerical models because they have strong impact on near surface dynamics mcwilliams 2016 net ocean atmosphere heat fluxes su et al 2018 and biogeochemical processes levy et al 2012 the current set of satellite altimeters cannot observe submesoscale features and therefore regional models that explicitly resolve submesoscales are unable to constrain the placement and evolution of the phenomenon swot will provide an important path forward towards bridging this gap between model resolution and observational capabilities this requires testing to quantify the range of wavelengths the swot observations will allow the assimilation system to constrain ocean forecasting systems have been designed for mesoscale prediction cummings et al 2009 and it is unclear if mesoscale assumptions translate to submesoscale predictive skill even when utilizing high resolution data streams that explicitly resolve the phenomenon the material is organized by first describing the construction of an observing system simulation experiment osse e g halliwell et al 2014 in section 2 a simulated truth hereafter called nature was generated using a submesoscale resolving non assimilative model run nature was sampled at real observation locations and times for remotely sensed sea surface temperature sst in situ profiles and satellite altimetry swot sampling was derived using the swot simulator osses deviate from nature through initial condition perturbation different sets of simulated observations were assimilated into each osse experiment the errors in the osses are evaluated in section 3 by comparison of area averaged statistics and by wavenumber spectra of errors section 4 considers the potential usefulness of emerging data assimilation techniques based on results derived by adjusting the analysis decorrelation length scale in an attempt to further utilize the small scale variability observed by swot in section 3 2 methods ascertaining the utility of a remote sensing platform that is not currently producing data requires the construction of a controlled laboratory environment in which simulated data consistent with expected sampling can be tested this section documents the methodology of the experiments the numerical ocean model configuration used by nature and each of the osse experiments section 2 1 nature spin up and validation section 2 2 setup of the osses section 2 3 and the data assimilation methodology section 2 4 2 1 model system setup the navy coastal ocean model ncom barron et al 2006 provided simulated three dimensional ocean fields and we applied the system within the western pacific ocean fig 1a a region that contains a strong western boundary current extensive continental shelves deep ocean basins strong seasonal surface mixed layer variability strong mesoscale features in the deep ocean submesoscale processes and interactions between all of these ncom integrates the primitive equations forward in time using the hydrostatic and boussinesq approximations it features a hybrid σ z vertical grid allowing for higher vertical resolution in the near surface environment as well as terrain following capabilities in the coastal ocean a standard z vertical grid is used at deeper layers and the transition from z to upper layer sigma coordinates is a user input for experiments here 50 vertical layers were used to a maximum depth of 4000 m with the σ z transition occurring at layer 25 corresponding to a depth of 120 m at rest the surface sigma layer at its thickest is about 1 m and layer thicknesses progressively increase with increasing depth in the horizontal the model resolution was set to 1 km allowing ncom to produce ocean features with wavelengths down to o 10 km which is a minimal resolution for representing submesoscale processes capet et al 2008 using a model grid that can explicitly resolve submesoscale features provides the ability to conduct an important hypothesis test can assimilating simulated swot observations into the high resolution system constrain features at submesoscale wavelengths using a model grid any coarser than that chosen would preclude the rejection or acceptance of any such hypothesis lateral ocean boundary conditions were provided by a double one way nesting procedure first boundary conditions from the operational global 1 12 hybrid coordinate ocean model hycom were provided to the larger nest 113 e 136 e 15 n 38 n fig 1a a regional ncom simulation with a horizontal resolution of 3 km boundary conditions were generated from the 3 km simulation and provided to the 1 km nest 116 e 133 e 18 n 34 n fig 1b this approach was taken to mitigate numerical instabilities that can arise from interpolating boundary conditions from a model at least 3 times coarser than the nested simulation atmospheric forcing was provided by the navy global environmental model navgem hogan et al 2014 the forcing derived from this model has a horizontal resolution of 37 km and a frequency of 3 h surface wind stress and precipitation were extracted directly from the navgem output latent and sensible heat flux were computed by coupled ocean atmosphere response experiment coare version 3 0 fairall et al 2003 solar radiation provided by navgem was absorbed through the water column using a jerlov water type ii jerlov 1976 river in flow was introduced at fixed points approximating the geographic location of large river mouths using the ncom river database barron and smedstad 2002 the final 1 km nest included tidal forcing from the global oregon tidal inverse solution otis egbert and erofeeva 2002 the tidal forcing was not included in global hycom or the 3 km outer nest any analyses featuring either ssh or velocity have had the barotropic tidal signal removed from each variable through a post processing procedure nonetheless this harmonic analysis will inevitably miss incoherent baroclinic tides that have non tidal frequencies this phenomenon is present in temperature and salinity below the mixed layer ssh as well as surface and subsurface velocities and will therefore be included in our error analyses this problem deserves attention as these waves are expected to containment balanced mesoscale and submesoscale swot observations chavanne et al 2010 but the subject is outside the scope of this study in all we endeavored to produce a highly realistic system that includes short time and small spatial scale variability representative of the physical ocean and will therefore be present in the swot observations 2 2 nature setup and validation this section describes nature and a validation of nature statistics in comparison with climatological observations of the real ocean and an independent assimilative ocean forecasting system the 3 km ncom nest was initialized on november 1 2015 and spun up until the end of the month the 3 km december 1 2015 forecast was then interpolated onto the final 1 km grid and used as the initial condition for nature nature was then spun up for the entirety of december 2015 to ensure that both mesoscale and submesoscale features had sufficient time to properly develop the simulation was then integrated forward for an entire year with the complete time period being january 1 2016 to december 31 2016 no data assimilation was applied to nature the completely unconstrained nature of this simulation could introduce problems in the osse whereby the statistics of nature deviate so far from the real ocean that conclusions gleaned from the experiment may not be applicable to the physical world for this reason it is common practice to validate the nature simulation to ensure that it is sufficiently realistic atlas 1997 the purpose of this procedure is not to test the error of the solution in terms of how it exactly compares with the real ocean at equivalent times at any given time step nature will be quite different from the real ocean instead we are testing to determine if nature statistics are consistent with the statistics of the real ocean to begin surface temperature mixed layer and thermocline means are analyzed qualitatively the mean nature sst compares favorably with both the observation based generalized digital environmental model version 4 gdem4 teague et al 1990 carnes et al 2010 sst climatology and the assimilative hycom 2016 annual sst mean fig 2 all three means have similar magnitude and comparable locations of large scale fronts such as the kuroshio western boundary current that meets the coastal waters along the continental shelf by taking the area averaged value at each time step of each dataset the seasonal cycle of nature can be validated fig 2d both nature and hycom deviate from the area averaged gdem4 climatology within each month with the model deviations from climatology being similar the seasonal cycle amplitude is consistent between the models and climatology the higher frequency events in the model time series are similar and are responses to atmospheric events using a 0 2 c temperature criteria to derive mixed layer depth mld produces a similar mean spatial distribution from all three of the examined datasets fig 3 in the deep ocean gdem4 has slightly shallower mld than both nature and hycom nature produces the shallow mld along the kuroshio pathway evident in the gdem4 data much better than hycom across the annual cycle nature and hycom track the gdem4 climatology closely although mixed layers are generally deeper in both simulations between january and the end of march fig 3d below the deepest regional mean mld 90 m fig 3d 100 m temperature provides a representation of the mean thermocline structure fig 4 the location of the kuroshio front is in good agreement between the three datasets and deep ocean magnitudes are highly comparable through time the nature spatial mean shows deviations from both gdem4 and hycom on the order of approximately 1 c between february and november fig 4d the seasonal cycle of three datasets however are in good agreement in all these analyses suggest that nature sst mld and 100 m temperature means have similar magnitudes spatial distributions and seasonal cycles to that of the climatology of the real ocean next nature energy is evaluated the mean surface eddy kinetic energy eke from nature compares favorably with drifter observations and assimilative hycom fig 5 all drifter data collected between 1983 and 2009 were binned into 1 1 grid boxes only grid points with at least 100 drifter observations were considered in the temporal mean thoppil et al 2011 the spatial distribution of mean eke is similar in all three datasets but nature magnitudes are more similar to that of the observations than hycom this is most likely due to model differences in horizontal resolution prior experiments have shown that a model horizontal resolution of at least 3 km is required to completely represent mesoscale dynamics e g hogan and hurlburt 2000 spatially the three datasets are highly consistent with higher eke in the deep ocean and along the pathway of the kuroshio western boundary current as well as lower eke north of the current along the wide continental shelf strong eke seasonality is not observed and despite differences in magnitude the two time series have strong correlation through time fig 5d 2016 annual nature ssh root mean square rms is evaluated against nadir altimetry observations and assimilative hycom over the same time period fig 6 all three datasets feature comparable magnitudes the points of maximum rms in each dataset are located primarily along the pathway of the kuroshio and to the east of the boundary current south of approximately 20 n rms values are lower in each overall hycom compares most favorably with the observations in terms of feature location as it assimilated the altimeter data throughout 2016 the non assimilative nature does not produce local maxima in exactly the same locations as observed but the overall magnitude and general spatial pattern is consistent with the observations finally annual subsurface temperature standard deviation along 21 n is examined fig 7 all three datasets produce depth maximum temperature standard deviation within the top 150 m lower amplitude thermocline variability is present below this level and the 1 c standard deviation contour extends down to approximately 500 m in nature and gdem4 the same contour in hycom is shallower with a maximum depth of approximately 250 m in all the nature temperature depth variance structure is more comparable with the climatological data than hycom overall nature statistics are in good agreement with observations and an assimilative ocean model with this confirmation nature was used as a reasonable approximation of the real ocean and sampled to provide simulated observations to the osse experiments the nature sampling osse configuration and data assimilation methodology are described in the remainder of section 2 2 3 osse experiments if the same model horizontal resolution initial condition boundary conditions and surface forcing were used to generate the osse experiments an exact replica of nature would be created formally osses should utilize a completely different model run at a coarser resolution to represent errors in model physics and resolution limitations atlas 1997 the approach taken in this study however is to use the same dynamical model and resolution and a realistically different initial condition for the osses the hypothesis is that the new initial condition is sufficiently different and that the processes inside the 1 km numerical simulation are non deterministic so the nature and osse simulations are realistically different from one another over the experiment time period there are many examples of successful experiments using this methodology e g jacobs et al 2014a li et al 2015a carrier et al 2016 ultimately the study makes the strong hypothesis of a perfect model whereby having a perfect set of observations at all model grid points would provide the perfect forecast this removes an independent variable from the osse error analysis i e model error and allows us to focus on the impact of the different observation types for the experiments presented here the osse initial condition was perturbed by offsetting the initial condition by one year the nature state on december 1 2016 was used as the initial condition of the osses starting december 1 2015 the validity of the initial condition perturbation approach was tested by generating a parallel non assimilative experiment using this new initial condition called the free run the free run was spun up for the entirety of december 2015 beginning with the altered initial condition and then run out for all of 2016 which is the same time frame as nature the free run was then compared with nature during 2016 to demonstrate that the two solutions do indeed differ due to non deterministic processes fig 8 shows mean absolute error mae between nature and the free run every 3 h for ssh surface speed and mld at all grid points within the simulation domain with water depth of at least 1000 m shelf dynamics are largely deterministic so we focus on deep water variability where mesoscale and submesoscale nonlinearities should cause the two simulations to differ substantially over time ssh errors oscillate around a rms of 9 cm with a minimum of 5 5 cm and maximum of 12 cm fig 8a for reference the rms of nature ssh anomalies for all of 2016 was calculated and found to be 13 cm this suggests that free run ssh errors with respect to nature are on average more than half of the signal surface speed mae features less variability around a rms of 20 cm s 1 fig 8b the rms of nature speed anomalies are found to be 25 cm s 1 which is very close to the free run error amplitude initially mld mae is large 30 m but then a sharp decline in error is observed starting in march fig 8c this is not due to the free run dramatically converging towards nature but instead due to seasonal variations in the mixed layer boreal winter is characterized by deep mixed layers and therefore larger errors across the domain as the region transitions towards boreal spring and summer stratification increases in the near surface due to increased solar radiation and mld becomes shallower this causes a natural reduction of error until december when the transition towards boreal winter causes mixed layers to deepen again the rms of nature mld anomalies was found to be 17 8 m and free run error rms was found to be 32 7 m the analyses performed demonstrate that the use of a perturbed initial condition for the free run causes it to differ from nature throughout the 2016 forward integration period with expected magnitudes thus error reduction in the assimilative runs is attributed to assimilation and not a steady decline in error due to the identical numerical model used in all runs with confidence that the methodology outlined above does produce a different solution the next step was to sample nature to generate simulated observations for observational datasets currently in operation sst in situ and altimetry nature was sampled at real observation locations and times throughout 2016 simulated sst and in situ observations were assumed to be without error i e no noise was added to the sampled observations errors were not added to these data because the impact of the altimetry data is desired nature was sampled at jason 2 altika and cryosat 2 mission observation locations and times and error was added to the simulated observations based on a random gaussian distribution with a standard deviation of 3 cm to generate simulated swot observations we employed the jet propulsion laboratory s jpl swot simulator gaultier et al 2016 version 2 0 0 of the simulator was used to sample nature on a 2 km grid in both along and across track directions nature was output in netcdf format in 3 hourly time intervals the swot simulator interpolated the model fields in space and time to obtain the simulated observations on the swot grid along the 21 day repeat tracks the simulator includes functionality to add random realizations of simulated error to the swot observations based on an estimated swot error spectrum these errors include karin noise roll error phase error timing error baseline error and wet troposphere error gaultier et al 2016 these simulated errors are known to currently be conservative i e expecting worst case errors especially for errors with long wavelengths i e roll phase and baseline errors ubelmann et al 2018 https spark adobe com page okwkaikjwvm0e 5000 random realizations of simulated swot errors using version 2 0 0 of the swot simulator were generated and found to have an error standard deviation of 6 5 cm not shown a proposed solution is to reduce the magnitude of these strongly correlated errors by performing crossover calibration ubelmann et al 2018 with such large simulated errors and with ongoing work being performed to optimize the simulator we chose to apply the same random gaussian errors that were applied to the simulated nadir altimetry data to the simulated swot observations therefore this experiment quantifies differences in analysis forecast skill due only to differences between altimetry and swot sampling with a prescribed white noise level i e resolution swath width and sampling frequency 2 4 data assimilation a 3dvar data assimilation was used in the experiments in a manner similar to that used in the operational global hycom system while the more advanced 4dvar scheme is becoming more widely used in oceanography particularly in regional nests e g ngodock and carrier 2014 the 3dvar provides a lower computational cost to enable us to perform the multiple experiments run at such high resolutions 4dvar systems are expected to provide greater skill and the magnitude of this increased skill remains an important research problem for the future the navy coupled ocean data assimilation ncoda system cummings 2005 was used for these experiments vertical correlations of temperature salinity geopotential and velocity were provided by the improved synthetic ocean profile isop helber et al 2013 the isop system is described more fully in the following paragraph data assimilation was performed daily at 00z using the previous 24 h forecast as the background to be updated available in situ altimetric and sst observations 12 days 5 days and 12 h prior were collected for the analysis respectively the temporal and spatial scarcity of the in situ observations e g argo http www argo ucsd edu dictate the longer window when compared to the other observation types conversely the short 12 hour window used for sst is due to the relative ubiquity of these observations using a 5 day observation window for the altimetric observations might be too short to properly represent the mesoscale field and too long to correctly fit transient submesoscale features this choice is a compromise based off prior results that tested different sets of observation windows jacobs et al 2014b section 4 elaborates on how future work might search for an optimal window to accommodate the different time scales of the mesoscale and submesoscale phenomena the 12 day and 5 day windows cause individual observations to be assimilated on successive days a practice that violates optimal estimation theory using observations repeatedly however improves assimilation performance and is a technique employed by a number of different global ocean data assimilation experiment godae systems martin et al 2007 cummings et al 2009 jacobs et al 2014a 2014b innovations or the difference between the background and observations were derived using the first guess at appropriate time fgat method and used to minimize the cost function to achieve an optimal increment cummings 2005 a 6 h hindcast was performed to incrementally insert the analysis correction the increment was divided by the total number of time steps in the 6 hour hindcast prior to the 00z time of the analysis and the divided increment was added to the model tendency at each time step inserting the entire increment directly into the full background at 00z can generate spurious gravity waves and inertial oscillations that take time for the forward solution to damp out the incremental insertion method attempts to mitigate the development of such motions and therefore provide an initial state with lower energy in these extraneous features nonetheless we did observe analysis steps that still featured these transient features not shown which suggests some potential influence on our error analysis finally background error variances are a function of the state variable geographic position and depth and are based on the gdem4 climatology the background error variances are not scaled by the decorrelation length scale that is discussed in section 2 4 1 sst and in situ observations were used directly to generate innovations nadir altimetry and swot observations were treated in a different manner using isop altimetric observations were converted into subsurface temperature and salinity anomalies using a one dimensional variational analysis employing vertical correlations based on a relatively coarse set of in situ observations of mesoscale processes climatological temperature and salinity provide additional constraint and allow for full temperature and salinity profiles the isop climatological temperature and salinity were derived from in situ observations collected by the navy s master oceanographic observation data set moods world ocean database wod 2005 and delayed mode argo helber et al 2013 the synthetic temperature and salinity were then used to generate innovations and ultimately increments the most important isop variational constraint is to steric height anomaly not ssh anomaly generally ssh and steric height are strongly correlated but many processes cause discrepancies e g wind driven high frequency barotropic flows because our experiments were conducted in a controlled environment we optimized the process by sampling nature steric height anomalies instead of ssh anomalies nature steric height referenced to 1000 m was calculated and the gdem4 mean steric height field was removed to generate anomalies 2 4 1 analysis decorrelation length scale and super observations an important element of the 3dvar assimilation procedure is the analysis decorrelation length scale i e decorrelation length scale of the background error the parameter controls the length scale over which analysis increments are spread a few factors motivate the magnitude of the decorrelation length scale a numerical grid represents physical features that are approximately 10 grid points in size hence the system should not attempt to correct features that the model cannot reasonably represent and this dictates a lower bound on the scale additionally the assimilation system should correct features that are believed to be the primary error sources historically these have been mesoscale eddies cummings et al 2009 the rossby radius of deformation describes the length scale for which planetary vorticity is primarily balanced by pressure i e geostrophy and therefore provides a convenient physically relevant constraint for fitting mesoscale features thus the decorrelation length scale is often taken to be related to the deformation radius cummings 2005 these considerations have worked in concert in the past the swot observations provide information on scales below the deformation radius and therefore considerations must be made to deal with the high density of these data with respect to the decorrelation length scale as more observations cluster within a decorrelation length scale the computational cost of the observation preparation and deriving the minimization increases and in an extreme case could cause the solution to never converge due to practical limitations e g round off errors additionally the nadir altimeter and swot surface observations are converted into synthetic temperature and salinity profiles by the isop system vertical representation error becomes problematic as more small scale information is introduced into the assimilation by the high resolution observations that swot provides isop is based off a mesoscale climatology which does not accurately represent smaller scale phenomena such as balanced submesoscales and internal gravity waves that are explicitly represented in our modeling framework and thus also within the observations sampled from nature these issues provide motivation to thin the observations there are two approaches to reducing the number of observations one is thinning that simply selects a subset of the available observations the second approach is through the creation of a super observation whereby a weighted average is derived over the local analysis decorrelation length scale and treated as the true observation to be assimilated the latter methodology is used in this experiment the weighting is gaussian using distance from the centroid of the data going into the super observation with an e folding scale of the local analysis decorrelation length scale a simple observation operator maps the control variables from the nearest model grid point to the centroid over which the super observation was created to calculate innovations the super observation reduces observation error and maintains features larger than the decorrelation scale therefore the super observation produces an observation that is consistent with the analysis scales and the types of physics that isop is able to reproduce for sst a set of super observations was derived and passed directly to ncoda for assimilation for nadir altimetry and swot data a set of super observations was derived and then passed to isop to generate synthetic temperature and salinity profiles at the centroid of the data over which the super observation was taken this drastically reduces the number of observations that are assimilated into the system fig 9 the full observation set fig 9a b includes swot observations on a 2 km along and across track grid fig 9c d shows how using a mean 15 km decorrelation length scale affects the volume of observations after super observations are constructed using a larger average analysis decorrelation length scale 30 km fig 9e f results in a smaller number of super observations the errors incurred by inferring synthetic temperature and salinity using the default 30 km decorrelation length scale super observations fig 9e f of steric height anomalies between january and march 2016 are shown in fig 10 error in the observed steric height anomalies were taken into account when the isop synthetics were created thus the isop errors shown in fig 10 are a function of both measurment error and fitting imperfect temperature and salinity profiles for both temperature fig 10a and salinity fig 10b the comparison between nature and isop synthetic data fall primarily along the 1 1 line temperature statistics show that isop synthetic profiles have a mae of 0 63 c and an error standard deviation of approximately 1 c fig 10c isop synthetic salinity profiles have a mae of 0 06 psu and an error standard deviation of 0 08 psu fig 10d these errors are consistent with prior validation comparing isop derived synthetic temperature and salinity with in situ observations helber et al 2013 the non gaussian distribution of both temperature and salinity errors is an undesirable result but further investigation of this issue is outside the scope of this work 3 results table 1 provides a brief summary of each of the different experiments conducted differentiated by the types of data incorporated into the daily analysis cycle four osse experiments were performed and evaluated the free run altim swot and altim swot all four osses started with the same initial condition on december 1 2015 by using the state from nature on december 1 2016 all experiments were integrated forward without assimilation to january 1 2016 starting january 1 2016 cycling assimilation was performed every 24 h with the exception of the free run which did not assimilate any information the altim run assimilated sst in situ profiles and traditional nadir altimetry the swot experiment is similar to altim except that it assimilated swot data instead of nadir altimetry data finally altim swot assimilated all possible observation types used in this study the assimilative osses altim swot and altim swot used the default mean decorrelation length scale of 30 km for the initial set of results shown in sections 3 1 and 3 2 each osse was integrated forward until march 31 2016 and then evaluated relative to nature error statistics were computed for three variables ssh mld and 100 m temperature ssh defines the surface pressure field and is a depth integrated quantity approximating the underlying baroclinic structure that is primarily controlled by mesoscale processes but is also influenced by smaller scale variability such as balanced submesoscales and internal gravity waves mld is a complicated variable that is a function of both large scale forcing and local frontogenesis model skill with respect to this variable is essential for accurately representing oceanic variability and air sea exchange finally 100 m temperature provides an estimate of internal ocean variability the maximum mean depth of the mixed layer in this region is 100 m fig 3 which allows the use of 100 m temperature to quantify model skill with respect to thermocline variability deeper variables e g 1000 m temperature could also be considered however balanced submesoscales are primarily confined within the mixed layer and upper thermocline bachman et al 2017 and therefore any deep water analysis would feature only mesoscale and internal gravity wave variability using these surface and near surface variables allows us to focus on the widest continuum of ocean physics present in this modeling framework the comparison of results begins with area averaged errors to gain a broad view of model skill and then the evaluation focuses on wavenumber spectra to determine constrained spatial scales 3 1 area averaged errors 30 km decorrelation length scale fig 11 shows mae between nature and each osse for 100 m temperature ssh and mld the mae includes information at a location only if the water depth is at least 1000 m the free run errors are consistently higher than any of the assimilative experiments for all three variables tested as the assimilation process begins on january 1 a sharp decrease in errors is observed for both 100 m temperature and ssh the initial rate of error decrease correlates with the quantity of observations used in the assimilation process in the ssh mae the altim swot errors decrease most rapidly followed by the swot experiment because ssh is a direct observation this provides verification that the quantity of data is constraining the system more rapidly by january 11 the altim experiment error levels are roughly equivalent to those of the swot and altim swot experiments all three assimilative experiment error levels then oscillate around a mae of 0 65 c for 100 m temperature and 5 cm for ssh with respect to mld the assimilative experiment errors are generally lower compared to the free run but the difference between the free run and the assimilative run mae is smaller than the other variables 3 2 wavenumber spectra 30 km decorrelation length scale the bulk statistics do not finely differentiate the observation system impacts the spectra of ocean variables tend to be red and it is not possible to determine if smaller scales are more accurately represented by the area averaged errors therefore we quantify the wavelengths that are constrained within the osses through wavenumber spectral analysis two dimensional power spectral density psd was calculated for each 3 hour time step in the square subdomain shown in fig 1b the time series of two dimensional psd was then averaged into a single two dimensional field in kx ky wavenumber space the time averaged psd was then averaged radially to produce a one dimensional spectrum the time and space averaged 100 m temperature ssh and mld nature spectra for 2016 are shown in fig 12 all three variables have an unbroken cascade of psd from the largest observed scale 640 km down to the nyquist wavelength 2 km each variable has a different spectral slope between the 200 km and 10 km wavelength range ssh produces the steepest slope followed by 100 m temperature and then mld these slopes are consistent with previous studies that examined the same variables at comparable model resolutions capet et al 2008 richman et al 2012 spatial gradients accentuate small scale variability temperature is heavily influenced by horizontal stirring caused by mesoscale and submesoscale velocities the horizontal gradient of ssh being a reasonable approximation of the velocity vector therefore 100 m temperature psd has a flatter slope as much of its spatial variability is tied to intermediate to small scale horizontal motions mld is driven by mesoscale and submesoscale processes controlling stratification stirring and frontogenesis the latter being responsible for convergence divergence along eddy fronts the frontal processes are a derivative quantify of the horizontal velocity and buoyancy fields mld is therefore characterized by even greater small scale variability and subsequently has a flatter slope than both ssh and 100 m temperature these dynamics will be important considerations later when discussing the ramifications of 3dvar data assimilation in this high resolution modeling environment the spectra of many other oceanic variables could be analyzed as well for example kinetic energy an important metric could be analyzed but due to the nature of our assimilation method of fitting temperature and salinity synthetics velocity is indirectly altered by corrections in surface and subsurface pressure i e through geostrophic correlations therefore any error trends in the pressure field will simply be extrapolated onto the resulting velocity in the subsurface temperature and salinity primarily act as passive tracers and therefore have similar spectral slopes not shown for these reasons redundancy in the results is reduced by focusing on 100 m temperature ssh and mld which are each controlled by a unique set of physical processes conceptually we separate the wavenumber space into two domains larger scales small wavenumbers that are constrained by the available observations and smaller scales larger wavenumbers which are unconstrained an appropriate assimilation should place constrained osse features in locations and times that are similar to those in nature the spatial scales constrained by each osse may be determined more clearly by differencing fields of each osse from nature which provides the error in the osse the amplitude of the errors in the constrained features should be reduced below the amplitude of the features and the spectral energy should also be removed from the constrained scales in the psd of the errors at small scales unconstrained features in the osse experiments will not be at the same locations and times as in nature the result is that amplitudes of errors at unconstrained scales become greater than the amplitude of the features and spectral energy is increased in the unconstrained scales of the psd of the errors we can observe this effect most clearly by normalizing the error spectrum 1 ε osse γ nature γ osse where ε osse is the psd of the error nature minus osse γ nature is the psd of nature γ osse is the psd of the osse and brackets denote the mean of the two spectra this normalization creates a convenient metric for measuring the error of each experiment as a function of spatial scales at a particular wavenumber if the normalized value is zero nature and the respective experiment share exactly the same features in that spatial scale if features are completely unconstrained osse and nature features are uncorrelated random variables and the psd of the error is the sum of the psd of the osse and nature thus a normalized psd value of 2 0 implies that the assimilation has not impacted features at that particular spatial scale a normalized psd value of 1 0 indicates that the correlation between the osse and nature is 0 5 and we define this value as the separation point between constrained and unconstrained spatial scales the spectral analyses were derived for the four osse experiments during the month of february n 232 time steps the results contain several trends fig 13 the free run performs the worst with respect to all three variables 100 m temperature ssh and mld with a normalized psd below one at only the largest of spatial scales for 100 m temperature the altim experiment produces the next highest errors fig 13a both swot assimilating experiments have lower errors and cross the normalized psd threshold of 1 0 at lower wavelengths than the other osse experiments we quantify the performance of each osse by evaluating the ratios of integrated spectra 2 k min k nyquist ε osse dk k min k nyquist γ nature γ osse dk where k denotes wavenumbers kmin is the minimum resolved wavenumber 1 640 km 1 and knyquist is the nyquist wavenumber 1 2 km 1 as the assimilation more accurately accounts for more of the features in nature this value should trend towards zero table 2 provides a summary of the ratios and is consistent with the prior analysis for 100 m temperature experiments that assimilated simulated swot observations contain less error than both the free run and altim experiments with the swot experiment producing the smallest value which is a 23 decrease in error over the altim experiment analyses of ssh results in similar conclusions visual inspection shows that both experiments using the simulated swot observations outperform the free run and altim experiments fig 13b ssh ratios of integrated spectra per eq 2 demonstrate that the swot experiment again performs best with a 19 decrease in error over the altim experiment table 2 finally the same analyses are performed for mld this variable is the least constrained of the three tested with the altim swot and altim swot producing similar normalized spectra fig 13c the ratio of integrated spectra shows that the reduction in error in the two swot experiments is only 2 when compared to the result from the altim experiment table 2 finally the smallest wavelength at which the normalized spectra cross the 1 0 threshold is determined for each osse and for each variable fig 14 for 100 m temperature fig 14a the altim experiment constrains wavelengths down to 161 km a 28 km improvement over the free run the swot experiment constrains wavelengths down to 145 km and the altim swot experiment down to 130 km this result shows that the experiment using both current nadir altimetry and simulated swot observations constrains an additional 31 km over the experiment utilizing only nadir altimetry this is significant as it approaches the deformation radius for this geographical region 50 km chelton et al 1998 again the analysis of ssh produces similar results fig 14b the altim swot experiment produces the lowest minimum constrained wavelength of 139 km a value slightly higher than that produced when analyzing 100 m temperature mld produces the largest minimum constrained wavelength of 323 km fig 14c in each case the osses that include simulated swot observations produce the smallest minimum constrained wavelength therefore the results indicate that including swot observations in a highly realistic cycling forecast analysis system does produce an advancement in forecast skill 3 3 area averaged errors and wavenumber spectra 15 km decorrelation length scale gaultier et al 2016 and ubelmann et al 2015 found that two dimensional fields of swot ssh constructed using optimal and dynamic interpolation respectively can resolve scales of 100 km and less these interpolation schemes are difficult to compare to the combined variational assimilation primitive equation forecasting performed here the approach we use relies on dynamic extrapolation into the future from an initial condition the interpolation schemes however benefit from a set of observations prior and posterior to the mapping time regardless swot observations clearly contain information on scales smaller than those shown to be constrained by the analysis forecast system in our first set of experiments fig 14 this prompts a second set of experiments in which the assimilation settings were altered in an attempt to further utilize the high density swot observations in our experiments the horizontal resolution of the forward model is 1 km and the model can therefore represent scales smaller than the regional rossby radius of deformation 50 km chelton et al 1998 in addition the swot observations resolve much smaller scales in two dimensions than the nadir altimeters this transition to both higher resolution models and observations motivates that the long held mesoscale assumptions built into the current analysis forecast systems be challenged e g the decorrelation length scale as a function of the deformation radius in this section the swot and altim swot experiments were repeated with a mean analysis decorrelation length scale of 15 km the effects of changing the decorrelation length scale on thinning show more of the data are retained within the analysis fig 9c d the less severely thinned data were used to obtain different isop temperature and salinity synthetics over a larger set of geographic locations this should ultimately bias the analysis towards the smaller scale features present in the high density swot data and potentially allow the system to constrain a larger set of wavelengths area averaged errors and wavenumber spectra were recalculated for the updated analysis forecast fields to quantify improvement in skill the altim experiment was not altered and therefore serves as a useful reference between the previous results using a larger analysis decorrelation length scale 30 km and those shown in this section using a shorter analysis decorrelation length scale 15 km compared with the experiments run with the larger 30 km decorrelation length scale we observe a slight increase in area averaged errors for 100 m temperature and ssh and a decrease in errors for mld fig 15 wavenumber spectral analysis again provides a finer differentiation between the osses fig 16 in comparison to the experiments using the larger decorrelation length scale visual inspection suggests little difference or a slight decrease in skill for 100 m temperature and ssh and an increase in skill with respect to mld this observation is quantified by the ratio of integrated spectra table 2 for 100 m temperature the ratios are similar between the experiments run with a larger or shorter decorrelation length scale for ssh a slight decrease in skill is noted for the swot experiment run with the shorter decorrelation length scale but a substantial decrease in skill occurs for the altim swot experiment as observed in the area averaged errors the experiments utilizing the shorter decorrelation length scale also produced greater skill in wavenumber space with respect to mld finally these observations are mirrored in the estimations of the minimum constrained wavelengths fig 14 the minimum constrained wavelength for 100 m temperature is slightly lower for the swot experiment and slightly higher for the altim swot experiment when rerun with the shorter decorrelation length scale for ssh both experiments using the shorter decorrelation length scale produce a larger minimum constrained wavelength when compared to the same experiments run with the larger decorrelation length scale for mld the experiments using the shorter decorrelation length scale produces a minimum constrained wavelength up to 87 km smaller than the same experiments run with a larger decorrelation length scale overall we observe that decreasing the decorrelation length scale reduces skill with respect to 100 m temperature and ssh while increasing skill for mld substantially the apparent dichotomy of these results is explored in section 4 4 discussion reducing the analysis decorrelation length scale in an attempt to further utilize the small scale information within the high density swot observations resulted in conflicting results a reduction of skill occurs for 100 m temperature and ssh while an increase in skill occurs for mld fig 12 demonstrates that 100 m temperature and ssh have steeper spectral slopes and therefore a relatively higher concentration of energy at larger wavelengths mld however has a flatter slope and therefore a relatively higher concentration of energy at smaller wavelengths the results demonstrated in section 3 3 therefore suggest that reducing the decorrelation length scale preferentially sets small scale features at the expense of the large scale phenomena the reverse is true when using a relatively large analysis decorrelation length scale this situation has been addressed by implementing a multi scale assimilation process for 3dvar muscarella et al 2014 li et al 2015a 2015b miyazawa et al 2017 these multi scale systems use a two step assimilation method whereby large scale information from observations are fit to the background using a larger decorrelation length scale in the first pass this analysis is then used as the background in the second step in which small scale information is assimilated using a smaller decorrelation length scale this allows the analysis to compute a correction to both the large scale and small scale without compromising skill in one or the other the initial results reported here indicate an advancement in skill when using swot observations and are consistent with the expected effects of a single scale analysis examination of results derived using swot observations in a 3dvar multi scale analysis system would be an appropriate next step this work should include investigations into the optimal decorrelation length scales used in each of the analysis steps our results suggest that larger intermediary and smaller decorrelation length scales affect ocean variables differently and some balance may be required depending on the needs of the user additionally more than two assimilation steps might be considered so that no compromise is necessary the drawback would be the additional computation cost of running the extra analyses the selection of the observation window may also be critical here a 5 day window for the nadir altimetry and swot observations was used but both longer and shorter windows have merit a longer window may allow a much more accurate representation of the mesoscale field especially when considering the relatively long 21 day repeat period swot will have this long window however will severely misfit small scale features that generally have shorter time scales and will no longer be at their previously observed location at the analysis time a shorter time window would mitigate this issue but would then generate an inferior representation of the mesoscale field finally mesoscale and submesoscale physics are fundamentally different mcwilliams 2016 the two step assimilation should also alter the dynamical balances applied to the analysis increments to account for the physics of the features that each analysis step is trying to optimally fit a more sophisticated assimilation system could also be used such as the 4dvar by inserting observations along a time evolving trajectory the action of the adjoint and tangent linear model dynamically spreads high resolution information along all available wavelengths in this framework a longer observation window is always advantageous but comes with a much greater computational cost the 4dvar however still uses an error covariance that is based on a preset decorrelation length scale that will generate an analysis increment that is too smooth to effectively constrain small scale features for this reason there is ongoing work to generate multi scale 4dvar solutions as well which also set each scale independently by partitioning observations and decorrelation length scales carrier et al 2018 finally the topic of scale separation has also been approached using ensemble variational data assimilation schemes buehner and shlyaeva 2015 these considerations should be a continued area of focus to extend the influence of high density observations such as those from swot 5 summary and conclusions a set of osses tested the utility of forthcoming swot data in a realistic submesoscale resolving ocean assimilation and forecasting system the usefulness of this new data type was first evaluated by calculating regional errors with respect to nature from january 1 to march 31 2016 experiments including simulated swot data converged towards nature at a faster rate area averaged errors indicated experiments with and without swot observations reached a similar error level after approximately 11 days a finer differentiation of the osses was obtained using wavenumber spectral analysis of differences between each experiment and nature the osses utilizing the simulated swot observations consistently produced lower error in wavenumber space when compared to the experiment that assimilated only nadir altimetry data with respect to 100 m temperature the minimum constrained wavelength was found to be 161 km for the experiment using only nadir altimetry as opposed to 130 km for the experiment utilizing both nadir altimetry and swot observations this 31 km improvement in skill is substantial and suggests that operational ocean analysis forecast systems can expect notable increases in predictive skill when swot data become available the smallest constrained wavelength found for all tested variables and all osse experiments 130 km is greater than the regional rossby radius of deformation 50 km which serves as an estimate of scale separation between mesoscales and submesoscales it was hypothesized that it may be necessary to reduce the analysis decorrelation length scale in order to fully utilize the high density swot observations a degradation of skill was noted for 100 m temperature and ssh for the swot experiments using this reduced decorrelation length scale an increase in skill for mld was observed for the same experiments based off derived spectral slopes ssh and 100 m temperature feature a relatively higher concentrations of psd at longer wavelengths than mld this lead us to conclude that reducing the decorrelation length scale improved analysis forecast skill for variables that feature more small scale variability at the expense of variables that feature more large scale variability the reverse was shown to be true when using a relatively large decorrelation length scale these findings further highlight the need for multi scale assimilation solutions when utilizing a suite of observations which include both large scale and small scale information we have shown that swot observations will improve ocean analysis forecast skill to a substantial degree when they become available to fully constrain all the wavelengths that swot can observe multi scale assimilation solutions will need to be implemented work is currently underway to build this functionality into the analysis forecast system used in this study with the intent of fully constraining the mesoscale field while also beginning to generate predictive skill into the submesoscale regime acknowledgements joseph m d addezio is supported by the naval research laboratory cooperative agreement baa n00173 03 73 13 01 awarded to the university of southern mississippi this research is funded by the naval research laboratory base program submesoscale prediction of eddies by altimeter retrieval spear the authors appreciate constructive comments provided by the anonymous reviews and the editor which improved the manuscript the authors thank prasad g thoppil for helping process the surface drifter observations the authors are also grateful to numerous nrl colleagues for instructive discussions had throughout experimentation 
24051,using a suite of observing system simulation experiments osses the utility of simulated surface water ocean topography swot observations is estimated in a high resolution 1 km ocean analysis forecasting system sampling a nature run provides observations for the osses and the realism of the nature run is established by comparison to climatological data and an independent ocean analysis forecast system each osse experiment assimilated different sets of simulated observations including traditional nadir altimeters satellite sea surface temperature sst in situ profile data and swot osse evaluation metrics include area averaged errors and wavenumber spectra with the latter providing much finer differentiation between experiments 100 m temperature sea surface height ssh and mixed layer depth mld errors across the observed wavenumber spectra were reduced by up to 20 for osses assimilating the simulated swot observations the minimum constrained wavelength was found to be 130 km when both nadir altimetry and swot observations were used the experiment using only nadir altimetry produced a value of 161 km this 31 km gain in skill of predictable scales suggests that ocean forecasts can expect substantial gains in capability when utilizing the forthcoming swot data experimentation with the analysis decorrelation length scale suggests that emerging multi scale assimilation methodologies will provide additional advancements in predictive skill keywords osse swot altimeter 3dvar mesoscale submesoscale 1 introduction numerous studies have documented the utility of altimetric observations of the ocean surface in generating mesoscale predictive skill e g smedstad et al 2003 ananda et al 2006 jacobs et al 2014a le traon et al 2015 however the current suite of nadir looking altimeters produces an ocean surface representation that is limited by spatial and temporal sampling since jason 2 at least two altimeter sensors have been in orbit at any one time with their merged observations producing two dimensional grids of sea surface height ssh that can resolve wavelengths of approximately 150 km and greater ducet et al 2000 fu and ubelmann 2014 these estimates are significantly coarser than the features present ocean prediction systems can resolve this observational deficit may soon be alleviated with the launch of the surface water ocean topography swot satellite mission in 2021 fu and ubelmann 2014 the sensor is expected to collect along and across track ssh observations at very high resolutions 1 km allowing oceanographers to study previously under observed phenomena on a global scale this observational capability poses important questions to the ocean prediction community what increases in forecast skill can be expected by assimilating these data into a high resolution ocean analysis forecasting system will the swot observations allow the assimilation system to constrain spatial scales below that which is currently achievable using a constellation of nadir altimeters the objective of this study is to determine how swot observations can change ocean predictability when compared to results derived using only currently operating nadir altimetry a number of studies have tested the usefulness of simulated swot observations for more narrowly focused hydrological and hydrographic modeling andreadis et al 2007 durand et al 2008 biancamaria et al 2010 yoon et al 2012 pedinotti et al 2014 munier et al 2015 oubanas et al 2018a 2018b carrier et al 2016 showed that within a regional ocean 4dvar data assimilation framework simulated swot observations significantly improved analysis forecast skill with respect to both the placement of mesoscale features and surface velocities the work presented here extends the resolution of the model system from 6 km to 1 km and quantifies the bulk error magnitudes and resolved spatial scales this is a critical expansion of experimentation as a horizontal model resolution of 1 km allows the simulation to explicitly resolve submesoscale processes with wavelengths o 10 km capet et al 2008 these small scale dynamics are important to accurately represent and predict in numerical models because they have strong impact on near surface dynamics mcwilliams 2016 net ocean atmosphere heat fluxes su et al 2018 and biogeochemical processes levy et al 2012 the current set of satellite altimeters cannot observe submesoscale features and therefore regional models that explicitly resolve submesoscales are unable to constrain the placement and evolution of the phenomenon swot will provide an important path forward towards bridging this gap between model resolution and observational capabilities this requires testing to quantify the range of wavelengths the swot observations will allow the assimilation system to constrain ocean forecasting systems have been designed for mesoscale prediction cummings et al 2009 and it is unclear if mesoscale assumptions translate to submesoscale predictive skill even when utilizing high resolution data streams that explicitly resolve the phenomenon the material is organized by first describing the construction of an observing system simulation experiment osse e g halliwell et al 2014 in section 2 a simulated truth hereafter called nature was generated using a submesoscale resolving non assimilative model run nature was sampled at real observation locations and times for remotely sensed sea surface temperature sst in situ profiles and satellite altimetry swot sampling was derived using the swot simulator osses deviate from nature through initial condition perturbation different sets of simulated observations were assimilated into each osse experiment the errors in the osses are evaluated in section 3 by comparison of area averaged statistics and by wavenumber spectra of errors section 4 considers the potential usefulness of emerging data assimilation techniques based on results derived by adjusting the analysis decorrelation length scale in an attempt to further utilize the small scale variability observed by swot in section 3 2 methods ascertaining the utility of a remote sensing platform that is not currently producing data requires the construction of a controlled laboratory environment in which simulated data consistent with expected sampling can be tested this section documents the methodology of the experiments the numerical ocean model configuration used by nature and each of the osse experiments section 2 1 nature spin up and validation section 2 2 setup of the osses section 2 3 and the data assimilation methodology section 2 4 2 1 model system setup the navy coastal ocean model ncom barron et al 2006 provided simulated three dimensional ocean fields and we applied the system within the western pacific ocean fig 1a a region that contains a strong western boundary current extensive continental shelves deep ocean basins strong seasonal surface mixed layer variability strong mesoscale features in the deep ocean submesoscale processes and interactions between all of these ncom integrates the primitive equations forward in time using the hydrostatic and boussinesq approximations it features a hybrid σ z vertical grid allowing for higher vertical resolution in the near surface environment as well as terrain following capabilities in the coastal ocean a standard z vertical grid is used at deeper layers and the transition from z to upper layer sigma coordinates is a user input for experiments here 50 vertical layers were used to a maximum depth of 4000 m with the σ z transition occurring at layer 25 corresponding to a depth of 120 m at rest the surface sigma layer at its thickest is about 1 m and layer thicknesses progressively increase with increasing depth in the horizontal the model resolution was set to 1 km allowing ncom to produce ocean features with wavelengths down to o 10 km which is a minimal resolution for representing submesoscale processes capet et al 2008 using a model grid that can explicitly resolve submesoscale features provides the ability to conduct an important hypothesis test can assimilating simulated swot observations into the high resolution system constrain features at submesoscale wavelengths using a model grid any coarser than that chosen would preclude the rejection or acceptance of any such hypothesis lateral ocean boundary conditions were provided by a double one way nesting procedure first boundary conditions from the operational global 1 12 hybrid coordinate ocean model hycom were provided to the larger nest 113 e 136 e 15 n 38 n fig 1a a regional ncom simulation with a horizontal resolution of 3 km boundary conditions were generated from the 3 km simulation and provided to the 1 km nest 116 e 133 e 18 n 34 n fig 1b this approach was taken to mitigate numerical instabilities that can arise from interpolating boundary conditions from a model at least 3 times coarser than the nested simulation atmospheric forcing was provided by the navy global environmental model navgem hogan et al 2014 the forcing derived from this model has a horizontal resolution of 37 km and a frequency of 3 h surface wind stress and precipitation were extracted directly from the navgem output latent and sensible heat flux were computed by coupled ocean atmosphere response experiment coare version 3 0 fairall et al 2003 solar radiation provided by navgem was absorbed through the water column using a jerlov water type ii jerlov 1976 river in flow was introduced at fixed points approximating the geographic location of large river mouths using the ncom river database barron and smedstad 2002 the final 1 km nest included tidal forcing from the global oregon tidal inverse solution otis egbert and erofeeva 2002 the tidal forcing was not included in global hycom or the 3 km outer nest any analyses featuring either ssh or velocity have had the barotropic tidal signal removed from each variable through a post processing procedure nonetheless this harmonic analysis will inevitably miss incoherent baroclinic tides that have non tidal frequencies this phenomenon is present in temperature and salinity below the mixed layer ssh as well as surface and subsurface velocities and will therefore be included in our error analyses this problem deserves attention as these waves are expected to containment balanced mesoscale and submesoscale swot observations chavanne et al 2010 but the subject is outside the scope of this study in all we endeavored to produce a highly realistic system that includes short time and small spatial scale variability representative of the physical ocean and will therefore be present in the swot observations 2 2 nature setup and validation this section describes nature and a validation of nature statistics in comparison with climatological observations of the real ocean and an independent assimilative ocean forecasting system the 3 km ncom nest was initialized on november 1 2015 and spun up until the end of the month the 3 km december 1 2015 forecast was then interpolated onto the final 1 km grid and used as the initial condition for nature nature was then spun up for the entirety of december 2015 to ensure that both mesoscale and submesoscale features had sufficient time to properly develop the simulation was then integrated forward for an entire year with the complete time period being january 1 2016 to december 31 2016 no data assimilation was applied to nature the completely unconstrained nature of this simulation could introduce problems in the osse whereby the statistics of nature deviate so far from the real ocean that conclusions gleaned from the experiment may not be applicable to the physical world for this reason it is common practice to validate the nature simulation to ensure that it is sufficiently realistic atlas 1997 the purpose of this procedure is not to test the error of the solution in terms of how it exactly compares with the real ocean at equivalent times at any given time step nature will be quite different from the real ocean instead we are testing to determine if nature statistics are consistent with the statistics of the real ocean to begin surface temperature mixed layer and thermocline means are analyzed qualitatively the mean nature sst compares favorably with both the observation based generalized digital environmental model version 4 gdem4 teague et al 1990 carnes et al 2010 sst climatology and the assimilative hycom 2016 annual sst mean fig 2 all three means have similar magnitude and comparable locations of large scale fronts such as the kuroshio western boundary current that meets the coastal waters along the continental shelf by taking the area averaged value at each time step of each dataset the seasonal cycle of nature can be validated fig 2d both nature and hycom deviate from the area averaged gdem4 climatology within each month with the model deviations from climatology being similar the seasonal cycle amplitude is consistent between the models and climatology the higher frequency events in the model time series are similar and are responses to atmospheric events using a 0 2 c temperature criteria to derive mixed layer depth mld produces a similar mean spatial distribution from all three of the examined datasets fig 3 in the deep ocean gdem4 has slightly shallower mld than both nature and hycom nature produces the shallow mld along the kuroshio pathway evident in the gdem4 data much better than hycom across the annual cycle nature and hycom track the gdem4 climatology closely although mixed layers are generally deeper in both simulations between january and the end of march fig 3d below the deepest regional mean mld 90 m fig 3d 100 m temperature provides a representation of the mean thermocline structure fig 4 the location of the kuroshio front is in good agreement between the three datasets and deep ocean magnitudes are highly comparable through time the nature spatial mean shows deviations from both gdem4 and hycom on the order of approximately 1 c between february and november fig 4d the seasonal cycle of three datasets however are in good agreement in all these analyses suggest that nature sst mld and 100 m temperature means have similar magnitudes spatial distributions and seasonal cycles to that of the climatology of the real ocean next nature energy is evaluated the mean surface eddy kinetic energy eke from nature compares favorably with drifter observations and assimilative hycom fig 5 all drifter data collected between 1983 and 2009 were binned into 1 1 grid boxes only grid points with at least 100 drifter observations were considered in the temporal mean thoppil et al 2011 the spatial distribution of mean eke is similar in all three datasets but nature magnitudes are more similar to that of the observations than hycom this is most likely due to model differences in horizontal resolution prior experiments have shown that a model horizontal resolution of at least 3 km is required to completely represent mesoscale dynamics e g hogan and hurlburt 2000 spatially the three datasets are highly consistent with higher eke in the deep ocean and along the pathway of the kuroshio western boundary current as well as lower eke north of the current along the wide continental shelf strong eke seasonality is not observed and despite differences in magnitude the two time series have strong correlation through time fig 5d 2016 annual nature ssh root mean square rms is evaluated against nadir altimetry observations and assimilative hycom over the same time period fig 6 all three datasets feature comparable magnitudes the points of maximum rms in each dataset are located primarily along the pathway of the kuroshio and to the east of the boundary current south of approximately 20 n rms values are lower in each overall hycom compares most favorably with the observations in terms of feature location as it assimilated the altimeter data throughout 2016 the non assimilative nature does not produce local maxima in exactly the same locations as observed but the overall magnitude and general spatial pattern is consistent with the observations finally annual subsurface temperature standard deviation along 21 n is examined fig 7 all three datasets produce depth maximum temperature standard deviation within the top 150 m lower amplitude thermocline variability is present below this level and the 1 c standard deviation contour extends down to approximately 500 m in nature and gdem4 the same contour in hycom is shallower with a maximum depth of approximately 250 m in all the nature temperature depth variance structure is more comparable with the climatological data than hycom overall nature statistics are in good agreement with observations and an assimilative ocean model with this confirmation nature was used as a reasonable approximation of the real ocean and sampled to provide simulated observations to the osse experiments the nature sampling osse configuration and data assimilation methodology are described in the remainder of section 2 2 3 osse experiments if the same model horizontal resolution initial condition boundary conditions and surface forcing were used to generate the osse experiments an exact replica of nature would be created formally osses should utilize a completely different model run at a coarser resolution to represent errors in model physics and resolution limitations atlas 1997 the approach taken in this study however is to use the same dynamical model and resolution and a realistically different initial condition for the osses the hypothesis is that the new initial condition is sufficiently different and that the processes inside the 1 km numerical simulation are non deterministic so the nature and osse simulations are realistically different from one another over the experiment time period there are many examples of successful experiments using this methodology e g jacobs et al 2014a li et al 2015a carrier et al 2016 ultimately the study makes the strong hypothesis of a perfect model whereby having a perfect set of observations at all model grid points would provide the perfect forecast this removes an independent variable from the osse error analysis i e model error and allows us to focus on the impact of the different observation types for the experiments presented here the osse initial condition was perturbed by offsetting the initial condition by one year the nature state on december 1 2016 was used as the initial condition of the osses starting december 1 2015 the validity of the initial condition perturbation approach was tested by generating a parallel non assimilative experiment using this new initial condition called the free run the free run was spun up for the entirety of december 2015 beginning with the altered initial condition and then run out for all of 2016 which is the same time frame as nature the free run was then compared with nature during 2016 to demonstrate that the two solutions do indeed differ due to non deterministic processes fig 8 shows mean absolute error mae between nature and the free run every 3 h for ssh surface speed and mld at all grid points within the simulation domain with water depth of at least 1000 m shelf dynamics are largely deterministic so we focus on deep water variability where mesoscale and submesoscale nonlinearities should cause the two simulations to differ substantially over time ssh errors oscillate around a rms of 9 cm with a minimum of 5 5 cm and maximum of 12 cm fig 8a for reference the rms of nature ssh anomalies for all of 2016 was calculated and found to be 13 cm this suggests that free run ssh errors with respect to nature are on average more than half of the signal surface speed mae features less variability around a rms of 20 cm s 1 fig 8b the rms of nature speed anomalies are found to be 25 cm s 1 which is very close to the free run error amplitude initially mld mae is large 30 m but then a sharp decline in error is observed starting in march fig 8c this is not due to the free run dramatically converging towards nature but instead due to seasonal variations in the mixed layer boreal winter is characterized by deep mixed layers and therefore larger errors across the domain as the region transitions towards boreal spring and summer stratification increases in the near surface due to increased solar radiation and mld becomes shallower this causes a natural reduction of error until december when the transition towards boreal winter causes mixed layers to deepen again the rms of nature mld anomalies was found to be 17 8 m and free run error rms was found to be 32 7 m the analyses performed demonstrate that the use of a perturbed initial condition for the free run causes it to differ from nature throughout the 2016 forward integration period with expected magnitudes thus error reduction in the assimilative runs is attributed to assimilation and not a steady decline in error due to the identical numerical model used in all runs with confidence that the methodology outlined above does produce a different solution the next step was to sample nature to generate simulated observations for observational datasets currently in operation sst in situ and altimetry nature was sampled at real observation locations and times throughout 2016 simulated sst and in situ observations were assumed to be without error i e no noise was added to the sampled observations errors were not added to these data because the impact of the altimetry data is desired nature was sampled at jason 2 altika and cryosat 2 mission observation locations and times and error was added to the simulated observations based on a random gaussian distribution with a standard deviation of 3 cm to generate simulated swot observations we employed the jet propulsion laboratory s jpl swot simulator gaultier et al 2016 version 2 0 0 of the simulator was used to sample nature on a 2 km grid in both along and across track directions nature was output in netcdf format in 3 hourly time intervals the swot simulator interpolated the model fields in space and time to obtain the simulated observations on the swot grid along the 21 day repeat tracks the simulator includes functionality to add random realizations of simulated error to the swot observations based on an estimated swot error spectrum these errors include karin noise roll error phase error timing error baseline error and wet troposphere error gaultier et al 2016 these simulated errors are known to currently be conservative i e expecting worst case errors especially for errors with long wavelengths i e roll phase and baseline errors ubelmann et al 2018 https spark adobe com page okwkaikjwvm0e 5000 random realizations of simulated swot errors using version 2 0 0 of the swot simulator were generated and found to have an error standard deviation of 6 5 cm not shown a proposed solution is to reduce the magnitude of these strongly correlated errors by performing crossover calibration ubelmann et al 2018 with such large simulated errors and with ongoing work being performed to optimize the simulator we chose to apply the same random gaussian errors that were applied to the simulated nadir altimetry data to the simulated swot observations therefore this experiment quantifies differences in analysis forecast skill due only to differences between altimetry and swot sampling with a prescribed white noise level i e resolution swath width and sampling frequency 2 4 data assimilation a 3dvar data assimilation was used in the experiments in a manner similar to that used in the operational global hycom system while the more advanced 4dvar scheme is becoming more widely used in oceanography particularly in regional nests e g ngodock and carrier 2014 the 3dvar provides a lower computational cost to enable us to perform the multiple experiments run at such high resolutions 4dvar systems are expected to provide greater skill and the magnitude of this increased skill remains an important research problem for the future the navy coupled ocean data assimilation ncoda system cummings 2005 was used for these experiments vertical correlations of temperature salinity geopotential and velocity were provided by the improved synthetic ocean profile isop helber et al 2013 the isop system is described more fully in the following paragraph data assimilation was performed daily at 00z using the previous 24 h forecast as the background to be updated available in situ altimetric and sst observations 12 days 5 days and 12 h prior were collected for the analysis respectively the temporal and spatial scarcity of the in situ observations e g argo http www argo ucsd edu dictate the longer window when compared to the other observation types conversely the short 12 hour window used for sst is due to the relative ubiquity of these observations using a 5 day observation window for the altimetric observations might be too short to properly represent the mesoscale field and too long to correctly fit transient submesoscale features this choice is a compromise based off prior results that tested different sets of observation windows jacobs et al 2014b section 4 elaborates on how future work might search for an optimal window to accommodate the different time scales of the mesoscale and submesoscale phenomena the 12 day and 5 day windows cause individual observations to be assimilated on successive days a practice that violates optimal estimation theory using observations repeatedly however improves assimilation performance and is a technique employed by a number of different global ocean data assimilation experiment godae systems martin et al 2007 cummings et al 2009 jacobs et al 2014a 2014b innovations or the difference between the background and observations were derived using the first guess at appropriate time fgat method and used to minimize the cost function to achieve an optimal increment cummings 2005 a 6 h hindcast was performed to incrementally insert the analysis correction the increment was divided by the total number of time steps in the 6 hour hindcast prior to the 00z time of the analysis and the divided increment was added to the model tendency at each time step inserting the entire increment directly into the full background at 00z can generate spurious gravity waves and inertial oscillations that take time for the forward solution to damp out the incremental insertion method attempts to mitigate the development of such motions and therefore provide an initial state with lower energy in these extraneous features nonetheless we did observe analysis steps that still featured these transient features not shown which suggests some potential influence on our error analysis finally background error variances are a function of the state variable geographic position and depth and are based on the gdem4 climatology the background error variances are not scaled by the decorrelation length scale that is discussed in section 2 4 1 sst and in situ observations were used directly to generate innovations nadir altimetry and swot observations were treated in a different manner using isop altimetric observations were converted into subsurface temperature and salinity anomalies using a one dimensional variational analysis employing vertical correlations based on a relatively coarse set of in situ observations of mesoscale processes climatological temperature and salinity provide additional constraint and allow for full temperature and salinity profiles the isop climatological temperature and salinity were derived from in situ observations collected by the navy s master oceanographic observation data set moods world ocean database wod 2005 and delayed mode argo helber et al 2013 the synthetic temperature and salinity were then used to generate innovations and ultimately increments the most important isop variational constraint is to steric height anomaly not ssh anomaly generally ssh and steric height are strongly correlated but many processes cause discrepancies e g wind driven high frequency barotropic flows because our experiments were conducted in a controlled environment we optimized the process by sampling nature steric height anomalies instead of ssh anomalies nature steric height referenced to 1000 m was calculated and the gdem4 mean steric height field was removed to generate anomalies 2 4 1 analysis decorrelation length scale and super observations an important element of the 3dvar assimilation procedure is the analysis decorrelation length scale i e decorrelation length scale of the background error the parameter controls the length scale over which analysis increments are spread a few factors motivate the magnitude of the decorrelation length scale a numerical grid represents physical features that are approximately 10 grid points in size hence the system should not attempt to correct features that the model cannot reasonably represent and this dictates a lower bound on the scale additionally the assimilation system should correct features that are believed to be the primary error sources historically these have been mesoscale eddies cummings et al 2009 the rossby radius of deformation describes the length scale for which planetary vorticity is primarily balanced by pressure i e geostrophy and therefore provides a convenient physically relevant constraint for fitting mesoscale features thus the decorrelation length scale is often taken to be related to the deformation radius cummings 2005 these considerations have worked in concert in the past the swot observations provide information on scales below the deformation radius and therefore considerations must be made to deal with the high density of these data with respect to the decorrelation length scale as more observations cluster within a decorrelation length scale the computational cost of the observation preparation and deriving the minimization increases and in an extreme case could cause the solution to never converge due to practical limitations e g round off errors additionally the nadir altimeter and swot surface observations are converted into synthetic temperature and salinity profiles by the isop system vertical representation error becomes problematic as more small scale information is introduced into the assimilation by the high resolution observations that swot provides isop is based off a mesoscale climatology which does not accurately represent smaller scale phenomena such as balanced submesoscales and internal gravity waves that are explicitly represented in our modeling framework and thus also within the observations sampled from nature these issues provide motivation to thin the observations there are two approaches to reducing the number of observations one is thinning that simply selects a subset of the available observations the second approach is through the creation of a super observation whereby a weighted average is derived over the local analysis decorrelation length scale and treated as the true observation to be assimilated the latter methodology is used in this experiment the weighting is gaussian using distance from the centroid of the data going into the super observation with an e folding scale of the local analysis decorrelation length scale a simple observation operator maps the control variables from the nearest model grid point to the centroid over which the super observation was created to calculate innovations the super observation reduces observation error and maintains features larger than the decorrelation scale therefore the super observation produces an observation that is consistent with the analysis scales and the types of physics that isop is able to reproduce for sst a set of super observations was derived and passed directly to ncoda for assimilation for nadir altimetry and swot data a set of super observations was derived and then passed to isop to generate synthetic temperature and salinity profiles at the centroid of the data over which the super observation was taken this drastically reduces the number of observations that are assimilated into the system fig 9 the full observation set fig 9a b includes swot observations on a 2 km along and across track grid fig 9c d shows how using a mean 15 km decorrelation length scale affects the volume of observations after super observations are constructed using a larger average analysis decorrelation length scale 30 km fig 9e f results in a smaller number of super observations the errors incurred by inferring synthetic temperature and salinity using the default 30 km decorrelation length scale super observations fig 9e f of steric height anomalies between january and march 2016 are shown in fig 10 error in the observed steric height anomalies were taken into account when the isop synthetics were created thus the isop errors shown in fig 10 are a function of both measurment error and fitting imperfect temperature and salinity profiles for both temperature fig 10a and salinity fig 10b the comparison between nature and isop synthetic data fall primarily along the 1 1 line temperature statistics show that isop synthetic profiles have a mae of 0 63 c and an error standard deviation of approximately 1 c fig 10c isop synthetic salinity profiles have a mae of 0 06 psu and an error standard deviation of 0 08 psu fig 10d these errors are consistent with prior validation comparing isop derived synthetic temperature and salinity with in situ observations helber et al 2013 the non gaussian distribution of both temperature and salinity errors is an undesirable result but further investigation of this issue is outside the scope of this work 3 results table 1 provides a brief summary of each of the different experiments conducted differentiated by the types of data incorporated into the daily analysis cycle four osse experiments were performed and evaluated the free run altim swot and altim swot all four osses started with the same initial condition on december 1 2015 by using the state from nature on december 1 2016 all experiments were integrated forward without assimilation to january 1 2016 starting january 1 2016 cycling assimilation was performed every 24 h with the exception of the free run which did not assimilate any information the altim run assimilated sst in situ profiles and traditional nadir altimetry the swot experiment is similar to altim except that it assimilated swot data instead of nadir altimetry data finally altim swot assimilated all possible observation types used in this study the assimilative osses altim swot and altim swot used the default mean decorrelation length scale of 30 km for the initial set of results shown in sections 3 1 and 3 2 each osse was integrated forward until march 31 2016 and then evaluated relative to nature error statistics were computed for three variables ssh mld and 100 m temperature ssh defines the surface pressure field and is a depth integrated quantity approximating the underlying baroclinic structure that is primarily controlled by mesoscale processes but is also influenced by smaller scale variability such as balanced submesoscales and internal gravity waves mld is a complicated variable that is a function of both large scale forcing and local frontogenesis model skill with respect to this variable is essential for accurately representing oceanic variability and air sea exchange finally 100 m temperature provides an estimate of internal ocean variability the maximum mean depth of the mixed layer in this region is 100 m fig 3 which allows the use of 100 m temperature to quantify model skill with respect to thermocline variability deeper variables e g 1000 m temperature could also be considered however balanced submesoscales are primarily confined within the mixed layer and upper thermocline bachman et al 2017 and therefore any deep water analysis would feature only mesoscale and internal gravity wave variability using these surface and near surface variables allows us to focus on the widest continuum of ocean physics present in this modeling framework the comparison of results begins with area averaged errors to gain a broad view of model skill and then the evaluation focuses on wavenumber spectra to determine constrained spatial scales 3 1 area averaged errors 30 km decorrelation length scale fig 11 shows mae between nature and each osse for 100 m temperature ssh and mld the mae includes information at a location only if the water depth is at least 1000 m the free run errors are consistently higher than any of the assimilative experiments for all three variables tested as the assimilation process begins on january 1 a sharp decrease in errors is observed for both 100 m temperature and ssh the initial rate of error decrease correlates with the quantity of observations used in the assimilation process in the ssh mae the altim swot errors decrease most rapidly followed by the swot experiment because ssh is a direct observation this provides verification that the quantity of data is constraining the system more rapidly by january 11 the altim experiment error levels are roughly equivalent to those of the swot and altim swot experiments all three assimilative experiment error levels then oscillate around a mae of 0 65 c for 100 m temperature and 5 cm for ssh with respect to mld the assimilative experiment errors are generally lower compared to the free run but the difference between the free run and the assimilative run mae is smaller than the other variables 3 2 wavenumber spectra 30 km decorrelation length scale the bulk statistics do not finely differentiate the observation system impacts the spectra of ocean variables tend to be red and it is not possible to determine if smaller scales are more accurately represented by the area averaged errors therefore we quantify the wavelengths that are constrained within the osses through wavenumber spectral analysis two dimensional power spectral density psd was calculated for each 3 hour time step in the square subdomain shown in fig 1b the time series of two dimensional psd was then averaged into a single two dimensional field in kx ky wavenumber space the time averaged psd was then averaged radially to produce a one dimensional spectrum the time and space averaged 100 m temperature ssh and mld nature spectra for 2016 are shown in fig 12 all three variables have an unbroken cascade of psd from the largest observed scale 640 km down to the nyquist wavelength 2 km each variable has a different spectral slope between the 200 km and 10 km wavelength range ssh produces the steepest slope followed by 100 m temperature and then mld these slopes are consistent with previous studies that examined the same variables at comparable model resolutions capet et al 2008 richman et al 2012 spatial gradients accentuate small scale variability temperature is heavily influenced by horizontal stirring caused by mesoscale and submesoscale velocities the horizontal gradient of ssh being a reasonable approximation of the velocity vector therefore 100 m temperature psd has a flatter slope as much of its spatial variability is tied to intermediate to small scale horizontal motions mld is driven by mesoscale and submesoscale processes controlling stratification stirring and frontogenesis the latter being responsible for convergence divergence along eddy fronts the frontal processes are a derivative quantify of the horizontal velocity and buoyancy fields mld is therefore characterized by even greater small scale variability and subsequently has a flatter slope than both ssh and 100 m temperature these dynamics will be important considerations later when discussing the ramifications of 3dvar data assimilation in this high resolution modeling environment the spectra of many other oceanic variables could be analyzed as well for example kinetic energy an important metric could be analyzed but due to the nature of our assimilation method of fitting temperature and salinity synthetics velocity is indirectly altered by corrections in surface and subsurface pressure i e through geostrophic correlations therefore any error trends in the pressure field will simply be extrapolated onto the resulting velocity in the subsurface temperature and salinity primarily act as passive tracers and therefore have similar spectral slopes not shown for these reasons redundancy in the results is reduced by focusing on 100 m temperature ssh and mld which are each controlled by a unique set of physical processes conceptually we separate the wavenumber space into two domains larger scales small wavenumbers that are constrained by the available observations and smaller scales larger wavenumbers which are unconstrained an appropriate assimilation should place constrained osse features in locations and times that are similar to those in nature the spatial scales constrained by each osse may be determined more clearly by differencing fields of each osse from nature which provides the error in the osse the amplitude of the errors in the constrained features should be reduced below the amplitude of the features and the spectral energy should also be removed from the constrained scales in the psd of the errors at small scales unconstrained features in the osse experiments will not be at the same locations and times as in nature the result is that amplitudes of errors at unconstrained scales become greater than the amplitude of the features and spectral energy is increased in the unconstrained scales of the psd of the errors we can observe this effect most clearly by normalizing the error spectrum 1 ε osse γ nature γ osse where ε osse is the psd of the error nature minus osse γ nature is the psd of nature γ osse is the psd of the osse and brackets denote the mean of the two spectra this normalization creates a convenient metric for measuring the error of each experiment as a function of spatial scales at a particular wavenumber if the normalized value is zero nature and the respective experiment share exactly the same features in that spatial scale if features are completely unconstrained osse and nature features are uncorrelated random variables and the psd of the error is the sum of the psd of the osse and nature thus a normalized psd value of 2 0 implies that the assimilation has not impacted features at that particular spatial scale a normalized psd value of 1 0 indicates that the correlation between the osse and nature is 0 5 and we define this value as the separation point between constrained and unconstrained spatial scales the spectral analyses were derived for the four osse experiments during the month of february n 232 time steps the results contain several trends fig 13 the free run performs the worst with respect to all three variables 100 m temperature ssh and mld with a normalized psd below one at only the largest of spatial scales for 100 m temperature the altim experiment produces the next highest errors fig 13a both swot assimilating experiments have lower errors and cross the normalized psd threshold of 1 0 at lower wavelengths than the other osse experiments we quantify the performance of each osse by evaluating the ratios of integrated spectra 2 k min k nyquist ε osse dk k min k nyquist γ nature γ osse dk where k denotes wavenumbers kmin is the minimum resolved wavenumber 1 640 km 1 and knyquist is the nyquist wavenumber 1 2 km 1 as the assimilation more accurately accounts for more of the features in nature this value should trend towards zero table 2 provides a summary of the ratios and is consistent with the prior analysis for 100 m temperature experiments that assimilated simulated swot observations contain less error than both the free run and altim experiments with the swot experiment producing the smallest value which is a 23 decrease in error over the altim experiment analyses of ssh results in similar conclusions visual inspection shows that both experiments using the simulated swot observations outperform the free run and altim experiments fig 13b ssh ratios of integrated spectra per eq 2 demonstrate that the swot experiment again performs best with a 19 decrease in error over the altim experiment table 2 finally the same analyses are performed for mld this variable is the least constrained of the three tested with the altim swot and altim swot producing similar normalized spectra fig 13c the ratio of integrated spectra shows that the reduction in error in the two swot experiments is only 2 when compared to the result from the altim experiment table 2 finally the smallest wavelength at which the normalized spectra cross the 1 0 threshold is determined for each osse and for each variable fig 14 for 100 m temperature fig 14a the altim experiment constrains wavelengths down to 161 km a 28 km improvement over the free run the swot experiment constrains wavelengths down to 145 km and the altim swot experiment down to 130 km this result shows that the experiment using both current nadir altimetry and simulated swot observations constrains an additional 31 km over the experiment utilizing only nadir altimetry this is significant as it approaches the deformation radius for this geographical region 50 km chelton et al 1998 again the analysis of ssh produces similar results fig 14b the altim swot experiment produces the lowest minimum constrained wavelength of 139 km a value slightly higher than that produced when analyzing 100 m temperature mld produces the largest minimum constrained wavelength of 323 km fig 14c in each case the osses that include simulated swot observations produce the smallest minimum constrained wavelength therefore the results indicate that including swot observations in a highly realistic cycling forecast analysis system does produce an advancement in forecast skill 3 3 area averaged errors and wavenumber spectra 15 km decorrelation length scale gaultier et al 2016 and ubelmann et al 2015 found that two dimensional fields of swot ssh constructed using optimal and dynamic interpolation respectively can resolve scales of 100 km and less these interpolation schemes are difficult to compare to the combined variational assimilation primitive equation forecasting performed here the approach we use relies on dynamic extrapolation into the future from an initial condition the interpolation schemes however benefit from a set of observations prior and posterior to the mapping time regardless swot observations clearly contain information on scales smaller than those shown to be constrained by the analysis forecast system in our first set of experiments fig 14 this prompts a second set of experiments in which the assimilation settings were altered in an attempt to further utilize the high density swot observations in our experiments the horizontal resolution of the forward model is 1 km and the model can therefore represent scales smaller than the regional rossby radius of deformation 50 km chelton et al 1998 in addition the swot observations resolve much smaller scales in two dimensions than the nadir altimeters this transition to both higher resolution models and observations motivates that the long held mesoscale assumptions built into the current analysis forecast systems be challenged e g the decorrelation length scale as a function of the deformation radius in this section the swot and altim swot experiments were repeated with a mean analysis decorrelation length scale of 15 km the effects of changing the decorrelation length scale on thinning show more of the data are retained within the analysis fig 9c d the less severely thinned data were used to obtain different isop temperature and salinity synthetics over a larger set of geographic locations this should ultimately bias the analysis towards the smaller scale features present in the high density swot data and potentially allow the system to constrain a larger set of wavelengths area averaged errors and wavenumber spectra were recalculated for the updated analysis forecast fields to quantify improvement in skill the altim experiment was not altered and therefore serves as a useful reference between the previous results using a larger analysis decorrelation length scale 30 km and those shown in this section using a shorter analysis decorrelation length scale 15 km compared with the experiments run with the larger 30 km decorrelation length scale we observe a slight increase in area averaged errors for 100 m temperature and ssh and a decrease in errors for mld fig 15 wavenumber spectral analysis again provides a finer differentiation between the osses fig 16 in comparison to the experiments using the larger decorrelation length scale visual inspection suggests little difference or a slight decrease in skill for 100 m temperature and ssh and an increase in skill with respect to mld this observation is quantified by the ratio of integrated spectra table 2 for 100 m temperature the ratios are similar between the experiments run with a larger or shorter decorrelation length scale for ssh a slight decrease in skill is noted for the swot experiment run with the shorter decorrelation length scale but a substantial decrease in skill occurs for the altim swot experiment as observed in the area averaged errors the experiments utilizing the shorter decorrelation length scale also produced greater skill in wavenumber space with respect to mld finally these observations are mirrored in the estimations of the minimum constrained wavelengths fig 14 the minimum constrained wavelength for 100 m temperature is slightly lower for the swot experiment and slightly higher for the altim swot experiment when rerun with the shorter decorrelation length scale for ssh both experiments using the shorter decorrelation length scale produce a larger minimum constrained wavelength when compared to the same experiments run with the larger decorrelation length scale for mld the experiments using the shorter decorrelation length scale produces a minimum constrained wavelength up to 87 km smaller than the same experiments run with a larger decorrelation length scale overall we observe that decreasing the decorrelation length scale reduces skill with respect to 100 m temperature and ssh while increasing skill for mld substantially the apparent dichotomy of these results is explored in section 4 4 discussion reducing the analysis decorrelation length scale in an attempt to further utilize the small scale information within the high density swot observations resulted in conflicting results a reduction of skill occurs for 100 m temperature and ssh while an increase in skill occurs for mld fig 12 demonstrates that 100 m temperature and ssh have steeper spectral slopes and therefore a relatively higher concentration of energy at larger wavelengths mld however has a flatter slope and therefore a relatively higher concentration of energy at smaller wavelengths the results demonstrated in section 3 3 therefore suggest that reducing the decorrelation length scale preferentially sets small scale features at the expense of the large scale phenomena the reverse is true when using a relatively large analysis decorrelation length scale this situation has been addressed by implementing a multi scale assimilation process for 3dvar muscarella et al 2014 li et al 2015a 2015b miyazawa et al 2017 these multi scale systems use a two step assimilation method whereby large scale information from observations are fit to the background using a larger decorrelation length scale in the first pass this analysis is then used as the background in the second step in which small scale information is assimilated using a smaller decorrelation length scale this allows the analysis to compute a correction to both the large scale and small scale without compromising skill in one or the other the initial results reported here indicate an advancement in skill when using swot observations and are consistent with the expected effects of a single scale analysis examination of results derived using swot observations in a 3dvar multi scale analysis system would be an appropriate next step this work should include investigations into the optimal decorrelation length scales used in each of the analysis steps our results suggest that larger intermediary and smaller decorrelation length scales affect ocean variables differently and some balance may be required depending on the needs of the user additionally more than two assimilation steps might be considered so that no compromise is necessary the drawback would be the additional computation cost of running the extra analyses the selection of the observation window may also be critical here a 5 day window for the nadir altimetry and swot observations was used but both longer and shorter windows have merit a longer window may allow a much more accurate representation of the mesoscale field especially when considering the relatively long 21 day repeat period swot will have this long window however will severely misfit small scale features that generally have shorter time scales and will no longer be at their previously observed location at the analysis time a shorter time window would mitigate this issue but would then generate an inferior representation of the mesoscale field finally mesoscale and submesoscale physics are fundamentally different mcwilliams 2016 the two step assimilation should also alter the dynamical balances applied to the analysis increments to account for the physics of the features that each analysis step is trying to optimally fit a more sophisticated assimilation system could also be used such as the 4dvar by inserting observations along a time evolving trajectory the action of the adjoint and tangent linear model dynamically spreads high resolution information along all available wavelengths in this framework a longer observation window is always advantageous but comes with a much greater computational cost the 4dvar however still uses an error covariance that is based on a preset decorrelation length scale that will generate an analysis increment that is too smooth to effectively constrain small scale features for this reason there is ongoing work to generate multi scale 4dvar solutions as well which also set each scale independently by partitioning observations and decorrelation length scales carrier et al 2018 finally the topic of scale separation has also been approached using ensemble variational data assimilation schemes buehner and shlyaeva 2015 these considerations should be a continued area of focus to extend the influence of high density observations such as those from swot 5 summary and conclusions a set of osses tested the utility of forthcoming swot data in a realistic submesoscale resolving ocean assimilation and forecasting system the usefulness of this new data type was first evaluated by calculating regional errors with respect to nature from january 1 to march 31 2016 experiments including simulated swot data converged towards nature at a faster rate area averaged errors indicated experiments with and without swot observations reached a similar error level after approximately 11 days a finer differentiation of the osses was obtained using wavenumber spectral analysis of differences between each experiment and nature the osses utilizing the simulated swot observations consistently produced lower error in wavenumber space when compared to the experiment that assimilated only nadir altimetry data with respect to 100 m temperature the minimum constrained wavelength was found to be 161 km for the experiment using only nadir altimetry as opposed to 130 km for the experiment utilizing both nadir altimetry and swot observations this 31 km improvement in skill is substantial and suggests that operational ocean analysis forecast systems can expect notable increases in predictive skill when swot data become available the smallest constrained wavelength found for all tested variables and all osse experiments 130 km is greater than the regional rossby radius of deformation 50 km which serves as an estimate of scale separation between mesoscales and submesoscales it was hypothesized that it may be necessary to reduce the analysis decorrelation length scale in order to fully utilize the high density swot observations a degradation of skill was noted for 100 m temperature and ssh for the swot experiments using this reduced decorrelation length scale an increase in skill for mld was observed for the same experiments based off derived spectral slopes ssh and 100 m temperature feature a relatively higher concentrations of psd at longer wavelengths than mld this lead us to conclude that reducing the decorrelation length scale improved analysis forecast skill for variables that feature more small scale variability at the expense of variables that feature more large scale variability the reverse was shown to be true when using a relatively large decorrelation length scale these findings further highlight the need for multi scale assimilation solutions when utilizing a suite of observations which include both large scale and small scale information we have shown that swot observations will improve ocean analysis forecast skill to a substantial degree when they become available to fully constrain all the wavelengths that swot can observe multi scale assimilation solutions will need to be implemented work is currently underway to build this functionality into the analysis forecast system used in this study with the intent of fully constraining the mesoscale field while also beginning to generate predictive skill into the submesoscale regime acknowledgements joseph m d addezio is supported by the naval research laboratory cooperative agreement baa n00173 03 73 13 01 awarded to the university of southern mississippi this research is funded by the naval research laboratory base program submesoscale prediction of eddies by altimeter retrieval spear the authors appreciate constructive comments provided by the anonymous reviews and the editor which improved the manuscript the authors thank prasad g thoppil for helping process the surface drifter observations the authors are also grateful to numerous nrl colleagues for instructive discussions had throughout experimentation 
24052,the paper presents the adriatic sea and coast adrisc meteotsunami forecast system which has been developed to operationally forecast meteotsunamis atmospherically generated destructive ocean waves in the tsunami frequency band in the adriatic sea the challenges posed by modelling meteotsunamis are first reviewed then the adrisc meteotsunami forecast system set up is presented in detail and finally the atmosphere and ocean model results are evaluated against 48 air pressure sensors and 19 tide gauges for six different meteotsunami events the statistical analysis of the high frequency model results reveals that the adrisc atmospheric and ocean models can reproduce meteotsunami events even though their performances highly vary depending on the event and observation location a qualitative analysis of the maps of extreme sea level and mean sea level pressure high frequency model results shows that even a slight shift in location of the order of 1 to 10 km of the atmospheric disturbances responsible for the meteotsunami generation results in the incapability of the ocean models to reproduce the observed floods occurring during the meteotsunami events this study presents the first available thorough evaluation of a deterministic meteotsunami forecast system as such it establishes that a carefully envisioned modelling system even if imperfect can be implemented to reproduce and forecast meteotsunami events keywords meteotsunamis atmosphere and ocean modelling and forecast high frequency model result evaluation adriatic sea 1 introduction modelling meteorological tsunamis or meteotsunamis destructive long waves generated by traveling atmospheric disturbances has recently been raised as a critical issue in several studies satake and fujii 2014 whitmore and knight 2014 šepić et al 2015 even if the physics of ocean models theoretically allows for reproducing meteotsunami events rabinovich et al 1999 liu et al 2003 vilibić et al 2004 dragani 2007 resolution and bathymetry of these models vilibić et al 2008 orlić et al 2010 as well as meteorological forcing horvath and vilibić 2014 are not accurate enough to recreate the generation propagation and amplification of such extreme phenomenon development of reliable atmospheric oceanic models in operational meteotsunami short term forecast has thus been defined as one of the main challenges of the meteotsunami community vilibić et al 2016 such a modelling suite is already running for the region of the balearic islands renault et al 2011 but has so far not been thoroughly evaluated for meteotsunami hazard forecasting then a main scientific question remains unanswered can meteotsunami events be deterministically reproduced and forecasted to answer this question the eastern side of the adriatic sea and particularly the croatian coast and islands where recurrent meteotsunamis occur orlić 2015 is an ideal test case indeed in addition to the long tradition of studying and modelling meteotsunamis in this area orlić 1980 vilibić et al 2004 vilibić and šepić 2009 orlić et al 2010 šepić et al 2016 horvath et al 2018 several uncoupled models covering the whole adriatic sea have been running operationally during the last decade including 1 the 4 km resolution mediterranean forecast system mfs pinardi et al 2003 pinardi and coppini 2010 tonani et al 2014 based on the nucleus for european modelling of the ocean nemo model and forced by the 6 hourly atmospheric fields provided by the european centre for medium range weather forecasts ecmwf 2 the 2 km adriaroms 4 0 system russo et al 2013 based on the regional ocean modeling system roms and forced by the cosmo i7 hourly atmospheric fields 3 the 2 2 km adriatic regional areg model oddo et al 2005 2006 guarnieri et al 2010 based on princeton ocean model pom and also forced by the 6 hourly ecmwf fields 4 the 2 km roms model janeković et al 2014 forced by the 8 km aladin numerical weather prediction model operational at the croatian meteorological and hydrological service tudor et al 2013 and 5 the finite element shyfem 2d model umgiesser et al 2004 used to forecast storm surge in the city of venice discretized with elements ranging from 1 5 km in the northern adriatic to 100 m inside venice lagoon and forced by ecmwf wind and pressure fields a comparison of 3d forecast systems chiggiato and oddo 2008 reveals that higher resolution models such as adriroms and areg perform better in terms of general ocean dynamics than the mfs model for shallow areas below 50 m depth which cover about 20 of the entire adriatic sea domain in addition a study by bressan et al 2017 concludes that the reproduction of storm events with adriroms in the northern adriatic highly depends on quality and resolution of the atmospheric forcing but also of the open boundary ocean forcing based on this past experience and taking into account inherent challenges of reproducing and forecasting the atmospheric physics responsible for creation of tsunamigenic disturbances belušić et al 2007 tanaka 2010 as well as the conjoint response of the ocean assumed barotropic to the first order monserrat et al 2006 this study aims to present a thorough description and evaluation of a new meteotsunami forecast system the adriatic sea and coast adrisc meteotsunami forecast component the modelling strategy including description of 1 the prerequisites for meteotsunami modelling 2 the adrisc modelling suite set up and 3 the data and the events used for evaluation is presented in section 2 the capability of the different models of the adrisc modelling suite to reproduce and forecast meteotsunami events is then assessed in details in section 3 finally section 4 discusses the feasibility of deterministically modelling meteotsunami events and presents conclusions 2 modelling strategy 2 1 prerequisites for meteotsunami modelling meteotsunamis are tsunami like ocean waves accompanied by strong currents they occur over periods from a few minutes to a few hours and are generated by traveling surface air pressure and or wind disturbances monserrat et al 2006 that interact with the ocean via proudman proudman 1929 hibiya and kajiura 1982 greenspan greenspan 1956 munk et al 1956 and shelf rabinovich 1993 resonances to study meteotsunamis one thus has to analyze high frequency signals of air pressure wind and sea level data ideally 1 min records which are often discarded as noise in typical atmospheric and oceanographic studies reproduction and forecast of meteotsunamis require a carefully planned and unconventional modelling strategy which includes both atmospheric and ocean modelling when studying meteotsunamis the main goal of the atmospheric model is to capture tsunamigenic atmospheric processes like internal gravity waves igws convective clouds squall lines etc this requires 1 high horizontal spatial resolution at least 2 km horvath and vilibić 2014 as igws typically range between 10 and 1000 km plougonven and zhang 2014 2 increased vertical resolution in the first 2 km above the earth surface and 3 substantially reduced model time step below 1 min in order to properly represent the generation and the propagation of the tsunamigenic processes characterized by atmospheric variations of the order of a few minutes and to preserve the numerical stability of the model given the above requirements it is clear that atmospheric processes responsible for generation of meteotsunamis cannot be properly represented by available forecast products such as ecmwf or aladin model results used by the croatian meteorological and hydrological service because they are spanning over temporal and spatial scales where these models are not performing well churchill et al 1995 monserrat and thorpe 1992 1996 skamarock 2004 bechle et al 2016 a dedicated high resolution atmospheric model should then be implemented in order to reproduce the meteotsunami genesis processes high resolution non hydrostatic atmosphere models such as the 1 25 km moloch model http www isac cnr it dinamica projects forecasts are already operational in the adriatic sea however their outputs are not saved at high enough frequency to be used as forcing in meteotsunami studies concerning the ocean model the two critical processes that must be captured are 1 the offshore generation and resonant amplification of meteotsunamis and 2 the nearshore amplification of the tsunami like wave by topography and harbor resonance rabinovich 2009 the offshore generation of meteotsunamis strongly depends on the atmospheric disturbance speed if this speed is equal to the local shallow water wave speed the energy of the atmospheric disturbance is resonantly transferred to the ocean waves the topography of the continental shelf then controls the shoaling of the generated tsunami like wave during its propagation towards the coast in order for an ocean model to capture the offshore meteotsunami dynamics the following criteria are thus required 1 the atmospheric forcing should be imposed every minute in order to capture the speed and amplitude of pressure disturbances and 2 the spatial resolution should allow for accurate representation of the continental shelf the nearshore amplification of meteotsunami waves depends on the geomorphology coastline and bathymetry and thus on the natural frequency of resonance of local areas of interest such as harbor bay estuary etc due to the extremely complex geomorphology of the croatian coastline including a network of 78 islands 525 islets and 642 rocks or reefs a resolution higher than 20 m is needed in the nearshore areas where the harbor resonance occurs even if previous modelling studies e g renault et al 2011 have been using traditional 3d free surface regional ocean models with a resolution of 10 m 1 the submesoscale dissipation is dominated by numerical constraints rather than physical ones soufflet et al 2016 for such models and 2 covering all the areas of interest along the croatian coastline at this resolution would require to use up to 6 regular grids of average size 600 600 then the use of structured ocean models at resolutions higher than 1 km may be impractical and instead barotropic unstructured models which allow to adjust the resolution depending on the depth and or the area of interest are a logical option these models are widely used by the tsunami and meteotsunami modelling community park et al 2014 zhang and baptista 2008 šepić et al 2016 bubalo et al 2018 as they properly represent nearshore amplification of the tsunami like wave by topography and harbor resonance during short term meteo tsunami events 2 2 model setup 2 2 1 adrisc modelling suite modules the adriatic sea and coast adrisc modelling suite has been developed with the aim to accurately represent the processes driving the atmospheric and oceanic adriatic circulation in particular during extreme weather conditions within the framework of a pilot meteotsunami early warning system šepić et al 2017 a special attention has been paid to the capability of the adrisc suite to reproduce and forecast the adriatic meteotsunamis in this spirit two different modules of the adrisc modelling suite have been developed conjointly 1 a basic module providing atmospheric and oceanic adriatic baroclinic circulation at the deep sea and coastal scales and 2 a dedicated nearshore module used to better reproduce atmospherically driven extreme sea level events and most particularly meteotsunamis modelling of the adriatic baroclinic circulation at the coastal scale requires to properly resolve the orographic and bathymetric features of the studied area for the atmosphere the bora wind intensity for example highly depends on the capability of the model to capture the topography of the velebit channel where the speed of these winds can reach up to 30 m s with gusts surpassing 60 m s e g jiang and doyle 2005 belušić and klaić 2006 gohm et al 2008 for the ocean the complex network of islands along the croatian coast influences the mostly wind driven coastal circulation orlić et al 1992 in addition as the adriatic is a relatively small semi enclosed basin the mediterranean regional atmospheric circulation as well as the exchanges of water masses with the ionian sea via the strait of otranto play an important role on the local circulation the basic module model domains presented in fig 1 blue box are thus defined accordingly for the atmosphere a 15 km grid horizontal size 140 140 approximately covering the central mediterranean basin and a nested 3 km grid 266 361 encompassing the entire adriatic and ionian seas allow for the proper modelling of the adriatic atmospheric circulation depending on both local orography and mediterranean regional forcing while for the ocean a 3 km grid identical to the atmospheric grid and a nested additional 1 km grid 676 730 provide a good representation of both the exchanges with the ionian sea and the complex geomorphology of the adriatic sea and most particularly of the croatian coastline the vertical discretization of the grids is achieved via terrain following coordinates 58 levels refined in the surface layer for the atmosphere laprise 1992 and 35 levels refined near both the sea surface and bottom floor for the ocean shchepetkin and mcwilliams 2009 the basic module of the adrisc modelling suite which produces hourly atmospheric and oceanic results is based on a modified version of the coupled ocean atmosphere wave sediment transport coawst v3 3 modelling system developed by warner et al 2010 the state of the art coawst model couples online the regional ocean modeling system roms svn 885 shchepetkin and mcwilliams 2005 2009 and the weather research and forecasting wrf v3 9 1 1 model skamarock et al 2005 via the model coupling toolkit mct v2 6 0 larson et al 2005 and the remapping weights computed between the 15 km 3 km and 1 km atmospheric and ocean grids with the spherical coordinate remapping and interpolation package scrip concerning the modelling of atmospherically driven extreme sea level events in the adriatic sea and most particularly meteotsunamis an even better representation of the orography and geomorphology is needed than in the basic module for the atmosphere the atmospheric disturbances responsible for meteotsunamis are generally generated over the apennines on the eastern side of the italian peninsula vilibić and šepić 2009 šepić et al 2016 the capability of the atmospheric model to represent these disturbances thus highly depends on how well the grid resolves the chain of mountains for the ocean the harbor and bay resonance play an important role on the local amplification of meteotsunami waves and the local geomorphology including coastline and bathymetry must be precisely represented in the ocean model to properly capture the extreme sea levels the nearshore module model domains chosen to represent atmospherically driven extreme sea level events are presented in fig 1 red box a 1 5 km atmospheric grid 450 486 covering the entire adriatic region provides a good representation of the orography of the main croatian islands and the adriatic region complex coastal topography for the ocean an unstructured mesh with a resolution ranging from about 5 km in the deepest part of the adriatic to 10 m in the locations where harbor resonance is known to occur 286 336 nodes 513 340 triangular elements with 477 islands and islets included is used given the spatial and temporal resolution of the available atmospheric and oceanic forcing for the adriatic the direct use of the 1 5 km atmospheric grid and the unstructured ocean mesh to reproduce extreme events would definitely lead to a misrepresentation of the conditions driving the extreme sea levels however using the hourly results produced by the 3 km atmospheric and 1 km ocean grids to force the nearshore module allow for a better representation of the short term extreme events as the initial and boundary conditions already include high temporal and spatial variabilities the nearshore module which thus downscales the atmospheric and ocean results obtained with the basic module couples offline the wrf model 1 5 km grid with the barotropic version 2ddi of the unstructured advanced circulation adcirc v52 30 model luettich et al 1991 the definition of modules within the adrisc modelling suite allows for a great flexibility in terms of spatial and temporal scales of the simulated ocean processes e g short term extreme nearshore events vs deep sea decadal processes while homogenizing the domains and models used to investigate the adriatic sea circulation in other words depending on the kind of study the physics of the models the number of models and modules used and the length of the simulations will vary but not the common settings of the presented adrisc modules 2 2 2 adrisc basic and nearshore module settings as model orography bathymetry and coastline are crucial a single digital terrain model dtm incorporating offshore bathymetry from etopo1 amante and eakins 2009 nearshore bathymetry from navigation charts cm93 2011 topography from gebco 30 arc second grid 2014 weatherall et al 2015 and coastline data generated by the institute of oceanography and fisheries split croatia is providing the terrain data for all presented adrisc grids a linear programming lp method developed by dutour sikiric et al 2009 is applied to the roms grids 3 km and 1 km to smooth the bathymetry with imposed minimum depth of 2 m i e to minimize the roughness factors while keeping the bathymetric features of the dtm and to reduce the horizontal pressure gradient errors generated by the use of terrain following coordinates with sharp bathymetric gradients additionally the adrisc modelling suite is using a common tidal and river forcing for the ocean grids eight tidal constituents m2 s2 n2 k2 k1 o1 p1 q1 extracted from the mediterranean and black seas 2011 1 30 regional solution of the osu tidal inversion software otis egbert et al 1994 egbert and erofeeva 2002 are imposed on the offshore boundaries of the 3 km grid these constituents are found to satisfactorily reproduce tidal dynamics in a micro tidal adriatic sea cushman roisin and naimie 2002 janeković and kuzmić 2005 a total of 54 river flows 49 for the 1 km grid are imposed over at least 6 grid points each 18 grid points for the po river delta with river mouths located along the coastline of greece acheloos and arachthos albania and montenegro bistrica vjosa seman shkumbini erzen mat ishem drin and bojana croatia and slovenia kupari ombla neretva cetina jadro krka zrmanja senj crikvenica bakarac rječina raša mirna dragonja and rižana italian peninsula timavo isonzo vivapa tagliamento livenza piave brenta adige po reno lamone foglia metauro esino musone potenza chienti tronto pescara sangro trigno biferno cervaro ofanto bradano cavone agri sinni crati noce sele volturno garigliano and tevere and sicily oreto platani and simeto the river flow monthly climatology is based on the rivdis database vörösmarty et al 1996 and studies from malačič and petelin 2009 pano and abdyli 2002 pano et al 2010 janeković et al 2014 and ljubenkov 2015 the interannual variability of the flows is derived from ludwig et al 2009 finally as the focus of the adrisc modelling suite is to study the adriatic sea circulation forced by both the general mediterranean circulation and the local atmospheric conditions the coawst model has been modified in order to balance model efficiency and quality by reducing the exchanges between the different grids of the basic module first as the two way nesting of grids can dramatically increase the computation time in the roms model the adrisc roms grids are only one way nested this online downscaling of the roms grids allows for a good representation of the spatial and temporal variability of the 1 km grid offshore boundary forcing which mostly depends on the exchanges between the mediterranean general circulation and the ionian sea modelled by the 3 km grid second as the spatial extension of the ocean grids does not entirely cover the 15 km atmospheric domain the sea surface temperature sst from the roms grids is not prescribed in the atmospheric model in order to avoid any potential discontinuities along the border between the two way nested 15 km and 3 km atmospheric grids the atmosphere ocean coupling is thus in this sense a one way only coupling between wrf and roms models third with optically clear water in shallow areas like in the eastern adriatic sea the absorption of the shortwaves reaching the seafloor generates a warming sst trend a solution to this problem is to impose a heat flux correction via the calculation of the kinematic surface net heat flux sensitivity to a sst of reference measured assimilated etc such as presented in barnier et al 1995 or combes and matano 2014 this procedure is hereafter referred as dq dsst and is presented in more details in appendix a in this adriatic sea configuration of the coawst model high resolution sst forcing which ideally assimilates sst from remote sensing products is thus imposed directly as lower boundary condition to the wrf grids and used as reference for the calculation of the dq dsst method with the roms model this procedure is used to minimize the corrections of the heat fluxes provided by wrf while insuring that no artificial sst trends are generated in the shallow areas of the roms ocean grids which have a minimum depth of 2 m 2 2 3 operational adrisc meteotsunami forecast component the adrisc meteotsunami forecast component has been developed in order to provide a daily forecast of 1 the adriatic sea surface circulation at the deep sea and coastal scales and 2 most importantly the genesis and propagation of potential destructive meteotsunamis at the coastal scale as well as their associated extreme sea levels at the nearshore scale the basic and nearshore modules of the adrisc modelling suite are thus both used in the operational set up of the adrisc meteotsunami forecast component in terms of model parameterizations and physics the optimal configuration of adriatic high resolution wrf models described by kehler poljak et al 2017 and successfully applied to meteotsunami modelling by horvath et al 2018 is also used in the adrisc meteotsunami forecast configuration for all three grids 15 km 3 km and 1 5 km with the morison 2 moment scheme microphysics scheme morrison et al 2005 the myj planetary boundary layer janjić 1994 the dudhia dudhia 1989 and rrtm mlawer et al 1997 short and long wave radiation schemes the eta surface layer scheme janjić 1994 and the five layer thermal diffusion scheme for soil temperature dudhia 1996 in addition the kain fritch cumulus parameterization kain 2004 is applied to the 15 km grid concerning the configuration of the roms model the flather flather 1976 chapman chapman 1985 and orlanski orlanski 1976 raymond and kuo 1984 conditions are used to impose respectively the barotropic velocity the surface elevation and the baroclinic fields at the open boundaries furthermore two nudging relaxation zones are used to relax the baroclinic structure with a minimum folding time of 3 days towards the fields provided by the ocean climatology marchesiello et al 2001 1 a ten grid point wide area along the open boundaries is used for all the fields and 2 an area covering the bathymetry deeper than 2000 m is used for the temperature and salinity fields only in order to minimize the numerical diapycnal mixing a sponge area is also defined in such a way that the horizontal viscosity is four times bigger at the open boundary of the grids than seven grid points away from it the other parameterizations used in roms are a multidimensional positive definite advection transport algorithm mpdata smolarkiewicz 1984 smolarkiewicz and clark 1986 smolarkiewicz and grabowski 1990 for the tracer advection a fourth order centered scheme for the horizontal momentum advection and the gls gen umlauf and burchard 2003 turbulence closure scheme at last the 2ddi adcirc model is 1 initialized and hourly forced at the open boundary by the 1 km roms sea surface elevation results and 2 forced by the 1 min surface stress and pressure input at each node of the model derived from the 1 5 km wrf 10 m wind and surface atmospheric pressure results the model also simulates wetting drying processes in low lying areas and imposes zero land boundary flux the models of the adrisc meteotsunami forecast component were compiled with the intel 17 0 3 053 compiler the pnetcdf 1 8 0 library and the mpi library mpich 7 5 3 on the european centre for middle range forecast s ecmwf s high performance computing facility hpcf in addition ecflow 4 9 0 the work flow package used by all ecmwf operational suites was set up to automatically and efficiently run all the modules of the adrisc modelling suite in a controlled environment in terms of workload no hyper threading is used and the coawst model optimally runs on 260 cpus with both the wrf and roms grids decomposed in 10 13 tiles while the wrf 1 5 km model uses 210 cpus 14 15 tiles and the adcirc model runs with 200 cpus i e sub domains this optimal configuration of the models has been tested for each model separately via stand alone simulations as well as in the coupling mode for the coawst model and found to maximize the running time of each individual model as well as the time used to exchange data between the different grids since the 1st of march 2018 the adrisc meteotsunami forecast component runs operationally every day at midnight utc in two different steps fig 1 first the coawst model basic module blue box in fig 1 exchanging wrf fields with roms grids every minute is used to generate hourly outputs for the next three day period with the initial state and boundary conditions provided 1 6 hourly to the wrf 15 km grid by the previous day 12 utc based analysis of the ecmwf atmospheric model high resolution 0 1 0 1 10 day forecast hres lalaurette 2002 tsonevsky and richardson 2012 petroliagis and pinson 2012 zsótér 2006 zsótér et al 2014 and 2 daily to the roms 3 km grid by the mediterranean forecasting system mfs high resolution 1 24 1 24 10 day medsea forecast pinardi et al 2003 pinardi and coppini 2010 tonani et al 2014 which also provides 6 hourly interpolated sst fields to the wrf grids in addition the skin temperature of the hres model is extracted near the river mouths and imposed as river temperature in the roms grids second the nearshore module runs for a 36 h period beginning a day and half after the start date of the coawst model run the hourly wrf 3 km results are downscaled to the wrf 1 5 km grid and the hourly roms 1 km sea surface elevation results are imposed as initial state and boundary conditions to the adcirc model the wrf model then runs for the single 1 5 km grid and provides 1 min outputs that at the end of the simulation are used as atmospheric forcing in the adcirc model the choice of starting the coawst model run 12 h after the latest hres analysis 12 utc based is principally driven by the need to produce at least a two day short term forecast in 24 h staring from 19 00 utc when the hres results are theoretically available also some spin up period is needed to adjust the physics of the models to the analysis or more generally the initial condition for the adrisc meteotsunami forecast component this spin up period is assumed to be 24 h for the coawst model basic module and 12 h for the offline coupling of wrf 1 5 km and adcirc nearshore module this means that only the last 48 h of the basic module run and the last 24 h of the nearshore module results are analyzed and published daily a conservative estimate of the running times of the different modules of the adrisc meteotsunami forecast component is as follow fig 1 1 h to download and format the ecmwf and medsea forecast fields 10 h to run the coawst model 20 min to downscale the wrf 3 km results to the 1 5 km grid and to produce the initial boundary conditions of the adcirc model from the roms 1 km results 6 h30 to run the wrf 1 5 km grid 10 min to generate the adcirc atmospheric forcing 3 h30 to run the adcirc model and 1 h30 to format and download locally the model surface results including 10 m wind 2 m air temperature air pressure sea temperature salinity ocean surface and barotropic currents and sea level at the end of every day the next 48 h hourly forecast surface results from the coawst run as well as the 15 min forecast surface results from wrf 1 5 km and adcirc simulations for the next day are downloaded in a database optimized for automatic storage and published at http www izor hr adrisc 2 3 available data of recorded meteotsunami events to properly evaluate the skills of the adrisc meteotsunami forecast component two important conditions had to be fulfilled first 1 to 5 min high resolution records of atmospheric pressure and sea level had to be available which is as mentioned previously not the atmospheric and or oceanographic standard and second the meteotsunami event had to be strong enough to be noticed by the public i e flooding of inhabited areas in the eastern adriatic these required observations only became available in recent years mostly due to an observational system which encompass a network of eight air pressure sensors split ražanj vrboska vela luka vis ancona ortona vieste and four tide gauges split stari grad vela luka and sobra installed in areas where either the generation or the amplification of meteotsunami are known to occur fig 2 in addition air pressure data is also provided by 1 the meteorological and hydrological service of the republic of croatia http meteo hr with high quality 1 min records at up to five locations of interest and 2 a non profit association of croatian amateur meteorologists crometeo https pljusak com karta php with 5 min records at 40 locations of interest concerning the sea level data 1 min records are provided by 1 the ioc sea level monitoring facility http www ioc sealevelmonitoring org map php at eight locations along the italian coast otranto vieste isole tremiti ortona st benedetto del tronto ancona venice and trieste 2 the hydrographic institute of the republic of croatia at four locations rovinj zadar ploče dubrovnik and 3 the institute of hydrometeorology and seismology of montenegro podgorica at two locations bar kotor all listed data are used for the adrisc skill assessment and the locations of the 48 pressure sensors in yellow and 19 tidal gauges in red are presented in fig 2 destructive meteotsunami waves are recurring events along the croatian coast with wave heights and periods documented by eyewitnesses since the early 20th century and collected in a catalogue by orlić 2015 however the proper monitoring of the eastern adriatic meteotsunami events only started a decade ago and only six well recorded events were available to carry out the evaluation of the models the first two events took place on the 25th and 26th of june 2014 and are well described by šepić et al 2016 on the 25th at least two different meteotsunami waves reached the croatian coast with reported 3 m and 2 5 m wave heights in vela luka and rijeka dubrovačka harbors respectively fig 3 and on the 26th a single 1 m height meteotsunami wave was witnessed in ston and pelješac channel summer 2017 was also a dynamic period in terms of meteotsunami events three tsunami like waves were generated and observed on the 28th of june in stari grad on the 1st of july in vrboska and on the 11th of july in the north eastern adriatic with the latter meteotsunami driven by the squall line of a fast moving storm finally the last event uncharacteristically generated in early spring happened on the 31st of march 2018 in stari grad as the adrisc meteotsunami forecast component started to be operational in march 2018 the first five events had thus to be simulated with conditions as close as possible to the operational setup for the atmospheric forcing the ecmwf hres operational model results are stored since 1985 and the configuration used for running the wrf model is identical to the one described in section 2 2 3 however for the ocean the mfs operational model results are not publicly available once the analysis or reanalysis results are produced practically it means that only reanalysis medsea results are available online for the 2014 simulations and that only analysis results can be used for the 2017 runs finally for the spring 2018 meteotsunami event the adrisc meteotsunami forecast component was already running operationally and both atmosphere and ocean were forced with real time forecast results for each of the six events only the last 24 h results of the coawst model and of the wrf adcirc offline coupling are analyzed and used for the statistical evaluation this strategy is used to conservatively determine whether or not the meteotsunami events would have been predicted in operational mode for all of the events a high pass filter with a 2 h cutoff period was applied to the 1 min spatial results of mean sea level msl pressure and sea level extracted from the offline coupling of wrf 1 5 km and adcirc in order to better visualize meteotsunami component of reproduced atmospheric and sea level time series examples of these filtered results are presented in fig 3 animations are provided as supplementary material and time series of measured and modelled signals are presented in vela luka and stari grad stations during the 28th of june 2017 event in fig 4 as the adrisc meteotsunami forecast component started to be operational in march 2018 the first five events had thus to be simulated with conditions as close as possible to the operational setup for the atmospheric forcing the ecmwf hres operational model results are stored since 1985 and the configuration used for running the wrf model is identical to the one described in section 2 2 3 however for the ocean the mfs operational model results are not publicly available once the analysis or reanalysis results are produced practically it means that only reanalysis medsea results are available online for the 2014 simulations and that only analysis results can be used for the 2017 runs finally for the spring 2018 meteotsunami event the adrisc meteotsunami forecast component was already running operationally and both atmosphere and ocean were forced with real time forecast results for each of the six events only the last 24 h results of the coawst model and of the wrf adcirc offline coupling are analyzed and used for the statistical evaluation this strategy is used to conservatively determine whether or not the meteotsunami events would have been predicted in operational mode for all of the events a high pass filter with a 2 h cutoff period was applied to the 1 min spatial results of mean sea level msl pressure and sea level extracted from the offline coupling of wrf 1 5 km and adcirc in order to better visualize meteotsunami component of reproduced atmospheric and sea level time series examples of these filtered results are presented in fig 3 animations are provided as supplementary material and time series of measured and modelled signals are presented in vela luka and stari grad stations during the 28th of june 2017 event in fig 4 in fig 3 wave patterns can be seen on the filtered pressure results for the presented 2014 2017 and 2018 events the characteristics of the patterns wave length period amplitude width etc highly depend on the meteotsunami event the filtered sea level results also present wave patterns but due to the effects of the bathymetry and geomorphology of the coast including reflection they are less coherent than in the atmosphere in addition fig 4 illustrates how the mean sea level pressure and sea level 1 min station data from both measurements and models are high pass filtered with a 2 h cutoff period in order to better analyze the high frequency signals during the meteotsunami events the aim of this study is not to describe in depth the different events but to assess the skill of the models used to forecast meteotsunamis the dynamics of each event genesis propagation wave characteristics in the atmosphere and the ocean will thus not be presented in this paper 3 skill assessment of the adrisc meteotsunami forecast component 3 1 statistical analysis the evaluation of the different models used in the adrisc modelling suite is carried out only for the msl air pressure extracted from the wrf results and for the sea levels from the roms adcirc runs it follows three different steps 1 the general performance of the models is assessed with taylor diagrams presenting the analysis of normalized standard deviations hereafter referred as model to measurement standard deviation ratio or sdr and cross correlation cc of the 1 min time series of unfiltered data models vs measurements 2 the model capability to represent high frequency signals characteristic of meteotsunami events is presented with a quantile distribution analysis of the high pass filtered data 2 h cutoff period presented in q q plots and 3 as the frequency space is the best way to analyze generation and amplification of meteotsunamis the goodness of fit of the different models defined as the normalized root mean square error nrmse is derived from the complex frequency response complex result of the fast fourier transform or fft decomposition both filtered and unfiltered of the data in addition 1 as the roms 3 km grid is too coarse to properly represent the harbor resonance the performance of this grid is not presented nor discussed and 2 the high frequency wrf 15 km time series extracted at the locations of the pressure sensor stations are not kept in operational mode and thus are not available for the 31st of march 2018 event the statistics used for the taylor diagrams figs 5 and 6 are derived from 1440 samples for each of the six 24 h events concerning the wrf model results using higher resolution does not seem to clearly improve neither the cross correlation cc nor the standard deviation ratio sdr which shows that the air pressure signal is probably dominated by hourly variations well represented even with the 15 km grid however more pronounced differences are seen between the roms 1 km and adcirc model results in addition events with the best results concerning the atmospheric pressure do not necessarily have the best results for sea level and vice versa in more details on the 25th of june 2014 half of the pressure stations seem to capture properly the event cc 0 6 and 0 5 sdr 1 5 while the other half do not perform well cc 0 5 and sdr 1 5 for the sea level stations the roms model 0 5 cc 0 9 and 0 75 sdr 0 9 seems to be more accurate than the adcirc model 0 5 cc 0 75 and 0 1 sdr 0 75 on the 26th of june 2014 the majority of the pressure stations present really high cross correlation 0 5 cc 0 75 but the standard deviation ratio is quite spread 0 15 sdr 0 75 while for the sea level stations adcirc 0 5 cc 0 95 and 0 15 sdr 1 15 and roms 1 km 0 6 cc 0 9 and 0 5 sdr 1 15 are quite accurate on the 28th of june 2017 the wrf model performs well 0 75 cc 0 95 and 0 5 sdr 1 5 while the accuracy of the adcirc 0 5 cc 0 9 and 0 25 sdr 1 5 and roms 1 km 0 45 cc 0 9 and 0 5 sdr 1 75 models highly depends on the sea level stations the 1st of july 2017 is the event with the poorest performances for all the models the wrf results are extremely spread 0 cc 0 85 and 0 5 sdr 2 5 while roms and adcirc models have really low accuracy cc 0 5 and or sdr 0 5 for most of the stations on the 11th of july 2017 the wrf model has a consistent standard deviation ratio 0 25 sdr 1 15 but only two third of the stations have a good cross correlation 0 5 cc 0 85 concerning the sea level stations the cross correlation is higher than 0 5 for both models and standard deviation ratios are also reasonable roms 1 sdr 1 75 and adcirc 0 5 sdr 2 finally the best performance of the wrf model is obtained for the event of spring 2018 cc 0 9 and 0 5 sdr 1 while the ocean models generally show good accuracy with roms 0 5 cc 0 7 and 0 5 sdr 1 6 and adcirc 0 45 cc 0 95 and 0 75 sdr 2 15 the unfiltered model results seem to generally be in good agreement with the measurements however as they are dominated by the tides for the ocean models and by daily to hourly variations for the air pressure they cannot properly show how well the models reproduce meteotsunamis in the eastern adriatic comparisons of the high pass filtered signals with 2 h cutoff period of msl air pressure and sea level between measurements and models are thus presented with q q plots in figs 7 and 8 overall for the wrf filtered results fig 7 the lines joining the first and third quartiles of model vs observation distributions highlight that the higher the wrf model resolution the closer the model distribution to the measurements implying that higher resolution models can better reproduce pressure disturbances for ocean models fig 8 these same lines clearly show that the distributions of the filtered roms results are closer to the observations than the ones of the filtered adcirc results the filtered results are thus not following the general behavior presented in the taylor plots figs 5 and 6 which didn t systematically show a better performance for neither the wrf 1 5 km nor the adcirc models in addition for the 2014 and first two 2017 events figs 7 and 8 panels a b d and e a good agreement between filtered results from wrf and roms adcirc models is observed the closer are the filtered air pressures to the observations the closer are sea levels to the measurements for the 11th of july 2017 the model result distributions of neither the filtered air pressures nor the filtered sea levels can reproduce the distributions of the observations thus this meteotsunami event seems to not be captured by the adrisc meteotsunami forecast component for the 2018 event the filtered wrf results are in good agreement with the observations while the filtered sea level model results are about 3 times nearly 6 times for the adcirc results smaller than the measured ones although it appears that the amplitude of the atmospheric disturbances is well caught by the wrf model it is possible that a stronger air pressure disturbance of limited dimensions not caught by our measurement network and not reproduced by the model propagated over the area and generated the measured meteotsunami the q q plots of the high pass filtered data models vs measurements clearly demonstrate the link between atmospheric disturbances and meteotsunami generation but their main limitation is that the correlation of the compared signals is not taken into account as only the quantile distributions are compared and they only give a partial picture of the capability of the models to reproduce the studied meteotsunamis the final analysis of the comparison between time series of models and measurements is carried out by generating the complex frequency response of the signals the fft decomposition of a signal s is given by s fft which is hereafter referred as the complex frequency response both for the entire range of frequencies and the high frequencies only maximum period of 2 h the goodness of fit or normalized root mean square error nrmse 100 1 o fft m fft o fft o fft is estimated between the complex frequency response of the models m fft and the observations o fft basing the goodness of fit of the models on the comparison of complex frequency responses is probably the best way to capture the meteotsunami events but leads to poor accuracy in particular for the filtered results due to uncorrelated signals in the frequency space as multimodal distributions are recurrent in geoscience violin plots hintze and nelson 1998 based on box plots but including the full distribution of the data via a kernel density estimation are used to present the statistics of the model goodness of fit the shape as well as the median horizontal lines of each distribution are presented 1 for the six different events in fig 9 and 2 for all the stations in fig 10 as the q q plot analysis demonstrated that the wrf coarse grid poorly reproduce the high resolution processes the wfr 15 km nrmse is not presented for both wrf 3 km and 1 5 km models the median of air pressure nrmse reaches at least 99 fig 9a for all the events with distributions strongly negatively skewed and a second mode found around 95 median values of both roms 1 km and adcirc sea level nrmse are varying between 2 and 27 5 fig 9c depending on the events with distributions positively skewed and second or third modes found between 50 and 75 in addition the adcirc model seems to slightly perform better than the roms model even if for the two first events of 2014 outliers with values below 50 are seen in the adcirc sea level distributions while the roms nrmse distributions stop around 0 for the filtered data the wrf model nrmse fig 9b is largely decreased with a median varying between 9 and 65 while the adcirc roms model accuracy fig 9d is only slightly changed with median values between 5 and 13 5 the distributions of the goodness of fit of the filtered model results are mostly close to normal although for the four first events the filtered air pressure distributions are negatively skewed towards 100 finally for the filtered sea level results the roms model generally seems to be less accurate than the adcirc model which is in contradiction with the results presented in the q q plots fig 8 this reveals that the roms model is likely to generate strong unrealistic high frequency perturbations while the adcirc model is not capable to fully reproduce the amplitude of the observed perturbations in order to have a better idea of the spatial distribution of the model performances keeping in mind that the statistics for each station are derived for a maximum of six events most often less because data is not available at all the stations for all events the distributions of the model goodness of fit are presented fig 10 at each station for the air pressure the same behavior as seen in fig 9 is observed median varying between 92 and 99 for the unfiltered signals and between 2 and 45 for the high pass filtered results however concerning the sea level results the station by station analysis reveals that the performance of the roms 1 km and adcirc models is highly dependent of the location the roms model seems to better performs along the italian coastline st benedetto del tronto ortona isole tremiti and vieste stations and the adcirc model along the croatian and montenegrin ones split harbor vela luka sobra ploče dubrovnik bar and kotor stations this can be easily explained by the fact that the resolution of the adcirc model is at least 2 km outside of the croatian waters vs 1 km for the roms model where igws are formed and start to propagate but up to 10 m in areas where meteotsunami amplification is known to occur along the eastern side of the adriatic sea the assumption that sea elevation of the modelled meteotsunamis highly depends on the representation of the geomorphology of nearshore studied areas is thus confirmed summarily the statistical analysis of the adrisc meteotsunami forecast component model performances highlights the difficulty to reproduce correctly both the atmospheric disturbances and the associated proudman resonance and nearshore amplification responsible for meteotsunami generation and propagation it also shows the importance of using different kind of complementary analysis taylor diagrams q q plots goodness of fit of the complex frequency responses etc in order to better understand the capability of the models to reproduce both the model general behavior and the high frequency studied signals 3 2 analysis of the extremes for meteotsunami forecast the analysis of maximum elevations is critical this is indeed the final product of the modelling suite which allows warming the residents of the coastal areas of a potential flood it is also unfortunately the model parameter with the highest associated uncertainty due to the precision of the bathymetry at the nearshore areas of interest the location of the generated air pressure disturbances and the generation of the proudman and harbor resonances linked to the capacity to reproduce the exact speed amplitude and period of the air pressure disturbances in addition due to the extreme nature of meteotsunami events and the practical constraints associated with setting up measurement stations in harbors no observation is available in the precise locations where the meteotsunami amplification is maximum given these limitations fig 11 is showing the scatter plot models vs measurements of the maximum elevations extracted from the high pass filtered signals for each of the six events and at all the available sea level stations maximum 19 per event presented in fig 2 table 1 summarizes the statistics associated with the linear fits of the roms and adcirc model results as the results seem to present different behavior depending on the amplitude of the events the analysis of the maximum elevations is done separately for observations above and below the 0 2 m threshold for observed maximum elevations below 0 2 m the adcirc results seem to be in good agreement with the measurements even if adcirc tends to systematically underestimate them the coefficient of the linear fit is of 0 66 0 05 associated with a small rmse of 0 04 the roms 1 km results however are much more scattered strong over and under estimations but in average better fit to the measurements linear regression coefficient of 0 91 0 13 with a larger rmse of 0 09 similar results are found for observations above 0 2 m except that both models show an even larger underestimation linear coefficient of 0 33 0 05 for adcirc and 0 68 0 08 for roms associated with larger rmse 0 06 for adcirc and 0 11 for roms the fact that the roms model has the tendency to generate strong unrealistic sea level oscillations and that the adcirc model tends to underestimate the amplitude of these oscillations is thus confirmed by this simple analysis of the maximum elevations in order to better understand the capability of the adrisc meteotsunami forecast component to reproduce the six studied meteotsunami waves the spatial evolution of the minimum air pressure and the maximum sea level extracted respectively from the 1 min high pass filtered wrf 1 5 km and adcirc results is presented for each event figs 12 to 17 as can be seen in figs 12a 14a 15a and 17a during meteotsunami events the wrf model generates several atmospheric distributions in blue and white at different locations of the domain similarly for each event different coastal locations are affected by potentially different meteotsunami waves fig 12b 14b 15b and 17b as seen in the statistical analysis particularly figs 7 and 8 both atmospheric and ocean models present reasonable skills concerning meteotsunami modelling for four different events 25th of june 2014 26th of june 2014 28th of june 2017 and 1st of july 2017 for the 25th and 26th of june 2014 events the spatial analysis of the minimum filtered mean sea level air pressure figs 12a and 13a shows that the wrf model produces 1 various air pressure disturbances of limited cross propagation dimensions between 42 8 n and 43 1 n of latitude for the 25th of june and 2 a unique atmospheric disturbance below 42 8 n latitude for the 26th of june which are both in good agreement with what has been observed šepić et al 2016 concerning the associated maximum filtered sea elevation generated with the adcirc model figs 12b and 13b the flooding observed at various locations šepić et al 2016 are reproduced vela luka 1 15 m modelled vs 1 5 m observed rijeka dubrovačka 0 6 m modelled vs 1 25 m observed stari grad 0 45 m modelled vs 0 5 m observed and vrboska 0 35 m modelled vs 0 75 m observed for the 25th of june and ston harbor 0 35 m modelled vs 0 5 m observed for the 26th of june during the 26th of june event extreme water levels were also modelled in rijeka dubrovačka 0 5 m but not reported thus the modelled atmospheric disturbance is probably slightly shifted south compared to the observed one in addition as the sea elevation observations are a qualitative estimate provided by eyewitnesses they include tidal and other effects therefore it is expected that eyewitness observations have higher values than the presented filtered and thus detided sea elevation results the adcirc model has thus correctly captured spatial distribution and amplitudes of the meteotsunami waves observed during these two events however for the two first 2017 events figs 14a and 15a the wrf model is less successful in reproducing the location of the atmospheric pressure fields as the maximum filtered sea elevation of the adcirc model figs 14b and 15b reaches only 0 25 m in stari grad and 0 55 m in vrboska where flooding were respectively reported during the 28th of june and the 1st of july as documented with an amateur video available at https www youtube com watch v hxp4jidoubm as some amplifications occur in mali ston bay for the 28th of june and in vela luka for the 1st of july where no flooding was reported the location of the pressure disturbances modelled by wrf are probably not well reproduced for these events 1 too south 43 n latitude instead of 43 2 n to reach stari grad the 28th of june and 2 too south below 43 n and or too west west of 16 6 e to properly generate the observed meteotsunami in vrboska the 1st of july for the 11th of july 2017 event which happened in the northern adriatic the statistical analysis particularly figs 7 and 8 shows that neither the wrf models nor the roms and adcirc models could reproduced the observed meteotsunami dynamics this event was driven by the squall line of a storm https www youtube com watch v iu63d6i lc which was captured by the wrf 1 5 km model but shifted in location the modelled pressure disturbances fig 16a are indeed located too far north above 44 8 n instead of 44 6 n of latitude to be able to generate meteotsunami waves in mali lošinj bay which was flooded during this event and the adcirc model does not reproduce the observed sea elevation fig 16b finally for the 31st march 2018 event fig 17 modelled atmospheric pressure disturbances are too weak above 80 pa and located far too south below 42 9 n instead of 43 2 n of latitude to generate a meteotsunami in stari grad where flooding was reported https www istramet hr vijesti video meteoroloski tsunami pogodio stari grad na hvaru however as seen in figs 7 and 9 the wrf models reproduce the filtered mean sea level air pressure measured by the network of 48 pressure sensors because the disturbances are well reproduced inland but not at sea in summary the analysis of the extremes highlights the major difficulty of modelling meteotsunami to be able to reproduce the right location and the right intensity of the air pressure disturbance in the atmosphere in order to generate the correct proudman and harbor resonances in the ocean 4 discussion and conclusions meteotsunami forecast is based on the assumption that numerical models are capable of reproducing high frequency disturbances gravity waves in the atmosphere and resonant processes in the ocean in their review article plougonven and zhang 2014 highlighted the challenges of modelling gravity waves generated by jets and fronts and conclude that it will likely be impossible to draw a simple deterministic and convincing picture of the way gravity waves are generated from these processes in a complex flow environment such as a cold front within a baroclinic wave for the ocean proudman and topographic resonances are the main generation and amplification process of long oceanic waves monserrat et al 2006 vennell 2010 due to spatial discretization and lack of precise bathymetric data it is unlikely that present state of the art ocean numerical models can accurately represent the ocean and coast complex geomorphology responsible for the meteotsunami wave generation and amplification which is particularly true for the middle and southern parts of the eastern adriatic however given these overwhelming limitations the adrisc meteotsunami forecast component is showing skills in fair reproduction of meteotsunami events which might be used for operational forecasting qualitatively speaking about the model performance the presence of atmospheric disturbances is captured by the wrf model fig 7 even if the timing precise location direction and amplitude of these high frequency waves may not be well represented figs 9b and 10b moreover topographic amplification is reproduced in the harbors where meteotsunamis are known to occur figs 12b to 17b quantitatively speaking the capacity of both atmospheric and ocean adrisc models to reproduce meteotsunamis is far from being satisfactory with a goodness of fit lower than 65 and 13 5 for wrf and roms adcirc high frequency results respectively so can meteotsunami events be deterministically reproduced and forecasted given the results of this evaluation study based on available state of the art atmospheric and ocean models the answer is not for all events and not accurately however keeping in mind the few events studied the scattered spatial distribution of the observations used for the model evaluation and the inherent difficulty of modelling any high frequency signal in geosciences this study is presenting encouraging results and is a first step towards a holistic approach for meteotsunami hazard assessment indeed if it is unrealistic to only rely on deterministic forecast to design early warning systems for extreme events model results can still be used 1 to apply pattern recognition algorithms to the high pass filtered msl pressure results in order to detect disturbances likely to generate meteotsunamis then 2 to extract wave parameters from these patterns such as speed period amplitude etc and finally 3 to use a stochastic approach to estimate the meteotsunami hazard linked to each modelled pressure disturbance such an approach is currently under development within the croatian meteotsunami early warning system in conclusion generation and propagation of meteotsunamis is probably at the edge of what present state of the art numerical models can reproduce in particular it requires 1 to carefully check the numerical stability of the atmospheric model which should be set up to handle internal gravity waves i e high spatial resolution and reduced time step 2 to use accurate orography bathymetry and coastline data in high resolution atmospheric and ocean models and 3 to evaluate the model high frequency results with various statistical tools in order to draw a clear picture of the model skills in addition the analysis of the msl pressure and sea elevation filtered results reveals some contradictions with the assumption that the more accurately the atmospheric disturbance is modelled the closest to reality the simulated meteotsunami is for example the best performance of the wrf model is reached for the spring 2018 event median of 65 in fig 9 b when the worst performance of the roms adcirc models median of about 2 in fig 9 d is obtained similarly the best results of maximum sea elevation were simulated for the 25th of june 2014 event fig 12 b when the worst performance of the atmospheric models was obtained median of 9 in fig 9 b this is not per se a proof that the assumption is incorrect but more that 1 the observation network is not dense enough to cover the places where most probably the wrf model is failing during the spring 2018 event i e it is likely that the atmospheric disturbance which generated the meteotsunami was not captured by either the measuring network nor the wrf model 2 the atmospheric disturbances simulated by the wrf model probably have the right location speed and amplitude but are not correlated in the frequency space with the observations due to wrong periods of resonance e g for the 25th of june 2014 event and 3 a small failure in reproduction of atmospheric disturbance parameters speed direction and intensity results in a large misrepresentation of modelled meteotsunami waves because the generation of meteotsunami ocean waves is extremely sensitive to the speed of atmospheric disturbances vilibić et al 2008 a detailed process analysis including genesis propagation amplification and timing of the extrema of the different meteotsunami waves of the six presented events is going to be performed in order to better understand why the models are failing and how to improve their overall performances in addition with the observation network recently installed and the adrisc meteotsunami forecast component being operational since march 2018 more data about meteotsunamis is expected to be collected in the next few years this will hopefully lead to better statistical analyses of the adrisc model skills finally the perspective of including meteotsunamis as sources of extreme water levels in long term modelling studies will contribute to our understanding of the variability of these recurrent but rare events by building a larger database of simulated events the following are the supplementary data related to this article supplementary video 1 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 25th and 26th of june 2014 meteotsunami events supplementary video 1 supplementary video 2 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 28th of june 2017 meteotsunami event supplementary video 2 supplementary video 3 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 1st of july 2017 meteotsunami event supplementary video 3 supplementary video 4 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 11th of july 2017 meteotsunami event supplementary video 4 supplementary video 5 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 31st of march 2018 meteotsunami event supplementary video 5 supplementary data to this article can be found online at https doi org 10 1016 j ocemod 2019 02 003 acknowledgements we would like to thank all organisations that kindly provided us observations used in this study unesco ioc paris www ioc sealevelmonitoring org hydrographic institute of the republic of croatia split institute of oceanography and fisheries split institute of hydrometeorology and seismology of montenegro podgorica at two locations bar kotor and crometeo pljusak www pljusak com acknowledgement is also made for the support of the ecmwf staff in particular xavier abellan as well as for ecmwf s computing and archive facilities used in this research which has been supported by projects messi ukf grant 25 15 adios croatian science foundation grant ip 2016 06 1955 and ecmwf special project the adriatic decadal and inter annual oscillations modelling component finally we acknowledge the comments raised by two anonymous reviewers which greatly helped to improve the quality of the manuscript appendix a typical configuration of many ocean models running in the adriatic sea imposes a 10 m minimum depth instead of the 2 m used in the adrisc modelling suite however about 2 of the 3 km and 1 km ocean grids of the adrisc basic module have depths below 10 m which means that these shallow areas located along the coastline are not negligible and can influence the final model results unfortunately a consequence may be a creation of unrealistic gradients of surface temperature between the shallow areas and the remaining of the ocean domain in most of the places these spatial temperature gradients have the tendency to grow when coupled with the wrf model as properly representing the bathymetry of the shallow areas is important in the context of nearshore and more particularly meteotsunami studies a balance between accuracy of the bathymetry and the surface temperature of the ocean models had to be found and the dq dsst procedure was adopted in the adrisc modelling suite as described in combes and matano 2014 the heat flux derived from the wrf 3 km model fields and calculated within the roms model includes a tendency restoring term to the medsea daily sea surface temperature sst medsea such as q modified q wrf dqdsst ρ 0 c p sst roms sst medsea with q wrf the heat flux derived from the wrf 3 km model fields only and dqdsst the kinetic surface net heat flux sensitivity to sst medsea defined as dqdsst 4 σ sst medsea 3 ρ air c pair c h u ρ air c e 2501000 2370 t air 273 16 u 2353 ln 10 q air sst medsea 2 where σ 5 67 10 8 w m 2 k 4 is the stefan boltzmann constant c pair 1004 67 j kg 1 k 1 is the specific heat of the atmosphere c h 0 66 10 3 is the sensible heat transfer non dimensional coefficient c e 1 15 10 3 is the latent heat transfer non dimensional coefficient and ρ 0 1025 0 kg m 3 is the reference seawater density and c p 3985 j kg 1 k 1 is the specific heat of seawater as defined in roms model the surface wind speed u the surface air temperature t air the atmospheric density ρ air and the surface specific humidity q air are derived from the wrf 3 km fields this kind of correction has been used in previous studies and typical values of dq dsst are around 30 w m 2 k 1 in the south china sea tested in roms model zhu et al 2016 and 40 w m 2 k 1 in the gulf of lion mediterranean sea tested in nemomed12 model escudier 2015 two examples of the spatial and temporal variations of the daily dq dsst corrections are presented for a summer 25th of june 2014 and a spring 31st of march 2018 period in fig a1 the daily mean and variations are the average value and the standard deviation of the dq dsst correction respectively calculated over a 24 h period fig a1 highlights that the calculated dq dsst is 1 small in average between 7 and 5 w m 2 k 1 in comparison to the correction applied in the gulf of lion 2 quite constant during the daily calculations daily variations below 0 5 w m 2 k 1 mostly due to the use of daily medsea sst and 3 generally stronger in the croatian coastal area located between 42 n and 43 5 n characterized by extremely clear waters the biggest difference between the summer and winter periods presented in fig a1 can be seen in the northern part of the adriatic up to 1 w m 2 k 1 which is a shallow area with depths below 50 m strongly influenced by the discharge of the po river the dq dsst correction being small and the sst fields from medsea assimilating available remote sensing products in the adriatic reduce the possibility for propagation of sst errors from the medsea results to the adrisc modelling suite simulations fig a1 daily mean and daily variability i e standard deviation of the dq dsst correction applied in summer during the 25th of june 2014 and in winter during the 31st of march 2018 fig a1 
24052,the paper presents the adriatic sea and coast adrisc meteotsunami forecast system which has been developed to operationally forecast meteotsunamis atmospherically generated destructive ocean waves in the tsunami frequency band in the adriatic sea the challenges posed by modelling meteotsunamis are first reviewed then the adrisc meteotsunami forecast system set up is presented in detail and finally the atmosphere and ocean model results are evaluated against 48 air pressure sensors and 19 tide gauges for six different meteotsunami events the statistical analysis of the high frequency model results reveals that the adrisc atmospheric and ocean models can reproduce meteotsunami events even though their performances highly vary depending on the event and observation location a qualitative analysis of the maps of extreme sea level and mean sea level pressure high frequency model results shows that even a slight shift in location of the order of 1 to 10 km of the atmospheric disturbances responsible for the meteotsunami generation results in the incapability of the ocean models to reproduce the observed floods occurring during the meteotsunami events this study presents the first available thorough evaluation of a deterministic meteotsunami forecast system as such it establishes that a carefully envisioned modelling system even if imperfect can be implemented to reproduce and forecast meteotsunami events keywords meteotsunamis atmosphere and ocean modelling and forecast high frequency model result evaluation adriatic sea 1 introduction modelling meteorological tsunamis or meteotsunamis destructive long waves generated by traveling atmospheric disturbances has recently been raised as a critical issue in several studies satake and fujii 2014 whitmore and knight 2014 šepić et al 2015 even if the physics of ocean models theoretically allows for reproducing meteotsunami events rabinovich et al 1999 liu et al 2003 vilibić et al 2004 dragani 2007 resolution and bathymetry of these models vilibić et al 2008 orlić et al 2010 as well as meteorological forcing horvath and vilibić 2014 are not accurate enough to recreate the generation propagation and amplification of such extreme phenomenon development of reliable atmospheric oceanic models in operational meteotsunami short term forecast has thus been defined as one of the main challenges of the meteotsunami community vilibić et al 2016 such a modelling suite is already running for the region of the balearic islands renault et al 2011 but has so far not been thoroughly evaluated for meteotsunami hazard forecasting then a main scientific question remains unanswered can meteotsunami events be deterministically reproduced and forecasted to answer this question the eastern side of the adriatic sea and particularly the croatian coast and islands where recurrent meteotsunamis occur orlić 2015 is an ideal test case indeed in addition to the long tradition of studying and modelling meteotsunamis in this area orlić 1980 vilibić et al 2004 vilibić and šepić 2009 orlić et al 2010 šepić et al 2016 horvath et al 2018 several uncoupled models covering the whole adriatic sea have been running operationally during the last decade including 1 the 4 km resolution mediterranean forecast system mfs pinardi et al 2003 pinardi and coppini 2010 tonani et al 2014 based on the nucleus for european modelling of the ocean nemo model and forced by the 6 hourly atmospheric fields provided by the european centre for medium range weather forecasts ecmwf 2 the 2 km adriaroms 4 0 system russo et al 2013 based on the regional ocean modeling system roms and forced by the cosmo i7 hourly atmospheric fields 3 the 2 2 km adriatic regional areg model oddo et al 2005 2006 guarnieri et al 2010 based on princeton ocean model pom and also forced by the 6 hourly ecmwf fields 4 the 2 km roms model janeković et al 2014 forced by the 8 km aladin numerical weather prediction model operational at the croatian meteorological and hydrological service tudor et al 2013 and 5 the finite element shyfem 2d model umgiesser et al 2004 used to forecast storm surge in the city of venice discretized with elements ranging from 1 5 km in the northern adriatic to 100 m inside venice lagoon and forced by ecmwf wind and pressure fields a comparison of 3d forecast systems chiggiato and oddo 2008 reveals that higher resolution models such as adriroms and areg perform better in terms of general ocean dynamics than the mfs model for shallow areas below 50 m depth which cover about 20 of the entire adriatic sea domain in addition a study by bressan et al 2017 concludes that the reproduction of storm events with adriroms in the northern adriatic highly depends on quality and resolution of the atmospheric forcing but also of the open boundary ocean forcing based on this past experience and taking into account inherent challenges of reproducing and forecasting the atmospheric physics responsible for creation of tsunamigenic disturbances belušić et al 2007 tanaka 2010 as well as the conjoint response of the ocean assumed barotropic to the first order monserrat et al 2006 this study aims to present a thorough description and evaluation of a new meteotsunami forecast system the adriatic sea and coast adrisc meteotsunami forecast component the modelling strategy including description of 1 the prerequisites for meteotsunami modelling 2 the adrisc modelling suite set up and 3 the data and the events used for evaluation is presented in section 2 the capability of the different models of the adrisc modelling suite to reproduce and forecast meteotsunami events is then assessed in details in section 3 finally section 4 discusses the feasibility of deterministically modelling meteotsunami events and presents conclusions 2 modelling strategy 2 1 prerequisites for meteotsunami modelling meteotsunamis are tsunami like ocean waves accompanied by strong currents they occur over periods from a few minutes to a few hours and are generated by traveling surface air pressure and or wind disturbances monserrat et al 2006 that interact with the ocean via proudman proudman 1929 hibiya and kajiura 1982 greenspan greenspan 1956 munk et al 1956 and shelf rabinovich 1993 resonances to study meteotsunamis one thus has to analyze high frequency signals of air pressure wind and sea level data ideally 1 min records which are often discarded as noise in typical atmospheric and oceanographic studies reproduction and forecast of meteotsunamis require a carefully planned and unconventional modelling strategy which includes both atmospheric and ocean modelling when studying meteotsunamis the main goal of the atmospheric model is to capture tsunamigenic atmospheric processes like internal gravity waves igws convective clouds squall lines etc this requires 1 high horizontal spatial resolution at least 2 km horvath and vilibić 2014 as igws typically range between 10 and 1000 km plougonven and zhang 2014 2 increased vertical resolution in the first 2 km above the earth surface and 3 substantially reduced model time step below 1 min in order to properly represent the generation and the propagation of the tsunamigenic processes characterized by atmospheric variations of the order of a few minutes and to preserve the numerical stability of the model given the above requirements it is clear that atmospheric processes responsible for generation of meteotsunamis cannot be properly represented by available forecast products such as ecmwf or aladin model results used by the croatian meteorological and hydrological service because they are spanning over temporal and spatial scales where these models are not performing well churchill et al 1995 monserrat and thorpe 1992 1996 skamarock 2004 bechle et al 2016 a dedicated high resolution atmospheric model should then be implemented in order to reproduce the meteotsunami genesis processes high resolution non hydrostatic atmosphere models such as the 1 25 km moloch model http www isac cnr it dinamica projects forecasts are already operational in the adriatic sea however their outputs are not saved at high enough frequency to be used as forcing in meteotsunami studies concerning the ocean model the two critical processes that must be captured are 1 the offshore generation and resonant amplification of meteotsunamis and 2 the nearshore amplification of the tsunami like wave by topography and harbor resonance rabinovich 2009 the offshore generation of meteotsunamis strongly depends on the atmospheric disturbance speed if this speed is equal to the local shallow water wave speed the energy of the atmospheric disturbance is resonantly transferred to the ocean waves the topography of the continental shelf then controls the shoaling of the generated tsunami like wave during its propagation towards the coast in order for an ocean model to capture the offshore meteotsunami dynamics the following criteria are thus required 1 the atmospheric forcing should be imposed every minute in order to capture the speed and amplitude of pressure disturbances and 2 the spatial resolution should allow for accurate representation of the continental shelf the nearshore amplification of meteotsunami waves depends on the geomorphology coastline and bathymetry and thus on the natural frequency of resonance of local areas of interest such as harbor bay estuary etc due to the extremely complex geomorphology of the croatian coastline including a network of 78 islands 525 islets and 642 rocks or reefs a resolution higher than 20 m is needed in the nearshore areas where the harbor resonance occurs even if previous modelling studies e g renault et al 2011 have been using traditional 3d free surface regional ocean models with a resolution of 10 m 1 the submesoscale dissipation is dominated by numerical constraints rather than physical ones soufflet et al 2016 for such models and 2 covering all the areas of interest along the croatian coastline at this resolution would require to use up to 6 regular grids of average size 600 600 then the use of structured ocean models at resolutions higher than 1 km may be impractical and instead barotropic unstructured models which allow to adjust the resolution depending on the depth and or the area of interest are a logical option these models are widely used by the tsunami and meteotsunami modelling community park et al 2014 zhang and baptista 2008 šepić et al 2016 bubalo et al 2018 as they properly represent nearshore amplification of the tsunami like wave by topography and harbor resonance during short term meteo tsunami events 2 2 model setup 2 2 1 adrisc modelling suite modules the adriatic sea and coast adrisc modelling suite has been developed with the aim to accurately represent the processes driving the atmospheric and oceanic adriatic circulation in particular during extreme weather conditions within the framework of a pilot meteotsunami early warning system šepić et al 2017 a special attention has been paid to the capability of the adrisc suite to reproduce and forecast the adriatic meteotsunamis in this spirit two different modules of the adrisc modelling suite have been developed conjointly 1 a basic module providing atmospheric and oceanic adriatic baroclinic circulation at the deep sea and coastal scales and 2 a dedicated nearshore module used to better reproduce atmospherically driven extreme sea level events and most particularly meteotsunamis modelling of the adriatic baroclinic circulation at the coastal scale requires to properly resolve the orographic and bathymetric features of the studied area for the atmosphere the bora wind intensity for example highly depends on the capability of the model to capture the topography of the velebit channel where the speed of these winds can reach up to 30 m s with gusts surpassing 60 m s e g jiang and doyle 2005 belušić and klaić 2006 gohm et al 2008 for the ocean the complex network of islands along the croatian coast influences the mostly wind driven coastal circulation orlić et al 1992 in addition as the adriatic is a relatively small semi enclosed basin the mediterranean regional atmospheric circulation as well as the exchanges of water masses with the ionian sea via the strait of otranto play an important role on the local circulation the basic module model domains presented in fig 1 blue box are thus defined accordingly for the atmosphere a 15 km grid horizontal size 140 140 approximately covering the central mediterranean basin and a nested 3 km grid 266 361 encompassing the entire adriatic and ionian seas allow for the proper modelling of the adriatic atmospheric circulation depending on both local orography and mediterranean regional forcing while for the ocean a 3 km grid identical to the atmospheric grid and a nested additional 1 km grid 676 730 provide a good representation of both the exchanges with the ionian sea and the complex geomorphology of the adriatic sea and most particularly of the croatian coastline the vertical discretization of the grids is achieved via terrain following coordinates 58 levels refined in the surface layer for the atmosphere laprise 1992 and 35 levels refined near both the sea surface and bottom floor for the ocean shchepetkin and mcwilliams 2009 the basic module of the adrisc modelling suite which produces hourly atmospheric and oceanic results is based on a modified version of the coupled ocean atmosphere wave sediment transport coawst v3 3 modelling system developed by warner et al 2010 the state of the art coawst model couples online the regional ocean modeling system roms svn 885 shchepetkin and mcwilliams 2005 2009 and the weather research and forecasting wrf v3 9 1 1 model skamarock et al 2005 via the model coupling toolkit mct v2 6 0 larson et al 2005 and the remapping weights computed between the 15 km 3 km and 1 km atmospheric and ocean grids with the spherical coordinate remapping and interpolation package scrip concerning the modelling of atmospherically driven extreme sea level events in the adriatic sea and most particularly meteotsunamis an even better representation of the orography and geomorphology is needed than in the basic module for the atmosphere the atmospheric disturbances responsible for meteotsunamis are generally generated over the apennines on the eastern side of the italian peninsula vilibić and šepić 2009 šepić et al 2016 the capability of the atmospheric model to represent these disturbances thus highly depends on how well the grid resolves the chain of mountains for the ocean the harbor and bay resonance play an important role on the local amplification of meteotsunami waves and the local geomorphology including coastline and bathymetry must be precisely represented in the ocean model to properly capture the extreme sea levels the nearshore module model domains chosen to represent atmospherically driven extreme sea level events are presented in fig 1 red box a 1 5 km atmospheric grid 450 486 covering the entire adriatic region provides a good representation of the orography of the main croatian islands and the adriatic region complex coastal topography for the ocean an unstructured mesh with a resolution ranging from about 5 km in the deepest part of the adriatic to 10 m in the locations where harbor resonance is known to occur 286 336 nodes 513 340 triangular elements with 477 islands and islets included is used given the spatial and temporal resolution of the available atmospheric and oceanic forcing for the adriatic the direct use of the 1 5 km atmospheric grid and the unstructured ocean mesh to reproduce extreme events would definitely lead to a misrepresentation of the conditions driving the extreme sea levels however using the hourly results produced by the 3 km atmospheric and 1 km ocean grids to force the nearshore module allow for a better representation of the short term extreme events as the initial and boundary conditions already include high temporal and spatial variabilities the nearshore module which thus downscales the atmospheric and ocean results obtained with the basic module couples offline the wrf model 1 5 km grid with the barotropic version 2ddi of the unstructured advanced circulation adcirc v52 30 model luettich et al 1991 the definition of modules within the adrisc modelling suite allows for a great flexibility in terms of spatial and temporal scales of the simulated ocean processes e g short term extreme nearshore events vs deep sea decadal processes while homogenizing the domains and models used to investigate the adriatic sea circulation in other words depending on the kind of study the physics of the models the number of models and modules used and the length of the simulations will vary but not the common settings of the presented adrisc modules 2 2 2 adrisc basic and nearshore module settings as model orography bathymetry and coastline are crucial a single digital terrain model dtm incorporating offshore bathymetry from etopo1 amante and eakins 2009 nearshore bathymetry from navigation charts cm93 2011 topography from gebco 30 arc second grid 2014 weatherall et al 2015 and coastline data generated by the institute of oceanography and fisheries split croatia is providing the terrain data for all presented adrisc grids a linear programming lp method developed by dutour sikiric et al 2009 is applied to the roms grids 3 km and 1 km to smooth the bathymetry with imposed minimum depth of 2 m i e to minimize the roughness factors while keeping the bathymetric features of the dtm and to reduce the horizontal pressure gradient errors generated by the use of terrain following coordinates with sharp bathymetric gradients additionally the adrisc modelling suite is using a common tidal and river forcing for the ocean grids eight tidal constituents m2 s2 n2 k2 k1 o1 p1 q1 extracted from the mediterranean and black seas 2011 1 30 regional solution of the osu tidal inversion software otis egbert et al 1994 egbert and erofeeva 2002 are imposed on the offshore boundaries of the 3 km grid these constituents are found to satisfactorily reproduce tidal dynamics in a micro tidal adriatic sea cushman roisin and naimie 2002 janeković and kuzmić 2005 a total of 54 river flows 49 for the 1 km grid are imposed over at least 6 grid points each 18 grid points for the po river delta with river mouths located along the coastline of greece acheloos and arachthos albania and montenegro bistrica vjosa seman shkumbini erzen mat ishem drin and bojana croatia and slovenia kupari ombla neretva cetina jadro krka zrmanja senj crikvenica bakarac rječina raša mirna dragonja and rižana italian peninsula timavo isonzo vivapa tagliamento livenza piave brenta adige po reno lamone foglia metauro esino musone potenza chienti tronto pescara sangro trigno biferno cervaro ofanto bradano cavone agri sinni crati noce sele volturno garigliano and tevere and sicily oreto platani and simeto the river flow monthly climatology is based on the rivdis database vörösmarty et al 1996 and studies from malačič and petelin 2009 pano and abdyli 2002 pano et al 2010 janeković et al 2014 and ljubenkov 2015 the interannual variability of the flows is derived from ludwig et al 2009 finally as the focus of the adrisc modelling suite is to study the adriatic sea circulation forced by both the general mediterranean circulation and the local atmospheric conditions the coawst model has been modified in order to balance model efficiency and quality by reducing the exchanges between the different grids of the basic module first as the two way nesting of grids can dramatically increase the computation time in the roms model the adrisc roms grids are only one way nested this online downscaling of the roms grids allows for a good representation of the spatial and temporal variability of the 1 km grid offshore boundary forcing which mostly depends on the exchanges between the mediterranean general circulation and the ionian sea modelled by the 3 km grid second as the spatial extension of the ocean grids does not entirely cover the 15 km atmospheric domain the sea surface temperature sst from the roms grids is not prescribed in the atmospheric model in order to avoid any potential discontinuities along the border between the two way nested 15 km and 3 km atmospheric grids the atmosphere ocean coupling is thus in this sense a one way only coupling between wrf and roms models third with optically clear water in shallow areas like in the eastern adriatic sea the absorption of the shortwaves reaching the seafloor generates a warming sst trend a solution to this problem is to impose a heat flux correction via the calculation of the kinematic surface net heat flux sensitivity to a sst of reference measured assimilated etc such as presented in barnier et al 1995 or combes and matano 2014 this procedure is hereafter referred as dq dsst and is presented in more details in appendix a in this adriatic sea configuration of the coawst model high resolution sst forcing which ideally assimilates sst from remote sensing products is thus imposed directly as lower boundary condition to the wrf grids and used as reference for the calculation of the dq dsst method with the roms model this procedure is used to minimize the corrections of the heat fluxes provided by wrf while insuring that no artificial sst trends are generated in the shallow areas of the roms ocean grids which have a minimum depth of 2 m 2 2 3 operational adrisc meteotsunami forecast component the adrisc meteotsunami forecast component has been developed in order to provide a daily forecast of 1 the adriatic sea surface circulation at the deep sea and coastal scales and 2 most importantly the genesis and propagation of potential destructive meteotsunamis at the coastal scale as well as their associated extreme sea levels at the nearshore scale the basic and nearshore modules of the adrisc modelling suite are thus both used in the operational set up of the adrisc meteotsunami forecast component in terms of model parameterizations and physics the optimal configuration of adriatic high resolution wrf models described by kehler poljak et al 2017 and successfully applied to meteotsunami modelling by horvath et al 2018 is also used in the adrisc meteotsunami forecast configuration for all three grids 15 km 3 km and 1 5 km with the morison 2 moment scheme microphysics scheme morrison et al 2005 the myj planetary boundary layer janjić 1994 the dudhia dudhia 1989 and rrtm mlawer et al 1997 short and long wave radiation schemes the eta surface layer scheme janjić 1994 and the five layer thermal diffusion scheme for soil temperature dudhia 1996 in addition the kain fritch cumulus parameterization kain 2004 is applied to the 15 km grid concerning the configuration of the roms model the flather flather 1976 chapman chapman 1985 and orlanski orlanski 1976 raymond and kuo 1984 conditions are used to impose respectively the barotropic velocity the surface elevation and the baroclinic fields at the open boundaries furthermore two nudging relaxation zones are used to relax the baroclinic structure with a minimum folding time of 3 days towards the fields provided by the ocean climatology marchesiello et al 2001 1 a ten grid point wide area along the open boundaries is used for all the fields and 2 an area covering the bathymetry deeper than 2000 m is used for the temperature and salinity fields only in order to minimize the numerical diapycnal mixing a sponge area is also defined in such a way that the horizontal viscosity is four times bigger at the open boundary of the grids than seven grid points away from it the other parameterizations used in roms are a multidimensional positive definite advection transport algorithm mpdata smolarkiewicz 1984 smolarkiewicz and clark 1986 smolarkiewicz and grabowski 1990 for the tracer advection a fourth order centered scheme for the horizontal momentum advection and the gls gen umlauf and burchard 2003 turbulence closure scheme at last the 2ddi adcirc model is 1 initialized and hourly forced at the open boundary by the 1 km roms sea surface elevation results and 2 forced by the 1 min surface stress and pressure input at each node of the model derived from the 1 5 km wrf 10 m wind and surface atmospheric pressure results the model also simulates wetting drying processes in low lying areas and imposes zero land boundary flux the models of the adrisc meteotsunami forecast component were compiled with the intel 17 0 3 053 compiler the pnetcdf 1 8 0 library and the mpi library mpich 7 5 3 on the european centre for middle range forecast s ecmwf s high performance computing facility hpcf in addition ecflow 4 9 0 the work flow package used by all ecmwf operational suites was set up to automatically and efficiently run all the modules of the adrisc modelling suite in a controlled environment in terms of workload no hyper threading is used and the coawst model optimally runs on 260 cpus with both the wrf and roms grids decomposed in 10 13 tiles while the wrf 1 5 km model uses 210 cpus 14 15 tiles and the adcirc model runs with 200 cpus i e sub domains this optimal configuration of the models has been tested for each model separately via stand alone simulations as well as in the coupling mode for the coawst model and found to maximize the running time of each individual model as well as the time used to exchange data between the different grids since the 1st of march 2018 the adrisc meteotsunami forecast component runs operationally every day at midnight utc in two different steps fig 1 first the coawst model basic module blue box in fig 1 exchanging wrf fields with roms grids every minute is used to generate hourly outputs for the next three day period with the initial state and boundary conditions provided 1 6 hourly to the wrf 15 km grid by the previous day 12 utc based analysis of the ecmwf atmospheric model high resolution 0 1 0 1 10 day forecast hres lalaurette 2002 tsonevsky and richardson 2012 petroliagis and pinson 2012 zsótér 2006 zsótér et al 2014 and 2 daily to the roms 3 km grid by the mediterranean forecasting system mfs high resolution 1 24 1 24 10 day medsea forecast pinardi et al 2003 pinardi and coppini 2010 tonani et al 2014 which also provides 6 hourly interpolated sst fields to the wrf grids in addition the skin temperature of the hres model is extracted near the river mouths and imposed as river temperature in the roms grids second the nearshore module runs for a 36 h period beginning a day and half after the start date of the coawst model run the hourly wrf 3 km results are downscaled to the wrf 1 5 km grid and the hourly roms 1 km sea surface elevation results are imposed as initial state and boundary conditions to the adcirc model the wrf model then runs for the single 1 5 km grid and provides 1 min outputs that at the end of the simulation are used as atmospheric forcing in the adcirc model the choice of starting the coawst model run 12 h after the latest hres analysis 12 utc based is principally driven by the need to produce at least a two day short term forecast in 24 h staring from 19 00 utc when the hres results are theoretically available also some spin up period is needed to adjust the physics of the models to the analysis or more generally the initial condition for the adrisc meteotsunami forecast component this spin up period is assumed to be 24 h for the coawst model basic module and 12 h for the offline coupling of wrf 1 5 km and adcirc nearshore module this means that only the last 48 h of the basic module run and the last 24 h of the nearshore module results are analyzed and published daily a conservative estimate of the running times of the different modules of the adrisc meteotsunami forecast component is as follow fig 1 1 h to download and format the ecmwf and medsea forecast fields 10 h to run the coawst model 20 min to downscale the wrf 3 km results to the 1 5 km grid and to produce the initial boundary conditions of the adcirc model from the roms 1 km results 6 h30 to run the wrf 1 5 km grid 10 min to generate the adcirc atmospheric forcing 3 h30 to run the adcirc model and 1 h30 to format and download locally the model surface results including 10 m wind 2 m air temperature air pressure sea temperature salinity ocean surface and barotropic currents and sea level at the end of every day the next 48 h hourly forecast surface results from the coawst run as well as the 15 min forecast surface results from wrf 1 5 km and adcirc simulations for the next day are downloaded in a database optimized for automatic storage and published at http www izor hr adrisc 2 3 available data of recorded meteotsunami events to properly evaluate the skills of the adrisc meteotsunami forecast component two important conditions had to be fulfilled first 1 to 5 min high resolution records of atmospheric pressure and sea level had to be available which is as mentioned previously not the atmospheric and or oceanographic standard and second the meteotsunami event had to be strong enough to be noticed by the public i e flooding of inhabited areas in the eastern adriatic these required observations only became available in recent years mostly due to an observational system which encompass a network of eight air pressure sensors split ražanj vrboska vela luka vis ancona ortona vieste and four tide gauges split stari grad vela luka and sobra installed in areas where either the generation or the amplification of meteotsunami are known to occur fig 2 in addition air pressure data is also provided by 1 the meteorological and hydrological service of the republic of croatia http meteo hr with high quality 1 min records at up to five locations of interest and 2 a non profit association of croatian amateur meteorologists crometeo https pljusak com karta php with 5 min records at 40 locations of interest concerning the sea level data 1 min records are provided by 1 the ioc sea level monitoring facility http www ioc sealevelmonitoring org map php at eight locations along the italian coast otranto vieste isole tremiti ortona st benedetto del tronto ancona venice and trieste 2 the hydrographic institute of the republic of croatia at four locations rovinj zadar ploče dubrovnik and 3 the institute of hydrometeorology and seismology of montenegro podgorica at two locations bar kotor all listed data are used for the adrisc skill assessment and the locations of the 48 pressure sensors in yellow and 19 tidal gauges in red are presented in fig 2 destructive meteotsunami waves are recurring events along the croatian coast with wave heights and periods documented by eyewitnesses since the early 20th century and collected in a catalogue by orlić 2015 however the proper monitoring of the eastern adriatic meteotsunami events only started a decade ago and only six well recorded events were available to carry out the evaluation of the models the first two events took place on the 25th and 26th of june 2014 and are well described by šepić et al 2016 on the 25th at least two different meteotsunami waves reached the croatian coast with reported 3 m and 2 5 m wave heights in vela luka and rijeka dubrovačka harbors respectively fig 3 and on the 26th a single 1 m height meteotsunami wave was witnessed in ston and pelješac channel summer 2017 was also a dynamic period in terms of meteotsunami events three tsunami like waves were generated and observed on the 28th of june in stari grad on the 1st of july in vrboska and on the 11th of july in the north eastern adriatic with the latter meteotsunami driven by the squall line of a fast moving storm finally the last event uncharacteristically generated in early spring happened on the 31st of march 2018 in stari grad as the adrisc meteotsunami forecast component started to be operational in march 2018 the first five events had thus to be simulated with conditions as close as possible to the operational setup for the atmospheric forcing the ecmwf hres operational model results are stored since 1985 and the configuration used for running the wrf model is identical to the one described in section 2 2 3 however for the ocean the mfs operational model results are not publicly available once the analysis or reanalysis results are produced practically it means that only reanalysis medsea results are available online for the 2014 simulations and that only analysis results can be used for the 2017 runs finally for the spring 2018 meteotsunami event the adrisc meteotsunami forecast component was already running operationally and both atmosphere and ocean were forced with real time forecast results for each of the six events only the last 24 h results of the coawst model and of the wrf adcirc offline coupling are analyzed and used for the statistical evaluation this strategy is used to conservatively determine whether or not the meteotsunami events would have been predicted in operational mode for all of the events a high pass filter with a 2 h cutoff period was applied to the 1 min spatial results of mean sea level msl pressure and sea level extracted from the offline coupling of wrf 1 5 km and adcirc in order to better visualize meteotsunami component of reproduced atmospheric and sea level time series examples of these filtered results are presented in fig 3 animations are provided as supplementary material and time series of measured and modelled signals are presented in vela luka and stari grad stations during the 28th of june 2017 event in fig 4 as the adrisc meteotsunami forecast component started to be operational in march 2018 the first five events had thus to be simulated with conditions as close as possible to the operational setup for the atmospheric forcing the ecmwf hres operational model results are stored since 1985 and the configuration used for running the wrf model is identical to the one described in section 2 2 3 however for the ocean the mfs operational model results are not publicly available once the analysis or reanalysis results are produced practically it means that only reanalysis medsea results are available online for the 2014 simulations and that only analysis results can be used for the 2017 runs finally for the spring 2018 meteotsunami event the adrisc meteotsunami forecast component was already running operationally and both atmosphere and ocean were forced with real time forecast results for each of the six events only the last 24 h results of the coawst model and of the wrf adcirc offline coupling are analyzed and used for the statistical evaluation this strategy is used to conservatively determine whether or not the meteotsunami events would have been predicted in operational mode for all of the events a high pass filter with a 2 h cutoff period was applied to the 1 min spatial results of mean sea level msl pressure and sea level extracted from the offline coupling of wrf 1 5 km and adcirc in order to better visualize meteotsunami component of reproduced atmospheric and sea level time series examples of these filtered results are presented in fig 3 animations are provided as supplementary material and time series of measured and modelled signals are presented in vela luka and stari grad stations during the 28th of june 2017 event in fig 4 in fig 3 wave patterns can be seen on the filtered pressure results for the presented 2014 2017 and 2018 events the characteristics of the patterns wave length period amplitude width etc highly depend on the meteotsunami event the filtered sea level results also present wave patterns but due to the effects of the bathymetry and geomorphology of the coast including reflection they are less coherent than in the atmosphere in addition fig 4 illustrates how the mean sea level pressure and sea level 1 min station data from both measurements and models are high pass filtered with a 2 h cutoff period in order to better analyze the high frequency signals during the meteotsunami events the aim of this study is not to describe in depth the different events but to assess the skill of the models used to forecast meteotsunamis the dynamics of each event genesis propagation wave characteristics in the atmosphere and the ocean will thus not be presented in this paper 3 skill assessment of the adrisc meteotsunami forecast component 3 1 statistical analysis the evaluation of the different models used in the adrisc modelling suite is carried out only for the msl air pressure extracted from the wrf results and for the sea levels from the roms adcirc runs it follows three different steps 1 the general performance of the models is assessed with taylor diagrams presenting the analysis of normalized standard deviations hereafter referred as model to measurement standard deviation ratio or sdr and cross correlation cc of the 1 min time series of unfiltered data models vs measurements 2 the model capability to represent high frequency signals characteristic of meteotsunami events is presented with a quantile distribution analysis of the high pass filtered data 2 h cutoff period presented in q q plots and 3 as the frequency space is the best way to analyze generation and amplification of meteotsunamis the goodness of fit of the different models defined as the normalized root mean square error nrmse is derived from the complex frequency response complex result of the fast fourier transform or fft decomposition both filtered and unfiltered of the data in addition 1 as the roms 3 km grid is too coarse to properly represent the harbor resonance the performance of this grid is not presented nor discussed and 2 the high frequency wrf 15 km time series extracted at the locations of the pressure sensor stations are not kept in operational mode and thus are not available for the 31st of march 2018 event the statistics used for the taylor diagrams figs 5 and 6 are derived from 1440 samples for each of the six 24 h events concerning the wrf model results using higher resolution does not seem to clearly improve neither the cross correlation cc nor the standard deviation ratio sdr which shows that the air pressure signal is probably dominated by hourly variations well represented even with the 15 km grid however more pronounced differences are seen between the roms 1 km and adcirc model results in addition events with the best results concerning the atmospheric pressure do not necessarily have the best results for sea level and vice versa in more details on the 25th of june 2014 half of the pressure stations seem to capture properly the event cc 0 6 and 0 5 sdr 1 5 while the other half do not perform well cc 0 5 and sdr 1 5 for the sea level stations the roms model 0 5 cc 0 9 and 0 75 sdr 0 9 seems to be more accurate than the adcirc model 0 5 cc 0 75 and 0 1 sdr 0 75 on the 26th of june 2014 the majority of the pressure stations present really high cross correlation 0 5 cc 0 75 but the standard deviation ratio is quite spread 0 15 sdr 0 75 while for the sea level stations adcirc 0 5 cc 0 95 and 0 15 sdr 1 15 and roms 1 km 0 6 cc 0 9 and 0 5 sdr 1 15 are quite accurate on the 28th of june 2017 the wrf model performs well 0 75 cc 0 95 and 0 5 sdr 1 5 while the accuracy of the adcirc 0 5 cc 0 9 and 0 25 sdr 1 5 and roms 1 km 0 45 cc 0 9 and 0 5 sdr 1 75 models highly depends on the sea level stations the 1st of july 2017 is the event with the poorest performances for all the models the wrf results are extremely spread 0 cc 0 85 and 0 5 sdr 2 5 while roms and adcirc models have really low accuracy cc 0 5 and or sdr 0 5 for most of the stations on the 11th of july 2017 the wrf model has a consistent standard deviation ratio 0 25 sdr 1 15 but only two third of the stations have a good cross correlation 0 5 cc 0 85 concerning the sea level stations the cross correlation is higher than 0 5 for both models and standard deviation ratios are also reasonable roms 1 sdr 1 75 and adcirc 0 5 sdr 2 finally the best performance of the wrf model is obtained for the event of spring 2018 cc 0 9 and 0 5 sdr 1 while the ocean models generally show good accuracy with roms 0 5 cc 0 7 and 0 5 sdr 1 6 and adcirc 0 45 cc 0 95 and 0 75 sdr 2 15 the unfiltered model results seem to generally be in good agreement with the measurements however as they are dominated by the tides for the ocean models and by daily to hourly variations for the air pressure they cannot properly show how well the models reproduce meteotsunamis in the eastern adriatic comparisons of the high pass filtered signals with 2 h cutoff period of msl air pressure and sea level between measurements and models are thus presented with q q plots in figs 7 and 8 overall for the wrf filtered results fig 7 the lines joining the first and third quartiles of model vs observation distributions highlight that the higher the wrf model resolution the closer the model distribution to the measurements implying that higher resolution models can better reproduce pressure disturbances for ocean models fig 8 these same lines clearly show that the distributions of the filtered roms results are closer to the observations than the ones of the filtered adcirc results the filtered results are thus not following the general behavior presented in the taylor plots figs 5 and 6 which didn t systematically show a better performance for neither the wrf 1 5 km nor the adcirc models in addition for the 2014 and first two 2017 events figs 7 and 8 panels a b d and e a good agreement between filtered results from wrf and roms adcirc models is observed the closer are the filtered air pressures to the observations the closer are sea levels to the measurements for the 11th of july 2017 the model result distributions of neither the filtered air pressures nor the filtered sea levels can reproduce the distributions of the observations thus this meteotsunami event seems to not be captured by the adrisc meteotsunami forecast component for the 2018 event the filtered wrf results are in good agreement with the observations while the filtered sea level model results are about 3 times nearly 6 times for the adcirc results smaller than the measured ones although it appears that the amplitude of the atmospheric disturbances is well caught by the wrf model it is possible that a stronger air pressure disturbance of limited dimensions not caught by our measurement network and not reproduced by the model propagated over the area and generated the measured meteotsunami the q q plots of the high pass filtered data models vs measurements clearly demonstrate the link between atmospheric disturbances and meteotsunami generation but their main limitation is that the correlation of the compared signals is not taken into account as only the quantile distributions are compared and they only give a partial picture of the capability of the models to reproduce the studied meteotsunamis the final analysis of the comparison between time series of models and measurements is carried out by generating the complex frequency response of the signals the fft decomposition of a signal s is given by s fft which is hereafter referred as the complex frequency response both for the entire range of frequencies and the high frequencies only maximum period of 2 h the goodness of fit or normalized root mean square error nrmse 100 1 o fft m fft o fft o fft is estimated between the complex frequency response of the models m fft and the observations o fft basing the goodness of fit of the models on the comparison of complex frequency responses is probably the best way to capture the meteotsunami events but leads to poor accuracy in particular for the filtered results due to uncorrelated signals in the frequency space as multimodal distributions are recurrent in geoscience violin plots hintze and nelson 1998 based on box plots but including the full distribution of the data via a kernel density estimation are used to present the statistics of the model goodness of fit the shape as well as the median horizontal lines of each distribution are presented 1 for the six different events in fig 9 and 2 for all the stations in fig 10 as the q q plot analysis demonstrated that the wrf coarse grid poorly reproduce the high resolution processes the wfr 15 km nrmse is not presented for both wrf 3 km and 1 5 km models the median of air pressure nrmse reaches at least 99 fig 9a for all the events with distributions strongly negatively skewed and a second mode found around 95 median values of both roms 1 km and adcirc sea level nrmse are varying between 2 and 27 5 fig 9c depending on the events with distributions positively skewed and second or third modes found between 50 and 75 in addition the adcirc model seems to slightly perform better than the roms model even if for the two first events of 2014 outliers with values below 50 are seen in the adcirc sea level distributions while the roms nrmse distributions stop around 0 for the filtered data the wrf model nrmse fig 9b is largely decreased with a median varying between 9 and 65 while the adcirc roms model accuracy fig 9d is only slightly changed with median values between 5 and 13 5 the distributions of the goodness of fit of the filtered model results are mostly close to normal although for the four first events the filtered air pressure distributions are negatively skewed towards 100 finally for the filtered sea level results the roms model generally seems to be less accurate than the adcirc model which is in contradiction with the results presented in the q q plots fig 8 this reveals that the roms model is likely to generate strong unrealistic high frequency perturbations while the adcirc model is not capable to fully reproduce the amplitude of the observed perturbations in order to have a better idea of the spatial distribution of the model performances keeping in mind that the statistics for each station are derived for a maximum of six events most often less because data is not available at all the stations for all events the distributions of the model goodness of fit are presented fig 10 at each station for the air pressure the same behavior as seen in fig 9 is observed median varying between 92 and 99 for the unfiltered signals and between 2 and 45 for the high pass filtered results however concerning the sea level results the station by station analysis reveals that the performance of the roms 1 km and adcirc models is highly dependent of the location the roms model seems to better performs along the italian coastline st benedetto del tronto ortona isole tremiti and vieste stations and the adcirc model along the croatian and montenegrin ones split harbor vela luka sobra ploče dubrovnik bar and kotor stations this can be easily explained by the fact that the resolution of the adcirc model is at least 2 km outside of the croatian waters vs 1 km for the roms model where igws are formed and start to propagate but up to 10 m in areas where meteotsunami amplification is known to occur along the eastern side of the adriatic sea the assumption that sea elevation of the modelled meteotsunamis highly depends on the representation of the geomorphology of nearshore studied areas is thus confirmed summarily the statistical analysis of the adrisc meteotsunami forecast component model performances highlights the difficulty to reproduce correctly both the atmospheric disturbances and the associated proudman resonance and nearshore amplification responsible for meteotsunami generation and propagation it also shows the importance of using different kind of complementary analysis taylor diagrams q q plots goodness of fit of the complex frequency responses etc in order to better understand the capability of the models to reproduce both the model general behavior and the high frequency studied signals 3 2 analysis of the extremes for meteotsunami forecast the analysis of maximum elevations is critical this is indeed the final product of the modelling suite which allows warming the residents of the coastal areas of a potential flood it is also unfortunately the model parameter with the highest associated uncertainty due to the precision of the bathymetry at the nearshore areas of interest the location of the generated air pressure disturbances and the generation of the proudman and harbor resonances linked to the capacity to reproduce the exact speed amplitude and period of the air pressure disturbances in addition due to the extreme nature of meteotsunami events and the practical constraints associated with setting up measurement stations in harbors no observation is available in the precise locations where the meteotsunami amplification is maximum given these limitations fig 11 is showing the scatter plot models vs measurements of the maximum elevations extracted from the high pass filtered signals for each of the six events and at all the available sea level stations maximum 19 per event presented in fig 2 table 1 summarizes the statistics associated with the linear fits of the roms and adcirc model results as the results seem to present different behavior depending on the amplitude of the events the analysis of the maximum elevations is done separately for observations above and below the 0 2 m threshold for observed maximum elevations below 0 2 m the adcirc results seem to be in good agreement with the measurements even if adcirc tends to systematically underestimate them the coefficient of the linear fit is of 0 66 0 05 associated with a small rmse of 0 04 the roms 1 km results however are much more scattered strong over and under estimations but in average better fit to the measurements linear regression coefficient of 0 91 0 13 with a larger rmse of 0 09 similar results are found for observations above 0 2 m except that both models show an even larger underestimation linear coefficient of 0 33 0 05 for adcirc and 0 68 0 08 for roms associated with larger rmse 0 06 for adcirc and 0 11 for roms the fact that the roms model has the tendency to generate strong unrealistic sea level oscillations and that the adcirc model tends to underestimate the amplitude of these oscillations is thus confirmed by this simple analysis of the maximum elevations in order to better understand the capability of the adrisc meteotsunami forecast component to reproduce the six studied meteotsunami waves the spatial evolution of the minimum air pressure and the maximum sea level extracted respectively from the 1 min high pass filtered wrf 1 5 km and adcirc results is presented for each event figs 12 to 17 as can be seen in figs 12a 14a 15a and 17a during meteotsunami events the wrf model generates several atmospheric distributions in blue and white at different locations of the domain similarly for each event different coastal locations are affected by potentially different meteotsunami waves fig 12b 14b 15b and 17b as seen in the statistical analysis particularly figs 7 and 8 both atmospheric and ocean models present reasonable skills concerning meteotsunami modelling for four different events 25th of june 2014 26th of june 2014 28th of june 2017 and 1st of july 2017 for the 25th and 26th of june 2014 events the spatial analysis of the minimum filtered mean sea level air pressure figs 12a and 13a shows that the wrf model produces 1 various air pressure disturbances of limited cross propagation dimensions between 42 8 n and 43 1 n of latitude for the 25th of june and 2 a unique atmospheric disturbance below 42 8 n latitude for the 26th of june which are both in good agreement with what has been observed šepić et al 2016 concerning the associated maximum filtered sea elevation generated with the adcirc model figs 12b and 13b the flooding observed at various locations šepić et al 2016 are reproduced vela luka 1 15 m modelled vs 1 5 m observed rijeka dubrovačka 0 6 m modelled vs 1 25 m observed stari grad 0 45 m modelled vs 0 5 m observed and vrboska 0 35 m modelled vs 0 75 m observed for the 25th of june and ston harbor 0 35 m modelled vs 0 5 m observed for the 26th of june during the 26th of june event extreme water levels were also modelled in rijeka dubrovačka 0 5 m but not reported thus the modelled atmospheric disturbance is probably slightly shifted south compared to the observed one in addition as the sea elevation observations are a qualitative estimate provided by eyewitnesses they include tidal and other effects therefore it is expected that eyewitness observations have higher values than the presented filtered and thus detided sea elevation results the adcirc model has thus correctly captured spatial distribution and amplitudes of the meteotsunami waves observed during these two events however for the two first 2017 events figs 14a and 15a the wrf model is less successful in reproducing the location of the atmospheric pressure fields as the maximum filtered sea elevation of the adcirc model figs 14b and 15b reaches only 0 25 m in stari grad and 0 55 m in vrboska where flooding were respectively reported during the 28th of june and the 1st of july as documented with an amateur video available at https www youtube com watch v hxp4jidoubm as some amplifications occur in mali ston bay for the 28th of june and in vela luka for the 1st of july where no flooding was reported the location of the pressure disturbances modelled by wrf are probably not well reproduced for these events 1 too south 43 n latitude instead of 43 2 n to reach stari grad the 28th of june and 2 too south below 43 n and or too west west of 16 6 e to properly generate the observed meteotsunami in vrboska the 1st of july for the 11th of july 2017 event which happened in the northern adriatic the statistical analysis particularly figs 7 and 8 shows that neither the wrf models nor the roms and adcirc models could reproduced the observed meteotsunami dynamics this event was driven by the squall line of a storm https www youtube com watch v iu63d6i lc which was captured by the wrf 1 5 km model but shifted in location the modelled pressure disturbances fig 16a are indeed located too far north above 44 8 n instead of 44 6 n of latitude to be able to generate meteotsunami waves in mali lošinj bay which was flooded during this event and the adcirc model does not reproduce the observed sea elevation fig 16b finally for the 31st march 2018 event fig 17 modelled atmospheric pressure disturbances are too weak above 80 pa and located far too south below 42 9 n instead of 43 2 n of latitude to generate a meteotsunami in stari grad where flooding was reported https www istramet hr vijesti video meteoroloski tsunami pogodio stari grad na hvaru however as seen in figs 7 and 9 the wrf models reproduce the filtered mean sea level air pressure measured by the network of 48 pressure sensors because the disturbances are well reproduced inland but not at sea in summary the analysis of the extremes highlights the major difficulty of modelling meteotsunami to be able to reproduce the right location and the right intensity of the air pressure disturbance in the atmosphere in order to generate the correct proudman and harbor resonances in the ocean 4 discussion and conclusions meteotsunami forecast is based on the assumption that numerical models are capable of reproducing high frequency disturbances gravity waves in the atmosphere and resonant processes in the ocean in their review article plougonven and zhang 2014 highlighted the challenges of modelling gravity waves generated by jets and fronts and conclude that it will likely be impossible to draw a simple deterministic and convincing picture of the way gravity waves are generated from these processes in a complex flow environment such as a cold front within a baroclinic wave for the ocean proudman and topographic resonances are the main generation and amplification process of long oceanic waves monserrat et al 2006 vennell 2010 due to spatial discretization and lack of precise bathymetric data it is unlikely that present state of the art ocean numerical models can accurately represent the ocean and coast complex geomorphology responsible for the meteotsunami wave generation and amplification which is particularly true for the middle and southern parts of the eastern adriatic however given these overwhelming limitations the adrisc meteotsunami forecast component is showing skills in fair reproduction of meteotsunami events which might be used for operational forecasting qualitatively speaking about the model performance the presence of atmospheric disturbances is captured by the wrf model fig 7 even if the timing precise location direction and amplitude of these high frequency waves may not be well represented figs 9b and 10b moreover topographic amplification is reproduced in the harbors where meteotsunamis are known to occur figs 12b to 17b quantitatively speaking the capacity of both atmospheric and ocean adrisc models to reproduce meteotsunamis is far from being satisfactory with a goodness of fit lower than 65 and 13 5 for wrf and roms adcirc high frequency results respectively so can meteotsunami events be deterministically reproduced and forecasted given the results of this evaluation study based on available state of the art atmospheric and ocean models the answer is not for all events and not accurately however keeping in mind the few events studied the scattered spatial distribution of the observations used for the model evaluation and the inherent difficulty of modelling any high frequency signal in geosciences this study is presenting encouraging results and is a first step towards a holistic approach for meteotsunami hazard assessment indeed if it is unrealistic to only rely on deterministic forecast to design early warning systems for extreme events model results can still be used 1 to apply pattern recognition algorithms to the high pass filtered msl pressure results in order to detect disturbances likely to generate meteotsunamis then 2 to extract wave parameters from these patterns such as speed period amplitude etc and finally 3 to use a stochastic approach to estimate the meteotsunami hazard linked to each modelled pressure disturbance such an approach is currently under development within the croatian meteotsunami early warning system in conclusion generation and propagation of meteotsunamis is probably at the edge of what present state of the art numerical models can reproduce in particular it requires 1 to carefully check the numerical stability of the atmospheric model which should be set up to handle internal gravity waves i e high spatial resolution and reduced time step 2 to use accurate orography bathymetry and coastline data in high resolution atmospheric and ocean models and 3 to evaluate the model high frequency results with various statistical tools in order to draw a clear picture of the model skills in addition the analysis of the msl pressure and sea elevation filtered results reveals some contradictions with the assumption that the more accurately the atmospheric disturbance is modelled the closest to reality the simulated meteotsunami is for example the best performance of the wrf model is reached for the spring 2018 event median of 65 in fig 9 b when the worst performance of the roms adcirc models median of about 2 in fig 9 d is obtained similarly the best results of maximum sea elevation were simulated for the 25th of june 2014 event fig 12 b when the worst performance of the atmospheric models was obtained median of 9 in fig 9 b this is not per se a proof that the assumption is incorrect but more that 1 the observation network is not dense enough to cover the places where most probably the wrf model is failing during the spring 2018 event i e it is likely that the atmospheric disturbance which generated the meteotsunami was not captured by either the measuring network nor the wrf model 2 the atmospheric disturbances simulated by the wrf model probably have the right location speed and amplitude but are not correlated in the frequency space with the observations due to wrong periods of resonance e g for the 25th of june 2014 event and 3 a small failure in reproduction of atmospheric disturbance parameters speed direction and intensity results in a large misrepresentation of modelled meteotsunami waves because the generation of meteotsunami ocean waves is extremely sensitive to the speed of atmospheric disturbances vilibić et al 2008 a detailed process analysis including genesis propagation amplification and timing of the extrema of the different meteotsunami waves of the six presented events is going to be performed in order to better understand why the models are failing and how to improve their overall performances in addition with the observation network recently installed and the adrisc meteotsunami forecast component being operational since march 2018 more data about meteotsunamis is expected to be collected in the next few years this will hopefully lead to better statistical analyses of the adrisc model skills finally the perspective of including meteotsunamis as sources of extreme water levels in long term modelling studies will contribute to our understanding of the variability of these recurrent but rare events by building a larger database of simulated events the following are the supplementary data related to this article supplementary video 1 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 25th and 26th of june 2014 meteotsunami events supplementary video 1 supplementary video 2 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 28th of june 2017 meteotsunami event supplementary video 2 supplementary video 3 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 1st of july 2017 meteotsunami event supplementary video 3 supplementary video 4 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 11th of july 2017 meteotsunami event supplementary video 4 supplementary video 5 animation of the high pass filtered with a 2 h cutoff period wrf 1 5 km msl pressure and adcirc sea level results for the 31st of march 2018 meteotsunami event supplementary video 5 supplementary data to this article can be found online at https doi org 10 1016 j ocemod 2019 02 003 acknowledgements we would like to thank all organisations that kindly provided us observations used in this study unesco ioc paris www ioc sealevelmonitoring org hydrographic institute of the republic of croatia split institute of oceanography and fisheries split institute of hydrometeorology and seismology of montenegro podgorica at two locations bar kotor and crometeo pljusak www pljusak com acknowledgement is also made for the support of the ecmwf staff in particular xavier abellan as well as for ecmwf s computing and archive facilities used in this research which has been supported by projects messi ukf grant 25 15 adios croatian science foundation grant ip 2016 06 1955 and ecmwf special project the adriatic decadal and inter annual oscillations modelling component finally we acknowledge the comments raised by two anonymous reviewers which greatly helped to improve the quality of the manuscript appendix a typical configuration of many ocean models running in the adriatic sea imposes a 10 m minimum depth instead of the 2 m used in the adrisc modelling suite however about 2 of the 3 km and 1 km ocean grids of the adrisc basic module have depths below 10 m which means that these shallow areas located along the coastline are not negligible and can influence the final model results unfortunately a consequence may be a creation of unrealistic gradients of surface temperature between the shallow areas and the remaining of the ocean domain in most of the places these spatial temperature gradients have the tendency to grow when coupled with the wrf model as properly representing the bathymetry of the shallow areas is important in the context of nearshore and more particularly meteotsunami studies a balance between accuracy of the bathymetry and the surface temperature of the ocean models had to be found and the dq dsst procedure was adopted in the adrisc modelling suite as described in combes and matano 2014 the heat flux derived from the wrf 3 km model fields and calculated within the roms model includes a tendency restoring term to the medsea daily sea surface temperature sst medsea such as q modified q wrf dqdsst ρ 0 c p sst roms sst medsea with q wrf the heat flux derived from the wrf 3 km model fields only and dqdsst the kinetic surface net heat flux sensitivity to sst medsea defined as dqdsst 4 σ sst medsea 3 ρ air c pair c h u ρ air c e 2501000 2370 t air 273 16 u 2353 ln 10 q air sst medsea 2 where σ 5 67 10 8 w m 2 k 4 is the stefan boltzmann constant c pair 1004 67 j kg 1 k 1 is the specific heat of the atmosphere c h 0 66 10 3 is the sensible heat transfer non dimensional coefficient c e 1 15 10 3 is the latent heat transfer non dimensional coefficient and ρ 0 1025 0 kg m 3 is the reference seawater density and c p 3985 j kg 1 k 1 is the specific heat of seawater as defined in roms model the surface wind speed u the surface air temperature t air the atmospheric density ρ air and the surface specific humidity q air are derived from the wrf 3 km fields this kind of correction has been used in previous studies and typical values of dq dsst are around 30 w m 2 k 1 in the south china sea tested in roms model zhu et al 2016 and 40 w m 2 k 1 in the gulf of lion mediterranean sea tested in nemomed12 model escudier 2015 two examples of the spatial and temporal variations of the daily dq dsst corrections are presented for a summer 25th of june 2014 and a spring 31st of march 2018 period in fig a1 the daily mean and variations are the average value and the standard deviation of the dq dsst correction respectively calculated over a 24 h period fig a1 highlights that the calculated dq dsst is 1 small in average between 7 and 5 w m 2 k 1 in comparison to the correction applied in the gulf of lion 2 quite constant during the daily calculations daily variations below 0 5 w m 2 k 1 mostly due to the use of daily medsea sst and 3 generally stronger in the croatian coastal area located between 42 n and 43 5 n characterized by extremely clear waters the biggest difference between the summer and winter periods presented in fig a1 can be seen in the northern part of the adriatic up to 1 w m 2 k 1 which is a shallow area with depths below 50 m strongly influenced by the discharge of the po river the dq dsst correction being small and the sst fields from medsea assimilating available remote sensing products in the adriatic reduce the possibility for propagation of sst errors from the medsea results to the adrisc modelling suite simulations fig a1 daily mean and daily variability i e standard deviation of the dq dsst correction applied in summer during the 25th of june 2014 and in winter during the 31st of march 2018 fig a1 
24053,a theoretical model for the interaction among surface gravity waves frazil pancake sea ice and currents in a marginal ice zone miz is developed and is implemented into a free surface terrain following oceanic model the regional oceanic modeling system roms the wave model is a wentzel kramers brillouin wkb model with wave refraction and dissipation the sea ice model includes equations for sea ice mass and sea ice momentum wave energy is damped by sea ice and the ice is accelerated by wave radiation stress convergence the ocean ice interfacial stress accelerates the currents and mixes the oceanic surface boundary layer vertically the effects of waves on the ocean are represented by conservative wave averaged vortex forces and material advection by stokes drift the model is configured to simulate obliquely incident waves impinging on a marginal ice zone over an otherwise quiescent ocean the wave driven ice edge jet is unstable mesoscale eddies with a typical diameter of 20 km consistent with observations are generated the oceanic eddy kinetic energy eke can be strengthened by increasing the amount of energy transferred into the mean along edge current by increasing either the incident wave amplitude a physical variable or the wave damping rate by ice a tunable parameter eke also increases when the mixed layer depth decreases keywords wave ice interaction mesoscale eddies barotropic instability 1 introduction the marginal ice zone miz characterized by partial ice cover is the transition zone between the open ocean and the pack ice zone johannessen et al 1987 kohout and meylan 2008 it is typically 100 200 km wide häkkinen 1986 and can extend for more than 200 km under favorable atmospheric and oceanic conditions such as in the weddell sea lange et al 1989 wadhams and holt 1991 in the miz the presence of ice floes and the proximity to the open ocean substantially modify the dynamics of both sides of the ocean atmosphere interface leading to some distinct ocean flows at the ice edge such as upwelling eddies and mixing important to this study is the role of ice floes on the ocean atmosphere momentum flux and on ocean surface gravity waves the momentum flux from the atmosphere to the ocean is more efficient via ice floes than directly through the ocean atmosphere interface leading to a differential momentum flux gradient across the ice edge moreover surface gravity waves are dissipated and scattered by ice floes resulting in the acceleration of the ice floes and the underlying currents the miz is characterized by strong eddy activities whose signature can easily be detected in synthetic aperture radar images and in situ observations johannessen et al 1987 dumont et al 2011 it was observed that arctic miz eddies are mostly cyclonic with a diameter of 5 to 60 km and a maximum orbital velocity of 0 5 0 7 m s johannessen and johannessen 1983 johannessen et al 1987 three mechanisms have been proposed for the formation of miz eddies first miz eddies form due to the vorticity perturbation associated with topography häkkinen 1987b second miz eddies can be driven directly by the momentum flux curl across the ice edge third miz eddies can arise from the baroclinic and or barotropic instability of miz currents the three mechanisms for eddy generation and subsequent eddy evolution have been partially investigated using numerical models the effect of topography in eddy generation first mechanism was demonstrated by häkkinen 1987b with a two layer ocean model the second mechanism was analyzed by häkkinen 1986 and liu et al 1993 häkkinen 1986 showed that eddies spin up by a uniform wind in the presence of a wavy ice edge although the wind is the same across the ice edge the atmospheric momentum flux to the ocean is different because momentum transfer is more efficient via ice in the miz than directly through the ocean atmosphere interface in the open ocean the effect of the miz current instability on eddy formation third mechanism was investigated by manucharyan and thompson 2017 in that study an unstable ice edge current was driven by a strong cross ice edge surface fresh water flux gradient an unstable current in the miz can also be driven exclusively by waves entering the miz as is the focus of the present study surface gravity waves also play important roles in eddy formation liu et al 1993 demonstrated that eddy spin up by the second mechanism is accelerated by the addition of a wave field entering the miz waves are dissipated after entering the miz the convergence of radiation stress associated with wave dissipation accelerates the sea ice and the underlying ocean enhancing the vorticity driven by the differential cross ice edge wind stress the radiation stress convergence is largest at the ice edge liu et al 1993 observed that an along ice edge jet develops when waves are included although they were not able to study the subsequent jet evolution and eddy formation through current instability in liu et al 1993 the wave forcing was simply parameterized with a constant wave decay rate from the ice edge but other wave processes including propagation and refraction and their coupling with the ice and ocean were neglected wave propagation and refraction occur within the ice field while being dissipated which indicates the need to replace parameterized waves with an explicit wave model a realistic simulation of miz currents requires the coupling of a sea ice model an ocean circulation model and a wave model surface gravity waves entering the miz can also drive unstable currents at the ice edge and spin up eddies by the third mechanism the purpose of this study is to demonstrate how wave ice ocean interactions can lead to the generation of mesoscale eddies with only an incident wave field from a simple initial state with no ocean or ice motion and a straight ice edge in deep water this phenomenon is analogous to the generation of near shore currents by depth induced breaking of obliquely incident waves longuet higgins 1970 except that here the sea ice is the cause of wave dissipation and momentum exchange we set up a wave ice ocean model by relying primarily on previous formulations liu and mollo christensen 1988 in the regional oceanic modeling system roms model wave effects on currents are modeled by wave phase averaged vortex forces proportional to stokes drift velocity of the waves and the material advection due to stokes drift mcwilliams et al 2004 uchiyama et al 2010 additional nonconservative mixing occurs where waves break and at the bottom in the wentzel kramers brillouin wkb model waves refract due to current shear and variable oceanic depth and they dissipate due to bottom drag and wave breaking uchiyama et al 2010 however we derive a new wave dispersion relation that generalizes the results of wadhams and holt 1991 by including oceanic currents a modified wkb model is proposed that combines current and ice mass refraction with dissipation within the ice field the ocean ice interfacial stress formula in the model also includes the stokes drift effect in the interfacial velocity difference this study focuses on a common form of sea ice in the miz i e pancake ice which is usually a few meters in diameter and more than tens of centimeters thick wadhams et al 2002 sea ice in the miz can also be in the form of frazil ice which is a slurry of spicules although this is not considered in this study the rest of paper is arranged as follows section 2 introduces the formulas used for the wave and ice evolution section 3 describes their application to the miz and the experiment settings section 4 analyzes the current and eddy genesis processes in the numerical simulations section 5 provides a summary and identifies future research questions and model applications 2 model description a coupled ocean wave ice model built upon a coupled ocean wave model uchiyama et al 2010 in the framework of the regional oceanic modeling system roms shchepetkin and mcwilliams 2005 is employed in this study the three model components are described in the following three subsections 2 1 surface gravity waves sea ice significantly alters the evolution of ocean surface gravity waves when waves arrive at the ice edge they are altered by reflection and or transmission at the edge and their wavenumber and amplitude further evolve within the ice zone wadhams and holt 1991 bennetts and squire 2012 squire and montiel 2008 collins et al 2017 williams et al 2017 usually the wavenumber increases after wave refraction which means that the wavenumber is larger in the ice zone and it is determined by the ice mass and the incident wave frequency when the incident wave frequency is above a critical value total reflection occurs when the frequency is smaller than the critical value transmission co occurs with reflection and its importance increases with decreasing frequency when waves propagate into the ice field they dissipate rather quickly weber 1987 wang and shen 2010 meylan et al 2014 mosig et al 2015 ardhuin et al 2016 tolman and the wavewatch iii development group 2016 wave energy decays with a typical e folding distance of 1 20 km as a result most wave ice interactions occur near the ice edge with large waves significant wave height 3 m and low ice fraction 20 wave energy decays linearly with distance from the ice edge and can propagate more than 100 km into miz kohout et al 2014 this scenario is not considered in the current study for a deep water monochromatic wave refracted due to interactions with the ice edge and oceanic current the dispersion relationship can be generalized from wadhams and holt 1991 more details are shown in appendix b1 by adding horizontal currents 1 ω u k b 0 k v i k g k 1 b 0 k in eq 1 ω is the doppler shifted wave frequency u u v is the oceanic current averaged over the depths where the wave orbital motions are active 40 50 m in this study k k x k y is the wavenumber vector with k being its amplitude g is the acceleration of gravity b 0 ρ i ρ w m i where m i a i d i is the ice mass ai is the fraction of sea covered by ice and di is the ice thickness ρi and ρw are the ice and ocean densities respectively and v i u i v i is the ice velocity the critical ice ocean reflection frequency above which incident waves are completely reflected at the ice edge is calculated as wadhams and holt 1991 2 ω c 2 ρ w g ρ i a i d i in this study the critical ice ocean reflection frequency is of the order 1 hz and is much larger than the frequency of the incident swell order 0 1 hz total wave reflection is therefore neglected the dispersion relation functionally expressed as ω ω k x is solved using the ray theory for propagation in a slowly varying medium together with the wave action dissipation law the assumption of slow variations is valid for the horizontal scale of the current and ice mass relative to the wavelength and for the temporal scale of the changes in u and mi relative to the relevant wave propagation time the consequent spectrum peak wkb wave refraction model uchiyama et al 2010 is as follows more details can be found in appendix b 2 eqs b 26 b 38 3 k t c g k ω x k u k ρ i ρ w gk 2 1 b 0 k 3 2 m i 4 λ t c g λ 1 a i ϵ b ω 0 a i α c g λ where is the horizontal gradient operator λ e w ω 0 is the wave action ew is the depth integrated wave energy density ω 0 ω u k is the wave intrinsic frequency c g ω k is the wave group velocity vector with cg being its amplitude ϵ b is the wave dissipation rate due to breaking in the open water and α is the wave energy spatial decay rate as it propagates through the ice field in the idealized problem in section 3 we neglect both local wind generated wave and open water wave breaking and use a finite α the choice of α will be discussed in section 4 1 2 2 sea ice a sea ice dynamical model predicts the movement of the sea ice with winds ocean currents and the material strength of the ice as inputs hunke and dukowicz 1997 li et al 2014b wind stress is one of the primary drivers of ice motion and its effect on ice is often greater than its direct effect on the ocean røed and o brien 1983 oceanic currents act on sea ice by ocean ice interfacial stress and by a horizontal pressure gradient when the sea surface is tilted the interfacial stress is related to the velocity difference between the ice movement and surface ocean currents and the momentum transfer is usually from the ice to the ocean mcphee 1975 internal to the sea ice are stresses that resist ice convergence and a rigidity that resists deformation and divergence the importance of these factors depends on the material properties of the ice field previous studies have developed different rheological laws for ice the viscous plastic model vp is a commonly used rheology hibler 1979 the elastic viscous plastic model evp hunke and dukowicz 1997 is a computationally efficient solver for the vp rheology since the vp model does not give a good representaion of ice drift and deformation rampal et al 2008 more recently the elasto brittle rampal et al 2016 and maxwell elasto brittle dansereau et al 2017 rheologies that perform much better are being developed however at low ice concentrations the internal stress is very small based on all rheologies which means that the ice moves more freely a single layer ice model liu et al 1993 hunke and dukowicz 1997 is used in this study the model assumes that the thickness of pancake ice under the waterline is no more than a few meters and the thickness of frazil ice is even smaller ice thermodynamics and snow processes are also neglected in this idealized process study in reality ice growth may be nonnegligible during the eddy genesis process which lasts for tens of days while the focus of this study is the effect of long incident waves that do not break pancake ice ice floe breakup due to rapid ice melting is possible under the influence of breaking waves or storm conditions the ice momentum and mass equations are as follows 5 ρ i m i u i t u i u i x v i u i y ρ i m i g η x f v i a i τ a i x τ w i x f i x a i f r x 6 ρ i m i v i t u i v i x v i v i y ρ i m i g η y f u i a i τ a i y τ w i y f i y a i f r y 7 a i t a i u i x a i v i y 0 0 a i 1 8 m i t m i u i x m i v i y 0 where ui vi is the ice velocity vector f is the coriolis frequency τai is the wind stress over the ice τwi is the interfacial stress between the ocean and the ice f i is the ice internal stress and f r is the wave radiation stress divergence when the ice fraction ai is less than 1 the ice thickness di does not change when ai locally equals 1 di increases if there is further ice mass convergence as discussed in the beginning of this section several theories have been developed for the internal stress fi in the miz since there is no ice flexure e 0 in the frazil pancake ice the elastic part is invalid hunke and dukowicz 1997 and thus the results from the evp model and the vp model are similar we follow häkkinen 1987a which is similar to the vp model but with a simpler formulation moreover in this rheology model ice internal stress is negligible when divergence occurs in the ice zone neglecting open ocean wave breaking a wave radiation stress gradient only occurs due to the dissipation of waves propagating through sea ice dingemans et al 1987 9 a i f r ϵ k ω ϵ b ϵ i k ω a i α e w c g k ω where ϵ i a i α e w c g is the wave energy dissipation rate by wave ice interaction α is the ice spatial energy dissipation rate and ϵ b is assumed to be zero in this study 2 3 ocean the oceanic component of the coupled system is from the regional oceanic modeling system roms e g shchepetkin and mcwilliams 2005 it solves the three dimensional hydrostatic primitive equations in a vertical hybrid z sigma grid lemarié et al 2012 with horizontal curvilinear coordinates the interaction between surface gravity waves and currents is based on an asymptotic wave averaged theory mcwilliams et al 2004 lane et al 2007 vertical mixing in the top and bottom boundary layers uses the k profile parameterization kpp large et al 1994 which depends on the surface wind stress the surface buoyancy flux the oceanic current the coriolis parameter and the ocean density structure in the presence of sea ice the total surface stress is the sum of the stress between the atmosphere and the ocean τaw and the stress between the sea ice and the ocean τwi in this study the surface buoyancy flux is set to zero consistent with the lack of thermodynamic processes in the sea ice model wave enhanced vertical mixing related to wave breaking is also neglected uchiyama et al 2010 the ocean ice interfacial stress is caused by velocity differences between the ice and the surface water for a wave phase averaged model the relevant surface current is a combination of the oceanic velocity and the wave induced stokes drift at the surface i e 10 τ wi c w i v i v v st v i v v st where cwi is the drag coefficient between the ocean and the ice in the ice zone the wind stress that acts on the ocean becomes 1 a i τ a w because the wind stress cannot drive the motion of the ocean where there is ice cover while the effect of the ice on the water is aiτwi with the air ice drag coefficient cai typically being substantially larger than caw røed and o brien 1983 häkkinen 1986 liu et al 1993 momentum is more efficiently transferred from the atmosphere to the ocean via the ice than in the absence of sea ice in other words the wind stress is smaller than the ocean ice interfacial stress under the same wind speed the stress gradient across an ice edge creates a divergence of ekman transport and is the cause for wind driven upwelling along an ice edge häkkinen 1986 liu et al 1993 in addition the ocean ice interfacial stress also drives shear turbulence and vertical mixing in the oceanic boundary layer in a way analogous to wind stress eddy formation due to wind driven unstable currents in the miz was studied in dai et al 2017 in the current study the wind stress τaw is zero to investigate the pure wave effect on sea ice and oceanic currents 3 model configuration the model is configured on a 200 km 100 km domain with a horizontal resolution of 0 5 km the results remain nearly the same when we use a resolution of 1 km supplementary materials the baroclinic deformation radius chelton et al 1998 is approximately 20 km no main thermocline in this study therefore mesoscale eddies are well resolved there are 40 grid levels in the vertical direction spanning a total depth of 400 m the grid is stretched vertically with the finest resolution near the ocean surface there are 7 levels in the upper 24 m of the water column all of the cases are integrated for 54 model days although eddies appear much earlier than 54 days the relatively long integration allows us to study the equilibrium state the coriolis parameter f is set to a constant of 10 4 s 1 in all experiments although f is larger at high latitudes where the miz exists sensitivity experiments suggest that the eddy genesis process and mechanism are not changed although eddy activity is reduced with a larger f appendix c in the simulations the reference water density is set to 1027 5 kg m 3 the lateral momentum and material diffusion coefficient is k h 0 1 m2 s 1 a sensitivity experiment with k h 0 generates nearly identical results not shown the initial oceanic velocity ice velocity and wave amplitude are all set to zero the initial density temperature and salinity are horizontally uniform and vertically stratified with a buoyancy frequency of n 6 10 3 s 1 below the mixed layer the initial mixed layer depth mld is set to 24 m a small amplitude perturbation is added to the flat sea surface to accelerate the development of instability in the realistic ocean perturbations always exist at the ice boundary the ice fraction distribution follows a hyperbolic tangent function the smooth ice boundary is necessary for the stability of the numerical experiments and the ice thickness is maintained at 2 m liu et al 1993 to study the sole effect of wave radiation stress no wind stress is imposed in the experiments the processes are schematically demonstrated in fig 1 in the control experiment we use an ice spatial energy dissipation rate α of 15 α 0 with α 0 being defined by equation 4 15 of weber 1987 the choice of a much larger dissipation rate than α 0 is justified in the following section where its sensitivity is examined the amplitude of the incident wave is 1 6 m the wave numbers in the x and y directions kx and ky are 0 006 m 1 and 0 02 m 1 respectively representing a slightly oblique incidence the wave length of the incident wave is 300 m and the wave period is 14 s the simulated incident wave corresponds to long swells that are typical in the polar ocean for example wadhams et al 2002 observed that the wave length of swells can exceed 500 m at greenland sea to examine the influence of wave forcing and mixed layer depth on eddy generation four sensitivity experiments are performed using the 1 km grid table 1 the three tested parameters include the following the ice induced wave energy dissipation rate α the incident wave energy wave amplitude and the initial mixed layer depth mld for the spatial energy decay rate we use 5 α 0 and 15α 0 designated as the α and a experiments for the wave energy we use e w 6 75 and 11 25 m 3 s 2 corresponding to a wave amplitude of 1 2 and 1 5 m respectively designated as ew and ew for the initial mixed layer depth we use 24 and 96 m defined as hmix and hmix the aewhmix experiment defined in table 1 has the same settings as the primary experiment in this study except for the resolution this is defined as the control experiment in the sensitivity experiments 4 results 4 1 ice wave evolution in this study the ice boundary is defined as the location where the ice fraction ai equals 0 1 inside the ice zone ai 0 1 the wave energy is attenuated by sea ice the wave attenuation rate due to sea ice has been previously estimated from observations weber 1987 based on the following equation 11 λ λ 0 e x p a i α 0 r where r is the distance from the ice boundary in the miz however when the observation derived wave attenuation rate is used i e α α 0 weber 1987 the simulated wave e folding distance is 20 km much larger than the observed values 2 to 5 km wadhams et al 1988 liu et al 1993 squire et al 1995 squire 2007 simulations with a few different wave attenuation rate α 2 3 4 5 15 α 0 have been carried out and wave e folding distance is within the observed range 2 to 5 km when α 5α 0 or 15α 0 the need for a wave dissipation rate larger than α 0 can be understood by examining the wave action eq 4 in an equilibrium state t 0 eq 4 reduces to 12 c g λ r λ c g r α c g a i λ when the second term on the left side λ c g r is neglected equation 12 reduces to eq 11 which was used in weber 1987 and wadhams et al 1988 to estimate α from observations however the second term in eq 12 i e λ d c g d r λ d ω k d r λ ω d 1 k d r λ ω k 2 d k d r o 10 1 especially at the ice edge see fig 2 is of the same order of magnitude as the first term in eq 11 i e c g d λ d r o 10 1 the term λ d c g d r is nonnegligible and eq 11 is inaccurate for studying wave evolution in the miz physically wave energy convergence due to decreased cg can compensate partially for the effect of wave dissipation to simulate λ accurately we must use a larger α than that derived from observational studies which assumes no wave energy convergence the wavenumber changes primarily in the x direction kx fig 2 red line the change is due to refraction by miz currents and sea ice the wavenumber in the x direction kx decreases slightly by 8 3 right before waves reach the ice boundary because of the refraction by the cross ice edge current which is analyzed in the next section the wavenumber increases significantly when waves enter the ice zone because of the large ice mass gradient in the cross ice edge direction the last term on the right hand side of eq 3 the current shear the first term on the right hand side of eq 3 effect is very small in this study by the 6th day the ice boundary moves to x 45 km from its initial location at x 28 km the wave energy λ increases slightly by approximately 8 3 right before waves enter the ice zone through convergence of the cross ice edge group velocity see eq 4 then it decreases precipitously by more than 90 during the first 6 days there is negligible refraction in the along ice edge y direction and ky not shown only changes by less than 0 01 because there is nearly no ice mass gradient in the along ice edge direction in addition the wave frequency remains nearly unchanged because the doppler shift due to the mean flow i e u k in eq 1 is of the order 0 01 s 1 and is much smaller than the intrinsic frequency in eq 1 i e ω 0 g k 0 4 s 1 the attenuation of wave energy leads to a radiation stress gradient and drives an along ice edge jet in both the ice and ocean the jet is confined near the ice edge where the wave energy dissipates before the wave energy is completely dissipated the radiation stress gradient acting on the ice is balanced by ocean ice interfacial stress which drives the ocean current in the along ice edge direction fig 3 a the maximum ocean ice interfacial stress is 0 0645 n m 2 equivalent to a 6 5 m s wind stress in the cross ice edge direction the radiation stress gradient and coriolis forces are balanced by the ice internal stress fig 3b as the ice boundary is pushed toward the rest of the ice the ice internal stress prevents it from converging the advection term in the ice momentum equation is two orders of magnitude smaller than the radiation stress gradient not shown this result supports the assumption in other ice modeling studies that advection is negligible i e hunke and dukowicz 1997 within the ice zone where waves have been completely dissipated there is no radiation stress gradient and the ice internal stress is balanced by the ocean ice interfacial stress and the coriolis force fig 3b in the cross ice edge direction in the along ice edge direction the momentum balance is primarily between the ocean ice interfacial stress and the coriolis force fig 3a thus the ice dynamics can be explained as follows the internal ice stress accelerates the ice eastward and the ice turns southward due to the coriolis force during this process the fast moving ice also continues transferring momentum into the ocean through the ocean ice interfacial stress 4 2 ocean jet spin up and evolution waves play an important role in the circulation of coastal zones where waves dissipate during breaking and transfer their momentum to the currents e g longuet higgins 1970 lentz and fewings 2012 in our miz model however wave breaking is neglected and the momentum transfer to currents occurs indirectly through the ocean ice interfacial stress fig 4 a b in the cross ice edge direction fig 4a the primary oceanic momentum balance is among the ocean ice interfacial stress coriolis force and pressure gradient the along ice edge jet is translated in the x eastward direction the translation speed is the strongest at the ice edge and decreases toward both sides of the ice edge the translational speed gradient leads to convergence on the miz side of the jet and divergence on the open ocean side of the jet resulting in tilting of the sea surface and pressure gradient forcing in the cross ice edge direction in the along ice edge direction fig 4b the ocean ice interfacial stress drives the jet and is partially balanced by the vertical momentum flux gradient the momentum budget is unbalanced at this stage because the jet is accelerating in both directions the vortex force o 10 3 n m 2 is negligibly small compared to other terms in the momentum budget o 10 2 n m 2 and is not shown in fig 4a b after 6 days of integration the ice boundary moves eastward to x 45 km while the jet center defined as the peak of the sea surface along ice edge velocity is located inside the ice zone but close to the ice boundary fig 4c this finding indicates that the jet follows the ice boundary according to eq 9 the radiation stress gradient is proportional to the ice induced wave damping rate α and the wave energy the wave energy the radiation stress and the resultant along ice edge jet are largest immediately inside the ice zone the largest speeds in the along ice edge and the cross ice edge directions are 0 38 m s and 0 05 m s respectively fig 4c within the ice zone the eastward ice internal stress drives an eastward ice flow and the ice motion turns south under the influence of the coriolis force fig 3a the resultant southward ocean ice interfacial stress fig 4b drives a southward ocean current fig 4d shaded east of the along ice edge jet as a result a strong cross ice edge shear arises at the east flank of the jet fig 4c blue line and this is where the eddies develop at a later time in addition the richardson number fig 4d green contour is smaller than 0 25 at the base of the mixed layer in the along ice edge jet suggesting kelvin helmholtz instability and mixed layer deepening in the region to test the sensitivity of the along ice edge jet to different parameters related to the waves ice and hydrography sensitivity tests table 1 in which those parameters are varied are examined the strength of the jet is sensitive to the dissipated wave energy in the sensitivity tests with a smaller wave dissipation rate or a smaller incident wave energy the along ice edge jet is weaker than that in the control experiment fig 5 a b c when the dissipated wave energy decreases the associated radiation stress gradient also decreases resulting in a weakening of the ice jet and the ocean ice interfacial stress on the other hand the location of the along ice edge jets are different in the two experiments with small dissipated wave energy aewhmix and αewhmix the smaller incident wave energy in experiment aewhmix leads to a weakening of the current in the cross ice edge direction and slowing of the eastward movement sensitivity experiment aewhmix shows that the jet is also influenced by the mixed layer depth when the mixed layer is deeper momentum is distributed over a deeper water column and the along ice edge jet is weaker fig 5d 4 3 eddy genesis and evolution after 4 days eddies begin to develop and grow due to the strong horizontal shear associated with the jet during this period energy is transferred from the mean flow to turbulence u i u j u i x j this process is demonstrated with the instantaneous snapshots of near surface cross ice edge velocities fig 6 on day 4 a broad band seemingly chaotic perturbation pattern arises around the jet fig 6a as the jet strengthens the chaotic perturbation strengthens fig 6b and reaches approximately 6 cm s on day 6 after day 6 the chaotic perturbations continue to grow and start to amalgamate into a more ordered pattern that becomes visible eddies which stay in an along ice edge line within the jet zone fig 6c d during this process both the ice boundary and the jet continue moving eastward and the growing eddies also follow the jet eastward the ice boundary and the jet continue to move eastward at the same time eddies grow larger and begin to merge eventually the small eddies merge into a streak of anticyclonic cyclonic eddies with a vorticity magnitude comparable to f fig 7 a and a diameter of 20 km at a later stage 54 days there is one large eddy and a few small ones because the primary eddy grows within the ice boundary where the vertical vorticity is negative the dominant eddy vorticity is anticyclonic as the ice is advected by the circular motion of the eddy the ice boundary meanders fig 7b the eddy circulation is the dominant current along the ice edge fig 7c there is also a density trough associated with the cyclonic eddy fig 7d similar to in the open ocean wave refraction fig 8 a shading and wave dissipation fig 8b shading are strongest at the ice boundary fig 8a b solid line and the location of wave refraction and dissipation moves eastward at the same rate as the ice boundary however the peak of the depth integrated kinetic energy fig 8a b dashed line moves more slowly than the ice boundary this finding implies that the peak of the depth integrated kinetic energy is slower than the surface jet movement which is probably due to the time lag caused by the upper oceanic energy transported to the deeper layers both the eddy kinetic energy eke 1 2 u i u i fig 8c green line and the eddy available potential energy eape 1 2 b b b z fig 8c black line grow throughout the simulation and reach 9 18 and 2 27 tj respectively by the end of the experiment the growth of the eke q and eape q can be understood by examining the budget for the two variables similar analysis has been carried out in global and regional oceans e g liang et al 2012 chen et al 2014 the budget equations are detailed derivation is in appendix d 13 d q d t 1 ρ w u i p x i 1 2 u j u j u i x i ν 2 q x j 2 u i u j u i x j ν u i x j u i x j u i b δ i 3 14 t u h h q h f e p u h b h b b z b w b j z b z the majority of the eke growth is from the shear production of the mean current fig 8c and the conversion from eape to eke only accounts for a small portion of the eke growth dissipation is the only sink for eke almost all of the eape comes from the available potential energy ape of the mean flow fig 8c purple line like the along ice edge jet the eddy intensity and eke are also sensitive to the wave forcing and mixed layer depth in all experiments the eke is converted from the mean flow ke this process in the eke equation is expressed as u i u j u i x j considering that the initial perturbations u i u j are all the same the mean flow horizontal shear u i x j determines the energy transfer from ke to eke the mean flow ke fig 9 a is controlled by the incident wave energy through the associated momentum transfer while being dissipated by sea ice see eq 9 on the one hand if the incident wave is smaller experiment aewhmix the jet and the mean flow ke are weaker fig 9a purple line on the other hand the eke fig 9b is determined by both the mean flow ke and the instability rate horizontal shear for a deeper mld or a smaller α the along ice edge jet is weaker and wider smaller u i x j and the rate is greatly decreased the eke fig 9b blue and green lines is smaller than that in the control experiment fig 9b red line however with a decrease in the wave energy the mean flow ke is smaller the occurrence of a narrower jet decreases the transfer efficiency therefore the total eke fig 9b purple line depends on the competition between the smaller mean flow ke and the larger transfer efficiency the response of the eape fig 9c is similar to that of the eke for example a lower incident wave energy can more easily reduce the eape because when wave energy is lower the vertical deflection of the isopycnals is shallower which results in reduced vertical motion and buoyancy 5 summary and discussion this study investigates wave ice current interactions in the marginal ice zone miz using a coupled ocean ice wave model a new wave ice interaction model is formulated as generalized from previous work by wadhams and holt 1991 and liu et al 1993 this is the first analysis of how waves refract in the miz with a dynamic current the model includes ice induced refraction ice induced wave dissipation and ice acceleration by wave radiation stress although the ice model can be applied for two prevalent forms of sea ice i e frazil ice and pancake ice simulations are only carried out using parameters for pancake ice using the ocean ice wave model we reveal that mesoscale eddies and subsequent ice edge meandering can be driven purely by incident waves even in the absence of wind and large scale currents some important parameters including the wave energy dissipation rate α the mixed layer depth mld and the incident wave energy ew have substantial effects on the eddy genesis process the wave energy dissipation rate α influences eddy activity by controlling the intensity and width of the along ice edge jet increasing α enhances the radiation stress gradient and drives a stronger and narrower ice edge jet resulting in stronger eddy activity using both theoretical analysis and numerical simulations we also demonstrate that the dissipation rate derived from observations using eq 11 is too small because it neglects wave energy convergence the mixed layer depth influences eddy activity by modulating the intensity of the along ice edge jet the momentum input to the ocean is distributed over a greater depth when the mld is larger both the ice edge jet and mesoscale eddies are weaker the incident wave energy controls eddy activity by determining the amount of wave energy available to accelerate the ice edge jet increasing ew induces a stronger radiation stress gradient both in the along ice edge and cross ice edge directions the former increases the ice edge jet strength larger ke in the mean flow whereas the later increases the width of the jet smaller horizontal shear the effect on the eddy strength becomes a result of the competition between larger ke in the mean flow and a smaller transfer rate from ke to eke the fully dynamical ocean ice wave model developed in this work improves on the 2d ocean ice model developed by liu et al 1993 in several ways 1 in liu et al 1993 waves were not allowed to evolve dynamically the simplification entails the assumption that wave energy is temporally steady and spatially unchanged before penetrating into sea ice independent of currents the assumption is inaccurate and influences the evolution of sea ice and currents with a dynamical wave model we demonstrate that ocean currents can influence wave evolution the wave energy undergoes divergence before arriving at the ice boundary and convergence occurs immediately inside the ice boundary see fig 2 the accumulation of wave energy near the ice boundary leads to a larger wave dissipation and radiation stress which in turn produce a stronger along ice edge jet and greater cross ice edge horizontal shear and is therefore favorable for eddy genesis 2 dynamical processes in a 3d ocean model differ from those in a 2d model the ocean ice interfacial stress is calculated by the velocity difference between the ocean and sea ice in a 3d ocean model the surface velocity is used for the drag calculation and is much greater than the depth averaged velocity that would be used for a 2d ocean model ice therefore is subject to reduced drag and moves faster when coupled with a 3d ocean model in a 3d ocean model there is additional motion in the vertical direction that is absent in a 2d ocean model the additional vertical motion decreases the sea surface elevation dai et al 2017 showed that this results in an order of magnitude smaller sea surface elevation than in liu et al 1993 who used a 2d model 3 in liu et al 1993 the ice boundary meandering was driven by nonuniform wave forcing however in this study the ice boundary meandering is driven by uniform wave forcing in his work eddies were spun up by differential wind stress across a wavy ice edge in this study the initial ice field is uniform along a meridian and eddies grow as a result of the current instability we have revealed a more general phenomenon as a special wave forcing or special ice distribution is not required in the model and we demonstrate how eddies grow from a small initial perturbation the purpose of this paper is to demonstrate the phenomenon of wave driven currents in the miz the problem here is highly idealized both due to many simplifications of the ice model and in the isolation of wave driven currents from all the other circulation phenomena in polar regions in the future if the model were to be applied to other ice types i e pack ice which are thicker and more likely to be deformed several changes should be made the resisting force is zero when divergence occurs in pancake ice however it is no longer negligible in pack ice for pack ice the dispersion relation should be derived from a different thin plate equation see liu and mollo christensen 1988 for an example under a static current in addition the reflection and transmission rates as well as the wave dissipation rate will be more variable fox and squire 1990 finally the fracturing of ice floe and the possible energy associated with this process liu et al 1991 dumont et al 2011 williams et al 2013a 2013b should also be included the model could also be generalized to include ice thermodynamic processes such as melting and congealing bitz and lipscomb 1999 which are dominated by the surface energy flux i e sensible heat flux li et al 2014a additional forcing conditions including wind stress and surface buoyancy forcing and more complicated but realistic initial conditions including oceanic buoyancy profile contrasts across the ice edge boundary will all have an effect that adds to the wave driven ice edge current in this study three parameters including the wave dissipation rate the mixed layer depth and the incident wave energy which have important effects during mesoscale eddy genesis have been discussed in this study other parameters including the oblique incidence the ice thickness and the wave frequency play a less important role in eddy spin up although they have substantial impacts on wave evolution and wave driven current processes for instance the oblique incidence influences wave driven current processes significantly the refraction is determined by the incidence angle and ice distribution which controls the partition of the radiation stress in the along ice edge and cross ice edge directions the effect of these factors will be investigated in future work acknowledgments we thank dr alexander shchepetkin and prof yusuke uchiyama for sharing the ocean and wave model codes we also thank dr timothy williams for rigorous suggestions regarding the dispersion relation derivation this work was jointly supported by the chinese scholarship counsel csc 201206010103 prof james c mcwilliams and prof haijun yang the national natural science foundation of china nos 91337106 41376007 41176002 40976007 appendix a definitions of symbols symbol name defined in section α ice spatial energy dissipation rate 2 1 α 0 ice spatial energy dissipation rate weber 1987 4 1 λ wave action 2 1 a i ice concentration 2 1 b 0 parameter defined as ρ i ρ w m i 2 1 c g group velocity amplitude 2 1 c g group velocity vector 2 1 c a i air ice drag coefficient 2 3 c a w air ocean drag coefficient 2 3 c w i ocean ice drag coefficient 2 3 d i ice thickness 2 1 d d d e w depth integrated wave energy density 2 1 ϵ total wave energy dissipation 2 2 ϵ b wave energy dissipation by wave breaking 2 1 ϵ i wave energy dissipation by ice 2 2 f coriolis frequency 2 2 symbol name defined in section f i ice internal stress vector 2 2 f i x cross ice edge ice internal stress 2 2 f i y along ice edge ice internal stress 2 2 f r merdional radiation stress gradient vector 2 2 f r x cross ice edge radiation stress gradient 2 2 f r y along ice edge radiation stress gradient 2 2 g gravitational acceleration 2 1 k wave number amplitude 2 1 k wave number vector 2 1 k x cross ice edge wave number 2 1 k y along ice edge wave number 2 1 d d k h lateral momentum diffusion coefficient 3 m i ice mass 2 1 n buoyancy frequency 3 d η sea surface elevation 2 2 d d ρ i ice density 2 1 ρ w ocean density 2 1 symbol name defined in section d d τ a i x cross ice edge wind stress over ice 2 2 τ a i y along ice edge wind stress over ice 2 2 τ a w x cross ice edge wind stress over water 2 2 τ a w y along ice edge wind stress over water 2 2 τ wi ocean ice drag vector 2 2 τ w i x cross ice edge ocean ice drag 2 2 τ w i y along ice edge ocean ice drag 2 2 u i cross ice edge ice velocity 2 2 u velocity vector integrated over the top 40 42 m 2 1 u cross ice edge velocity integrated over the top 40 42 m 2 1 v i ice velocity vector 2 3 v i along ice edge ice velocity 2 2 v along ice edge velocity integrated over the top 40 42 m 2 1 v st surface stokes velocity vector 2 3 v surface velocity vector 2 3 d ω doppler shifted wave frequency 2 1 ω c critical wave frequency 2 1 ω 0 internal wave frequency 2 1 ω wave frequency function 2 1 appendix b dispersion relation and ray theory b1 dispersion relation the derivation in this appendix follows the theory of wadhams and holt 1991 it is under the assumption that the flow is irrotational and incompressible at the ice edge subscript n is either 1 or 2 with 1 indicating a variable for the open ocean and 2 indicating a variable for the ice zone the continuity equation is written as b 1 2 ϕ n 0 here ϕn is the velocity potential whose derivative ϕ n ϕ n z u n v n w n provides the current velocities in the x y and z directions respectively the boundary condition for ϕn is b 2 ϕ n z 0 z h the solution to eq b 1 with boundary condition b 2 is b 3 ϕ n b n e i k n x x k n y y r n e i k n x x k n y y e k n z e i ω n t here k n x 2 k n y 2 k n 2 which can also be written as knx kny kn if a horizontal mean flow u is considered in the ice model and the vertical mean current is negligibly small compared to the horizontal mean current the total derivative is defined as d d t t u b1 1 in the open ocean in the open ocean the dynamical boundary condition is the linearized bernoulli equation b 4 ϕ 1 t u ϕ 1 g η 1 0 where η is the free surface the kinetic surface boundary condition is b 5 η 1 t u η 1 ϕ 1 z z 0 a solution for ϕ 1 can be obtained by substituting eq b 3 into eqs b 4 and b 5 and the dispersion relation is b 6 ω 1 u k 1 g k 1 b1 2 in the ice zone under the framework of the mass loading model that is suitable for frazil pancake ice squire et al 1995 wadhams and holt 1991 the simplified thin plate equation is written as b 7 δ p ρ i a i d i 2 t 2 2 v i t v i 2 2 η 2 where δp is the pressure just below the ice water surface the dynamical boundary condition at the water surface is the linearized bernoulli equation b 8 δ p ρ w g η 2 ϕ 2 t u ϕ 2 the kinetic surface boundary condition is b 9 η 2 t u η 2 ϕ 2 z z 0 substituting eq b 3 into eqs b 7 b 8 and b 9 provides b 10 1 b 0 k 2 ω 2 2 2 b 0 k 2 v i k 2 u k 2 ω 2 b 0 k 2 v i 2 k 2 2 u 2 k 2 2 g k 2 0 where b 0 ρ i ρ w a i d i the dispersion relation can be determined from eq b 10 as follows b 11 ω 2 u k 2 b 0 k 2 v i k 2 b 0 k 2 3 2 v i u u 2 v i 2 1 b 0 k 2 g k 2 1 b 0 k 2 since k 2 1 b 0 k 2 3 2 v i u u 2 v i 2 b 0 k 2 1 g k 2 eq b 11 becomes b 12 ω 2 u k 2 b 0 k 2 v i k 2 b 0 k 2 1 g k 2 1 b 0 k 2 for a long wave which is the focus of our experiments u k 2 b 0 k 2 v i k 2 therefore b 0 k 2 vi k2 is neglected in our model in a quiescent ocean i e u v i 0 b 13 ω 2 g k 2 1 a i d i k 2 ρ i ρ w wadhams and holt 1991 in the open ocean i e ai 0 b 14 ω 2 u k 2 g k 2 we use the perturbation method to determine the wave number from eq b 10 i e k 2 k 2 0 ɛ k 2 1 ɛ 2 k 2 2 with ε being a small parameter because the mean flow u is slow we consider o u to be the same order of magnitude as o ε substituting k 2 in eq b 10 we obtain an equation for o ε0 b 15 ω 2 2 b 0 k 2 0 ω 2 2 g k 2 0 0 b 16 k 2 0 ρ w ω 2 2 ρ w g ρ i a i d i ω 2 2 because k 2 0 0 ρ w g ρ i a i d i ω 2 2 0 thus b 17 ω 2 2 ρ w g ρ i a i d i ω c 2 at the boundary ω 2 ω 1 as a result if the incident frequency is larger than ωc total reflection will occur the equation for o ε1 is b 18 b 0 ɛ k 2 1 ω 2 2 2 u k 2 0 ω 2 g ɛ k 2 1 0 b 19 ɛ k 2 1 2 u k 2 0 ω 2 b 0 ω 2 2 g as a result b 20 k 2 k 2 0 ɛ k 2 1 k 2 0 1 2 u k 2 0 k 2 0 g b 0 ω 2 2 in the open ocean ω 1 u k 1 g k 1 b 21 k 2 0 g k 1 u 2 k 1 2 2 u k 1 g k 1 g b 0 g k 1 u 2 k 1 2 2 u k 1 g k 1 at the boundary snell s law can be applied to obtain b 22 s i n θ 1 s i n θ 2 k 2 k 1 b 23 θ 2 a r c s i n 1 g k 1 ω 1 2 b 0 k 1 s i n θ 1 for total reflection θ 2 is equal to 90 and we have b 24 s i n θ 1 c k 2 k 1 u 2 k 1 g 2 u k 1 g k 1 k 1 g b 0 u 2 k 1 2 g k 1 2 u k 1 g k 1 1 here we assume that u is a small parameter as a result there is no critical angle in the mass loading model squire et al 1995 b2 ray theory the group velocity is b 25 c g ω k u 2 b 0 k 2 v i g k 2 k 1 b 0 k 3 2 g k if ai 0 c g u g k 2 k g k open ocean if u v i 0 c g g k 2 k 1 b 0 k 3 2 g k static flow the dispersion relation can also be written as ω σ k u v i m i mei et al 2009 already analyzed the linear equation with a small parameter in the open ocean following his assumption of a slowly varying bottom we assume that the typical wavelength is much less than the horizontal length scale of depth variation induced by the ice thickness a small parameter can be defined as μ o d i k h 1 which is valid in our experiment by introducing the slow coordinate x μ x y μ y t μ t x y thus the following equation can be derived from eqs b 7 b 9 b 26 ρ i m i μ 2 2 t 2 2 v i t v i 2 2 ϕ z ρ w g ϕ z ρ w μ 2 2 t 2 2 u t u 2 2 ϕ z 0 typical wkb expansion is written as b 27 ϕ ϕ 0 i μ ϕ 1 e i s μ where ϕ j ϕ j x y z t for j 0 1 2 and s s x y t we define k s and ω s t as the local wavenumber vector and frequency respectively substituting eq b 27 into eqs b 26 b 1 and b 2 and separating the orders we obtain the following at o i μ 0 b 28 ρ i m i ω v i k 2 ϕ 0 z ρ w g ϕ 0 z ρ w ω u k 2 ϕ z 0 b 29 2 ϕ 0 z 2 k 2 ϕ 0 0 b 30 ϕ 0 z 0 z the solution to eqs b 28 b 30 is b 31 ϕ 0 ρ w ω u k 2 ρ i m i ω v i k 2 ρ w g k e k z where ω u k b 0 k v i k b 0 k 3 2 v i u u 2 v i 2 1 b 0 k g k 1 b 0 k based on the definition of k and ω we have k t ω 0 which is equivalent to b 32 k t ω 0 b 33 k t σ k k σ u u σ v i v i σ m i m i b 34 k t c g k k u b 0 k k v i ρ i ρ w k v i k m i ρ i ρ w k g k 2 1 b 0 k 3 2 m i since v i k gk eq b 34 becomes b 35 k t c g k k u b 0 k k v i ρ i ρ w k g k 2 1 b 0 k 3 2 m i since v i u and k 1 b 0 k k v i can also be neglected equation b 35 becomes b 36 k t c g k k u ρ i ρ w k g k 2 1 b 0 k 3 2 m i if ai 0 ice free b 0 0 and m i 0 thus eq b 36 becomes b 37 k t c g k k u if u 0 eq b 36 becomes b 38 k t c g k ρ i 2 ρ w k 1 b 0 k gk 1 b 0 k m i appendix c sensitivity to the coriolis parameter in this study we employ a coriolis parameter of 10 4 s 1 which is smaller than the coriolis parameter at high latitudes in this appendix we test the sensitivity of the eddy genesis process to the coriolis parameter in the experiment f14 the coriolis parameter is 1 4 10 4 s 1 all other settings in experiment f14 are the same as those in experiment aewhmix f 10 4 s 1 on day 6 the along ice edge jet is slightly weaker in experiment f14 v max 0 33 m s than in experiment aewhmix v max 0 38 m s fig a 1 a b as a result less energy is transferred from the mean shear currents to the eddies in experiment f14 than in experiment aewhmix at the end of day 30 the eke is 3 04 tj and 4 66 tj in experiments f14 and aewhmix respectively fig a 1c d in both experiments eddies arises from barotropic shear instability overall the eddy genesis process and mechanism are similar in the two cases with different coriolis parameters appendix d eddy energy equation d1 eddy kinetic energy equation a budget equation for the eddy kinetic energy eke defined as q 1 2 u i u i can be written as e g harrison and robinson 1978 d 1 d q d t 1 ρ w u i p x i 1 2 u j u j u i x i ν 2 q x j 2 u i u j u i x j ν u i x j u i x j u i b δ i 3 here 1 ρ w u i p x i is the pressure diffusion 1 2 u j u j u i x i is the turbulent transport which is caused by turbulent velocity fluctuations ν 2 q x j 2 is the molecular viscous transport u i u j u i x j is the shear mechanical production which is energy conversion between the mean shear and eke ν u i x j u i x j is the dissipation and g ρ w ρ w u i δ i 3 is the buoyancy production consumption which is the energy conversion between the eddy available potential energy and eke moreover i and j in the equation indicate different directions u 1 u u 2 v and u 3 w are the current velocities in the x y and z directions respectively u 1 u 2 u 3 u v w is the mean flow velocity u 1 u 2 u 3 u v w is the turbulent velocity p is the turbulent pressure and ρ w is the turbulent density the eke equation eq d 1 is derived from the primitive equation mcwilliams j c 2006 olbers d willebrand j and eden c 2012 d 2 u t u u x v u y w u z 1 ρ 0 p x f v ν 2 u f x d 3 v t u v x v v y w v z 1 ρ 0 p y f u ν 2 v f y d 4 w t u w x v w y w w z 1 ρ 0 p z ν 2 w d 5 u x v y w z 0 d 6 b t u b x v b y w b z j z ν is the molecular viscous coefficient fx and fy are external forcings in the x and y directions respectively such as ice ocean stress in this study and j z accounts for any diabatic buoyancy source term buoyancy b is decomposed as follows d 7 b b z t b x y z t d 8 b x y z t b x z t b x y z t where b is the mean buoyancy in the specific layer and b x z t is the mean buoyancy along the y direction the velocity components can be decomposed similarly as d 9 u u u v v v w w w letting d 2 u d 3 v and d 4 w we have d 10 u u u t u u u u u x u v v u u y u w w u u z u ρ 0 p p x f u v v ν u 2 u u u f x f x d 11 v v v t v u u v v x v v v v v y u w w u u z v ρ 0 p p y f v u u ν v 2 v v v f y f y d 12 w w w t w u u w w x w v v w w y w w w w w z w ρ 0 p p z ν w 2 w w we then average eqs d 10 d 11 and d 12 in the y direction to obtain d 13 1 2 u 2 t 1 2 u u 2 x u 2 u x u 2 u x 1 2 v u 2 y u v u y 1 2 w u 2 z u w u z u w u z u ρ 0 p x f u v ν u 2 u u f x d 14 1 2 v 2 t 1 2 u v 2 x u v v x u v v x 1 2 v v 2 y v v v y 1 2 w v 2 z v w v z v w v z v ρ 0 p y f u v ν v 2 v v f y d 15 1 2 w 2 t 1 2 u w 2 x u w w x u w w x 1 2 v w 2 y v w w y 1 2 w w 2 z w w w z w w w z w ρ 0 p z w b ν w 2 w since q 1 2 u 2 v 2 w 2 the sum of eqs d 13 d 14 d 15 becomes d 16 q t u i q x u i u j u i x 1 2 u j u j u i x i 1 ρ 0 u i p x u i b δ i 3 ν 2 q x i 2 ν u i x j u i x j u i f i if there is no external forcing i e u i f i 0 eq d 1 is recovered d2 eddy available potential energy equation the eddy available potential energy eape is defined as q 1 2 b b b z where b b z t b x y z t and b x y z t b x z t b x y z t a budget equation for the eape can be written as e g olbers d willebrand j and eden c 2012 d 17 t u h h q h f e p u h b h b b z b w b j z b z according to the eape budget there are two main sources for eape one is energy conversion from the mean ape u h b h b b z and the other is the buoyancy flux b w which is energy transferred from the eke on the left hand side of eq d 17 f e p 1 2 u h b 2 b z describes the eape transport by eddies on the right hand side of eq d 17 eq d 17 is derived from the buoyancy equation olbers d willebrand j and eden c 2012 d 18 d b d t w n 2 j z where the buoyancy frequency is n 2 d b d z substituting eq d 8 into eq d 18 d 19 b b t u b b x v b b y w n 2 j z then we multiply eq d 19 by b and neglect the vertical gradient by assuming that it is much smaller than horizontal gradients d 20 b b b t u b b b x v b b b y w b n 2 b j z if eq d 20 is averaged in the along ice edge y direction eq d 20 becomes d 21 1 2 b 2 t 1 2 u b 2 x 1 2 u b 2 x 1 2 v b 2 y 1 2 v b 2 y u b b x v b b y w b n 2 b j z by dividing eq d 21 by n 2 eq b 17 can be recovered the formulas in appendix d are per unit mass we multiply by the total mass when presenting the energy and conversion terms over the whole domain supplementary material supplementary material associated with this article can be found in the online version at 10 1016 j ocemod 2018 11 006 appendix e supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
24053,a theoretical model for the interaction among surface gravity waves frazil pancake sea ice and currents in a marginal ice zone miz is developed and is implemented into a free surface terrain following oceanic model the regional oceanic modeling system roms the wave model is a wentzel kramers brillouin wkb model with wave refraction and dissipation the sea ice model includes equations for sea ice mass and sea ice momentum wave energy is damped by sea ice and the ice is accelerated by wave radiation stress convergence the ocean ice interfacial stress accelerates the currents and mixes the oceanic surface boundary layer vertically the effects of waves on the ocean are represented by conservative wave averaged vortex forces and material advection by stokes drift the model is configured to simulate obliquely incident waves impinging on a marginal ice zone over an otherwise quiescent ocean the wave driven ice edge jet is unstable mesoscale eddies with a typical diameter of 20 km consistent with observations are generated the oceanic eddy kinetic energy eke can be strengthened by increasing the amount of energy transferred into the mean along edge current by increasing either the incident wave amplitude a physical variable or the wave damping rate by ice a tunable parameter eke also increases when the mixed layer depth decreases keywords wave ice interaction mesoscale eddies barotropic instability 1 introduction the marginal ice zone miz characterized by partial ice cover is the transition zone between the open ocean and the pack ice zone johannessen et al 1987 kohout and meylan 2008 it is typically 100 200 km wide häkkinen 1986 and can extend for more than 200 km under favorable atmospheric and oceanic conditions such as in the weddell sea lange et al 1989 wadhams and holt 1991 in the miz the presence of ice floes and the proximity to the open ocean substantially modify the dynamics of both sides of the ocean atmosphere interface leading to some distinct ocean flows at the ice edge such as upwelling eddies and mixing important to this study is the role of ice floes on the ocean atmosphere momentum flux and on ocean surface gravity waves the momentum flux from the atmosphere to the ocean is more efficient via ice floes than directly through the ocean atmosphere interface leading to a differential momentum flux gradient across the ice edge moreover surface gravity waves are dissipated and scattered by ice floes resulting in the acceleration of the ice floes and the underlying currents the miz is characterized by strong eddy activities whose signature can easily be detected in synthetic aperture radar images and in situ observations johannessen et al 1987 dumont et al 2011 it was observed that arctic miz eddies are mostly cyclonic with a diameter of 5 to 60 km and a maximum orbital velocity of 0 5 0 7 m s johannessen and johannessen 1983 johannessen et al 1987 three mechanisms have been proposed for the formation of miz eddies first miz eddies form due to the vorticity perturbation associated with topography häkkinen 1987b second miz eddies can be driven directly by the momentum flux curl across the ice edge third miz eddies can arise from the baroclinic and or barotropic instability of miz currents the three mechanisms for eddy generation and subsequent eddy evolution have been partially investigated using numerical models the effect of topography in eddy generation first mechanism was demonstrated by häkkinen 1987b with a two layer ocean model the second mechanism was analyzed by häkkinen 1986 and liu et al 1993 häkkinen 1986 showed that eddies spin up by a uniform wind in the presence of a wavy ice edge although the wind is the same across the ice edge the atmospheric momentum flux to the ocean is different because momentum transfer is more efficient via ice in the miz than directly through the ocean atmosphere interface in the open ocean the effect of the miz current instability on eddy formation third mechanism was investigated by manucharyan and thompson 2017 in that study an unstable ice edge current was driven by a strong cross ice edge surface fresh water flux gradient an unstable current in the miz can also be driven exclusively by waves entering the miz as is the focus of the present study surface gravity waves also play important roles in eddy formation liu et al 1993 demonstrated that eddy spin up by the second mechanism is accelerated by the addition of a wave field entering the miz waves are dissipated after entering the miz the convergence of radiation stress associated with wave dissipation accelerates the sea ice and the underlying ocean enhancing the vorticity driven by the differential cross ice edge wind stress the radiation stress convergence is largest at the ice edge liu et al 1993 observed that an along ice edge jet develops when waves are included although they were not able to study the subsequent jet evolution and eddy formation through current instability in liu et al 1993 the wave forcing was simply parameterized with a constant wave decay rate from the ice edge but other wave processes including propagation and refraction and their coupling with the ice and ocean were neglected wave propagation and refraction occur within the ice field while being dissipated which indicates the need to replace parameterized waves with an explicit wave model a realistic simulation of miz currents requires the coupling of a sea ice model an ocean circulation model and a wave model surface gravity waves entering the miz can also drive unstable currents at the ice edge and spin up eddies by the third mechanism the purpose of this study is to demonstrate how wave ice ocean interactions can lead to the generation of mesoscale eddies with only an incident wave field from a simple initial state with no ocean or ice motion and a straight ice edge in deep water this phenomenon is analogous to the generation of near shore currents by depth induced breaking of obliquely incident waves longuet higgins 1970 except that here the sea ice is the cause of wave dissipation and momentum exchange we set up a wave ice ocean model by relying primarily on previous formulations liu and mollo christensen 1988 in the regional oceanic modeling system roms model wave effects on currents are modeled by wave phase averaged vortex forces proportional to stokes drift velocity of the waves and the material advection due to stokes drift mcwilliams et al 2004 uchiyama et al 2010 additional nonconservative mixing occurs where waves break and at the bottom in the wentzel kramers brillouin wkb model waves refract due to current shear and variable oceanic depth and they dissipate due to bottom drag and wave breaking uchiyama et al 2010 however we derive a new wave dispersion relation that generalizes the results of wadhams and holt 1991 by including oceanic currents a modified wkb model is proposed that combines current and ice mass refraction with dissipation within the ice field the ocean ice interfacial stress formula in the model also includes the stokes drift effect in the interfacial velocity difference this study focuses on a common form of sea ice in the miz i e pancake ice which is usually a few meters in diameter and more than tens of centimeters thick wadhams et al 2002 sea ice in the miz can also be in the form of frazil ice which is a slurry of spicules although this is not considered in this study the rest of paper is arranged as follows section 2 introduces the formulas used for the wave and ice evolution section 3 describes their application to the miz and the experiment settings section 4 analyzes the current and eddy genesis processes in the numerical simulations section 5 provides a summary and identifies future research questions and model applications 2 model description a coupled ocean wave ice model built upon a coupled ocean wave model uchiyama et al 2010 in the framework of the regional oceanic modeling system roms shchepetkin and mcwilliams 2005 is employed in this study the three model components are described in the following three subsections 2 1 surface gravity waves sea ice significantly alters the evolution of ocean surface gravity waves when waves arrive at the ice edge they are altered by reflection and or transmission at the edge and their wavenumber and amplitude further evolve within the ice zone wadhams and holt 1991 bennetts and squire 2012 squire and montiel 2008 collins et al 2017 williams et al 2017 usually the wavenumber increases after wave refraction which means that the wavenumber is larger in the ice zone and it is determined by the ice mass and the incident wave frequency when the incident wave frequency is above a critical value total reflection occurs when the frequency is smaller than the critical value transmission co occurs with reflection and its importance increases with decreasing frequency when waves propagate into the ice field they dissipate rather quickly weber 1987 wang and shen 2010 meylan et al 2014 mosig et al 2015 ardhuin et al 2016 tolman and the wavewatch iii development group 2016 wave energy decays with a typical e folding distance of 1 20 km as a result most wave ice interactions occur near the ice edge with large waves significant wave height 3 m and low ice fraction 20 wave energy decays linearly with distance from the ice edge and can propagate more than 100 km into miz kohout et al 2014 this scenario is not considered in the current study for a deep water monochromatic wave refracted due to interactions with the ice edge and oceanic current the dispersion relationship can be generalized from wadhams and holt 1991 more details are shown in appendix b1 by adding horizontal currents 1 ω u k b 0 k v i k g k 1 b 0 k in eq 1 ω is the doppler shifted wave frequency u u v is the oceanic current averaged over the depths where the wave orbital motions are active 40 50 m in this study k k x k y is the wavenumber vector with k being its amplitude g is the acceleration of gravity b 0 ρ i ρ w m i where m i a i d i is the ice mass ai is the fraction of sea covered by ice and di is the ice thickness ρi and ρw are the ice and ocean densities respectively and v i u i v i is the ice velocity the critical ice ocean reflection frequency above which incident waves are completely reflected at the ice edge is calculated as wadhams and holt 1991 2 ω c 2 ρ w g ρ i a i d i in this study the critical ice ocean reflection frequency is of the order 1 hz and is much larger than the frequency of the incident swell order 0 1 hz total wave reflection is therefore neglected the dispersion relation functionally expressed as ω ω k x is solved using the ray theory for propagation in a slowly varying medium together with the wave action dissipation law the assumption of slow variations is valid for the horizontal scale of the current and ice mass relative to the wavelength and for the temporal scale of the changes in u and mi relative to the relevant wave propagation time the consequent spectrum peak wkb wave refraction model uchiyama et al 2010 is as follows more details can be found in appendix b 2 eqs b 26 b 38 3 k t c g k ω x k u k ρ i ρ w gk 2 1 b 0 k 3 2 m i 4 λ t c g λ 1 a i ϵ b ω 0 a i α c g λ where is the horizontal gradient operator λ e w ω 0 is the wave action ew is the depth integrated wave energy density ω 0 ω u k is the wave intrinsic frequency c g ω k is the wave group velocity vector with cg being its amplitude ϵ b is the wave dissipation rate due to breaking in the open water and α is the wave energy spatial decay rate as it propagates through the ice field in the idealized problem in section 3 we neglect both local wind generated wave and open water wave breaking and use a finite α the choice of α will be discussed in section 4 1 2 2 sea ice a sea ice dynamical model predicts the movement of the sea ice with winds ocean currents and the material strength of the ice as inputs hunke and dukowicz 1997 li et al 2014b wind stress is one of the primary drivers of ice motion and its effect on ice is often greater than its direct effect on the ocean røed and o brien 1983 oceanic currents act on sea ice by ocean ice interfacial stress and by a horizontal pressure gradient when the sea surface is tilted the interfacial stress is related to the velocity difference between the ice movement and surface ocean currents and the momentum transfer is usually from the ice to the ocean mcphee 1975 internal to the sea ice are stresses that resist ice convergence and a rigidity that resists deformation and divergence the importance of these factors depends on the material properties of the ice field previous studies have developed different rheological laws for ice the viscous plastic model vp is a commonly used rheology hibler 1979 the elastic viscous plastic model evp hunke and dukowicz 1997 is a computationally efficient solver for the vp rheology since the vp model does not give a good representaion of ice drift and deformation rampal et al 2008 more recently the elasto brittle rampal et al 2016 and maxwell elasto brittle dansereau et al 2017 rheologies that perform much better are being developed however at low ice concentrations the internal stress is very small based on all rheologies which means that the ice moves more freely a single layer ice model liu et al 1993 hunke and dukowicz 1997 is used in this study the model assumes that the thickness of pancake ice under the waterline is no more than a few meters and the thickness of frazil ice is even smaller ice thermodynamics and snow processes are also neglected in this idealized process study in reality ice growth may be nonnegligible during the eddy genesis process which lasts for tens of days while the focus of this study is the effect of long incident waves that do not break pancake ice ice floe breakup due to rapid ice melting is possible under the influence of breaking waves or storm conditions the ice momentum and mass equations are as follows 5 ρ i m i u i t u i u i x v i u i y ρ i m i g η x f v i a i τ a i x τ w i x f i x a i f r x 6 ρ i m i v i t u i v i x v i v i y ρ i m i g η y f u i a i τ a i y τ w i y f i y a i f r y 7 a i t a i u i x a i v i y 0 0 a i 1 8 m i t m i u i x m i v i y 0 where ui vi is the ice velocity vector f is the coriolis frequency τai is the wind stress over the ice τwi is the interfacial stress between the ocean and the ice f i is the ice internal stress and f r is the wave radiation stress divergence when the ice fraction ai is less than 1 the ice thickness di does not change when ai locally equals 1 di increases if there is further ice mass convergence as discussed in the beginning of this section several theories have been developed for the internal stress fi in the miz since there is no ice flexure e 0 in the frazil pancake ice the elastic part is invalid hunke and dukowicz 1997 and thus the results from the evp model and the vp model are similar we follow häkkinen 1987a which is similar to the vp model but with a simpler formulation moreover in this rheology model ice internal stress is negligible when divergence occurs in the ice zone neglecting open ocean wave breaking a wave radiation stress gradient only occurs due to the dissipation of waves propagating through sea ice dingemans et al 1987 9 a i f r ϵ k ω ϵ b ϵ i k ω a i α e w c g k ω where ϵ i a i α e w c g is the wave energy dissipation rate by wave ice interaction α is the ice spatial energy dissipation rate and ϵ b is assumed to be zero in this study 2 3 ocean the oceanic component of the coupled system is from the regional oceanic modeling system roms e g shchepetkin and mcwilliams 2005 it solves the three dimensional hydrostatic primitive equations in a vertical hybrid z sigma grid lemarié et al 2012 with horizontal curvilinear coordinates the interaction between surface gravity waves and currents is based on an asymptotic wave averaged theory mcwilliams et al 2004 lane et al 2007 vertical mixing in the top and bottom boundary layers uses the k profile parameterization kpp large et al 1994 which depends on the surface wind stress the surface buoyancy flux the oceanic current the coriolis parameter and the ocean density structure in the presence of sea ice the total surface stress is the sum of the stress between the atmosphere and the ocean τaw and the stress between the sea ice and the ocean τwi in this study the surface buoyancy flux is set to zero consistent with the lack of thermodynamic processes in the sea ice model wave enhanced vertical mixing related to wave breaking is also neglected uchiyama et al 2010 the ocean ice interfacial stress is caused by velocity differences between the ice and the surface water for a wave phase averaged model the relevant surface current is a combination of the oceanic velocity and the wave induced stokes drift at the surface i e 10 τ wi c w i v i v v st v i v v st where cwi is the drag coefficient between the ocean and the ice in the ice zone the wind stress that acts on the ocean becomes 1 a i τ a w because the wind stress cannot drive the motion of the ocean where there is ice cover while the effect of the ice on the water is aiτwi with the air ice drag coefficient cai typically being substantially larger than caw røed and o brien 1983 häkkinen 1986 liu et al 1993 momentum is more efficiently transferred from the atmosphere to the ocean via the ice than in the absence of sea ice in other words the wind stress is smaller than the ocean ice interfacial stress under the same wind speed the stress gradient across an ice edge creates a divergence of ekman transport and is the cause for wind driven upwelling along an ice edge häkkinen 1986 liu et al 1993 in addition the ocean ice interfacial stress also drives shear turbulence and vertical mixing in the oceanic boundary layer in a way analogous to wind stress eddy formation due to wind driven unstable currents in the miz was studied in dai et al 2017 in the current study the wind stress τaw is zero to investigate the pure wave effect on sea ice and oceanic currents 3 model configuration the model is configured on a 200 km 100 km domain with a horizontal resolution of 0 5 km the results remain nearly the same when we use a resolution of 1 km supplementary materials the baroclinic deformation radius chelton et al 1998 is approximately 20 km no main thermocline in this study therefore mesoscale eddies are well resolved there are 40 grid levels in the vertical direction spanning a total depth of 400 m the grid is stretched vertically with the finest resolution near the ocean surface there are 7 levels in the upper 24 m of the water column all of the cases are integrated for 54 model days although eddies appear much earlier than 54 days the relatively long integration allows us to study the equilibrium state the coriolis parameter f is set to a constant of 10 4 s 1 in all experiments although f is larger at high latitudes where the miz exists sensitivity experiments suggest that the eddy genesis process and mechanism are not changed although eddy activity is reduced with a larger f appendix c in the simulations the reference water density is set to 1027 5 kg m 3 the lateral momentum and material diffusion coefficient is k h 0 1 m2 s 1 a sensitivity experiment with k h 0 generates nearly identical results not shown the initial oceanic velocity ice velocity and wave amplitude are all set to zero the initial density temperature and salinity are horizontally uniform and vertically stratified with a buoyancy frequency of n 6 10 3 s 1 below the mixed layer the initial mixed layer depth mld is set to 24 m a small amplitude perturbation is added to the flat sea surface to accelerate the development of instability in the realistic ocean perturbations always exist at the ice boundary the ice fraction distribution follows a hyperbolic tangent function the smooth ice boundary is necessary for the stability of the numerical experiments and the ice thickness is maintained at 2 m liu et al 1993 to study the sole effect of wave radiation stress no wind stress is imposed in the experiments the processes are schematically demonstrated in fig 1 in the control experiment we use an ice spatial energy dissipation rate α of 15 α 0 with α 0 being defined by equation 4 15 of weber 1987 the choice of a much larger dissipation rate than α 0 is justified in the following section where its sensitivity is examined the amplitude of the incident wave is 1 6 m the wave numbers in the x and y directions kx and ky are 0 006 m 1 and 0 02 m 1 respectively representing a slightly oblique incidence the wave length of the incident wave is 300 m and the wave period is 14 s the simulated incident wave corresponds to long swells that are typical in the polar ocean for example wadhams et al 2002 observed that the wave length of swells can exceed 500 m at greenland sea to examine the influence of wave forcing and mixed layer depth on eddy generation four sensitivity experiments are performed using the 1 km grid table 1 the three tested parameters include the following the ice induced wave energy dissipation rate α the incident wave energy wave amplitude and the initial mixed layer depth mld for the spatial energy decay rate we use 5 α 0 and 15α 0 designated as the α and a experiments for the wave energy we use e w 6 75 and 11 25 m 3 s 2 corresponding to a wave amplitude of 1 2 and 1 5 m respectively designated as ew and ew for the initial mixed layer depth we use 24 and 96 m defined as hmix and hmix the aewhmix experiment defined in table 1 has the same settings as the primary experiment in this study except for the resolution this is defined as the control experiment in the sensitivity experiments 4 results 4 1 ice wave evolution in this study the ice boundary is defined as the location where the ice fraction ai equals 0 1 inside the ice zone ai 0 1 the wave energy is attenuated by sea ice the wave attenuation rate due to sea ice has been previously estimated from observations weber 1987 based on the following equation 11 λ λ 0 e x p a i α 0 r where r is the distance from the ice boundary in the miz however when the observation derived wave attenuation rate is used i e α α 0 weber 1987 the simulated wave e folding distance is 20 km much larger than the observed values 2 to 5 km wadhams et al 1988 liu et al 1993 squire et al 1995 squire 2007 simulations with a few different wave attenuation rate α 2 3 4 5 15 α 0 have been carried out and wave e folding distance is within the observed range 2 to 5 km when α 5α 0 or 15α 0 the need for a wave dissipation rate larger than α 0 can be understood by examining the wave action eq 4 in an equilibrium state t 0 eq 4 reduces to 12 c g λ r λ c g r α c g a i λ when the second term on the left side λ c g r is neglected equation 12 reduces to eq 11 which was used in weber 1987 and wadhams et al 1988 to estimate α from observations however the second term in eq 12 i e λ d c g d r λ d ω k d r λ ω d 1 k d r λ ω k 2 d k d r o 10 1 especially at the ice edge see fig 2 is of the same order of magnitude as the first term in eq 11 i e c g d λ d r o 10 1 the term λ d c g d r is nonnegligible and eq 11 is inaccurate for studying wave evolution in the miz physically wave energy convergence due to decreased cg can compensate partially for the effect of wave dissipation to simulate λ accurately we must use a larger α than that derived from observational studies which assumes no wave energy convergence the wavenumber changes primarily in the x direction kx fig 2 red line the change is due to refraction by miz currents and sea ice the wavenumber in the x direction kx decreases slightly by 8 3 right before waves reach the ice boundary because of the refraction by the cross ice edge current which is analyzed in the next section the wavenumber increases significantly when waves enter the ice zone because of the large ice mass gradient in the cross ice edge direction the last term on the right hand side of eq 3 the current shear the first term on the right hand side of eq 3 effect is very small in this study by the 6th day the ice boundary moves to x 45 km from its initial location at x 28 km the wave energy λ increases slightly by approximately 8 3 right before waves enter the ice zone through convergence of the cross ice edge group velocity see eq 4 then it decreases precipitously by more than 90 during the first 6 days there is negligible refraction in the along ice edge y direction and ky not shown only changes by less than 0 01 because there is nearly no ice mass gradient in the along ice edge direction in addition the wave frequency remains nearly unchanged because the doppler shift due to the mean flow i e u k in eq 1 is of the order 0 01 s 1 and is much smaller than the intrinsic frequency in eq 1 i e ω 0 g k 0 4 s 1 the attenuation of wave energy leads to a radiation stress gradient and drives an along ice edge jet in both the ice and ocean the jet is confined near the ice edge where the wave energy dissipates before the wave energy is completely dissipated the radiation stress gradient acting on the ice is balanced by ocean ice interfacial stress which drives the ocean current in the along ice edge direction fig 3 a the maximum ocean ice interfacial stress is 0 0645 n m 2 equivalent to a 6 5 m s wind stress in the cross ice edge direction the radiation stress gradient and coriolis forces are balanced by the ice internal stress fig 3b as the ice boundary is pushed toward the rest of the ice the ice internal stress prevents it from converging the advection term in the ice momentum equation is two orders of magnitude smaller than the radiation stress gradient not shown this result supports the assumption in other ice modeling studies that advection is negligible i e hunke and dukowicz 1997 within the ice zone where waves have been completely dissipated there is no radiation stress gradient and the ice internal stress is balanced by the ocean ice interfacial stress and the coriolis force fig 3b in the cross ice edge direction in the along ice edge direction the momentum balance is primarily between the ocean ice interfacial stress and the coriolis force fig 3a thus the ice dynamics can be explained as follows the internal ice stress accelerates the ice eastward and the ice turns southward due to the coriolis force during this process the fast moving ice also continues transferring momentum into the ocean through the ocean ice interfacial stress 4 2 ocean jet spin up and evolution waves play an important role in the circulation of coastal zones where waves dissipate during breaking and transfer their momentum to the currents e g longuet higgins 1970 lentz and fewings 2012 in our miz model however wave breaking is neglected and the momentum transfer to currents occurs indirectly through the ocean ice interfacial stress fig 4 a b in the cross ice edge direction fig 4a the primary oceanic momentum balance is among the ocean ice interfacial stress coriolis force and pressure gradient the along ice edge jet is translated in the x eastward direction the translation speed is the strongest at the ice edge and decreases toward both sides of the ice edge the translational speed gradient leads to convergence on the miz side of the jet and divergence on the open ocean side of the jet resulting in tilting of the sea surface and pressure gradient forcing in the cross ice edge direction in the along ice edge direction fig 4b the ocean ice interfacial stress drives the jet and is partially balanced by the vertical momentum flux gradient the momentum budget is unbalanced at this stage because the jet is accelerating in both directions the vortex force o 10 3 n m 2 is negligibly small compared to other terms in the momentum budget o 10 2 n m 2 and is not shown in fig 4a b after 6 days of integration the ice boundary moves eastward to x 45 km while the jet center defined as the peak of the sea surface along ice edge velocity is located inside the ice zone but close to the ice boundary fig 4c this finding indicates that the jet follows the ice boundary according to eq 9 the radiation stress gradient is proportional to the ice induced wave damping rate α and the wave energy the wave energy the radiation stress and the resultant along ice edge jet are largest immediately inside the ice zone the largest speeds in the along ice edge and the cross ice edge directions are 0 38 m s and 0 05 m s respectively fig 4c within the ice zone the eastward ice internal stress drives an eastward ice flow and the ice motion turns south under the influence of the coriolis force fig 3a the resultant southward ocean ice interfacial stress fig 4b drives a southward ocean current fig 4d shaded east of the along ice edge jet as a result a strong cross ice edge shear arises at the east flank of the jet fig 4c blue line and this is where the eddies develop at a later time in addition the richardson number fig 4d green contour is smaller than 0 25 at the base of the mixed layer in the along ice edge jet suggesting kelvin helmholtz instability and mixed layer deepening in the region to test the sensitivity of the along ice edge jet to different parameters related to the waves ice and hydrography sensitivity tests table 1 in which those parameters are varied are examined the strength of the jet is sensitive to the dissipated wave energy in the sensitivity tests with a smaller wave dissipation rate or a smaller incident wave energy the along ice edge jet is weaker than that in the control experiment fig 5 a b c when the dissipated wave energy decreases the associated radiation stress gradient also decreases resulting in a weakening of the ice jet and the ocean ice interfacial stress on the other hand the location of the along ice edge jets are different in the two experiments with small dissipated wave energy aewhmix and αewhmix the smaller incident wave energy in experiment aewhmix leads to a weakening of the current in the cross ice edge direction and slowing of the eastward movement sensitivity experiment aewhmix shows that the jet is also influenced by the mixed layer depth when the mixed layer is deeper momentum is distributed over a deeper water column and the along ice edge jet is weaker fig 5d 4 3 eddy genesis and evolution after 4 days eddies begin to develop and grow due to the strong horizontal shear associated with the jet during this period energy is transferred from the mean flow to turbulence u i u j u i x j this process is demonstrated with the instantaneous snapshots of near surface cross ice edge velocities fig 6 on day 4 a broad band seemingly chaotic perturbation pattern arises around the jet fig 6a as the jet strengthens the chaotic perturbation strengthens fig 6b and reaches approximately 6 cm s on day 6 after day 6 the chaotic perturbations continue to grow and start to amalgamate into a more ordered pattern that becomes visible eddies which stay in an along ice edge line within the jet zone fig 6c d during this process both the ice boundary and the jet continue moving eastward and the growing eddies also follow the jet eastward the ice boundary and the jet continue to move eastward at the same time eddies grow larger and begin to merge eventually the small eddies merge into a streak of anticyclonic cyclonic eddies with a vorticity magnitude comparable to f fig 7 a and a diameter of 20 km at a later stage 54 days there is one large eddy and a few small ones because the primary eddy grows within the ice boundary where the vertical vorticity is negative the dominant eddy vorticity is anticyclonic as the ice is advected by the circular motion of the eddy the ice boundary meanders fig 7b the eddy circulation is the dominant current along the ice edge fig 7c there is also a density trough associated with the cyclonic eddy fig 7d similar to in the open ocean wave refraction fig 8 a shading and wave dissipation fig 8b shading are strongest at the ice boundary fig 8a b solid line and the location of wave refraction and dissipation moves eastward at the same rate as the ice boundary however the peak of the depth integrated kinetic energy fig 8a b dashed line moves more slowly than the ice boundary this finding implies that the peak of the depth integrated kinetic energy is slower than the surface jet movement which is probably due to the time lag caused by the upper oceanic energy transported to the deeper layers both the eddy kinetic energy eke 1 2 u i u i fig 8c green line and the eddy available potential energy eape 1 2 b b b z fig 8c black line grow throughout the simulation and reach 9 18 and 2 27 tj respectively by the end of the experiment the growth of the eke q and eape q can be understood by examining the budget for the two variables similar analysis has been carried out in global and regional oceans e g liang et al 2012 chen et al 2014 the budget equations are detailed derivation is in appendix d 13 d q d t 1 ρ w u i p x i 1 2 u j u j u i x i ν 2 q x j 2 u i u j u i x j ν u i x j u i x j u i b δ i 3 14 t u h h q h f e p u h b h b b z b w b j z b z the majority of the eke growth is from the shear production of the mean current fig 8c and the conversion from eape to eke only accounts for a small portion of the eke growth dissipation is the only sink for eke almost all of the eape comes from the available potential energy ape of the mean flow fig 8c purple line like the along ice edge jet the eddy intensity and eke are also sensitive to the wave forcing and mixed layer depth in all experiments the eke is converted from the mean flow ke this process in the eke equation is expressed as u i u j u i x j considering that the initial perturbations u i u j are all the same the mean flow horizontal shear u i x j determines the energy transfer from ke to eke the mean flow ke fig 9 a is controlled by the incident wave energy through the associated momentum transfer while being dissipated by sea ice see eq 9 on the one hand if the incident wave is smaller experiment aewhmix the jet and the mean flow ke are weaker fig 9a purple line on the other hand the eke fig 9b is determined by both the mean flow ke and the instability rate horizontal shear for a deeper mld or a smaller α the along ice edge jet is weaker and wider smaller u i x j and the rate is greatly decreased the eke fig 9b blue and green lines is smaller than that in the control experiment fig 9b red line however with a decrease in the wave energy the mean flow ke is smaller the occurrence of a narrower jet decreases the transfer efficiency therefore the total eke fig 9b purple line depends on the competition between the smaller mean flow ke and the larger transfer efficiency the response of the eape fig 9c is similar to that of the eke for example a lower incident wave energy can more easily reduce the eape because when wave energy is lower the vertical deflection of the isopycnals is shallower which results in reduced vertical motion and buoyancy 5 summary and discussion this study investigates wave ice current interactions in the marginal ice zone miz using a coupled ocean ice wave model a new wave ice interaction model is formulated as generalized from previous work by wadhams and holt 1991 and liu et al 1993 this is the first analysis of how waves refract in the miz with a dynamic current the model includes ice induced refraction ice induced wave dissipation and ice acceleration by wave radiation stress although the ice model can be applied for two prevalent forms of sea ice i e frazil ice and pancake ice simulations are only carried out using parameters for pancake ice using the ocean ice wave model we reveal that mesoscale eddies and subsequent ice edge meandering can be driven purely by incident waves even in the absence of wind and large scale currents some important parameters including the wave energy dissipation rate α the mixed layer depth mld and the incident wave energy ew have substantial effects on the eddy genesis process the wave energy dissipation rate α influences eddy activity by controlling the intensity and width of the along ice edge jet increasing α enhances the radiation stress gradient and drives a stronger and narrower ice edge jet resulting in stronger eddy activity using both theoretical analysis and numerical simulations we also demonstrate that the dissipation rate derived from observations using eq 11 is too small because it neglects wave energy convergence the mixed layer depth influences eddy activity by modulating the intensity of the along ice edge jet the momentum input to the ocean is distributed over a greater depth when the mld is larger both the ice edge jet and mesoscale eddies are weaker the incident wave energy controls eddy activity by determining the amount of wave energy available to accelerate the ice edge jet increasing ew induces a stronger radiation stress gradient both in the along ice edge and cross ice edge directions the former increases the ice edge jet strength larger ke in the mean flow whereas the later increases the width of the jet smaller horizontal shear the effect on the eddy strength becomes a result of the competition between larger ke in the mean flow and a smaller transfer rate from ke to eke the fully dynamical ocean ice wave model developed in this work improves on the 2d ocean ice model developed by liu et al 1993 in several ways 1 in liu et al 1993 waves were not allowed to evolve dynamically the simplification entails the assumption that wave energy is temporally steady and spatially unchanged before penetrating into sea ice independent of currents the assumption is inaccurate and influences the evolution of sea ice and currents with a dynamical wave model we demonstrate that ocean currents can influence wave evolution the wave energy undergoes divergence before arriving at the ice boundary and convergence occurs immediately inside the ice boundary see fig 2 the accumulation of wave energy near the ice boundary leads to a larger wave dissipation and radiation stress which in turn produce a stronger along ice edge jet and greater cross ice edge horizontal shear and is therefore favorable for eddy genesis 2 dynamical processes in a 3d ocean model differ from those in a 2d model the ocean ice interfacial stress is calculated by the velocity difference between the ocean and sea ice in a 3d ocean model the surface velocity is used for the drag calculation and is much greater than the depth averaged velocity that would be used for a 2d ocean model ice therefore is subject to reduced drag and moves faster when coupled with a 3d ocean model in a 3d ocean model there is additional motion in the vertical direction that is absent in a 2d ocean model the additional vertical motion decreases the sea surface elevation dai et al 2017 showed that this results in an order of magnitude smaller sea surface elevation than in liu et al 1993 who used a 2d model 3 in liu et al 1993 the ice boundary meandering was driven by nonuniform wave forcing however in this study the ice boundary meandering is driven by uniform wave forcing in his work eddies were spun up by differential wind stress across a wavy ice edge in this study the initial ice field is uniform along a meridian and eddies grow as a result of the current instability we have revealed a more general phenomenon as a special wave forcing or special ice distribution is not required in the model and we demonstrate how eddies grow from a small initial perturbation the purpose of this paper is to demonstrate the phenomenon of wave driven currents in the miz the problem here is highly idealized both due to many simplifications of the ice model and in the isolation of wave driven currents from all the other circulation phenomena in polar regions in the future if the model were to be applied to other ice types i e pack ice which are thicker and more likely to be deformed several changes should be made the resisting force is zero when divergence occurs in pancake ice however it is no longer negligible in pack ice for pack ice the dispersion relation should be derived from a different thin plate equation see liu and mollo christensen 1988 for an example under a static current in addition the reflection and transmission rates as well as the wave dissipation rate will be more variable fox and squire 1990 finally the fracturing of ice floe and the possible energy associated with this process liu et al 1991 dumont et al 2011 williams et al 2013a 2013b should also be included the model could also be generalized to include ice thermodynamic processes such as melting and congealing bitz and lipscomb 1999 which are dominated by the surface energy flux i e sensible heat flux li et al 2014a additional forcing conditions including wind stress and surface buoyancy forcing and more complicated but realistic initial conditions including oceanic buoyancy profile contrasts across the ice edge boundary will all have an effect that adds to the wave driven ice edge current in this study three parameters including the wave dissipation rate the mixed layer depth and the incident wave energy which have important effects during mesoscale eddy genesis have been discussed in this study other parameters including the oblique incidence the ice thickness and the wave frequency play a less important role in eddy spin up although they have substantial impacts on wave evolution and wave driven current processes for instance the oblique incidence influences wave driven current processes significantly the refraction is determined by the incidence angle and ice distribution which controls the partition of the radiation stress in the along ice edge and cross ice edge directions the effect of these factors will be investigated in future work acknowledgments we thank dr alexander shchepetkin and prof yusuke uchiyama for sharing the ocean and wave model codes we also thank dr timothy williams for rigorous suggestions regarding the dispersion relation derivation this work was jointly supported by the chinese scholarship counsel csc 201206010103 prof james c mcwilliams and prof haijun yang the national natural science foundation of china nos 91337106 41376007 41176002 40976007 appendix a definitions of symbols symbol name defined in section α ice spatial energy dissipation rate 2 1 α 0 ice spatial energy dissipation rate weber 1987 4 1 λ wave action 2 1 a i ice concentration 2 1 b 0 parameter defined as ρ i ρ w m i 2 1 c g group velocity amplitude 2 1 c g group velocity vector 2 1 c a i air ice drag coefficient 2 3 c a w air ocean drag coefficient 2 3 c w i ocean ice drag coefficient 2 3 d i ice thickness 2 1 d d d e w depth integrated wave energy density 2 1 ϵ total wave energy dissipation 2 2 ϵ b wave energy dissipation by wave breaking 2 1 ϵ i wave energy dissipation by ice 2 2 f coriolis frequency 2 2 symbol name defined in section f i ice internal stress vector 2 2 f i x cross ice edge ice internal stress 2 2 f i y along ice edge ice internal stress 2 2 f r merdional radiation stress gradient vector 2 2 f r x cross ice edge radiation stress gradient 2 2 f r y along ice edge radiation stress gradient 2 2 g gravitational acceleration 2 1 k wave number amplitude 2 1 k wave number vector 2 1 k x cross ice edge wave number 2 1 k y along ice edge wave number 2 1 d d k h lateral momentum diffusion coefficient 3 m i ice mass 2 1 n buoyancy frequency 3 d η sea surface elevation 2 2 d d ρ i ice density 2 1 ρ w ocean density 2 1 symbol name defined in section d d τ a i x cross ice edge wind stress over ice 2 2 τ a i y along ice edge wind stress over ice 2 2 τ a w x cross ice edge wind stress over water 2 2 τ a w y along ice edge wind stress over water 2 2 τ wi ocean ice drag vector 2 2 τ w i x cross ice edge ocean ice drag 2 2 τ w i y along ice edge ocean ice drag 2 2 u i cross ice edge ice velocity 2 2 u velocity vector integrated over the top 40 42 m 2 1 u cross ice edge velocity integrated over the top 40 42 m 2 1 v i ice velocity vector 2 3 v i along ice edge ice velocity 2 2 v along ice edge velocity integrated over the top 40 42 m 2 1 v st surface stokes velocity vector 2 3 v surface velocity vector 2 3 d ω doppler shifted wave frequency 2 1 ω c critical wave frequency 2 1 ω 0 internal wave frequency 2 1 ω wave frequency function 2 1 appendix b dispersion relation and ray theory b1 dispersion relation the derivation in this appendix follows the theory of wadhams and holt 1991 it is under the assumption that the flow is irrotational and incompressible at the ice edge subscript n is either 1 or 2 with 1 indicating a variable for the open ocean and 2 indicating a variable for the ice zone the continuity equation is written as b 1 2 ϕ n 0 here ϕn is the velocity potential whose derivative ϕ n ϕ n z u n v n w n provides the current velocities in the x y and z directions respectively the boundary condition for ϕn is b 2 ϕ n z 0 z h the solution to eq b 1 with boundary condition b 2 is b 3 ϕ n b n e i k n x x k n y y r n e i k n x x k n y y e k n z e i ω n t here k n x 2 k n y 2 k n 2 which can also be written as knx kny kn if a horizontal mean flow u is considered in the ice model and the vertical mean current is negligibly small compared to the horizontal mean current the total derivative is defined as d d t t u b1 1 in the open ocean in the open ocean the dynamical boundary condition is the linearized bernoulli equation b 4 ϕ 1 t u ϕ 1 g η 1 0 where η is the free surface the kinetic surface boundary condition is b 5 η 1 t u η 1 ϕ 1 z z 0 a solution for ϕ 1 can be obtained by substituting eq b 3 into eqs b 4 and b 5 and the dispersion relation is b 6 ω 1 u k 1 g k 1 b1 2 in the ice zone under the framework of the mass loading model that is suitable for frazil pancake ice squire et al 1995 wadhams and holt 1991 the simplified thin plate equation is written as b 7 δ p ρ i a i d i 2 t 2 2 v i t v i 2 2 η 2 where δp is the pressure just below the ice water surface the dynamical boundary condition at the water surface is the linearized bernoulli equation b 8 δ p ρ w g η 2 ϕ 2 t u ϕ 2 the kinetic surface boundary condition is b 9 η 2 t u η 2 ϕ 2 z z 0 substituting eq b 3 into eqs b 7 b 8 and b 9 provides b 10 1 b 0 k 2 ω 2 2 2 b 0 k 2 v i k 2 u k 2 ω 2 b 0 k 2 v i 2 k 2 2 u 2 k 2 2 g k 2 0 where b 0 ρ i ρ w a i d i the dispersion relation can be determined from eq b 10 as follows b 11 ω 2 u k 2 b 0 k 2 v i k 2 b 0 k 2 3 2 v i u u 2 v i 2 1 b 0 k 2 g k 2 1 b 0 k 2 since k 2 1 b 0 k 2 3 2 v i u u 2 v i 2 b 0 k 2 1 g k 2 eq b 11 becomes b 12 ω 2 u k 2 b 0 k 2 v i k 2 b 0 k 2 1 g k 2 1 b 0 k 2 for a long wave which is the focus of our experiments u k 2 b 0 k 2 v i k 2 therefore b 0 k 2 vi k2 is neglected in our model in a quiescent ocean i e u v i 0 b 13 ω 2 g k 2 1 a i d i k 2 ρ i ρ w wadhams and holt 1991 in the open ocean i e ai 0 b 14 ω 2 u k 2 g k 2 we use the perturbation method to determine the wave number from eq b 10 i e k 2 k 2 0 ɛ k 2 1 ɛ 2 k 2 2 with ε being a small parameter because the mean flow u is slow we consider o u to be the same order of magnitude as o ε substituting k 2 in eq b 10 we obtain an equation for o ε0 b 15 ω 2 2 b 0 k 2 0 ω 2 2 g k 2 0 0 b 16 k 2 0 ρ w ω 2 2 ρ w g ρ i a i d i ω 2 2 because k 2 0 0 ρ w g ρ i a i d i ω 2 2 0 thus b 17 ω 2 2 ρ w g ρ i a i d i ω c 2 at the boundary ω 2 ω 1 as a result if the incident frequency is larger than ωc total reflection will occur the equation for o ε1 is b 18 b 0 ɛ k 2 1 ω 2 2 2 u k 2 0 ω 2 g ɛ k 2 1 0 b 19 ɛ k 2 1 2 u k 2 0 ω 2 b 0 ω 2 2 g as a result b 20 k 2 k 2 0 ɛ k 2 1 k 2 0 1 2 u k 2 0 k 2 0 g b 0 ω 2 2 in the open ocean ω 1 u k 1 g k 1 b 21 k 2 0 g k 1 u 2 k 1 2 2 u k 1 g k 1 g b 0 g k 1 u 2 k 1 2 2 u k 1 g k 1 at the boundary snell s law can be applied to obtain b 22 s i n θ 1 s i n θ 2 k 2 k 1 b 23 θ 2 a r c s i n 1 g k 1 ω 1 2 b 0 k 1 s i n θ 1 for total reflection θ 2 is equal to 90 and we have b 24 s i n θ 1 c k 2 k 1 u 2 k 1 g 2 u k 1 g k 1 k 1 g b 0 u 2 k 1 2 g k 1 2 u k 1 g k 1 1 here we assume that u is a small parameter as a result there is no critical angle in the mass loading model squire et al 1995 b2 ray theory the group velocity is b 25 c g ω k u 2 b 0 k 2 v i g k 2 k 1 b 0 k 3 2 g k if ai 0 c g u g k 2 k g k open ocean if u v i 0 c g g k 2 k 1 b 0 k 3 2 g k static flow the dispersion relation can also be written as ω σ k u v i m i mei et al 2009 already analyzed the linear equation with a small parameter in the open ocean following his assumption of a slowly varying bottom we assume that the typical wavelength is much less than the horizontal length scale of depth variation induced by the ice thickness a small parameter can be defined as μ o d i k h 1 which is valid in our experiment by introducing the slow coordinate x μ x y μ y t μ t x y thus the following equation can be derived from eqs b 7 b 9 b 26 ρ i m i μ 2 2 t 2 2 v i t v i 2 2 ϕ z ρ w g ϕ z ρ w μ 2 2 t 2 2 u t u 2 2 ϕ z 0 typical wkb expansion is written as b 27 ϕ ϕ 0 i μ ϕ 1 e i s μ where ϕ j ϕ j x y z t for j 0 1 2 and s s x y t we define k s and ω s t as the local wavenumber vector and frequency respectively substituting eq b 27 into eqs b 26 b 1 and b 2 and separating the orders we obtain the following at o i μ 0 b 28 ρ i m i ω v i k 2 ϕ 0 z ρ w g ϕ 0 z ρ w ω u k 2 ϕ z 0 b 29 2 ϕ 0 z 2 k 2 ϕ 0 0 b 30 ϕ 0 z 0 z the solution to eqs b 28 b 30 is b 31 ϕ 0 ρ w ω u k 2 ρ i m i ω v i k 2 ρ w g k e k z where ω u k b 0 k v i k b 0 k 3 2 v i u u 2 v i 2 1 b 0 k g k 1 b 0 k based on the definition of k and ω we have k t ω 0 which is equivalent to b 32 k t ω 0 b 33 k t σ k k σ u u σ v i v i σ m i m i b 34 k t c g k k u b 0 k k v i ρ i ρ w k v i k m i ρ i ρ w k g k 2 1 b 0 k 3 2 m i since v i k gk eq b 34 becomes b 35 k t c g k k u b 0 k k v i ρ i ρ w k g k 2 1 b 0 k 3 2 m i since v i u and k 1 b 0 k k v i can also be neglected equation b 35 becomes b 36 k t c g k k u ρ i ρ w k g k 2 1 b 0 k 3 2 m i if ai 0 ice free b 0 0 and m i 0 thus eq b 36 becomes b 37 k t c g k k u if u 0 eq b 36 becomes b 38 k t c g k ρ i 2 ρ w k 1 b 0 k gk 1 b 0 k m i appendix c sensitivity to the coriolis parameter in this study we employ a coriolis parameter of 10 4 s 1 which is smaller than the coriolis parameter at high latitudes in this appendix we test the sensitivity of the eddy genesis process to the coriolis parameter in the experiment f14 the coriolis parameter is 1 4 10 4 s 1 all other settings in experiment f14 are the same as those in experiment aewhmix f 10 4 s 1 on day 6 the along ice edge jet is slightly weaker in experiment f14 v max 0 33 m s than in experiment aewhmix v max 0 38 m s fig a 1 a b as a result less energy is transferred from the mean shear currents to the eddies in experiment f14 than in experiment aewhmix at the end of day 30 the eke is 3 04 tj and 4 66 tj in experiments f14 and aewhmix respectively fig a 1c d in both experiments eddies arises from barotropic shear instability overall the eddy genesis process and mechanism are similar in the two cases with different coriolis parameters appendix d eddy energy equation d1 eddy kinetic energy equation a budget equation for the eddy kinetic energy eke defined as q 1 2 u i u i can be written as e g harrison and robinson 1978 d 1 d q d t 1 ρ w u i p x i 1 2 u j u j u i x i ν 2 q x j 2 u i u j u i x j ν u i x j u i x j u i b δ i 3 here 1 ρ w u i p x i is the pressure diffusion 1 2 u j u j u i x i is the turbulent transport which is caused by turbulent velocity fluctuations ν 2 q x j 2 is the molecular viscous transport u i u j u i x j is the shear mechanical production which is energy conversion between the mean shear and eke ν u i x j u i x j is the dissipation and g ρ w ρ w u i δ i 3 is the buoyancy production consumption which is the energy conversion between the eddy available potential energy and eke moreover i and j in the equation indicate different directions u 1 u u 2 v and u 3 w are the current velocities in the x y and z directions respectively u 1 u 2 u 3 u v w is the mean flow velocity u 1 u 2 u 3 u v w is the turbulent velocity p is the turbulent pressure and ρ w is the turbulent density the eke equation eq d 1 is derived from the primitive equation mcwilliams j c 2006 olbers d willebrand j and eden c 2012 d 2 u t u u x v u y w u z 1 ρ 0 p x f v ν 2 u f x d 3 v t u v x v v y w v z 1 ρ 0 p y f u ν 2 v f y d 4 w t u w x v w y w w z 1 ρ 0 p z ν 2 w d 5 u x v y w z 0 d 6 b t u b x v b y w b z j z ν is the molecular viscous coefficient fx and fy are external forcings in the x and y directions respectively such as ice ocean stress in this study and j z accounts for any diabatic buoyancy source term buoyancy b is decomposed as follows d 7 b b z t b x y z t d 8 b x y z t b x z t b x y z t where b is the mean buoyancy in the specific layer and b x z t is the mean buoyancy along the y direction the velocity components can be decomposed similarly as d 9 u u u v v v w w w letting d 2 u d 3 v and d 4 w we have d 10 u u u t u u u u u x u v v u u y u w w u u z u ρ 0 p p x f u v v ν u 2 u u u f x f x d 11 v v v t v u u v v x v v v v v y u w w u u z v ρ 0 p p y f v u u ν v 2 v v v f y f y d 12 w w w t w u u w w x w v v w w y w w w w w z w ρ 0 p p z ν w 2 w w we then average eqs d 10 d 11 and d 12 in the y direction to obtain d 13 1 2 u 2 t 1 2 u u 2 x u 2 u x u 2 u x 1 2 v u 2 y u v u y 1 2 w u 2 z u w u z u w u z u ρ 0 p x f u v ν u 2 u u f x d 14 1 2 v 2 t 1 2 u v 2 x u v v x u v v x 1 2 v v 2 y v v v y 1 2 w v 2 z v w v z v w v z v ρ 0 p y f u v ν v 2 v v f y d 15 1 2 w 2 t 1 2 u w 2 x u w w x u w w x 1 2 v w 2 y v w w y 1 2 w w 2 z w w w z w w w z w ρ 0 p z w b ν w 2 w since q 1 2 u 2 v 2 w 2 the sum of eqs d 13 d 14 d 15 becomes d 16 q t u i q x u i u j u i x 1 2 u j u j u i x i 1 ρ 0 u i p x u i b δ i 3 ν 2 q x i 2 ν u i x j u i x j u i f i if there is no external forcing i e u i f i 0 eq d 1 is recovered d2 eddy available potential energy equation the eddy available potential energy eape is defined as q 1 2 b b b z where b b z t b x y z t and b x y z t b x z t b x y z t a budget equation for the eape can be written as e g olbers d willebrand j and eden c 2012 d 17 t u h h q h f e p u h b h b b z b w b j z b z according to the eape budget there are two main sources for eape one is energy conversion from the mean ape u h b h b b z and the other is the buoyancy flux b w which is energy transferred from the eke on the left hand side of eq d 17 f e p 1 2 u h b 2 b z describes the eape transport by eddies on the right hand side of eq d 17 eq d 17 is derived from the buoyancy equation olbers d willebrand j and eden c 2012 d 18 d b d t w n 2 j z where the buoyancy frequency is n 2 d b d z substituting eq d 8 into eq d 18 d 19 b b t u b b x v b b y w n 2 j z then we multiply eq d 19 by b and neglect the vertical gradient by assuming that it is much smaller than horizontal gradients d 20 b b b t u b b b x v b b b y w b n 2 b j z if eq d 20 is averaged in the along ice edge y direction eq d 20 becomes d 21 1 2 b 2 t 1 2 u b 2 x 1 2 u b 2 x 1 2 v b 2 y 1 2 v b 2 y u b b x v b b y w b n 2 b j z by dividing eq d 21 by n 2 eq b 17 can be recovered the formulas in appendix d are per unit mass we multiply by the total mass when presenting the energy and conversion terms over the whole domain supplementary material supplementary material associated with this article can be found in the online version at 10 1016 j ocemod 2018 11 006 appendix e supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
24054,global climate simulations do not capture the exact time history making it difficult to directly compare them with observations in this study we simulate the sampling of altimeter observations from a seven member wind and wave climate ensemble this allows us to assess the skill of the climate simulations relative to satellite observations instead of the typical approach which uses reanalysis or hindcast datasets as reference out of the sampling methods tested we find that a systematic sampling technique performs the best we then apply systematic sampling to wind fields from ec earth and wave fields generated using the wave model wam to replicate the changing sampling of the satellite observations next we then quantitatively assess the climate simulations and find that the probability density functions pdfs computed from the ec earth wind speed samples match the shape of the pdfs obtained from the altimeter observations ec earth consistently underestimates the wind speed with respect to the altimeter observations contrary to the wind speed underestimation the wave simulations overestimate wave heights especially in the extra tropics the wind speed seasonality in ec earth is larger than the seasonality evaluated from altimeter wind observations while the opposite is true for the wave height seasonality suggesting the wave physical parameterizations can be improved we find that the wave height inter annual variability of the modeled data is considerably less than the inter annual variability evaluated from the altimeter observations suggesting long term climate variability is not well captured overall the wave ensemble captures the important features of the global wave climate the methodology can be adapted to other climate simulations and observational datasets keywords wave climate cowclip wind and wave projections ec earth altimeter observations inter annual variability climate ensemble 1 introduction global climate models gcm are tools to study future changes in climate and can potentially be used to mitigate impacts to humans and infrastructure the most recent climate projections use ensembles where the simulations of future conditions are generated using multiple climate models or different initial conditions rather than a single climate simulation ensembles are used to explore and reduce the uncertainties inherent in the simulations that arise from the model s internal variability hawkins and sutton 2009 knutti and sedlacek 2010 rauser et al 2015 uncertainties in climate modeling inevitably occur due to errors in the physical parameterizations missing physical parameterizations or small scale processes not resolved due computational constrains stocker et al 2013 these uncertainties have often been limiting factors in climate studies particularly on regional scales falloon et al 2014 payne et al 2015 the intergovernmental panel on climate change ipcc recognized ocean waves as a significant driver of hazardous events in the coastal area stocker et al 2013 thus together with the expected sea level rise waves will likely play an increasingly important role in dangerous high water levels hemer et al 2013 despite the important role of waves within the earth system there is still no coupled ocean wave atmosphere climate model system in operation therefore global wave climate studies rely on the forcing from gcm projections and are produced as separate simulations both statistical and dynamical methods have been used to simulate future wave climate while statistical methods are less computationally demanding they require a priori conditions and these are typically based on gcm projections perez et al 2015 camus et al 2017 the dynamic approach uses wind speeds and sea ice coverage from gcms to drive a wave model and perform wave climate projections the first global wave climate projections were developed under the auspices of the world climate research program joint technical commission for oceanography and marine meteorology wrcp jcomm coordinated ocean wave climate projections cowclip project mori et al 2010 hemer et al 2012 semedo et al 2013 these studies led to an ensemble of statistical and dynamical global wave climate projections and the ensemble was used to quantify future wave conditions hemer et al 2013 recent studies used multi coupled model intercomparison project phase 5 cmip5 gcm projections to produce dynamical wave climate projections e g hemer and trenham 2016 since the wave climate simulations are not time constrained most studies compare different statistics such as seasonal or long term averages between the climate simulations and wave hindcasts hemer et al 2013 semedo et al 2013 hemer and trenham 2016 some examples of wave hindcasts and reanalysis are the national center for environmental prediction ncep climate forecast system cfsr chawla et al 2013 or the european centre for medium range weather forecasts ecmwf reanalysis era interim dee et al 2011 the problem with using reanalysis and hindcast datasets as reference is that there are known errors associated with the driving wind fields stopa and cheung 2014a and the physical parameterizations implemented in the wave model stopa et al 2016 in addition it can be difficult to assess the ability of the wave climate simulations to reproduce extreme waves since hindcasts tend to underestimate the largest sea states rascle and ardhuin 2013 the goal of this study is two fold our first objective is to develop a method to compare sparse observational datasets altimeter observations in our case to climate simulations from gcms our second objective is to demonstrate the sampling method on an ensemble of cimp5 ec earth wind simulations and associated wave simulations to determine the models performance comparing sparse observations with gcms is not straightforward because the quantity of the satellite observations changes in time and space as new platforms are activated and others are decommissioned therefore sufficient efforts related to the first objective are taken to adequately sample the climate simulations to capture the statistical properties such as the mean percentiles probability density functions and variance of the altimeter observations for the second objective we assess the performance of cimp5 ec earth wind simulations and associated wave simulations in reproducing the wind and wave climate relative to altimeter observations the ec earth and wam simulation wind and wave ensembles composed of seven members each was evaluated with respect to in situ observations and wave reanalysis datasets semedo et al 2018 this group of simulations was arbitrarily chosen and other cimp5 simulations are available e g hemer and trenham 2016 our intent is to demonstrate the method as well as assess the wind speeds and wave heights from the ec earth and wave simulations against altimeter observations spatially and for a wide range of sea states the study is organized as follows in section 2 we describe the altimeter observations and the ec earth and the wave climate simulations in section 3 we test several sampling techniques to best capture the variance and sampling of the altimeter observations and in section 4 we compare the wind and wave simulations to the altimeter measurements for a characteristic period of 10 years 1996 2005 here we emphasize on assessing the model observation differences spatially and statistically through probability density functions as well as assessing the extremes seasonality and inter annual variability of the modeled and sampled wave properties our discussion and conclusions follow in section 5 2 datasets 2 1 ec earth ensemble ec earth is a full physics coupled atmosphere ocean sea ice earth system model developed from the ecmwf integrated forecast system ifs operational seasonal forecast system hazeleger et al 2011 note that a wave model is not included in the system the ec earth version 2 2 used here is based on the ecmwf seasonal forecast system 3 https www ecmwf int en forecasts documentation and support evolution ifs cycles implementation seasonal forecast system the atmospheric model in ec earth is the same as the ecmwf ifs cycle 31r the ec earth atmospheric model uses a t159 triangular truncation at wavenumber 159 grid with horizontal spectral resolution of 125 km and 62 vertical levels of a terrain following mixed sigma pressure hybrid coordinates of which about 15 are within the planetary boundary layer the lowest model level is at 30 m height and the highest level is at 5 hpa the ocean model in ec earth is the nucleus for european modeling of the ocean nemo vancoppenolle et al 2009 nemo uses a horizontal resolution of roughly one degree the ec earth performance skills have been evaluated in several studies e g hazeleger et al 2011 the ec earth runs were provided by several research groups as detailed in table 1 out of the seven ec earth runs used to force wam six are part of the regular cmip5 ec earth ensemble a seventh ec earth run pc20 6 with an increased number of vertical levels is also used the ec earth runs were initialized between 1850 and 1855 spanning until 2005 each ec earth simulation is independent and no bias corrections were applied the seven dynamical wave simulations were produced by forcing the 3rd generation wave model wam wamdi group 1988 with u10 components east west and north south every 6 hours and daily sea ice concentration from each of the cmip5 ec earth runs we use wam cycle 4 5 3 an update of the wam cycle 4 described in gunther et al 1992 and janssen 2008 the source function integration scheme made by hersbach and janssen 1999 and the model updates by bidlot et al 2007 are incorporated the wam simulations were performed on a regular global latitude longitude grid covering a latitude range of 78 n to 78 s and using a fixed spatial grid size of 1 degree the spectral domain is discretized into 25 frequency bins in a geometrical progression with a common ratio of 1 1 that cover the range from 0 04177 to 0 41145 hz wave directions are discretized into 15 bins the 1 minute world gridded elevations bathymetry etopo1 data amante and eakins 2009 defines the water depths wam was run for each ensemble member for an approximate twentieth century time slice from 1970 to 2005 representing the present or historical climate the ensemble members will hereafter be mentioned for convenience by pc20 present climate 20th century followed by their ensemble number pc20 i where i is 1 to 7 see table 1 and the ensemble as pc20e for convenience we will use the pc20 for both the ec earth and wave climate runs since we will analyze both the wind speed u10 and significant wave height hs the wam cycle 4 5 3 did not implement a sub grid parametrization which causes the sea states in regions with islands smaller than the computational grid to be overestimated e g semedo et al 2013 2018 2 2 multi platform altimeter dataset the multi platform altimeter product abbreviated as alt herein was quality controlled and calibrated by queffeulou and croize fillon 2017 it was produced as part of the globwave project and is now extended to form the first version of the sea state climate change initiative database seastatecci v0 here we use a 10 year period to assess the simulations from 1996 through 2005 this period is chosen because there are the largest number of observations during the historical ec earth simulations 1970 2005 for the period 1996 2005 there are 6 missions ers1 1991 96 ers2 1996 2011 envisat 2002 12 topex 1993 2005 jason1 2002 13 and gfo 2000 07 observations from each platform have been cross calibrated between platforms and calibrated to moored buoys queffeulou and croize fillon 2017 the multi mission dataset is expected to be consistent in time with very little deviation between platforms since the 1 hz altimeter measurements capture the instantaneous and spatially localized estimate of hs it is an unfair comparison with the time space averaged outcome of the spectral wave model e g chawla et al 2013 stopa and cheung 2014a therefore we average all observations within the 1 degree bin from the various satellite platforms that fall within a one hour window the 1 degree bin matches the output of the wam simulations this one hour average represents the satellite observation and is comparable to the time scales resolved by the phase averaged spectral wave model at 1 degree resolution chawla et al 2013 3 methodology and assessment of sampling techniques the ensemble uses a single forcing and a single wave model so it is expected that the intra ensemble variability of pc20e is small we create a wind speed ensemble and wave height ensemble using equal weighting of the seven simulations from ec earth and wam respectively in order to compare the performance of the dynamic climate simulations to the altimeter observations it is essential to capture the wind speed and wave height magnitudes and variance of the satellite observations which change as a function of time and space an example time series is given in fig 1 a taken from a location in the north atlantic 20 w 46 n the location is denoted by the black x in fig 1 b this point was chosen arbitrarily and used as an example to show the effects of satellite sampling notice that the number of satellite observations per month changes and there are a larger number of measurements from 2002 to 2005 when there were 4 concurrent missions we are not concerned with the sparsity of satellite observations we only consider the altimeter observations to be the reference dataset the different number of satellite observations in single bins compared to the regularly time spaced wave simulations impacts the statistics therefore our goal is to properly sample the simulations so that the statistical properties such as the median and various percentiles match the ones from the altimeter observations three fundamental sampling methods are tested 1 simple random sampling 2 systematic sampling and 3 stratified sampling simple random sampling uses an equal weighting to select an event without replacement from the larger population an event in our application is an individual time step this method minimizes biases but it can be vulnerable to sampling errors especially in the tails of the distribution systematic sampling first orders the dataset and then chooses events at regular intervals based on a random starting position for our application we sort the data by time a disadvantage of systematic sampling is that it might not capture events that are periodic in nature such as diurnal cycles stratified sampling is the process of first dividing all possible events into mutually exclusive subgroups or strata before sampling in our case the strata are months and the events are the individual time steps for each month or strata we use simple random sampling or systematic sampling to select the events we tested a combination of these sampling techniques and summarize them with the following four cases in each 1 degree bin let m be the total number of time steps available from the gcm simulation and n be the number of altimeter observations where m n case 1 simple random sampling n time steps are randomly chosen from the entire climate simulation time series of length m without replacement case 2 systematic sampling data are selected every d x i n t m n where int denotes the greatest integer the floor function by randomly choosing an initial index i 0 within the range 1 dx of the time series case 3 monthly stratified with simple random sampling version 1 here we select a variable number of events from each monthly pc20 i strata the number of events selected directly corresponds to the number of satellite observations for the given month for example in fig 1 a there are 3 observations in january 2001 this means we randomly select 3 events from the model simulations in january 2001 case 4 monthly stratified with simple random sampling version 2 here we select the same number of events each month the number of events for a given location is defined by the average number of satellite observations for the complete time series referring to fig 1 a there is an average of 6 samples per month for 1996 2005 thus 6 events are selected from each month assuming the complete 6 h model simulation represents the true probability density function f we can estimate the variance for a given percentile p 0 1 as 1 σ 2 1 f x p 2 p 1 p n where xp represents the given variable hs or u10 at the given percentile the total number of satellite observations in 1 degree bins are shown in fig 1 b for the period 1996 2005 the asymptotic variance eq 1 was assessed by brown and wolfe 1983 for smaller sample sizes n 160 than our application therefore we expect eq 1 is an unbiased estimator of the variance since there are at least 350 samples in each 1 degree bin we repeat the sampling procedures above for a number of trials the final statistics are created by averaging all of the trials without loss of generality we use the hs from pc20 1 to assess both the magnitude and variance of the sub sampled datasets in fig 2 we show results of the different sampling methods relative to statistics of the full time series using the time series in fig 1 for a single trial fig 2 a and e all methods capture the percentile within 5 of the expected value however the variance can have large discrepancies 10 15 notice the extremes of the distribution are not well captured especially for percentiles 90 if we use ten trials and then average the statistics we can reduce the differences in sampled magnitudes and variance of the full time series as shown in fig 2 b and f however it is still difficult to capture the variance of the largest events next we assess the ability of the sampling methods to capture the seasonality and use december january february djf fig 2 c and g and june july august jja fig 2 d and h as representative seasons in djf fig 2 c and g when the waves are large all cases match the percentiles 10 difference all sampling techniques perform similarly and the largest differences are still in the tails of the distribution for percentiles less than 90 95 all sampling methods capture the magnitude and variance reasonably well in jja when hs is smaller we find similar results case 3 sampling has the most pronounced deviations from the reference full 6 hourly time series with variances varying 2 fig 2 h overall case 2 seems to perform the best because the percentiles are within 1 fig 2 b and the variance is well matched for the majority of the percentiles fig 2 f in order to optimize our sampling technique various trials were tested using the 95th percentile p95 pc20 1 hs time series in the north atlantic not shown after 25 trials all of the sampling methods are less than 3 of the p95 observations not shown cases 1 and 2 systematically converged with a lower number of trials than cases 3 and 4 after 10 trials only marginal improvements were observed therefore in the remainder of the study we average 10 trials to represent the statistics from the sampled simulations the spatial distribution of the sampling effects for hs p95 in fig 3 are analyzed next we compare both the ratio of hs p95 p95 sample p95 all and the ratio of hs p95 variance varsample varall for all cases cases 1 and 2 perform similarly and the ratios of hs p95 are close to one meaning nearly a perfect match the spatial distribution of the variance of the sampled time series from case 1 and 2 is nearly uniform across the basins fig 3 b and d the variance of the time series using case 1 and case 2 sampling is typically 5 larger that the full 6 hourly time series it is expected that the sampled dataset has a larger variance than the 6 hour time series because the full time series has approximately 10 times more data the case 3 ratios p95 sample p95 all of hs p95 in fig 3 e have a distinct spatial pattern with 2 deviations from the p95 hs full time series used as reference in the north atlantic western pacific and northern indian oceans case 3 sampling underestimates hs p95 while in the indian north eastern pacific and south atlantic oceans case 3 sampling overestimates hs p95 in case 3 sampling we select the actual number of altimeter observations from the corresponding month of the simulated dataset this means the number of events selected from the simulated time series in january 1996 corresponds to the actual number of altimeter observations in january 1996 consequently case 3 sampling favors months in 2003 2005 since there are more satellites in operation see fig 1 this sampling strategy introduces the largest spatial differences with respect to the full time series because the months that have more altimeter observations do not correspond to same months in the gcm forced wave simulations for all cases the variance of the sampled dataset is 5 10 larger than variance of the full time series shown in panels b d f and h in fig 3 the magnitude of the hs p95 ratios p95 sample p95 all between the sampled and full time series using case 4 sampling in fig 3 g is nearly one similar to cases 1 and 2 fig 3 a and c there is a subtle tendency for case 4 to overestimate hs p95 in the northwest pacific north atlantic 30 n and in the mediterranean fig 3 g the variance ratio of the case 4 sampling in fig 3 h is slightly larger than cases 1 and 2 6 7 for case 4 sampling compared to 4 5 for cases 1 and 2 fig 3 b and d the performance of each sampling procedure is summarized in table 2 by comparing various hs percentile and variance ratios s a m p l e d t i m e s e r i e s f u l l t i m e s e r i e s in percentages we compare the percentiles 5th 50th median and 95th in different zonal regions northern hemisphere nh 25 n equatorial region eq 25 n s and southern hemisphere sh 25 s and seasons djf and jja all sampling methods capture the overall variance very well and the errors are typically less than 0 5 the results in table 2 reflect similar features seen in figs 2 and 3 and are summarized as follows all sampling methods overestimate the small percentiles and the variance is often 1 the medians are very well matched using any of the sampling methods case 3 sampling introduces spatial discrepancies typically all sampled hs p95 match the full time series and hs p95 ratios are 0 1 the sampled datasets have larger variance than the full time 6 hourly series table 2 shows the variance can be considerably larger using the sampled time series for particular seasons djf and jja compared to the full time series especially for p95 we consistently find case 2 systematic sampling performs the best therefore this method is implemented to sample the climate simulations to match the satellite observations we continue to use the average of the 10 trials as a representative sample of the simulated climate wave data since using only one trial can have large differences of magnitude and variability relative to the observations see fig 2 a and e 4 assessment of the wind and wave climate simulations in this section we assess the sampled u10 and hs datasets pc20 1 to pc20 7 relative to the altimeter observations by analyzing the spatial errors the probability density functions pdfs seasonality inter annual variability and large sea states 4 1 spatial features and statistical properties first we highlight the spatial differences and variability between the ensemble and observations for various statistics such as the median p50 and upper percentile p95 wind speeds and wave heights for the entire 10 year period fig 4 shows the comparison between pc20e and alt for both u10 and hs at p50 the u10 p50 residuals pc20e alt in fig 4 b show that ec earth underestimates u10 by 1 2 ms 1 across the majority of the ocean near the equator there is a strong underestimation of u10 that is persistent for all simulations pc20 1 to pc20 7 however we should note that near the equator nadir looking altimeters are not the best source of wind and or wave data since the calm ocean surface coupled with weak winds can have nearly a specular reflection thus producing erroneous high wind speeds elfouhaily et al 1998 in addition there are impacts from the sea state which distort u10 when only the radar cross section one parameter approximation is used to estimate u10 gourrion et al 2002 consequently the u10 from altimeters is often higher than the reference buoy wind speeds especially in low wind regions young et al 2017 near the ice edge in the southern ocean there is a typical underestimation of 1 2 ms 1 otherwise the ensemble data in the extra tropics 30 50 n s which are important wave generation regions agree with altimeter observations u 10 a l t u 10 p c 20 e 0 5 ms 1 the intra ensemble variability from the seven simulations in fig 4 c is low 0 2 ms 1 with respect to the u10 differences typically 1 ms 1 which equates to 20 of the variability of the ensemble regions in the sh extra tropics eastern equatorial indian ocean and the trade wind regions of the nh and sh have the largest intra ensemble variations in fig 4 d f we show the p50 hs comparison between pc20e and alt overall the hs p50 of pc20e matches the observations within 0 25 m across the majority of the ocean the ensemble overestimates hs otherwise there are only select regions such as the nw atlantic mediterranean gulf of mexico and western pacific where pc20e underestimates hs this might be partially related to discrepancies in u10 altimeters tend to overestimate wave heights in low sea states sepulveda et al 2015 kudryavtseva and soomere 2017 so wave intensity in regions like the mediterranean and gulf of mexico which typically have small wave heights might be overestimated by the altimeters consequently in low sea states it is difficult to assess the simulations when using the altimeters as reference in the pacific trade wind regions the ensemble systematically overestimates hs by 0 5 m with a global maximum difference p50 hs pc20e alt coinciding near micronesia 130 w 20 s some of these features are related to unresolved islands smaller than the 1 resolution similar to features seen in semedo et al 2013 the intra ensemble variability is low and the hs deviations are less than 10 cm so near the noted large differences in the trade wind regions the intra ensemble variability is 4 of the residuals the intra ensemble variability in the southern ocean is 3 to 10 cm which is 12 to 25 of the typical 25 cm hs p50 residual so the ensemble reduces some of the uncertainty in the sh compared to using only one simulation in fig 5 we show the corresponding plots for the u10 and hs for the upper percentiles p95 the u10 p95 residuals in fig 5 b have nearly the same spatial structure as u10 p50 residuals in fig 4 b the most obvious difference is that the u10 p95 residuals have enhanced underestimation near the western boundaries in the tropics 5 30 n s relative to the u10 p50 residuals these regions are affected by tropical cyclones and the ensemble underestimates u10 p95 by 1 2 ms 1 the intra ensemble variability in fig 5 c is largest in the nh extra tropics 30 60 n in the nh extra tropics there are ec earth u10 p95 deviations of 0 2 0 3 ms 1 this is 40 60 of the average value of the residuals 0 5 ms 1 in fig 5 b therefore in these regions i e the gold colored areas in fig 5 c the use of the ensemble improves the performance the bottom panels of fig 5 show the corresponding plots for the hs at p95 the hs p95 residuals pc20e alt in fig 5 e are positive in the trade wind regions of the pacific meaning that pc20e overestimates hs p95 the spatial pattern of the hs p95 residuals in fig 5 e is similar to hs p50 residual in fig 4 e in the nh and sh extra tropics 30 60 n s the ensemble overestimates hs at p95 by at least 0 5 m and in some areas the hs p95 residuals exceed 0 75 m for example in the north pacific near the aleutians and south pacific near the ice edge the hs p95 is much higher exceeds 0 75 m than the observations ec earth underestimates u10 p95 in the western portion of the pacific and atlantic and likely contributes to a portion of the underestimation of hs the underestimation in the western portion of the pacific and atlantic is compounded by the fact that spectral wave models underestimate hs in rapidly changing short fetch conditions e g ardhuin et al 2010 similar to u10 p95 the intra ensemble variability helps to reduce the hs p95 differences mostly in the nh extra tropics with standard deviations of 0 2 m this is approximately 20 of the common hs p95 residual of 1 m next we compare the pdfs and the quantiles to give further insights on the performance of the climate simulations fig 6 shows the u10 probability distributions and quantile quantile qq plots the shape of the pdfs calculated from the simulations match the ones obtained from observations well but the pdfs are mis aligned in particular when u10 5 10 ms 1 the probabilities obtained from the simulations are larger than the probabilities obtained from the altimeter observations when u10 5 10 ms 1 the probabilities obtained from the simulations are lower than those of the altimeters in these plots each of the seven simulations is analyzed separately and its results plotted with a different color the pdfs obtained from the simulations are nearly the same and only subtle differences are distinguishable in this representation the qq plots show ec earth underestimates u10 uniformly across all wind speeds by approximately 0 75 ms 1 notice that in each region the qq plots are similar besides the noted spatial differences discussed in the previous section the simulations perform equally well in the different latitude bands we provide the corresponding pdfs for the hs in fig 7 the shape of pdfs obtained from the wave simulations is similar to the pdfs obtained from altimeter observations but they are mis aligned when hs 2 3 m the probabilities obtained from the simulations are smaller than the probabilities obtained from the altimeter observations when hs 2 3 m the probabilities obtained from the simulations are larger than those of the altimeter observations the wave simulations favor the mid range 2 hs 3 m more than the altimeter observations as shown by the reduced width of the pdfs obtained from the wave simulations we can see some distinction 2 difference between the pc20 i members near the median this effect is most evident in the sh in the sh there are the largest differences between the pdfs obtained from the wave simulations and the altimeter observations here the pdfs obtained from the simulations have higher occurrence of sea states with 2 hs 4 m compared to the pdfs obtained from the altimeter observations the qq plots show that the simulations of the lower percentiles median are often 0 25 m larger than the altimeter observations for the higher percentiles such as p95 the simulations overestimate hs by 0 25 0 5 m relative to the observations the qq hs results here in fig 7 are consistent with the buoy comparisons of semedo et al 2018 their figure 10 and show that hs is typically overestimated however in our analysis the comparisons are global and extend to wave heights of 8 m thus establishing the validity of the wave simulations to larger sea states notice that the global qq hs differences are reflective of the patterns observed in the sh since in the nh the pdfs obtained from the wave simulations match those of the observations reasonably well near the equator eq 25 n s in the lower percentiles p50 the wave heights are overestimated the largest contribution comes from the lower latitudes 15 as shown in figs 4 e and 5 e these areas are dominated by swell and the underestimation of the swell dissipation in wam might be contributing to the discrepancies in the sh the differences in the pdfs obtained from the wave simulations and altimeter observations are the largest the hs probabilities obtained from the simulations are lower than those of the altimeters for low sea states hs 2 m for sea states with 2 hs 5 m the probabilities obtained from the simulations are higher than those of the altimeters the hs qq plots show the thresholds for a given wave height quantile is overestimated in low seas p50 and high seas p95 we observe the largest variability between the ensemble members in the upper percentiles in summary u10 is underestimated by ec earth and hs is overestimated by the wave simulations this suggests the wave model physical parameterizations are causing the differences and not necessarily the forcing wind 4 2 seasonality to assess the ability of the pc20 e members to capture seasonality we use a metric called the mean annual variability mav stopa et al 2013 it is defined as the average of the annual standard deviation normalized by the annual average 2 m a v σ i x i where index i refers to the year σ is the standard deviation and the overbar denotes average we compare the mav between the ensemble average pc20 e and alt in fig 8 note that the altimeter patterns of the u10 and hs are provided as reference in fig 8 a and c the spatial pattern and magnitudes of the mav computed from the altimeter observations is similar to that of the mav computed from the cfsr wave hindcast of chawla et al 2013 and presented in stopa et al 2013 their figure 6 u10 from ec earth has more seasonal variability than the altimeters see fig 8 b in particular pc20e has a larger seasonality in the southern ocean extra tropics this might partially be influenced by the ice coverage near the equator pc20e has a larger mav north of the inter tropical convergence zone itcz and a smaller mav south of the itcz relative to the observations however it is expected the altimeter u 10 is of poorer quality near the itcz due to sea state impacts when the wind is calm and specular reflection is strong gourrion et al 2002 the hs comparison in fig 8 d shows the ensemble typically underestimates the wave seasonality by as much as 15 but typically 4 8 it is possible that there are missing physical parameterizations within the wave model or the physical parameterizations are not responding correctly to the wind input since we observe higher mav in u10 and lower mav in the wave field the seasonality within the ensemble is further analyzed in figs 9 and 10 here we present only results from the p95 since the spatial patterns for other percentiles and the average were nearly the same in djf fig 9 b the u10 p95 differences between pc20 e and alt are largest in the sh trade wind regions in the pacific and in the nw atlantic otherwise the differences are less than 1 ms 1 ec earth is overestimating u10 p95 in the sh extra tropics but usually less than 0 5 ms 1 the intra ensemble variability in fig 9 c is largest in the nh sh extra tropics and near the eq in the indian ocean the corresponding hs p95 residuals of pc20e alt in fig 9 e are similar to the u10 p95 residuals with the zonal pattern pc20e overestimates in 40 60 n s and pc20e underestimates 20 30 n s near the eq the u10 and hs p95 residuals have opposite signs with an overestimation in hs and an underestimation of u10 in jja fig 10 b ec earth underestimates u10 p95 relative to alt across the majority of the global ocean there are some exceptions where ec earth overestimates u10 p95 such as regions in the north pacific nw atlantic and near eastern africa in the nh the u10 and hs from the wind and wave ensembles are not capturing the tropical cyclones that are more common this time of the year especially in the western pacific fig 10 b and e the intra ensemble variability is largest in the sh for both u10 and hs p95 fig 10 c and f if a single member was used the differences in the sh might be larger than pc20 e shown in fig 10 b where the average is 1 ms 1 the ensemble produces a better estimation of the seasonality especially in the sh the spatial pattern of hs p95 residuals in fig 10 e do not match the u10 p95 residuals except for the region in the western pacific pc20 e overestimates the hs p95 relative to alt on average by 0 35 m with some regions in the sh and nh extra tropics exceeding 0 5 m in both the nh and sh extra tropics the intra ensemble variability is largest and 0 25 m fig 10 f in the wave generation regions of the extra tropics pc20e underestimates u10 p95 while pc20e underestimates hs p95 some of the other hs discrepancies are due to land mask used in the wam set up which is different from the one used in era interim additionally the wam version v4 5 3 used here is known to dissipate swell improperly in the low latitudes contributing to an overestimation of the wave heights there semedo et al 2013 these differences such as higher waves in the tropics around polynesia micronesia the maldives and near the aleutians islands might also occur due to unresolved sub grid scale bathymetry the intra ensemble variability in u10 and hs is largest in the nh and sh extra tropics 4 3 inter annual variability lastly we assess the ability of the ensemble to capture inter annual variability iav over this 10 year period the iav is defined as the standard deviation of the annual averages normalized by the overall average 3 i a v σ x i x we compare the iav between pc20 e and alt in fig 11 the spatial patterns of the altimeter observations in fig 11 a and c qualitatively look similar to the iav of cfsr presented in stopa et al 2013 their figure 7 the u10 iav maxima of the altimeter observations fig 11 a are located in the eastern and western equatorial pacific the hs iav maxima of altimeter observations fig 11 c are located in the southern ocean near chile and in the western pacific 120 e 15 n the u10 iav residuals between pc20e and alt are largest near the equator especially in the pacific which might be related to not properly capturing the el nino southern oscillation enso which is known to be the dominant mode of inter annual variability in this region e g stopa and cheung 2014b otherwise the ec earth u10 ensemble has differences less than 1 across 84 of the global ocean fig 11 b suggesting ec earth u10 captures a large amount of the u10 iav the hs iav difference in fig 11 d shows that the iav for pc20 e is considerably less than the iav of the altimeter observations these large differences between pc20 e and alt mean the iav of the wave field is not well captured in pc20 e and is typically much smaller than the observations at least over this period of 10 years 5 discussion and conclusion the u10 and hs climate simulations were sampled such that their statistical properties such as average variance and percentiles replicated those of the altimeter observations we analyzed both the magnitude and the variance of several sampling techniques at various percentiles we found that systematic sampling case 2 performed better than the other tested sampling methods properly sampling climate simulations that do not capture the exact time history is particularly important when the reference observations are sparse and or the number of observations changes in time and space our methodology can be adapted to other climate simulation and observational datasets we systematically analyzed the skill of the ensemble in reproducing the wind speeds u10 and the resulting wave heights hs relative to the altimeter observations ec earth underestimates the magnitude of u10 uniformly across all percentiles the pdfs obtained from the u10 of ec earth and those obtained from the altimeter observations are very similar suggesting that ec earth is a satisfactory predictor of wind speeds globally even though pc20e underestimates u10 the wave heights are overestimated this suggests the implementation of wam is not properly calibrated for the ec earth wind field and it is possible to correct this bias by reducing the wind wave growth parameter βmax in the parametrization of janssen 1991 as shown by stopa 2018 in the nh the pdfs computed from u10 and hs of both the simulations and altimeter observations are similar however in the sh the pdfs are different therefore the performance of the simulations in the nh is better than the sh the qq plots also support this point the global discrepancies in the pdfs and qq plots strongly reflect the discrepancies of the sh stressing the importance of future efforts to better simulate the sh the almost identical match of the pdfs for the 7 simulations limits the possibilities of the ensemble to improve forecasts or hindcasts since the ensemble variance is much less than typical simulation observation error variances for example the hs standard deviations of wave hindcasts errors at buoys typically ranged from 40 or 0 3 to 0 8 m as presented by stopa and cheung 2014a their table 2 the hs standard deviation of pc20 e is generally small and less than 0 06 0 2 m at p50 p95 we find pc20 e overestimates hs in the tropics namely in the pacific ocean this region has an abundance of swell semedo et al 2011 and wam is most likely underestimating the swell decay in addition large hs discrepancies coincide with island chains in the pacific and are due to the treatment of sub grid features not resolved by the model grid resolution regions affected by tropical cyclones most notably in the western pacific are not well captured by the climate simulations and we observe a severe underestimation of hs at p95 the use of the ensemble has a minimal effect on improving the predictability in this case now that the wave simulations are sampled like the satellite measurements it is possible to develop a bias correction for the wave simulations and it is topic for future work notice that all of the sampling techniques introduce errors of less than 2 for hs at p95 see fig 3 while the hs model to simulation discrepancies at p95 are typically on the order of 10 25 fig 5 so we expect that our results are robust and there is minimal impact from the sampling technique applied the seasonality is reasonably captured by the u10 and hs ensembles we find some differences for example ec earth overestimates the u10 seasonality while the wave ensemble underestimates the hs seasonality this seasonal mismatch was found in other datasets for example seasonal residuals between a cfsr wave hindcast and altimeter observations both u10 and hs were observed in chawla et al 2013 and stopa and cheung 2014a this suggests the physical parameterizations in spectral wave models like wavewatch and wam have missing physical processes or the existing parameterizations can be improved to better capture the atmospheric response in both the strong and weak seasons such as temperature differences or water density differences we speculate that the current physical parameterizations in spectral wave models have the tendency to underestimate both growth and dissipation which might contribute to a portion of the hs seasonality residuals the ensemble improves the prediction of the seasons especially in the southern ocean otherwise the typical intra ensemble variability is less than or approximately 10 30 of the pc20e alt residuals the u10 from ec earth captures the important features of the inter annual variability on the other hand the gcm wave simulations have lower inter annual variability suggesting the time series of wave simulations forced by ec earth have a much smoother time series relative to the altimeter observations our comparison of the inter annual variability is a challenging test for the wave climate simulations one possible reason why we have such large differences in the iav between the simulations and satellite observations could be because we use a 10 year period a longer time series might capture more of the long term variability since the gcm forced wave simulations have difficulty in reproducing the iav caution should be taken when analyzing the inter annual variability of future climate scenarios improving the ability of the wave climate simulations to reproduce the inter annual variability is an opportunity for future efforts previous works use wave reanalysis or wave hindcasts to assess gcm forced wave simulations here we take a novel approach and we use altimeter observations as reference this is important because the altimeter database is expected to better represent the large sea states and are not subjected to missing or improper wave parameterizations as in models it also stresses the importance of having an accurate and quality controlled altimeter database and is currently being re assessed by the european space agency s sea state climate change initiative using the altimeter observations to assess the gcm simulations especially at large sea states hs p95 is certainly a benefit of applying the method in this study we provide more spatial details of the simulation errors and validate the simulations across a wider range of sea states compared to semedo et al 2018 who used reanalysis datasets and in situ buoys as reference datasets future assessments of the historical wave simulations either dynamical or statistical could use a similar methodology and compare to sparse observational datasets like our example of using the altimeter observations as reference overall the ec earth simulations and associated wave simulations capture the essential features of the climate since we understand the discrepancies between the simulations and satellite observations it is now possible to interpret the wave data for the future simulations which extend until the end of the 22nd century acknowledgments this work has been done under the auspices of the jcomm cowclip coordinated ocean wave climate projections project alvaro semedo has been supported by the project solar ptdc geomet 7078 2014 financed by portuguese foundation for science and technology fct gil lemos is supported by the earth systems doctoral school fct project uid geo 50019 2013 university of lisbon 
24054,global climate simulations do not capture the exact time history making it difficult to directly compare them with observations in this study we simulate the sampling of altimeter observations from a seven member wind and wave climate ensemble this allows us to assess the skill of the climate simulations relative to satellite observations instead of the typical approach which uses reanalysis or hindcast datasets as reference out of the sampling methods tested we find that a systematic sampling technique performs the best we then apply systematic sampling to wind fields from ec earth and wave fields generated using the wave model wam to replicate the changing sampling of the satellite observations next we then quantitatively assess the climate simulations and find that the probability density functions pdfs computed from the ec earth wind speed samples match the shape of the pdfs obtained from the altimeter observations ec earth consistently underestimates the wind speed with respect to the altimeter observations contrary to the wind speed underestimation the wave simulations overestimate wave heights especially in the extra tropics the wind speed seasonality in ec earth is larger than the seasonality evaluated from altimeter wind observations while the opposite is true for the wave height seasonality suggesting the wave physical parameterizations can be improved we find that the wave height inter annual variability of the modeled data is considerably less than the inter annual variability evaluated from the altimeter observations suggesting long term climate variability is not well captured overall the wave ensemble captures the important features of the global wave climate the methodology can be adapted to other climate simulations and observational datasets keywords wave climate cowclip wind and wave projections ec earth altimeter observations inter annual variability climate ensemble 1 introduction global climate models gcm are tools to study future changes in climate and can potentially be used to mitigate impacts to humans and infrastructure the most recent climate projections use ensembles where the simulations of future conditions are generated using multiple climate models or different initial conditions rather than a single climate simulation ensembles are used to explore and reduce the uncertainties inherent in the simulations that arise from the model s internal variability hawkins and sutton 2009 knutti and sedlacek 2010 rauser et al 2015 uncertainties in climate modeling inevitably occur due to errors in the physical parameterizations missing physical parameterizations or small scale processes not resolved due computational constrains stocker et al 2013 these uncertainties have often been limiting factors in climate studies particularly on regional scales falloon et al 2014 payne et al 2015 the intergovernmental panel on climate change ipcc recognized ocean waves as a significant driver of hazardous events in the coastal area stocker et al 2013 thus together with the expected sea level rise waves will likely play an increasingly important role in dangerous high water levels hemer et al 2013 despite the important role of waves within the earth system there is still no coupled ocean wave atmosphere climate model system in operation therefore global wave climate studies rely on the forcing from gcm projections and are produced as separate simulations both statistical and dynamical methods have been used to simulate future wave climate while statistical methods are less computationally demanding they require a priori conditions and these are typically based on gcm projections perez et al 2015 camus et al 2017 the dynamic approach uses wind speeds and sea ice coverage from gcms to drive a wave model and perform wave climate projections the first global wave climate projections were developed under the auspices of the world climate research program joint technical commission for oceanography and marine meteorology wrcp jcomm coordinated ocean wave climate projections cowclip project mori et al 2010 hemer et al 2012 semedo et al 2013 these studies led to an ensemble of statistical and dynamical global wave climate projections and the ensemble was used to quantify future wave conditions hemer et al 2013 recent studies used multi coupled model intercomparison project phase 5 cmip5 gcm projections to produce dynamical wave climate projections e g hemer and trenham 2016 since the wave climate simulations are not time constrained most studies compare different statistics such as seasonal or long term averages between the climate simulations and wave hindcasts hemer et al 2013 semedo et al 2013 hemer and trenham 2016 some examples of wave hindcasts and reanalysis are the national center for environmental prediction ncep climate forecast system cfsr chawla et al 2013 or the european centre for medium range weather forecasts ecmwf reanalysis era interim dee et al 2011 the problem with using reanalysis and hindcast datasets as reference is that there are known errors associated with the driving wind fields stopa and cheung 2014a and the physical parameterizations implemented in the wave model stopa et al 2016 in addition it can be difficult to assess the ability of the wave climate simulations to reproduce extreme waves since hindcasts tend to underestimate the largest sea states rascle and ardhuin 2013 the goal of this study is two fold our first objective is to develop a method to compare sparse observational datasets altimeter observations in our case to climate simulations from gcms our second objective is to demonstrate the sampling method on an ensemble of cimp5 ec earth wind simulations and associated wave simulations to determine the models performance comparing sparse observations with gcms is not straightforward because the quantity of the satellite observations changes in time and space as new platforms are activated and others are decommissioned therefore sufficient efforts related to the first objective are taken to adequately sample the climate simulations to capture the statistical properties such as the mean percentiles probability density functions and variance of the altimeter observations for the second objective we assess the performance of cimp5 ec earth wind simulations and associated wave simulations in reproducing the wind and wave climate relative to altimeter observations the ec earth and wam simulation wind and wave ensembles composed of seven members each was evaluated with respect to in situ observations and wave reanalysis datasets semedo et al 2018 this group of simulations was arbitrarily chosen and other cimp5 simulations are available e g hemer and trenham 2016 our intent is to demonstrate the method as well as assess the wind speeds and wave heights from the ec earth and wave simulations against altimeter observations spatially and for a wide range of sea states the study is organized as follows in section 2 we describe the altimeter observations and the ec earth and the wave climate simulations in section 3 we test several sampling techniques to best capture the variance and sampling of the altimeter observations and in section 4 we compare the wind and wave simulations to the altimeter measurements for a characteristic period of 10 years 1996 2005 here we emphasize on assessing the model observation differences spatially and statistically through probability density functions as well as assessing the extremes seasonality and inter annual variability of the modeled and sampled wave properties our discussion and conclusions follow in section 5 2 datasets 2 1 ec earth ensemble ec earth is a full physics coupled atmosphere ocean sea ice earth system model developed from the ecmwf integrated forecast system ifs operational seasonal forecast system hazeleger et al 2011 note that a wave model is not included in the system the ec earth version 2 2 used here is based on the ecmwf seasonal forecast system 3 https www ecmwf int en forecasts documentation and support evolution ifs cycles implementation seasonal forecast system the atmospheric model in ec earth is the same as the ecmwf ifs cycle 31r the ec earth atmospheric model uses a t159 triangular truncation at wavenumber 159 grid with horizontal spectral resolution of 125 km and 62 vertical levels of a terrain following mixed sigma pressure hybrid coordinates of which about 15 are within the planetary boundary layer the lowest model level is at 30 m height and the highest level is at 5 hpa the ocean model in ec earth is the nucleus for european modeling of the ocean nemo vancoppenolle et al 2009 nemo uses a horizontal resolution of roughly one degree the ec earth performance skills have been evaluated in several studies e g hazeleger et al 2011 the ec earth runs were provided by several research groups as detailed in table 1 out of the seven ec earth runs used to force wam six are part of the regular cmip5 ec earth ensemble a seventh ec earth run pc20 6 with an increased number of vertical levels is also used the ec earth runs were initialized between 1850 and 1855 spanning until 2005 each ec earth simulation is independent and no bias corrections were applied the seven dynamical wave simulations were produced by forcing the 3rd generation wave model wam wamdi group 1988 with u10 components east west and north south every 6 hours and daily sea ice concentration from each of the cmip5 ec earth runs we use wam cycle 4 5 3 an update of the wam cycle 4 described in gunther et al 1992 and janssen 2008 the source function integration scheme made by hersbach and janssen 1999 and the model updates by bidlot et al 2007 are incorporated the wam simulations were performed on a regular global latitude longitude grid covering a latitude range of 78 n to 78 s and using a fixed spatial grid size of 1 degree the spectral domain is discretized into 25 frequency bins in a geometrical progression with a common ratio of 1 1 that cover the range from 0 04177 to 0 41145 hz wave directions are discretized into 15 bins the 1 minute world gridded elevations bathymetry etopo1 data amante and eakins 2009 defines the water depths wam was run for each ensemble member for an approximate twentieth century time slice from 1970 to 2005 representing the present or historical climate the ensemble members will hereafter be mentioned for convenience by pc20 present climate 20th century followed by their ensemble number pc20 i where i is 1 to 7 see table 1 and the ensemble as pc20e for convenience we will use the pc20 for both the ec earth and wave climate runs since we will analyze both the wind speed u10 and significant wave height hs the wam cycle 4 5 3 did not implement a sub grid parametrization which causes the sea states in regions with islands smaller than the computational grid to be overestimated e g semedo et al 2013 2018 2 2 multi platform altimeter dataset the multi platform altimeter product abbreviated as alt herein was quality controlled and calibrated by queffeulou and croize fillon 2017 it was produced as part of the globwave project and is now extended to form the first version of the sea state climate change initiative database seastatecci v0 here we use a 10 year period to assess the simulations from 1996 through 2005 this period is chosen because there are the largest number of observations during the historical ec earth simulations 1970 2005 for the period 1996 2005 there are 6 missions ers1 1991 96 ers2 1996 2011 envisat 2002 12 topex 1993 2005 jason1 2002 13 and gfo 2000 07 observations from each platform have been cross calibrated between platforms and calibrated to moored buoys queffeulou and croize fillon 2017 the multi mission dataset is expected to be consistent in time with very little deviation between platforms since the 1 hz altimeter measurements capture the instantaneous and spatially localized estimate of hs it is an unfair comparison with the time space averaged outcome of the spectral wave model e g chawla et al 2013 stopa and cheung 2014a therefore we average all observations within the 1 degree bin from the various satellite platforms that fall within a one hour window the 1 degree bin matches the output of the wam simulations this one hour average represents the satellite observation and is comparable to the time scales resolved by the phase averaged spectral wave model at 1 degree resolution chawla et al 2013 3 methodology and assessment of sampling techniques the ensemble uses a single forcing and a single wave model so it is expected that the intra ensemble variability of pc20e is small we create a wind speed ensemble and wave height ensemble using equal weighting of the seven simulations from ec earth and wam respectively in order to compare the performance of the dynamic climate simulations to the altimeter observations it is essential to capture the wind speed and wave height magnitudes and variance of the satellite observations which change as a function of time and space an example time series is given in fig 1 a taken from a location in the north atlantic 20 w 46 n the location is denoted by the black x in fig 1 b this point was chosen arbitrarily and used as an example to show the effects of satellite sampling notice that the number of satellite observations per month changes and there are a larger number of measurements from 2002 to 2005 when there were 4 concurrent missions we are not concerned with the sparsity of satellite observations we only consider the altimeter observations to be the reference dataset the different number of satellite observations in single bins compared to the regularly time spaced wave simulations impacts the statistics therefore our goal is to properly sample the simulations so that the statistical properties such as the median and various percentiles match the ones from the altimeter observations three fundamental sampling methods are tested 1 simple random sampling 2 systematic sampling and 3 stratified sampling simple random sampling uses an equal weighting to select an event without replacement from the larger population an event in our application is an individual time step this method minimizes biases but it can be vulnerable to sampling errors especially in the tails of the distribution systematic sampling first orders the dataset and then chooses events at regular intervals based on a random starting position for our application we sort the data by time a disadvantage of systematic sampling is that it might not capture events that are periodic in nature such as diurnal cycles stratified sampling is the process of first dividing all possible events into mutually exclusive subgroups or strata before sampling in our case the strata are months and the events are the individual time steps for each month or strata we use simple random sampling or systematic sampling to select the events we tested a combination of these sampling techniques and summarize them with the following four cases in each 1 degree bin let m be the total number of time steps available from the gcm simulation and n be the number of altimeter observations where m n case 1 simple random sampling n time steps are randomly chosen from the entire climate simulation time series of length m without replacement case 2 systematic sampling data are selected every d x i n t m n where int denotes the greatest integer the floor function by randomly choosing an initial index i 0 within the range 1 dx of the time series case 3 monthly stratified with simple random sampling version 1 here we select a variable number of events from each monthly pc20 i strata the number of events selected directly corresponds to the number of satellite observations for the given month for example in fig 1 a there are 3 observations in january 2001 this means we randomly select 3 events from the model simulations in january 2001 case 4 monthly stratified with simple random sampling version 2 here we select the same number of events each month the number of events for a given location is defined by the average number of satellite observations for the complete time series referring to fig 1 a there is an average of 6 samples per month for 1996 2005 thus 6 events are selected from each month assuming the complete 6 h model simulation represents the true probability density function f we can estimate the variance for a given percentile p 0 1 as 1 σ 2 1 f x p 2 p 1 p n where xp represents the given variable hs or u10 at the given percentile the total number of satellite observations in 1 degree bins are shown in fig 1 b for the period 1996 2005 the asymptotic variance eq 1 was assessed by brown and wolfe 1983 for smaller sample sizes n 160 than our application therefore we expect eq 1 is an unbiased estimator of the variance since there are at least 350 samples in each 1 degree bin we repeat the sampling procedures above for a number of trials the final statistics are created by averaging all of the trials without loss of generality we use the hs from pc20 1 to assess both the magnitude and variance of the sub sampled datasets in fig 2 we show results of the different sampling methods relative to statistics of the full time series using the time series in fig 1 for a single trial fig 2 a and e all methods capture the percentile within 5 of the expected value however the variance can have large discrepancies 10 15 notice the extremes of the distribution are not well captured especially for percentiles 90 if we use ten trials and then average the statistics we can reduce the differences in sampled magnitudes and variance of the full time series as shown in fig 2 b and f however it is still difficult to capture the variance of the largest events next we assess the ability of the sampling methods to capture the seasonality and use december january february djf fig 2 c and g and june july august jja fig 2 d and h as representative seasons in djf fig 2 c and g when the waves are large all cases match the percentiles 10 difference all sampling techniques perform similarly and the largest differences are still in the tails of the distribution for percentiles less than 90 95 all sampling methods capture the magnitude and variance reasonably well in jja when hs is smaller we find similar results case 3 sampling has the most pronounced deviations from the reference full 6 hourly time series with variances varying 2 fig 2 h overall case 2 seems to perform the best because the percentiles are within 1 fig 2 b and the variance is well matched for the majority of the percentiles fig 2 f in order to optimize our sampling technique various trials were tested using the 95th percentile p95 pc20 1 hs time series in the north atlantic not shown after 25 trials all of the sampling methods are less than 3 of the p95 observations not shown cases 1 and 2 systematically converged with a lower number of trials than cases 3 and 4 after 10 trials only marginal improvements were observed therefore in the remainder of the study we average 10 trials to represent the statistics from the sampled simulations the spatial distribution of the sampling effects for hs p95 in fig 3 are analyzed next we compare both the ratio of hs p95 p95 sample p95 all and the ratio of hs p95 variance varsample varall for all cases cases 1 and 2 perform similarly and the ratios of hs p95 are close to one meaning nearly a perfect match the spatial distribution of the variance of the sampled time series from case 1 and 2 is nearly uniform across the basins fig 3 b and d the variance of the time series using case 1 and case 2 sampling is typically 5 larger that the full 6 hourly time series it is expected that the sampled dataset has a larger variance than the 6 hour time series because the full time series has approximately 10 times more data the case 3 ratios p95 sample p95 all of hs p95 in fig 3 e have a distinct spatial pattern with 2 deviations from the p95 hs full time series used as reference in the north atlantic western pacific and northern indian oceans case 3 sampling underestimates hs p95 while in the indian north eastern pacific and south atlantic oceans case 3 sampling overestimates hs p95 in case 3 sampling we select the actual number of altimeter observations from the corresponding month of the simulated dataset this means the number of events selected from the simulated time series in january 1996 corresponds to the actual number of altimeter observations in january 1996 consequently case 3 sampling favors months in 2003 2005 since there are more satellites in operation see fig 1 this sampling strategy introduces the largest spatial differences with respect to the full time series because the months that have more altimeter observations do not correspond to same months in the gcm forced wave simulations for all cases the variance of the sampled dataset is 5 10 larger than variance of the full time series shown in panels b d f and h in fig 3 the magnitude of the hs p95 ratios p95 sample p95 all between the sampled and full time series using case 4 sampling in fig 3 g is nearly one similar to cases 1 and 2 fig 3 a and c there is a subtle tendency for case 4 to overestimate hs p95 in the northwest pacific north atlantic 30 n and in the mediterranean fig 3 g the variance ratio of the case 4 sampling in fig 3 h is slightly larger than cases 1 and 2 6 7 for case 4 sampling compared to 4 5 for cases 1 and 2 fig 3 b and d the performance of each sampling procedure is summarized in table 2 by comparing various hs percentile and variance ratios s a m p l e d t i m e s e r i e s f u l l t i m e s e r i e s in percentages we compare the percentiles 5th 50th median and 95th in different zonal regions northern hemisphere nh 25 n equatorial region eq 25 n s and southern hemisphere sh 25 s and seasons djf and jja all sampling methods capture the overall variance very well and the errors are typically less than 0 5 the results in table 2 reflect similar features seen in figs 2 and 3 and are summarized as follows all sampling methods overestimate the small percentiles and the variance is often 1 the medians are very well matched using any of the sampling methods case 3 sampling introduces spatial discrepancies typically all sampled hs p95 match the full time series and hs p95 ratios are 0 1 the sampled datasets have larger variance than the full time 6 hourly series table 2 shows the variance can be considerably larger using the sampled time series for particular seasons djf and jja compared to the full time series especially for p95 we consistently find case 2 systematic sampling performs the best therefore this method is implemented to sample the climate simulations to match the satellite observations we continue to use the average of the 10 trials as a representative sample of the simulated climate wave data since using only one trial can have large differences of magnitude and variability relative to the observations see fig 2 a and e 4 assessment of the wind and wave climate simulations in this section we assess the sampled u10 and hs datasets pc20 1 to pc20 7 relative to the altimeter observations by analyzing the spatial errors the probability density functions pdfs seasonality inter annual variability and large sea states 4 1 spatial features and statistical properties first we highlight the spatial differences and variability between the ensemble and observations for various statistics such as the median p50 and upper percentile p95 wind speeds and wave heights for the entire 10 year period fig 4 shows the comparison between pc20e and alt for both u10 and hs at p50 the u10 p50 residuals pc20e alt in fig 4 b show that ec earth underestimates u10 by 1 2 ms 1 across the majority of the ocean near the equator there is a strong underestimation of u10 that is persistent for all simulations pc20 1 to pc20 7 however we should note that near the equator nadir looking altimeters are not the best source of wind and or wave data since the calm ocean surface coupled with weak winds can have nearly a specular reflection thus producing erroneous high wind speeds elfouhaily et al 1998 in addition there are impacts from the sea state which distort u10 when only the radar cross section one parameter approximation is used to estimate u10 gourrion et al 2002 consequently the u10 from altimeters is often higher than the reference buoy wind speeds especially in low wind regions young et al 2017 near the ice edge in the southern ocean there is a typical underestimation of 1 2 ms 1 otherwise the ensemble data in the extra tropics 30 50 n s which are important wave generation regions agree with altimeter observations u 10 a l t u 10 p c 20 e 0 5 ms 1 the intra ensemble variability from the seven simulations in fig 4 c is low 0 2 ms 1 with respect to the u10 differences typically 1 ms 1 which equates to 20 of the variability of the ensemble regions in the sh extra tropics eastern equatorial indian ocean and the trade wind regions of the nh and sh have the largest intra ensemble variations in fig 4 d f we show the p50 hs comparison between pc20e and alt overall the hs p50 of pc20e matches the observations within 0 25 m across the majority of the ocean the ensemble overestimates hs otherwise there are only select regions such as the nw atlantic mediterranean gulf of mexico and western pacific where pc20e underestimates hs this might be partially related to discrepancies in u10 altimeters tend to overestimate wave heights in low sea states sepulveda et al 2015 kudryavtseva and soomere 2017 so wave intensity in regions like the mediterranean and gulf of mexico which typically have small wave heights might be overestimated by the altimeters consequently in low sea states it is difficult to assess the simulations when using the altimeters as reference in the pacific trade wind regions the ensemble systematically overestimates hs by 0 5 m with a global maximum difference p50 hs pc20e alt coinciding near micronesia 130 w 20 s some of these features are related to unresolved islands smaller than the 1 resolution similar to features seen in semedo et al 2013 the intra ensemble variability is low and the hs deviations are less than 10 cm so near the noted large differences in the trade wind regions the intra ensemble variability is 4 of the residuals the intra ensemble variability in the southern ocean is 3 to 10 cm which is 12 to 25 of the typical 25 cm hs p50 residual so the ensemble reduces some of the uncertainty in the sh compared to using only one simulation in fig 5 we show the corresponding plots for the u10 and hs for the upper percentiles p95 the u10 p95 residuals in fig 5 b have nearly the same spatial structure as u10 p50 residuals in fig 4 b the most obvious difference is that the u10 p95 residuals have enhanced underestimation near the western boundaries in the tropics 5 30 n s relative to the u10 p50 residuals these regions are affected by tropical cyclones and the ensemble underestimates u10 p95 by 1 2 ms 1 the intra ensemble variability in fig 5 c is largest in the nh extra tropics 30 60 n in the nh extra tropics there are ec earth u10 p95 deviations of 0 2 0 3 ms 1 this is 40 60 of the average value of the residuals 0 5 ms 1 in fig 5 b therefore in these regions i e the gold colored areas in fig 5 c the use of the ensemble improves the performance the bottom panels of fig 5 show the corresponding plots for the hs at p95 the hs p95 residuals pc20e alt in fig 5 e are positive in the trade wind regions of the pacific meaning that pc20e overestimates hs p95 the spatial pattern of the hs p95 residuals in fig 5 e is similar to hs p50 residual in fig 4 e in the nh and sh extra tropics 30 60 n s the ensemble overestimates hs at p95 by at least 0 5 m and in some areas the hs p95 residuals exceed 0 75 m for example in the north pacific near the aleutians and south pacific near the ice edge the hs p95 is much higher exceeds 0 75 m than the observations ec earth underestimates u10 p95 in the western portion of the pacific and atlantic and likely contributes to a portion of the underestimation of hs the underestimation in the western portion of the pacific and atlantic is compounded by the fact that spectral wave models underestimate hs in rapidly changing short fetch conditions e g ardhuin et al 2010 similar to u10 p95 the intra ensemble variability helps to reduce the hs p95 differences mostly in the nh extra tropics with standard deviations of 0 2 m this is approximately 20 of the common hs p95 residual of 1 m next we compare the pdfs and the quantiles to give further insights on the performance of the climate simulations fig 6 shows the u10 probability distributions and quantile quantile qq plots the shape of the pdfs calculated from the simulations match the ones obtained from observations well but the pdfs are mis aligned in particular when u10 5 10 ms 1 the probabilities obtained from the simulations are larger than the probabilities obtained from the altimeter observations when u10 5 10 ms 1 the probabilities obtained from the simulations are lower than those of the altimeters in these plots each of the seven simulations is analyzed separately and its results plotted with a different color the pdfs obtained from the simulations are nearly the same and only subtle differences are distinguishable in this representation the qq plots show ec earth underestimates u10 uniformly across all wind speeds by approximately 0 75 ms 1 notice that in each region the qq plots are similar besides the noted spatial differences discussed in the previous section the simulations perform equally well in the different latitude bands we provide the corresponding pdfs for the hs in fig 7 the shape of pdfs obtained from the wave simulations is similar to the pdfs obtained from altimeter observations but they are mis aligned when hs 2 3 m the probabilities obtained from the simulations are smaller than the probabilities obtained from the altimeter observations when hs 2 3 m the probabilities obtained from the simulations are larger than those of the altimeter observations the wave simulations favor the mid range 2 hs 3 m more than the altimeter observations as shown by the reduced width of the pdfs obtained from the wave simulations we can see some distinction 2 difference between the pc20 i members near the median this effect is most evident in the sh in the sh there are the largest differences between the pdfs obtained from the wave simulations and the altimeter observations here the pdfs obtained from the simulations have higher occurrence of sea states with 2 hs 4 m compared to the pdfs obtained from the altimeter observations the qq plots show that the simulations of the lower percentiles median are often 0 25 m larger than the altimeter observations for the higher percentiles such as p95 the simulations overestimate hs by 0 25 0 5 m relative to the observations the qq hs results here in fig 7 are consistent with the buoy comparisons of semedo et al 2018 their figure 10 and show that hs is typically overestimated however in our analysis the comparisons are global and extend to wave heights of 8 m thus establishing the validity of the wave simulations to larger sea states notice that the global qq hs differences are reflective of the patterns observed in the sh since in the nh the pdfs obtained from the wave simulations match those of the observations reasonably well near the equator eq 25 n s in the lower percentiles p50 the wave heights are overestimated the largest contribution comes from the lower latitudes 15 as shown in figs 4 e and 5 e these areas are dominated by swell and the underestimation of the swell dissipation in wam might be contributing to the discrepancies in the sh the differences in the pdfs obtained from the wave simulations and altimeter observations are the largest the hs probabilities obtained from the simulations are lower than those of the altimeters for low sea states hs 2 m for sea states with 2 hs 5 m the probabilities obtained from the simulations are higher than those of the altimeters the hs qq plots show the thresholds for a given wave height quantile is overestimated in low seas p50 and high seas p95 we observe the largest variability between the ensemble members in the upper percentiles in summary u10 is underestimated by ec earth and hs is overestimated by the wave simulations this suggests the wave model physical parameterizations are causing the differences and not necessarily the forcing wind 4 2 seasonality to assess the ability of the pc20 e members to capture seasonality we use a metric called the mean annual variability mav stopa et al 2013 it is defined as the average of the annual standard deviation normalized by the annual average 2 m a v σ i x i where index i refers to the year σ is the standard deviation and the overbar denotes average we compare the mav between the ensemble average pc20 e and alt in fig 8 note that the altimeter patterns of the u10 and hs are provided as reference in fig 8 a and c the spatial pattern and magnitudes of the mav computed from the altimeter observations is similar to that of the mav computed from the cfsr wave hindcast of chawla et al 2013 and presented in stopa et al 2013 their figure 6 u10 from ec earth has more seasonal variability than the altimeters see fig 8 b in particular pc20e has a larger seasonality in the southern ocean extra tropics this might partially be influenced by the ice coverage near the equator pc20e has a larger mav north of the inter tropical convergence zone itcz and a smaller mav south of the itcz relative to the observations however it is expected the altimeter u 10 is of poorer quality near the itcz due to sea state impacts when the wind is calm and specular reflection is strong gourrion et al 2002 the hs comparison in fig 8 d shows the ensemble typically underestimates the wave seasonality by as much as 15 but typically 4 8 it is possible that there are missing physical parameterizations within the wave model or the physical parameterizations are not responding correctly to the wind input since we observe higher mav in u10 and lower mav in the wave field the seasonality within the ensemble is further analyzed in figs 9 and 10 here we present only results from the p95 since the spatial patterns for other percentiles and the average were nearly the same in djf fig 9 b the u10 p95 differences between pc20 e and alt are largest in the sh trade wind regions in the pacific and in the nw atlantic otherwise the differences are less than 1 ms 1 ec earth is overestimating u10 p95 in the sh extra tropics but usually less than 0 5 ms 1 the intra ensemble variability in fig 9 c is largest in the nh sh extra tropics and near the eq in the indian ocean the corresponding hs p95 residuals of pc20e alt in fig 9 e are similar to the u10 p95 residuals with the zonal pattern pc20e overestimates in 40 60 n s and pc20e underestimates 20 30 n s near the eq the u10 and hs p95 residuals have opposite signs with an overestimation in hs and an underestimation of u10 in jja fig 10 b ec earth underestimates u10 p95 relative to alt across the majority of the global ocean there are some exceptions where ec earth overestimates u10 p95 such as regions in the north pacific nw atlantic and near eastern africa in the nh the u10 and hs from the wind and wave ensembles are not capturing the tropical cyclones that are more common this time of the year especially in the western pacific fig 10 b and e the intra ensemble variability is largest in the sh for both u10 and hs p95 fig 10 c and f if a single member was used the differences in the sh might be larger than pc20 e shown in fig 10 b where the average is 1 ms 1 the ensemble produces a better estimation of the seasonality especially in the sh the spatial pattern of hs p95 residuals in fig 10 e do not match the u10 p95 residuals except for the region in the western pacific pc20 e overestimates the hs p95 relative to alt on average by 0 35 m with some regions in the sh and nh extra tropics exceeding 0 5 m in both the nh and sh extra tropics the intra ensemble variability is largest and 0 25 m fig 10 f in the wave generation regions of the extra tropics pc20e underestimates u10 p95 while pc20e underestimates hs p95 some of the other hs discrepancies are due to land mask used in the wam set up which is different from the one used in era interim additionally the wam version v4 5 3 used here is known to dissipate swell improperly in the low latitudes contributing to an overestimation of the wave heights there semedo et al 2013 these differences such as higher waves in the tropics around polynesia micronesia the maldives and near the aleutians islands might also occur due to unresolved sub grid scale bathymetry the intra ensemble variability in u10 and hs is largest in the nh and sh extra tropics 4 3 inter annual variability lastly we assess the ability of the ensemble to capture inter annual variability iav over this 10 year period the iav is defined as the standard deviation of the annual averages normalized by the overall average 3 i a v σ x i x we compare the iav between pc20 e and alt in fig 11 the spatial patterns of the altimeter observations in fig 11 a and c qualitatively look similar to the iav of cfsr presented in stopa et al 2013 their figure 7 the u10 iav maxima of the altimeter observations fig 11 a are located in the eastern and western equatorial pacific the hs iav maxima of altimeter observations fig 11 c are located in the southern ocean near chile and in the western pacific 120 e 15 n the u10 iav residuals between pc20e and alt are largest near the equator especially in the pacific which might be related to not properly capturing the el nino southern oscillation enso which is known to be the dominant mode of inter annual variability in this region e g stopa and cheung 2014b otherwise the ec earth u10 ensemble has differences less than 1 across 84 of the global ocean fig 11 b suggesting ec earth u10 captures a large amount of the u10 iav the hs iav difference in fig 11 d shows that the iav for pc20 e is considerably less than the iav of the altimeter observations these large differences between pc20 e and alt mean the iav of the wave field is not well captured in pc20 e and is typically much smaller than the observations at least over this period of 10 years 5 discussion and conclusion the u10 and hs climate simulations were sampled such that their statistical properties such as average variance and percentiles replicated those of the altimeter observations we analyzed both the magnitude and the variance of several sampling techniques at various percentiles we found that systematic sampling case 2 performed better than the other tested sampling methods properly sampling climate simulations that do not capture the exact time history is particularly important when the reference observations are sparse and or the number of observations changes in time and space our methodology can be adapted to other climate simulation and observational datasets we systematically analyzed the skill of the ensemble in reproducing the wind speeds u10 and the resulting wave heights hs relative to the altimeter observations ec earth underestimates the magnitude of u10 uniformly across all percentiles the pdfs obtained from the u10 of ec earth and those obtained from the altimeter observations are very similar suggesting that ec earth is a satisfactory predictor of wind speeds globally even though pc20e underestimates u10 the wave heights are overestimated this suggests the implementation of wam is not properly calibrated for the ec earth wind field and it is possible to correct this bias by reducing the wind wave growth parameter βmax in the parametrization of janssen 1991 as shown by stopa 2018 in the nh the pdfs computed from u10 and hs of both the simulations and altimeter observations are similar however in the sh the pdfs are different therefore the performance of the simulations in the nh is better than the sh the qq plots also support this point the global discrepancies in the pdfs and qq plots strongly reflect the discrepancies of the sh stressing the importance of future efforts to better simulate the sh the almost identical match of the pdfs for the 7 simulations limits the possibilities of the ensemble to improve forecasts or hindcasts since the ensemble variance is much less than typical simulation observation error variances for example the hs standard deviations of wave hindcasts errors at buoys typically ranged from 40 or 0 3 to 0 8 m as presented by stopa and cheung 2014a their table 2 the hs standard deviation of pc20 e is generally small and less than 0 06 0 2 m at p50 p95 we find pc20 e overestimates hs in the tropics namely in the pacific ocean this region has an abundance of swell semedo et al 2011 and wam is most likely underestimating the swell decay in addition large hs discrepancies coincide with island chains in the pacific and are due to the treatment of sub grid features not resolved by the model grid resolution regions affected by tropical cyclones most notably in the western pacific are not well captured by the climate simulations and we observe a severe underestimation of hs at p95 the use of the ensemble has a minimal effect on improving the predictability in this case now that the wave simulations are sampled like the satellite measurements it is possible to develop a bias correction for the wave simulations and it is topic for future work notice that all of the sampling techniques introduce errors of less than 2 for hs at p95 see fig 3 while the hs model to simulation discrepancies at p95 are typically on the order of 10 25 fig 5 so we expect that our results are robust and there is minimal impact from the sampling technique applied the seasonality is reasonably captured by the u10 and hs ensembles we find some differences for example ec earth overestimates the u10 seasonality while the wave ensemble underestimates the hs seasonality this seasonal mismatch was found in other datasets for example seasonal residuals between a cfsr wave hindcast and altimeter observations both u10 and hs were observed in chawla et al 2013 and stopa and cheung 2014a this suggests the physical parameterizations in spectral wave models like wavewatch and wam have missing physical processes or the existing parameterizations can be improved to better capture the atmospheric response in both the strong and weak seasons such as temperature differences or water density differences we speculate that the current physical parameterizations in spectral wave models have the tendency to underestimate both growth and dissipation which might contribute to a portion of the hs seasonality residuals the ensemble improves the prediction of the seasons especially in the southern ocean otherwise the typical intra ensemble variability is less than or approximately 10 30 of the pc20e alt residuals the u10 from ec earth captures the important features of the inter annual variability on the other hand the gcm wave simulations have lower inter annual variability suggesting the time series of wave simulations forced by ec earth have a much smoother time series relative to the altimeter observations our comparison of the inter annual variability is a challenging test for the wave climate simulations one possible reason why we have such large differences in the iav between the simulations and satellite observations could be because we use a 10 year period a longer time series might capture more of the long term variability since the gcm forced wave simulations have difficulty in reproducing the iav caution should be taken when analyzing the inter annual variability of future climate scenarios improving the ability of the wave climate simulations to reproduce the inter annual variability is an opportunity for future efforts previous works use wave reanalysis or wave hindcasts to assess gcm forced wave simulations here we take a novel approach and we use altimeter observations as reference this is important because the altimeter database is expected to better represent the large sea states and are not subjected to missing or improper wave parameterizations as in models it also stresses the importance of having an accurate and quality controlled altimeter database and is currently being re assessed by the european space agency s sea state climate change initiative using the altimeter observations to assess the gcm simulations especially at large sea states hs p95 is certainly a benefit of applying the method in this study we provide more spatial details of the simulation errors and validate the simulations across a wider range of sea states compared to semedo et al 2018 who used reanalysis datasets and in situ buoys as reference datasets future assessments of the historical wave simulations either dynamical or statistical could use a similar methodology and compare to sparse observational datasets like our example of using the altimeter observations as reference overall the ec earth simulations and associated wave simulations capture the essential features of the climate since we understand the discrepancies between the simulations and satellite observations it is now possible to interpret the wave data for the future simulations which extend until the end of the 22nd century acknowledgments this work has been done under the auspices of the jcomm cowclip coordinated ocean wave climate projections project alvaro semedo has been supported by the project solar ptdc geomet 7078 2014 financed by portuguese foundation for science and technology fct gil lemos is supported by the earth systems doctoral school fct project uid geo 50019 2013 university of lisbon 
