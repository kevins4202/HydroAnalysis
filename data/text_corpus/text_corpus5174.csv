index,text
25870,reservoir construction and operation have significant impacts on catchment hydrology flood risk and fluvial processes however few available hydrological modelling packages can simulate complex dynamic manually operated reservoir control structures we present shetran reservoir a physically based spatially distributed modelling tool to simulate catchment hydrology including reservoir operations we also propose a method for deriving parsimonious reservoir operation rules from real world observations application of shetran reservoir to the upper cocker catchment in the lake district national park uk is shown to improve modelling of hydrological response modelling combined climate change and water resource management scenarios demonstrates the influence of operational control rules on hydrological impacts especially during droughts we discuss how shetran reservoir can be applied to other reservoir containing catchments to guide decisions concerning water resources ecology and flood risk we also discuss potential future software developments keywords reservoir management reservoir operations hydrology shetran climate change water resources 1 introduction 1 1 the importance of reservoirs reservoirs are used for water supply hydropower generation river regulation for navigation and flood risk control and recreation binnie 2004 brown et al 2009 globally there are over 57 000 registered large dams i e 15 m high or 5 m high and impounding 3 million m3 containing 14 600 km3 water equivalent to 1 6th of that found in freshwater lakes icold 2020 shiklomanov 1993 moreover thousands of new large reservoirs are being commissioned particularly in low and middle income countries in asia south america africa and the balkans couto and olden 2018 winemiller et al 2016 meanwhile operations at existing reservoirs are changing as a result of growing water demands economic pressures climate change environmental flow requirements and demands for multi purpose management reservoirs have important effects on hydrological systems allowing water transport through abstractions and discharges allowing large scale irrigation increasing surfacing water extents raising water tables regulating river flow regimes birnie gauvin et al 2017 disrupting sediment transport schmutz and sendzimir 2018 and fragmenting river habitats grill et al 2019 it is therefore important for hydrological models to reliably incorporate reservoir structures and operations 1 2 reservoir hydrological processes reservoir containing catchments exhibit standard terrestrial and additional reservoir hydrological processes fig 1 ideally reservoir models should integrate all of these interdependent processes to better manage the water environment zhao et al 2016 however these processes are typically represented by related yet distinct models 1 hydrologic 2 hydraulic and 3 water resources models 1 hydrology describes the spatial temporal distribution and fluxes of water within the catchment for example precipitation generates surface and subsurface reservoir inflows and outflows hydrological models aim to conserve mass within catchments they tend to route flow using simplified kinematic or diffusive wave forms of the saint venant equations castro orgaz and hager 2019 2 hydraulics describes the fluid mechanics of water more fully including velocity and depth energy and pressure important hydraulic effects in reservoirs include backwaters flow attenuation and tail waters at outflow control structures hydraulic models aim to conserve mass momentum and sometimes energy to study flood peak levels velocity and timing they generally use the full dynamic wave saint venant equations castro orgaz and hager 2019 3 water resources describes the storage treatment and distribution of water to satisfy demand water resources models typically include multiple interdependent water supplies and demand centres linked by complex networks at the catchment level processes include reservoir abstractions and operations such as environmental flow releases these in turn affect reservoir storage and river flow regimes 1 3 reservoir hydrological modelling review besides catchment hydrology reservoirs have been modelled for hydropower optimization ahmad and hossain 2020 agronomy brasil and medeiros 2020 geomorphology coulthard et al 2013 water quality zhang et al 2019 limnology elliott 2020 and socio hydrology di baldassarre et al 2017 these models should include key hydrological and water management processes below we briefly review the capabilities and limitations of current reservoir outflow modelling methods 1 3 1 stage discharge and storage discharge methods reservoir outflows are most commonly calculated as a function of reservoir water level stage or volume storage these are usually implemented as pre calculated empirically or theoretically derived tables this approach is applicable to lumped conceptual semi distributed and distributed models for example hbv calculates reservoir outflows using a storage discharge relationship bergström 1992 in the advanced hydrological prediction system for the american great lakes croley 2006 gronewold et al 2017 outflows from each lumped lake are calculated using empirically derived stage discharge equations while the hydraulic connections between the lakes allow for backwater effects some versions of the semi distributed soil and water assessment tool swat allow reservoir operations such as abstraction and diversions arnold and fohrer 2005 zhang et al 2019 swat2005 uses empirical relationships to estimate outflows from reservoirs zhang et al 2012 an alternative to pre calculated stage discharge relationships is the direct solution of outflow equations e g in mgb fleischmann et al 2019 spatially distributed models include similar reservoir hydrological processes in addition they can allow reservoirs to interact with surface and subsurface hydrology e g backwater effects fleischmann et al 2019 for example the finite difference modelling package water balance simulation model wasim includes reservoirs that can interact with surface and subsurface water and abstractions schulla 2019 with outflows calculated using volume discharge relationships similarly the university of belgrade s 3dnet package todorović et al 2019 can include hydraulic structures using elevation volume discharge curves to allow reservoir storage and routing to be simulated stanić et al 2018 a weakness of current stage discharge methods is the lack of active reservoir management e g to achieve seasonal target storage volumes correspondingly they tend to lack dynamic i e adjustable control structures such as sluice gates and pumps 1 3 2 discharge policy methods an alternative method suitable for large dams with high outflow capacities is to determine reservoir releases using policies or rules known as control rules curves conditional rules and target volumes for example the dynamically zoned target release dztr approach implemented in modélisation environmentale surface et hydrologie mesh uses a piecewise linear reservoir release function based on reservoir storage zones yassin et al 2019 similarly vic resopt can use control curves dang et al 2020 distributed hydrology soil vegetation model dhsvm also uses conditional rules zhao et al 2016 the catchment modelling framework cmf can include reservoir operations such as pumping with user defined functions kraft et al 2011 kraft and breuer 2020 some packages allow both stage discharge and discharge policy methods for example large area runoff simulation larsim allows emergency spillages driven by stage discharge relationships and operating rules governed by maximum drawdowns release volumes and variable target storage volumes leg 2019 ludwig and bremicker 2006 discharge policy methods are able to simulate active reservoir management however they generally assume that reservoirs are managed according to rational operating procedures enabled by accurate and automated control structures whilst this assumption may be reasonable for large dams with highly engineered control structures it is unsuitable for reservoirs with old imprecise and manually operated structures 1 3 3 water resource models water resource models are used to forecast and optimize interdependent water networks rani and moreira 2010 sulis and sechi 2013 although they rely on simplified catchment hydrology they include important processes that are often missing from catchment models for example hec ressim includes reservoir leakage controlled outlets with operating rules defined by the user uncontrolled outlets and pumps usace 2013 aquator allows reservoir spills and seepages to be calculated as a function of reservoir stage using weir equations oxford scientific software 2014a 2014b reconciling catchment and water resource models is challenging even some of the most recently developed models tools such as pywr tomlinson et al 2020 do not propose to explicitly model catchment hydrological processes however many aspects of their detailed outflow models can be more readily incorporated into catchment models dhi s proprietary mike software suite allows coupled catchment water resource models to simulate many pertinent reservoir hydrological processes mike she generates catchment runoff mike hydro river previously mike 11 simulates regulating hydraulic structures such as sluice gates with user defined control curves ngo et al 2005 and mike hydro basin simulates reservoir operations and abstractions dhi 2020a 2020b 2020c 2 objectives currently available reservoir hydrological modelling packages are poorly suited to simulating catchments with imprecise and or manually operated control structures furthermore coupled models may underestimate the intricate links between these different processes finally the poor understanding of reservoir operations is a key barrier to reservoir modelling hughes and mantel 2010 zhang et al 2012 there is therefore a need for a new integrated modelling package that allows simulation of dynamic and manually operated control structures this would allow combined analysis of changes in hydrology e g climate and water management e g changing abstractions we developed a physically based catchment hydrological modelling program to simulate multi level dynamic and manually operated control structures we tested this program by building a model of the upper cocker catchment uk and simulating the effects of climate change and changing reservoir operations this article describes the shetran reservoir modelling software and its application to the catchment assesses the functionality and fitness of the upper cocker model and discusses the software s capabilities limitations and potential applications 3 methods the methods section describes the following 1 study catchment 2 shetran standard model development 3 shetran reservoir program and model development and 4 climate change and water resources scenario development 3 1 study catchment and reservoir description the upper cocker catchment is part of the river derwent basin within the lake district national park in northern england fig 2 the mostly mountainous catchment drained by the river cocker to the scale hill gauging station has an area of 63 2 km2 the catchment contains three glacial moraine dammed lakes covering 6 5 of its area of these crummock water is the largest at 47 5 m deep with 1 5 m of its depth 4 mm3 or 6 volume being controlled fig 3 crummock s main inflows are the tributaries from upstream lakes buttermere and loweswater which account for 64 of crummock s upstream catchment area crummock water has been a raised lake since 1904 when a masonry weir was built to raise its water level above the natural outlet bed elevation the headworks comprises four parts 1 sluice gates 2 fish pass notch 3 main crest and 4 wing walls which overspill at high water level fig 4 the two main reservoir operations are direct lake abstraction and environmental flow release abstraction is via two gravity fed pipes and currently accounts for an average of 18 000 m3d 1 0 2 m3 s 1 or 5 of total outflows according to time series records environmental flows must be released to maintain 27 300 m3 d 1 0 32 m3 s 1 into the river cocker these are controlled by manually raising and lowering the sluice gates reservoir operations sustain river flow during dry periods and cause water levels to drop below weir crest nearly 10 of the time by up to 1m fig 5 abstraction at crummock water will cease by 2022 the water company and environmental regulators need to understand the impacts of management and climatic changes on catchment hydrology in particular lake level and river flow regimes 3 2 shetran standard model development shetran is freely available distributed catchment hydrological modelling software based on the système hydrologique européen she principles which simulates surface and subsurface flows and their interactions on a 3d spatial grid ewen et al 2000 shetran allows abstraction of surface and ground water and models lake flow attenuation lewis 2016 we initially used a recent version of shetran v 4 4 6 that lacks reservoir structures and operations which we refer to as shetran standard newcastle university 2020a a shetran standard model of the upper cocker catchment was built for benchmarking purposes several grid sizes were tested to obtain a reasonable representation of lake surface areas and the stream network while minimising computational expense a 500 m grid size was selected since 1000 m grids were too coarse and 200 m grids offered no notable improvements in model fitness spatial data inputs on this grid were mean and minimum digital elevation models dems rainfall areas land cover and soil maps fig 6 the time series inputs to the model were precipitation potential evaporation pe and reservoir abstraction precipitation is observed hourly data mm from three environment agency rain gauges using the thiessen polygons shown pe is interpolated daily data mm near crummock weir from the chess dataset robinson et al 2017 abstraction is the observed daily record from the operator see supplementary materials 1 for model data input details nb observed abstraction at crummock is relatively constant the model was initially built using the shetran prepare program with an infilled dem i e without lake bathymetry and automatically generated stream network this was subsequently replaced with a hollow dem i e with lake bathymetry with channel links removed from the lake grid cells channel link locations and bed elevations were also modified to match the physical catchment a user guide describing the procedure is available on the shetran website newcastle university 2020b the resulting configuration is three lakes that consist of sets of grid cells connected by streams fig 7 flow between lake grid cells and inflow outflow channel links relies on overbank flows whereby water spills over the bank between the grid element and channel link figs 7 and 8 flow is calculated using a broad crested weir equation over the length of the channel parkin 1995 3 3 shetran reservoir model development 3 3 1 outflow model development modellers frequently lack access to reservoir operating records and or policies we gained a broad conceptual understanding of sluice operations at crummock water through site visits and operator interviews during dry periods operators adjust the sluice gates daily to ensure sufficient environmental flows are released sluice opening lengths are primarily determined by the current reservoir stage operators informally consider recent and forecast weather given the mechanical imprecision of the sluices releases are often excessive to ensure compliance with minimum downstream flow requirements crummock s outflow model was developed in two stages firstly a static weir model i e with closed sluice was built to help identify sluice operating rules steps 1 5 secondly a dynamic weir model was developed steps 6 7 1 the static weir model was derived using surveyed weir geometry fig 4 and theoretical equations table 1 2 the static weir model was used to simulate downstream flow which was compared to observed flow 3 differences were used to infer the timing reservoir level input variable thresholds and resulting discharge output variable of specific operations fig 10 for example sluice opening was inferred when observed discharge increases while static model discharge decreases due to reservoir stage decrease i e increasing differences between the time series sluice closing was inferred when observed and static model discharges converge i e reducing differences between the time series precipitation driven discharge increases were identified by increases in both observed and simulated discharge 5 the timing and resulting discharge of specific operations were analysed to determine general real world operating rules 6 a dynamic weir model was developed by calibrating the sluice opening length a to fit modelled discharge to observed discharge 7 given the real world imprecision of sluice opening lengths and resulting model uncertainty parameter a sluice opening length was modified by 33 to give upper and lower values fig 11 we propose a generic framework for modelling other manually operated reservoirs requires time series of reservoir levels and downstream flows the steps are as follows 1 measure control structure geometry using surveys engineering drawings aerial imagery etc 2 record the operating procedures including any known operating regime periods using operator interviews written policies etc 3 develop a static weir model i e additional discharge structures closed using theoretical equations this can be as simple as a 1d model in a spreadsheet or programming script 4 split the time series into discrete operating regime periods if applicable split each period further into a calibration validation sample 5 use the static weir model to simulate downstream flow and compare to observed flow differences between the time series indicate discharge operations 6 use the differences to infer the timing reservoir level input variable thresholds and resulting discharge output variable of specific operations 7 analyse specific operations to determine general real world operating rules including conditional logic to describe the operation decision 8 identify the operational terms in the outflow equations i e terms that describe operations these may include sluice gates valves pumps etc 9 develop a dynamic weir model i e additional discharge structures operating by calibrating a the operational terms b conditional logic to fit the simulated discharge to observed discharge this process will yield a range of acceptable values for terms adopt the value that generates the best fit and additionally the upper and lower values for use in uncertainty analysis 10 validate the model for each discrete operating regime period 11 incorporate the validated dynamic model into the reservoir hydrological model this must include conditional logic to describe the operation decision and the resulting discharge 12 run simulations using the best fit dynamic model and upper and lower discharge models to indicate the range of uncertainty 3 3 2 outflow program reservoir models should simulate abstraction and discharge abstraction may be easily simulated using observations or estimates outflow simulation requires a mathematical model describing a control structure s specific design geometry and materials novak et al 2015 dam headworks such as weirs siphons bell mouths sluices valves and pumps are the most hydrologically pertinent part of reservoir control structures however chutes and terminal structures may also have hydraulically important effects pepper et al 2019 pepper et al 2019 many existing static reservoir models use fixed stage elevation discharge relationships we designed a program that allows dynamic control structures by including multiple elevation discharge relationships this is sufficiently flexible to represent any structure with moving parts this method relies on a valid pre computed outflow model and modellers may need to consider phenomena such as tail waters which restrict outflow particularly in low gradient downstream channels during high discharges this new method was implemented in shetran using several program modifications the modeler can now replace the standard spilling flow routing mechanism at the reservoir outlet with a new boundary condition whereby flow is read from a user defined elevation discharge zq table the zq table can contain multiple bespoke relationships describing downstream discharge as a function of upstream reservoir surface elevation the program currently assumes that reservoir operations take place daily at a user defined hour technical details about software development can be found in supplementary materials 2 the new software was used to modify the initial shetran standard model to incorporate reservoir operations into the shetran reservoir model 3 3 3 performance assessment the shetran standard and shetran reservoir models were run and validated against crummock reservoir stage and river cocker at scale hill river discharge for the five year period from 1st october 2011 to 1st october 2016 nash sutcliffe efficiency nse and water balance bias wb were calculated for discharge and root mean squared error rmse was calculated for discharge and reservoir stage to test model fitness moriasi et al 2015 wb is the total volume of simulated discharge divided by observed discharge 5 w b i 0 n qsimulated i 0 n qobserved 100 i e wb 1 indicates the simulation under predicts discharge and vice versa the ideal values are nse 0 5 and close to 1 perfect fit rmse minimised close to 0 perfect and wb close to 100 3 4 model application climate change and water resources scenarios construction the enhanced utility of the shetran reservoir model over the standard model was demonstrated using a climate change and abstraction scenario shetran reservoir can also simulate scenarios including changes in catchment land use reservoir releases and reservoir construction re engineering or decommissioning we constructed plausible scenarios in climate change and abstraction at crummock to explore the capabilities of the new model a notional climate change scenario relevant to dry periods was constructed by applying a simple 20 change factor to summer june july august precipitation in the observed series for 2018 this is consistent with the range of expected change chan et al 2018 meanwhile abstraction rates could conceivably increase to meet greater demand or decrease for environmental purposes accordingly three abstraction scenarios were run a abstraction cessation b current abstraction c doubled abstraction reservoir operators may adapt to a drier climate by releasing less environmental flow to conserve stored water therefore a reduced sluice opening length 33 was simulated for each abstraction scenario the shetran reservoir model was used to simulate the combined impacts of a drier summer 2018 changing abstraction and changing sluice operating regimes in the upper cocker 4 results and discussion 4 1 shetran standard model the shetran standard model lacks skill in reproducing reservoir stage and river flow particularly at high and low exceedances fig 9 at high exceedances dry periods observed reservoir stage drops below the main weir crest due to discharge over the main crest and through the fish pass notch evaporation abstraction and environmental flow release through sluice gate opening shetran standard does not simulate discharge through the sluice gate or fish pass notch consequently simulated reservoir levels are drawn down only to the weir crest this causes simulated discharge to approach zero meanwhile observed flows are maintained by sluice gate opening at low exceedances wet periods simulated reservoir levels are under predicted by shetran s spilling mechanism this is because river flow is calculated in this case using a high strickler runoff value this is an invalid representation of crummock s weir structure overall the shetran standard model exhibits poor fit with nse 0 53 table 2 the failure to simulate periods of low stage flow is a serious weakness for reservoir managers and ecologists for example reservoir managers may have to implement costly drought plans meanwhile these conditions physiologically stress aquatic flora and fauna in contrast high stage flow can cause flooding which reservoir management may mitigate these results highlight the need to adequately simulate reservoir operations such as environmental flow releases 4 2 shetran reservoir model 4 2 1 outflow model the dry period analysis reveals sluice operation 1 timing 2 criteria and 3 resulting discharge fig 10 1 sluice operations occur during working hours between 08 00 and 18 00 2 sluices are generally opened when reservoir elevation falls below 98 56 m 0 04 m above the main crest 3 sluice discharges are frequently excessive 0 32 m3 s 1 the sluice opening calibration exercise indicates that two lengths for reservoir stage above and below 98 56 maod yields good results table 1 equation 1b correspondingly the dynamic weir in the shetran reservoir model is operated daily at 12 00 when the reservoir elevation threshold of 98 56 m is crossed and one of two zq relationships is selected fig 11 the analysis highlights that real world operating conditions at crummock differ from ideal reservoir operations which would conserve water and release only the specified environmental flows the dynamic weir model is a simplified yet parsimonious simplification of the real world system in which sluice opening lengths are continuous and operation hours vary for old imprecise and manually operated structures simulating observed reservoir operation regimes is probably more appropriate than discharge policy methods such as ideal target volumes and ideal control rules 4 2 2 shetran reservoir model shetran reservoir outperforms shetran standard in several respects it successfully draws the reservoir water level below weir crest during dry periods fig 12 correspondingly the stage duration curve also shows a much better fit fig 13 furthermore it reproduces the reservoir stage dynamics 1 3m and reduces reservoir stage rmse 0 07 m compared to 0 17 m table 2 it also increases flow nse from 0 53 to 0 82 and decreases flow rmse from 3 7 to 2 3 m3 s 1 adjusting the simulated sluice opening length by 33 has only a small effect on discharge and reservoir stage these improvements are due to the valid dynamic weir model this includes the four weir components rather than simply spilling over a bank fig 8 in particular sluice operations generate flow and draw the reservoir stage below weir crest during dry periods nse is greatly improved despite this measure s insensitivity to low flow values moriasi et al 2015 the reason is that shetran reservoir improves not only the low flows but also flow peaks during and after dry periods as a result of more realistic antecedent reservoir levels nonetheless the improved low flow simulations are valuable although they account for small volumes of discharge low flows are crucial for aquatic ecologists and reservoir operators who must carefully balance environmental flow releases with water conservation furthermore the improved dry period flow peaks are useful as they can cause downstream flooding and ecologically important spate flows shetran reservoir is therefore a more powerful tool for investigating a range of hydrological questions the impact of adjusting the sluice opening length 33 is most visible in the cumulative reservoir drawdown in dry periods however this remains limited because the dry periods are not particularly severe 4 3 model application climate change and water resources scenarios the shetran reservoir model outputs demonstrate several aspects of reservoir response to changing climate abstraction and sluice operation regimes firstly when reservoir inflows are high abstraction makes little difference to the reservoir stage fig 14 this is because abstraction is compensated for by reduced discharge over the weir secondly when reservoir inflows are low may august reservoir stage drops below weir crest and small river discharges are maintained via the sluices outputs exceed inputs and consequently reservoir stage decreases the reservoir stage minima reached for abstraction scenarios a b and c with the current sluice operating regime are 0 3 m 0 6 m and 1 1 m below weir crest respectively thirdly greater abstractions also bring an earlier onset and later recovery of reservoir drawdown fourthly reservoir drawdown also attenuates subsequent flow peaks in agreement with others miotto et al 2007 furthermore intermittent rainfall during dry periods can cause small increases in discharge through open sluices the more conservative sluice opening length 33 0 2m has only a small effect in the early stages of reservoir drawdown however in combination with abstraction and over prolonged dry periods this cumulative conservation has a notable effect on reservoir storage up to 0 1m or 260 000 m3 nb reservoir storage volume can be calculated either as a sum of lake cell storages or using a hypsometric curve fig 3 the shetran reservoir model captures some vital aspects of catchment and reservoir response that the shetran standard model cannot the impacts of climate change and water resources scenarios need to be estimated by water managers and environmental regulators longer and deeper reservoir drawdowns place greater stress on water resources aquatic plants water quality etc the most drastic scenario c shows crummock s reservoir stage almost drawn down to the sluice invert below this critical threshold discharge would cease the more conservative operating regime would be unlikely to forestall this catchment and water resource managers need to plan for these scenarios to mitigate their impacts 5 overall discussion globally reservoirs are coming under pressure due to changes in climate water demand land cover and environmental flow requirements jackson 2006 reservoir modellers need tools to assess reservoir operations as well as catchments where reservoir construction or decommissioning is planned shetran reservoir and the transferable methods we propose here can be applied to other reservoir hydrological modelling problems in particular the method for deriving parsimonious operating rules and similar dynamic sluice modules can be implemented in other modelling packages a limitation of shetran reservoir s dynamic weir module is the assumption that reservoir operation is predominantly a function of reservoir stage other factors such as weather forecasts and antecedent conditions are implicitly rather than explicitly included in the operational rules in catchments where weather forecasts and catchment monitoring are increasingly used to refine operations including these explicitly may improve model predictions for example a more sophisticated model could use numerical weather forecast data that was available to operators in the past or from weather generators for future scenarios further investigation would be needed to ascertain whether this extra effort is rewarded by greater model skill similarly antecedent conditions such as upstream river lake levels and soil water storage could be used to inform sluice operations a more sophisticated agent based model could be developed although its extra predictive power might be negligible the dynamic weir module we present could be used to improve regional and national scale hydrological modelling lewis et al 2018 shetran reservoir can incorporate multiple reservoirs and allows the extraction of stream hydrographs at any channel link and reservoir stage at any lake cell further work could develop interdependent reservoir network models in a similar way to water resource models however modelling large reservoir networks remains challenging due to the lack of accurate requisite reservoir information e g bathymetry location abstraction fluxes discharge equations and operational procedures fleischmann et al 2019 passaia et al 2020 while some of this information is becoming more available via remote sensing data getirana et al 2018 pekel et al 2016 and reservoir databases durant and counsell 2018 mulligan et al 2020 yigzaw et al 2018 understanding of actual operational procedures remains a challenge the method we propose for deriving operational rules could provide a basis for addressing this 6 conclusion we have highlighted the importance of including reservoir hydrological processes in catchment hydrological models we identified that few if any catchment modelling packages are able to include manual reservoir operations and set out to incorporate this new functionality in shetran reservoir in developing shetran reservoir we emulated existing models insofar as we used an elevation discharge relationship to model reservoir outflows however unlike existing models we included the ability to add multiple dynamic discharge relationships in order to simulate manual sluice operations to test the new software we built a model for the upper cocker catchment that includes reservoir abstractions a complex weir model and empirically derived rules for sluice operations we developed a method for investigating the timing and opening lengths of sluice operations and deriving a parsimonious model to allow simulation of this real world behaviour we demonstrated that the new shetran reservoir model outperforms the shetran standard model improvements are particularly noticeable during and after dry periods when the reservoir stage drops below its main weir crest and reservoir operations dominate outflows we then used this model to run six climate change and water resources scenarios to further illustrate the effects of reservoir operations we discussed the importance of modelling reservoir operations for water resources ecology and flood risk purposes finally we discussed potential future work to improve these methods and applications to reservoir hydrological modelling shetran reservoir is now publically available the methods and software presented here can improve simulations of reservoir containing catchments worldwide software availability software name shetran version 4 5 0 shetran reservoir developers of latest version stephen birkinshaw daryl hughes geoff parkin contact s j birkinshaw ncl ac uk year first available 2020 availability and cost free open use software repository https github com nclwater shetran public software homepage https research ncl ac uk shetran software documentation http research ncl ac uk shetran shetran res documentationv1 zip program language fortran90 program size executable program 16 mb documentation 1 2 mb hardware required basic cpu ram storage drive software required microsoft xp vista windows 7 8 and 10 the standard version of shetran requires a 64 bit machine declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests the corresponding author s engd research is part funded by a water company united utilities plc the motivation to develop a reliable predictive hydrological model for crummock water reservoir originated with united utilities at project conception however united utilities has had no influence over the methodology scope and presentation of this manuscript this has been developed independently by the authors at newcastle university acknowledgements this work has been funded by the engineering and physical science research council epsrc and united utilities plc as part of the centre for doctoral training in skills technology research management stream ep l015412 1 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104980 
25870,reservoir construction and operation have significant impacts on catchment hydrology flood risk and fluvial processes however few available hydrological modelling packages can simulate complex dynamic manually operated reservoir control structures we present shetran reservoir a physically based spatially distributed modelling tool to simulate catchment hydrology including reservoir operations we also propose a method for deriving parsimonious reservoir operation rules from real world observations application of shetran reservoir to the upper cocker catchment in the lake district national park uk is shown to improve modelling of hydrological response modelling combined climate change and water resource management scenarios demonstrates the influence of operational control rules on hydrological impacts especially during droughts we discuss how shetran reservoir can be applied to other reservoir containing catchments to guide decisions concerning water resources ecology and flood risk we also discuss potential future software developments keywords reservoir management reservoir operations hydrology shetran climate change water resources 1 introduction 1 1 the importance of reservoirs reservoirs are used for water supply hydropower generation river regulation for navigation and flood risk control and recreation binnie 2004 brown et al 2009 globally there are over 57 000 registered large dams i e 15 m high or 5 m high and impounding 3 million m3 containing 14 600 km3 water equivalent to 1 6th of that found in freshwater lakes icold 2020 shiklomanov 1993 moreover thousands of new large reservoirs are being commissioned particularly in low and middle income countries in asia south america africa and the balkans couto and olden 2018 winemiller et al 2016 meanwhile operations at existing reservoirs are changing as a result of growing water demands economic pressures climate change environmental flow requirements and demands for multi purpose management reservoirs have important effects on hydrological systems allowing water transport through abstractions and discharges allowing large scale irrigation increasing surfacing water extents raising water tables regulating river flow regimes birnie gauvin et al 2017 disrupting sediment transport schmutz and sendzimir 2018 and fragmenting river habitats grill et al 2019 it is therefore important for hydrological models to reliably incorporate reservoir structures and operations 1 2 reservoir hydrological processes reservoir containing catchments exhibit standard terrestrial and additional reservoir hydrological processes fig 1 ideally reservoir models should integrate all of these interdependent processes to better manage the water environment zhao et al 2016 however these processes are typically represented by related yet distinct models 1 hydrologic 2 hydraulic and 3 water resources models 1 hydrology describes the spatial temporal distribution and fluxes of water within the catchment for example precipitation generates surface and subsurface reservoir inflows and outflows hydrological models aim to conserve mass within catchments they tend to route flow using simplified kinematic or diffusive wave forms of the saint venant equations castro orgaz and hager 2019 2 hydraulics describes the fluid mechanics of water more fully including velocity and depth energy and pressure important hydraulic effects in reservoirs include backwaters flow attenuation and tail waters at outflow control structures hydraulic models aim to conserve mass momentum and sometimes energy to study flood peak levels velocity and timing they generally use the full dynamic wave saint venant equations castro orgaz and hager 2019 3 water resources describes the storage treatment and distribution of water to satisfy demand water resources models typically include multiple interdependent water supplies and demand centres linked by complex networks at the catchment level processes include reservoir abstractions and operations such as environmental flow releases these in turn affect reservoir storage and river flow regimes 1 3 reservoir hydrological modelling review besides catchment hydrology reservoirs have been modelled for hydropower optimization ahmad and hossain 2020 agronomy brasil and medeiros 2020 geomorphology coulthard et al 2013 water quality zhang et al 2019 limnology elliott 2020 and socio hydrology di baldassarre et al 2017 these models should include key hydrological and water management processes below we briefly review the capabilities and limitations of current reservoir outflow modelling methods 1 3 1 stage discharge and storage discharge methods reservoir outflows are most commonly calculated as a function of reservoir water level stage or volume storage these are usually implemented as pre calculated empirically or theoretically derived tables this approach is applicable to lumped conceptual semi distributed and distributed models for example hbv calculates reservoir outflows using a storage discharge relationship bergström 1992 in the advanced hydrological prediction system for the american great lakes croley 2006 gronewold et al 2017 outflows from each lumped lake are calculated using empirically derived stage discharge equations while the hydraulic connections between the lakes allow for backwater effects some versions of the semi distributed soil and water assessment tool swat allow reservoir operations such as abstraction and diversions arnold and fohrer 2005 zhang et al 2019 swat2005 uses empirical relationships to estimate outflows from reservoirs zhang et al 2012 an alternative to pre calculated stage discharge relationships is the direct solution of outflow equations e g in mgb fleischmann et al 2019 spatially distributed models include similar reservoir hydrological processes in addition they can allow reservoirs to interact with surface and subsurface hydrology e g backwater effects fleischmann et al 2019 for example the finite difference modelling package water balance simulation model wasim includes reservoirs that can interact with surface and subsurface water and abstractions schulla 2019 with outflows calculated using volume discharge relationships similarly the university of belgrade s 3dnet package todorović et al 2019 can include hydraulic structures using elevation volume discharge curves to allow reservoir storage and routing to be simulated stanić et al 2018 a weakness of current stage discharge methods is the lack of active reservoir management e g to achieve seasonal target storage volumes correspondingly they tend to lack dynamic i e adjustable control structures such as sluice gates and pumps 1 3 2 discharge policy methods an alternative method suitable for large dams with high outflow capacities is to determine reservoir releases using policies or rules known as control rules curves conditional rules and target volumes for example the dynamically zoned target release dztr approach implemented in modélisation environmentale surface et hydrologie mesh uses a piecewise linear reservoir release function based on reservoir storage zones yassin et al 2019 similarly vic resopt can use control curves dang et al 2020 distributed hydrology soil vegetation model dhsvm also uses conditional rules zhao et al 2016 the catchment modelling framework cmf can include reservoir operations such as pumping with user defined functions kraft et al 2011 kraft and breuer 2020 some packages allow both stage discharge and discharge policy methods for example large area runoff simulation larsim allows emergency spillages driven by stage discharge relationships and operating rules governed by maximum drawdowns release volumes and variable target storage volumes leg 2019 ludwig and bremicker 2006 discharge policy methods are able to simulate active reservoir management however they generally assume that reservoirs are managed according to rational operating procedures enabled by accurate and automated control structures whilst this assumption may be reasonable for large dams with highly engineered control structures it is unsuitable for reservoirs with old imprecise and manually operated structures 1 3 3 water resource models water resource models are used to forecast and optimize interdependent water networks rani and moreira 2010 sulis and sechi 2013 although they rely on simplified catchment hydrology they include important processes that are often missing from catchment models for example hec ressim includes reservoir leakage controlled outlets with operating rules defined by the user uncontrolled outlets and pumps usace 2013 aquator allows reservoir spills and seepages to be calculated as a function of reservoir stage using weir equations oxford scientific software 2014a 2014b reconciling catchment and water resource models is challenging even some of the most recently developed models tools such as pywr tomlinson et al 2020 do not propose to explicitly model catchment hydrological processes however many aspects of their detailed outflow models can be more readily incorporated into catchment models dhi s proprietary mike software suite allows coupled catchment water resource models to simulate many pertinent reservoir hydrological processes mike she generates catchment runoff mike hydro river previously mike 11 simulates regulating hydraulic structures such as sluice gates with user defined control curves ngo et al 2005 and mike hydro basin simulates reservoir operations and abstractions dhi 2020a 2020b 2020c 2 objectives currently available reservoir hydrological modelling packages are poorly suited to simulating catchments with imprecise and or manually operated control structures furthermore coupled models may underestimate the intricate links between these different processes finally the poor understanding of reservoir operations is a key barrier to reservoir modelling hughes and mantel 2010 zhang et al 2012 there is therefore a need for a new integrated modelling package that allows simulation of dynamic and manually operated control structures this would allow combined analysis of changes in hydrology e g climate and water management e g changing abstractions we developed a physically based catchment hydrological modelling program to simulate multi level dynamic and manually operated control structures we tested this program by building a model of the upper cocker catchment uk and simulating the effects of climate change and changing reservoir operations this article describes the shetran reservoir modelling software and its application to the catchment assesses the functionality and fitness of the upper cocker model and discusses the software s capabilities limitations and potential applications 3 methods the methods section describes the following 1 study catchment 2 shetran standard model development 3 shetran reservoir program and model development and 4 climate change and water resources scenario development 3 1 study catchment and reservoir description the upper cocker catchment is part of the river derwent basin within the lake district national park in northern england fig 2 the mostly mountainous catchment drained by the river cocker to the scale hill gauging station has an area of 63 2 km2 the catchment contains three glacial moraine dammed lakes covering 6 5 of its area of these crummock water is the largest at 47 5 m deep with 1 5 m of its depth 4 mm3 or 6 volume being controlled fig 3 crummock s main inflows are the tributaries from upstream lakes buttermere and loweswater which account for 64 of crummock s upstream catchment area crummock water has been a raised lake since 1904 when a masonry weir was built to raise its water level above the natural outlet bed elevation the headworks comprises four parts 1 sluice gates 2 fish pass notch 3 main crest and 4 wing walls which overspill at high water level fig 4 the two main reservoir operations are direct lake abstraction and environmental flow release abstraction is via two gravity fed pipes and currently accounts for an average of 18 000 m3d 1 0 2 m3 s 1 or 5 of total outflows according to time series records environmental flows must be released to maintain 27 300 m3 d 1 0 32 m3 s 1 into the river cocker these are controlled by manually raising and lowering the sluice gates reservoir operations sustain river flow during dry periods and cause water levels to drop below weir crest nearly 10 of the time by up to 1m fig 5 abstraction at crummock water will cease by 2022 the water company and environmental regulators need to understand the impacts of management and climatic changes on catchment hydrology in particular lake level and river flow regimes 3 2 shetran standard model development shetran is freely available distributed catchment hydrological modelling software based on the système hydrologique européen she principles which simulates surface and subsurface flows and their interactions on a 3d spatial grid ewen et al 2000 shetran allows abstraction of surface and ground water and models lake flow attenuation lewis 2016 we initially used a recent version of shetran v 4 4 6 that lacks reservoir structures and operations which we refer to as shetran standard newcastle university 2020a a shetran standard model of the upper cocker catchment was built for benchmarking purposes several grid sizes were tested to obtain a reasonable representation of lake surface areas and the stream network while minimising computational expense a 500 m grid size was selected since 1000 m grids were too coarse and 200 m grids offered no notable improvements in model fitness spatial data inputs on this grid were mean and minimum digital elevation models dems rainfall areas land cover and soil maps fig 6 the time series inputs to the model were precipitation potential evaporation pe and reservoir abstraction precipitation is observed hourly data mm from three environment agency rain gauges using the thiessen polygons shown pe is interpolated daily data mm near crummock weir from the chess dataset robinson et al 2017 abstraction is the observed daily record from the operator see supplementary materials 1 for model data input details nb observed abstraction at crummock is relatively constant the model was initially built using the shetran prepare program with an infilled dem i e without lake bathymetry and automatically generated stream network this was subsequently replaced with a hollow dem i e with lake bathymetry with channel links removed from the lake grid cells channel link locations and bed elevations were also modified to match the physical catchment a user guide describing the procedure is available on the shetran website newcastle university 2020b the resulting configuration is three lakes that consist of sets of grid cells connected by streams fig 7 flow between lake grid cells and inflow outflow channel links relies on overbank flows whereby water spills over the bank between the grid element and channel link figs 7 and 8 flow is calculated using a broad crested weir equation over the length of the channel parkin 1995 3 3 shetran reservoir model development 3 3 1 outflow model development modellers frequently lack access to reservoir operating records and or policies we gained a broad conceptual understanding of sluice operations at crummock water through site visits and operator interviews during dry periods operators adjust the sluice gates daily to ensure sufficient environmental flows are released sluice opening lengths are primarily determined by the current reservoir stage operators informally consider recent and forecast weather given the mechanical imprecision of the sluices releases are often excessive to ensure compliance with minimum downstream flow requirements crummock s outflow model was developed in two stages firstly a static weir model i e with closed sluice was built to help identify sluice operating rules steps 1 5 secondly a dynamic weir model was developed steps 6 7 1 the static weir model was derived using surveyed weir geometry fig 4 and theoretical equations table 1 2 the static weir model was used to simulate downstream flow which was compared to observed flow 3 differences were used to infer the timing reservoir level input variable thresholds and resulting discharge output variable of specific operations fig 10 for example sluice opening was inferred when observed discharge increases while static model discharge decreases due to reservoir stage decrease i e increasing differences between the time series sluice closing was inferred when observed and static model discharges converge i e reducing differences between the time series precipitation driven discharge increases were identified by increases in both observed and simulated discharge 5 the timing and resulting discharge of specific operations were analysed to determine general real world operating rules 6 a dynamic weir model was developed by calibrating the sluice opening length a to fit modelled discharge to observed discharge 7 given the real world imprecision of sluice opening lengths and resulting model uncertainty parameter a sluice opening length was modified by 33 to give upper and lower values fig 11 we propose a generic framework for modelling other manually operated reservoirs requires time series of reservoir levels and downstream flows the steps are as follows 1 measure control structure geometry using surveys engineering drawings aerial imagery etc 2 record the operating procedures including any known operating regime periods using operator interviews written policies etc 3 develop a static weir model i e additional discharge structures closed using theoretical equations this can be as simple as a 1d model in a spreadsheet or programming script 4 split the time series into discrete operating regime periods if applicable split each period further into a calibration validation sample 5 use the static weir model to simulate downstream flow and compare to observed flow differences between the time series indicate discharge operations 6 use the differences to infer the timing reservoir level input variable thresholds and resulting discharge output variable of specific operations 7 analyse specific operations to determine general real world operating rules including conditional logic to describe the operation decision 8 identify the operational terms in the outflow equations i e terms that describe operations these may include sluice gates valves pumps etc 9 develop a dynamic weir model i e additional discharge structures operating by calibrating a the operational terms b conditional logic to fit the simulated discharge to observed discharge this process will yield a range of acceptable values for terms adopt the value that generates the best fit and additionally the upper and lower values for use in uncertainty analysis 10 validate the model for each discrete operating regime period 11 incorporate the validated dynamic model into the reservoir hydrological model this must include conditional logic to describe the operation decision and the resulting discharge 12 run simulations using the best fit dynamic model and upper and lower discharge models to indicate the range of uncertainty 3 3 2 outflow program reservoir models should simulate abstraction and discharge abstraction may be easily simulated using observations or estimates outflow simulation requires a mathematical model describing a control structure s specific design geometry and materials novak et al 2015 dam headworks such as weirs siphons bell mouths sluices valves and pumps are the most hydrologically pertinent part of reservoir control structures however chutes and terminal structures may also have hydraulically important effects pepper et al 2019 pepper et al 2019 many existing static reservoir models use fixed stage elevation discharge relationships we designed a program that allows dynamic control structures by including multiple elevation discharge relationships this is sufficiently flexible to represent any structure with moving parts this method relies on a valid pre computed outflow model and modellers may need to consider phenomena such as tail waters which restrict outflow particularly in low gradient downstream channels during high discharges this new method was implemented in shetran using several program modifications the modeler can now replace the standard spilling flow routing mechanism at the reservoir outlet with a new boundary condition whereby flow is read from a user defined elevation discharge zq table the zq table can contain multiple bespoke relationships describing downstream discharge as a function of upstream reservoir surface elevation the program currently assumes that reservoir operations take place daily at a user defined hour technical details about software development can be found in supplementary materials 2 the new software was used to modify the initial shetran standard model to incorporate reservoir operations into the shetran reservoir model 3 3 3 performance assessment the shetran standard and shetran reservoir models were run and validated against crummock reservoir stage and river cocker at scale hill river discharge for the five year period from 1st october 2011 to 1st october 2016 nash sutcliffe efficiency nse and water balance bias wb were calculated for discharge and root mean squared error rmse was calculated for discharge and reservoir stage to test model fitness moriasi et al 2015 wb is the total volume of simulated discharge divided by observed discharge 5 w b i 0 n qsimulated i 0 n qobserved 100 i e wb 1 indicates the simulation under predicts discharge and vice versa the ideal values are nse 0 5 and close to 1 perfect fit rmse minimised close to 0 perfect and wb close to 100 3 4 model application climate change and water resources scenarios construction the enhanced utility of the shetran reservoir model over the standard model was demonstrated using a climate change and abstraction scenario shetran reservoir can also simulate scenarios including changes in catchment land use reservoir releases and reservoir construction re engineering or decommissioning we constructed plausible scenarios in climate change and abstraction at crummock to explore the capabilities of the new model a notional climate change scenario relevant to dry periods was constructed by applying a simple 20 change factor to summer june july august precipitation in the observed series for 2018 this is consistent with the range of expected change chan et al 2018 meanwhile abstraction rates could conceivably increase to meet greater demand or decrease for environmental purposes accordingly three abstraction scenarios were run a abstraction cessation b current abstraction c doubled abstraction reservoir operators may adapt to a drier climate by releasing less environmental flow to conserve stored water therefore a reduced sluice opening length 33 was simulated for each abstraction scenario the shetran reservoir model was used to simulate the combined impacts of a drier summer 2018 changing abstraction and changing sluice operating regimes in the upper cocker 4 results and discussion 4 1 shetran standard model the shetran standard model lacks skill in reproducing reservoir stage and river flow particularly at high and low exceedances fig 9 at high exceedances dry periods observed reservoir stage drops below the main weir crest due to discharge over the main crest and through the fish pass notch evaporation abstraction and environmental flow release through sluice gate opening shetran standard does not simulate discharge through the sluice gate or fish pass notch consequently simulated reservoir levels are drawn down only to the weir crest this causes simulated discharge to approach zero meanwhile observed flows are maintained by sluice gate opening at low exceedances wet periods simulated reservoir levels are under predicted by shetran s spilling mechanism this is because river flow is calculated in this case using a high strickler runoff value this is an invalid representation of crummock s weir structure overall the shetran standard model exhibits poor fit with nse 0 53 table 2 the failure to simulate periods of low stage flow is a serious weakness for reservoir managers and ecologists for example reservoir managers may have to implement costly drought plans meanwhile these conditions physiologically stress aquatic flora and fauna in contrast high stage flow can cause flooding which reservoir management may mitigate these results highlight the need to adequately simulate reservoir operations such as environmental flow releases 4 2 shetran reservoir model 4 2 1 outflow model the dry period analysis reveals sluice operation 1 timing 2 criteria and 3 resulting discharge fig 10 1 sluice operations occur during working hours between 08 00 and 18 00 2 sluices are generally opened when reservoir elevation falls below 98 56 m 0 04 m above the main crest 3 sluice discharges are frequently excessive 0 32 m3 s 1 the sluice opening calibration exercise indicates that two lengths for reservoir stage above and below 98 56 maod yields good results table 1 equation 1b correspondingly the dynamic weir in the shetran reservoir model is operated daily at 12 00 when the reservoir elevation threshold of 98 56 m is crossed and one of two zq relationships is selected fig 11 the analysis highlights that real world operating conditions at crummock differ from ideal reservoir operations which would conserve water and release only the specified environmental flows the dynamic weir model is a simplified yet parsimonious simplification of the real world system in which sluice opening lengths are continuous and operation hours vary for old imprecise and manually operated structures simulating observed reservoir operation regimes is probably more appropriate than discharge policy methods such as ideal target volumes and ideal control rules 4 2 2 shetran reservoir model shetran reservoir outperforms shetran standard in several respects it successfully draws the reservoir water level below weir crest during dry periods fig 12 correspondingly the stage duration curve also shows a much better fit fig 13 furthermore it reproduces the reservoir stage dynamics 1 3m and reduces reservoir stage rmse 0 07 m compared to 0 17 m table 2 it also increases flow nse from 0 53 to 0 82 and decreases flow rmse from 3 7 to 2 3 m3 s 1 adjusting the simulated sluice opening length by 33 has only a small effect on discharge and reservoir stage these improvements are due to the valid dynamic weir model this includes the four weir components rather than simply spilling over a bank fig 8 in particular sluice operations generate flow and draw the reservoir stage below weir crest during dry periods nse is greatly improved despite this measure s insensitivity to low flow values moriasi et al 2015 the reason is that shetran reservoir improves not only the low flows but also flow peaks during and after dry periods as a result of more realistic antecedent reservoir levels nonetheless the improved low flow simulations are valuable although they account for small volumes of discharge low flows are crucial for aquatic ecologists and reservoir operators who must carefully balance environmental flow releases with water conservation furthermore the improved dry period flow peaks are useful as they can cause downstream flooding and ecologically important spate flows shetran reservoir is therefore a more powerful tool for investigating a range of hydrological questions the impact of adjusting the sluice opening length 33 is most visible in the cumulative reservoir drawdown in dry periods however this remains limited because the dry periods are not particularly severe 4 3 model application climate change and water resources scenarios the shetran reservoir model outputs demonstrate several aspects of reservoir response to changing climate abstraction and sluice operation regimes firstly when reservoir inflows are high abstraction makes little difference to the reservoir stage fig 14 this is because abstraction is compensated for by reduced discharge over the weir secondly when reservoir inflows are low may august reservoir stage drops below weir crest and small river discharges are maintained via the sluices outputs exceed inputs and consequently reservoir stage decreases the reservoir stage minima reached for abstraction scenarios a b and c with the current sluice operating regime are 0 3 m 0 6 m and 1 1 m below weir crest respectively thirdly greater abstractions also bring an earlier onset and later recovery of reservoir drawdown fourthly reservoir drawdown also attenuates subsequent flow peaks in agreement with others miotto et al 2007 furthermore intermittent rainfall during dry periods can cause small increases in discharge through open sluices the more conservative sluice opening length 33 0 2m has only a small effect in the early stages of reservoir drawdown however in combination with abstraction and over prolonged dry periods this cumulative conservation has a notable effect on reservoir storage up to 0 1m or 260 000 m3 nb reservoir storage volume can be calculated either as a sum of lake cell storages or using a hypsometric curve fig 3 the shetran reservoir model captures some vital aspects of catchment and reservoir response that the shetran standard model cannot the impacts of climate change and water resources scenarios need to be estimated by water managers and environmental regulators longer and deeper reservoir drawdowns place greater stress on water resources aquatic plants water quality etc the most drastic scenario c shows crummock s reservoir stage almost drawn down to the sluice invert below this critical threshold discharge would cease the more conservative operating regime would be unlikely to forestall this catchment and water resource managers need to plan for these scenarios to mitigate their impacts 5 overall discussion globally reservoirs are coming under pressure due to changes in climate water demand land cover and environmental flow requirements jackson 2006 reservoir modellers need tools to assess reservoir operations as well as catchments where reservoir construction or decommissioning is planned shetran reservoir and the transferable methods we propose here can be applied to other reservoir hydrological modelling problems in particular the method for deriving parsimonious operating rules and similar dynamic sluice modules can be implemented in other modelling packages a limitation of shetran reservoir s dynamic weir module is the assumption that reservoir operation is predominantly a function of reservoir stage other factors such as weather forecasts and antecedent conditions are implicitly rather than explicitly included in the operational rules in catchments where weather forecasts and catchment monitoring are increasingly used to refine operations including these explicitly may improve model predictions for example a more sophisticated model could use numerical weather forecast data that was available to operators in the past or from weather generators for future scenarios further investigation would be needed to ascertain whether this extra effort is rewarded by greater model skill similarly antecedent conditions such as upstream river lake levels and soil water storage could be used to inform sluice operations a more sophisticated agent based model could be developed although its extra predictive power might be negligible the dynamic weir module we present could be used to improve regional and national scale hydrological modelling lewis et al 2018 shetran reservoir can incorporate multiple reservoirs and allows the extraction of stream hydrographs at any channel link and reservoir stage at any lake cell further work could develop interdependent reservoir network models in a similar way to water resource models however modelling large reservoir networks remains challenging due to the lack of accurate requisite reservoir information e g bathymetry location abstraction fluxes discharge equations and operational procedures fleischmann et al 2019 passaia et al 2020 while some of this information is becoming more available via remote sensing data getirana et al 2018 pekel et al 2016 and reservoir databases durant and counsell 2018 mulligan et al 2020 yigzaw et al 2018 understanding of actual operational procedures remains a challenge the method we propose for deriving operational rules could provide a basis for addressing this 6 conclusion we have highlighted the importance of including reservoir hydrological processes in catchment hydrological models we identified that few if any catchment modelling packages are able to include manual reservoir operations and set out to incorporate this new functionality in shetran reservoir in developing shetran reservoir we emulated existing models insofar as we used an elevation discharge relationship to model reservoir outflows however unlike existing models we included the ability to add multiple dynamic discharge relationships in order to simulate manual sluice operations to test the new software we built a model for the upper cocker catchment that includes reservoir abstractions a complex weir model and empirically derived rules for sluice operations we developed a method for investigating the timing and opening lengths of sluice operations and deriving a parsimonious model to allow simulation of this real world behaviour we demonstrated that the new shetran reservoir model outperforms the shetran standard model improvements are particularly noticeable during and after dry periods when the reservoir stage drops below its main weir crest and reservoir operations dominate outflows we then used this model to run six climate change and water resources scenarios to further illustrate the effects of reservoir operations we discussed the importance of modelling reservoir operations for water resources ecology and flood risk purposes finally we discussed potential future work to improve these methods and applications to reservoir hydrological modelling shetran reservoir is now publically available the methods and software presented here can improve simulations of reservoir containing catchments worldwide software availability software name shetran version 4 5 0 shetran reservoir developers of latest version stephen birkinshaw daryl hughes geoff parkin contact s j birkinshaw ncl ac uk year first available 2020 availability and cost free open use software repository https github com nclwater shetran public software homepage https research ncl ac uk shetran software documentation http research ncl ac uk shetran shetran res documentationv1 zip program language fortran90 program size executable program 16 mb documentation 1 2 mb hardware required basic cpu ram storage drive software required microsoft xp vista windows 7 8 and 10 the standard version of shetran requires a 64 bit machine declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests the corresponding author s engd research is part funded by a water company united utilities plc the motivation to develop a reliable predictive hydrological model for crummock water reservoir originated with united utilities at project conception however united utilities has had no influence over the methodology scope and presentation of this manuscript this has been developed independently by the authors at newcastle university acknowledgements this work has been funded by the engineering and physical science research council epsrc and united utilities plc as part of the centre for doctoral training in skills technology research management stream ep l015412 1 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104980 
25871,the study evaluates the biogeochemical model forsafe 2d designed to simulate water and chemical transport from the forest to the stream by simulating the hydrology and the transport of the chemical tracer chloride cl along a forest hillslope in northern sweden the simulated cl exports were in balance with the simulated inputs but measurements suggested a net release of cl from the catchment underestimated deposition inputs deposition peaks and possibly dry deposition were probably and partially responsible for this mismatch however we could not exclude that other soil biogeochemical processes omitted in forsafe 2d could also contribute to cl exports from the catchment the study showed that forsafe 2d is a promising tool to better understand the factors that regulate the chemical export from the forest to the stream the results also confirmed that there are limitations in using cl as a tracer in forest ecosystems keywords dynamic ecosystem model chemical transport hydrology lateral flow forest hillslope forsafe 2d 1 introduction the protection and improvement of water resources are key issues in current environmental legislation in the european union the water framework directive 2000 60 ec has set the objectives to maintain and improve the aquatic environment in the community through measures developed by river basin districts in each member state it includes land use among the anthropogenic pressures on water bodies the directive mainly stresses the importance of urban areas and agriculture but recognizes the possible role of forests when these are relevant for land use patterns ec 2000 in sweden where forest covers almost 70 of the country slu 2016 the impacts of forest ecosystems and forestry activities on water resources cannot be neglected these can be negative impacts such as acidification and nutrient leaching akselsson et al 2013 duncker et al 2012 hughes and quinn 2019 nisbet and evans 2014 thiffault et al 2011 or positive impacts such as nutrient retention and erosion control chang 2006 lowrance et al 1984 under certain circumstances forests might contribute also to flood alleviation but the provision of this service is debated within the scientific community calder 2002 chang 2006 the complex interactions between the hydrological and nutrient cycles in ecosystems often require the support of models to understand how land use influences water resources at present and in the future process based biogeochemical models can be used for this purpose by dynamically simulating nutrient dynamics in forests under changing conditions with a limited dependence on measured data aber et al 1997 kerns and peterson 2014 more recently process based biogeochemical models have been applied to better understand the effect of forest ecosystems and environmental changes on nutrient export to surface waters katsuyama et al 2009 tang et al 2014 zhang et al 2018 however these models often include water percolation but exclude lateral water flows between adjacent modelling units because of the large scale at which they are applied camino serrano et al 2017 kiese et al 2011 machimura et al 2016 ooba et al 2012 other models that include lateral water transport are capable of dynamically simulating only a limited number of chemical elements principally nitrogen or dissolved organic matter katsuyama et al 2009 laurén et al 2008 tang et al 2014 zhang et al 2018 forsafe is a biogeochemical model designed to dynamically simulate water and the most relevant chemical cycles in forest ecosystems given the amount of processes that are dynamically simulated it is an appropriate tool to investigate the effect of changes in climate atmospheric deposition and management on forest resources and soil water chemistry akselsson et al 2010 belyazid et al 2006 gaudio et al 2015 yu et al 2016 zanchi et al 2014 the aim of this study is to present and evaluate a new version of the forsafe model including the lateral transport of water and chemical elements in the soil as well as a distinction between saturated and unsaturated zones the model is tested along a forest hillslope in northern sweden by simulating water discharge and the transport of the chemical tracer chloride from the forest to the stream on a daily basis chloride is often used a tracer in mass balance studies because it is considered a conservative ion buchter et al 1997 li et al 2017 lockwood et al 1995 van der heijden et al 2019 i e chloride export in streamflow is assumed to be mainly driven by inputs from deposition in this study model achievements and limitations are discussed by comparing simulated to measured water storage and fluxes as well as chloride concentrations in the soil water and in the nearest stream the study also discusses implications of using chloride as a tracer and indicates future research needs 2 data and methods 2 1 the forsafe model forsafe is a mechanistic model of the dynamics of forest ecosystems it was originally developed to simulate the dynamic responses of forest sites to environmental changes the model is an integration of several interacting processes belyazid et al 2006 wallman et al 2005 it merges together the three basic material and energy cycles the biological cycle representing the processes of tree growth the biochemical cycle including uptake litter decomposition and soil nutrient dynamics and the geochemical cycle including atmospheric deposition and weathering processes forsafe is based on the integration of four models the tree growth model pnet aber and federer 1992 the soil chemistry model safe alveteg 1998 the decomposition model decomp wallman et al 2006 and the hydrology model pulse lindström and gardelin 1992 the model simulates the most relevant chemical cycles in natural ecosystems carbon nitrogen base cations sodium calcium magnesium potassium sulphur chlorine and aluminium more recently the phosphorous cycle was also added to the model yu et al 2018 forsafe originally simulates water storage and fluxes at the forest site level by estimating soil moisture content vertical water fluxes in the soil and evapotranspiration at a monthly time step belyazid 2006 the hydrology affects all the biogeochemical processes included in the model in this study forsafe was further developed to include a novel hydrology module simulating both vertical and lateral water flows and water saturated and unsaturated zones in the soil the hydrology module was previously developed and tested separately from forsafe as a model prototype in the visual modelling environment stella zanchi et al 2016 while replacing the original one dimensional hydrology concept with the two dimensional one the time resolution in the model was also changed to daily time steps to better reflect water flows variability in addition the mass balance equations regulating the chemical concentrations in the soil solution in each soil layer belyazid 2006 were modified to account for inputs and outputs from lateral water flows in the specific case of chloride the concentration in each soil layer is calculated as the difference between inputs to the soil layer from inflowing water precipitation percolation or lateral inflow and outputs from the soil layer in outflowing water percolation and lateral outflow q v o c l c l 1 q h 0 cl c 1 l q v qh z d θ d t c l c l z θ d c l c l d t where cl kmol m 3 is the concentration of chloride c is the simulated soil column l is the simulated soil layer qv 0 and qh 0 m3 m 2 d 1 are the vertical and horizontal fluxes of water to the soil layer qv and qh are the vertical and horizontal fluxes of water from the soil layer θ m3 m 3 is the moisture of the soil layer and z m is the layer thickness therefore chloride is simulated as a conservative chemical element i e the concentrations in the soil are the difference between inputs from deposition and outputs from leaching as a result of the changes in hydrology and soil chemistry the two dimensional version of the model forsafe 2d fig 1 can simulate water flows and the transport of chemical elements from the forest ecosystem to the stream on a daily basis moreover it is able to distinguish between saturated and unsaturated zones in the soil 2 2 study site forsafe 2d was tested along a forest hillslope in the vindeln research forest 64 14 n 19 46 e in northern sweden fig 2 the hillslope is located at 250 m a s l and it is identified as the s transect within the västrabäcken sub catchment in the krycklan catchment erlandsson et al 2016 laudon et al 2013 ledesma et al 2016 the s transect is aligned parallel to lateral flow paths towards the västrabäcken stream measurements of soil moisture groundwater level and soil water chemistry have been collected since 1997 stream water samples have been collected since 1986 at the outlet of the västrabäcken sub catchment c2 laudon et al 2013 nyberg et al 2001 in the study area the mean annual air temperature for the period 2009 2014 was 2 7 c the average annual precipitation 670 mm and the average annual runoff 232 mm the dominant tree species are norway spruce close to the stream and scots pine upslope the bedrock is gneiss overlaid by glacial till which is 30 40 m deep in the middle part of the svartberget catchment a dense basal till covers the bedrock and it is overlaid by a less dense till of 1 3 m depth lindqvist et al 1989 at the s transect the predominant soil type is podzol that is replaced by an organic rich histosol in the riparian zone inputs of cl from precipitation in the catchment are quite low and follow a slight decreasing trend the average wet deposition calculated from measurements of bulk deposition in 1986 2007 was equal to 2 05 0 59 kg ha 1 y 1 and decreased annually of about 0 02 kg ha 1 y 1 the outputs of cl in the stream were about 2 90 0 95 kg ha 1 y 1 in 1998 2007 which are higher than the inputs from precipitation over the same period 2 02 0 57 kg ha 1 y 1 however inputs from precipitation exclude dry deposition which can be a very variable fraction of the total deposition svensson et al 2012 available measurements of so4 2 deposition in throughfall and precipitation in 1983 1984 suggest that dry deposition is about a quarter of wet deposition see section 2 3 2 under this assumption the total cl inputs from deposition would be equal to 2 48 0 70 kg ha 1 y 1 i e inputs are 17 less than outputs in the streamflow however the very limited amount of throughfall data does not allow to draw final conclusions on the cl budget in the catchment measurements of soil moisture 2010 2014 streamflow 2010 2015 concentration of chloride cl in the soil solution 1996 2006 and in the stream 2000 2015 were used to evaluate the simulation of water and tracer flows in forsafe 2d on a daily basis 2 3 input data to the model input data to the model included yearly deposition daily climate variables soil properties tree species and forest management practices table 1 2 3 1 climate the climate data used as input to forsafe 2d are a combination of direct climate observations in 1981 2016 and outputs of climate models in 1900 1980 measured temperature and precipitation data were derived from the swedish infrastructure for ecosystem science sites at the svartberget research station 64 14 n 19 46 e data from the nearby smhi weather station vindeln sunnansjönäs 64 14 n 19 77 e were used to integrate the sites observations when these were missing precipitation and temperature data for the period 1961 1980 originated from the echam5 r3 model kjellström et al 2011 of the regional climate model rca3 samuelsson et al 2011 based on the global climate model echam5 roeckner et al 2003 daily mean temperature and precipitation for this period were bias corrected applying distribution based scaling yang et al 2010 towards climatic observations johansson 2000 daily minimum and maximum temperatures for 1961 1980 were based on the average observed monthly ranges from the temperature mean at the sites svartberget station for the period 1991 2000 climate data for a random year of the period 1961 1970 were used to generate climate driving data for each year in the period 1900 1960 data on photosynthetically active radiation par were derived from monthly data from the ncep ncar reanalysis global solar radiation and calibrated using the smhi strång model david ryner 2010 personal communication 2 3 2 deposition atmospheric yearly depositions of sulphate so4 2 nitrate no3 and ammonium nh4 for the period 1900 2016 were derived from a simulation with the match atmospheric dispersion model engardt and langner 2013 robertson et al 1999 the match simulation applied air pollutant emissions according to the cleo eurobase scenario munthe et al 2014 for the period 1961 2016 while it applied emissions for the period 1900 1960 originated from the eclaire project based on lamarque et al 2010 climatic drivers for match were produced with the echam5 r3 model for the period 1960 2016 see the previous section climate the rca3 meteorological output from a random year of the period 1960 1969 was the climatic driving input to match for each simulated year of the period 1900 1959 measurements of precipitation chemistry in 1987 2007 in svartberget on a monthly basis were used to estimate the average wet deposition of chloride cl and base cations ca2 k mg2 these average values of wet deposition were used as input data the model when measured values were not available a ratio of 0 23 between dry and wet deposition was used to estimate the yearly total deposition of cl k ca2 and mg2 for the simulation period 1900 2016 the ratio was assessed based on measurements of so4 2 in throughfall and precipitation in 1983 1984 2 3 3 soil the modelled hillslope was represented by six forest plots with different properties each plot includes a soil column of 1 5 m depth the soil columns have different properties representing discretely the change from an organic rich soil in the riparian zone to a podzol uphill ledesma et al 2016 data on grain size distribution and soil mineralogy at different points along the hillslope were used to define the texture and the mineral composition of the six soil columns each divided into seven layers supplementary material tables s1 and s2 the mineral composition of the soil samples was determined with x ray powder diffraction xrpd 2 3 4 modelled vegetation as a simplification it was assumed that the tree vegetation is uniform along the hillslope i e a norway spruce forest therefore a unique set of model parameters was applied for tree vegetation derived from previous studies aber et al 1995 yu et al 2016 zanchi et al 2014 and from model calibration supplementary material box s1 the information on the management at the site was based on management records in the svartberget research area 2 4 model calibration the calibration of the model included the comparison of the simulated tree biomass with a calculated tree biomass based on measured tree diameters in 2010 the diameters were used to estimate the total biomass through marklund s equations marklund 1988 based on the comparison the fractional mortality of live wood per year was decreased to 0 02 y 1 compared to the value of 0 025 y 1 reported in aber et al 1997 which is suitable for mature broadleaved forests wang et al 2014 xu et al 2017 zanchi et al 2014 as a result the modelled tree biomass was comparable to calculated values based on measured diameters fig 3 the calibration phase included also a comparison between simulated and measured ground water levels gwl to regulate the percolation at the bottom of the soil columns zanchi et al 2016 the new hydrology module simulates the soil water storage and fluxes to a depth of 1 5 m without further assumptions the percolation at the bottom of the soil columns is only constrained by the hydraulic conductivity of the deepest soil layer that is the lower permeability of the soil below 1 5 m depth is not taken into account therefore the permeability at the bottom of the soil columns is constrained by setting a maximum amount of water percolating through the deepest soil layers bflow mm d 1 zanchi et al 2016 the calibration showed that when we assumed a constant bflow the water table was simulated parallel to the soil surface however according to measurements the groundwater level is closer to the soil surface when closer to the water divide amvrosiadi et al 2017 therefore it was assumed that the bflow increases linearly from the stream to the water divide ranging from 0 to 2 5 mm d 1 simulating an increasing permeability with distance from the stream at 1 5 m soil depth these values were calibrated based on the comparison between simulated and measured average values of gwl in 2010 2014 fig 4 due to the structure of the model which assumes discrete soil columns the modelled water table is discontinuous moreover the model can simulate a maximum gwl of 1 5 m equal to the depth of the modelled soil columns for this reason the modelled groundwater is above the measured one at the water divide 2 5 model evaluation the model was evaluated by comparing the modelled hydrology and water chemistry to long term measurements and calculated indicators the evaluation included the analysis of soil water content and streamflow and cl concentrations in soil water and in the stream the measurements included data collected along the s transect on soil moisture determined with time domain reflectometry probes tdr soil water chemistry monitored with ceramic suction lysimeters and observed groundwater levels from wells extending to different depths laudon et al 2013 in addition measured data on streamflow and stream water chemistry collected at the västrabäcken sub catchment c2 laudon et al 2013 were used for the model evaluation 3 results and discussion this section compares model results with measurements and discusses model strengths and limitations it illustrates first the simulated water content and soil water chemistry within the forest ecosystem and secondly the results on the discharge from the forest ecosystem to the stream and cl concentrations in the stream 3 1 in the forest modelled soil water and cl concentrations in the soil water were compared to measurements at different points along the hillslope average values for modelled and measured soil moisture were calculated for the period 2010 2014 and compared fig 5 the model simulated a good approximation of the amount and patterns of soil moisture including a decreasing water content towards the surface layers caused by evapotranspiration and a decreasing water content with depth due to decreasing porosity that create a bulge in water content along the soil profile dingman 2008 the comparison of chloride concentrations cl in the soil water showed that modelled and measured cl were also comparable fig 6 in both cases the chloride concentrations were quite uniform along the soil profile and the transect however the mean simulated cl was 3 0 μeq l 1 lower than the measured value 24 34 15 88 μeq l 1 against 27 34 1 63 μeq l 1 on average in the three soil columns and over 1996 2006 the underestimation of simulated cl could indicate that the dry cl deposition and thereby the total deposition were underestimated another difference was the higher variability of simulated data compared to measured data as indicated by the high standard deviation this variability was linked to the variability in deposition in 1996 2006 when measured deposition values were used as input data 0 02 0 05 meq m 2 d 1 a limited number of measured cl were available 3 62 per measured point especially in upper soil layers this could explain the lower variability of measured cl values considering that the model simulated higher cl fluctuations in upper soil layers 3 2 in the stream the comparison between modelled and measured streamflow data showed that the model captured the water flow dynamics but tended to overestimate the total streamflow fig 7 a the overestimation was due to a higher simulated base flow by the model 0 42 mm d 1 at the 10th percentile of modelled data versus 0 05 mm d 1 for measured data simulated peak flows were comparable to measured ones 1 54 mm d 1 against 1 50 mm d 1 at the 90th percentile but the model failed to capture peak flows produced by intense precipitation and thaw in spring fig 7a these results are consistent with the simulations produced with the model prototype developed in stella and the results of the sensitivity analysis presented in zanchi et al 2016 these previous results showed that the mismatch between measured and simulated streamflow was mainly caused by the approach used to limit the percolation at the bottom of the soil columns i e by model boundaries excluding soil deeper than 1 5 m and by the lack of a mechanism regulating soil water frost in winter the modelled tracer concentrations in the stream cl were on average lower and less variable than the measurements 19 85 3 79 and 26 0 11 61 μeq l 1 respectively failing especially to capture the measured cl peaks in the stream fig 7b one reason for the lower modelled cl could be caused by an underestimation of cl deposition as already suggested by the results on cl in soil water on one hand the limited information on throughfall could have caused a systematic underestimation of dry deposition on the other hand annual deposition data used as input to forsafe could have caused an underestimation of the effects of deposition peaks which in the model are redistributed over the year this could be the reason why the model failed to simulate peaks of cl in the stream such as the ones in may 2004 and march 2007 it should also be noted that deposition measurements were irregularly collected before these two peaks further contributing to the uncertainties around deposition inputs and peaks a second reason for the differences between modelled and measured data could be that other sources of chloride in the slope were not represented by the model previous research studies showed that cl export in streamflow might be not entirely controlled by inputs from deposition but could originate from chloride mobilized and immobilized in the ecosystem by other biogeochemical processes such as weathering ion exchange adsorption biological uptake and production of organically bound chlorine in soil organic matter bastviken et al 2007 öberg and sandén 2005 osswald et al 2016 these processes are enhanced by longer residence times bastviken et al 2006 therefore they could have a greater impact on base flow concentrations given that base flow has longer residence times than quick flows it has also been shown that other sources of cl might play a bigger role in catchments with low cl inputs from deposition 6 kg ha 1 y 1 such as the one included in this study leading to a net cl release from the catchment svensson et al 2012 the analysis of the cl at different levels of streamflow seems to confirm that cl are higher at base flow but these higher concentrations are not fully represented in the model fig 8 based on modelled results the simulated outputs of cl in the stream in the period 1998 2007 were equal to 2 50 0 79 kg ha 1y 1 which were lower than the calculated value from measurements over the same period 2 90 0 95 kg ha 1 y 1 this also confirms that sources of chloride existing in the catchment were not represented in the model such as higher deposition e g dry deposition and deposition peaks or sources of chloride from the soil 4 conclusions the evaluation of forsafe 2d including lateral water and water chemistry flows highlighted model strengths and weaknesses in simulating the hydrology and chemical transport on a forest hillslope when considering the hydrology forsafe 2d could simulate well the water storage along the transect which was closely comparable to measurements some limitations were detected in the estimate of streamflow due to an overestimation of runoff at base flow and the underestimation of peak flows in spring these limitations are mainly linked to the model boundaries and the lack of consideration of soil frost in the model zanchi et al 2016 alternative approaches to limit the deep percolation should be evaluated and mechanisms to regulate soil water frost should be included in future model developments when evaluating the chemical transport of chloride the model forsafe 2d underestimated the export of cl from the studied catchment simulated cl exports were in balance with the simulated inputs 2 47 0 43 and 2 52 0 31 kg h 1 y 1 respectively over the simulation period 1900 2016 a result compatible with the assumption that cl acts as a conservative tracer however measurements suggested that a net release of cl exists in the catchment 17 of the inputs on one hand the study showed that at least part of the unassessed exports can be a consequence of higher deposition inputs temporary deposition peaks and possibly extended over time dry deposition if higher deposition inputs are not properly considered in the estimate of the cl budget it might be questionable that cl is actually released from the västrabäcken catchment on the other hand we could not exclude that other soil biogeochemical processes omitted in forsafe 2d could also contribute to cl exports and thereby to a net release of cl at the catchment level such processes should be considered in future developments of the model regarding for instance decomposition ion exchange and weathering all things considered forsafe 2d is a promising tool to better understand the factors that regulate the chemical export from boreal forest ecosystems to the stream finally the study confirmed that there are limitations in using chloride as a tracer in forest ecosystems data and software svartberget catchment data used in this study are available at https franklin vfp slu se model parametrization data and data on soil properties are available in the supplementary material name of software forsafe 2d developers giuliana zanchi salim belyazid harald sverdrup patrik wallman lin yu contact details giuliana zanchi nateko lu se salim belyazid natgeo su se language fortran supported systems microsoft windows macos distribution previous research collaborations with other research groups have shown that new users need an initial period of guidance to be able to independently run the model therefore the model is freely available upon request to the model developers see contact details above with the intent to support new user in the initial stage of their work with the forsafe model declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank for the financial support granted by the projects forwater and managing multiple stressors in the baltic sea funded by the swedish research council formas http www formas se en this study has also been made possible by the swedish infrastructure for ecosystem science sites which provided data from the svartberget research station finally we thank nino amvrosiadi for sharing relevant data on the hydrology of the s transect appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104984 
25871,the study evaluates the biogeochemical model forsafe 2d designed to simulate water and chemical transport from the forest to the stream by simulating the hydrology and the transport of the chemical tracer chloride cl along a forest hillslope in northern sweden the simulated cl exports were in balance with the simulated inputs but measurements suggested a net release of cl from the catchment underestimated deposition inputs deposition peaks and possibly dry deposition were probably and partially responsible for this mismatch however we could not exclude that other soil biogeochemical processes omitted in forsafe 2d could also contribute to cl exports from the catchment the study showed that forsafe 2d is a promising tool to better understand the factors that regulate the chemical export from the forest to the stream the results also confirmed that there are limitations in using cl as a tracer in forest ecosystems keywords dynamic ecosystem model chemical transport hydrology lateral flow forest hillslope forsafe 2d 1 introduction the protection and improvement of water resources are key issues in current environmental legislation in the european union the water framework directive 2000 60 ec has set the objectives to maintain and improve the aquatic environment in the community through measures developed by river basin districts in each member state it includes land use among the anthropogenic pressures on water bodies the directive mainly stresses the importance of urban areas and agriculture but recognizes the possible role of forests when these are relevant for land use patterns ec 2000 in sweden where forest covers almost 70 of the country slu 2016 the impacts of forest ecosystems and forestry activities on water resources cannot be neglected these can be negative impacts such as acidification and nutrient leaching akselsson et al 2013 duncker et al 2012 hughes and quinn 2019 nisbet and evans 2014 thiffault et al 2011 or positive impacts such as nutrient retention and erosion control chang 2006 lowrance et al 1984 under certain circumstances forests might contribute also to flood alleviation but the provision of this service is debated within the scientific community calder 2002 chang 2006 the complex interactions between the hydrological and nutrient cycles in ecosystems often require the support of models to understand how land use influences water resources at present and in the future process based biogeochemical models can be used for this purpose by dynamically simulating nutrient dynamics in forests under changing conditions with a limited dependence on measured data aber et al 1997 kerns and peterson 2014 more recently process based biogeochemical models have been applied to better understand the effect of forest ecosystems and environmental changes on nutrient export to surface waters katsuyama et al 2009 tang et al 2014 zhang et al 2018 however these models often include water percolation but exclude lateral water flows between adjacent modelling units because of the large scale at which they are applied camino serrano et al 2017 kiese et al 2011 machimura et al 2016 ooba et al 2012 other models that include lateral water transport are capable of dynamically simulating only a limited number of chemical elements principally nitrogen or dissolved organic matter katsuyama et al 2009 laurén et al 2008 tang et al 2014 zhang et al 2018 forsafe is a biogeochemical model designed to dynamically simulate water and the most relevant chemical cycles in forest ecosystems given the amount of processes that are dynamically simulated it is an appropriate tool to investigate the effect of changes in climate atmospheric deposition and management on forest resources and soil water chemistry akselsson et al 2010 belyazid et al 2006 gaudio et al 2015 yu et al 2016 zanchi et al 2014 the aim of this study is to present and evaluate a new version of the forsafe model including the lateral transport of water and chemical elements in the soil as well as a distinction between saturated and unsaturated zones the model is tested along a forest hillslope in northern sweden by simulating water discharge and the transport of the chemical tracer chloride from the forest to the stream on a daily basis chloride is often used a tracer in mass balance studies because it is considered a conservative ion buchter et al 1997 li et al 2017 lockwood et al 1995 van der heijden et al 2019 i e chloride export in streamflow is assumed to be mainly driven by inputs from deposition in this study model achievements and limitations are discussed by comparing simulated to measured water storage and fluxes as well as chloride concentrations in the soil water and in the nearest stream the study also discusses implications of using chloride as a tracer and indicates future research needs 2 data and methods 2 1 the forsafe model forsafe is a mechanistic model of the dynamics of forest ecosystems it was originally developed to simulate the dynamic responses of forest sites to environmental changes the model is an integration of several interacting processes belyazid et al 2006 wallman et al 2005 it merges together the three basic material and energy cycles the biological cycle representing the processes of tree growth the biochemical cycle including uptake litter decomposition and soil nutrient dynamics and the geochemical cycle including atmospheric deposition and weathering processes forsafe is based on the integration of four models the tree growth model pnet aber and federer 1992 the soil chemistry model safe alveteg 1998 the decomposition model decomp wallman et al 2006 and the hydrology model pulse lindström and gardelin 1992 the model simulates the most relevant chemical cycles in natural ecosystems carbon nitrogen base cations sodium calcium magnesium potassium sulphur chlorine and aluminium more recently the phosphorous cycle was also added to the model yu et al 2018 forsafe originally simulates water storage and fluxes at the forest site level by estimating soil moisture content vertical water fluxes in the soil and evapotranspiration at a monthly time step belyazid 2006 the hydrology affects all the biogeochemical processes included in the model in this study forsafe was further developed to include a novel hydrology module simulating both vertical and lateral water flows and water saturated and unsaturated zones in the soil the hydrology module was previously developed and tested separately from forsafe as a model prototype in the visual modelling environment stella zanchi et al 2016 while replacing the original one dimensional hydrology concept with the two dimensional one the time resolution in the model was also changed to daily time steps to better reflect water flows variability in addition the mass balance equations regulating the chemical concentrations in the soil solution in each soil layer belyazid 2006 were modified to account for inputs and outputs from lateral water flows in the specific case of chloride the concentration in each soil layer is calculated as the difference between inputs to the soil layer from inflowing water precipitation percolation or lateral inflow and outputs from the soil layer in outflowing water percolation and lateral outflow q v o c l c l 1 q h 0 cl c 1 l q v qh z d θ d t c l c l z θ d c l c l d t where cl kmol m 3 is the concentration of chloride c is the simulated soil column l is the simulated soil layer qv 0 and qh 0 m3 m 2 d 1 are the vertical and horizontal fluxes of water to the soil layer qv and qh are the vertical and horizontal fluxes of water from the soil layer θ m3 m 3 is the moisture of the soil layer and z m is the layer thickness therefore chloride is simulated as a conservative chemical element i e the concentrations in the soil are the difference between inputs from deposition and outputs from leaching as a result of the changes in hydrology and soil chemistry the two dimensional version of the model forsafe 2d fig 1 can simulate water flows and the transport of chemical elements from the forest ecosystem to the stream on a daily basis moreover it is able to distinguish between saturated and unsaturated zones in the soil 2 2 study site forsafe 2d was tested along a forest hillslope in the vindeln research forest 64 14 n 19 46 e in northern sweden fig 2 the hillslope is located at 250 m a s l and it is identified as the s transect within the västrabäcken sub catchment in the krycklan catchment erlandsson et al 2016 laudon et al 2013 ledesma et al 2016 the s transect is aligned parallel to lateral flow paths towards the västrabäcken stream measurements of soil moisture groundwater level and soil water chemistry have been collected since 1997 stream water samples have been collected since 1986 at the outlet of the västrabäcken sub catchment c2 laudon et al 2013 nyberg et al 2001 in the study area the mean annual air temperature for the period 2009 2014 was 2 7 c the average annual precipitation 670 mm and the average annual runoff 232 mm the dominant tree species are norway spruce close to the stream and scots pine upslope the bedrock is gneiss overlaid by glacial till which is 30 40 m deep in the middle part of the svartberget catchment a dense basal till covers the bedrock and it is overlaid by a less dense till of 1 3 m depth lindqvist et al 1989 at the s transect the predominant soil type is podzol that is replaced by an organic rich histosol in the riparian zone inputs of cl from precipitation in the catchment are quite low and follow a slight decreasing trend the average wet deposition calculated from measurements of bulk deposition in 1986 2007 was equal to 2 05 0 59 kg ha 1 y 1 and decreased annually of about 0 02 kg ha 1 y 1 the outputs of cl in the stream were about 2 90 0 95 kg ha 1 y 1 in 1998 2007 which are higher than the inputs from precipitation over the same period 2 02 0 57 kg ha 1 y 1 however inputs from precipitation exclude dry deposition which can be a very variable fraction of the total deposition svensson et al 2012 available measurements of so4 2 deposition in throughfall and precipitation in 1983 1984 suggest that dry deposition is about a quarter of wet deposition see section 2 3 2 under this assumption the total cl inputs from deposition would be equal to 2 48 0 70 kg ha 1 y 1 i e inputs are 17 less than outputs in the streamflow however the very limited amount of throughfall data does not allow to draw final conclusions on the cl budget in the catchment measurements of soil moisture 2010 2014 streamflow 2010 2015 concentration of chloride cl in the soil solution 1996 2006 and in the stream 2000 2015 were used to evaluate the simulation of water and tracer flows in forsafe 2d on a daily basis 2 3 input data to the model input data to the model included yearly deposition daily climate variables soil properties tree species and forest management practices table 1 2 3 1 climate the climate data used as input to forsafe 2d are a combination of direct climate observations in 1981 2016 and outputs of climate models in 1900 1980 measured temperature and precipitation data were derived from the swedish infrastructure for ecosystem science sites at the svartberget research station 64 14 n 19 46 e data from the nearby smhi weather station vindeln sunnansjönäs 64 14 n 19 77 e were used to integrate the sites observations when these were missing precipitation and temperature data for the period 1961 1980 originated from the echam5 r3 model kjellström et al 2011 of the regional climate model rca3 samuelsson et al 2011 based on the global climate model echam5 roeckner et al 2003 daily mean temperature and precipitation for this period were bias corrected applying distribution based scaling yang et al 2010 towards climatic observations johansson 2000 daily minimum and maximum temperatures for 1961 1980 were based on the average observed monthly ranges from the temperature mean at the sites svartberget station for the period 1991 2000 climate data for a random year of the period 1961 1970 were used to generate climate driving data for each year in the period 1900 1960 data on photosynthetically active radiation par were derived from monthly data from the ncep ncar reanalysis global solar radiation and calibrated using the smhi strång model david ryner 2010 personal communication 2 3 2 deposition atmospheric yearly depositions of sulphate so4 2 nitrate no3 and ammonium nh4 for the period 1900 2016 were derived from a simulation with the match atmospheric dispersion model engardt and langner 2013 robertson et al 1999 the match simulation applied air pollutant emissions according to the cleo eurobase scenario munthe et al 2014 for the period 1961 2016 while it applied emissions for the period 1900 1960 originated from the eclaire project based on lamarque et al 2010 climatic drivers for match were produced with the echam5 r3 model for the period 1960 2016 see the previous section climate the rca3 meteorological output from a random year of the period 1960 1969 was the climatic driving input to match for each simulated year of the period 1900 1959 measurements of precipitation chemistry in 1987 2007 in svartberget on a monthly basis were used to estimate the average wet deposition of chloride cl and base cations ca2 k mg2 these average values of wet deposition were used as input data the model when measured values were not available a ratio of 0 23 between dry and wet deposition was used to estimate the yearly total deposition of cl k ca2 and mg2 for the simulation period 1900 2016 the ratio was assessed based on measurements of so4 2 in throughfall and precipitation in 1983 1984 2 3 3 soil the modelled hillslope was represented by six forest plots with different properties each plot includes a soil column of 1 5 m depth the soil columns have different properties representing discretely the change from an organic rich soil in the riparian zone to a podzol uphill ledesma et al 2016 data on grain size distribution and soil mineralogy at different points along the hillslope were used to define the texture and the mineral composition of the six soil columns each divided into seven layers supplementary material tables s1 and s2 the mineral composition of the soil samples was determined with x ray powder diffraction xrpd 2 3 4 modelled vegetation as a simplification it was assumed that the tree vegetation is uniform along the hillslope i e a norway spruce forest therefore a unique set of model parameters was applied for tree vegetation derived from previous studies aber et al 1995 yu et al 2016 zanchi et al 2014 and from model calibration supplementary material box s1 the information on the management at the site was based on management records in the svartberget research area 2 4 model calibration the calibration of the model included the comparison of the simulated tree biomass with a calculated tree biomass based on measured tree diameters in 2010 the diameters were used to estimate the total biomass through marklund s equations marklund 1988 based on the comparison the fractional mortality of live wood per year was decreased to 0 02 y 1 compared to the value of 0 025 y 1 reported in aber et al 1997 which is suitable for mature broadleaved forests wang et al 2014 xu et al 2017 zanchi et al 2014 as a result the modelled tree biomass was comparable to calculated values based on measured diameters fig 3 the calibration phase included also a comparison between simulated and measured ground water levels gwl to regulate the percolation at the bottom of the soil columns zanchi et al 2016 the new hydrology module simulates the soil water storage and fluxes to a depth of 1 5 m without further assumptions the percolation at the bottom of the soil columns is only constrained by the hydraulic conductivity of the deepest soil layer that is the lower permeability of the soil below 1 5 m depth is not taken into account therefore the permeability at the bottom of the soil columns is constrained by setting a maximum amount of water percolating through the deepest soil layers bflow mm d 1 zanchi et al 2016 the calibration showed that when we assumed a constant bflow the water table was simulated parallel to the soil surface however according to measurements the groundwater level is closer to the soil surface when closer to the water divide amvrosiadi et al 2017 therefore it was assumed that the bflow increases linearly from the stream to the water divide ranging from 0 to 2 5 mm d 1 simulating an increasing permeability with distance from the stream at 1 5 m soil depth these values were calibrated based on the comparison between simulated and measured average values of gwl in 2010 2014 fig 4 due to the structure of the model which assumes discrete soil columns the modelled water table is discontinuous moreover the model can simulate a maximum gwl of 1 5 m equal to the depth of the modelled soil columns for this reason the modelled groundwater is above the measured one at the water divide 2 5 model evaluation the model was evaluated by comparing the modelled hydrology and water chemistry to long term measurements and calculated indicators the evaluation included the analysis of soil water content and streamflow and cl concentrations in soil water and in the stream the measurements included data collected along the s transect on soil moisture determined with time domain reflectometry probes tdr soil water chemistry monitored with ceramic suction lysimeters and observed groundwater levels from wells extending to different depths laudon et al 2013 in addition measured data on streamflow and stream water chemistry collected at the västrabäcken sub catchment c2 laudon et al 2013 were used for the model evaluation 3 results and discussion this section compares model results with measurements and discusses model strengths and limitations it illustrates first the simulated water content and soil water chemistry within the forest ecosystem and secondly the results on the discharge from the forest ecosystem to the stream and cl concentrations in the stream 3 1 in the forest modelled soil water and cl concentrations in the soil water were compared to measurements at different points along the hillslope average values for modelled and measured soil moisture were calculated for the period 2010 2014 and compared fig 5 the model simulated a good approximation of the amount and patterns of soil moisture including a decreasing water content towards the surface layers caused by evapotranspiration and a decreasing water content with depth due to decreasing porosity that create a bulge in water content along the soil profile dingman 2008 the comparison of chloride concentrations cl in the soil water showed that modelled and measured cl were also comparable fig 6 in both cases the chloride concentrations were quite uniform along the soil profile and the transect however the mean simulated cl was 3 0 μeq l 1 lower than the measured value 24 34 15 88 μeq l 1 against 27 34 1 63 μeq l 1 on average in the three soil columns and over 1996 2006 the underestimation of simulated cl could indicate that the dry cl deposition and thereby the total deposition were underestimated another difference was the higher variability of simulated data compared to measured data as indicated by the high standard deviation this variability was linked to the variability in deposition in 1996 2006 when measured deposition values were used as input data 0 02 0 05 meq m 2 d 1 a limited number of measured cl were available 3 62 per measured point especially in upper soil layers this could explain the lower variability of measured cl values considering that the model simulated higher cl fluctuations in upper soil layers 3 2 in the stream the comparison between modelled and measured streamflow data showed that the model captured the water flow dynamics but tended to overestimate the total streamflow fig 7 a the overestimation was due to a higher simulated base flow by the model 0 42 mm d 1 at the 10th percentile of modelled data versus 0 05 mm d 1 for measured data simulated peak flows were comparable to measured ones 1 54 mm d 1 against 1 50 mm d 1 at the 90th percentile but the model failed to capture peak flows produced by intense precipitation and thaw in spring fig 7a these results are consistent with the simulations produced with the model prototype developed in stella and the results of the sensitivity analysis presented in zanchi et al 2016 these previous results showed that the mismatch between measured and simulated streamflow was mainly caused by the approach used to limit the percolation at the bottom of the soil columns i e by model boundaries excluding soil deeper than 1 5 m and by the lack of a mechanism regulating soil water frost in winter the modelled tracer concentrations in the stream cl were on average lower and less variable than the measurements 19 85 3 79 and 26 0 11 61 μeq l 1 respectively failing especially to capture the measured cl peaks in the stream fig 7b one reason for the lower modelled cl could be caused by an underestimation of cl deposition as already suggested by the results on cl in soil water on one hand the limited information on throughfall could have caused a systematic underestimation of dry deposition on the other hand annual deposition data used as input to forsafe could have caused an underestimation of the effects of deposition peaks which in the model are redistributed over the year this could be the reason why the model failed to simulate peaks of cl in the stream such as the ones in may 2004 and march 2007 it should also be noted that deposition measurements were irregularly collected before these two peaks further contributing to the uncertainties around deposition inputs and peaks a second reason for the differences between modelled and measured data could be that other sources of chloride in the slope were not represented by the model previous research studies showed that cl export in streamflow might be not entirely controlled by inputs from deposition but could originate from chloride mobilized and immobilized in the ecosystem by other biogeochemical processes such as weathering ion exchange adsorption biological uptake and production of organically bound chlorine in soil organic matter bastviken et al 2007 öberg and sandén 2005 osswald et al 2016 these processes are enhanced by longer residence times bastviken et al 2006 therefore they could have a greater impact on base flow concentrations given that base flow has longer residence times than quick flows it has also been shown that other sources of cl might play a bigger role in catchments with low cl inputs from deposition 6 kg ha 1 y 1 such as the one included in this study leading to a net cl release from the catchment svensson et al 2012 the analysis of the cl at different levels of streamflow seems to confirm that cl are higher at base flow but these higher concentrations are not fully represented in the model fig 8 based on modelled results the simulated outputs of cl in the stream in the period 1998 2007 were equal to 2 50 0 79 kg ha 1y 1 which were lower than the calculated value from measurements over the same period 2 90 0 95 kg ha 1 y 1 this also confirms that sources of chloride existing in the catchment were not represented in the model such as higher deposition e g dry deposition and deposition peaks or sources of chloride from the soil 4 conclusions the evaluation of forsafe 2d including lateral water and water chemistry flows highlighted model strengths and weaknesses in simulating the hydrology and chemical transport on a forest hillslope when considering the hydrology forsafe 2d could simulate well the water storage along the transect which was closely comparable to measurements some limitations were detected in the estimate of streamflow due to an overestimation of runoff at base flow and the underestimation of peak flows in spring these limitations are mainly linked to the model boundaries and the lack of consideration of soil frost in the model zanchi et al 2016 alternative approaches to limit the deep percolation should be evaluated and mechanisms to regulate soil water frost should be included in future model developments when evaluating the chemical transport of chloride the model forsafe 2d underestimated the export of cl from the studied catchment simulated cl exports were in balance with the simulated inputs 2 47 0 43 and 2 52 0 31 kg h 1 y 1 respectively over the simulation period 1900 2016 a result compatible with the assumption that cl acts as a conservative tracer however measurements suggested that a net release of cl exists in the catchment 17 of the inputs on one hand the study showed that at least part of the unassessed exports can be a consequence of higher deposition inputs temporary deposition peaks and possibly extended over time dry deposition if higher deposition inputs are not properly considered in the estimate of the cl budget it might be questionable that cl is actually released from the västrabäcken catchment on the other hand we could not exclude that other soil biogeochemical processes omitted in forsafe 2d could also contribute to cl exports and thereby to a net release of cl at the catchment level such processes should be considered in future developments of the model regarding for instance decomposition ion exchange and weathering all things considered forsafe 2d is a promising tool to better understand the factors that regulate the chemical export from boreal forest ecosystems to the stream finally the study confirmed that there are limitations in using chloride as a tracer in forest ecosystems data and software svartberget catchment data used in this study are available at https franklin vfp slu se model parametrization data and data on soil properties are available in the supplementary material name of software forsafe 2d developers giuliana zanchi salim belyazid harald sverdrup patrik wallman lin yu contact details giuliana zanchi nateko lu se salim belyazid natgeo su se language fortran supported systems microsoft windows macos distribution previous research collaborations with other research groups have shown that new users need an initial period of guidance to be able to independently run the model therefore the model is freely available upon request to the model developers see contact details above with the intent to support new user in the initial stage of their work with the forsafe model declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank for the financial support granted by the projects forwater and managing multiple stressors in the baltic sea funded by the swedish research council formas http www formas se en this study has also been made possible by the swedish infrastructure for ecosystem science sites which provided data from the svartberget research station finally we thank nino amvrosiadi for sharing relevant data on the hydrology of the s transect appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104984 
25872,sustainable management of water ecosystem services requires reliable information to support decision making we evaluate the performance of the invest seasonal water yield model swym against water monitoring records in 224 catchments in southern chile we run the swym in three years 1998 2007 and 2013 to account for recent land use change and climatic variations we computed squared pearson correlations between swym monthly quickflow predictions and streamflow observations and applied a generalized mixed effects model to evaluate annual estimations results show relatively low monthly correlations with marked latitudinal and temporal variations while annual estimates show a good match between observed and modeled values especially for values under 1000 mm year better predictions were observed in regions with high rainfall and in dry years while poorer predictions were found in snow dominated and drier regions our results improve swym performance and contribute to water supply and regulation decision making particularly in data scarce regions graphical abstract image 1 keywords ecosystem service model water regulation water supply south america data scarce regions blue ecosystem services 1 introduction human wellbeing as well as entire ecosystems rely on water resources for their life sustaining supply of freshwater keeler et al 2012 water related ecosystem services es such as water supply and water regulation are highly valued by the public therefore information regarding water es is increasingly being demanded by water resource managers landscape planners and political decision makers guswa et al 2014 keeler et al 2012 assessing water es requires the understanding of hydrological processes and their response to climate and land cover changes in this sense the ability to reliably represent watershed 1 1 watershed catchment and basin are used interchangeably along the manuscript processes is a pivotal element for decision makers and water managers to protect water es in the long term scordo et al 2018 this is particularly relevant for the global south given the rapid current land cover and climate changes threatening long term water es supply alvarez garreton et al 2019 garreaud et al 2017 hydrological models including both land use change and climatic dynamics appear as practical tools for predicting water es and their local effects scordo et al 2018 for example hydrological models can be used to identify areas susceptible to floods or droughts and to project the spatio temporal location where water supply will be scarce or restricted under land use change and changing climate scenarios alvarez garreton et al 2018 scordo et al 2018 hydrological models can also be used for comparative hydrology and catchment classification to explore dis similarities in the supply of water es addor et al 2019 and transfer model information to ungauged locations hrachowitz et al 2013 there are many models to represent hydrological es such as the variable infiltration capacity model vic or the soil and water assessment tool swat these models are often highly complex and data demanding as they require a large number of parameters and information in chile vic has been used for the national update of the chilean water balance at the national scale vargas et al 2017 whereas swat has been used to assess land use changes in basins in the central regions of the country aguayo et al 2016 stehr et al 2008 2009 both models count with applications such as measuring climate change impacts and estimate soil erosion demaria et al 2013 vigerstol and aukema 2011 however in data scarce regions such as southern chile and many other latin american countries the required data and expertise to apply these models is often not available limiting their application vigerstol and aukema 2011 therefore simpler hydrological models i e with a user friendly interface and comparatively low data requirements e g using global freely available data sources are needed to model water es in large parts of the world one of the most used tools for modelling water es is the suite of models that comprise the integrated valuation of ecosystem services and tradeoffs invest developed by the natural capital project posner et al 2016 in particular the seasonal water yield model swym has been used to model water yield in diverse geographical contexts hamel et al 2020 sahle et al 2019 wang et al 2018 assisting stakeholders and decision makers in the management of natural resources cong et al 2020 mandle et al 2017 yang et al 2018 nature based solutions zawadzka et al 2019 and protected areas gaglio et al 2019 wei et al 2019 the swym is based on the curve number method boughton 1989 usda 1986 using relatively simple data inputs main input data consists of land cover and average monthly rainfall to estimate the monthly quickflow per pixel which can be scaled up or down to the area of interest e g the watershed municipality region through summation cong et al 2020 the swym computes spatial indices that quantify the relative contribution of a piece of land to the generation of both baseflow and quickflow i e underground water surface and subsurface runoff respectively sahle et al 2019 sharp et al 2019 reasons for using the swym are its reduced data requirements and outputs that can be directly interpreted as water es i e water supply and regulation hence being readily applicable for managers and decision makers vigerstol and aukema 2011 in addition swym allows managers to work with individual months or seasons an aspect that is important in areas with marked seasonality such as southern chile generally studies using swym to model water es have focused on comparing input parameters and evaluating their sensitivity scale ease of use and interpretability avoiding data scarce regions bryant et al 2018 ochoa and urbina cardona 2017 vigerstol and aukema 2011 despite data availability as potential deterrent to use the model in such data scarce regions scordo et al 2018 recent studies have shown that it is important and meaningful to develop research on the swym in those areas hamel et al 2020 in chile most hydrological modelling studies have studied catchments in the central part of the country e g mediterranean region due to larger data availability demaria et al 2013 iroumé and palacios 2013 only few studies have used some of the invest suit of models see locher krause et al 2017 manuschevich et al 2019 outeiro et al 2015 and none have used the swym in general little is known about the actual performance of swym against observed data cong et al 2020 pessacg et al 2020 and only a few studies have addressed this issue hamel et al 2020 this knowledge gap is especially critical in southern chile as water management might become increasingly important to local stakeholders and decision makers due to increasing land use and climate change impacts e g conversion of land uses to non native tree plantations and decreasing rainfall therefore research is needed to investigate the consequences of these changes for water es in the long term in data scarce regions such as southern chile in this context chile provides an exceptional case study over the last decades there have been dramatic land use changes due to forestry and agricultural policies causing loss of both native forest and agricultural area and afforestation with non native tree plantations particularly in the central and southern regions of chile echeverria et al 2006 heilmayr et al 2020 lara et al 2012 miranda et al 2015 it has been estimated that more than 50 of the original chilean native forest cover was lost by 2007 lara et al 2009 forest policies such as the law decree 701 subsidizing non native tree plantations have caused forest degradation and intensive growth of non native tree plantations areas heilmayr et al 2020 miranda et al 2015 in parallel climate change is leading to prolonged droughts and extreme climatic events in central southern chile such as heat waves and water deficits alvarez garreton et al 2020 garreaud et al 2017 in this study we assessed the ability of swym to predict water es in southern chile over a latitudinal range of 2 000 km 34 7s 55s by comparing monthly and annual water predictions to streamflow observations we implemented the swym for three different years 1998 2007 and 2013 to represent changes in land use and climate this paper aims at 1 characterizing and evaluating swym model performance and uncertainty in complex geographical areas 2 to assess and understand spatial and temporal features influencing model performance and 3 to identify room for model improvement e g additional variables to include in order to inform decision making regarding water es 2 methods 2 1 study area the study area consists of 224 watersheds located in the seven southern administrative regions of chile 2 2 one of the assessed regions bio bio region recently separated administratively from its northern province originating the ñuble region for practical reasons the ñuble region was not considered as a separate region in the analyses fig 1 the number of catchments per region with available streamflow observations was 41 for maule 63 for bio bio 33 for araucanía 12 for los ríos 24 for los lagos 22 for aysén and 29 for magallanes the 224 watersheds ranged in size from 17 9 to 10 400 4 km2 comprising a total area of 232 069 7 km2 with a mean watershed area of 1 040 6 km2 and a standard deviation of 2 144 5 km2 the geographical spread of the watersheds covers a large geographic and climatic gradient of southern chile between 34 7 s and 55 s and 73 7 w and 67 6 w and with altitudes ranging from 0 to 4 077 m a s l the regions stretch for 2 000 km along a north south axis 34 7 s to 55 s flanked by the andes mountains on the east and the pacific ocean on the west 73 7 w to 67 6 w the andes act as a barrier for atmospheric flows leading to high precipitation levels on the chilean side and shaping regional hydroclimatic conditions alvarez garreton et al 2018 garreaud 2009 the study area includes five different climate regions from north to south according to the köppen classification kottek et al 2006 sub humid mediterranean humid mediterranean temperate rain oceanic rain cool oceanic and cold steppe rainfall peaks in southern winter months of june july and august for all regions except for magallanes region and the eastern portion of aysén region where precipitations occur equitably during the seasons fig 2 evapotranspiration crests in the summer months of december january and february the northern and central parts part of the study area i e maule bio bio araucanía los ríos and los lagos regions have experienced highly dynamic land cover change with an increasing and ongoing pressure to convert native woodlands agricultural areas shrubs and pastures to non native tree plantations nahuelhual et al 2012 zamorano elgueta et al 2015 these changes have not been as pronounced in the southern part i e aysén and magallanes where forest fires forest degradation glaciers and snow dynamics play and have historically played a more important role than the incipient non native tree plantations moreno et al 2019 úbeda and sarricolea 2016 in supplementary material 1 s1 we provide matrices of land use change transitions and dynamics per region and year 2 2 invest seasonal water yield model to perform the swym we used spatially explicit climatic land cover soil type digital elevation model dem as well as other non spatial variables as input data table 1 the model was computed through invest a locally installed software remotely connected to an online platform available at https naturalcapitalproject stanford edu software invest to characterize the land cover of the study watersheds we used the chilean national vegetation cadaster which generates land use layers for each region of the country and reclassified the land use types into 11 categories following benra and nahuelhual 2019 urban areas agricultural areas shrubland old growth native forest non native tree plantations arborescent shrubland secondary native forest pastures and meadows non recognized areas including ice and snow areas water and wetlands to assess land cover change over time we run the model for three time steps covering a period of 20 years table 2 since sampling campaigns for the official of land cover cadaster last several years data for the study regions are not available for the exact same years in each region thus we chose the periods of 1996 1998 2005 2009 and 2011 2016 assuming that land cover did not change over the course of each period table 2 we chose year 1998 2007 and 2013 as representing years because of data availability and particular conditions they represent year 1998 is considered the driest year of the past century with the strong influence of el niño event in contrast year 2007 presented a below average thirty years average 1980 2010 precipitation peaking in winter year 2013 presented strong precipitation events in autumn and spring and a dry winter and is part of an ongoing drought series 2010 today with below average precipitation called the chilean mega drought kane 1999 garreaud et al 2020 alvarez garreton et al 2020 despite the study area has witnessed a constant reduction of precipitation and increase of heatwaves in the last two decades alvarez garretón et al 2020 the selected years presented different climatic conditions in the different regions fig 1 however land use data for aysén and magallanes regions were not available for the second and third period respectively therefore we used the closest available land use data for these regions i e year 2011 for aysén and 2005 for magallanes acknowledging that this assumption can influence our results we categorized the administrative regions of the study area in three zones north central and south to simplify analyses and interpretation of results table 2 the swym requires monthly precipitation and potential evapotranspiration i e a raster file per month and year and the total number of precipitation events per month to match the only years with freely available land use data 1998 2007 and 2013 we retrieved the climatic variables for those exact years we extracted the spatial climatic variables for each year using the package raster hijmans 2020 and gdal bivand et al 2019 in r software r core team 2018 for each year for the calculation of the total number of precipitation days per month in each catchment we averaged the total daily precipitation across all pixels contained within the boundaries of each catchments per year 1998 2007 2013 unlike other input variables e g soil type climatic variables of precipitation and potential evapotranspiration as well as land cover data were considered dynamic i e variables changing every year the adopted model configuration differs from recent literature using the swym where authors maintained land cover constant for model runs even when climatic forcing variables changed e g scordo et al 2018 in this study we increased the variability and accuracy of the model by adding different land use data for each respective year for curve number values boughton 1989 we combined estimations adapted to local land use e g forest grassland and soil types data obtained from jullian et al 2018 and clipped them with the administrative regions shapefile we consider this as an improvement of the model as most studies use curve number values provided by the united states department of agriculture usda despite these might not be well suited to represent local conditions crop coefficient kc values of each land use category n 11 were obtained using remote sensing products which offer the possibility to derive kc values for large non agricultural areas comprising a range of land covers de oliveira ferreira silva et al 2018 hence this approach is superior to the common approach of using kc values allen et al 1998 and has the potential to estimate crop coefficients in agricultural and natural ecosystems bhavsar and patel 2016 glenn et al 2011 we applied the methodology of kamble et al 2013 to ndvi modis images 250 m resolution 16 days product for 2000 to 2018 which includes interannual variability of crops and plants to each one of our land use categories to do so first we obtained the mean ndvi values for each land use category n 11 and for each month next we applied the linear regression model of kamble et al 2013 kcndvi 1 457 ndvi 0 1725 this model presented strong linear correlation between ndvi estimated and kc calculated from field data r 2 0 91 in agricultural and grassland areas in the united states once all input data was collected and processed we transformed them to match the coordinate reference systems in linear units meters of all other spatial data layers invest swym automatically adapts all the layers to the resolution of the dem the model also contains several parameters that can be optimized to improve performance α β γ and flow accumulation threshold differently from most studies applying the swym model with default parameters we used the α parameter including antecedent precipitation conditions pm 1 pannual which accounts for the precipitation of the previous month and its contribution to runoff parameter β is a function of local topography and soils and their storage capacity and γ refers to the fraction of pixel recharge that is available to downslope pixels for both parameters we used the default values β 1 0 γ 1 0 because our results were not sensitive to changes in these parameters the flow accumulation threshold is the number of upstream cells that must flow into a cell before it is considered part of a stream and we set it to 30 m which corresponds to the dem resolution 2 3 invest swym outputs the invest swym generates several outputs among them monthly and annual quickflow qf and annual baseflow bf rasters for each watershed qf is the rapid surface runoff after a rainfall event guswa et al 2018 sharp et al 2019 and can be interpreted as an indicator of water regulation and flood control gaglio et al 2019 bf is the portion of the total water flow that is fed from deep subsurface and delayed subsurface storage between precipitation and or snowmelt events ward and robinson 2000 and is often used as an indicator of water supply gaglio et al 2019 data for monthly qf as well as yearly bf values for all analyzed basins are available in supplementary material 2 s2 2 3 1 quickflow and baseflow estimations to obtain annual qf values per catchment i e mm year we followed the method of scordo et al 2018 first we summed the values of all pixels within the monthly qf rasters n 12 for each watershed next we divided the sum by the number of pixels of each basin to obtain the mean value per basin followed by a summation of all the months i e to get an annual value per basin this process was repeated for all 3 selected years table 2 we followed the same procedure of pixel summation for annual bf calculation rasters were processed with r software packages raster hijmans 2020 and rgdal bivand et al 2019 fig 3 we also calculated the bf index which is the proportion of baseflow relative to total streamflow hamel et al 2020 to assess flow partitioning i e contributions of qf and bf to total streamflow in each region we retrieved the index from the camels cl database see section 2 3 2 and computed the mean for all basins per region table 3 2 3 2 streamflow observations and catchment characteristics we used data from the camels cl dataset alvarez garreton et al 2018 a nationwide catchment dataset for chile this database provides streamflow observations from active and historic gauging stations at the daily monthly and annual basis and climatic time series for 516 basins in chile and includes 70 catchment attributes describing climatic topographic geological and anthropogenic catchments characteristics in this database all catchment boundaries have the streamflow gauge as outlet alvarez garreton et al 2018 the database complies with the fair i e findability accessibility interoperability and reuse principles addor et al 2019 from this database we selected the 224 basins that complied with the condition of being within national and regional borders i e no transboundary basins because data availability was constrained to chile and respective administrative regions from the total 224 different watersheds modeled with the swym we used 101 134 and 140 basins for 1998 2007 and 2013 respectively due to the availability of streamflow observations for each year 3 statistical analyses 3 1 describing environmental characteristics through principal component analysis pca we used pca to explore and describe the behavior of environmental attributes climatic and geographical among the study area basins using primer 6 1 13 this method has been proven to effectively uncover climatic and geographic patterns benito et al 2018 darand and mansouri daneshvar 2014 pisani et al 2020 we selected a subset of 20 catchment attributes from the camels cl dataset table 3 among those with available data for all the basins due to the existence of similar variables in the database e g local vs global climatic products we calculated the spearman correlation coefficient r to assess collinearity correlation coefficients for all variables are presented in appendix a fig a 1 the selected variables were formerly transformed to reduce normality departures using arcsin x 100 0 5 for environmental data expressed in ratios or percentages terms and log x 1 for the others aschonitis et al 2015 muresan et al 2020 3 2 monthly comparison of modeled versus observed flows first we compared the modeled qf from the swym with the observed streamflow at each catchment s outlet based on the squared pearson product moment correlation r2 following scordo et al 2018 currently the swym does not provide streamflow values i e qf bf at monthly temporal scale because bf values are only estimated on an annual scale based on this and by following previous studies hamel et al 2020 scordo et al 2018 we used monthly qf values for the comparison with observed streamflow this method comparing qf to total streamflow is a common practice in hydrological studies because it reveals the interrelations between rapid water release i e qf and effects on streamflow and we discuss the results accounting for this we used the r2 threshold of 0 5 as a moderate effect size of the pairwise correlations moore et al 2013 secondly we investigated the main environmental characteristics table 4 influencing model performance i e r2 between monthly qf and observed streamflow by computing multiple regressions with backward stepwise selection using statgraphics centurion xv i statpoint inc removal of variables was based on an f to remove test specifically if the least significant variable had an f value 4 it was removed from the model the procedure stopped when all remaining variables had large f values 3 3 annual comparison of modeled versus observed flows for comparing annual flow values we first summed estimated annual qf and bf outputs i e swym streamflow see fig 3 then we fitted a mixed effects model glmm with gaussian response and identity link using the nlme pinheiro et al 2019 and r2glmm jaeger 2017 packages in r specifically we included random intercepts for each unique watershed i e the random effect watersheds in the glmm see equation 1 to account for the fact that some basins had missing data for particular years which is a common issue with hydrological data to identify the best models we followed the recommendations of zuur et al 2009 for selecting a mixed effect model and used akaike s information criterion aic we considered p values 0 05 to be significant and checked the assumptions of the optimal models as i the homogeneity between model residuals versus fitted values ii the histogram of the model residuals for normality and iii the absence of temporal and spatial autocorrelation in the residuals following the protocol for graphical model validation described in zuur et al 2009 the best model included a non linear transformation log to both the dependent variables swym streamflow and independent variables observed streamflow to normalize the model residuals in this way the swym annual predictions for different catchments and different years were modeled as a function of the observed streamflow as follows 1 swym streamflow ij θ0 θ1 observed streamflow ij a i ε ij where θ0 and θ1 are the linear regression intercept and slope respectively a i is a random intercept assumed to be normally distributed with mean 0 and variance σ a 2 and ε ij is a noise term with mean 0 and variance σ 2 the index i refers to watersheds i 1 224 and j to the observation year j 1 3 within a watershed 4 results 4 1 catchment attributes the two first components of the pca explained 75 5 52 9 and 22 5 for pc1 and pc2 respectively of the total variance in environmental variables in pc1 the variable with the largest eigenvector was the catchment area 0 974 while for pc2 were mean elevation 0 810 mean slope 0 417 and mean precipitation 0 236 see full set of eigenvalues in appendix c table c1 however these variables showed no differences across the location of the catchments north central and south fig 4 neither by model performance appendix c fig c1 therefore further specific analyses are needed to identify the combined role of such multiple environmental characteristics for identifying common catchment attributes influencing swym performances 4 2 monthly evaluation the correlation between swym modeled monthly qf and observed streamflow was relatively low monthly mean r2 sd 0 34 0 24 and varied temporally and spatially fig 5 appendix b fig b1 overall we observed higher r2 in central regions and lower values in northern and southern regions with the lowest r2 in higher latitudes the region with the best performance for all years was los lagos region located in the central zone of the study area the regions with the worst estimations were maule and magallanes regions which are in the northernmost and southernmost zones of the study area respectively fig 5 appendix b fig b 1 for the years 1998 and 2007 32 of the r2 coefficients presented values larger than 0 5 whereas for the year 2013 only 20 of r2 values were larger than 0 5 results show marked variations in the number of basins with values of r2 greater than 0 5 table 5 for instance in 1998 the northern study area regions of maule and bio bio presented 15 0 and 52 6 of the r2 values larger than 0 5 respectively the regions that presented the majority of r2 values larger than 0 5 were los ríos and los lagos central zone with 71 4 and 80 respectively the southernmost regions i e aysén and magallanes only 22 2 and 16 7 of the r2 values complied with that threshold for the year 2007 only two regions in the central part of the study area presented half or more of the basins with r2 values larger than 0 5 year 2013 presented the lowest r2 values fig 5 and lowest percentages of r2 values larger than 0 5 compared to the other analyzed years table 5 however years 2007 and 2013 are quite similar in that they present similar low model performances in contrast to the better model performance in year 1998 to test the effects of environmental characteristics in the performance of the swym we carried out multiple regressions separately for each year the overall variance explained by the regressions varied across years between 46 18 for 1998 and 52 8 for 2013 a subset of 12 different variables were selected in each s year model 7 for 1998 and 5 for both 2007 and 2013 table 6 notably high precipitation frequency was selected for all the regression models while exotic forest plantation and snow cover fraction were selected in two out of three models 1998 and 2013 the larger coefficient values were found for snow cover fraction in 2013 306 9 and glacier 102 7 in 1998 models which were dry years fig 2 depicting the negative effects of snow and ice presence on the swym monthly estimations all the other selected parameters showed relatively low coefficient values 1 4 3 annual comparison of swym outputs versus observed flows the swym streamflow i e qf bf and observed streamflow annual values were significantly positively associated p 0 001 r2 47 1 table 7 these values were approximately on the red dashed line indicating a good estimate fig 6 however the swym underestimated the observed streamflow values above approx 1000 mm year see dotted line in fig 6 which mostly correspond to the southernmost basins table 8 indeed of the seven basins with highest streamflow values 4500 mm year only one corresponds to the northern zone while the rest belongs to the southern zone 5 discussion 5 1 model performance our results show that invest swym monthly estimations have a relatively low mean performance r2 0 34 while annual estimations perform better r2 0 47 fig 5 fig 6 however both monthly and annual estimations present high spatial and temporal variability appendix b fig b1 as other studies have also shown scordo et al 2018 wang et al 2018 monthly estimations are better in more rainy regions i e larger mean monthly precipitation while poorer in more arid and snow dominated regions monthly results are in line with scordo et al 2018 who found better swym performance in humid forest rich regions in north america but poorer performance in regions where snow ice and glaciers played a more dominant role arguably the better estimates produced by the monthly analysis focused on qf in rainfall rich regions could be linked to the constant high soil moisture which causes a quicker water release after rainfall crow et al 2018 this soil moisture is maintained by constant high precipitation but divided in several events which in turn triggers a reaction between the cause rainfall and effect qf that is registered at the gauging stations this was demonstrated by guswa et al 2018 that showed that only small events have no significant impact in total modeled runoff in contrast regions with more snow cover like aysén and magallanes featured poorer performances of the swym scordo et al 2018 incorporated a snow melt component to the default swym outputs which improved mean estimation precision by 10 and hamel et al 2020 included a snowmelt component derived from another hydrological model swat by adding it to the baseflow component provided by the swym therefore it is critical that the swym includes a parameter to incorporate snowmelt to the model annual estimates follow the same trend i e better estimations in rainy regions but considerably better mean performances in arid and snow dominated regions interestingly our study was able to detect the threshold for annual estimations up to which the model performs satisfactorily i e up to 1000 mm year of observed streamflow drastically decreasing performance for streamflow values above that threshold fig 6 we obtained better estimations in the drier year 1998 an aspect that has not being analyzed in previous swym applications fig 5 the analysis of catchments with extreme streamflow values above 4 500 mm year table 8 underlines a consistent underestimation of the swym those basins were located predominantly in southern regions aysén and magallanes and averaged 35 of their area covered by snow the presence of snow was not detected in northern and central regions but it is well known that in those regions high altitude snow cover and glacier presence are important contributors to streamflow particularly in summer and autumn months even though they might be relatively small in size bravo et al 2017 to further improve swym predictions we argue that an important element is the incorporation of bf in the annual analysis in our case study the relative improvement of the annual prediction compared to the monthly one could be related to bf playing an important part in more arid environments and in environments with presence of snow bravo et al 2017 price 2011 for instance catchments within pluvio nival regimes in arid areas show lower bf index table 3 meaning a larger contribution of bf to total streamflow which is in line with several studies in the mediterranean region of chile ayala et al 2016 bravo et al 2017 the relative lower bf index in northern and southern regions coincides with high proportion of forest and snow cover i e glaciers ice snow precipitation which are important contributors and regulators of bf little et al 2009 martínez retureta et al 2020 larger bf indices in central regions indicate lower contribution of bf to total streamflow or conversely higher contribution of qf which can be related to better monthly swym s estimations further the bf qf flow partition could influence localized monthly estimations depending on which element or combination of elements is analyzed for example our monthly analysis which only included qf showed better estimations in rainy regions while the incorporation of bf to the annual analysis improved swym estimations in snow dominated and arid areas interestingly hamel et al 2020 obtained a good model fit for monthly values incorporating bf calculated with swat software an action that can be easily taken in other studies if the swym would provide monthly bf output rasters 5 2 spatial and temporal considerations the pca analysis revealed that area mean elevation and mean slope geographical variables were the most important variables describing the catchments despite that other studies have shown that climatic and other land use variables were the most important for the swym scordo et al 2018 wang et al 2018 basin characteristics were well described by the environmental parameters considered in the study explaining 75 5 of the variance thus corroborating the suitability for further insights however we did not observe strong differences between basins by location of the catchments fig 4 nor by model performance appendix c fig c1 the lack of patterns regarding location of the catchments could be explained by the mountainous characteristics of most of the studied basins in that they could hide latitudinal north south axis differences probably the inclusion of other environmental attributes could give more insights on patterns or lack of patterns by location of the basins and model performance in contrast regression analysis table 6 looking at monthly swym performance revealed that high precipitation frequency was a variable selected in all three analyzed years indicating the relation and sensitivity of the swym to climatic variables wang et al 2018 this variable also highlights the importance of storm events for swym performance due to the link and dependency of the curve number method on storm events guswa et al 2018 however monthly swym performance depends on several factors in different years such as seasonality of precipitation for instance snow and forest related variables were selected in the years 1998 the whole year and 2013 particularly in winter months which were very dry years table 6 this could indicate the important regulating effects of snow and forest landscapes to water flows in dry years and the relevance of adequate land management options related to these variables e g forest and glacier management for instance in northern and central regions an important portion of the landscape is covered by forested landscapes which are experiencing intense land use changes such as the advancement of exotic plantations and native forest degradation echeverria et al 2006 miranda et al 2015 nahuelhual et al 2012 increased exotic tree plantations areas at the expense of native forest has been shown to cause reductions of water flows alvarez garreton et al 2019 huber 2008 little et al 2009 on the other hand landscapes in southern regions include grasslands barren land ice and snow which could be jeopardized by advancing climate change and the interplay of the climatic and land use variables for example due to climate change ice masses displacement are leaving huge areas of barren lands and free space for plant colonization and therefore land use change moreno et al 2019 overall the aforementioned changes in forested landscapes and in snow and ice masses displacement need to be monitored through time as they critically impact seasonal water flows the temporal analysis of the two main climatic inputs of the swym shows that year 1998 presented the lowest precipitation in southern winter months fig 2 in fact 1998 is considered one of the driest years of the century in the study area and the strongest el niño year recorded associated with severe drought water scarcity and wild fires on that year daniels and veblen 2000 gonzález et al 2011 kane 1999 year 2013 is part of the recent mega drought experienced in chile garreaud et al 2017 although there was unusually high spring and autumn precipitation with a dry winter while year 2007 presented a normal distribution of precipitation although below average in winter months notably these climatic phenomena in 1998 and 2013 associated with below average precipitation and heatwaves coincided with better swym estimates in the central and southern regions however year 2007 and 2013 present similarly low modeled values when contrasted to year 1998 which showed better swym estimations year 1998 presented high potential evapotranspiration values in the northern and central regions in spring and summer months fig 2b while this trend did not appear in southern regions these regional and seasonal differences can be related to reigning atmospheric circulation conditions in southern chile which are different to the ones in the central and northern regions and to the location of most of the basins within these regions on the eastern rain shadow side of the andes mountain garreaud et al 2013 garreaud 2009 5 3 overcoming swym limitations as with any model there are errors associated with swym predictions which include structural errors derived from the assumptions upon which the model works e g flow routing and curve number methods the suitability of selected parameters and errors in the input data e g climatic forcing variables regarding model structure and parameterization we are aware that the use of the same model parameters in different basins is not optimal and would require individual sensitivity analysis parameters α and β are not readily available for any given watershed making them difficult to set therefore further research in both model parameter sensitivity and direct comparison of modeled against observed values is needed e g hamel et al 2020 hamel and guswa 2015 regarding the quality of climatic input data in this study we used the product developed within the chilean water balance vargas et al 2017 which represents the most updated gridded dataset for the country and has been increasingly used and evaluated in hydrological applications however precipitation estimates remain as the main source of uncertainty in hydrological models hrachowitz et al 2013 for instance the forcing variables used in the model precipitation and evapotranspiration imply two problems the lack of representation of meteorological stations above 1000 m a s l even though chile is high elevation a mountainous country and low density of meteorological stations in the southern part of the study area which makes climatic estimations more uncertain alvarez garreton et al 2018 there is an increasing body of research highlighting the importance of including precipitation inputs in rainfall runoff models mcglynn et al 2012 zhou et al 2012 and in particular for the invest model boithias et al 2014 we argue that usage and handling of swym could improve if developers consider the following suggestions first to enable the addition of locally significant variables in the default input interface which could increase model performance and reliability for policy makers and local stakeholders guswa et al 2014 for example incorporating snow precipitation and ice or snowmelt as a default element of the swym has been recommended by scordo et al 2018 and hamel et al 2020 and could extend the application of swym to many mountainous and high latitude areas allowing for more accurate model estimates we are aware that including more parameters to the model e g snowmelt increases model complexity but better swym estimations would outweigh this constrain second we suggest providing bf as an output at the monthly scale which would make evaluations more straightforward since model users could compare the same elements of the water cycle in different seasons in this case streamflow qf bf this would also extend the applicability of the model to specific seasons periods which are important for their practical implications for managers and decision makers interested in particular periods of the year for instance calculating water availability in the dry season or predicting flood events in the rainy season 5 4 implications for model users and es decision making the swym was developed for applications in data scarce environments where demand for decision support tools is increasing hamel et al 2020 therefore the application of the model is recommended in chile and other data scarce countries to understand local effects of rapid land use and climate changes on water es which is often required in watershed management programs hamel et al 2020 however local decision makers should be aware of the limitations of the model and how to overcome them for instance large scale studies such as this work can show where it is more recommended to apply the swym i e where the model performs better leading to basin specific studies that could be more appropriate from a management perspective hamel et al 2020 interpretation and translation of the hydrological concepts qf and bf i e swym outputs into es vocabulary is straightforward and can be done using water es related literature e g gaglio et al 2019 for example users can interpret qf as water regulation and bf as water supply however interpretation depends on swym users and local context 6 conclusion in this study we exemplify the application of the invest swym and its capability to estimate water es in a large and diverse area in southern chile across several time periods learning about the estimative power of the swym is an important task for validating and supporting model usage among managers and policy makers in a data scarce region our analyses hint that the model performs better at the annual scale rather than the monthly scale and that the model has high potential for multiscale water es assessments furthermore the swym seems to be more accurate in drier years and in basins with yearly streamflow values below 1000 mm year but paradoxically in rainier and ice free regions a critical future research avenue is the application and evaluation of the model in more inaccessible regions such as mountainous and ice covered areas as well as in other countries in latin america or with limited data availability it is our hope that this work contributes to the water es research with direct takeaways for decision makers supporting sustainably management of water es in the long term credit authorship contribution statement f benra conceptualization data curation formal analysis methodology investigation visualization writing original draft a de frutos data curation methodology visualization formal analysis writing review editing m gaglio methodology conceptualization formal analysis writing review editing c álvarez garretón conceptualization writing review editing m felipe lucia writing review editing a bonn writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements f b was funded by the national agency for research and development anid through scholarship program becas chile doctorado acuerdo bilateral daad convocatoria 2017 number 62170002 f b m f l and a b gratefully acknowledge the support of idiv funded by the german research foundation dfg fzt 118 202548816 c a g is supported by the center for climate and resilience research cr2 anid fondap 15110009 and the joint research project anid nsfc190018 appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 multimedia component 3 multimedia component 3 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104982 appendix a table a 1 correlation plot of selected 20 variables table a 1 appendix b fig b 1 monthly mean r2 values for basins in the study area yellow represents catchments with na values for the respective year fig b 1 appendix c fig c1 pca showing performance of the model against environmental attributes fig c1 table c1 eigenvalues and eigenvectors from the pca analysis table c1 eigenvalues pc eigenvalues variation cum variation 1 0 33 52 9 52 9 2 0 141 22 5 75 5 3 5 95e 2 9 5 85 4 3 48e 2 5 6 90 6 5 2 05e 2 3 3 93 9 eigenvectors variable pc1 pc2 pc3 pc4 pc5 area 0 974 0 173 0 092 0 017 0 097 elev mean 0 175 0 81 0 188 0 192 0 07 slope mean 0 024 0 417 0 091 0 082 0 14 crop 0 009 0 031 0 038 0 045 0 059 nf 0 094 0 148 0 609 0 401 0 584 fp 0 032 0 05 0 097 0 162 0 006 grass 0 004 0 129 0 028 0 109 0 113 shrub 0 012 0 0 09 0 12 0 095 wet 0 003 0 011 0 014 0 016 0 032 imp 0 0 0 0 0 001 barren 0 028 0 118 0 15 0 146 0 088 snow frac 0 001 0 006 0 008 0 047 0 031 glacier 0 001 0 007 0 008 0 058 0 038 prec mean 0 07 0 236 0 366 0 351 0 683 pet mean 0 015 0 004 0 033 0 316 0 135 aridity 0 033 0 127 0 195 0 051 0 302 snowfall 0 0 0 0 0 high prec freq 0 053 0 091 0 601 0 692 0 105 p mean spread 0 003 0 053 0 024 0 091 0 008 interv degree 0 002 0 012 0 008 0 002 0 047 
25872,sustainable management of water ecosystem services requires reliable information to support decision making we evaluate the performance of the invest seasonal water yield model swym against water monitoring records in 224 catchments in southern chile we run the swym in three years 1998 2007 and 2013 to account for recent land use change and climatic variations we computed squared pearson correlations between swym monthly quickflow predictions and streamflow observations and applied a generalized mixed effects model to evaluate annual estimations results show relatively low monthly correlations with marked latitudinal and temporal variations while annual estimates show a good match between observed and modeled values especially for values under 1000 mm year better predictions were observed in regions with high rainfall and in dry years while poorer predictions were found in snow dominated and drier regions our results improve swym performance and contribute to water supply and regulation decision making particularly in data scarce regions graphical abstract image 1 keywords ecosystem service model water regulation water supply south america data scarce regions blue ecosystem services 1 introduction human wellbeing as well as entire ecosystems rely on water resources for their life sustaining supply of freshwater keeler et al 2012 water related ecosystem services es such as water supply and water regulation are highly valued by the public therefore information regarding water es is increasingly being demanded by water resource managers landscape planners and political decision makers guswa et al 2014 keeler et al 2012 assessing water es requires the understanding of hydrological processes and their response to climate and land cover changes in this sense the ability to reliably represent watershed 1 1 watershed catchment and basin are used interchangeably along the manuscript processes is a pivotal element for decision makers and water managers to protect water es in the long term scordo et al 2018 this is particularly relevant for the global south given the rapid current land cover and climate changes threatening long term water es supply alvarez garreton et al 2019 garreaud et al 2017 hydrological models including both land use change and climatic dynamics appear as practical tools for predicting water es and their local effects scordo et al 2018 for example hydrological models can be used to identify areas susceptible to floods or droughts and to project the spatio temporal location where water supply will be scarce or restricted under land use change and changing climate scenarios alvarez garreton et al 2018 scordo et al 2018 hydrological models can also be used for comparative hydrology and catchment classification to explore dis similarities in the supply of water es addor et al 2019 and transfer model information to ungauged locations hrachowitz et al 2013 there are many models to represent hydrological es such as the variable infiltration capacity model vic or the soil and water assessment tool swat these models are often highly complex and data demanding as they require a large number of parameters and information in chile vic has been used for the national update of the chilean water balance at the national scale vargas et al 2017 whereas swat has been used to assess land use changes in basins in the central regions of the country aguayo et al 2016 stehr et al 2008 2009 both models count with applications such as measuring climate change impacts and estimate soil erosion demaria et al 2013 vigerstol and aukema 2011 however in data scarce regions such as southern chile and many other latin american countries the required data and expertise to apply these models is often not available limiting their application vigerstol and aukema 2011 therefore simpler hydrological models i e with a user friendly interface and comparatively low data requirements e g using global freely available data sources are needed to model water es in large parts of the world one of the most used tools for modelling water es is the suite of models that comprise the integrated valuation of ecosystem services and tradeoffs invest developed by the natural capital project posner et al 2016 in particular the seasonal water yield model swym has been used to model water yield in diverse geographical contexts hamel et al 2020 sahle et al 2019 wang et al 2018 assisting stakeholders and decision makers in the management of natural resources cong et al 2020 mandle et al 2017 yang et al 2018 nature based solutions zawadzka et al 2019 and protected areas gaglio et al 2019 wei et al 2019 the swym is based on the curve number method boughton 1989 usda 1986 using relatively simple data inputs main input data consists of land cover and average monthly rainfall to estimate the monthly quickflow per pixel which can be scaled up or down to the area of interest e g the watershed municipality region through summation cong et al 2020 the swym computes spatial indices that quantify the relative contribution of a piece of land to the generation of both baseflow and quickflow i e underground water surface and subsurface runoff respectively sahle et al 2019 sharp et al 2019 reasons for using the swym are its reduced data requirements and outputs that can be directly interpreted as water es i e water supply and regulation hence being readily applicable for managers and decision makers vigerstol and aukema 2011 in addition swym allows managers to work with individual months or seasons an aspect that is important in areas with marked seasonality such as southern chile generally studies using swym to model water es have focused on comparing input parameters and evaluating their sensitivity scale ease of use and interpretability avoiding data scarce regions bryant et al 2018 ochoa and urbina cardona 2017 vigerstol and aukema 2011 despite data availability as potential deterrent to use the model in such data scarce regions scordo et al 2018 recent studies have shown that it is important and meaningful to develop research on the swym in those areas hamel et al 2020 in chile most hydrological modelling studies have studied catchments in the central part of the country e g mediterranean region due to larger data availability demaria et al 2013 iroumé and palacios 2013 only few studies have used some of the invest suit of models see locher krause et al 2017 manuschevich et al 2019 outeiro et al 2015 and none have used the swym in general little is known about the actual performance of swym against observed data cong et al 2020 pessacg et al 2020 and only a few studies have addressed this issue hamel et al 2020 this knowledge gap is especially critical in southern chile as water management might become increasingly important to local stakeholders and decision makers due to increasing land use and climate change impacts e g conversion of land uses to non native tree plantations and decreasing rainfall therefore research is needed to investigate the consequences of these changes for water es in the long term in data scarce regions such as southern chile in this context chile provides an exceptional case study over the last decades there have been dramatic land use changes due to forestry and agricultural policies causing loss of both native forest and agricultural area and afforestation with non native tree plantations particularly in the central and southern regions of chile echeverria et al 2006 heilmayr et al 2020 lara et al 2012 miranda et al 2015 it has been estimated that more than 50 of the original chilean native forest cover was lost by 2007 lara et al 2009 forest policies such as the law decree 701 subsidizing non native tree plantations have caused forest degradation and intensive growth of non native tree plantations areas heilmayr et al 2020 miranda et al 2015 in parallel climate change is leading to prolonged droughts and extreme climatic events in central southern chile such as heat waves and water deficits alvarez garreton et al 2020 garreaud et al 2017 in this study we assessed the ability of swym to predict water es in southern chile over a latitudinal range of 2 000 km 34 7s 55s by comparing monthly and annual water predictions to streamflow observations we implemented the swym for three different years 1998 2007 and 2013 to represent changes in land use and climate this paper aims at 1 characterizing and evaluating swym model performance and uncertainty in complex geographical areas 2 to assess and understand spatial and temporal features influencing model performance and 3 to identify room for model improvement e g additional variables to include in order to inform decision making regarding water es 2 methods 2 1 study area the study area consists of 224 watersheds located in the seven southern administrative regions of chile 2 2 one of the assessed regions bio bio region recently separated administratively from its northern province originating the ñuble region for practical reasons the ñuble region was not considered as a separate region in the analyses fig 1 the number of catchments per region with available streamflow observations was 41 for maule 63 for bio bio 33 for araucanía 12 for los ríos 24 for los lagos 22 for aysén and 29 for magallanes the 224 watersheds ranged in size from 17 9 to 10 400 4 km2 comprising a total area of 232 069 7 km2 with a mean watershed area of 1 040 6 km2 and a standard deviation of 2 144 5 km2 the geographical spread of the watersheds covers a large geographic and climatic gradient of southern chile between 34 7 s and 55 s and 73 7 w and 67 6 w and with altitudes ranging from 0 to 4 077 m a s l the regions stretch for 2 000 km along a north south axis 34 7 s to 55 s flanked by the andes mountains on the east and the pacific ocean on the west 73 7 w to 67 6 w the andes act as a barrier for atmospheric flows leading to high precipitation levels on the chilean side and shaping regional hydroclimatic conditions alvarez garreton et al 2018 garreaud 2009 the study area includes five different climate regions from north to south according to the köppen classification kottek et al 2006 sub humid mediterranean humid mediterranean temperate rain oceanic rain cool oceanic and cold steppe rainfall peaks in southern winter months of june july and august for all regions except for magallanes region and the eastern portion of aysén region where precipitations occur equitably during the seasons fig 2 evapotranspiration crests in the summer months of december january and february the northern and central parts part of the study area i e maule bio bio araucanía los ríos and los lagos regions have experienced highly dynamic land cover change with an increasing and ongoing pressure to convert native woodlands agricultural areas shrubs and pastures to non native tree plantations nahuelhual et al 2012 zamorano elgueta et al 2015 these changes have not been as pronounced in the southern part i e aysén and magallanes where forest fires forest degradation glaciers and snow dynamics play and have historically played a more important role than the incipient non native tree plantations moreno et al 2019 úbeda and sarricolea 2016 in supplementary material 1 s1 we provide matrices of land use change transitions and dynamics per region and year 2 2 invest seasonal water yield model to perform the swym we used spatially explicit climatic land cover soil type digital elevation model dem as well as other non spatial variables as input data table 1 the model was computed through invest a locally installed software remotely connected to an online platform available at https naturalcapitalproject stanford edu software invest to characterize the land cover of the study watersheds we used the chilean national vegetation cadaster which generates land use layers for each region of the country and reclassified the land use types into 11 categories following benra and nahuelhual 2019 urban areas agricultural areas shrubland old growth native forest non native tree plantations arborescent shrubland secondary native forest pastures and meadows non recognized areas including ice and snow areas water and wetlands to assess land cover change over time we run the model for three time steps covering a period of 20 years table 2 since sampling campaigns for the official of land cover cadaster last several years data for the study regions are not available for the exact same years in each region thus we chose the periods of 1996 1998 2005 2009 and 2011 2016 assuming that land cover did not change over the course of each period table 2 we chose year 1998 2007 and 2013 as representing years because of data availability and particular conditions they represent year 1998 is considered the driest year of the past century with the strong influence of el niño event in contrast year 2007 presented a below average thirty years average 1980 2010 precipitation peaking in winter year 2013 presented strong precipitation events in autumn and spring and a dry winter and is part of an ongoing drought series 2010 today with below average precipitation called the chilean mega drought kane 1999 garreaud et al 2020 alvarez garreton et al 2020 despite the study area has witnessed a constant reduction of precipitation and increase of heatwaves in the last two decades alvarez garretón et al 2020 the selected years presented different climatic conditions in the different regions fig 1 however land use data for aysén and magallanes regions were not available for the second and third period respectively therefore we used the closest available land use data for these regions i e year 2011 for aysén and 2005 for magallanes acknowledging that this assumption can influence our results we categorized the administrative regions of the study area in three zones north central and south to simplify analyses and interpretation of results table 2 the swym requires monthly precipitation and potential evapotranspiration i e a raster file per month and year and the total number of precipitation events per month to match the only years with freely available land use data 1998 2007 and 2013 we retrieved the climatic variables for those exact years we extracted the spatial climatic variables for each year using the package raster hijmans 2020 and gdal bivand et al 2019 in r software r core team 2018 for each year for the calculation of the total number of precipitation days per month in each catchment we averaged the total daily precipitation across all pixels contained within the boundaries of each catchments per year 1998 2007 2013 unlike other input variables e g soil type climatic variables of precipitation and potential evapotranspiration as well as land cover data were considered dynamic i e variables changing every year the adopted model configuration differs from recent literature using the swym where authors maintained land cover constant for model runs even when climatic forcing variables changed e g scordo et al 2018 in this study we increased the variability and accuracy of the model by adding different land use data for each respective year for curve number values boughton 1989 we combined estimations adapted to local land use e g forest grassland and soil types data obtained from jullian et al 2018 and clipped them with the administrative regions shapefile we consider this as an improvement of the model as most studies use curve number values provided by the united states department of agriculture usda despite these might not be well suited to represent local conditions crop coefficient kc values of each land use category n 11 were obtained using remote sensing products which offer the possibility to derive kc values for large non agricultural areas comprising a range of land covers de oliveira ferreira silva et al 2018 hence this approach is superior to the common approach of using kc values allen et al 1998 and has the potential to estimate crop coefficients in agricultural and natural ecosystems bhavsar and patel 2016 glenn et al 2011 we applied the methodology of kamble et al 2013 to ndvi modis images 250 m resolution 16 days product for 2000 to 2018 which includes interannual variability of crops and plants to each one of our land use categories to do so first we obtained the mean ndvi values for each land use category n 11 and for each month next we applied the linear regression model of kamble et al 2013 kcndvi 1 457 ndvi 0 1725 this model presented strong linear correlation between ndvi estimated and kc calculated from field data r 2 0 91 in agricultural and grassland areas in the united states once all input data was collected and processed we transformed them to match the coordinate reference systems in linear units meters of all other spatial data layers invest swym automatically adapts all the layers to the resolution of the dem the model also contains several parameters that can be optimized to improve performance α β γ and flow accumulation threshold differently from most studies applying the swym model with default parameters we used the α parameter including antecedent precipitation conditions pm 1 pannual which accounts for the precipitation of the previous month and its contribution to runoff parameter β is a function of local topography and soils and their storage capacity and γ refers to the fraction of pixel recharge that is available to downslope pixels for both parameters we used the default values β 1 0 γ 1 0 because our results were not sensitive to changes in these parameters the flow accumulation threshold is the number of upstream cells that must flow into a cell before it is considered part of a stream and we set it to 30 m which corresponds to the dem resolution 2 3 invest swym outputs the invest swym generates several outputs among them monthly and annual quickflow qf and annual baseflow bf rasters for each watershed qf is the rapid surface runoff after a rainfall event guswa et al 2018 sharp et al 2019 and can be interpreted as an indicator of water regulation and flood control gaglio et al 2019 bf is the portion of the total water flow that is fed from deep subsurface and delayed subsurface storage between precipitation and or snowmelt events ward and robinson 2000 and is often used as an indicator of water supply gaglio et al 2019 data for monthly qf as well as yearly bf values for all analyzed basins are available in supplementary material 2 s2 2 3 1 quickflow and baseflow estimations to obtain annual qf values per catchment i e mm year we followed the method of scordo et al 2018 first we summed the values of all pixels within the monthly qf rasters n 12 for each watershed next we divided the sum by the number of pixels of each basin to obtain the mean value per basin followed by a summation of all the months i e to get an annual value per basin this process was repeated for all 3 selected years table 2 we followed the same procedure of pixel summation for annual bf calculation rasters were processed with r software packages raster hijmans 2020 and rgdal bivand et al 2019 fig 3 we also calculated the bf index which is the proportion of baseflow relative to total streamflow hamel et al 2020 to assess flow partitioning i e contributions of qf and bf to total streamflow in each region we retrieved the index from the camels cl database see section 2 3 2 and computed the mean for all basins per region table 3 2 3 2 streamflow observations and catchment characteristics we used data from the camels cl dataset alvarez garreton et al 2018 a nationwide catchment dataset for chile this database provides streamflow observations from active and historic gauging stations at the daily monthly and annual basis and climatic time series for 516 basins in chile and includes 70 catchment attributes describing climatic topographic geological and anthropogenic catchments characteristics in this database all catchment boundaries have the streamflow gauge as outlet alvarez garreton et al 2018 the database complies with the fair i e findability accessibility interoperability and reuse principles addor et al 2019 from this database we selected the 224 basins that complied with the condition of being within national and regional borders i e no transboundary basins because data availability was constrained to chile and respective administrative regions from the total 224 different watersheds modeled with the swym we used 101 134 and 140 basins for 1998 2007 and 2013 respectively due to the availability of streamflow observations for each year 3 statistical analyses 3 1 describing environmental characteristics through principal component analysis pca we used pca to explore and describe the behavior of environmental attributes climatic and geographical among the study area basins using primer 6 1 13 this method has been proven to effectively uncover climatic and geographic patterns benito et al 2018 darand and mansouri daneshvar 2014 pisani et al 2020 we selected a subset of 20 catchment attributes from the camels cl dataset table 3 among those with available data for all the basins due to the existence of similar variables in the database e g local vs global climatic products we calculated the spearman correlation coefficient r to assess collinearity correlation coefficients for all variables are presented in appendix a fig a 1 the selected variables were formerly transformed to reduce normality departures using arcsin x 100 0 5 for environmental data expressed in ratios or percentages terms and log x 1 for the others aschonitis et al 2015 muresan et al 2020 3 2 monthly comparison of modeled versus observed flows first we compared the modeled qf from the swym with the observed streamflow at each catchment s outlet based on the squared pearson product moment correlation r2 following scordo et al 2018 currently the swym does not provide streamflow values i e qf bf at monthly temporal scale because bf values are only estimated on an annual scale based on this and by following previous studies hamel et al 2020 scordo et al 2018 we used monthly qf values for the comparison with observed streamflow this method comparing qf to total streamflow is a common practice in hydrological studies because it reveals the interrelations between rapid water release i e qf and effects on streamflow and we discuss the results accounting for this we used the r2 threshold of 0 5 as a moderate effect size of the pairwise correlations moore et al 2013 secondly we investigated the main environmental characteristics table 4 influencing model performance i e r2 between monthly qf and observed streamflow by computing multiple regressions with backward stepwise selection using statgraphics centurion xv i statpoint inc removal of variables was based on an f to remove test specifically if the least significant variable had an f value 4 it was removed from the model the procedure stopped when all remaining variables had large f values 3 3 annual comparison of modeled versus observed flows for comparing annual flow values we first summed estimated annual qf and bf outputs i e swym streamflow see fig 3 then we fitted a mixed effects model glmm with gaussian response and identity link using the nlme pinheiro et al 2019 and r2glmm jaeger 2017 packages in r specifically we included random intercepts for each unique watershed i e the random effect watersheds in the glmm see equation 1 to account for the fact that some basins had missing data for particular years which is a common issue with hydrological data to identify the best models we followed the recommendations of zuur et al 2009 for selecting a mixed effect model and used akaike s information criterion aic we considered p values 0 05 to be significant and checked the assumptions of the optimal models as i the homogeneity between model residuals versus fitted values ii the histogram of the model residuals for normality and iii the absence of temporal and spatial autocorrelation in the residuals following the protocol for graphical model validation described in zuur et al 2009 the best model included a non linear transformation log to both the dependent variables swym streamflow and independent variables observed streamflow to normalize the model residuals in this way the swym annual predictions for different catchments and different years were modeled as a function of the observed streamflow as follows 1 swym streamflow ij θ0 θ1 observed streamflow ij a i ε ij where θ0 and θ1 are the linear regression intercept and slope respectively a i is a random intercept assumed to be normally distributed with mean 0 and variance σ a 2 and ε ij is a noise term with mean 0 and variance σ 2 the index i refers to watersheds i 1 224 and j to the observation year j 1 3 within a watershed 4 results 4 1 catchment attributes the two first components of the pca explained 75 5 52 9 and 22 5 for pc1 and pc2 respectively of the total variance in environmental variables in pc1 the variable with the largest eigenvector was the catchment area 0 974 while for pc2 were mean elevation 0 810 mean slope 0 417 and mean precipitation 0 236 see full set of eigenvalues in appendix c table c1 however these variables showed no differences across the location of the catchments north central and south fig 4 neither by model performance appendix c fig c1 therefore further specific analyses are needed to identify the combined role of such multiple environmental characteristics for identifying common catchment attributes influencing swym performances 4 2 monthly evaluation the correlation between swym modeled monthly qf and observed streamflow was relatively low monthly mean r2 sd 0 34 0 24 and varied temporally and spatially fig 5 appendix b fig b1 overall we observed higher r2 in central regions and lower values in northern and southern regions with the lowest r2 in higher latitudes the region with the best performance for all years was los lagos region located in the central zone of the study area the regions with the worst estimations were maule and magallanes regions which are in the northernmost and southernmost zones of the study area respectively fig 5 appendix b fig b 1 for the years 1998 and 2007 32 of the r2 coefficients presented values larger than 0 5 whereas for the year 2013 only 20 of r2 values were larger than 0 5 results show marked variations in the number of basins with values of r2 greater than 0 5 table 5 for instance in 1998 the northern study area regions of maule and bio bio presented 15 0 and 52 6 of the r2 values larger than 0 5 respectively the regions that presented the majority of r2 values larger than 0 5 were los ríos and los lagos central zone with 71 4 and 80 respectively the southernmost regions i e aysén and magallanes only 22 2 and 16 7 of the r2 values complied with that threshold for the year 2007 only two regions in the central part of the study area presented half or more of the basins with r2 values larger than 0 5 year 2013 presented the lowest r2 values fig 5 and lowest percentages of r2 values larger than 0 5 compared to the other analyzed years table 5 however years 2007 and 2013 are quite similar in that they present similar low model performances in contrast to the better model performance in year 1998 to test the effects of environmental characteristics in the performance of the swym we carried out multiple regressions separately for each year the overall variance explained by the regressions varied across years between 46 18 for 1998 and 52 8 for 2013 a subset of 12 different variables were selected in each s year model 7 for 1998 and 5 for both 2007 and 2013 table 6 notably high precipitation frequency was selected for all the regression models while exotic forest plantation and snow cover fraction were selected in two out of three models 1998 and 2013 the larger coefficient values were found for snow cover fraction in 2013 306 9 and glacier 102 7 in 1998 models which were dry years fig 2 depicting the negative effects of snow and ice presence on the swym monthly estimations all the other selected parameters showed relatively low coefficient values 1 4 3 annual comparison of swym outputs versus observed flows the swym streamflow i e qf bf and observed streamflow annual values were significantly positively associated p 0 001 r2 47 1 table 7 these values were approximately on the red dashed line indicating a good estimate fig 6 however the swym underestimated the observed streamflow values above approx 1000 mm year see dotted line in fig 6 which mostly correspond to the southernmost basins table 8 indeed of the seven basins with highest streamflow values 4500 mm year only one corresponds to the northern zone while the rest belongs to the southern zone 5 discussion 5 1 model performance our results show that invest swym monthly estimations have a relatively low mean performance r2 0 34 while annual estimations perform better r2 0 47 fig 5 fig 6 however both monthly and annual estimations present high spatial and temporal variability appendix b fig b1 as other studies have also shown scordo et al 2018 wang et al 2018 monthly estimations are better in more rainy regions i e larger mean monthly precipitation while poorer in more arid and snow dominated regions monthly results are in line with scordo et al 2018 who found better swym performance in humid forest rich regions in north america but poorer performance in regions where snow ice and glaciers played a more dominant role arguably the better estimates produced by the monthly analysis focused on qf in rainfall rich regions could be linked to the constant high soil moisture which causes a quicker water release after rainfall crow et al 2018 this soil moisture is maintained by constant high precipitation but divided in several events which in turn triggers a reaction between the cause rainfall and effect qf that is registered at the gauging stations this was demonstrated by guswa et al 2018 that showed that only small events have no significant impact in total modeled runoff in contrast regions with more snow cover like aysén and magallanes featured poorer performances of the swym scordo et al 2018 incorporated a snow melt component to the default swym outputs which improved mean estimation precision by 10 and hamel et al 2020 included a snowmelt component derived from another hydrological model swat by adding it to the baseflow component provided by the swym therefore it is critical that the swym includes a parameter to incorporate snowmelt to the model annual estimates follow the same trend i e better estimations in rainy regions but considerably better mean performances in arid and snow dominated regions interestingly our study was able to detect the threshold for annual estimations up to which the model performs satisfactorily i e up to 1000 mm year of observed streamflow drastically decreasing performance for streamflow values above that threshold fig 6 we obtained better estimations in the drier year 1998 an aspect that has not being analyzed in previous swym applications fig 5 the analysis of catchments with extreme streamflow values above 4 500 mm year table 8 underlines a consistent underestimation of the swym those basins were located predominantly in southern regions aysén and magallanes and averaged 35 of their area covered by snow the presence of snow was not detected in northern and central regions but it is well known that in those regions high altitude snow cover and glacier presence are important contributors to streamflow particularly in summer and autumn months even though they might be relatively small in size bravo et al 2017 to further improve swym predictions we argue that an important element is the incorporation of bf in the annual analysis in our case study the relative improvement of the annual prediction compared to the monthly one could be related to bf playing an important part in more arid environments and in environments with presence of snow bravo et al 2017 price 2011 for instance catchments within pluvio nival regimes in arid areas show lower bf index table 3 meaning a larger contribution of bf to total streamflow which is in line with several studies in the mediterranean region of chile ayala et al 2016 bravo et al 2017 the relative lower bf index in northern and southern regions coincides with high proportion of forest and snow cover i e glaciers ice snow precipitation which are important contributors and regulators of bf little et al 2009 martínez retureta et al 2020 larger bf indices in central regions indicate lower contribution of bf to total streamflow or conversely higher contribution of qf which can be related to better monthly swym s estimations further the bf qf flow partition could influence localized monthly estimations depending on which element or combination of elements is analyzed for example our monthly analysis which only included qf showed better estimations in rainy regions while the incorporation of bf to the annual analysis improved swym estimations in snow dominated and arid areas interestingly hamel et al 2020 obtained a good model fit for monthly values incorporating bf calculated with swat software an action that can be easily taken in other studies if the swym would provide monthly bf output rasters 5 2 spatial and temporal considerations the pca analysis revealed that area mean elevation and mean slope geographical variables were the most important variables describing the catchments despite that other studies have shown that climatic and other land use variables were the most important for the swym scordo et al 2018 wang et al 2018 basin characteristics were well described by the environmental parameters considered in the study explaining 75 5 of the variance thus corroborating the suitability for further insights however we did not observe strong differences between basins by location of the catchments fig 4 nor by model performance appendix c fig c1 the lack of patterns regarding location of the catchments could be explained by the mountainous characteristics of most of the studied basins in that they could hide latitudinal north south axis differences probably the inclusion of other environmental attributes could give more insights on patterns or lack of patterns by location of the basins and model performance in contrast regression analysis table 6 looking at monthly swym performance revealed that high precipitation frequency was a variable selected in all three analyzed years indicating the relation and sensitivity of the swym to climatic variables wang et al 2018 this variable also highlights the importance of storm events for swym performance due to the link and dependency of the curve number method on storm events guswa et al 2018 however monthly swym performance depends on several factors in different years such as seasonality of precipitation for instance snow and forest related variables were selected in the years 1998 the whole year and 2013 particularly in winter months which were very dry years table 6 this could indicate the important regulating effects of snow and forest landscapes to water flows in dry years and the relevance of adequate land management options related to these variables e g forest and glacier management for instance in northern and central regions an important portion of the landscape is covered by forested landscapes which are experiencing intense land use changes such as the advancement of exotic plantations and native forest degradation echeverria et al 2006 miranda et al 2015 nahuelhual et al 2012 increased exotic tree plantations areas at the expense of native forest has been shown to cause reductions of water flows alvarez garreton et al 2019 huber 2008 little et al 2009 on the other hand landscapes in southern regions include grasslands barren land ice and snow which could be jeopardized by advancing climate change and the interplay of the climatic and land use variables for example due to climate change ice masses displacement are leaving huge areas of barren lands and free space for plant colonization and therefore land use change moreno et al 2019 overall the aforementioned changes in forested landscapes and in snow and ice masses displacement need to be monitored through time as they critically impact seasonal water flows the temporal analysis of the two main climatic inputs of the swym shows that year 1998 presented the lowest precipitation in southern winter months fig 2 in fact 1998 is considered one of the driest years of the century in the study area and the strongest el niño year recorded associated with severe drought water scarcity and wild fires on that year daniels and veblen 2000 gonzález et al 2011 kane 1999 year 2013 is part of the recent mega drought experienced in chile garreaud et al 2017 although there was unusually high spring and autumn precipitation with a dry winter while year 2007 presented a normal distribution of precipitation although below average in winter months notably these climatic phenomena in 1998 and 2013 associated with below average precipitation and heatwaves coincided with better swym estimates in the central and southern regions however year 2007 and 2013 present similarly low modeled values when contrasted to year 1998 which showed better swym estimations year 1998 presented high potential evapotranspiration values in the northern and central regions in spring and summer months fig 2b while this trend did not appear in southern regions these regional and seasonal differences can be related to reigning atmospheric circulation conditions in southern chile which are different to the ones in the central and northern regions and to the location of most of the basins within these regions on the eastern rain shadow side of the andes mountain garreaud et al 2013 garreaud 2009 5 3 overcoming swym limitations as with any model there are errors associated with swym predictions which include structural errors derived from the assumptions upon which the model works e g flow routing and curve number methods the suitability of selected parameters and errors in the input data e g climatic forcing variables regarding model structure and parameterization we are aware that the use of the same model parameters in different basins is not optimal and would require individual sensitivity analysis parameters α and β are not readily available for any given watershed making them difficult to set therefore further research in both model parameter sensitivity and direct comparison of modeled against observed values is needed e g hamel et al 2020 hamel and guswa 2015 regarding the quality of climatic input data in this study we used the product developed within the chilean water balance vargas et al 2017 which represents the most updated gridded dataset for the country and has been increasingly used and evaluated in hydrological applications however precipitation estimates remain as the main source of uncertainty in hydrological models hrachowitz et al 2013 for instance the forcing variables used in the model precipitation and evapotranspiration imply two problems the lack of representation of meteorological stations above 1000 m a s l even though chile is high elevation a mountainous country and low density of meteorological stations in the southern part of the study area which makes climatic estimations more uncertain alvarez garreton et al 2018 there is an increasing body of research highlighting the importance of including precipitation inputs in rainfall runoff models mcglynn et al 2012 zhou et al 2012 and in particular for the invest model boithias et al 2014 we argue that usage and handling of swym could improve if developers consider the following suggestions first to enable the addition of locally significant variables in the default input interface which could increase model performance and reliability for policy makers and local stakeholders guswa et al 2014 for example incorporating snow precipitation and ice or snowmelt as a default element of the swym has been recommended by scordo et al 2018 and hamel et al 2020 and could extend the application of swym to many mountainous and high latitude areas allowing for more accurate model estimates we are aware that including more parameters to the model e g snowmelt increases model complexity but better swym estimations would outweigh this constrain second we suggest providing bf as an output at the monthly scale which would make evaluations more straightforward since model users could compare the same elements of the water cycle in different seasons in this case streamflow qf bf this would also extend the applicability of the model to specific seasons periods which are important for their practical implications for managers and decision makers interested in particular periods of the year for instance calculating water availability in the dry season or predicting flood events in the rainy season 5 4 implications for model users and es decision making the swym was developed for applications in data scarce environments where demand for decision support tools is increasing hamel et al 2020 therefore the application of the model is recommended in chile and other data scarce countries to understand local effects of rapid land use and climate changes on water es which is often required in watershed management programs hamel et al 2020 however local decision makers should be aware of the limitations of the model and how to overcome them for instance large scale studies such as this work can show where it is more recommended to apply the swym i e where the model performs better leading to basin specific studies that could be more appropriate from a management perspective hamel et al 2020 interpretation and translation of the hydrological concepts qf and bf i e swym outputs into es vocabulary is straightforward and can be done using water es related literature e g gaglio et al 2019 for example users can interpret qf as water regulation and bf as water supply however interpretation depends on swym users and local context 6 conclusion in this study we exemplify the application of the invest swym and its capability to estimate water es in a large and diverse area in southern chile across several time periods learning about the estimative power of the swym is an important task for validating and supporting model usage among managers and policy makers in a data scarce region our analyses hint that the model performs better at the annual scale rather than the monthly scale and that the model has high potential for multiscale water es assessments furthermore the swym seems to be more accurate in drier years and in basins with yearly streamflow values below 1000 mm year but paradoxically in rainier and ice free regions a critical future research avenue is the application and evaluation of the model in more inaccessible regions such as mountainous and ice covered areas as well as in other countries in latin america or with limited data availability it is our hope that this work contributes to the water es research with direct takeaways for decision makers supporting sustainably management of water es in the long term credit authorship contribution statement f benra conceptualization data curation formal analysis methodology investigation visualization writing original draft a de frutos data curation methodology visualization formal analysis writing review editing m gaglio methodology conceptualization formal analysis writing review editing c álvarez garretón conceptualization writing review editing m felipe lucia writing review editing a bonn writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements f b was funded by the national agency for research and development anid through scholarship program becas chile doctorado acuerdo bilateral daad convocatoria 2017 number 62170002 f b m f l and a b gratefully acknowledge the support of idiv funded by the german research foundation dfg fzt 118 202548816 c a g is supported by the center for climate and resilience research cr2 anid fondap 15110009 and the joint research project anid nsfc190018 appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 multimedia component 3 multimedia component 3 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104982 appendix a table a 1 correlation plot of selected 20 variables table a 1 appendix b fig b 1 monthly mean r2 values for basins in the study area yellow represents catchments with na values for the respective year fig b 1 appendix c fig c1 pca showing performance of the model against environmental attributes fig c1 table c1 eigenvalues and eigenvectors from the pca analysis table c1 eigenvalues pc eigenvalues variation cum variation 1 0 33 52 9 52 9 2 0 141 22 5 75 5 3 5 95e 2 9 5 85 4 3 48e 2 5 6 90 6 5 2 05e 2 3 3 93 9 eigenvectors variable pc1 pc2 pc3 pc4 pc5 area 0 974 0 173 0 092 0 017 0 097 elev mean 0 175 0 81 0 188 0 192 0 07 slope mean 0 024 0 417 0 091 0 082 0 14 crop 0 009 0 031 0 038 0 045 0 059 nf 0 094 0 148 0 609 0 401 0 584 fp 0 032 0 05 0 097 0 162 0 006 grass 0 004 0 129 0 028 0 109 0 113 shrub 0 012 0 0 09 0 12 0 095 wet 0 003 0 011 0 014 0 016 0 032 imp 0 0 0 0 0 001 barren 0 028 0 118 0 15 0 146 0 088 snow frac 0 001 0 006 0 008 0 047 0 031 glacier 0 001 0 007 0 008 0 058 0 038 prec mean 0 07 0 236 0 366 0 351 0 683 pet mean 0 015 0 004 0 033 0 316 0 135 aridity 0 033 0 127 0 195 0 051 0 302 snowfall 0 0 0 0 0 high prec freq 0 053 0 091 0 601 0 692 0 105 p mean spread 0 003 0 053 0 024 0 091 0 008 interv degree 0 002 0 012 0 008 0 002 0 047 
25873,distinct calibration for wet and dry periods of the simulation period has resulted in fixed discretization of the simulation periods throughout the year with a repetitive pattern for all the simulation years ignoring the variability of rainfall and soil moisture conditions along time this may induce anomalies in the water balance of the basin this study focused on developing a discretization methodology using clustering methods that help eliminate the existing limitations subsequently the clusters are calibrated independently as well as simultaneous with multiple objectives the procedure is illustrated through two models viz swat and a grid based model set up for the us watersheds cedar creek indiana and riesel y2 texas respectively the proposed approach resulted in improved stream flow simulations with higher nse 0 83 in multi objective 0 68 in traditional calibration in cedar creek the simulation of water balance components was found to be more effective in both the basins graphical abstract image 1 keywords discrete parameterization soil moisture clustering multi objective optimization streamflow water balance 1 introduction hydrologic simulation models are commonly used by water resource managers to explore the complex rainfall runoff relationship in a watershed these models can be either process driven or data driven the process driven models are mostly considered superior to data driven ones as they can better capture the physics of the hydrological processes within the watershed bárdossy 2007 clark et al 2017 lan et al 2018 the interaction between the water balance components vary spatially and temporally in a watershed and essentially a process driven hydrologic simulation model should be capable of reflecting the same the soil land use and topography exhibits spatial heterogeneity while the climatic forcing have a temporal behavior the distributed hydrologic simulation models are believed to describe the spatial variability of the dominant hydrological processes to a great extent refsgaard 1997 rosso 1994 through unique computational units which are generated by disaggregating the watershed characteristics in space the effectiveness of simulation depends on the estimated value of the parameters which is generally achieved through appropriate calibration of the model during calibration we identify the value of the model parameter which helps closely match the simulated and actual response of the catchment of interest the general practice is to assume static values of the parameters throughout the simulation period despite any change in the climatic and land use conditions of the watershed across the simulation period therefore most of the hydrological models do not account for the time varying nature of the hydrological responses the reliability of simulations based on static parameter set has been questioned by many researchers freer et al 2003 guse et al 2014 muleta 2012 paik et al 2005 wu and johnston 2007 among many others over the last two decades many attempts have been made to accurately model the temporal variations in the hydrological processes dis continuous calibration of models for specific independent time periods hereafter termed as discrete calibration emerged as a feasible solution lévesque et al 2008 muleta 2012 most of the studies partitioned the simulation period into discrete wet and dry periods on the basis of watershed wetness fowler et al 2016 gao et al 2018 although the model was simulated for the whole time frame of the study the parameter estimation was performed only for the selected discrete time period this discretized periods were assumed to remain constant for all the simulated years as the model was calibrated for a shorter period with a unique climate setting the performance of the model improved especially during dry periods with low flows fowler et al 2016 lévesque et al 2008 muleta 2012 various clustering techniques were also analyzed by researchers for discretization of simulation period fuzzy c means fcm and k means clustering were employed for partitioning the time period and subsequently each cluster was calibrated separately choi and beven 2007 de vos et al 2010 choi and beven 2007 carried out a multi period sampling of the hydrologic response of the watershed using a 30 day moving window approach with a ten day overlap for allowing smooth transition of the windows these samples were further clustered into fifteen groups using the fcm clustering algorithm in an unsupervised manner de vos et al 2010 used precipitation its 10 day moving average and simulated soil moisture series for k means clustering twelve clusters were chosen for the analysis however the number of parameters to be calibrated increased as the number of clusters were more in these studies zhang et al 2011 achieved improved performance for swat model by integrating the principal component analysis and fcm clustering for dividing the hydro climatic periods into five clusters using six drought indices a two level fuzzy clustering framework using climate and land surface indices ten indices on a half monthly time scale was developed by lan et al 2018 and demonstrated on topmodel they observed that the low and medium flows were better simulated by topmodel without compromising the high flows all the above studies indicated a strong temporal variability of the hydrological processes a major issue associated with the discrete calibration is that it results in dis continuous simulations few studies attempted to recombine the discretely calibrated series into a single one deng et al 2018 gao et al 2018 zhang et al 2015 but the effectiveness of the process representation at the transition periods where two discrete series join is an issue and is little explored in most of the studies the same annual discretization pattern is applied across all the years of simulation which is also a concern as it ignores inter annual process dynamics this procedure invariably assumes that the dynamic nature of the watershed response remain the same in each year which may not be true this concern becomes more prominent in cases where there is a short dry spell without rainfall within a wet season or vice versa and according to the existing methods this spell also gets classified into a wet spell where the runoff dynamics may be actually different the foregoing discussions illustrate that the temporal hydrological process dynamics is to be effectively parametrized during the model simulations and the currently adopted procedures have limitations to address this issue accordingly this research is formulated to propose an improved procedure that addresses the current limitations the specific objectives of the study are multifold i to devise an approach for conglomerating the periods of similar dynamics of hydrologic processes in discrete calibration ii to examine the process representation on transition days between the discrete groups and iii to suggest a procedure to ensure smooth transition of process dynamics between the groups the proposed methodology is demonstrated using soil and water assessment tool swat arnold et al 1998 arnold and fohrer 2005 and a grid based hydrological model developed by vema et al 2017 on two different us watersheds 2 description of models study watersheds and tools 2 1 watershed models used in the study 2 1 1 soil and water assessment tool swat the swat model is a continuous time semi distributed gis based hydrological model operating on a daily time step it simulates the hydrological chemical and microbial processes of the watershed heathman et al 2008 song and liu 2010 among many others the major hydrological processes modeled by swat includes surface runoff snow melt snow pack potential evapotranspiration infiltration lateral sub surface flow and ground water flow all the hydrological processes are simulated at the hru level aggregated at the sub basin outlet and subsequently routed to the watershed outlet for complete documentation the reader is referred to neitsch et al 2011 2 1 2 grid based model the grid based model works on the principle of water balance within each grid i e all the major hydrological processes like surface runoff evapotranspiration ground water flow infiltration and lateral flow are simulated at each grid the conceptual design of the model is similar to that of swat and swat grid model rathjens et al 2015 the model uses raster datasets to obtain data pertaining to land use soil topography flow direction and slope gradient more details of the model can be found in vema et al 2017 2 2 study watersheds 2 2 1 cedar creek watershed indiana usa the cedar creek watershed usgs hydrologic unit code no 0410000306 and 0410000307 is located in north eastern indiana usa fig 1 it is the south west part of st joseph river basin covering an area of about 707 km2 this is a cropland dominated watershed with mainly corn and soybean digital elevation model dem from the national elevation dataset ned 30 m resolution developed by united states geological survey usgs was used to delineate the watershed nass 2010 crop data layer cdl 30 m and state soil geographic statsgo 250 m provided the land use as well as the soil data respectively in swat 57 sub basins and 1122 hrus constituted the watershed for this study weather data from two stations as well as records of daily discharge obtained from usgs station 04180000 were used for illustrating the methodology 2 2 2 riesel y2 watershed texas usa the riesel watershed texas was established during 1936 1938 as an experimental station by the united states department of agriculture soil conservation service usda scs with continuous measurement of hydrological as well as water quality data it consists of 13 actively monitored small watersheds harmel et al 2014 of which y2 53 4 ha is considered for this study fig 1 the land use is mainly cultivation corn wheat and sorghum in rotation followed by rangeland and pasture houston black clay soil vertisol dominates the watershed the region experiences long hot summers and short mild winters with an annual average precipitation of about 900 mm furl et al 2015 land use soil and terrain parameters are obtained from raster data sets the archydro toolbox in arcgis helped in deriving the hydrological features such as flow accumulation flow direction and slope gradient from the digital elevation model the climate data as well as stream flow were provided by the gauging stations of usda 2 3 clustering algorithm the conglomeration of time periods of similar process dynamics is achieved by using a clustering algorithm in this study the main objective of an efficient clustering technique is to minimize the intra cluster dissimilarity and maximize the inter cluster distinctions jain et al 1999 the effectiveness of the clustering is highly dependent on the quality of the input data as well as the number of clusters specified the clustering techniques have found wide spread application in hydrology for example to minimize the number of objective functions to be optimized to group the monitoring sites based on water levels water pressure etc and for channel head identification from contours hooshyar et al 2016 huzurbazar and humphrey 2008 khu et al 2008 rinderer et al 2019 earlier hong et al 2002 had applied gustafson kessel gk clustering for ground water level forecasting nayak and sudheer 2008 observed that gk clustering provided reasonable forecast of reservoir inflows in this study gustafson kessel clustering is performed to cluster the days with similar process dynamics across the simulation period gustafson kessel gk clustering the standard fuzzy c means algorithm was extended by gustafson and kessel using an adaptive distance norm for detecting clusters of different geometrical shapes within a data set the original c means assumed the clusters to be spherical but gk algorithm can identify ellipsoidal clusters the gustafson kessel algorithm links every cluster with the cluster center and its covariance it uses the mahalanobis distance rather than euclidean distance as in c means clustering its major advantage over the other clustering measures is that it can handle high dimensional data each cluster has its own norm inducing matrix m i which is the covariance of the clusters the distance d of a data point x k to the cluster center v i is obtained from the inner product norm d i k m 2 x k v i t m i x k v i 1 i c a n d 1 k n w h e r e c i s t h e n u m b e r o f c l u s t e r s a n d n i s t h e n u m b e r o f o b j e c t s i n t h e c l u s t e r here u v 1 v 2 v c is a vector of cluster prototypes that have to be determined the gk algorithm determines u based on the minimization of j x u v i 1 c k 1 n v i k m d i k m 2 where m 1 is a weighting exponent that determines the fuzziness of the clusters the algorithm terminates when a predetermined stopping criterion is satisfied detailed description of the algorithm is available in gustafson et al 1978 and babuska et al 2002 3 methodology 3 1 model setup the initial step was to setup the hydrological model using the available dem land use soil and climate data the swat model setup for cedar creek watershed was for a time period of 22 years from 1994 to 2015 the first four years 1994 1997 were considered as the warm up period the grid based model was setup for riesel y2 catchment from 1991 to 2015 with 1991 1994 as warm up period using the default parameters for the watershed both the models were run for the entire simulation period the daily rainfall as well as simulated soil moisture were recorded for the next stage of analysis 3 2 cluster analysis 3 2 1 inputs for clustering the variability in process dynamics along time is caused by the climatic setting and the antecedent condition of the basin therefore the clustering of time periods of similar process dynamics could be based on associated variables accordingly the primary input to the clustering algorithm was the daily precipitation r i which is highly random in nature another input was the change in the soil moisture over a day denoted as δ s m i the rationale behind selection of δ sm i for the cluster analysis was that it would have a random behavior as compared to the actual soil moisture from the simulated daily soil moisture the δ s m i was computed for the entire simulation period values of both these variables at different lags were considered to represent the antecedent condition of the watershed consequently a trial and error procedure was carried out to arrive at the number of days by which the precipitation and δ s m i should be lagged the primary aim of the trial was to arrive at a distinct cluster pattern with minimal number of clusters the details of the analysis are presented in section 4 1 five day antecedent values of the above variables were finally selected for the study thus the two current day values and its five day antecedent values i e r i r i 1 r i 2 r i 3 r i 4 r i 5 and δ s m i δ s m i 1 δ s m i 2 δ s m i 3 δ s m i 4 δ s m i 5 which constituted a 12 dimensional data were used for the gk clustering analysis 3 2 2 optimal number of clusters a supervised clustering was followed in this study the number of clusters were determined through a trial and error procedure in the preliminary analysis of determining the input variables for clustering it was observed that 12 dimensional data had resulted in 4 distinct clusters this was further verified by employing the cluster validity indices partition coefficient pc classification entropy ce partition index sc separation index s xie and beni s index xb dunn s index di and alternate dunn index adi are some of the commonly used validity measures the optimal number of clusters is arrived at by comparing the values of all the indices as none of these measures are reliable only by itself moreover it is important that the number of clusters are kept minimum to ensure that the principle of parsimony is not compromised the clustering procedure was tested for 2 to 20 clusters the xie and beni index separation index as well as the partition index are shown in fig 2 no significant change is observed in the values of the indices beyond 8 clusters fig 2 a close examination suggested that the data points for the entire simulation period is more or less equally distributed in 4 clusters and the values of partition index and separation index are found not to change significantly after 4 clusters fig 2 therefore the number of clusters was fixed to be 4 for further analysis in this study for cedar creek in a similar way the number of clusters identified for riesel y2 watershed was 3 note that the rainfall in this watershed had very little variability and had a large number of non rainy days 3 3 calibration of the models as discussed earlier the discretely clustered time periods were used for calibration of the models in two different approaches i independent calibration of the clusters single objective optimization that result in 4 different parameter sets in cedar creek and 3 parameter sets in riesel y2 and ii simultaneous optimization of the performance of models in each cluster through a multi objective optimization that result in one compromising parameter set for each basin in both the approaches maximization of nash sutcliffe efficiency nse nash and sutcliffe 1970 was considered for the objective function while any optimization procedure can be employed for calibration amalgam vrugt and robinson 2007 was used as the optimizer in this study owing to its capability in improved search and faster convergence the performance evaluation measures included rmse pbias and r2 other than nse the schematic representation of the proposed methodology is in fig 3 3 3 1 single objective calibration of clusters after partitioning the simulation period into different clusters the calibration of the clusters were performed for single objective calibration of clusters the model was run for the entire simulation period the flow values of only one cluster at a time was selected for the calibration in this procedure parameter set was identified for each cluster independently the objective function was to maximize the nse in the swat model 18 parameters that influence the flow simulation were selected for calibration table 1 and the time period of calibration was from 1998 to 2008 for cedar creek the grid based model had six parameters to be optimized table 2 the calibration period was 14 years from 1995 to 2008 for the grid model in riesel y2 watershed the optimal parameter sets identified for different clusters during calibration were validated for a different time period 2009 to 2015 for both the watersheds the discretely simulated flows for the different clusters were finally recombined for the model performance evaluation the results of the cluster calibration were compared with those obtained from conventional calibration approach i e by employing a static parameter set over the entire simulation period 3 3 2 multi objective calibration of clusters the calibration was paused as a multi objective optimization of performance of the model in different clusters in both the watersheds in this approach the objective functions were to maximize the nse of all the clusters independently but simultaneously to arrive at a best compromising parameter set 4 results and discussions 4 1 clustering pattern the trial and error procedure of identifying the sufficient number of variables in the input to clustering is illustrated in fig 4 the results of riesel y2 not presented herein for brevity the procedure was initially carried out with two variables namely the current day precipitation and the change in soil moisture for the day r i a n d δ s m i for subsequent trials the input variable dimensionality was increased by adding one day antecedent value of both the variables to the cluster input fig 4 a and b are the clustering patterns obtained from two r i a n d δ s m i and four dimensional r i r i 1 δ s m i a n d δ s m i 1 data sets respectively for cedar creek watershed though three clusters could be obtained it can be observed that only two clusters were prominent in both the cases this indicated the need for higher dimensional data in more effective discretization eight dimensional data resulted in three distinct clusters fig 4 c on increasing the dimensionality of data to 10 four distinct clusters were obtained fig 4 d finally a 12 dimensional input data which included the current day precipitation and change in soil moisture as well as its five day antecedent values suggested a discretization with equal prominence for all clusters this was selected for further analysis as higher dimensional data resulted in no significant change in the discretization pattern fig 5 presents the 12 dimensional clustering pattern obtained for both the watersheds in cedar creek fig 5 a a close examination of the days in different clusters and the rainfall on these days indicate that these are distinct clusters with different antecedent conditions further it is noted that none of the clusters have a fixed duration in both the watersheds it is also observed that there is no sharp partitioning between the clusters indicating wet and dry periods as is done in other discretization methods by sharply dividing the time period into required number of clusters the clustering pattern obtained for each year is unique and absolutely dependent on the prevailing soil moisture a similar procedure was adopted for the riesel y2 watershed and 3 distinct clusters were identified fig 5 b 4 2 performance evaluation of the clustered model 4 2 1 performance of the single objective optimization and calibration of clusters tables 3 and 4 present the evaluation results of single objective calibration of clusters for both the respective study watersheds the nse values of individual clusters improved during calibration and validation period when compared with the corresponding values during conventional calibration see table 5 also the pbias of simulation for all the clusters in both the watershed was well within the range specified by moriasi et al 2007 except for cluster 1 in riesel y2 watershed which was slightly above the limit note that these statistics were computed for daily flow values the scatterplot of simulated and observed stream flow for each cluster is given in fig 6 it is clear from fig 6 that the clusters in cedar creek spans similar range of flow values and the performance of the model is equally good in all the clusters the presence of similar range of flow values in different clusters indicate that the process dynamics in these clusters are different as the classification is based on antecedent condition of the watershed the clustering in riesel y2 watershed resulted in distinct clusters but with varying value range this could be plausibly due to the large variability of rainfall including non rainy days and the consequent discharge values in this watershed nonetheless the process dynamics is sufficiently different in each cluster 4 2 2 performance of the recombined and multi objective optimization approaches it is noted that the cluster based calibration recombined results in significant improvement in the streamflow simulation in cedar creek during calibration as well as validation on comparing with the performance of the conventionally calibrated model nse improved from 0 68 to 0 82 during validation table 5 this is obtained by constructing a streamflow series by stitching the best simulations from each of the independent cluster calibration this improvement underpins that the antecedent soil moisture conditions play a major role in runoff generation as the proposed cluster based calibration considers it while discretizing the simulation period into clusters the improvement was not significant in riesel y2 watershed though the magnitude of rainfall received by the riesel y2 experimental watershed and the subsequent stream flow was low and resulted in equally good simulations for conventional and cluster based calibrations nse of 0 85 and 0 83 for calibration and validation respectively in both the cases the performance of the simulation models during multi objective calibration of clusters was also encouraging the nse values remained similar to the cluster recombined series while the pbias was considerably reduced in both the watersheds in multi objective cluster based calibration indicating reasonable preservation of the hydrograph shape the simulated hydrographs of streamflow corresponding to conventional as well as single objective cluster calibration along with the observed flow are presented in fig 7a the results of only cedar creek are presented here for brevity it can be noticed that the cluster simulated flow closely follow the hydrologic response of the watershed the shape of the hydrograph the peak flows were better simulated than in the conventional approach though some events were over predicted the mean monthly runoff simulated during the validation period using multi objective cluster calibration approach along with the observed flows are shown fig 7b the simulated flow closely matched with the observed flow as is evident in fig 7b that the shape and peak characteristics of the hydrograph are well simulated fig 8 shows the scatterplots of the observed and simulated flows corresponding to all the three approaches in both the watersheds in cedar creek the spread of the low flow values is more in conventional approach fig 8 i a than in the other two cases indicating that the cluster based method is more effective and better in the flow simulations in the case of riesel y2 the high flows were under predicted by all the approaches but low and medium flows were predicted more reasonably fig 8 ii e and f these results also reinforces the hypothesis that the clusters that account similar process dynamics when calibrated separately help simulate the hydrograph better 4 3 optimal parameter ranges in a parameter optimization problem it is generally assumed that the last generation of parameters suggested by the optimizer is a reduced range which would be close to the global optima the optimal parameter range obtained for selected 5 parameters namely surlag esco alpha bf sol awc and cn f during single objective calibration of clusters are presented in fig 9 for brevity the results of only cedar creek is discussed here it is evident from the figure that the optimal parameter range does vary across the clusters this can be attributed to the variability in soil moisture across the clusters as a result of the varying rainfall forcing which in turn is related to the hydrological processes of the watershed prominent variability was observed for cluster 3 which majorly contained the low flows the parameter range obtained for the multi objective calibration is also presented in this case the parameter set is a compromising set that ensures satisfactory performance in all the clusters and therefore have a larger variability as compared to independent cluster based calibration the optimal parameter set corresponding to the single as well as multi objective optimization of cedar creek and riesel y2 watersheds are presented in table 6 and table 7 respectively wide variability in the ground water parameters across the clusters can be observed in cedar creek this can be due to the significant contribution of base flow to water yield in this watershed larose et al 2007 higher values of gwqmn can be seen in cluster 3 followed by cluster 1 which may correspond to dry periods the optimal value of gw delay also supports this observation the initial cn f values are also low in relatively dry period clusters 1 and 3 the optimal value of esco is similar across all the clusters in cedar creek the riesel y2 watershed receives majority of the rainfall during spring season harmel et al 2003 consequently the initial cn f values are high in cluster 1 which may correspond to wet period the esco values are also high in cluster 1 which is plausible in a wet period the streamflow in the riesel y2 watershed does not receive significant contribution from base flow as the watershed has a shallow ground water system volk et al 2007 therefore the parameters that connects the base flow are less sensitive and hence the variability across clusters is not significant 4 4 impact of cluster calibration on water balance components the soil moisture fluctuations play a major role in maintaining the hydrological balance of the watershed the rainfall and climatic conditions are the major inputs to the water balance in simulation models the parameters describing the physical processes control the water balance thus it is very important to assess the effect of the proposed calibration scheme on the water balance components fig 10 presents the effect of single and multi objective calibration schemes on the various water balance components in single objective calibration the value of water balance components were obtained for the recombined series the horizontal axis of the figure indicates the cluster transition for example 3 1 indicates a change from cluster 3 previous day to cluster 1 current day all possible cluster transitions 16 nos have been carefully analyzed the variability of evapotranspiration on the transition days is presented in fig 10 i it can be noticed here that the single objective optimization was equally good as the multi objective optimization in cedar creek the parameter esco that describes evapotranspiration exhibited less variation across the different clusters in cedar creek and had a similar value in multi objective optimization too as per the st joseph river watershed initiative 2005 cedar creek receives a good distribution of rainfall throughout the year with about 60 in the spring and summer seasons and 40 during the remaining period as mentioned earlier the basin also experience a good base flow contribution this climate forcing would plausibly result in meeting the evaporative demand from the upper layers of the soil and suggests higher values for esco as is seen in all the clusters without large variation table 6 including the multi objective calibration the variability across the cluster transitions is similar in both the approaches in the case of evapotranspiration fig 10 ii indicates the variability in ground water on all the cluster transition days in single objective optimization it can be noted that the change in ground water level over a time period of 24 hours was negligible except for few cluster transitions though minimal see fig 10 ii c the multi objective optimization fig 10 ii d which optimizes all the four clusters simultaneously resulted in no variability of ground water close to zero in most of the cluster transitions the transitions 2 4 3 4 and 4 2 are found to have lesser variability in this case fig 10 ii d as compared to single objective calibration fig 10 ii c similar observations were arrived at while considering the water yield component fig 10 iii the daily change in soil water abruptly varied from 8 to 8 cm on many cluster transition days when calibrated using single objective approach fig 10 iv g wide variability could be observed in transitions 1 2 1 4 2 3 3 4 and 4 1 however it can be noted in fig 10 iv h that the same was minimal when the multi objective optimization was carried out for example in transition 2 3 the optimum value ranged between 30 and 65 mm for single objective but in latter case it dropped down between 6 and 5 mm the results in general indicate that the multi objective optimization of clusters which correspond to a continuous simulation is able to better represent the watershed than single objective cluster calibration 5 summary and conclusions the existing discrete calibration scheme of partitioning the simulation period into wet and dry periods and separately calibrating the model results in misrepresentation of watershed hydrology mainly at the wet to dry change point and vice versa this study was aimed at developing a methodology to overcome the limitations of the discrete calibration a discontinuous partitioning scheme based on the prevailing rainfall and soil moisture conditions using gk clustering was envisaged to better represent the process dynamics in the watershed in contrast to dividing the hydrological year into fixed and continuous time frames as is done currently in the discrete calibration approach the identified clusters were subsequently calibrated using a single and multi objective optimization framework the proposed methodology was tested for cedar creek watershed indiana using swat model and for riesel y2 watershed texas using a grid based watershed model the following specific conclusions could be drawn from this study 1 the proposed method of subdivision of the simulation period into distinct clusters ensures representation of distinct hydrological process dynamics and therefore eliminates the limitation of the current assumption of annual repetition of clusters 2 the single objective calibration of clusters and the recombination of best simulations resulted in acceptable streamflow simulation cedar creek nse 0 82 for recombined series and 0 68 for conventional approach riesel y2 nse 0 83 for both approaches however the optimal parameter sets had variations across the clusters 3 good correspondence of observed and simulated streamflow was obtained nse 0 83 while calibrating the model using the multi objective cluster based calibration further this approach showed little variability of the physics of the hydrological processes on the transition days in cedar creek watershed the study suggested a better way of portioning the simulation periods and subsequent calibration which facilitated improved performance of the model the selection of single or multi objective schemes depend on the objective of the study for accurate streamflow predictions alone the single objective cluster optimization would be a viable option but a major limitation of employing single objective cluster calibration and recombining the result of best simulation is that the concern of abrupt change in parameter value still persists this issue could be overcome by multi objective approach that preserved the realistic nature of the water balance components on transition days the best performance of the simulation model cannot be achieved by the compromising parameter set though the non availability of soil moisture observations has limited us to use simulated data for clustering the time period although the results of this study are promising and encouraging developing procedures that enable gradual transition of the optimal parameter values from one cluster to another and incorporating it into the hydrological model structure itself would help improve the model predictions further declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104981 
25873,distinct calibration for wet and dry periods of the simulation period has resulted in fixed discretization of the simulation periods throughout the year with a repetitive pattern for all the simulation years ignoring the variability of rainfall and soil moisture conditions along time this may induce anomalies in the water balance of the basin this study focused on developing a discretization methodology using clustering methods that help eliminate the existing limitations subsequently the clusters are calibrated independently as well as simultaneous with multiple objectives the procedure is illustrated through two models viz swat and a grid based model set up for the us watersheds cedar creek indiana and riesel y2 texas respectively the proposed approach resulted in improved stream flow simulations with higher nse 0 83 in multi objective 0 68 in traditional calibration in cedar creek the simulation of water balance components was found to be more effective in both the basins graphical abstract image 1 keywords discrete parameterization soil moisture clustering multi objective optimization streamflow water balance 1 introduction hydrologic simulation models are commonly used by water resource managers to explore the complex rainfall runoff relationship in a watershed these models can be either process driven or data driven the process driven models are mostly considered superior to data driven ones as they can better capture the physics of the hydrological processes within the watershed bárdossy 2007 clark et al 2017 lan et al 2018 the interaction between the water balance components vary spatially and temporally in a watershed and essentially a process driven hydrologic simulation model should be capable of reflecting the same the soil land use and topography exhibits spatial heterogeneity while the climatic forcing have a temporal behavior the distributed hydrologic simulation models are believed to describe the spatial variability of the dominant hydrological processes to a great extent refsgaard 1997 rosso 1994 through unique computational units which are generated by disaggregating the watershed characteristics in space the effectiveness of simulation depends on the estimated value of the parameters which is generally achieved through appropriate calibration of the model during calibration we identify the value of the model parameter which helps closely match the simulated and actual response of the catchment of interest the general practice is to assume static values of the parameters throughout the simulation period despite any change in the climatic and land use conditions of the watershed across the simulation period therefore most of the hydrological models do not account for the time varying nature of the hydrological responses the reliability of simulations based on static parameter set has been questioned by many researchers freer et al 2003 guse et al 2014 muleta 2012 paik et al 2005 wu and johnston 2007 among many others over the last two decades many attempts have been made to accurately model the temporal variations in the hydrological processes dis continuous calibration of models for specific independent time periods hereafter termed as discrete calibration emerged as a feasible solution lévesque et al 2008 muleta 2012 most of the studies partitioned the simulation period into discrete wet and dry periods on the basis of watershed wetness fowler et al 2016 gao et al 2018 although the model was simulated for the whole time frame of the study the parameter estimation was performed only for the selected discrete time period this discretized periods were assumed to remain constant for all the simulated years as the model was calibrated for a shorter period with a unique climate setting the performance of the model improved especially during dry periods with low flows fowler et al 2016 lévesque et al 2008 muleta 2012 various clustering techniques were also analyzed by researchers for discretization of simulation period fuzzy c means fcm and k means clustering were employed for partitioning the time period and subsequently each cluster was calibrated separately choi and beven 2007 de vos et al 2010 choi and beven 2007 carried out a multi period sampling of the hydrologic response of the watershed using a 30 day moving window approach with a ten day overlap for allowing smooth transition of the windows these samples were further clustered into fifteen groups using the fcm clustering algorithm in an unsupervised manner de vos et al 2010 used precipitation its 10 day moving average and simulated soil moisture series for k means clustering twelve clusters were chosen for the analysis however the number of parameters to be calibrated increased as the number of clusters were more in these studies zhang et al 2011 achieved improved performance for swat model by integrating the principal component analysis and fcm clustering for dividing the hydro climatic periods into five clusters using six drought indices a two level fuzzy clustering framework using climate and land surface indices ten indices on a half monthly time scale was developed by lan et al 2018 and demonstrated on topmodel they observed that the low and medium flows were better simulated by topmodel without compromising the high flows all the above studies indicated a strong temporal variability of the hydrological processes a major issue associated with the discrete calibration is that it results in dis continuous simulations few studies attempted to recombine the discretely calibrated series into a single one deng et al 2018 gao et al 2018 zhang et al 2015 but the effectiveness of the process representation at the transition periods where two discrete series join is an issue and is little explored in most of the studies the same annual discretization pattern is applied across all the years of simulation which is also a concern as it ignores inter annual process dynamics this procedure invariably assumes that the dynamic nature of the watershed response remain the same in each year which may not be true this concern becomes more prominent in cases where there is a short dry spell without rainfall within a wet season or vice versa and according to the existing methods this spell also gets classified into a wet spell where the runoff dynamics may be actually different the foregoing discussions illustrate that the temporal hydrological process dynamics is to be effectively parametrized during the model simulations and the currently adopted procedures have limitations to address this issue accordingly this research is formulated to propose an improved procedure that addresses the current limitations the specific objectives of the study are multifold i to devise an approach for conglomerating the periods of similar dynamics of hydrologic processes in discrete calibration ii to examine the process representation on transition days between the discrete groups and iii to suggest a procedure to ensure smooth transition of process dynamics between the groups the proposed methodology is demonstrated using soil and water assessment tool swat arnold et al 1998 arnold and fohrer 2005 and a grid based hydrological model developed by vema et al 2017 on two different us watersheds 2 description of models study watersheds and tools 2 1 watershed models used in the study 2 1 1 soil and water assessment tool swat the swat model is a continuous time semi distributed gis based hydrological model operating on a daily time step it simulates the hydrological chemical and microbial processes of the watershed heathman et al 2008 song and liu 2010 among many others the major hydrological processes modeled by swat includes surface runoff snow melt snow pack potential evapotranspiration infiltration lateral sub surface flow and ground water flow all the hydrological processes are simulated at the hru level aggregated at the sub basin outlet and subsequently routed to the watershed outlet for complete documentation the reader is referred to neitsch et al 2011 2 1 2 grid based model the grid based model works on the principle of water balance within each grid i e all the major hydrological processes like surface runoff evapotranspiration ground water flow infiltration and lateral flow are simulated at each grid the conceptual design of the model is similar to that of swat and swat grid model rathjens et al 2015 the model uses raster datasets to obtain data pertaining to land use soil topography flow direction and slope gradient more details of the model can be found in vema et al 2017 2 2 study watersheds 2 2 1 cedar creek watershed indiana usa the cedar creek watershed usgs hydrologic unit code no 0410000306 and 0410000307 is located in north eastern indiana usa fig 1 it is the south west part of st joseph river basin covering an area of about 707 km2 this is a cropland dominated watershed with mainly corn and soybean digital elevation model dem from the national elevation dataset ned 30 m resolution developed by united states geological survey usgs was used to delineate the watershed nass 2010 crop data layer cdl 30 m and state soil geographic statsgo 250 m provided the land use as well as the soil data respectively in swat 57 sub basins and 1122 hrus constituted the watershed for this study weather data from two stations as well as records of daily discharge obtained from usgs station 04180000 were used for illustrating the methodology 2 2 2 riesel y2 watershed texas usa the riesel watershed texas was established during 1936 1938 as an experimental station by the united states department of agriculture soil conservation service usda scs with continuous measurement of hydrological as well as water quality data it consists of 13 actively monitored small watersheds harmel et al 2014 of which y2 53 4 ha is considered for this study fig 1 the land use is mainly cultivation corn wheat and sorghum in rotation followed by rangeland and pasture houston black clay soil vertisol dominates the watershed the region experiences long hot summers and short mild winters with an annual average precipitation of about 900 mm furl et al 2015 land use soil and terrain parameters are obtained from raster data sets the archydro toolbox in arcgis helped in deriving the hydrological features such as flow accumulation flow direction and slope gradient from the digital elevation model the climate data as well as stream flow were provided by the gauging stations of usda 2 3 clustering algorithm the conglomeration of time periods of similar process dynamics is achieved by using a clustering algorithm in this study the main objective of an efficient clustering technique is to minimize the intra cluster dissimilarity and maximize the inter cluster distinctions jain et al 1999 the effectiveness of the clustering is highly dependent on the quality of the input data as well as the number of clusters specified the clustering techniques have found wide spread application in hydrology for example to minimize the number of objective functions to be optimized to group the monitoring sites based on water levels water pressure etc and for channel head identification from contours hooshyar et al 2016 huzurbazar and humphrey 2008 khu et al 2008 rinderer et al 2019 earlier hong et al 2002 had applied gustafson kessel gk clustering for ground water level forecasting nayak and sudheer 2008 observed that gk clustering provided reasonable forecast of reservoir inflows in this study gustafson kessel clustering is performed to cluster the days with similar process dynamics across the simulation period gustafson kessel gk clustering the standard fuzzy c means algorithm was extended by gustafson and kessel using an adaptive distance norm for detecting clusters of different geometrical shapes within a data set the original c means assumed the clusters to be spherical but gk algorithm can identify ellipsoidal clusters the gustafson kessel algorithm links every cluster with the cluster center and its covariance it uses the mahalanobis distance rather than euclidean distance as in c means clustering its major advantage over the other clustering measures is that it can handle high dimensional data each cluster has its own norm inducing matrix m i which is the covariance of the clusters the distance d of a data point x k to the cluster center v i is obtained from the inner product norm d i k m 2 x k v i t m i x k v i 1 i c a n d 1 k n w h e r e c i s t h e n u m b e r o f c l u s t e r s a n d n i s t h e n u m b e r o f o b j e c t s i n t h e c l u s t e r here u v 1 v 2 v c is a vector of cluster prototypes that have to be determined the gk algorithm determines u based on the minimization of j x u v i 1 c k 1 n v i k m d i k m 2 where m 1 is a weighting exponent that determines the fuzziness of the clusters the algorithm terminates when a predetermined stopping criterion is satisfied detailed description of the algorithm is available in gustafson et al 1978 and babuska et al 2002 3 methodology 3 1 model setup the initial step was to setup the hydrological model using the available dem land use soil and climate data the swat model setup for cedar creek watershed was for a time period of 22 years from 1994 to 2015 the first four years 1994 1997 were considered as the warm up period the grid based model was setup for riesel y2 catchment from 1991 to 2015 with 1991 1994 as warm up period using the default parameters for the watershed both the models were run for the entire simulation period the daily rainfall as well as simulated soil moisture were recorded for the next stage of analysis 3 2 cluster analysis 3 2 1 inputs for clustering the variability in process dynamics along time is caused by the climatic setting and the antecedent condition of the basin therefore the clustering of time periods of similar process dynamics could be based on associated variables accordingly the primary input to the clustering algorithm was the daily precipitation r i which is highly random in nature another input was the change in the soil moisture over a day denoted as δ s m i the rationale behind selection of δ sm i for the cluster analysis was that it would have a random behavior as compared to the actual soil moisture from the simulated daily soil moisture the δ s m i was computed for the entire simulation period values of both these variables at different lags were considered to represent the antecedent condition of the watershed consequently a trial and error procedure was carried out to arrive at the number of days by which the precipitation and δ s m i should be lagged the primary aim of the trial was to arrive at a distinct cluster pattern with minimal number of clusters the details of the analysis are presented in section 4 1 five day antecedent values of the above variables were finally selected for the study thus the two current day values and its five day antecedent values i e r i r i 1 r i 2 r i 3 r i 4 r i 5 and δ s m i δ s m i 1 δ s m i 2 δ s m i 3 δ s m i 4 δ s m i 5 which constituted a 12 dimensional data were used for the gk clustering analysis 3 2 2 optimal number of clusters a supervised clustering was followed in this study the number of clusters were determined through a trial and error procedure in the preliminary analysis of determining the input variables for clustering it was observed that 12 dimensional data had resulted in 4 distinct clusters this was further verified by employing the cluster validity indices partition coefficient pc classification entropy ce partition index sc separation index s xie and beni s index xb dunn s index di and alternate dunn index adi are some of the commonly used validity measures the optimal number of clusters is arrived at by comparing the values of all the indices as none of these measures are reliable only by itself moreover it is important that the number of clusters are kept minimum to ensure that the principle of parsimony is not compromised the clustering procedure was tested for 2 to 20 clusters the xie and beni index separation index as well as the partition index are shown in fig 2 no significant change is observed in the values of the indices beyond 8 clusters fig 2 a close examination suggested that the data points for the entire simulation period is more or less equally distributed in 4 clusters and the values of partition index and separation index are found not to change significantly after 4 clusters fig 2 therefore the number of clusters was fixed to be 4 for further analysis in this study for cedar creek in a similar way the number of clusters identified for riesel y2 watershed was 3 note that the rainfall in this watershed had very little variability and had a large number of non rainy days 3 3 calibration of the models as discussed earlier the discretely clustered time periods were used for calibration of the models in two different approaches i independent calibration of the clusters single objective optimization that result in 4 different parameter sets in cedar creek and 3 parameter sets in riesel y2 and ii simultaneous optimization of the performance of models in each cluster through a multi objective optimization that result in one compromising parameter set for each basin in both the approaches maximization of nash sutcliffe efficiency nse nash and sutcliffe 1970 was considered for the objective function while any optimization procedure can be employed for calibration amalgam vrugt and robinson 2007 was used as the optimizer in this study owing to its capability in improved search and faster convergence the performance evaluation measures included rmse pbias and r2 other than nse the schematic representation of the proposed methodology is in fig 3 3 3 1 single objective calibration of clusters after partitioning the simulation period into different clusters the calibration of the clusters were performed for single objective calibration of clusters the model was run for the entire simulation period the flow values of only one cluster at a time was selected for the calibration in this procedure parameter set was identified for each cluster independently the objective function was to maximize the nse in the swat model 18 parameters that influence the flow simulation were selected for calibration table 1 and the time period of calibration was from 1998 to 2008 for cedar creek the grid based model had six parameters to be optimized table 2 the calibration period was 14 years from 1995 to 2008 for the grid model in riesel y2 watershed the optimal parameter sets identified for different clusters during calibration were validated for a different time period 2009 to 2015 for both the watersheds the discretely simulated flows for the different clusters were finally recombined for the model performance evaluation the results of the cluster calibration were compared with those obtained from conventional calibration approach i e by employing a static parameter set over the entire simulation period 3 3 2 multi objective calibration of clusters the calibration was paused as a multi objective optimization of performance of the model in different clusters in both the watersheds in this approach the objective functions were to maximize the nse of all the clusters independently but simultaneously to arrive at a best compromising parameter set 4 results and discussions 4 1 clustering pattern the trial and error procedure of identifying the sufficient number of variables in the input to clustering is illustrated in fig 4 the results of riesel y2 not presented herein for brevity the procedure was initially carried out with two variables namely the current day precipitation and the change in soil moisture for the day r i a n d δ s m i for subsequent trials the input variable dimensionality was increased by adding one day antecedent value of both the variables to the cluster input fig 4 a and b are the clustering patterns obtained from two r i a n d δ s m i and four dimensional r i r i 1 δ s m i a n d δ s m i 1 data sets respectively for cedar creek watershed though three clusters could be obtained it can be observed that only two clusters were prominent in both the cases this indicated the need for higher dimensional data in more effective discretization eight dimensional data resulted in three distinct clusters fig 4 c on increasing the dimensionality of data to 10 four distinct clusters were obtained fig 4 d finally a 12 dimensional input data which included the current day precipitation and change in soil moisture as well as its five day antecedent values suggested a discretization with equal prominence for all clusters this was selected for further analysis as higher dimensional data resulted in no significant change in the discretization pattern fig 5 presents the 12 dimensional clustering pattern obtained for both the watersheds in cedar creek fig 5 a a close examination of the days in different clusters and the rainfall on these days indicate that these are distinct clusters with different antecedent conditions further it is noted that none of the clusters have a fixed duration in both the watersheds it is also observed that there is no sharp partitioning between the clusters indicating wet and dry periods as is done in other discretization methods by sharply dividing the time period into required number of clusters the clustering pattern obtained for each year is unique and absolutely dependent on the prevailing soil moisture a similar procedure was adopted for the riesel y2 watershed and 3 distinct clusters were identified fig 5 b 4 2 performance evaluation of the clustered model 4 2 1 performance of the single objective optimization and calibration of clusters tables 3 and 4 present the evaluation results of single objective calibration of clusters for both the respective study watersheds the nse values of individual clusters improved during calibration and validation period when compared with the corresponding values during conventional calibration see table 5 also the pbias of simulation for all the clusters in both the watershed was well within the range specified by moriasi et al 2007 except for cluster 1 in riesel y2 watershed which was slightly above the limit note that these statistics were computed for daily flow values the scatterplot of simulated and observed stream flow for each cluster is given in fig 6 it is clear from fig 6 that the clusters in cedar creek spans similar range of flow values and the performance of the model is equally good in all the clusters the presence of similar range of flow values in different clusters indicate that the process dynamics in these clusters are different as the classification is based on antecedent condition of the watershed the clustering in riesel y2 watershed resulted in distinct clusters but with varying value range this could be plausibly due to the large variability of rainfall including non rainy days and the consequent discharge values in this watershed nonetheless the process dynamics is sufficiently different in each cluster 4 2 2 performance of the recombined and multi objective optimization approaches it is noted that the cluster based calibration recombined results in significant improvement in the streamflow simulation in cedar creek during calibration as well as validation on comparing with the performance of the conventionally calibrated model nse improved from 0 68 to 0 82 during validation table 5 this is obtained by constructing a streamflow series by stitching the best simulations from each of the independent cluster calibration this improvement underpins that the antecedent soil moisture conditions play a major role in runoff generation as the proposed cluster based calibration considers it while discretizing the simulation period into clusters the improvement was not significant in riesel y2 watershed though the magnitude of rainfall received by the riesel y2 experimental watershed and the subsequent stream flow was low and resulted in equally good simulations for conventional and cluster based calibrations nse of 0 85 and 0 83 for calibration and validation respectively in both the cases the performance of the simulation models during multi objective calibration of clusters was also encouraging the nse values remained similar to the cluster recombined series while the pbias was considerably reduced in both the watersheds in multi objective cluster based calibration indicating reasonable preservation of the hydrograph shape the simulated hydrographs of streamflow corresponding to conventional as well as single objective cluster calibration along with the observed flow are presented in fig 7a the results of only cedar creek are presented here for brevity it can be noticed that the cluster simulated flow closely follow the hydrologic response of the watershed the shape of the hydrograph the peak flows were better simulated than in the conventional approach though some events were over predicted the mean monthly runoff simulated during the validation period using multi objective cluster calibration approach along with the observed flows are shown fig 7b the simulated flow closely matched with the observed flow as is evident in fig 7b that the shape and peak characteristics of the hydrograph are well simulated fig 8 shows the scatterplots of the observed and simulated flows corresponding to all the three approaches in both the watersheds in cedar creek the spread of the low flow values is more in conventional approach fig 8 i a than in the other two cases indicating that the cluster based method is more effective and better in the flow simulations in the case of riesel y2 the high flows were under predicted by all the approaches but low and medium flows were predicted more reasonably fig 8 ii e and f these results also reinforces the hypothesis that the clusters that account similar process dynamics when calibrated separately help simulate the hydrograph better 4 3 optimal parameter ranges in a parameter optimization problem it is generally assumed that the last generation of parameters suggested by the optimizer is a reduced range which would be close to the global optima the optimal parameter range obtained for selected 5 parameters namely surlag esco alpha bf sol awc and cn f during single objective calibration of clusters are presented in fig 9 for brevity the results of only cedar creek is discussed here it is evident from the figure that the optimal parameter range does vary across the clusters this can be attributed to the variability in soil moisture across the clusters as a result of the varying rainfall forcing which in turn is related to the hydrological processes of the watershed prominent variability was observed for cluster 3 which majorly contained the low flows the parameter range obtained for the multi objective calibration is also presented in this case the parameter set is a compromising set that ensures satisfactory performance in all the clusters and therefore have a larger variability as compared to independent cluster based calibration the optimal parameter set corresponding to the single as well as multi objective optimization of cedar creek and riesel y2 watersheds are presented in table 6 and table 7 respectively wide variability in the ground water parameters across the clusters can be observed in cedar creek this can be due to the significant contribution of base flow to water yield in this watershed larose et al 2007 higher values of gwqmn can be seen in cluster 3 followed by cluster 1 which may correspond to dry periods the optimal value of gw delay also supports this observation the initial cn f values are also low in relatively dry period clusters 1 and 3 the optimal value of esco is similar across all the clusters in cedar creek the riesel y2 watershed receives majority of the rainfall during spring season harmel et al 2003 consequently the initial cn f values are high in cluster 1 which may correspond to wet period the esco values are also high in cluster 1 which is plausible in a wet period the streamflow in the riesel y2 watershed does not receive significant contribution from base flow as the watershed has a shallow ground water system volk et al 2007 therefore the parameters that connects the base flow are less sensitive and hence the variability across clusters is not significant 4 4 impact of cluster calibration on water balance components the soil moisture fluctuations play a major role in maintaining the hydrological balance of the watershed the rainfall and climatic conditions are the major inputs to the water balance in simulation models the parameters describing the physical processes control the water balance thus it is very important to assess the effect of the proposed calibration scheme on the water balance components fig 10 presents the effect of single and multi objective calibration schemes on the various water balance components in single objective calibration the value of water balance components were obtained for the recombined series the horizontal axis of the figure indicates the cluster transition for example 3 1 indicates a change from cluster 3 previous day to cluster 1 current day all possible cluster transitions 16 nos have been carefully analyzed the variability of evapotranspiration on the transition days is presented in fig 10 i it can be noticed here that the single objective optimization was equally good as the multi objective optimization in cedar creek the parameter esco that describes evapotranspiration exhibited less variation across the different clusters in cedar creek and had a similar value in multi objective optimization too as per the st joseph river watershed initiative 2005 cedar creek receives a good distribution of rainfall throughout the year with about 60 in the spring and summer seasons and 40 during the remaining period as mentioned earlier the basin also experience a good base flow contribution this climate forcing would plausibly result in meeting the evaporative demand from the upper layers of the soil and suggests higher values for esco as is seen in all the clusters without large variation table 6 including the multi objective calibration the variability across the cluster transitions is similar in both the approaches in the case of evapotranspiration fig 10 ii indicates the variability in ground water on all the cluster transition days in single objective optimization it can be noted that the change in ground water level over a time period of 24 hours was negligible except for few cluster transitions though minimal see fig 10 ii c the multi objective optimization fig 10 ii d which optimizes all the four clusters simultaneously resulted in no variability of ground water close to zero in most of the cluster transitions the transitions 2 4 3 4 and 4 2 are found to have lesser variability in this case fig 10 ii d as compared to single objective calibration fig 10 ii c similar observations were arrived at while considering the water yield component fig 10 iii the daily change in soil water abruptly varied from 8 to 8 cm on many cluster transition days when calibrated using single objective approach fig 10 iv g wide variability could be observed in transitions 1 2 1 4 2 3 3 4 and 4 1 however it can be noted in fig 10 iv h that the same was minimal when the multi objective optimization was carried out for example in transition 2 3 the optimum value ranged between 30 and 65 mm for single objective but in latter case it dropped down between 6 and 5 mm the results in general indicate that the multi objective optimization of clusters which correspond to a continuous simulation is able to better represent the watershed than single objective cluster calibration 5 summary and conclusions the existing discrete calibration scheme of partitioning the simulation period into wet and dry periods and separately calibrating the model results in misrepresentation of watershed hydrology mainly at the wet to dry change point and vice versa this study was aimed at developing a methodology to overcome the limitations of the discrete calibration a discontinuous partitioning scheme based on the prevailing rainfall and soil moisture conditions using gk clustering was envisaged to better represent the process dynamics in the watershed in contrast to dividing the hydrological year into fixed and continuous time frames as is done currently in the discrete calibration approach the identified clusters were subsequently calibrated using a single and multi objective optimization framework the proposed methodology was tested for cedar creek watershed indiana using swat model and for riesel y2 watershed texas using a grid based watershed model the following specific conclusions could be drawn from this study 1 the proposed method of subdivision of the simulation period into distinct clusters ensures representation of distinct hydrological process dynamics and therefore eliminates the limitation of the current assumption of annual repetition of clusters 2 the single objective calibration of clusters and the recombination of best simulations resulted in acceptable streamflow simulation cedar creek nse 0 82 for recombined series and 0 68 for conventional approach riesel y2 nse 0 83 for both approaches however the optimal parameter sets had variations across the clusters 3 good correspondence of observed and simulated streamflow was obtained nse 0 83 while calibrating the model using the multi objective cluster based calibration further this approach showed little variability of the physics of the hydrological processes on the transition days in cedar creek watershed the study suggested a better way of portioning the simulation periods and subsequent calibration which facilitated improved performance of the model the selection of single or multi objective schemes depend on the objective of the study for accurate streamflow predictions alone the single objective cluster optimization would be a viable option but a major limitation of employing single objective cluster calibration and recombining the result of best simulation is that the concern of abrupt change in parameter value still persists this issue could be overcome by multi objective approach that preserved the realistic nature of the water balance components on transition days the best performance of the simulation model cannot be achieved by the compromising parameter set though the non availability of soil moisture observations has limited us to use simulated data for clustering the time period although the results of this study are promising and encouraging developing procedures that enable gradual transition of the optimal parameter values from one cluster to another and incorporating it into the hydrological model structure itself would help improve the model predictions further declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104981 
25874,agent based models abms are widely used to analyze coupled natural and human systems descriptive models require careful calibration with observed data however abms are often not calibrated in a formal sense here we examine the impact of data record size and aggregation on the calibration of an abm for housing abandonment in the presence of flood risk using a perfect model experiment we examine i model calibration and ii the ability to distinguish a model with inter agent interactions from one without we show how limited data sets may not adequately constrain a model with just four parameters and relatively minimal interactions we also illustrate how limited data can be insufficient to identify the correct model structure as a result many abm based inferences and projections rely strongly on prior distributions this emphasizes the need for utilizing independent lines of evidence to select sound and informative priors keywords agent based modeling statistical calibration model selection 1 introduction agent based models abms can be a useful tool for modeling and understanding how macro scale aggregate features of complex systems emerge from micro scale individual decisions interactions and feedbacks generative social science epstein 1999 as a result abms are used in many application areas including land use change parker et al 2003 evans and kelley 2004 brown et al 2005 evans and kelley 2008 kelley and evans 2011 evans et al 2013 brown et al 2017 dou et al 2020 li et al 2020 ecology black and mckane 2012 grimm 1999 van der vaart et al 2016 and climate change adaptation balbi et al 2013 barthel et al 2008 gerst et al 2013 schneider et al 2000 ziervogel et al 2005 lamperti et al 2020 one key application is modeling flood risk and impacts due to the presence of observed socio hydrological feedbacks aerts et al 2018 di baldassarre et al 2013 flood risk modeling using abms is an extremely active area of research dubbelboer et al 2017 haer et al 2016 jenkins et al 2017 tonn and guikema 2017 magliocca and walls 2018 de koning and filatova 2019 chandra putra and andrews 2020 o shea et al 2020 koc and işık 2020 models can be designed to address different questions about the modeled system including prediction explanation and demonstration epstein 2008 bankes bankes 1993 distinguishes consolidative models which are used to simulate the dynamics of a well understood system from exploratory models which are used to test hypotheses about model structures or system dynamics a similar but not identical classification is proposed by marks marks 2011 who classifies models as demonstrative or descriptive demonstrative abms are used to illustrate that patterns of interest can be produced through local level rules and interactions descriptive abms are intended to reproduce observed phenomena for the purpose of explanation prediction or both the descriptive model category includes both simpler strategic models and more complex tactical models holling and watt 1966 early abms such as the pioneering work on racial segregation schelling 1971 were primarily demonstrative janssen and ostrom 2006 marks 2011 over time there has been an increase in the fraction of descriptive models janssen and ostrom 2006 both demonstrative and descriptive models require tests to ensure that the model works as intended descriptive models also benefit from a comparison of model output against observations marks 2011 an example is pattern based modeling grimm et al 2005 in which one or more structural patterns in the data are compared to model output to see if the model is capable of simulating multi scale aspects of the data another model checking procedure are simulations over a historical period to demonstrate that the model reproduces historical data though this is not the same thing as demonstrating that the model is a reproduction of system dynamics oreskes et al 1994 as all models are approximations of real processes box 1976 the observation that models are only capable of approximating rather than reproducing real system dynamics box 1976 shows the importance of model calibration for descriptive modeling calibration is the process of selecting model structures and parameter values oreskes et al 1994 one common approach to abm calibration is to tune model parameters until model outputs are close to the empirical data kelley and evans 2011 schwarz and ernst 2009 van der vaart et al 2015 abm calibration can be complicated by the path dependence and feedbacks associated with many coupled natural human systems these path dependencies and nonlinear dynamics can cause observed outcomes to be very sensitive to small changes in any part of the system as a result observations of these systems are highly contingent brown et al 2005 and may reflect the influence of initial states or early shocks in a way which obscures the underlying dynamics as a result these procedures can lead to over fitting the model to the calibration data as data are merely one realization of an underlying data generating and observation process over fitting data which may have been less probable than other observations could result in biased inferences and projections the risk of over fitting may be particularly high when there are a large number of model parameters which have interactions resulting in compensating effects to account for the stochastic elements of a model another approach to calibration is to choose a model structure and parameter values which are most probable given the observations and prior information about system dynamics jaynes 2003 robert 2007 this approach which we adopt here is often called statistical calibration sansó and forest 2009 lee et al 2019 statistical calibration involves using statistical inference to obtain parameter values or select model structures another complication of abm development is the risk of over parameterization over parameterized models include variables and dynamics outside of what is supported by the evidence due to the additional degrees of freedom overly parameterized models are more likely to overfit observations and may generalize less well for the purposes of prediction while adding minimal theoretical benefit however whether descriptive abms are intended to be used for explanation or prediction these features suggest a need for quantification of model and parametric uncertainty as observed patterns may be dependent on external forcings which might be stochastic or initial conditions this discussion leads to a simple overarching question how does the amount of data required to statistically calibrate agent based models increase with model complexity increasing complexity of agent decision rules in the sense of the number of parameters and including agent agent and agent environment interactions and feedbacks in the sense of emergence can reduce the ability to constrain model parameters or test hypotheses particularly when data may be relatively scarce we address this question using a bayesian approach to uncertainty quantification we focus on three specific questions first how do varying dataset sizes and structures affect the statistical calibration of an abm second can we assess the relative evidence for models with varying levels of complexity either in terms of high dimensional decision rules or the types of agent interactions with each other and the environment third how are calibration and hypothesis testing affected by the use of spatially aggregated data as opposed to observations of individual agents which may be all that are available due to data collecting limitations or considerations of anonymity in particular we use a perfect model experiment a perfect model experiment uses pseudo observations generated from a known data generating process including known model parameters see e g reed and kollat 2012 or olson et al 2013 we generate pseudo observations for a variety of spatial and temporal extents we then calibrate the model using these pseudo data with different seeds to approximate the more typical situation where the model and the true data generating process are dissimilar this gives us a best case scenario for how much information these observations could provide about the considered model s real observations would provide less information given observational uncertainty and missing aspects of the model compared to the real data generating process for a concrete example we focus on the particular problem of modeling housing abandonment under flood risk following tonn and guikema tonn and guikema 2017 housing abandonment poses potentially severe economic problems for settlements along rivers and coastlines fowler et al 2017 indeed recent work has shown that repetitive flooding can intensity outmigration with an associated increase in climate gentrification de koning and filatova 2019 residents who haven t experienced flooding themselves may abandon their homes if their neighbors do due to depreciating values or anticipation of future flooding an associated abm and a submodel with fewer interactions and feedbacks are illustrated by the influence diagrams in fig 1 for the following work we use relatively simple abms with limited interactions between agents and their environment this choice allows us to highlight some of the concepts and difficulties associated with the statistical calibration of even simple abms with relatively few parameters and feedbacks with an understanding that these complications grow as models increase in complexity 2 methods 2 1 models we analyze two abms represented by the influence diagram in fig 1 in both models agents decide to vacate their homes using a probabilistic decision process logistic regression as opposed to maximizing utility or using heuristics which are more common in abms in certain application areas such as land use groeneveld et al 2017 once a house is abandoned there is a chance that it is occupied by a new agent in a subsequent year in the first considered model no interactions the probability of housing abandonment is determined only by the frequency of experienced floods over the previous ten years this model is parameterized using three parameters the logistic regression intercept β 0 the logistic regression coefficient for flood frequency β 1 and the probability that vacant houses are filled by a new agent α denote by s t i the state of parcel i where s t i 1 if the parcel is occupied and 0 if the parcel is vacant the probability that this parcel switches from occupied to abandoned is p s t i 0 s t 1 i 1 logit 1 β 0 β 1 r t where r t is the frequency of flooding events for the previous ten years the probability that this parcel switches from abandoned to occupied is constant p s t i 1 s t 1 i 0 α in the second considered model spatial interactions we include an additional logistic regression covariate the fraction of neighboring plots which are vacant at the start of time t as a result this model has four parameters including the coefficient for this neighboring vacancy covariate these state transition equations give both models a markovian structure see supplementary information s2 2 of course these models could be further expanded for example by including housing market dynamics see fig 1 in this study we focus for clarity just on the two models as we are interested in understanding the process and results of statistical calibration for simple abms 2 2 data we generated pseudo observations for the perfect model experiment using the model with spatial interactions to see if we could successfully test for the spatial interaction effect the pseudo observations are generated using the spatial interactions model for an artificial riparian settlement and realizations of annual flood height maxima see supplemental section s1 the parcel return periods and river heights are shown in supplementary figure s1 parcel residency was initialized by assuming that each parcel had a 99 probability of having a resident at the start of the simulation the additional dynamic mechanism resulting from spatial interactions leads to increased probabilities of parcel abandonment for all return periods across realizations of the stochastic process even for parcels that are far from floods fig 2 as data may not be available in individualized forms we examine the power of data for calibration and hypothesis testing about model structures in both individual and aggregate forms in the individual case the data set contains observations of each observed parcel at each time in the aggregate case we observe the total number of abandoned parcels at each time as a result the individually resolved data consists of maps of occupancy state whether each parcel is occupied or unoccupied while the aggregated data is a time series of counts of unoccupied parcels 2 3 calibration we use a bayesian framework for model calibration based on bayes theorem bayes 1763 p θ y p y θ p θ where p θ y is the posterior density p y θ is the data likelihood and p θ is the prior we constructed the priors that were used in this study table 1 using a rough understanding of the model dynamics so that the resulting probabilities of abandonment seemed plausible they are intentionally not centered on the known data generating parameter values for both individual parcel and aggregate data we model the probability of each parcel being vacant and compute the appropriate likelihood treating each parcel s vacant status at time t as independent and identically distributed conditional on the state its vacancy status and in the spatial interactions model that of its neighbors in time t 1 this markovian representation is common for many abms izquierdo et al 2009 and we describe this process in supplementary section s2 2 in the individual data case we use a binomial likelihood to model the probability of each parcel being vacant at each time in the aggregate data case we use a poisson likelihood which is commonly used to model count numbers on the expected number of vacant parcels for more details on how these likelihood functions are specified see supplemental section s2 1 the models described above are fast enough to use markov chain monte carlo mcmc for the bayesian inversion mcmc is an extremely general method for sampling from a target probability distribution in this case the posterior distribution the mcmc method constructs a markov chain of samples which converge to the target distribution mcmc has previously been used for calibrating abms keith and spring 2013 there are many mcmc algorithms of varying complexity we describe the algorithm we use the metropolis hastings algorithm metropolis et al 1953 hastings 1970 in supplementary section s2 3 other algorithms such as dream vrugt 2016 or hamiltonian monte carlo neal et al 2011 are more sophisticated and powerful but the relatively simple metropolis hastings algorithm performs satisfactorily for these simple models which have few parameters and have a runtime of under half a second for all considered cases we use 150 000 metropolis hastings iterations after a preliminary adaptive run vihola 2012 of 30 000 iterations which is used to estimate the starting value of the production run as well as the covariance matrix for the proposal distribution the preliminary run is initialized at the maximum likelihood estimate 2 4 model selection we use bayes factors to analyze the model selection problem kass and raftery 1995 bayes factors compare the evidence for each model structure using a ratio of marginal likelihoods see supplementary section s3 1 intuitively the marginal likelihood of a model captures the total probability assigned to the data by the calibrated model across the entire posterior distribution the bayes factor then captures the extent to which one model better predicts the data much like other model comparison methods such as the akaike information criterion or aic akaike 1974 bayes factors penalize models which produce overly diffuse realizations e g due to the presence of additional model parameters which are ill constrained by calibration one important consideration when using bayes factors is the dependence of marginal likelihoods on the choice of prior robert 2007 from a bayesian perspective this is consistent with the idea that the bayes factor is a metric comparing two model structures as the selection of the prior is a key part of bayesian model specification here we use the same priors for corresponding parameters to reduce this effect while the bayes factor compares the ability of two models to reproduce the calibration data a modeler may wish to select a model based on the expected ability of the model to predict out of sample data gelman et al 2014 to this end we also use an alternative metric the watanabe aikaike information criterion or waic watanabe 2010 vehtari et al 2017 which is described in more detail in supplementary section s3 2 however in our case waic may not provide a good approximation to the expected out of sample predicted error as we do not calibrate our model repeatedly on shorter data subseries we hence only use this metric to compare with the results of the bayes factor analysis 3 results 3 1 calibration the structure of the data individual parcel versus spatially aggregated strongly influences the final shape of the posterior distribution both due to the number of data points and the different likelihood function specifications fig 3 shows the result of updating the prior distributions specified in table 1 with 50 years of pseudo observations of 100 parcels for certain key parameters such as the logistic regression coefficient for the local flooding frequency aggregated data the total number of abandoned parcels at each time leaves the posterior close to the prior fig 3b for individually resolved data the marginal posterior is sharpened much further fig 3a while it appears from fig 3a that the original decision rules are not fully recovered looking at the posterior density at the data generating value it is important to keep in mind the influence of stochasticity in the realized data running the same model with the same parameter values can yield model output with very different dynamics due to stochastic forcings particularly in the presence of high levels of path dependence and positive feedbacks see fig 4 between the strong influence of the stochastic elements the logistic regression in the model and the relative lack of sensitivity to parameter values close to the data generating value it is not necessarily surprising that the data generating value is assigned a relatively low density the full posterior parameter estimates feature a high degree of correlation between parameters as seen in the pairs plot supplementary figure s5 for example the two logistic regression coefficients for flood frequency and proportion of neighboring abandoned parcels have a correlation coefficient of 0 66 a lower sensitivity to experienced floods can be offset by an increased sensitivity to neighbor behavior another example is the high positive correlation between the probability of a vacant lot being re occupied and both the logistic regression intercept term and the coefficient for neighboring parcels r 0 73 in both cases similar interactions would be missed by a deterministic calibration combined with one at a time sensitivity analysis ten broeke et al 2016 we analyze the hindcasting ability of the posterior predictive distribution shown in fig 5 to explore how the model was constrained by the observations and how well the model simulates the observed dynamics the three parameter no interactions model is well constrained by smaller data sets however the poor fit of the posterior predictive distribution compared to the pseudo observations for increased amounts of data reveals the missing abandonment dynamic mechanism without the inclusion of spatial interactions the no interactions model calibration results in a higher sensitivity to experienced flooding to account for the data which results in biased estimates of the number of abandoned parcels in later years meanwhile the spatial interactions model which has one additional parameter and includes an interaction requires more data to constrain the model 25 observed parcels is insufficient with up to 50 years of data but once constrained fits the pseudo observations better than the no interactions model in general having a larger spatial domain numbers of agents facilitates calibration more than having a longer data record this pattern remains in our study when we calibrate the model with alternative pseudo observations see supplemental figures s7 s10 while fig 5 might appear to show that calibration with aggregate data results in a better fit to the observations we hypothesize that this is an artifact of two different components of the modeling process first the likelihood function used for the aggregate data calibration is different than the individual data calibration poisson vs binomial which will change the shape of the posterior distribution second in the aggregate case we calibrate the model directly against the aggregated counts shown in fig 5 while in the individual data case the expected state of each parcel was used these two differences make it difficult to compare the quality of the hindcast as they are structurally different calibration procedures we would expect that in the latter case there is greater uncertainty about the total count of abandoned parcels however in some of the alternate realizations shown in supplemental figures s7 s10 using individually resolved data can result in overconfidence while as seen in supplemental figure s6 using aggregated data resulted in more consistent parameter estimates these details are likely to be extremely sensitive to the particular model specification 3 2 model selection more complex abms can be thought of as being constructed by adding new interactions and feedbacks to simpler abms as illustrated in fig 1 this allows us to view this type of model selection as hypothesis testing for the presence of additional feedback mechanisms cottineau et al 2015 as well as potential over parameterization posterior model structural probabilities are calculated by combining prior knowledge and beliefs about the relative probability of the competing models with the bayes factor this prior information about the probability of various model structures can be guided by domain specific insights that are gleaned for example from other observations or other qualitative information forrester 1980 in this stylized experiment we make the prior assumption that the models with and without spatial interactions are equally probable for our perfect model experiment one would expect additional in terms of the number of observations and spatially explicit rather than aggregated data to improve the ability to distinguish between the data generating spatial interactions model and the simpler no interactions model which is seen in fig 6 we neglect the case with 25 observed parcels due to unreasonably high estimates likely due to the ill constrained spatial interactions model however the hindcasts in fig 5 shows the qualitatively better fit of the no interactions model for this data set particularly in the individual data scenario for individual parcel data with more than 25 observed parcels there is at least strong evidence for the spatial interactions model no matter how long the parcels were observed which confirms the qualitative assessment on the summary statistic of total abandoned parcels obtained by comparing the hindcasts in fig 5c and d on the other hand when aggregated data is used for calibration there is essentially no quantitative evidence for the spatial interactions model this is the case whether we compare the models using bayes factors or a predictive information criterion such as waic the one standard error range of the difference in waic between the spatial interactions and the no interactions model is between 2 and 2 which can be interpreted as no difference in support between the two models burnham and anderson 2004 however a qualitative assessment obtained by comparing fig 5a and b might lead a researcher to conclude that the spatial interactions model fits the observations better than the no interactions model this suggests that hindcasting can serve an important supporting role to quantitative model selection 4 discussion statistical calibration is an important component of the descriptive agent based modeling process due to the path dependence associated with complex data generating processes as illustrated in fig 4 using a statistical approach reduces the potential for over fitting the model to the data which is a risk with a deterministic approach to calibration either through hand tuning the parameters or through the use of an optimization routine as a result the calibration procedure can take into account that the observations may not have been the most likely outcomes given the understanding of the system dynamics including the specifications of the likelihood function and prior distribution that the model encodes which has implications for parameter inference and model selection and hence for future projections our use of a didactic perfect model experiment somewhat limits the direct generalization of our results to other experiments using real world data in contrast to our perfect model didactic example the real world data may be more noisy and will be generated through a process which is incompletely represented by any model box et al 1979 in this case statistical approaches to calibration are potentially more useful than in our experiment as we can account for systematic model discrepancies kennedy and o hagan 2001 through the construction of a likelihood which separates these discrepancy terms from white noise as this perfect model experiment provides a somewhat best case scenario for parameter inference and model selection the demonstration of how limited data sets are unable to meaningfully constrain model hindcasts is likely to generalize to other studies it is likely however that model selection as conducted in this study will be more complicated in the case where two imperfect technically wrong box et al 1979 models are being compared showing the importance of carefully synthesizing the available evidence qualitative and quantitative to provide justifications for a particular set of model features it is important to point out that different modeling aims would induce different calibration needs with implications for the appropriateness of specific methods some users of demonstrative models for example might want to conduct a model based exploratory analysis rather than making projections of future system outcomes for example one might explore how certain bottom up rules which are broadly consistent with observations or other evidence could produce certain dynamics or outcomes in this case manual calibration based on some observational or survey data for example could be sufficient as another example a modeling exercise might be partially or entirely motivated by qualitative data which demonstrates that behaviors or outcomes follow certain patterns in which case quantitative approaches to calibration are either inappropriate or should be modified to account for this additional information if these aims are clearly indicated the resulting data needs and calibration procedures can be reconciled with them while our chosen method of metropolis hastings mcmc has the ability to produce high fidelity approximations to the full joint probability distribution of the model parameters robert 2014 it may be computationally intractable for complex models featuring long runtimes or high dimensional parameter spaces in this case the relative simplicity of the models facilitated the use of mcmc an additional complication is the need to specify a statistical likelihood function which may be difficult for particular applications in general there is a trade off between computational speed and accuracy of the resulting parameter distributions some other approaches to statistical calibration of abms which are aimed at reducing computational requirements or likelihood specification include statistical emulation lamperti et al 2018 oyebamiji et al 2017 particle filtering kattwinkel and reichert 2017 and approximate bayesian computation fabretti 2018 sirén et al 2018 van der vaart et al 2015 van der vaart et al 2016 while these methods reduce the computational burden they come at a cost of potentially severe statistical approximations that can influence the parameter estimates frazier et al 2018 künsch 2013 robert et al 2011 singh et al 2018 difficulties constructing likelihood functions may also emerge when a pattern oriented approach towards model evaluation and selection is adopted as it may be difficult to link multiple patterns together using an appropriate likelihood function in these cases alternative approaches like approximate bayesian computation or abc sunnåker et al 2013 would be useful abc may be particularly appropriate for pattern oriented calibration and evaluation though care should be taken that the set of statistics used to capture patterns is sufficient as otherwise the approximation to the true posterior will be degraded an additional concern is the specification of prior distributions when less data is available the data will have less power to update the prior distributions as we noted in the introduction real data as opposed to the pseudo data used in this study will also contain less information due to observational errors and non modeled aspects of the underlying real stochastic process this suggests that priors should be as informative as possible with a strong warning that priors ought not to be more informative that can be supported golchi golchi 2019 provides an overview of the usefulness of informative priors to solve several types of inference problems while we did not take prior correlations between parameters into account for this experiment good priors for real world problems will include prior information about correlations between parameters sound priors are informed by domain specific insights which may be obtained by for example expert assessments or survey results one approach to creating informed priors which include information about the relationships between parameters is probabilistic inversion kraan and cooke 2000 fuller et al 2017 in which expert assessments or as an alternative the results of judgement and decision making or economic experiments can be used to update more generic priors in a way which is consistent with those assessments or experimental results this allows the survey or experimental participants to provide information directly about outcomes rather than about model parameters and allows for a separation of the data involved in the prior construction and bayesian updating processes to avoid information reuse as our results illustrate each additional parameter or interaction in an abm can considerably increase the calibration data requirements trying to include every hypothesized feedback mechanism in the final model choice without supporting evidence can pose problems from statistical as well as decision theoretical points of view box 1976 jaynes 2003 robert 2007 starting with a simple model and adding complexity when supported by the data can produce more skillful hindcasts projections and more powerful insights box et al 1979 holling and watt 1966 indeed our analysis demonstrates that increased model complexity can result in an increased data need while our simple models were motivated by the problem of housing abandonment in the presence of flood risks we see no reason why this general point would not be applicable more broadly though the details of the analysis would differ depending on the complexity of the model structure author contributions statement v s and k k conceptualized the research v s wrote the model and analysis codes v s and k k designed the figures and wrote the paper declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank ben lee joel roop eckart tony wong casey helgeson and skip wishbone for their contributions this work was partially supported by the national science foundation nsf through the network for sustainable climate risk management scrim under nsf cooperative agreement geo 1240507 the penn state center for climate risk management and by the u s department of energy office of science biological and environmental research program earth and environmental systems modeling multisector dynamics contract no de sc0016162 any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding entities all codes for pseudo data generation model analysis and figure generation can be found at http www github com vsrikrish abm tree calibration appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104978 
25874,agent based models abms are widely used to analyze coupled natural and human systems descriptive models require careful calibration with observed data however abms are often not calibrated in a formal sense here we examine the impact of data record size and aggregation on the calibration of an abm for housing abandonment in the presence of flood risk using a perfect model experiment we examine i model calibration and ii the ability to distinguish a model with inter agent interactions from one without we show how limited data sets may not adequately constrain a model with just four parameters and relatively minimal interactions we also illustrate how limited data can be insufficient to identify the correct model structure as a result many abm based inferences and projections rely strongly on prior distributions this emphasizes the need for utilizing independent lines of evidence to select sound and informative priors keywords agent based modeling statistical calibration model selection 1 introduction agent based models abms can be a useful tool for modeling and understanding how macro scale aggregate features of complex systems emerge from micro scale individual decisions interactions and feedbacks generative social science epstein 1999 as a result abms are used in many application areas including land use change parker et al 2003 evans and kelley 2004 brown et al 2005 evans and kelley 2008 kelley and evans 2011 evans et al 2013 brown et al 2017 dou et al 2020 li et al 2020 ecology black and mckane 2012 grimm 1999 van der vaart et al 2016 and climate change adaptation balbi et al 2013 barthel et al 2008 gerst et al 2013 schneider et al 2000 ziervogel et al 2005 lamperti et al 2020 one key application is modeling flood risk and impacts due to the presence of observed socio hydrological feedbacks aerts et al 2018 di baldassarre et al 2013 flood risk modeling using abms is an extremely active area of research dubbelboer et al 2017 haer et al 2016 jenkins et al 2017 tonn and guikema 2017 magliocca and walls 2018 de koning and filatova 2019 chandra putra and andrews 2020 o shea et al 2020 koc and işık 2020 models can be designed to address different questions about the modeled system including prediction explanation and demonstration epstein 2008 bankes bankes 1993 distinguishes consolidative models which are used to simulate the dynamics of a well understood system from exploratory models which are used to test hypotheses about model structures or system dynamics a similar but not identical classification is proposed by marks marks 2011 who classifies models as demonstrative or descriptive demonstrative abms are used to illustrate that patterns of interest can be produced through local level rules and interactions descriptive abms are intended to reproduce observed phenomena for the purpose of explanation prediction or both the descriptive model category includes both simpler strategic models and more complex tactical models holling and watt 1966 early abms such as the pioneering work on racial segregation schelling 1971 were primarily demonstrative janssen and ostrom 2006 marks 2011 over time there has been an increase in the fraction of descriptive models janssen and ostrom 2006 both demonstrative and descriptive models require tests to ensure that the model works as intended descriptive models also benefit from a comparison of model output against observations marks 2011 an example is pattern based modeling grimm et al 2005 in which one or more structural patterns in the data are compared to model output to see if the model is capable of simulating multi scale aspects of the data another model checking procedure are simulations over a historical period to demonstrate that the model reproduces historical data though this is not the same thing as demonstrating that the model is a reproduction of system dynamics oreskes et al 1994 as all models are approximations of real processes box 1976 the observation that models are only capable of approximating rather than reproducing real system dynamics box 1976 shows the importance of model calibration for descriptive modeling calibration is the process of selecting model structures and parameter values oreskes et al 1994 one common approach to abm calibration is to tune model parameters until model outputs are close to the empirical data kelley and evans 2011 schwarz and ernst 2009 van der vaart et al 2015 abm calibration can be complicated by the path dependence and feedbacks associated with many coupled natural human systems these path dependencies and nonlinear dynamics can cause observed outcomes to be very sensitive to small changes in any part of the system as a result observations of these systems are highly contingent brown et al 2005 and may reflect the influence of initial states or early shocks in a way which obscures the underlying dynamics as a result these procedures can lead to over fitting the model to the calibration data as data are merely one realization of an underlying data generating and observation process over fitting data which may have been less probable than other observations could result in biased inferences and projections the risk of over fitting may be particularly high when there are a large number of model parameters which have interactions resulting in compensating effects to account for the stochastic elements of a model another approach to calibration is to choose a model structure and parameter values which are most probable given the observations and prior information about system dynamics jaynes 2003 robert 2007 this approach which we adopt here is often called statistical calibration sansó and forest 2009 lee et al 2019 statistical calibration involves using statistical inference to obtain parameter values or select model structures another complication of abm development is the risk of over parameterization over parameterized models include variables and dynamics outside of what is supported by the evidence due to the additional degrees of freedom overly parameterized models are more likely to overfit observations and may generalize less well for the purposes of prediction while adding minimal theoretical benefit however whether descriptive abms are intended to be used for explanation or prediction these features suggest a need for quantification of model and parametric uncertainty as observed patterns may be dependent on external forcings which might be stochastic or initial conditions this discussion leads to a simple overarching question how does the amount of data required to statistically calibrate agent based models increase with model complexity increasing complexity of agent decision rules in the sense of the number of parameters and including agent agent and agent environment interactions and feedbacks in the sense of emergence can reduce the ability to constrain model parameters or test hypotheses particularly when data may be relatively scarce we address this question using a bayesian approach to uncertainty quantification we focus on three specific questions first how do varying dataset sizes and structures affect the statistical calibration of an abm second can we assess the relative evidence for models with varying levels of complexity either in terms of high dimensional decision rules or the types of agent interactions with each other and the environment third how are calibration and hypothesis testing affected by the use of spatially aggregated data as opposed to observations of individual agents which may be all that are available due to data collecting limitations or considerations of anonymity in particular we use a perfect model experiment a perfect model experiment uses pseudo observations generated from a known data generating process including known model parameters see e g reed and kollat 2012 or olson et al 2013 we generate pseudo observations for a variety of spatial and temporal extents we then calibrate the model using these pseudo data with different seeds to approximate the more typical situation where the model and the true data generating process are dissimilar this gives us a best case scenario for how much information these observations could provide about the considered model s real observations would provide less information given observational uncertainty and missing aspects of the model compared to the real data generating process for a concrete example we focus on the particular problem of modeling housing abandonment under flood risk following tonn and guikema tonn and guikema 2017 housing abandonment poses potentially severe economic problems for settlements along rivers and coastlines fowler et al 2017 indeed recent work has shown that repetitive flooding can intensity outmigration with an associated increase in climate gentrification de koning and filatova 2019 residents who haven t experienced flooding themselves may abandon their homes if their neighbors do due to depreciating values or anticipation of future flooding an associated abm and a submodel with fewer interactions and feedbacks are illustrated by the influence diagrams in fig 1 for the following work we use relatively simple abms with limited interactions between agents and their environment this choice allows us to highlight some of the concepts and difficulties associated with the statistical calibration of even simple abms with relatively few parameters and feedbacks with an understanding that these complications grow as models increase in complexity 2 methods 2 1 models we analyze two abms represented by the influence diagram in fig 1 in both models agents decide to vacate their homes using a probabilistic decision process logistic regression as opposed to maximizing utility or using heuristics which are more common in abms in certain application areas such as land use groeneveld et al 2017 once a house is abandoned there is a chance that it is occupied by a new agent in a subsequent year in the first considered model no interactions the probability of housing abandonment is determined only by the frequency of experienced floods over the previous ten years this model is parameterized using three parameters the logistic regression intercept β 0 the logistic regression coefficient for flood frequency β 1 and the probability that vacant houses are filled by a new agent α denote by s t i the state of parcel i where s t i 1 if the parcel is occupied and 0 if the parcel is vacant the probability that this parcel switches from occupied to abandoned is p s t i 0 s t 1 i 1 logit 1 β 0 β 1 r t where r t is the frequency of flooding events for the previous ten years the probability that this parcel switches from abandoned to occupied is constant p s t i 1 s t 1 i 0 α in the second considered model spatial interactions we include an additional logistic regression covariate the fraction of neighboring plots which are vacant at the start of time t as a result this model has four parameters including the coefficient for this neighboring vacancy covariate these state transition equations give both models a markovian structure see supplementary information s2 2 of course these models could be further expanded for example by including housing market dynamics see fig 1 in this study we focus for clarity just on the two models as we are interested in understanding the process and results of statistical calibration for simple abms 2 2 data we generated pseudo observations for the perfect model experiment using the model with spatial interactions to see if we could successfully test for the spatial interaction effect the pseudo observations are generated using the spatial interactions model for an artificial riparian settlement and realizations of annual flood height maxima see supplemental section s1 the parcel return periods and river heights are shown in supplementary figure s1 parcel residency was initialized by assuming that each parcel had a 99 probability of having a resident at the start of the simulation the additional dynamic mechanism resulting from spatial interactions leads to increased probabilities of parcel abandonment for all return periods across realizations of the stochastic process even for parcels that are far from floods fig 2 as data may not be available in individualized forms we examine the power of data for calibration and hypothesis testing about model structures in both individual and aggregate forms in the individual case the data set contains observations of each observed parcel at each time in the aggregate case we observe the total number of abandoned parcels at each time as a result the individually resolved data consists of maps of occupancy state whether each parcel is occupied or unoccupied while the aggregated data is a time series of counts of unoccupied parcels 2 3 calibration we use a bayesian framework for model calibration based on bayes theorem bayes 1763 p θ y p y θ p θ where p θ y is the posterior density p y θ is the data likelihood and p θ is the prior we constructed the priors that were used in this study table 1 using a rough understanding of the model dynamics so that the resulting probabilities of abandonment seemed plausible they are intentionally not centered on the known data generating parameter values for both individual parcel and aggregate data we model the probability of each parcel being vacant and compute the appropriate likelihood treating each parcel s vacant status at time t as independent and identically distributed conditional on the state its vacancy status and in the spatial interactions model that of its neighbors in time t 1 this markovian representation is common for many abms izquierdo et al 2009 and we describe this process in supplementary section s2 2 in the individual data case we use a binomial likelihood to model the probability of each parcel being vacant at each time in the aggregate data case we use a poisson likelihood which is commonly used to model count numbers on the expected number of vacant parcels for more details on how these likelihood functions are specified see supplemental section s2 1 the models described above are fast enough to use markov chain monte carlo mcmc for the bayesian inversion mcmc is an extremely general method for sampling from a target probability distribution in this case the posterior distribution the mcmc method constructs a markov chain of samples which converge to the target distribution mcmc has previously been used for calibrating abms keith and spring 2013 there are many mcmc algorithms of varying complexity we describe the algorithm we use the metropolis hastings algorithm metropolis et al 1953 hastings 1970 in supplementary section s2 3 other algorithms such as dream vrugt 2016 or hamiltonian monte carlo neal et al 2011 are more sophisticated and powerful but the relatively simple metropolis hastings algorithm performs satisfactorily for these simple models which have few parameters and have a runtime of under half a second for all considered cases we use 150 000 metropolis hastings iterations after a preliminary adaptive run vihola 2012 of 30 000 iterations which is used to estimate the starting value of the production run as well as the covariance matrix for the proposal distribution the preliminary run is initialized at the maximum likelihood estimate 2 4 model selection we use bayes factors to analyze the model selection problem kass and raftery 1995 bayes factors compare the evidence for each model structure using a ratio of marginal likelihoods see supplementary section s3 1 intuitively the marginal likelihood of a model captures the total probability assigned to the data by the calibrated model across the entire posterior distribution the bayes factor then captures the extent to which one model better predicts the data much like other model comparison methods such as the akaike information criterion or aic akaike 1974 bayes factors penalize models which produce overly diffuse realizations e g due to the presence of additional model parameters which are ill constrained by calibration one important consideration when using bayes factors is the dependence of marginal likelihoods on the choice of prior robert 2007 from a bayesian perspective this is consistent with the idea that the bayes factor is a metric comparing two model structures as the selection of the prior is a key part of bayesian model specification here we use the same priors for corresponding parameters to reduce this effect while the bayes factor compares the ability of two models to reproduce the calibration data a modeler may wish to select a model based on the expected ability of the model to predict out of sample data gelman et al 2014 to this end we also use an alternative metric the watanabe aikaike information criterion or waic watanabe 2010 vehtari et al 2017 which is described in more detail in supplementary section s3 2 however in our case waic may not provide a good approximation to the expected out of sample predicted error as we do not calibrate our model repeatedly on shorter data subseries we hence only use this metric to compare with the results of the bayes factor analysis 3 results 3 1 calibration the structure of the data individual parcel versus spatially aggregated strongly influences the final shape of the posterior distribution both due to the number of data points and the different likelihood function specifications fig 3 shows the result of updating the prior distributions specified in table 1 with 50 years of pseudo observations of 100 parcels for certain key parameters such as the logistic regression coefficient for the local flooding frequency aggregated data the total number of abandoned parcels at each time leaves the posterior close to the prior fig 3b for individually resolved data the marginal posterior is sharpened much further fig 3a while it appears from fig 3a that the original decision rules are not fully recovered looking at the posterior density at the data generating value it is important to keep in mind the influence of stochasticity in the realized data running the same model with the same parameter values can yield model output with very different dynamics due to stochastic forcings particularly in the presence of high levels of path dependence and positive feedbacks see fig 4 between the strong influence of the stochastic elements the logistic regression in the model and the relative lack of sensitivity to parameter values close to the data generating value it is not necessarily surprising that the data generating value is assigned a relatively low density the full posterior parameter estimates feature a high degree of correlation between parameters as seen in the pairs plot supplementary figure s5 for example the two logistic regression coefficients for flood frequency and proportion of neighboring abandoned parcels have a correlation coefficient of 0 66 a lower sensitivity to experienced floods can be offset by an increased sensitivity to neighbor behavior another example is the high positive correlation between the probability of a vacant lot being re occupied and both the logistic regression intercept term and the coefficient for neighboring parcels r 0 73 in both cases similar interactions would be missed by a deterministic calibration combined with one at a time sensitivity analysis ten broeke et al 2016 we analyze the hindcasting ability of the posterior predictive distribution shown in fig 5 to explore how the model was constrained by the observations and how well the model simulates the observed dynamics the three parameter no interactions model is well constrained by smaller data sets however the poor fit of the posterior predictive distribution compared to the pseudo observations for increased amounts of data reveals the missing abandonment dynamic mechanism without the inclusion of spatial interactions the no interactions model calibration results in a higher sensitivity to experienced flooding to account for the data which results in biased estimates of the number of abandoned parcels in later years meanwhile the spatial interactions model which has one additional parameter and includes an interaction requires more data to constrain the model 25 observed parcels is insufficient with up to 50 years of data but once constrained fits the pseudo observations better than the no interactions model in general having a larger spatial domain numbers of agents facilitates calibration more than having a longer data record this pattern remains in our study when we calibrate the model with alternative pseudo observations see supplemental figures s7 s10 while fig 5 might appear to show that calibration with aggregate data results in a better fit to the observations we hypothesize that this is an artifact of two different components of the modeling process first the likelihood function used for the aggregate data calibration is different than the individual data calibration poisson vs binomial which will change the shape of the posterior distribution second in the aggregate case we calibrate the model directly against the aggregated counts shown in fig 5 while in the individual data case the expected state of each parcel was used these two differences make it difficult to compare the quality of the hindcast as they are structurally different calibration procedures we would expect that in the latter case there is greater uncertainty about the total count of abandoned parcels however in some of the alternate realizations shown in supplemental figures s7 s10 using individually resolved data can result in overconfidence while as seen in supplemental figure s6 using aggregated data resulted in more consistent parameter estimates these details are likely to be extremely sensitive to the particular model specification 3 2 model selection more complex abms can be thought of as being constructed by adding new interactions and feedbacks to simpler abms as illustrated in fig 1 this allows us to view this type of model selection as hypothesis testing for the presence of additional feedback mechanisms cottineau et al 2015 as well as potential over parameterization posterior model structural probabilities are calculated by combining prior knowledge and beliefs about the relative probability of the competing models with the bayes factor this prior information about the probability of various model structures can be guided by domain specific insights that are gleaned for example from other observations or other qualitative information forrester 1980 in this stylized experiment we make the prior assumption that the models with and without spatial interactions are equally probable for our perfect model experiment one would expect additional in terms of the number of observations and spatially explicit rather than aggregated data to improve the ability to distinguish between the data generating spatial interactions model and the simpler no interactions model which is seen in fig 6 we neglect the case with 25 observed parcels due to unreasonably high estimates likely due to the ill constrained spatial interactions model however the hindcasts in fig 5 shows the qualitatively better fit of the no interactions model for this data set particularly in the individual data scenario for individual parcel data with more than 25 observed parcels there is at least strong evidence for the spatial interactions model no matter how long the parcels were observed which confirms the qualitative assessment on the summary statistic of total abandoned parcels obtained by comparing the hindcasts in fig 5c and d on the other hand when aggregated data is used for calibration there is essentially no quantitative evidence for the spatial interactions model this is the case whether we compare the models using bayes factors or a predictive information criterion such as waic the one standard error range of the difference in waic between the spatial interactions and the no interactions model is between 2 and 2 which can be interpreted as no difference in support between the two models burnham and anderson 2004 however a qualitative assessment obtained by comparing fig 5a and b might lead a researcher to conclude that the spatial interactions model fits the observations better than the no interactions model this suggests that hindcasting can serve an important supporting role to quantitative model selection 4 discussion statistical calibration is an important component of the descriptive agent based modeling process due to the path dependence associated with complex data generating processes as illustrated in fig 4 using a statistical approach reduces the potential for over fitting the model to the data which is a risk with a deterministic approach to calibration either through hand tuning the parameters or through the use of an optimization routine as a result the calibration procedure can take into account that the observations may not have been the most likely outcomes given the understanding of the system dynamics including the specifications of the likelihood function and prior distribution that the model encodes which has implications for parameter inference and model selection and hence for future projections our use of a didactic perfect model experiment somewhat limits the direct generalization of our results to other experiments using real world data in contrast to our perfect model didactic example the real world data may be more noisy and will be generated through a process which is incompletely represented by any model box et al 1979 in this case statistical approaches to calibration are potentially more useful than in our experiment as we can account for systematic model discrepancies kennedy and o hagan 2001 through the construction of a likelihood which separates these discrepancy terms from white noise as this perfect model experiment provides a somewhat best case scenario for parameter inference and model selection the demonstration of how limited data sets are unable to meaningfully constrain model hindcasts is likely to generalize to other studies it is likely however that model selection as conducted in this study will be more complicated in the case where two imperfect technically wrong box et al 1979 models are being compared showing the importance of carefully synthesizing the available evidence qualitative and quantitative to provide justifications for a particular set of model features it is important to point out that different modeling aims would induce different calibration needs with implications for the appropriateness of specific methods some users of demonstrative models for example might want to conduct a model based exploratory analysis rather than making projections of future system outcomes for example one might explore how certain bottom up rules which are broadly consistent with observations or other evidence could produce certain dynamics or outcomes in this case manual calibration based on some observational or survey data for example could be sufficient as another example a modeling exercise might be partially or entirely motivated by qualitative data which demonstrates that behaviors or outcomes follow certain patterns in which case quantitative approaches to calibration are either inappropriate or should be modified to account for this additional information if these aims are clearly indicated the resulting data needs and calibration procedures can be reconciled with them while our chosen method of metropolis hastings mcmc has the ability to produce high fidelity approximations to the full joint probability distribution of the model parameters robert 2014 it may be computationally intractable for complex models featuring long runtimes or high dimensional parameter spaces in this case the relative simplicity of the models facilitated the use of mcmc an additional complication is the need to specify a statistical likelihood function which may be difficult for particular applications in general there is a trade off between computational speed and accuracy of the resulting parameter distributions some other approaches to statistical calibration of abms which are aimed at reducing computational requirements or likelihood specification include statistical emulation lamperti et al 2018 oyebamiji et al 2017 particle filtering kattwinkel and reichert 2017 and approximate bayesian computation fabretti 2018 sirén et al 2018 van der vaart et al 2015 van der vaart et al 2016 while these methods reduce the computational burden they come at a cost of potentially severe statistical approximations that can influence the parameter estimates frazier et al 2018 künsch 2013 robert et al 2011 singh et al 2018 difficulties constructing likelihood functions may also emerge when a pattern oriented approach towards model evaluation and selection is adopted as it may be difficult to link multiple patterns together using an appropriate likelihood function in these cases alternative approaches like approximate bayesian computation or abc sunnåker et al 2013 would be useful abc may be particularly appropriate for pattern oriented calibration and evaluation though care should be taken that the set of statistics used to capture patterns is sufficient as otherwise the approximation to the true posterior will be degraded an additional concern is the specification of prior distributions when less data is available the data will have less power to update the prior distributions as we noted in the introduction real data as opposed to the pseudo data used in this study will also contain less information due to observational errors and non modeled aspects of the underlying real stochastic process this suggests that priors should be as informative as possible with a strong warning that priors ought not to be more informative that can be supported golchi golchi 2019 provides an overview of the usefulness of informative priors to solve several types of inference problems while we did not take prior correlations between parameters into account for this experiment good priors for real world problems will include prior information about correlations between parameters sound priors are informed by domain specific insights which may be obtained by for example expert assessments or survey results one approach to creating informed priors which include information about the relationships between parameters is probabilistic inversion kraan and cooke 2000 fuller et al 2017 in which expert assessments or as an alternative the results of judgement and decision making or economic experiments can be used to update more generic priors in a way which is consistent with those assessments or experimental results this allows the survey or experimental participants to provide information directly about outcomes rather than about model parameters and allows for a separation of the data involved in the prior construction and bayesian updating processes to avoid information reuse as our results illustrate each additional parameter or interaction in an abm can considerably increase the calibration data requirements trying to include every hypothesized feedback mechanism in the final model choice without supporting evidence can pose problems from statistical as well as decision theoretical points of view box 1976 jaynes 2003 robert 2007 starting with a simple model and adding complexity when supported by the data can produce more skillful hindcasts projections and more powerful insights box et al 1979 holling and watt 1966 indeed our analysis demonstrates that increased model complexity can result in an increased data need while our simple models were motivated by the problem of housing abandonment in the presence of flood risks we see no reason why this general point would not be applicable more broadly though the details of the analysis would differ depending on the complexity of the model structure author contributions statement v s and k k conceptualized the research v s wrote the model and analysis codes v s and k k designed the figures and wrote the paper declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank ben lee joel roop eckart tony wong casey helgeson and skip wishbone for their contributions this work was partially supported by the national science foundation nsf through the network for sustainable climate risk management scrim under nsf cooperative agreement geo 1240507 the penn state center for climate risk management and by the u s department of energy office of science biological and environmental research program earth and environmental systems modeling multisector dynamics contract no de sc0016162 any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding entities all codes for pseudo data generation model analysis and figure generation can be found at http www github com vsrikrish abm tree calibration appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 104978 
