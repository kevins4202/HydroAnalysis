index,text
6900,we present a joint bayesian inverse method for analyzing conservative and reactive tracer data which estimates non parametric transfer functions and effective first order reaction rate coefficients simultaneously a stochastic sampling approach based on markov chain monte carlo mcmc methods was used to simulate samples from the posteriors with a metropolis within gibbs sampler used for transfer functions and reaction rate coefficients non negativity constraints were realized by choosing a reflected gaussian prior for the transfer function and a lognormal prior for the reaction rate coefficient the approach was tested by synthetic sparse datasets with introduced normal random errors or periodic errors and then it was applied to the tracer test data collected at oak ridge national laboratory the results indicate that the developed approach was well capable of characterizing anomalous transfer functions such as multi modal functions and quantifying the uncertainty of both transfer functions and reaction rate coefficients in particular compared with the approach of individual inversion of sparse data the joint inversion approach taking advantage of the sharing of information regarding transport processes across the conservative tracer and reactive tracer data leads to the improved estimation of transfer functions and reaction rate coefficients for sparse datasets keywords break through curves tracer test joint analysis bayesian inverse modeling mcmc 1 introduction to characterize transport in the subsurface conservative tracers such as bromide are usually injected into the subsurface and their concentration breakthrough curves btcs are measured in down gradient sampling wells comparing the conservative tracer btcs with the reactive tracer btcs one may demonstrate the effect of undergoing reactions and estimate the effective reaction rate coefficients a common approach to analyze such btcs is to develop transport models and fit the conservative tracer and reactive tracer data either sequentially or jointly luo et al 2006 massoudieh et al 2014 mccallum et al 2014 toride et al 1993 turnadge and smerdon 2014 sequential approaches typically use conservative tracer data first to calibrate a transport model and then take the fitted model as the true model to estimate reaction rates by fitting the reactive data joint approaches use both conservative and reactive data to simultaneously fit a transport model and the corresponding reaction rate sequential approaches are computationally more efficient but they ignore the uncertainties associated with the fitted transport models when fitting the reactive tracer data they also ignore the fact that reactive data also contain useful information about physical transport processes joint approaches are more costly but they are better at exploiting the information reflected by the data particularly the information on transport processes shared by conservative and reactive data mechanistic transport models for fitting tracer data usually require that the spatial distributions of hydrological chemical and biological properties are known such characterization of the subsurface is limited at most sites thus modelers often simplify transport models e g by applying one dimensional models in which unresolved subsurface heterogeneities are inadequately parameterized as an alternative to the mechanistic transport model the transfer function approach is more flexible for analyzing tracer tests in linear transport systems as specific transport processes need not be defined and a detailed subsurface characterization is not required besbes and de marsily 1984 box et al 2015 cvetkovic et al 1996 jury 1982 jury et al 1982 liu and liu 1974 long and derickson 1999 a transfer function can characterize a linear transport system given prescribed input and output signals and once obtained can be used for the evaluation of btcs given any input signal the transfer function of a conservative tracer can be interpreted as the tracer recovery times the travel time distribution which may be applied in the stochastic convective framework to simulate either linear or nonlinear reactive transport systems cirpka and kitanidis 2001 ginn 2001 ginn et al 1995 both parametric and nonparametric approaches have been developed for estimating transfer functions as examples of parametric transfer function models lognormal and inverse gaussian distributions were used for the representation of transfer functions in groundwater cirpka and kitanidis 2001 shapiro and cvetkovic 1988 simmons 1982 simmons et al 1995 luo et al 2006 used gamma functions to jointly estimate transfer functions and first order reaction rates for analyzing tracer tests conducted at the field research center of oak ridge national laboratory recently long tailed distributions such as the tempered one sided stable distribution have attained more popularity cvetkovic 2011 however when estimating parametric transfer functions one pre defines the type or shape of the functions which is similar to defining specific transport processes in mechanistic transport models by contrast non parametric approaches that do not define the shape of the transfer functions are more flexible in describing tracer tests in complex subsurface fienen et al 2006 developed a bayesian inversion approach based on a markov chain monte carlo mcmc sampling method for analyzing the tracer tests at the oak ridge field research center which recognizes the transfer function as a gaussian process in the time domain and utilizes gesotatistical kernel functions to describe its correlated structure parametric and non parametric analysis yielded a similar estimation of reaction rate coefficients but the non parametric transfer functions revealed multi modal behavior that could not be described by gamma functions however the inversion of conservative and reactive tracer test data was conducted separately and the reaction rate coefficients were evaluated via simple linear regression that is conservative and reactive transport were considered as two independent linear systems and their transfer functions were obtained by individually inversing the conservative and reactive btcs the information shared across the datasets was completely ignored in addition both parametric and non parametric approaches mentioned above considered reaction rate coefficients as constants which were estimated through optimization without considering the associated uncertainty even though individual members of the conditional ensembles could have been used to estimate the uncertainty of reaction rate coefficients the limited number of available points for regression and the disconnection between individually generated samples could bias the best estimate and jeopardized the uncertainty characterization of the reaction rate coefficient cirpka et al 2007 chose a different approach of non parametric deconvolution by enforcing non negativity using the method of lagrange multipliers which is more computationally efficient than an mcmc approach this approach generated conditional realizations to account for the uncertainty of transfer functions and has also been applied to estimate reactive parameters based on tracer data knapp et al 2015 lemke et al 2014 the present study extends the previous non parametric approach of fienen et al 2006 to develop a new bayesian inversion approach to jointly inverse conservative and reactive tracer data for estimating non parametric transfer functions and effective reaction rate coefficients bayesian inverse modeling has many advantages over other methods because it combines information from data and prior knowledge and quantifies the uncertainty of all involved parameters the new approach quantifies the uncertainty of reaction rate coefficients in a bayesian framework estimates transfer functions using both conservative and reactive data and thus is particularly useful for sparse data sets this paper is organized as follows section 2 describes the forward mathematical model to model the tracer tests section 3 presents the detailed solution procedures including the joint bayesian inversion approach and the markov chain monte carlo mcmc sampling approaches in section 4 two synthetic data cases are used to verify the new approach finally in section 5 the new approach is applied to analyze the tracer tests conducted at the oak ridge field research center and the results are compared to published results 2 forward modeling for a time invariant linear system the concentration of the tracer measured in a monitoring well can be described by the well known linear convolution principle 1 y t t 0 t x t τ s t t τ d τ where y t represents the tracer concentration in the monitoring well s t represents the transfer function describing the tracer transport for a unit pulse input at time zero x t represents the tracer concentration in the injection well the transfer function is identical to the btc corresponding to a unit impulse injection the forward convolution model can be numerically formulated as 2 y t h s t v t where y t represents an n 1 1 discrete concentration observation at a monitoring well s t represents an m 1 transfer function of tracer concentrations on a desirable discretization h represents an n 1 m sensitivity matrix that works as a numerical convolution operator in this particular case fienen et al 2006 3 h n m 1 2 x t τ 1 δ τ 0 0 0 1 2 x t τ 2 δ τ 1 2 x t τ 1 δ τ 0 0 1 2 x t τ m 1 δ τ x t τ m 2 δ τ 1 2 x t τ 1 δ τ 1 2 x t τ 1 δ τ 1 2 x t τ m δ τ x t τ m 1 δ τ x t τ 2 δ τ 1 2 x t τ 2 δ τ 0 1 2 x t τ m δ τ x t τ 3 δ τ 1 2 x t τ 3 δ τ 0 0 1 2 x t τ m δ τ 1 2 x t τ m 1 δ τ 0 0 0 1 2 x t τ m δ τ v t represents an n 1 1 random error vector incurred by inappropriate model formulations measurement errors discretization inaccuracy etc with refined discretization errors from numerical computation will become negligible compared to measurement and conceptual model errors in this paper we assume that all errors are uncorrelated v t is assumed to be from a gaussian distribution with the following properties 4 μ v t 0 σ v t d σ v t 2 where d represents a n 1 n 1 diagonal matrix and σ v t 2 represents the variance of measurement and model error in certain cases σ v t 2 σ v t 2 1 where σ v t 2 represents a single variance parameter and 1 represents a n 1 1 vector with all ones this simplification assumes different variances for the measurements at different spatial or temporal locations however the simplified gaussian random error model may lose validity in cases where the epistemic error or the measurement error exhibits highly non gaussian behaviors for simplicity following the previous studies fienen et al 2006 luo et al 2006 we consider a linear reactive system with an effective first order reaction rate to quantify the overall reaction behavior the concentration of reactive tracers can be evaluated by 5 y r t 0 t x r τ s r t τ d τ 0 t x r τ s t t τ exp k t τ d τ where y r represents the concentration of the reactive tracer at a monitoring well x r represents the injection history of the reactive tracer at the injection well and s r represents its transfer function which is related to the transfer function of the conservative tracer by 6 s r τ s t τ exp k τ accordingly the linearized forward model of the reactive tracer can be written as 7 y r h r s t v r where y r represents an n 2 1 discrete concentration observation at a monitoring well v r represents an n 2 1 random error vector involved in the process with u v r 0 and σ v r d σ v r 2 and h r represents an n 2 m sensitivity matrix given as 8 h r h d exp k τ where d represents an m m diagonal matrix and τ represents the discretized time difference it is noted that both forward models depend on the transfer function of the conservative tracer and its information is reflected in both conservative and reactive btcs to jointly analyze conservative tracer data and reactive tracer data the following linearized forward model is adopted 9 y h j s t v where y y t y r t represents the n 1 n 2 1 discrete concentration observation at a monitoring well s t represents the transfer function of tracer on a desired discretization h j h h r t represents the n 1 n 2 m sensitivity matrix and v represents an n 1 n 2 1 random error vector with μ 0 and σ d σ 2 with d representing a n 1 n 2 n 1 n 2 diagonal matrix and σ 2 representing the variance vector of the error 3 bayesian inverse modeling in the chosen bayesian framework the conservative tracer transfer functions and the reaction rate coefficients are estimated by deriving their full conditional distributions and simulating distribution samples using the mcmc method 3 1 full conditional distributions starting point is bayes theorem applied to values of the transfer function s and the reaction rate coefficient k 10 p s k y p y s k p s k to apply gibbs sampling geman and geman 1984 to simulate samples of s and k from the posterior distribution their full conditional distributions need to be derived which are the conditional distributions of s and k given each other and the data y the full conditional distributions are 11 p s y k p y s k p s k p k y s p y s k p s k where p s y k and p k y s represent the full conditional distributions of transfer functions and reaction rate coefficients p y s k represents the likelihood function which describes constraints imposed by available measurements p s k represents the joint prior distribution of transfer functions and reaction rates the prior distribution contains prior knowledge and constraints on these variables to simplify the expressions of the distributions further we assume that the transfer function s and reaction rate coefficient k are independent variables prior to conditioning on the tracer data then the following equations could apply p s k p s p k where p s and p k represent the prior distributions of the transfer function s and the reaction rate coefficient k respectively the final full conditional distributions are written as 12 p s y k p y s k p s p k y s p y s k p k the likelihood function has the following form 13 p y s k 1 2 π n 2 σ 1 2 exp 1 2 y h j k s t σ 1 y h j k s where σ represents the covariance matrix of random error v d σ 2 σ represents the determinant of matrix σ the index k following h j expresses that the discretized transfer function of the reactive compounds depends on the reaction rate coefficient so that h j k has to be reevaluated for each k value as negative values are prohibited in transfer functions negative concentration does not exist a reflected gaussian distribution is selected as the prior of s fienen et al 2006 michalak and kitanidis 2003 p s π i 2 m p s i s i 1 p s i s i 1 1 2 π θ t i t i 1 exp 1 2 s i s i 1 2 2 θ t i t i 1 exp 1 2 s i s i 1 2 2 θ t i t i 1 f o r s i 0 14 p s i s i 1 0 f o r s i 00 where θ represents the slope of a linear variogram model assumed for the autocorrelation of s fienen et al 2004 s i represents the transfer function estimated at time increment t i s i 1 represents the transfer function estimated at time increment t i 1 t i t i 1 represents the separation distance in time domain michalak and kitanidis 2003 a lognormal distribution is selected as the prior of the reaction rate coefficient to enforce non negativity 15 p k 1 k σ k 2 π exp ln k μ k 2 2 σ k 2 where μ k represents the prior mean of ln k σ k represents the prior standard deviation of ln k combining the priors of s and k with the likelihood function the full conditional distributions can be constructed as below 16a p s y k π i 2 m p s i s i 1 1 σ exp 1 2 y h j k s t σ 1 y h j k s 16b p k y s 1 k σ k 2 π exp ln k μ k 2 2 σ k 2 1 σ exp 1 2 y h j k s t σ 1 y h j k s then we follow the same procedure as shown in michalak and kitanidis 2003 to formulate the full conditional distribution of s i the discretized transfer function at time increment i details can be found in appendix a 3 2 implementation of inversion markov chain monte carlo mcmc methods are implemented to draw samples from the derived distributions chen et al 2008 chen et al 2004 wainwright et al 2014 wainwright et al 2015 s i and k are sampled consecutively using a gibbs sampler geman and geman 1984 as shown by michalak and kitanidis 2003 p s i s i y k can be proportionally sampled from a gaussian mixture model but p k y s has a complicated form from which direct sampling will be impossible instead the metropolis hastings sampling method is used to draw samples of k from the full conditional distribution chib and greenberg 1995 chib and jeliazkov 2001 hastings 1970 metropolis et al 1953 thus strictly speaking a metropolis within gibbs sampling method is implemented for drawing samples of s k a detailed procedure of the implementation is described in the appendix b in which we also include the expression of the proposal distribution of metropolis algorithm the chain convergence is justified according to gelman and rubin 1992 which requires the computation of chain summary statistics as the convergence criteria in our implementations we adopt 3000 mcmc iterations 1000 as the burn in period as it guarantees convergence and gives sufficient samples for inference σ 2 θ μ k and σ k 2 are estimated using an expectation maximization method dempster et al 1977 mclachlan and krishnan 2007 which iteratively optimizes these parameters using conditional realizations of the latent variables s and k in our synthetic and field experiments em iterations required for parameter convergence are between 4 and 6 iterations to achieve faster convergence in the em optimization step the reaction rate coefficient k could be initialized using a gamma function approach as done by luo et al 2006 our algorithm for joint inversion is summarized in fig 1 4 benchmark problems in order to verify the effectiveness of the developed joint inversion method synthetic input and output data with known transfer functions are generated as benchmark problems all generated quantities are dimensionless the first example is from neuman and de marsily 1976 where the transfer function is unimodal the second example is from fienen et al 2006 where the transfer function is a bimodal function synthesized by two gaussian probability distribution functions these two examples were also used by fienen et al 2006 as benchmark problems to verify their mcmc scheme we re examine these two examples to show how our joint analysis will perform in estimating conservative tracer transfer functions s the reaction rate constant k and quantifying the associated uncertainties the expressions of transfer functions used in our synthetic study are summarized in table 1 however different from the individual approach proposed in fienen et al 2006 which only requires conservative datasets the joint inverse approach requires both conservative and reactive datasets thus using relationship s r t s t t exp k t the reactive tracer transfer function s r t is generated using the conservative tracer transfer function s t t and the prescribed reaction rate coefficient k the conservative output dataset y t and the reactive output dataset y r are computed using the convolution equations listed in table 1 in sections 4 1 and 4 2 the correctness of the proposed joint inverse approach is verified using the two synthetic datasets the reaction rate coefficient is set to be k 1 t 1 for significant differences between conservative and reactive recovery curves without loss of generality only the conservative tracer transfer function is inversed and compared with the true synthetic values in section 4 3 we compared the performance of the joint inverse approach and the individual approach on a sparse synthetic dataset 4 1 error free cases we implement the joint inversion approach to estimate the conservative tracer transfer functions in the time domain t 0 8 with δ t 0 2 in the unimodal case and those in the time domain t 0 3 with δ t 0 1 in the bimodal case the prescribed the dimensionless reaction rate coefficient is k 1 for both cases the dash lines in fig 2 a 1 and a 2 show the error free x and y data used for inversion and the deconvolution results for each point of the transfer function s in the computational domain or the reaction rate coefficient k there are 2000 realizations simulated from its posterior the inverse results of the unimodal and bimodal cases are shown in fig 2a 3 and b 3 the best estimates of the transfer function greatly fit the synthetic true functions with tight confidence intervals compared with the results obtained in fienen et al 2006 the estimated confidence intervals are slightly larger which is due to the uncertainty contribution from reaction rate coefficients for the unimodal case the best estimate of reaction rate coefficient is k 1 0051 with the 95 confidence interval 0 9894 1 0203 for the bimodal case the best estimate of reaction rate coefficient is k 1 0001 with the 95 confidence interval 0 9907 1 0096 in both cases the joint inversion provides an accurate estimation of reaction coefficients with very tight confidence intervals the prescribed reaction rate coefficient are included in both confidence intervals in both testing examples the initial guess of k is 0 9 4 2 error involved cases errors are added to the synthetic data x and y according to equations in table 1 after adding errors any existing negative values in x e r r o r t and y e r r o r t are set to be zero error involved x and y data used for inversion and the deconvolution results are shown as markers in fig 2a 1 and a 2 the inverse results of the unimodal and bimodal cases are shown in fig 2a 4 and b 4 the best estimates of the conservative tracer transfer functions deviate more from the true transfer functions compared to the error free cases however most of the true conservative tracer transfer functions are contained within the confidence intervals in the unimodal case the best estimate of the reaction rate coefficient is k 1 0031 with the 95 confidence interval 0 9811 1 0264 in the bimodal case the best estimate of the reaction rate coefficient is k 0 9703 with the 95 confidence interval 0 9403 1 0017 confidence intervals of conservative tracer transfer functions s t and reaction coefficients k in error involved cases are slightly larger than those in the error free cases larger confidence intervals are normal for error contaminated data due to the uncertainties caused by errors nevertheless the joint inversion method provides good estimates of the conservative tracer transfer functions capturing their inherent patterns and provides accurate estimates of the reaction rate coefficients with their uncertainty quantification in addition the joint inversion approach demonstrates its ability to capture the main features of transfer functions when the dataset is involved with noises the joint inversion algorithm requires an initial guess of the reaction rate coefficient k to construct the sensitivity matrix h j according to our experimental results different initial guesses of the reaction rate coefficient k makes no difference in the best estimates of the interested variables s t and k for the presented cases the joint inversion is not sensitive to the initial guess of k however with a biased initial guess the joint inversion will take more em iterations to reach convergence in the following cases close initial guesses are used to guarantee a faster convergence 4 3 effectiveness for sparse dataset as mentioned in former sections the joint inverse method could jointly utilize conservative and reactive data so that the inversion is better at exploiting the whole dataset in order to show the efficient use of data via joint analysis we reexamine the sparse error contaminated dataset in fig 2b 2 we run both joint inversion and individual inversion to estimate the conservative tracer transfer function in the experiment the individual approach will only use the conservative dataset for the inference of the conservative tracer transfer function deconvolution results using the two approaches are shown in fig 3 the estimate of the conservative tracer transfer function using the joint approach has a much better quality than that of the individual approach firstly the joint approach is able to recognize the bimodal pattern in the transfer function while individual inversion only recognizes a fat tail secondly the true transfer function is contained better within the confidence intervals in the joint inversion method the reason is that the reactive data also contain information of the conservative tracer transfer function joint inversion integrates such information to characterize the conservative tracer transfer function the best estimate of reaction rates using the joint inverse method is the same as in section 4 2 for sparse datasets the joint approach can take advantages of both conservative and reactive data to provide an accurate estimation of the conservative tracer transfer function s t and the reaction rate coefficient k and quantify the uncertainty for all the interested variables 5 application to field data fig 4 shows the plan view of a multiple well system used in the field experiments at oak ridge fienen et al 2006 luo et al 2007 wu et al 2006a wu et al 2006b as this site was contaminated with uranium in situ bioremediation was implemented for uranium reduction and immobilization ethanol was used as the electron donor in the bioremediation experiments tracer tests were conducted in this multiple wells system to determine the reaction rate coefficients of the injected ethanol as shown in fig 4 the well fw 104 was the injection well into which both the conservative tracer bromide and the reactive tracer ethanol were introduced the injection history was treated as the input function x incomplete concentration recovery of bromide and ethanol was recorded at the multilevel sampling ports fw100 fw 101 and fw 102 and the extraction well fw 26 to demonstrate the data sparsity in a better way tracer data of well fw 101 2 fw 102 3 and fw 26 are plotted in fig 5 the conservative tracer data behaves similarly to the reactive tracer data and they are assumed to follow the same transport process luo et al 2006 but the sparsity of reactive data is much more significant than that of conservative data these records were used as the output function y a detailed description of the well system and the tracer test are in wu et al 2006b using collected field data both joint and individual inversion are implemented to estimate the conservative tracer and reactive tracer transfer functions and the effective first order reaction rate coefficients best estimates and uncertainty bounds of the transfer functions at different observation wells are shown in fig 6 the estimates of the conservative tracer transfer functions are very similar between the two methods because the number of conservative tracer measurements is sufficiently large by contrast the estimates of the reactive tracer transfer functions differ significantly between the two methods because 1 the number of reactive compound measurements is small luo et al 2006 2 in the individual approach the reactive tracer transfer function is estimated without enforcing eq 6 the inversion results using the joint approach are constrained by conservative tracer data reactive tracer data and the interdependence between conservative tracer and reactive tracer transfer functions defined by eq 6 the reaction rate coefficients k estimated by the joint inversion method are in good accordance with values obtained in luo et al 2006 and fienen et al 2006 the estimates from the three papers are listed in table 2 this is also the first time that the uncertainty bounds of the reaction rate coefficient are provided for the ornl data it is worth noting that an ensemble of the reaction rate coefficient can also be generated by the individual approach by fitting a pair of the conservative tracer transfer function and the reactive tracer transfer function however as the time length and the frequencies of reactive data are much lower than those of conservative data to estimate the reaction rate coefficient using the individual inversion the conservative tracer transfer function has to be truncated to the same time length and frequency for the linear regression approach and only a limited number of points in the conservative tracer transfer functions can be used for estimation in addition in the individual approach as the conservative tracer transfer function and the reactive tracer transfer function are estimated separately there is no one to one relationship between any two realizations from each group thus the choice of the transfer function realizations for estimating reaction rate coefficients is quite arbitrary on the other hand for the uncertainty quantification joint inversion yields a better accordance between each individual estimate of reaction rate coefficients and each individual estimate of transfer functions which prevents other uncertainty sources the best estimates and the 95 percent confidence intervals of the reaction rate coefficients determined from the tracer btcs in the different wells are shown in table 2 with other published results it should be noted that the proposed joint approach relies on prior knowledge of the underlying reaction process which can be misleading in real world applications in the scenario that the underlying reaction process is unknown a model selection approach is required the model selection can be achieved by the proposed methodology as expectation maximization provides the evidence lower bound which gives different credits to competing models and helps to reveal the true underlying process the optimized θ and σ 2 values of the field case are recorded in the appendix c as the maximum of the conservative tracer transfer function in fw 102 3 is higher it is supposed to have less smoothness compared to the conservative tracer transfer function estimates in the other two wells which is proved by the highest θ value of the conservative tracer transfer function in fw 102 3 on the other hand the conservative tracer transfer function in fw 26 has the smallest θ estimate which is in accordance with the fact that it has the smallest maximum the optimized σ 2 values are higher than the measurement error for some data points which means that there are other error sources involved in this process 6 conclusion we have extended the bayesian inverse modeling approach developed by fienen et al 2006 to jointly estimate non parametric conservative tracer transfer functions and effective reaction rate coefficients of reactive tracers the metropolis within gibbs sampler was implemented to simulate samples from the full conditional distributions to guarantee non negativity reflected gaussian distributions were used as a prior for the transfer functions and a lognormal distribution for the effective reaction rate coefficient we tested our approach by both synthetic data sets and field tracer tests and demonstrated that the developed joint inversion approach is advantageous in comparison to previous parametric and non parametric approaches as a non parametric approach the developed approach clearly demonstrated its capability for characterizing anomalous transfer functions such as multi modal functions without pre defining the shape of the transfer functions in addition our approach quantifies the uncertainty of the effective first order reaction rate coefficients without any post processing more importantly the joint inversion approach used both conservative tracer and reactive tracer data for estimating transfer functions which are particularly useful for sparse datasets in synthetic cases the computational time intel core i7 3770 cpu 3 40 ghz and 32 gb ram of the unimodal case is around 150 s and that of the bimodal case is around 200 s in field data cases the computational time ranges from 670 s 1070 s our developed approach was based on the assumption of the effective first order reactions such estimates provide lumped information useful in practice for adjusting operational parameters of remediation such as the concentration of injected chemical compounds and injection duration and frequency however it is possible that the joint inversion with the assumption of linear system behaviors introduces additional errors in estimating transfer functions for nonlinear reactive systems thus in reaction systems where effective first order reactions may oversimplify the reaction kinetics it may be better to apply a stochastic convective approach to account for nonlinear reaction kinetics and combine this with a transfer function approach simmons et al 1995 for example diem et al 2013 assumed zero order decay of oxygen upon river bank filtration and applied a stochastic convective approach the developed bayesian model may be extended to include model uncertainties when there are multiple competing reaction models available elsheikh et al 2014 schöniger et al 2014 acknowledgment the study was supported by usgs 2017ga377b we thank dr cirpka dr fienen and other reviewers for their constructive comments on the original manuscript their comments helped us improve the work quality significantly we also want to thank dr fienen for his generosity in providing us the field data and the former research code appendix a sampling scheme and expectation maximization in this paper we followed the procedures of michalak and kitanidis 2003 to launch a gibbs sampler to infer transfer functions of conservative and reactive tracer the most critical point for successful implementation of a gibbs sampler is the derivation of marginal distributions of interested variables according to eq 16a and michalak and kitanidis 2003 the marginal distribution of s i with respect to the rest unknown variables can be formulated as i p s i s i y 1 2 π τ l exp 1 2 s i μ l 2 τ l 1 2 π τ p p 1 exp 1 2 s i μ p 1 2 τ p p 1 exp 1 2 s i μ p 1 2 τ p p 2 exp 1 2 s i μ p 2 2 τ p p 2 exp 1 2 s i μ p 2 2 τ p where s i represents all the values of s except s i ii p 1 exp s i 1 s i 1 2 4 θ t i 1 t i 1 exp s i 1 s i 1 2 4 θ t i 1 t i 1 exp s i 1 s i 1 2 4 θ t i 1 t i 1 iii p 2 1 p 1 iv μ p 1 s i 1 t i t i 1 s i 1 t i 1 t i t i 1 t i 1 v μ p 2 s i 1 t i t i 1 s i 1 t i 1 t i t i 1 t i 1 vi τ p 2 θ t i t i 1 t i 1 t i t i 1 t i 1 eq 1 can be further simplified to be a mixture gaussian model which is formulated as vii p s i s i z σ j 1 4 k j 2 π τ p τ l exp 1 2 s i μ j 2 τ where τ τ p τ l τ p τ l viii k 1 p 1 exp 1 2 μ l μ p 1 2 τ l τ p μ 1 τ μ p 1 τ p μ l τ l ix k 2 p 1 exp 1 2 μ l μ p 1 2 τ l τ p μ 2 τ μ p 1 τ p μ l τ l x k 3 p 2 exp 1 2 μ l μ p 2 2 τ l τ p μ 3 τ μ p 2 τ p μ l τ l xi k 4 p 2 exp 1 2 μ l μ p 2 2 τ l τ p μ 4 τ μ p 2 τ p μ l τ l as this distribution is a mixture of four different gaussian distributions to draw a sample from it a uniformly distributed random number is first drawn to decide which gaussian distribution will be used then a realization of s i will be drawn from the selected gaussian distribution each s i is drawn sequentially until the entire s is updated the sample of the reaction rate coefficient k is drawn using metroplis hastings sampler during the j th iteration of mcmc the reaction rate coefficient k j 1 draw a candidate k from proposal distribution q k j 1 where k j 1 is the accepted reaction rate sample from the j 1 th iteration in this paper q k j 1 n k j 1 k j 1 5 is used as the proposal distribution 2 calculate acceptance ratio α min 1 p k y s p k j 1 y s where p k y s is computed as eq 15b 3 draw a random number u from a uniform distribution u 0 1 if u α set k j k otherwise set k j k j 1 based on samples from the posterior distribution structural parameters θ σ 2 σ k μ k are optimized using the expectation maximization method following steps in michalak and kitanidis 2003 1 start with an initial guess of θ σ 2 σ k and μ k which are denoted as θ 0 σ 2 0 σ k 0 and μ k 0 2 draw a large number of samples from the posterior distribution using the structural parameters from last iteration which are θ j 1 σ 2 j 1 σ k j 1 and μ k j 1 3 compute θ j which maximizes the objective function xii φ θ θ j 1 n σ l 1 n ln p s compute σ 2 j which maximizes the objective function xiii φ σ 2 σ 2 j 1 n σ l 1 n ln p y s k compute σ k j and μ k j which maximize the objective function xiv φ σ k μ k σ k j μ k j 1 n σ l 1 n ln p k 4 iterates until all the structural parameters converge appendix b individual inverse approach the individual inverse approach for estimating the transfer function was firstly presented in fienen et al 2006 the authors used a similar methodology reflected brownian distribution as the prior distribution gibbs sampling for estimating the transfer function and expectation maximization for estimating the structural parameters however when estimating the conservative tracer or reactive tracer transfer function the authors only used the conservative or the reactive tracer dataset from eq 6 a linear relationship between the conservative tracer and reactive tracer transfer functions can be revealed in the log scale as xv k τ ln s t s r thus given any pair of individually estimated conservative tracer and reactive tracer transfer functions the reaction rate coefficient k can be estimated by a linear regression approach according to eq xv appendix c estimates of structural parameters fw 101 2 θ is estimated to be 6699 σ 2 is estimated to range in 1 46 10 21 0 0017 fw 102 3 θ is estimated to be 22335 σ 2 is estimated to range in 1 48 10 21 0 0037 fw 26 θ is estimated to be 3883 σ 2 is estimated to range in 3 40 10 20 0 0010 
6900,we present a joint bayesian inverse method for analyzing conservative and reactive tracer data which estimates non parametric transfer functions and effective first order reaction rate coefficients simultaneously a stochastic sampling approach based on markov chain monte carlo mcmc methods was used to simulate samples from the posteriors with a metropolis within gibbs sampler used for transfer functions and reaction rate coefficients non negativity constraints were realized by choosing a reflected gaussian prior for the transfer function and a lognormal prior for the reaction rate coefficient the approach was tested by synthetic sparse datasets with introduced normal random errors or periodic errors and then it was applied to the tracer test data collected at oak ridge national laboratory the results indicate that the developed approach was well capable of characterizing anomalous transfer functions such as multi modal functions and quantifying the uncertainty of both transfer functions and reaction rate coefficients in particular compared with the approach of individual inversion of sparse data the joint inversion approach taking advantage of the sharing of information regarding transport processes across the conservative tracer and reactive tracer data leads to the improved estimation of transfer functions and reaction rate coefficients for sparse datasets keywords break through curves tracer test joint analysis bayesian inverse modeling mcmc 1 introduction to characterize transport in the subsurface conservative tracers such as bromide are usually injected into the subsurface and their concentration breakthrough curves btcs are measured in down gradient sampling wells comparing the conservative tracer btcs with the reactive tracer btcs one may demonstrate the effect of undergoing reactions and estimate the effective reaction rate coefficients a common approach to analyze such btcs is to develop transport models and fit the conservative tracer and reactive tracer data either sequentially or jointly luo et al 2006 massoudieh et al 2014 mccallum et al 2014 toride et al 1993 turnadge and smerdon 2014 sequential approaches typically use conservative tracer data first to calibrate a transport model and then take the fitted model as the true model to estimate reaction rates by fitting the reactive data joint approaches use both conservative and reactive data to simultaneously fit a transport model and the corresponding reaction rate sequential approaches are computationally more efficient but they ignore the uncertainties associated with the fitted transport models when fitting the reactive tracer data they also ignore the fact that reactive data also contain useful information about physical transport processes joint approaches are more costly but they are better at exploiting the information reflected by the data particularly the information on transport processes shared by conservative and reactive data mechanistic transport models for fitting tracer data usually require that the spatial distributions of hydrological chemical and biological properties are known such characterization of the subsurface is limited at most sites thus modelers often simplify transport models e g by applying one dimensional models in which unresolved subsurface heterogeneities are inadequately parameterized as an alternative to the mechanistic transport model the transfer function approach is more flexible for analyzing tracer tests in linear transport systems as specific transport processes need not be defined and a detailed subsurface characterization is not required besbes and de marsily 1984 box et al 2015 cvetkovic et al 1996 jury 1982 jury et al 1982 liu and liu 1974 long and derickson 1999 a transfer function can characterize a linear transport system given prescribed input and output signals and once obtained can be used for the evaluation of btcs given any input signal the transfer function of a conservative tracer can be interpreted as the tracer recovery times the travel time distribution which may be applied in the stochastic convective framework to simulate either linear or nonlinear reactive transport systems cirpka and kitanidis 2001 ginn 2001 ginn et al 1995 both parametric and nonparametric approaches have been developed for estimating transfer functions as examples of parametric transfer function models lognormal and inverse gaussian distributions were used for the representation of transfer functions in groundwater cirpka and kitanidis 2001 shapiro and cvetkovic 1988 simmons 1982 simmons et al 1995 luo et al 2006 used gamma functions to jointly estimate transfer functions and first order reaction rates for analyzing tracer tests conducted at the field research center of oak ridge national laboratory recently long tailed distributions such as the tempered one sided stable distribution have attained more popularity cvetkovic 2011 however when estimating parametric transfer functions one pre defines the type or shape of the functions which is similar to defining specific transport processes in mechanistic transport models by contrast non parametric approaches that do not define the shape of the transfer functions are more flexible in describing tracer tests in complex subsurface fienen et al 2006 developed a bayesian inversion approach based on a markov chain monte carlo mcmc sampling method for analyzing the tracer tests at the oak ridge field research center which recognizes the transfer function as a gaussian process in the time domain and utilizes gesotatistical kernel functions to describe its correlated structure parametric and non parametric analysis yielded a similar estimation of reaction rate coefficients but the non parametric transfer functions revealed multi modal behavior that could not be described by gamma functions however the inversion of conservative and reactive tracer test data was conducted separately and the reaction rate coefficients were evaluated via simple linear regression that is conservative and reactive transport were considered as two independent linear systems and their transfer functions were obtained by individually inversing the conservative and reactive btcs the information shared across the datasets was completely ignored in addition both parametric and non parametric approaches mentioned above considered reaction rate coefficients as constants which were estimated through optimization without considering the associated uncertainty even though individual members of the conditional ensembles could have been used to estimate the uncertainty of reaction rate coefficients the limited number of available points for regression and the disconnection between individually generated samples could bias the best estimate and jeopardized the uncertainty characterization of the reaction rate coefficient cirpka et al 2007 chose a different approach of non parametric deconvolution by enforcing non negativity using the method of lagrange multipliers which is more computationally efficient than an mcmc approach this approach generated conditional realizations to account for the uncertainty of transfer functions and has also been applied to estimate reactive parameters based on tracer data knapp et al 2015 lemke et al 2014 the present study extends the previous non parametric approach of fienen et al 2006 to develop a new bayesian inversion approach to jointly inverse conservative and reactive tracer data for estimating non parametric transfer functions and effective reaction rate coefficients bayesian inverse modeling has many advantages over other methods because it combines information from data and prior knowledge and quantifies the uncertainty of all involved parameters the new approach quantifies the uncertainty of reaction rate coefficients in a bayesian framework estimates transfer functions using both conservative and reactive data and thus is particularly useful for sparse data sets this paper is organized as follows section 2 describes the forward mathematical model to model the tracer tests section 3 presents the detailed solution procedures including the joint bayesian inversion approach and the markov chain monte carlo mcmc sampling approaches in section 4 two synthetic data cases are used to verify the new approach finally in section 5 the new approach is applied to analyze the tracer tests conducted at the oak ridge field research center and the results are compared to published results 2 forward modeling for a time invariant linear system the concentration of the tracer measured in a monitoring well can be described by the well known linear convolution principle 1 y t t 0 t x t τ s t t τ d τ where y t represents the tracer concentration in the monitoring well s t represents the transfer function describing the tracer transport for a unit pulse input at time zero x t represents the tracer concentration in the injection well the transfer function is identical to the btc corresponding to a unit impulse injection the forward convolution model can be numerically formulated as 2 y t h s t v t where y t represents an n 1 1 discrete concentration observation at a monitoring well s t represents an m 1 transfer function of tracer concentrations on a desirable discretization h represents an n 1 m sensitivity matrix that works as a numerical convolution operator in this particular case fienen et al 2006 3 h n m 1 2 x t τ 1 δ τ 0 0 0 1 2 x t τ 2 δ τ 1 2 x t τ 1 δ τ 0 0 1 2 x t τ m 1 δ τ x t τ m 2 δ τ 1 2 x t τ 1 δ τ 1 2 x t τ 1 δ τ 1 2 x t τ m δ τ x t τ m 1 δ τ x t τ 2 δ τ 1 2 x t τ 2 δ τ 0 1 2 x t τ m δ τ x t τ 3 δ τ 1 2 x t τ 3 δ τ 0 0 1 2 x t τ m δ τ 1 2 x t τ m 1 δ τ 0 0 0 1 2 x t τ m δ τ v t represents an n 1 1 random error vector incurred by inappropriate model formulations measurement errors discretization inaccuracy etc with refined discretization errors from numerical computation will become negligible compared to measurement and conceptual model errors in this paper we assume that all errors are uncorrelated v t is assumed to be from a gaussian distribution with the following properties 4 μ v t 0 σ v t d σ v t 2 where d represents a n 1 n 1 diagonal matrix and σ v t 2 represents the variance of measurement and model error in certain cases σ v t 2 σ v t 2 1 where σ v t 2 represents a single variance parameter and 1 represents a n 1 1 vector with all ones this simplification assumes different variances for the measurements at different spatial or temporal locations however the simplified gaussian random error model may lose validity in cases where the epistemic error or the measurement error exhibits highly non gaussian behaviors for simplicity following the previous studies fienen et al 2006 luo et al 2006 we consider a linear reactive system with an effective first order reaction rate to quantify the overall reaction behavior the concentration of reactive tracers can be evaluated by 5 y r t 0 t x r τ s r t τ d τ 0 t x r τ s t t τ exp k t τ d τ where y r represents the concentration of the reactive tracer at a monitoring well x r represents the injection history of the reactive tracer at the injection well and s r represents its transfer function which is related to the transfer function of the conservative tracer by 6 s r τ s t τ exp k τ accordingly the linearized forward model of the reactive tracer can be written as 7 y r h r s t v r where y r represents an n 2 1 discrete concentration observation at a monitoring well v r represents an n 2 1 random error vector involved in the process with u v r 0 and σ v r d σ v r 2 and h r represents an n 2 m sensitivity matrix given as 8 h r h d exp k τ where d represents an m m diagonal matrix and τ represents the discretized time difference it is noted that both forward models depend on the transfer function of the conservative tracer and its information is reflected in both conservative and reactive btcs to jointly analyze conservative tracer data and reactive tracer data the following linearized forward model is adopted 9 y h j s t v where y y t y r t represents the n 1 n 2 1 discrete concentration observation at a monitoring well s t represents the transfer function of tracer on a desired discretization h j h h r t represents the n 1 n 2 m sensitivity matrix and v represents an n 1 n 2 1 random error vector with μ 0 and σ d σ 2 with d representing a n 1 n 2 n 1 n 2 diagonal matrix and σ 2 representing the variance vector of the error 3 bayesian inverse modeling in the chosen bayesian framework the conservative tracer transfer functions and the reaction rate coefficients are estimated by deriving their full conditional distributions and simulating distribution samples using the mcmc method 3 1 full conditional distributions starting point is bayes theorem applied to values of the transfer function s and the reaction rate coefficient k 10 p s k y p y s k p s k to apply gibbs sampling geman and geman 1984 to simulate samples of s and k from the posterior distribution their full conditional distributions need to be derived which are the conditional distributions of s and k given each other and the data y the full conditional distributions are 11 p s y k p y s k p s k p k y s p y s k p s k where p s y k and p k y s represent the full conditional distributions of transfer functions and reaction rate coefficients p y s k represents the likelihood function which describes constraints imposed by available measurements p s k represents the joint prior distribution of transfer functions and reaction rates the prior distribution contains prior knowledge and constraints on these variables to simplify the expressions of the distributions further we assume that the transfer function s and reaction rate coefficient k are independent variables prior to conditioning on the tracer data then the following equations could apply p s k p s p k where p s and p k represent the prior distributions of the transfer function s and the reaction rate coefficient k respectively the final full conditional distributions are written as 12 p s y k p y s k p s p k y s p y s k p k the likelihood function has the following form 13 p y s k 1 2 π n 2 σ 1 2 exp 1 2 y h j k s t σ 1 y h j k s where σ represents the covariance matrix of random error v d σ 2 σ represents the determinant of matrix σ the index k following h j expresses that the discretized transfer function of the reactive compounds depends on the reaction rate coefficient so that h j k has to be reevaluated for each k value as negative values are prohibited in transfer functions negative concentration does not exist a reflected gaussian distribution is selected as the prior of s fienen et al 2006 michalak and kitanidis 2003 p s π i 2 m p s i s i 1 p s i s i 1 1 2 π θ t i t i 1 exp 1 2 s i s i 1 2 2 θ t i t i 1 exp 1 2 s i s i 1 2 2 θ t i t i 1 f o r s i 0 14 p s i s i 1 0 f o r s i 00 where θ represents the slope of a linear variogram model assumed for the autocorrelation of s fienen et al 2004 s i represents the transfer function estimated at time increment t i s i 1 represents the transfer function estimated at time increment t i 1 t i t i 1 represents the separation distance in time domain michalak and kitanidis 2003 a lognormal distribution is selected as the prior of the reaction rate coefficient to enforce non negativity 15 p k 1 k σ k 2 π exp ln k μ k 2 2 σ k 2 where μ k represents the prior mean of ln k σ k represents the prior standard deviation of ln k combining the priors of s and k with the likelihood function the full conditional distributions can be constructed as below 16a p s y k π i 2 m p s i s i 1 1 σ exp 1 2 y h j k s t σ 1 y h j k s 16b p k y s 1 k σ k 2 π exp ln k μ k 2 2 σ k 2 1 σ exp 1 2 y h j k s t σ 1 y h j k s then we follow the same procedure as shown in michalak and kitanidis 2003 to formulate the full conditional distribution of s i the discretized transfer function at time increment i details can be found in appendix a 3 2 implementation of inversion markov chain monte carlo mcmc methods are implemented to draw samples from the derived distributions chen et al 2008 chen et al 2004 wainwright et al 2014 wainwright et al 2015 s i and k are sampled consecutively using a gibbs sampler geman and geman 1984 as shown by michalak and kitanidis 2003 p s i s i y k can be proportionally sampled from a gaussian mixture model but p k y s has a complicated form from which direct sampling will be impossible instead the metropolis hastings sampling method is used to draw samples of k from the full conditional distribution chib and greenberg 1995 chib and jeliazkov 2001 hastings 1970 metropolis et al 1953 thus strictly speaking a metropolis within gibbs sampling method is implemented for drawing samples of s k a detailed procedure of the implementation is described in the appendix b in which we also include the expression of the proposal distribution of metropolis algorithm the chain convergence is justified according to gelman and rubin 1992 which requires the computation of chain summary statistics as the convergence criteria in our implementations we adopt 3000 mcmc iterations 1000 as the burn in period as it guarantees convergence and gives sufficient samples for inference σ 2 θ μ k and σ k 2 are estimated using an expectation maximization method dempster et al 1977 mclachlan and krishnan 2007 which iteratively optimizes these parameters using conditional realizations of the latent variables s and k in our synthetic and field experiments em iterations required for parameter convergence are between 4 and 6 iterations to achieve faster convergence in the em optimization step the reaction rate coefficient k could be initialized using a gamma function approach as done by luo et al 2006 our algorithm for joint inversion is summarized in fig 1 4 benchmark problems in order to verify the effectiveness of the developed joint inversion method synthetic input and output data with known transfer functions are generated as benchmark problems all generated quantities are dimensionless the first example is from neuman and de marsily 1976 where the transfer function is unimodal the second example is from fienen et al 2006 where the transfer function is a bimodal function synthesized by two gaussian probability distribution functions these two examples were also used by fienen et al 2006 as benchmark problems to verify their mcmc scheme we re examine these two examples to show how our joint analysis will perform in estimating conservative tracer transfer functions s the reaction rate constant k and quantifying the associated uncertainties the expressions of transfer functions used in our synthetic study are summarized in table 1 however different from the individual approach proposed in fienen et al 2006 which only requires conservative datasets the joint inverse approach requires both conservative and reactive datasets thus using relationship s r t s t t exp k t the reactive tracer transfer function s r t is generated using the conservative tracer transfer function s t t and the prescribed reaction rate coefficient k the conservative output dataset y t and the reactive output dataset y r are computed using the convolution equations listed in table 1 in sections 4 1 and 4 2 the correctness of the proposed joint inverse approach is verified using the two synthetic datasets the reaction rate coefficient is set to be k 1 t 1 for significant differences between conservative and reactive recovery curves without loss of generality only the conservative tracer transfer function is inversed and compared with the true synthetic values in section 4 3 we compared the performance of the joint inverse approach and the individual approach on a sparse synthetic dataset 4 1 error free cases we implement the joint inversion approach to estimate the conservative tracer transfer functions in the time domain t 0 8 with δ t 0 2 in the unimodal case and those in the time domain t 0 3 with δ t 0 1 in the bimodal case the prescribed the dimensionless reaction rate coefficient is k 1 for both cases the dash lines in fig 2 a 1 and a 2 show the error free x and y data used for inversion and the deconvolution results for each point of the transfer function s in the computational domain or the reaction rate coefficient k there are 2000 realizations simulated from its posterior the inverse results of the unimodal and bimodal cases are shown in fig 2a 3 and b 3 the best estimates of the transfer function greatly fit the synthetic true functions with tight confidence intervals compared with the results obtained in fienen et al 2006 the estimated confidence intervals are slightly larger which is due to the uncertainty contribution from reaction rate coefficients for the unimodal case the best estimate of reaction rate coefficient is k 1 0051 with the 95 confidence interval 0 9894 1 0203 for the bimodal case the best estimate of reaction rate coefficient is k 1 0001 with the 95 confidence interval 0 9907 1 0096 in both cases the joint inversion provides an accurate estimation of reaction coefficients with very tight confidence intervals the prescribed reaction rate coefficient are included in both confidence intervals in both testing examples the initial guess of k is 0 9 4 2 error involved cases errors are added to the synthetic data x and y according to equations in table 1 after adding errors any existing negative values in x e r r o r t and y e r r o r t are set to be zero error involved x and y data used for inversion and the deconvolution results are shown as markers in fig 2a 1 and a 2 the inverse results of the unimodal and bimodal cases are shown in fig 2a 4 and b 4 the best estimates of the conservative tracer transfer functions deviate more from the true transfer functions compared to the error free cases however most of the true conservative tracer transfer functions are contained within the confidence intervals in the unimodal case the best estimate of the reaction rate coefficient is k 1 0031 with the 95 confidence interval 0 9811 1 0264 in the bimodal case the best estimate of the reaction rate coefficient is k 0 9703 with the 95 confidence interval 0 9403 1 0017 confidence intervals of conservative tracer transfer functions s t and reaction coefficients k in error involved cases are slightly larger than those in the error free cases larger confidence intervals are normal for error contaminated data due to the uncertainties caused by errors nevertheless the joint inversion method provides good estimates of the conservative tracer transfer functions capturing their inherent patterns and provides accurate estimates of the reaction rate coefficients with their uncertainty quantification in addition the joint inversion approach demonstrates its ability to capture the main features of transfer functions when the dataset is involved with noises the joint inversion algorithm requires an initial guess of the reaction rate coefficient k to construct the sensitivity matrix h j according to our experimental results different initial guesses of the reaction rate coefficient k makes no difference in the best estimates of the interested variables s t and k for the presented cases the joint inversion is not sensitive to the initial guess of k however with a biased initial guess the joint inversion will take more em iterations to reach convergence in the following cases close initial guesses are used to guarantee a faster convergence 4 3 effectiveness for sparse dataset as mentioned in former sections the joint inverse method could jointly utilize conservative and reactive data so that the inversion is better at exploiting the whole dataset in order to show the efficient use of data via joint analysis we reexamine the sparse error contaminated dataset in fig 2b 2 we run both joint inversion and individual inversion to estimate the conservative tracer transfer function in the experiment the individual approach will only use the conservative dataset for the inference of the conservative tracer transfer function deconvolution results using the two approaches are shown in fig 3 the estimate of the conservative tracer transfer function using the joint approach has a much better quality than that of the individual approach firstly the joint approach is able to recognize the bimodal pattern in the transfer function while individual inversion only recognizes a fat tail secondly the true transfer function is contained better within the confidence intervals in the joint inversion method the reason is that the reactive data also contain information of the conservative tracer transfer function joint inversion integrates such information to characterize the conservative tracer transfer function the best estimate of reaction rates using the joint inverse method is the same as in section 4 2 for sparse datasets the joint approach can take advantages of both conservative and reactive data to provide an accurate estimation of the conservative tracer transfer function s t and the reaction rate coefficient k and quantify the uncertainty for all the interested variables 5 application to field data fig 4 shows the plan view of a multiple well system used in the field experiments at oak ridge fienen et al 2006 luo et al 2007 wu et al 2006a wu et al 2006b as this site was contaminated with uranium in situ bioremediation was implemented for uranium reduction and immobilization ethanol was used as the electron donor in the bioremediation experiments tracer tests were conducted in this multiple wells system to determine the reaction rate coefficients of the injected ethanol as shown in fig 4 the well fw 104 was the injection well into which both the conservative tracer bromide and the reactive tracer ethanol were introduced the injection history was treated as the input function x incomplete concentration recovery of bromide and ethanol was recorded at the multilevel sampling ports fw100 fw 101 and fw 102 and the extraction well fw 26 to demonstrate the data sparsity in a better way tracer data of well fw 101 2 fw 102 3 and fw 26 are plotted in fig 5 the conservative tracer data behaves similarly to the reactive tracer data and they are assumed to follow the same transport process luo et al 2006 but the sparsity of reactive data is much more significant than that of conservative data these records were used as the output function y a detailed description of the well system and the tracer test are in wu et al 2006b using collected field data both joint and individual inversion are implemented to estimate the conservative tracer and reactive tracer transfer functions and the effective first order reaction rate coefficients best estimates and uncertainty bounds of the transfer functions at different observation wells are shown in fig 6 the estimates of the conservative tracer transfer functions are very similar between the two methods because the number of conservative tracer measurements is sufficiently large by contrast the estimates of the reactive tracer transfer functions differ significantly between the two methods because 1 the number of reactive compound measurements is small luo et al 2006 2 in the individual approach the reactive tracer transfer function is estimated without enforcing eq 6 the inversion results using the joint approach are constrained by conservative tracer data reactive tracer data and the interdependence between conservative tracer and reactive tracer transfer functions defined by eq 6 the reaction rate coefficients k estimated by the joint inversion method are in good accordance with values obtained in luo et al 2006 and fienen et al 2006 the estimates from the three papers are listed in table 2 this is also the first time that the uncertainty bounds of the reaction rate coefficient are provided for the ornl data it is worth noting that an ensemble of the reaction rate coefficient can also be generated by the individual approach by fitting a pair of the conservative tracer transfer function and the reactive tracer transfer function however as the time length and the frequencies of reactive data are much lower than those of conservative data to estimate the reaction rate coefficient using the individual inversion the conservative tracer transfer function has to be truncated to the same time length and frequency for the linear regression approach and only a limited number of points in the conservative tracer transfer functions can be used for estimation in addition in the individual approach as the conservative tracer transfer function and the reactive tracer transfer function are estimated separately there is no one to one relationship between any two realizations from each group thus the choice of the transfer function realizations for estimating reaction rate coefficients is quite arbitrary on the other hand for the uncertainty quantification joint inversion yields a better accordance between each individual estimate of reaction rate coefficients and each individual estimate of transfer functions which prevents other uncertainty sources the best estimates and the 95 percent confidence intervals of the reaction rate coefficients determined from the tracer btcs in the different wells are shown in table 2 with other published results it should be noted that the proposed joint approach relies on prior knowledge of the underlying reaction process which can be misleading in real world applications in the scenario that the underlying reaction process is unknown a model selection approach is required the model selection can be achieved by the proposed methodology as expectation maximization provides the evidence lower bound which gives different credits to competing models and helps to reveal the true underlying process the optimized θ and σ 2 values of the field case are recorded in the appendix c as the maximum of the conservative tracer transfer function in fw 102 3 is higher it is supposed to have less smoothness compared to the conservative tracer transfer function estimates in the other two wells which is proved by the highest θ value of the conservative tracer transfer function in fw 102 3 on the other hand the conservative tracer transfer function in fw 26 has the smallest θ estimate which is in accordance with the fact that it has the smallest maximum the optimized σ 2 values are higher than the measurement error for some data points which means that there are other error sources involved in this process 6 conclusion we have extended the bayesian inverse modeling approach developed by fienen et al 2006 to jointly estimate non parametric conservative tracer transfer functions and effective reaction rate coefficients of reactive tracers the metropolis within gibbs sampler was implemented to simulate samples from the full conditional distributions to guarantee non negativity reflected gaussian distributions were used as a prior for the transfer functions and a lognormal distribution for the effective reaction rate coefficient we tested our approach by both synthetic data sets and field tracer tests and demonstrated that the developed joint inversion approach is advantageous in comparison to previous parametric and non parametric approaches as a non parametric approach the developed approach clearly demonstrated its capability for characterizing anomalous transfer functions such as multi modal functions without pre defining the shape of the transfer functions in addition our approach quantifies the uncertainty of the effective first order reaction rate coefficients without any post processing more importantly the joint inversion approach used both conservative tracer and reactive tracer data for estimating transfer functions which are particularly useful for sparse datasets in synthetic cases the computational time intel core i7 3770 cpu 3 40 ghz and 32 gb ram of the unimodal case is around 150 s and that of the bimodal case is around 200 s in field data cases the computational time ranges from 670 s 1070 s our developed approach was based on the assumption of the effective first order reactions such estimates provide lumped information useful in practice for adjusting operational parameters of remediation such as the concentration of injected chemical compounds and injection duration and frequency however it is possible that the joint inversion with the assumption of linear system behaviors introduces additional errors in estimating transfer functions for nonlinear reactive systems thus in reaction systems where effective first order reactions may oversimplify the reaction kinetics it may be better to apply a stochastic convective approach to account for nonlinear reaction kinetics and combine this with a transfer function approach simmons et al 1995 for example diem et al 2013 assumed zero order decay of oxygen upon river bank filtration and applied a stochastic convective approach the developed bayesian model may be extended to include model uncertainties when there are multiple competing reaction models available elsheikh et al 2014 schöniger et al 2014 acknowledgment the study was supported by usgs 2017ga377b we thank dr cirpka dr fienen and other reviewers for their constructive comments on the original manuscript their comments helped us improve the work quality significantly we also want to thank dr fienen for his generosity in providing us the field data and the former research code appendix a sampling scheme and expectation maximization in this paper we followed the procedures of michalak and kitanidis 2003 to launch a gibbs sampler to infer transfer functions of conservative and reactive tracer the most critical point for successful implementation of a gibbs sampler is the derivation of marginal distributions of interested variables according to eq 16a and michalak and kitanidis 2003 the marginal distribution of s i with respect to the rest unknown variables can be formulated as i p s i s i y 1 2 π τ l exp 1 2 s i μ l 2 τ l 1 2 π τ p p 1 exp 1 2 s i μ p 1 2 τ p p 1 exp 1 2 s i μ p 1 2 τ p p 2 exp 1 2 s i μ p 2 2 τ p p 2 exp 1 2 s i μ p 2 2 τ p where s i represents all the values of s except s i ii p 1 exp s i 1 s i 1 2 4 θ t i 1 t i 1 exp s i 1 s i 1 2 4 θ t i 1 t i 1 exp s i 1 s i 1 2 4 θ t i 1 t i 1 iii p 2 1 p 1 iv μ p 1 s i 1 t i t i 1 s i 1 t i 1 t i t i 1 t i 1 v μ p 2 s i 1 t i t i 1 s i 1 t i 1 t i t i 1 t i 1 vi τ p 2 θ t i t i 1 t i 1 t i t i 1 t i 1 eq 1 can be further simplified to be a mixture gaussian model which is formulated as vii p s i s i z σ j 1 4 k j 2 π τ p τ l exp 1 2 s i μ j 2 τ where τ τ p τ l τ p τ l viii k 1 p 1 exp 1 2 μ l μ p 1 2 τ l τ p μ 1 τ μ p 1 τ p μ l τ l ix k 2 p 1 exp 1 2 μ l μ p 1 2 τ l τ p μ 2 τ μ p 1 τ p μ l τ l x k 3 p 2 exp 1 2 μ l μ p 2 2 τ l τ p μ 3 τ μ p 2 τ p μ l τ l xi k 4 p 2 exp 1 2 μ l μ p 2 2 τ l τ p μ 4 τ μ p 2 τ p μ l τ l as this distribution is a mixture of four different gaussian distributions to draw a sample from it a uniformly distributed random number is first drawn to decide which gaussian distribution will be used then a realization of s i will be drawn from the selected gaussian distribution each s i is drawn sequentially until the entire s is updated the sample of the reaction rate coefficient k is drawn using metroplis hastings sampler during the j th iteration of mcmc the reaction rate coefficient k j 1 draw a candidate k from proposal distribution q k j 1 where k j 1 is the accepted reaction rate sample from the j 1 th iteration in this paper q k j 1 n k j 1 k j 1 5 is used as the proposal distribution 2 calculate acceptance ratio α min 1 p k y s p k j 1 y s where p k y s is computed as eq 15b 3 draw a random number u from a uniform distribution u 0 1 if u α set k j k otherwise set k j k j 1 based on samples from the posterior distribution structural parameters θ σ 2 σ k μ k are optimized using the expectation maximization method following steps in michalak and kitanidis 2003 1 start with an initial guess of θ σ 2 σ k and μ k which are denoted as θ 0 σ 2 0 σ k 0 and μ k 0 2 draw a large number of samples from the posterior distribution using the structural parameters from last iteration which are θ j 1 σ 2 j 1 σ k j 1 and μ k j 1 3 compute θ j which maximizes the objective function xii φ θ θ j 1 n σ l 1 n ln p s compute σ 2 j which maximizes the objective function xiii φ σ 2 σ 2 j 1 n σ l 1 n ln p y s k compute σ k j and μ k j which maximize the objective function xiv φ σ k μ k σ k j μ k j 1 n σ l 1 n ln p k 4 iterates until all the structural parameters converge appendix b individual inverse approach the individual inverse approach for estimating the transfer function was firstly presented in fienen et al 2006 the authors used a similar methodology reflected brownian distribution as the prior distribution gibbs sampling for estimating the transfer function and expectation maximization for estimating the structural parameters however when estimating the conservative tracer or reactive tracer transfer function the authors only used the conservative or the reactive tracer dataset from eq 6 a linear relationship between the conservative tracer and reactive tracer transfer functions can be revealed in the log scale as xv k τ ln s t s r thus given any pair of individually estimated conservative tracer and reactive tracer transfer functions the reaction rate coefficient k can be estimated by a linear regression approach according to eq xv appendix c estimates of structural parameters fw 101 2 θ is estimated to be 6699 σ 2 is estimated to range in 1 46 10 21 0 0017 fw 102 3 θ is estimated to be 22335 σ 2 is estimated to range in 1 48 10 21 0 0037 fw 26 θ is estimated to be 3883 σ 2 is estimated to range in 3 40 10 20 0 0010 
6901,we define model data interaction mdi as a two way process between models and data in which on one hand data can serve the modeling purpose by supporting model discrimination parameter refinement uncertainty analysis etc and on the other hand models provide a tool for data fusion interpretation interpolation etc mdi has many applications in the realm of groundwater and has been the topic of extensive research in the groundwater community for the past several decades this has led to the development of a multitude of increasingly sophisticated methods the progress of data acquisition technologies and the evolution of models are continuously changing the landscape of groundwater mdi creating new challenges and opportunities that must be properly understood and addressed this paper aims to review analyze and classify research on mdi in groundwater applications and discusses several related aspects including 1 basic theoretical concepts and classification of methods 2 sources of uncertainty and how they are commonly addressed 3 specific characteristics of groundwater models and data that affect the choice of methods 4 how models and data can interact to provide added value in groundwater applications 5 software and codes for mdi and 6 key issues that will likely form future research directions the review shows that there are many tools and techniques for groundwater mdi and this diversity is needed to support different mdi objectives assumptions model and data types and computational constraints the study identifies eight categories of applications for mdi in the groundwater literature and highlights the growing gap between mdi practices in the research community and those in consulting industry and government keywords model data interaction groundwater modeling uncertainty analysis data assimilation data fusion 1 introduction the complexities of physics based numerical models of groundwater flow and contaminant transport have grown substantially since the 1990s moving from early two dimensional steady state homogeneous or layer cake models to dynamic three dimensional models capable of simulating highly heterogeneous formations and complex phenomena such as coupled and multiscale processes this growing sophistication has resulted in models with significantly more data requirements compared to the past in the last three decades we have also seen a significant increase in the role of groundwater models in decision making processes refsgaard et al 2010 models are now used throughout the world to assist decision making on issues such as optimal groundwater extraction e g ketabchi and ataie ashtiani 2015a b triki et al 2017 groundwater contamination response e g ritzel et al 1994 aquifer recharge and recovery drumheller et al 2017 groundwater remediation and cleanup e g bayer and finkel 2004 2007 singh and minsker 2008 and determination of wellhead protection areas e g wheater et al 2000 feyen et al 2001 the increasing role of models in decision making means that models are required to provide more reliable predictions with proper estimation of prediction uncertainties regardless of a model s level of complexity this can only be achieved if the appropriate data are available and effectively incorporated into the modeling process in parallel hydrogeology has also become increasingly data rich due to the significant progress made in technologies that enable the collection transfer and storage of data fasbender 2008 barnhart et al 2010 advances in geophysical remote sensing e g satellite imaging smart meter and field sensor technologies have led to a massive upsurge in data quantity and diversification of data types moreover thanks to the impressive developments in communication technologies such as wireless sensor networks wsns data can now be delivered at extremely higher rates the past two decades have also seen the creation and expansion of many national and regional databases for geologic and groundwater related data e g united states geological survey groundwater database https water usgs gov ogw data html south africa national groundwater archive http www dwa gov za groundwater nga aspx etc in which a massive amount of data is being continuously collected szalkai et al 2007 these data related developments have created new challenges such as online data heterogeneous data and massive data issues which are well known challenges in some other fields of science but were not previously encountered by the groundwater modeling community hayley 2017 these trends have changed our conception of the relationship between models and data traditionally this relationship was mainly concerned with employing data for model calibration and validation but in a broadened and increasingly popular perspective that we refer to as model data interaction mdi this relationship is viewed as a two way process in which on one hand data can serve the modeling purpose by supporting model refinement discrimination uncertainty analysis etc and on the other hand models can provide a framework for guidance of data collection and data analysis by assisting data fusion interpretation interpolation etc to the author s knowledge the term mdi has not been previously used in the groundwater literature to describe this two way process but it has been used in some other fields of science and engineering e g norby et al 2016 from this perspective mdi offers great potential a number of which we review below such as sources of data in groundwater studies are numerous but no single data source can provide a complete picture of a groundwater system linde et al 2017 and therefore multiple data sources must be integrated in many instances the nature and spatiotemporal scale of hydrogeologic data is so diverse that they are not readily related to one another making data integration very difficult porter et al 2000 in these increasingly familiar situations mdi provides a unique framework for integrating multiple types of data and for solving related problems such as data conflict detection and resolution and outlier detection brunner et al 2017 with the progress of measurement technologies we are approaching a state where we are no longer hindered by the power to collect more data but by our ability to extract valuable information from available data in these circumstances mdi opens new opportunities for information extraction from different data types mdi can improve the performance of groundwater models and open the model structure selection and parameter estimation processes to new and previously untapped sources of information rajabi and ataie ashtiani 2016 this can alleviate the data scarcity problem frequently encountered in model construction efforts moreover there is a growing recognition of the importance of characterizing the uncertainties in our models and data beven 2010 in this sense mdi provides a consistent tool for examining all sources of uncertainty in a common framework data collection in groundwater studies is currently guided mostly by intuition and expert knowledge or by practical considerations rather than a quantitative understanding of what data will most reduce uncertainties and how much data are required to do so kikuchi et al 2015 in this context mdi techniques can be valuable tools in the guidance of groundwater data collection setting the stage for a shift of paradigm in this area mdi has been the topic of extensive research in the groundwater community for the past several decades leading to the development of a large number of increasingly sophisticated algorithms these studies have transformed mdi from the simple direct insertion of data into models to advanced sequential data assimilation techniques moradkhani et al 2005 liu et al 2012 a significant portion of the progress in groundwater mdi has originated from developments in other fields of science and technology such as meteorology atmospheric sciences oceanography robotics defense aerospace etc examples of reviews in these fields include ghil and malanotte rizzoli 1991 wang et al 2009 peng et al 2011 several issues have motivated us to write a review paper on groundwater mdi these include 1 recent trends that have changed the landscape of mdi in the groundwater literature creating new challenges and opportunities that must be properly understood and addressed 2 the multitude of mathematical algorithms presented in the literature for mdi that have made the topic confusing and hard to penetrate even for the experienced modeler and 3 lack of a comprehensive review on the subject although a number of notable reviews on related terms such as inverse modeling e g carrera et al 2005 2010 zhou et al 2014 and uncertainty analysis e g refsgaard et al 2012 wu and zeng 2013 linde et al 2017 are available the more general topic of mdi in the groundwater literature has not been yet reviewed the key objectives of this paper can be summarized as follows 1 to review the basic theoretical concepts and present a reasonably simple classification of different frameworks and algorithms for anyone interested in obtaining an overview of mdi 2 to analyze the pros cons and underlying assumptions of key algorithms with the intention of helping researchers and practitioners choose appropriate algorithms for various situations 3 to highlight different ways that models and data can interact to provide added value in groundwater applications 4 to identify codes and software previously used for mdi in the groundwater literature and explain key trends in this regard and 5 to identify key issues and gaps that will likely form future directions the outline of the paper is demonstrated in fig 1 it should be noted that almost every groundwater modeling study in the literature involves some component of mdi because as in any other field of engineering models without data are fantasy nisbet et al 2014 so it is rather impossible to be exhaustive in this review but we focus our review on a number of significant papers published largely over the last two decades which deal with novel formal mathematical algorithms for mdi the number of citations and our subjective judgment of the quality and significance of these papers has played a key role in their selection 2 review of theoretical concepts and techniques groundwater models are generic computer codes that use numerical algorithms to solve the partial differential equations that govern groundwater flow and also often contaminant transport these generic codes become site specific models when data obtained from a particular geographical area is used to 1 characterize the structure and parameters of the model these tasks are referred to as model structure identification and parameter estimation or model calibration respectively 2 test or validate the model in a procedure often referred to as model verification or validation the term model selection is also used in this regard if alternative plausible models exist konikow and bredehoeft 1992 oreskes et al 1994 beven 2018 the resulting models are used by research government and consulting communities for a variety of objectives including understanding of hydrogeological systems and their interacting components across different scales replication of past system behavior forecast of system responses to potential future stresses and management practices or to guide future data collection endeavors beven and young 2013 doherty and simmons 2013 as it is not possible for models to characterize groundwater systems perfectly model outputs should be associated with uncertainty intervals making uncertainty analysis an important part of the entire modelling process freeze et al 1990 1992 data can be used in a systematic way to refine both model predictions and their uncertainty estimates within the framework of different modeling objectives this procedure is often called state estimation model verification or selection parameter estimation guidance of future data collection and state estimation encompass different aspects of mdi the mdi process results in transformation of the initial datasets into new sets of data for instance assume that we are using sparse hydraulic conductivity k data obtained from pumping tests in conjunction with hydraulic head h data measured in a number of observation wells to estimate k values for a groundwater model through model calibration the original k values obtained from the pumping tests are rarely left unchanged by the time the model is calibrated the calibration hides some of the unknowns e g heterogeneity but also affects the representative scales as k values for the pumping tests may for instance represent a smaller region than the one being used in the calibration process moreover the calibration process uses sparse measurements of k to generate estimates that cover the entire modeling domain it also combines the information contained in k and h data to estimate the hydraulic conductivity these inevitable outcomes of mdi can be leveraged for a variety of purposes including customizing data resolution improving data coverage and fusing different forms of data 2 1 framework of model data interaction from the above discussions we can infer that mdi is not a one time occurrence but a continuous process that has many aspects and applications regardless of the intended application mdi rests on three foundations forward model data and synthesis method raupach et al 2005 a forward model of the system denoted by f propagates the state e g piezometric heads chemical concentrations temperatures etc at time y t to time y t 1 based on 1 a set of often assumed to be time invariant input parameters θ which include physical descriptions of subsurface characteristics e g porosity hydraulic conductivity etc and contaminant transport and transformation characteristics e g dispersivity sorption factor chemical reaction rates etc and 2 time dependent external forcing terms u t which include surface recharge lateral inflow river aquifer interactions etc this notion can be formulated as leisenring and moradkhani 2011 1 y t 1 f y t u t θ ω t where the generally state dependent and stochastic model error vector is represented by ω t and the conceptual and mathematical model structure is embedded in f this notion is schematically illustrated in fig 2 data denoted by d can be related to direct or indirect measurements hard data or qualitative assessments soft data of state variables d y external forcing terms d u parameters d θ or model structure d f moradkhani et al 2005 liu and gupta 2007 table 1 summarizes common types of data in groundwater mdi the measurement model or observation equation h t is the mapping from the parameters states and external forcing terms to the various types of data liu et al 2012 formulated as 2 d h t y t u t θ η t where the stochastic term η t represents observation error which is an inherent part of the measurement model the mean values of ω t and η t denote systematic bias and their covariance signifies the uncertainty in the model predictions and observations liu and gupta 2007 the mean and covariance of ω t and η t are generally not directly observable and are also difficult to estimate by indirect methods hence they are often assigned presumptive values a common practice is to assign uncorrelated gaussian distribution with zero mean i e white noise to ω t and η t e g fu and gómez hernández 2009 laloy et al 2013 the synthesis method is a formal mathematical algorithm that combines the model f and data d by varying some properties of the model to give their optimal combination accounting for the associated uncertainties wang et al 2009 keenan et al 2011 in general a host of methods exist for synthesis with widely varying degrees of sophistication it is important to realize that due to the diversity of model and data types and the various objectives and simplifying assumptions that are subsumed under mdi no universally best synthesis method exists porter et al 2000 peng et al 2011 zhou et al 2014 however groundwater mdi has several specific characteristics that affect the choice of a synthesis method 1 groundwater models are moderately to highly nonlinear samuel and jha 2003 schöniger et al 2012 wallis et al 2014 siade et al 2017 2 they result in state variables e g heads and concentrations that are time dependent eigbe et al 1998 3 they are commonly cpu intensive and have high computational demands most notably in real world applications as they rely on large systems of equations that need to be solved for each model run carrera et al 2010 rajabi et al 2015b 4 they are inherently high dimensional with respect to parameters external forcing terms and states unless strict parameterization is employed siade et al 2017 5 their parameter and state variables exhibit non gaussianity in certain cases such as strong spatial heterogeneity of hydraulic conductivity contaminant transport with sharp fronts as in advection dominated processes and curvilinear crispy geometries e g river beds hendricks franssen et al 2009 hendricks franssen and kinzelbach 2009 schöniger et al 2012 crestani et al 2013 6 they are controlled by physical properties e g permeability that are characterized by a high degree of heterogeneity possess scales of variation spanning several orders of magnitude and are scale dependent hill and tiedeman 2006 kerrou et al 2008 7 complex interactions exist between different inputs of a groundwater model e g between hydraulic conductivity and dispersivity gelhar et al 1992 8 groundwater related observations are often sparse and incomplete as they include an inadequate set of points in space and time to fully characterize the groundwater system rajabi and ataie ashtiani 2016 and 9 groundwater related observations are commonly indirect and have scaling differences with model parameters states and external forcing terms carrera et al 2005 liu and gupta 2007 2 2 uncertainty in model data interaction mdi has proven to be promising in improving understanding quantification communication and reduction of uncertainty in both models and data freeze et al 1992 porter et al 2000 liu et al 2012 in many cases uncertainty analysis is embedded in the mdi process sources of uncertainty in groundwater modeling can be classified into the following four interconnected categories 1 structural uncertainty which arises from the fact that models are inherently simplified and imperfect approximations of complex real world processes neuman 2003 structural uncertainty includes conceptual uncertainty arising from e g characterization of heterogeneity patterns type of boundary conditions time regime etc and mathematical uncertainty arising from alternatives in the mathematical implementation of conceptual models bredehoeft 2005 ma and la pointe 2011 2 parameter uncertainty which results from the fact that groundwater model parameters are often aggregate quantities that should be estimated from sparse and sometimes indirect measurements or qualitative assessments across the heterogeneous geological domain yeh 1986 rajabi and ataie ashtiani 2014 3 data uncertainty which arises from instrument uncertainty due to imperfect measurement devices and representativeness uncertainty due to inconsistency in spatial and or temporal scales between the measured variables and the associated model variables liu and gupta 2007 4 extrapolation uncertainty which stems from the temporal prediction errors in the estimation of future external forcing terms from past data dessai and hulme 2007 when the past state of the groundwater system is being simulated structural parameter and data uncertainties collectively propagate through the model and result in model uncertainty alternatively when the future state is being predicted all four sources of uncertainty affect predictive uncertainty liu and gupta 2007 throughout this paper we will refer to both as model output uncertainty the above concepts are illustrated in fig 3 there is some dispute regarding which source dominates model uncertainty in groundwater simulations some references suggest parameter uncertainty e g smith and schwartz 1981 hendricks franssen and kinzelbach 2009 schöniger et al 2012 and others suggest structural uncertainty e g bredehoeft 2005 højberg and refsgaard 2005 refsgaard et al 2012 this dispute is partly due to the different approaches employed in handling uncertainty nevertheless there is a wide consensus that 1 structural uncertainty is the most difficult to quantify refsgaard et al 2006 2 ideally all sources of uncertainty should be simultaneously addressed to avoid misleading uncertainty predictions pappenberger and beven 2006 linde et al 2017 3 different uncertainty sources have distinct characteristics and hence require different approaches to deal with rajabi and ataie ashtiani 2016 and 4 a challenging and important aspect of quantifying model uncertainty is to account for the effect of interaction among different uncertainty sources liu et al 2012 a review of the literature shows that there are basically two approaches to handling different sources of uncertainty in groundwater mdi in the first approach different sources of uncertainty are explicitly lumped together and mapped into model parameters some have noted that this method can create bias in uncertainty estimation kerrou et al 2008 the second approach is to address different sources of uncertainty separately according to their specific characteristics the most common way to do this is to characterize parameter data and extrapolation uncertainties as continuous probability distributions often normal log normal or uniform rajabi et al 2015b structural uncertainty is commonly described by discrete scenarios for the model structure with probabilities assigned to the scenario s existence refsgaard et al 2012 this results in multi model ensembles which are formed for example by defining different parameterizations of the aquifer system e g feyen et al 2001 since the selection of individual models in the ensemble is mostly based on expert insight rather than formal methods this approach is quite subjective and the scenarios may not represent a complete sampling of the model space beven 1993 liu et al 2012 hence obtaining reliable uncertainty estimates becomes a matter of both chance and experience nonetheless since no other commonly accepted approach exists this remains the dominant approach 2 3 review of synthesis methods in this sub section we review and classify a number of key synthesis methods previously used in the groundwater literature for mdi a map of these methods is provided in fig 1 to guide the interested reader through this sub section the review is meant to provide an overview of methods and so the mathematical descriptions are kept to a minimum and references are provided for further reading 2 3 1 manual insertion direct and indirect methods in the simplest observation scenario the model structure and values of all model parameters θ external forcing terms u t and initial states y t are measured or inferred from data in other words adequate data is available to fully characterize the groundwater system perform model simulations by manual insertion and estimate the state variables at a later time y t 1 at all points in the discretized domain of the problem kerrou et al 2008 the resulting simulations can be augmented with forward uncertainty propagation analysis upa to characterize the effect of measurement noise on the uncertainty in state estimations e g rajabi and ataie ashtiani 2014 rajabi et al 2015a an alternative observation scenario is that data on some model parameters and external forcing terms is sparse but the state y is known exhaustively at all nodes of the discretized domain at times t and t 1 in this scenario the unknown variables of the model can be estimated by the direct approach of solving the inverse problem formulated simply as θ f 1 y t u t y t 1 often neglecting the stochastic ω t term neuman 1973 only if the relationship between model inputs and state variables are assumed to be linear can the solution be calculated by closed form matrix expressions wang et al 2009 even so a key challenge of the direct method is the ill posedness and the singularity of the matrices involved in the numerical formulation zhou et al 2014 some researchers have tried to alleviate this problem by building overdetermined systems of equations i e systems that have more equations than unknowns e g ponzini and lozej 1982 these two scenarios namely having adequate data to fully characterize either all model inputs or state variables are mostly relevant to hypothetical and laboratory scale problems and are rare if not nonexistent in real world cases where data on various model inputs and state variables are typically sparse due to physical and financial limitations rajabi and ataie ashtiani 2016 in the case of data scarcity the indirect approach should be applied there are two broad classes of indirect approaches in mdi frequentist also known as classical or non bayesian and bayesian or probabilistic we will use this classification in the subsequent sub sections although other classifications for indirect approaches also exist which include batch vs sequential methods e g wang et al 2009 and optimization vs sampling methods e g zhou et al 2014 2 3 2 frequentist approach the frequentist approach assumes that model variables e g parameters θ are possibly unknown but have deterministic values and the only source of randomness is data uncertainty based on this assumption the frequentist approach tries to construct a point estimate for each unknown variable often along with its confidence interval that quantifies the accuracy of the estimation process bernardo and smith 2001 these estimated values are then used for deterministic state reconstruction or prediction the frequentist approach assumes no prior distribution for the unknown variables but many algorithms used in the frequentist approach allow for use of prior information to provide initial values and lower or upper bounds on the variations of the unknown parameters or to penalize departures from prior estimates alcolea et al 2006 the most popular method in the framework of the frequentist approach and historically the first widely successful inverse method in groundwater applications is maximum likelihood estimation mle carrera and neuman 1986a mle it is not based on the linearity assumption and does not depend on any approximation for the relationship between the state variables and the model inputs and it can also incorporate many types of data mle estimates parameters θ or external forcing u t in such a way that the model response i e state variable fits the data dy in some optimal sense in other words the most likely parameter values are those that maximize the likelihood of observing the data 3 θ mle argmax θ l θ d y where argmax θ refers to the input parameters θ or similarly u t called arguments at which the function outputs are as large as possible and l denotes likelihood a common way to formulate the likelihood function can be expressed as follows zhou et al 2014 4 l θ d y e x p 1 2 i 1 n obs f i y t 1 u t θ d y i t c i 1 f i y t 1 u t θ d y i where c i 1 is the corresponding covariance of the observation errors and n obs is the number of measurements in order to facilitate statistical analysis the measurement error is often assumed to be gaussian in mle mclaughlin and townley 1996 least squares estimation lse is a special case of mle based on the assumption that errors in data are independent and normally distributed with constant unknown variance nonlinear lse algorithms were first applied to distributed parameter groundwater problems when numerical models became widely available in the 1960s and 1970s in lse the sum of squared errors l2 norm between the observed values and values predicted by the model are minimized the ordinary least squares estimator is defined as 5 θ les argmin θ i 1 n d y i f i y t 1 u t θ 2 partly due to its simplicity and ease of implementation lse is widely used for parameter estimation in groundwater modeling applications and has been employed in several highly popular inverse codes see section 4 in weighted lse weighting factors are used to express the relative magnitude of values and confidence in data a regularization or plausibility term can be included in the objective function above in order to ensure stability of the optimization problem medina and carrera 1996 lse is highly sensitive to outliers and hence some studies employ other frequentist objective functions such as absolute value of the difference between measured and computed values l1 norm woodbury et al 1987 nash sutcliffe index e g mugunthan et al 2005 and minkowski distance function e g zhou et al 2012 mle lse and other similar frequentist optimization methods fall in the field of calculus of variations and so they are sometimes referred to as variational methods rayner et al 2016 optimization algorithms used in the context of the frequentist approach include 1 local optimization methods which often quickly converge to the optimum if the search is started from a point in sufficient proximity of the optimum but only guarantee local convergence as they do not have a mechanism to escape from local optima mugunthan et al 2005 local methods used in the context of groundwater mdi include 1 1 derivative based or gradient based methods such as the widely used levenberg marquardt lm algorithm and its modifications e g nowak and cirpka 2004 and the conjugate gradient method e g carrera and neuman 1986b which are both highly efficient especially for low dimensional problems and have been widely incorporated in popular inverse codes these methods can fail if the objective function is discontinuous or their derivatives are discontinuous non smooth multi modal or ill conditioned 1 2 derivative free methods which are used when derivative information is unavailable unreliable or impractical to obtain due to the above mentioned problems rios and sahinidis 2013 examples of these methods are pattern search hooke and jeeves 1961 including generalized pattern search and mesh adaptive direct search e g zhou et al 2012 haddad et al 2013 and nelder mead simplex algorithm nelder and mead 1965 e g lambot et al 2002 2 global optimization methods which are more likely to find the global optima for the objective functions in comparison to local methods wang et al 2009 global methods can be further classified into 2 1 deterministic or exact methods such as multilevel coordinate search huyer and neumaier 1999 e g lambot et al 2002 2004 and branch and bound method huyer and neumaier 2008 e g sun et al 2006 2 2 stochastic search algorithms which rely on probabilistic search rules to find good solutions and can locate the neighborhood of the global optima relatively fast but their efficiency comes at the cost of computational effort and inability to guarantee global optimality stochastic optimization methods used in the context of groundwater mdi are mostly meta heuristic methods meta heuristics are a group of both local and global optimization algorithms that are inspired by natural processes ketabchi and ataie ashtiani 2015c these include evolution as in genetic algorithm holland 1975 e g samuel and jha 2003 and derandomized evolution strategies hansen and ostermeier 2001 e g bayer and finkel 2004 social behavior of biological organisms as in ant colony optimization dorigo and stützle 2004 e g abbaspour et al 2001 particle swarm optimization kennedy and eberhart 1995 e g haddad et al 2013 and controlled cooling associated with a physical process as in simulated annealing e g tsai et al 2003 meta heuristic algorithms can find acceptable solutions in a reasonable time in both complex and large search domains e g ketabchi and ataie ashtiani 2015c local and global methods can be hybridized into efficient optimization methods for example lm can be combined with a stochastic quasi monte carlo algorithm to search for global optimal values peng et al 2011 2 3 3 bayesian approach the bayesian approach also referred to as bayesian inference has two key distinctions with the frequentist approach first it formally considers model inputs and outputs as random variables and hence formulates the entire problem in a probabilistic framework fasbender et al 2008 and second it allows for formal consideration of prior information in the inference process wang et al 2009 as discussed throughout the rest of the paper these two key distinctions provide a convenient framework for uncertainty analysis data fusion regularization data worth analysis and incorporation of soft data in groundwater applications we shall first present the formulation of bayesian inference as a parameter estimation problem and then generalize it to other model components we denote the prior distribution of the parameter set θ with p θ which is prior beliefs on the parameter values before employing a specific dataset we also represent the likelihood function that characterizes the likelihood of the observation set d y given a certain parameter set θ by p d y θ the distribution of observation d y given θ is tied to the measurement model in bayesian inference the posterior distribution p θ d y is obtained through the application of bayes theorem gamerman and lopes 2006 6 p θ d y p d y θ p θ p d y where p d y is the proportionality or normalization constant which characterizes the evidence or the marginal probability of the data and can be computed from gamerman and lopes 2006 7 p d y p d y θ p θ d θ the lack of prior information can be expressed by using a non informative prior gelman et al 2013 in the case where there are multiple measurements e g measurements at different times 1 2 t denoted by d y 1 t the joint likelihood of all measurements is the product of distributions of individual measurements if the measurements are assumed to be conditionally independent the resulting posterior distribution is box and tiao 2011 8 p θ d y 1 t 1 z p θ k 1 t p d y k θ where z is the normalization constant given by 9 z p θ k 1 t p d y k θ d θ the predictive posterior distribution is the distribution of not yet observed state variables when all the information in the observed measurements and the model is used the predictive posterior distribution can be estimated as follows box and tiao 2011 10 p y t n d y 1 t p y t n θ p θ d y 1 t d θ the bayesian posterior distribution can be reduced to point estimates through a host of methods which include choosing the mean or maximum of the posterior distribution the latter approach is often called the maximum a posteriori map estimate e g kowalsky et al 2004 mle can be seen as a map estimate with uniform prior p θ 1 on the parameter set θ in other words the bayesian approach provides a formal way of including prior information and regularization terms into mle särkkä 2013 the same notion can be applied to the estimation of all model components based on the sequence of conditional dependence described as f θ a n d u t y t dependent variables appear at the end of the arrows liu and gupta 2007 11 1 p f d y p d y f p f p d y 11 2 p θ d y f p d y f θ p θ f p f p d y f 11 3 p u t d y f θ p d y u t f θ p u t f θ p θ f p f p d y f θ 11 4 p y t d y f θ u t p d y y t f θ u t p y t f θ u t p u t f θ p θ f p f p d y f θ u t 2 3 3 1 batch vs recursive bayesian inference when various types of data obtained at different time steps are simultaneously taken into account as a single whole dataset the resulting posterior distribution is denoted by batch bayesian estimation this type of solution to bayesian inference is very common in groundwater applications e g hassan et al 2009 laloy et al 2013 rajabi and ataie ashtiani 2016 however this full posterior formulation has the disadvantage that each time we obtain a new measurement the full posterior distribution must be recomputed this is particularly a problem in dynamic estimation where measurements are typically obtained one at a time and we would want to compute the best possible estimate after each measurement särkkä 2013 so alternatively if we treat the posterior distribution obtained from data for the previous time step as the prior for the current time step the result is called recursive or sequential bayesian estimation or bayesian filtering the recursive formulation of bayesian estimation has several useful properties 1 parameter estimates can be updated gradually as soon as new observations arrive paving the way for online learning this is particularly useful when the problem is sequential by nature wang et al 2009 as in a groundwater plume with time variable source or when data is collected gradually and it needs to be incorporated into model estimations without having to solve the problem from the start el gharamti et al 2013 zhou et al 2014 2 it allows for reducing the computational size of the problem when the problem is computationally expensive bruhwiler et al 2005 3 it allows for considering the temporal evolution of parameter values i e parameters are assumed to be time dependent stochastic processes hence θ t instead of θ särkkä 2013 4 it does not require storage of all past information about the states and parameters moradkhani et al 2005 el gharamti et al 2013 2 3 3 2 numerical methods for batch bayesian inference in practical problems involving the estimation of parameters external forcing terms or model states exact analytical solutions for the continuous posterior distribution in batch bayesian inference are available for very limited combinations of model forms and probability functions such as the normal linear model qian et al 2003 khaleghi et al 2013 this necessitates the use of numerical approximation techniques markov chain monte carlo mcmc methods or samplers are a general class of strategies that provide a powerful tool for numerical approximation of the posterior distribution in batch bayesian inference mcmc came into widespread use as a tool for bayesian inference in science and engineering with the work of tanner and wong 1987 and gelfand and smith 1990 they were introduced into the groundwater literature by oliver et al 1997 and have been the dominant method for numerical approximation of batch bayesian inference in groundwater modeling applications ever since as the name suggests mcmc methods employ monte carlo concepts in the framework of markov chains they attempt to generate monte carlo samples from the posterior distributions conditioned on the observations by a special sequential process in which each new sample depends on the properties of the sample drawn immediately before it and not the more early ones thus creating a markovian chain of samples in mcmc these samples can be drawn from a distribution even if all that is known about the distribution is how to estimate the probability density for the samples gamerman and lopes 2006 van ravenzwaaij et al 2016 which is a very beneficial aspect of mcmc as the posterior distributions are unknown at the onset of calculations if the markovian chain is sufficiently large often on the order of 103 to 105 samples in previous groundwater applications e g hassan et al 2009 laloy et al 2013 rajabi and ataie ashtiani 2016 it will eventually converge to the stationary posterior distribution of the parameters andrieu et al 2003 estimation of the probability density for each sample constitutes a forward model simulation and hence when dealing with cpu intensive groundwater numerical models mcmc methods become extremely demanding in terms of the required computations hendricks franssen and kinzelbach 2008 the main difference amongst various mcmc methods is how sampling is implemented based on these general concepts there are two central notions used for building samplers tierney and mira 1999 1 dimension reduction by conditioning which is the foundation of the gibbs sampler e g michalak 2008 and 2 proposal and rejection which is the basis of the metropolis hastings e g laloy et al 2013 and similar algorithms such as adaptive metropolis am e g hassan et al 2009 wu et al 2011 and delayed rejection adaptive metropolis dram e g rajabi and ataie ashtiani 2016 these two notions have also been combined into what is called metropolis within gibbs samplers e g cui et al 2013 generally speaking there is no universally optimal mcmc algorithm and the choice of an appropriate mcmc algorithm depends on the specific nature of the problem nevertheless some researchers have proposed mcmc algorithms that seem to offer great potential for increasing the computational efficiency in comparison with more traditional mcmc algorithms these novel mcmc algorithms often rely on increasing the acceptance rates of proposals e g vrugt et al 2009 dimensionality reduction of the forward simulations e g laloy et al 2013 or parallelization of mcmc computations e g laloy and vrugt 2012 joseph and guillaume 2013 an alternative to mcmc is importance sampling is e g ng et al 2009 is is an algorithm for generating weighted samples i e particles from the posterior distribution the main difference between is and mcmc is that each of the particles in is has an associated weight which reflects its ability to match observations lu and zhang 2003 särkkä 2013 similar to mcmc is does not rely on the implicit gaussian and linearity assumptions but is can be inefficient if the unconditional probability density of the states is a weak approximation of the conditional density and can especially become computationally infeasible when the state vector is high dimensional and particles are computationally demanding daum and huang 2003 2 3 3 3 bayesian filtering the objective of bayesian filtering is to estimate the time varying state of the system or parameters and external forcing terms as described in section 3 which is observed through sparse and noisy measurements chen 2003 in bayesian filtering the marginal posterior distributions or filtering distributions of the state variables at time step k i e y k are computed using the history of measurements up to and including the time step k bayesian filtering generally includes two stages a prediction stage and an update stage in the prediction stage the distribution of the state y k is computed based on measurements in previous time steps by doucet et al 2001 chen 2003 12 p y k d y 1 k 1 p y k y k 1 p y k 1 d y 1 k 1 d y k 1 in the update stage the new measurements d y k is used to update the distribution obtained in the prediction stage by applying bayes rule 13 p y k d y 1 k 1 z k p d y k y k p y k d y 1 k 1 where z k is the normalization constant given by 14 z k p d y k y k p y k d y 1 k 1 d y k 2 3 3 4 closed form solutions for the bayesian filter a few classes of filtering problems have closed form solutions with the kalman filter kf kalman 1960 being the most popular one kf is based on a linear and gaussian assumption for the state space models described as follows eigbe et al 1998 15 a y k φ k 1 y k 1 q k 1 15 b d y k h k y k r k where q k 1 n 0 q k 1 is the process noise r k n 0 r k is the measurement noise and the initial distribution is assumed to be y 0 n m 0 ψ 0 φ k 1 is the transition matrix describing the forward model and h k is the measurement model matrix starting from the initial distribution of the state the prediction stage of the kf tries to estimate the mean and covariance of the state for the next time step by eigbe et al 1998 16 a m k φ k 1 m k 1 16 b ψ k φ k 1 ψ k 1 φ k 1 t q k 1 the update stage subsequently revises these estimations by employing data for time step k d y k as follows eigbe et al 1998 17 a m k m k l k d y k h k m k 17 b ψ k ψ k l k h k ψ k h k t r k l k t where l k is the kalman gain matrix wang et al 2009 kf can be further simplified by empirical forcing of the model fields toward the observed values which is called nudging lahoz et al 2007 the use of kf in groundwater mdi problems dates back to the 1970s e g mclaughlin 1976 and it has been applied to a range of applications ever since however the popularity of the classic kf in groundwater literature is considerably less than the more general domain of hydrology where kf is commonly applied to rainfall runoff modeling flood forecasting rainfall prediction etc see liu et al 2012 the reason is that kf in its most basic form has several key limitations which are particularly problematic in groundwater applications 1 it is based on the linearity assumption whereas groundwater flow and solute transport models are nonlinear zhou et al 2014 2 it cannot break down the computations over space the way it does over time and hence cannot account for the spatial physical and statistical relationships of groundwater systems porter et al 2000 3 there is often not enough information about error structures to fill the large matrixes of eq 17 b with meaningful numbers reichle 2008 and 4 it is computationally expensive for high dimensional problems and is hence strongly restricted to small size problems hendricks franssen and kinzelbach 2008 variational bayesian methods vbms notably the sequential 4dvar method and its batch counterparts 1dvar and 3dvar where 1d and 3d refer to one or three spatial dimensions the 4th dimension in 4dvar is time reichle 2008 and var stands for variational can be viewed as simplifications of the kf as they do not propagate the state covariance matrix explicitly liu et al 2012 vbms have relatively low computational demand and are preferred for use with computationally expensive models and large dimensional problems with poorly related nonlinear observations rawlins et al 2007 however vbms do not provide an estimate of predictive uncertainty by themselves peng et al 2011 vbms have been used extensively in the numerical weather prediction community one of the rather few applications in groundwater mdi is kabir et al 2017 which employs 3dvar and 4dvar for state estimation in a hypothetical test case more applications of vbms are expected in future groundwater studies 2 3 3 5 numerical approximations for the bayesian filter due to the limiting nature of closed form solutions and the intractability of the bayesian filtering equations särkkä 2013 several numerical approximation techniques have been proposed the most popular of such techniques in the groundwater literature are briefly reviewed in the following paragraphs extended kalman filter exkf gelb 1974 is a numerical approximation method which forms a taylor series expansion at the nominal or map solution to provide a linear approximation of the nonlinear and non gaussian state space models exkf has been applied to groundwater mdi problems by e g leng and yeh 2003 and yeh and huang 2005 exkf has several major setbacks that affect its application to groundwater mdi 1 the covariance approximation deteriorates with time particularly when the taylor series approximation is poor as in highly heterogeneous fields zhou et al 2014 2 it can be computationally very demanding due to the error covariance propagation evensen 2003 especially for finely discretized groundwater models and 3 it can lead to unstable results or even divergence when the nonlinearity in the system is strong miller et al 1994 moradkhani et al 2005 due to these setbacks the exkf has lost popularity in the groundwater literature ensemble kalman filter enkf is another method which was first introduced by evensen 1994 and later modified by burgers et al 1998 and is a monte carlo variant of the kf in enkf the probability distribution of state y k is represented by ensemble of realizations y k 1 y k 2 y k n this ensemble is built by sampling from the known distribution of y 0 in the first step of computations each of these realizations is then separately propagated through time in the subsequent steps by a two stage prediction update procedure in each time step the mean and covariance can be explicitly computed based on the realizations noting that the prediction stage involves a model simulation for each realization in the ensemble observations are treated as random variables by generating an observation ensemble with a mean equal to the actual observation at each time and using a predefined covariance the enkf also represents the model errors by generating perturbations at each time step evensen 2003 2009 the enkf has a number of advantages which are particularly desirable in groundwater mdi problems 1 it can handle modestly nonlinear state space models reichle et al 2008 2 it can be used to deal with high dimensional problems peng et al 2011 3 it is flexible in its treatment of errors in model dynamics and parameters reichle 2008 and 4 the covariance between states at any given time step is estimated efficiently from a limited ensemble of stochastic realizations without requiring sensitivity analyses schöniger et al 2012 in general the performance of enkf is affected by the choice of the ensemble size and generation method model characteristics and analysis scheme moradkhani et al 2005 due to these advantages and ease of implementation model independence and robustness in solving different types of problems encountered in groundwater applications the enkf has become more popular than any other method in addressing problems of a sequential nature in the groundwater literature examples for the use of the enkf in groundwater applications include chen and zhang 2006 drécourt et al 2006 liu et al 2008 hendricks franssen et al 2011 el gharamti et al 2013 erdal and cirpka 2017 and xu and gómez hernández 2018 however the basic form of enkf has the key disadvantage of being based on the gaussian assumption moreover highly nonlinear dynamics can result in increasing underestimation of variance over time called filter inbreeding and filter divergence in the enkf hendricks franssen and kinzelbach 2009 a number of studies in the groundwater literature have tried to make enkf applicable to non gaussian models for example schöniger et al 2012 proposed the use of nonlinear monotonic transformations to the observed states rendering them gaussian xu and gómez hernández 2016b employed the normal score enkf to jointly estimate non gaussian aquifer parameters by assimilating three kinds of state variables another important disadvantage of enkf is that the size of the ensemble can be computationally prohibitive for cpu intensive groundwater models because hundreds of ensemble members are usually needed for reliable updating without filter inbreeding liu et al 2012 the enkf has a number of variants such as the ensemble square root kalman filter ensrf whitaker and hamill 2002 which uses the traditional kalman gain for updating the ensemble mean but uses a reduced kalman gain to update deviations leisenring and moradkhani 2011 the use of ensrf and other variants of the enkf such as the adaptive ensemble kalman filter and the hybrid adaptive ensemble kalman filter in the groundwater literature is rare as one of the few examples see rajib et al 2017 sequential monte carlo smc methods gordon et al 1993 also known as particle filters and bootstrap filters are another group of numerical approximation techniques that represent the posterior distribution in recursive bayesian inference as a set of monte carlo samples with associated weights which are termed particles the particles sample the state and or parameter and external forcing space according to a given prior distribution the particles are then propagated forward in time with smc performing updates on particle weights instead of state variables peng et al 2011 this has the advantage of reducing numerical instability ristic et al 2003 smc is applicable to any state space model with any format and statistical distribution whether linear or nonlinear and gaussian or non gaussian han and li 2008 this is a highly advantageous characteristic in certain groundwater problems such as the inverse estimation of hydraulic conductivities for non multi gaussian media however the basic form of smc has two key undesirable characteristics 1 smc tends to assign very large weights to the few particles with strong data support leading to severe reduction of the effective sample size and hence deterioration of the statistics and 2 applying smc to a high dimensional state and parameter space requires a very large number of particles and hence a very large amount of cpu time snyder et al 2008 hendricks franssen and kinzelbach 2009 schöniger et al 2012 resampling techniques like sequential importance resampling can reduce these problems to some extent van leeuwen 2009 leisenring and moradkhani 2011 smc may outperform enkf when the number of particles is sufficiently large 100 but the often larger number of simulations required by scm compared to enkf liu et al 2012 has limited its application to cpu intensive real world groundwater models example of smc application in groundwater mdi problems includes chang et al 2012 and abbaszadeh et al 2018 smc is popular in some engineering fields such as tracking and signal processing djuric et al 2003 and it has also been applied to many hydrologic problems zhou et al 2006 smith et al 2008 smc can be combined with mcmc see moradkhani et al 2012 so that a desirable performance can be achieved with a small manageable ensemble size apart from the three families of methods described above other techniques for numerical approximations of the bayesian filter exist but are rarely applied to groundwater mdi an example is the unscented kalman filter unkf e g chang and sayemuzzaman 2014 which presumes that the state space is unimodal symmetric and unbound despite the more relaxed assumptions of the unkf it has received little attention in the groundwater literature to date and so we expect more applications in the future 2 3 3 6 bayesian smoothing while bayesian filters in their basic form only compute estimates of the current state of the system given the history of measurements bayesian smoothers can be used to reconstruct states that happened before the current time smoothing distributions computed by the bayesian smoothers are the marginal distributions of the state y k given a certain interval of measurements d y 1 k k 1 2 t in which t k kitagawa 1987 18 p y k d y 1 t p y k d y 1 k p y k 1 y k p y k 1 d y 1 t p y k 1 d y 1 k d y k 1 where p y k d y 1 k is the filtering distribution of the time step k the integration is replaced with summation if some of the state components are discrete särkkä 2013 similar to bayesian filtering there are both closed form and numerical solutions for the bayesian smoothing equation closed form solutions include the kalman smoother ks or the rauch tung striebel smoother rtss rauch 1963 for linear gaussian state space models numerical solutions include the extended rauch tung striebel smoother exrtss cox 1964 sage and melsa 1971 which assumes gaussian approximation to the smoothing distribution and the ensemble smoother es van leeuwen and evensen 1996 among these the most commonly used method in the groundwater literature is es similar to enkf the es employs an ensemble of realizations obtained through mcs but it is based on one in all conditioning and can assimilate all the measurements at once using a single analysis step rather than the stepwise conditioning of the enkf so es and other bayesian smoothers are also classified as batch methods in some references however note that employing es instead of enkf increases the nonlinearity of the parameter update step during data assimilation and also increases the need for iterations of the algorithm chen and oliver 2013 examples for the use of es in the groundwater literature includes bailey and baù 2010 2012 chang et al 2017 and white 2018 3 applications applications of mdi in groundwater literature can be classified into eight categories parameter estimation and uncertainty quantification state estimation and uncertainty quantification state parameter estimation and uncertainty quantification model selection and structural uncertainty analysis guidance of data collection and data worth analysis improving data coverage customizing data resolution and fusion of heterogeneous data these applications are not mutually exclusive and two or more applications may be intended simultaneously in this section we review these applications considering their objectives basic theoretical concepts types of algorithms used in each application and significant trends in the groundwater literature 3 1 parameter estimation and uncertainty quantification parameter estimation is referred to as parameter fitting optimization inference or tuning model calibration or inverse modeling in the groundwater literature carrera et al 2005 2010 ataie ashtiani et al 2013 its objective is to employ available data either directly related to the parameter of interest or associated with state variables to provide reasonable estimates of model parameters and external forcing terms over a past period conditional on the specification of model structure so that the model makes sufficiently accurate predictions of the true state of the system liu and gupta 2007 parameter estimation often also includes approximation of associated uncertainties in both research and practical groundwater modeling studies parameter estimation has long been the dominant method for model improvement by conditioning to data and is often considered a necessary step in groundwater modeling hill and tiedeman 2006 it is by far the most explicitly mentioned application of mdi in the groundwater literature there are several reasons for this profound attention toward parameter estimation in the groundwater literature first no reliable prediction can be made without proper estimation of model parameters and external forcing terms zhou et al 2014 and second it is often much easier to condition parameter and external forcing values to data as compared to model structure refsgaard et al 2006 2012 groundwater parameter estimation often involves the estimation of hydraulic conductivity or related parameters such as permeability or transmissivity and its spatial distribution e g hendricks franssen and kinzelbach 2009 hendricks franssen et al 2009 ataie ashtiani et al 2013 as it highly affects model outputs for the prediction of both groundwater flow and transport of contaminants and also because it may vary over many orders of magnitude in a relatively small volume of the media mclaughlin and townley 1996 however parameter estimation may also focus on other parameters and external forcing terms such as recharge rates ng et al 2009 hendricks franssen et al 2004 2008 hendricks franssen and kinzelbach 2008 discharges fluxes leakage coefficients and piezometric heads on designated boundaries e g liu et al 2009 hendricks franssen et al 2011 irsa and zhang 2012 pollutant source location and release histories e g sun et al 2006 hendricks franssen et al 2011 and dispersivity e g ataie ashtiani et al 2013 or a combination of different parameters e g xu and gómez hernández 2016a b 2018 amongst these the estimation of recharge rate is of key interest in arid and semi arid regions due to its more unpredictable nature in these areas hendricks franssen et al 2008 parameter estimation has been a topic of intensive research for the past decades and several notable review papers are available on the subject including mclaughlin and townley 1996 carrera et al 2005 2010 vrugt et al 2008 and zhou et al 2014 as described in all these review papers historically the common approach for the estimation of groundwater model parameters until the end of the 1990s was trial and error in which parameter values are manually changed until a reasonable match between model predictions and data is achieved this approach is highly dependent on the subjective judgment of the modeler and by no means guarantees the optimal choice of parameter values ataie ashtiani et al 2013 these key setbacks have resulted in increasing use of automated parameter estimation based on frequentist nonlinear batch methods despite the many advantages of using these frequentist methods instead of trial and error parameter estimation they have several limitations 1 these methods employ objective functions that are based on collective measures of uncertainty and ignore the special characteristics of the individual components of uncertainty such as structural and data uncertainties liu et al 2012 zhou et al 2014 2 pursuing a single optimal parameter set can create bias in model predictions hendricks franssen et al 2009 and 3 they do not have the ability to gradually reduce parameter and hence prediction uncertainty as new data become available liu and gupta 2007 in recognition of these limitations there has been growing interest in the use of monte carlo based bayesian techniques for parameter estimation algorithms that have been of key interest include enkf e g hendricks franssen et al 2011 and es e g bailey and baù 2010 2012 in monte carlo based methods likely realizations of the input parameters are conditioned to the available measurements with geostatistical techniques such as sequential gaussian simulation gómez hernández and journel 1993 if local measurements of the desired parameters are available or co located co simulation almeida and frykman 1994 hendricks franssen et al 2008 the estimation of heterogeneous fields of hydraulic conductivity and other similar parameters e g transmissivity storage coefficient and recharge rate from sparse data is commonly a highly underdetermined problem and is prone to ill posedness non uniqueness and instability to alleviate these problems the estimation of such parameter fields is often done by employing a parameterization technique that limits the number of unknown variables and provides the modeler with only enough heterogeneity required to simulate observations of past system behavior sepúlveda and doherty 2015 these include non geostatistical methods such as the classical zonation method carrera and neuman 1986a b and geostatistics based methods such as the pilot point method de marsily 1978 regularized pilot point method alcolea et al 2006 sequential self calibration gómez hernánez et al 1997 hendricks franssen et al 1999 and ridge function mantoglou 2003 geostatistical methods may turn the parameter estimation problem into the estimation of the geostatistical variables of the unknown parameters e g range nugget sill etc using these techniques almost always results in loss of detail and may produce overly smoothed parameter fields moore and doherty 2006 hence much work is still being done by the groundwater research community to develop new methods 3 2 state estimation and uncertainty quantification state estimation involves characterization of the past retrospective present or future forecast state of the groundwater system and their uncertainties by combining state information from both the model and available data liu and gupta 2007 liu et al 2012 this may include for example reconstructing spatial flow and contaminant plume fields state estimation which is also commonly referred to as data assimilation is typically based on specification of the model structure and parameters in advance and the estimations are solely applied to the state variables hence state estimations are conditional on the specific model structure s and parameter values moradkhani et al 2005 schöniger et al 2012 in the groundwater literature state estimation is often formulated as a filtering or smoothing problem and is commonly interrelated with three other application of mdi improving data coverage customizing data resolution and data fusion the commonly applied methodologies for solving the problem via filtering in recent groundwater literature is the enkf and smc methods e g bailey and baù 2012 dual state state estimation is a term used for the concurrent estimation of groundwater flow and contaminant states el gharamti et al 2013 3 3 simultaneous state parameter estimation and uncertainty quantification there are basically two formulations for the simultaneous estimation of states and parameters in the groundwater literature 1 the joint or state augmentation approach and 2 the dual estimation approach the standard joint approach simultaneously estimates state and parameters as a single augmented vector e g chen and zhang 2006 hendricks franssen and kinzelbach 2008 2009 liu et al 2008 hendricks franssen et al 2011 the joint approach is very susceptible to instability and intractability as a result of increase in the number of unknown variables especially in highly nonlinear systems moradkhani et al 2005 the alternative dual formulation is based on two interactive parallel filters a filter for the parameters and another for the states with the parameters undergoing an artificial evolution i e random walk while waiting to be updated indirectly by the state variables data e g el gharamti et al 2013 an example of dual estimation is the dual extended kalman filter dual exkf thiemann et al 2001 3 4 model selection and structural uncertainty analysis model selection also known as model discrimination or identification is a key part of multi model approaches for the consideration of structural uncertainty höge et al 2018 it involves using data to choose amongst various independent plausible alternative model structures including governing equations heterogeneity patterns type of boundary conditions etc that best describe the relationship between model inputs and outputs refsgaard et al 2006 gupta et al 2012 model selection may also include assigning probabilities to the chosen model structures based on their ability to reproduce the available data and then combining predictions made by the chosen model structures to form a reliable description of the total prediction uncertainty mdi for model selection and structural uncertainty analysis in the groundwater literature is mostly performed using one of the following bayesian methods generalized likelihood uncertainty estimation glue beven and binley 1992 bayesian model averaging bma draper 1995 and maximum likelihood bayesian model averaging mlbma neuman 2003 or a hybridization of at least two of them e g rojas et al 2010a these methods and some of their applications are briefly reviewed in the following sub sections 3 4 1 generalized likelihood uncertainty estimation glue is a conditional mcs technique that involves sequential implementation of the following steps 1 defining alternative candidate model structures 2 assigning appropriate prior parameter uncertainty distributions for each model structure 3 performing mcs based on samples drawn from the parameter distributions of each candidate 4 using a likelihood measure such as the gaussian romanowicz et al 1994 efficiency freer et al 1996 and fuzzy type jensen 2003 measures to assess the resemblance of each simulation output with data on systems states 5 selecting candidates with likelihoods above a specified threshold as behavioral models and setting the other candidates aside 6 calculating weights for each behavioral model by normalizing the corresponding likelihood values in a way that all the weights sum up to one and 7 estimating the likelihood weighted probability distribution of model outputs beven and freer 2001 liu and gupta 2007 in glue the likelihoods can be updated sequentially as new data becomes available glue allows for the explicit assessment of model structure and parameter uncertainties but does not account for data uncertainty applications of glue in groundwater mdi are numerous with the majority of applications focusing on the uncertainty in geological structures and hydraulic conductivity patterns and to a lesser extent on recharge patterns assuming that other components of the model structure e g governing equations are without uncertainty e g feyen et al 2001 morse et al 2003 hassan et al 2008 this is also the case for the other two methods discussed in this sub section bma and mlbma the glue methodology has been criticized for not having a likelihood function that is consistent with probability theory and instead relying on less formal likelihoods that are defined by the user without satisfying bayes theorem resulting in a loss of consistency in learning mantovan and todini 2006 montanari et al 2009 3 4 2 bayesian model averaging bma is a more formal bayesian approach for combining predictions made by multiple model structures the bma predictive distribution of an output of interest y given data d is estimated by hoeting et al 1999 19 p y d i 1 n m p y d f p f d where n m is the number of alternative model structures in bma the predictive distribution of y is an average of its prediction distributions for each alternative model structure p y d f weighted by its posterior model probability p f d bma can be used to differentiate between prediction uncertainties arising from individual models and is able to identify unfavorable models for model selection examples for the use of bma for mdi in the groundwater literature include tsai and li 2008 li and tsai 2009 ye et al 2010 and tsai 2010 bma is computationally very demanding especially when applied to cpu intensive groundwater models 3 4 3 maximum likelihood bayesian model averaging mlbma was developed in an attempt to make bma computationally feasible neuman 2003 it is in fact an approximation to bma that relies on producing maximum likelihood parameter estimations and then expanding around these values by mcs mlbma subsequently approximates the posterior model probabilities using e g the kashyap information criterion kashyap 1982 or the bayesian information criterion bic schwarz 1978 mlbma is capable of dealing with lack of prior information on model parameters ye et al 2005 examples of groundwater studies using mlbma for mdi include neuman 2003 ye et al 2004 2005 and lu et al 2015 despite the computational convenience several shortcomings have been mentioned for mlbma in the literature these include 1 it relies on the calibration of parameters for each alternative model structure hence creating the risk of biased parameter estimates that tend to compensate for errors in the model structure rojas et al 2010b and 2 prediction of state variables not included in the data used for calibration may become biased and may underestimate the effects of model structural uncertainty refsgaard et al 2006 troldborg et al 2007 3 5 guidance of data collection and data worth analysis groundwater data collection campaigns are costly and almost always prone to logistical and financial constraints this implies the need to develop vigorous methodologies for the optimal collection of data besides or complementary to the informal or subjective methods guided by professional experience and judgment and the formal or objective methods based on pure geostatistics e g kriging frameworks simulation based methods can play a key role in the guidance of data collection in groundwater studies in this regard models help in the identification of the most informative data to collect with respect to a specific set of objectives this process is referred to as experimental design value of information or data worth analyses dwa simulation based dwa has been used in the literature for the identification of the optimal number e g norberg and rosén 2006 and location of observation wells e g siade et al 2017 frequency of sampling e g kollat et al 2011 tracer test design including choice of the injection rate duration of test and type of tracer e g wallis et al 2014 and choosing between different types of data e g choosing between conductivity piezometric heads and travel times data as in fu and gómez hernández 2009 or between concentration and temperature data as in dausman et al 2010 in the latter case the worth of different types of data with different measurement accuracies can be analyzed by using simulation based pareto methodology see brunner et al 2012 simulation based dwa can be carried out in at least two contexts 1 it can be used to compare alternative future data collection schemes at a given stage in a phased survey and 2 it can be used to decide when to stop or limit a staged data collection program to reduce data redundancy i e observations having similar information content freeze et al 1992 khader and mckee 2014 in both of these contexts a precondition for the use of model based dwa is that some minimal groundwater exploration that allows for the development of a justifiable model has taken place kikuchi 2017 simulation based dwa is essentially built on a strategy to quantify the worth of measurements the most common strategy is to compute a measurement s ability to reduce the uncertainty or error variance of key model predictions e g heads contaminant concentrations or travel times magnitude of plume spreading etc which affect management decisions e g freeze et al 1992 cirpka et al 2004 dausman et al 2010 wallis et al 2014 kikuchi et al 2015 wöhling et al 2016 siade et al 2017 in context 1 above this is often done in the following two steps which are built upon bayesian statistics and are referred to as bayesian dwa or bayesian experimental design in the first step a prior analysis is performed where the uncertainty in key model predictions is quantified on the basis of currently available data in the second step which is called pre posterior analysis the uncertainty in key model predictions is re calculated by assuming that new measurements are carried out in a specific timeframe on a set of locations in the proposed data collection program obviously the values that are actually going to be measured at the proposed locations are unknown but what is known is that measurement will reduce the uncertainty at the proposed points to zero or to some measurement uncertainty for the intended parameters or state variables this is sufficient to allow for the calculation of the uncertainty reduction resulting from the proposed measurements with respect to the uncertainties calculated in the prior analysis hence in the pre posterior analysis the magnitude of predictive uncertainties are considered in a relative rather than absolute sense some references refer to this procedure as a form of sensitivity analysis finsterle 2015 the pre posterior probabilities are often calculated through linear uncertainty analysis e g dausman et al 2010 numerous variants of mcmc e g fu and gómez hernández 2009 null space monte carlo nsmc e g siade et al 2017 or enkf e g kollat et al 2011 repeating pre posterior analysis for various data collection alternatives in the framework of optimization e g by ga as in wöhling et al 2016 or scenario analysis e g fu and gómez hernández 2009 allows for the selection of the optimal design in the context 2 above a prior analysis is performed based on data collected in some initial stages of the data collection program initial dataset then pre posterior analysis is replaced by posterior analysis in which uncertainty in key model predictions is calculated based upon augmenting different subsets of data collected in the subsequent stages with known measurement values to the initial dataset by comparing the outcome of posterior analysis for different subsets of data one can choose to stop parts of the measurement program that result in the least impact on reducing model prediction uncertainties note that prior pre posterior and posterior analysis all require propagation of uncertainty from model parameters and observation data to model forecasts leaf 2017 some studies go a step further and characterize the worth of data by quantifying the benefits of reducing model prediction uncertainty in terms of risk reduction or monetary costs of economic regret resulting from making wrong decisions in the context of remedial or aquifer exploitation decision making e g feyen and gorelick 2005 norberg and rosén 2006 neuman et al 2012 a common formulation for this notion is to maximize some form of the following objective function ς 20 ς b c i γ p f c f where b is the benefit e g profit from water sales etc c i is the investment cost including the cost of measurements γ is the risk aversion factor p f is the probability of failure e g failing to abide by a regulation policy etc and c f is the cost of failure e g fines waste of groundwater resources etc this strategy has two key interconnected advantages first it is based on a more direct assessment of cost effectiveness and second communicating the results with stakeholders often becomes easier the downside to such an approach is that it requires a quantitative definition of the cost of being wrong due to lack of data which may not always be known or easy to quantify in simulation based methods dwa can be done based on a measurements ability to improve the estimation of unmeasurable or hard to measure parameters this can be done by assessing the sensitivity of potential measurements i e states to model parameters through model sensitivity analysis e g ataie ashtiani et al 2013 an alternative approach is to analyze the measurements ability to reduce parameter estimation uncertainty in a bayesian framework in the latter case the objective function is usually derived from the covariance matrix of the parameters based on a optimality minimizing the trace of the covariance matrix e g hsu and yeh 1989 d optimality minimizing the determinant of the covariance matrix e g catania and paladino 2009 siade et al 2017 e optimality minimizing the eigenvalue of the covariance matrix e g nordqvist 2000 or expected shannon information gain i e relative entropy e g zhang et al 2016 see nowak 2010 for a review of these criteria traditionally dwa studies have relied on a single conceptual mathematical model of the groundwater system making the predictions prone to statistical bias and underestimation of uncertainty xue et al 2014 a more recent approach in the literature is to perform predictions by means of multiple models and then characterize data worth as the contribution of a set of measurements to 1 the resulting multi model prediction uncertainty or 2 model selection discrimination among a set of viable alternative models this is often done within a bma e g pham and tsai 2016 or mlbma e g neuman et al 2012 xue et al 2014 framework in case 1 data worth can be defined for example as the difference between the trace of the posterior covariance with and without a set of real measurements in posterior analysis or randomly chosen estimates of potential measurements in pre posterior analysis neuman et al 2012 xue et al 2014 in 2 the worth of data can be assessed for example based on the number of conceptualizations retained in the ensemble after a specific subset of data is considered 3 6 improving data coverage in groundwater studies models can be used to interpolate and extrapolate data to provide spatial and temporal coverage of the desired domain a classic example is the use of groundwater models for the creation of water table or concentration contour maps from sparse and irregularly distributed field measurements although the use of classic geostatistical interpolation methods such as inverse distance weighting and kriging variants are common for this purpose these methods are known to be vulnerable to outliers may contradict obvious characteristics of the groundwater system and often fail to represent complex variations between relatively distant measurement points fasbender et al 2008 buchanan and triantafilis 2009 these shortcomings can be alleviated through the use of models because the physical constraints imposed by models offer additional valuable information in the development of contour maps the methodology is straightforward the model is calibrated using the sparse field measurements of water table and or concentration then the current state of the groundwater system is reconstructed by the model and the results are used to generate the contour maps data generalization can also be performed by solving bayesian filtering or smoothing state estimation problems use of models in such bayesian frameworks allows for the incorporation of auxiliary data and geostatistics in the data generalization process for example see peeters et al 2010 despite these advantages models are rarely developed for the single purpose of creating a groundwater contour map for two main reasons first the time and effort needed to create and calibrate the model compared to the use of pure geostatistics are considerably higher and second commonly a mismatch remains between observed and simulated values in the measurement points 3 7 customizing data resolution models can be used to upscale or similarly downscale data upscaling refers to the transformation of data collected at a fine scale onto a coarser scale a typical example in groundwater studies is the upscaling of hydraulic conductivity data also referred to as the estimation of effective equivalent interpreted homogenized or block hydraulic conductivity sanchez vila et al 2006 another parameter commonly upscaled in groundwater studies is dispersivity de barros and dentz 2016 the basic notion behind model based data upscaling in groundwater studies is that quantities such as flows and hydraulic head gradients computed by a model at a coarse scale block should match the corresponding average values of these quantities modeled at the fine scale blocks that form the course block and pertain to the scale of data acquisition in other words the upscaled quantity is chosen so that the upscaled blocks can reproduce the behavior of the heterogeneous medium through modeling the advantage of this model based method in comparison to pure geostatistics is that it is not limited to a specific spatial distribution pattern degree of variability or aquifer geometry a pioneering study in this regard is gómez hernández 1991 followed by studies such as zhou et al 2010 who extended the methodology of gómez hernández 1991 to three dimensions li et al 2012 which coupled this upscaling method with inverse modeling through the enkf fernàndez garcia et al 2009 and li et al 2011 who applied transport models to upscaling and godoy et al 2018 which employed the laplacian with skin method for upscaling of hydraulic conductivity 3 8 fusion of heterogeneous data hydrogeological site investigations involve the collection of an array of different types of data which should be combined to form a unified picture of the aquifer for several reasons hydrogeological data fusion is often a difficult task 1 various types of data may relate to different aspects of the system and hence do not share the same nature these inherently different forms of data cannot be readily related to each other a typical example of this notion is pollutant concentration and hydraulic conductivity data 2 even data of the same nature generally do not share the same quality and may have dissimilar spatial and temporal scales and degrees of uncertainty and imperfection for example in many site investigations data from traditional characterization and monitoring methods such as core analyses and hydraulic tests are supplemented with coverage of greater density from indirect geophysical surveys and soft data based on expert knowledge and field questionnaires the degree of uncertainty associated with each of these types of data is very different from the other this is known as data heterogeneity khaleghi et al 2013 3 there is the typical problem of handling inconsistency and conflict in temporally or spatially overlapping data for decades hydrogeologists have relied on a combination of expert knowledge and geostatistical methods for formal data fusion but most existing geostatistical methods such as classical kriging and cokriging are limited in their ability to simultaneously account for large numbers of information sources porter et al 2000 fasbender 2008 and hence research on the improvement of geostatistical data fusion methods is ongoing e g hosseini and kerachian 2017 model based data fusion also called data fusion modeling in the groundwater literature e g porter et al 2000 is a very powerful tool for solving the problems associated with data fusion in hydrogeology models provide prior knowledge of the physical relationships between dissimilar datasets and data fusion algorithms use these relationships to extract integrated information from the measured data we classify previous work on model based data fusion in the groundwater literature into three categories which are described in the following sub sections 3 8 1 fusion of different types of direct measurements this is the most common form of data fusion in groundwater studies partly because traditional frequentist parameter estimation methods implemented in codes such as pest modflowp ucode ithough2 etc embody this form of data fusion these frequentist methods use direct measurements of model parameters e g hydraulic conductivity porosity dispersivity etc to provide initial estimates and bounds for each of these parameters and then simultaneously employ different forms of data related to direct measurements of model state variables e g head concentration travel time etc to update these initial estimates hence both the resulting parameter estimates and model predictions are based on the integration of different forms of data but as previously discussed these methods do not provide a proper estimation of uncertainties the use of bayesian fusion techniques alleviates this problem in bayesian fusion data on model parameters is employed to build prior estimates for these parameters in the form of probability distributions and the data on state variables are used to update these priors and obtain the posterior probability distributions of model parameters bayesian fusion has been implemented through mcmc algorithms for the fusion of non sequential data e g hassan et al 2009 laloy et al 2013 and variants of the kf have been employed for the fusion of sequential data e g porter et al 2000 bailey and baù 2012 in the groundwater literature 3 8 2 fusion of direct and indirect measurements direct point measurements of hydrogeologic data are commonly limited because their acquisition is expensive time consuming and invasive rajabi and ataie ashtiani 2016 several types of indirect measurement data can be used to alleviate this problem two of the most commonly used are geophysical data and remote sensing rs data it is well known that the use of geophysical data such as ground penetrating radar data electrical resistance tomography data etc in conjunction with direct measurement of hydrogeologic variables can substantially improve characterization of subsurface variability kowalsky et al 2005 2006 yeh et al 2007 however geophysical methods provide data on geophysical properties in the subsurface that are nonlinearly related to the variables of interest and the standard relationships commonly used to infer these variables from geophysical data may induce artifacts that cannot be interpreted from a hydraulic viewpoint camporese et al 2011 groundwater models can be used to solve this problem through for example coupled hydrogeophysical inversion where the hydraulic and geophysical equations are considered as a coupled system pollock and cirpka 2012 a common approach for fusing geophysical data with direct measurements of hydrogeologic variables in this context is to employ geophysical data as part of the measurement model as follows kowalsky et al 2004 21 d aug d h d gp h t h y t u t θ h t gp y t u t θ η t h η t gp where d aug is an augmented vector of all observational data h t h is the measurement model that maps y t u t θ to the hydrological measurements d h h t gp is the measurement model that maps y t u t θ to the geophysical data d gp and η t h and η t gp are the observation stochastic error vectors for the hydrological and geophysical data respectively rs data usually combined with geographic information systems can also be a potentially useful source of information for groundwater modeling this is especially true in regional scale modeling in areas where other forms of data are scarce current air and satellite based rs technologies can penetrate the ground for only a few centimeters but this is enough to provide data for the inference of surface forcing and some geologic properties making rs a potentially valuable source of information in the study of shallow groundwater becker 2006 rs data is often supplemented with ground control measurements in order to scale rs data to the variable of interest or to estimate the error statistics i e uncertainty of the rs data hendricks franssen et al 2008 examples for the use of rs data in groundwater mdi include estimates of values and spatial patterns of groundwater model recharge rates from satellite images pertaining to precipitation actual evapotranspiration etc e g brunner et al 2004 hendricks franssen et al 2008 use of rs based digital elevation models dems to constrain groundwater flow model outputs and avoid erroneous artesian piezometric head values hendricks franssen et al 2008 employing geologic maps derived from rs data for groundwater prospecting e g providing information about hydraulic conductivities water reserves of water bearing formations and identification of faults and fracturing for groundwater modeling waters et al 1990 using rs imagery to identify and characterize boundary conditions for groundwater models this may include identification of streams lakes wetlands seepage areas recharge and evapotranspiration zones or dynamic monitoring of stream headwater becker 2006 3 8 3 fusion of field measurements and expert knowledge expert knowledge has long been identified as a key source of information for groundwater modeling because experts have the ability to interpret complex and ambiguous evidence based on their broader experiences o hagan 2012 this has made the fusion of soft data pertaining to expert knowledge and hard data obtained from field measurements an important topic in groundwater studies the informal use of expert knowledge in groundwater model conceptualization and parameter estimation is highly common formal mechanisms in this context are mostly based on the bayesian approach krueger et al 2012 in the bayesian approach the subjective belief of an individual expert or the inter subjective belief of several experts about the value of parameters or plausibility of alternative model structures can be represented by prior probability distributions through expert elicitation techniques beer et al 2013 rinderknecht et al 2014 these priors are then updated based on hard field measurement data this approach has been used in many previous groundwater studies for parameter estimation or model selection and structural uncertainty analysis e g hassan et al 2009 however this approach has been criticized for a number of reasons including the following 1 it neglects the imprecision essentially embedded in expert provided soft data which may lead to biased result lele and allen 2006 stein et al 2013 2 expressing expert knowledge in the form of probability distributions is often very difficult ross et al 2009 and 3 it is bound to the incorporation of expert knowledge regarding model parameters and structures and does not provide the means to include expert knowledge on other aspects of groundwater models such as state variables to solve these problems rajabi and ataie ashtiani 2016 proposed the use of fuzzy bayesian inference based on mcmc for incorporating expert knowledge in parameter estimation their method uses the power of fuzzy logic to provide a convenient framework for the representation of expert provided information regarding the various inputs to the bayesian inference algorithm furthermore it allows one to distinguishably model both uncertainty and imprecision in the fusion process 4 software and codes the mdi algorithms described in section 2 commonly involve large computational effort and hence their implementation inevitably requires computer programming while many mdi efforts in the groundwater literature rely on codes that are developed for the specific problems at hand and are not made available to the public some researchers institutions have focused their efforts on developing generic codes for this purpose these efforts have resulted in the development of several mdi software since the 1990s some of which are reviewed in table 2 these software have essentially transformed the way mdi is conducted in groundwater studies by paving the way for a mainstream change from trial and error techniques to automated mdi procedures mdi software used in the groundwater literature include 1 model dependent software that are developed for application in conjunction with specific groundwater models an example is modflowp hill 1992 2 model independent generic software such as pest doherty 1994 pest welter et al 2015 and ucode poeter and hill 1999 3 code packages mostly in r e g mcmc see http www stat umn edu geyer mcmc python e g pynsmc white and brakefield 2015 pyemu white et al 2016 and pymc patil et al 2010 and matlab e g dream vrugt 2016 the second and third categories can be used with any model often the only requirement is that the input and output files of the model are numerical ascii or text only these two categories are mostly community supported and open source and are also being used in other engineering fields most available codes and software are intended for parameter estimation and the absolute majority employ batch frequentist weighted lse with local derivative based optimization methods e g lm optimization the widespread use of these algorithms can be attributed to their ease of coding and affordability of computations in low dimensional problems there are also several codes available that are based on mcmc algorithms for bayesian parameter estimation e g dream in matlab mcmc in r and ucode mcmc lu et al 2014 the reason for such focus on parameter estimation as compared to model identification or state estimation is twofold 1 parameter estimation can often be performed by relatively simple automated modifications to the model input files while model structure or state updating requires a high level of interaction with the numerical model liu et al 2012 and 2 currently the generation of model structure realizations is mostly based on expert insight rather than formal methods making the development of automated model structure updating software difficult recent developments in mdi software for groundwater applications include developing parallel computing abilities e g parallel pest as in tang et al 2010 beopest see hunt et al 2010 and mcmc ucode see lu et al 2014 enabling cloud computing e g pest cloud see https pest cloud incorporating advanced regularization see http www pesthomepage org highly parameterized inversion php about pest using state of the art global optimization schemes see finsterle 2010 regarding itough2 and integrating mdi into risk based environmental management optimization e g estpp opt see white et al 2018 the pest suite will likely play a key role in the future of groundwater mdi one reason is that with the new modular nonintrusive parallel run manager named panther it is becoming easy for people to add programs to the pest suite and to run parallel computations on the cloud 5 discussion and prognosis for future work we defined mdi as a two way process between models and data and reviewed recent advances in mdi methods and applications in the groundwater literature the review shows that frequentist weighted lse is still the most widely used method for mdi in groundwater scientific literature and professional practice which is mostly due to the availability of open source user friendly software a multitude of case studies and a number of well established guidelines for its implementation however aided by advances in computing power and data handling there is a trend toward more extensive use of monte carlo based methods such as mcmc enkf smc and es in the literature and these methods are also gradually finding their way into professional practice the classic kf became popular in the groundwater scientific literature in 1990s and early 2000s but due to a number of limitations failed to become a mainstream practical method and is now mostly replaced by the enkf in the literature the exkf and vbms although popular in other fields e g weather prediction and atmospheric sciences have been given much less attention in the groundwater modeling community it is clear from this review that there are many tools and techniques for groundwater mdi and this diversity is needed for supporting different mdi objectives model and data types and computational constraints it is important to understand that the success of groundwater mdi does not necessarily depend on providing more data or using more sophisticated models but is mainly governed by their optimal synthesis and properly addressing the associated uncertainties this is an important reason for the significant interest in improving mdi methods in the literature the continuing progress of data acquisition technologies and the evolution of models means that the landscape of mdi in groundwater applications will continue to evolve in the future here we discuss a number of key issues that will likely form future directions 1 addressing computational challenges several key synthesis approaches used in mdi require a large number of model simulations this is most notably true for methods that rely on mcs such as mcmc enkf smc and es or stochastic meta heuristic optimization algorithms these synthesis approaches become computationally very expensive when the computational demand of a single model run is substantially high this has been an issue for the past several decades and interestingly the enormous increase of computer processing speed in recent years has not solved this problem the fact that computational demand remains to be an important issue to date and probably for the mid term future has mainly two reasons first recent advances in groundwater simulation software have mostly focused on increasing model fidelity i e improving the degree to which the model reproduces the behavior of the real world system resulting in continuous increase in their execution times carrera et al 2005 second we are seeing a constant shift from theoretical research on mdi using synthetic toy problems with limited computational demand e g henry problem henry 1964 to real world mdi applications involving computationally expensive groundwater models due to these reasons the computational challenge must be somehow confronted within the groundwater community in order to facilitate the success of mdi a review of literature shows that four main strategies are being pursued to address this problem 1 parallelization and grid computing applied to either or both the model and the synthesis approach for example see the parallel parflow model for simulating surface and subsurface flow kollet et al 2010 bürger et al 2012 see https parflow org xu et al 2013 for parallel mcmc joseph and guillaume 2013 for parallel enkf 2 replacing the model with data driven and physics free meta models such as polynomial chaos expansion pce e g laloy et al 2013 rajabi and ataie ashtiani 2016 3 improving the computational efficiency of synthesis methods e g vrugt et al 2009 and 4 employing cloud computing e g kurtz et al 2017 see hayley 2017 research on all four strategies is expected to continue in the future and it is expected that cloud computing will play an increasingly important role in solving the computational challenges of mdi in groundwater 2 accounting for local heterogeneities every technique currently available for the estimation of heterogeneous groundwater model parameters from data employs some level of averaging or smoothing through parameterization and regularization the consequence is that the results of parameter estimation may be locally quite flawed and this reduces the accuracy of model predictions that are sensitive to these local values hence much work is being currently done and will continue in the future on several fronts to alleviate these problems this includes developing methods for 1 use of by product information of regularized parameter estimation such as spatial covariance structure of the estimated field to identify misrepresented local details moore and doherty 2006 2 optimizing the choice of the limited number of parameters that are used for the reconstruction of the heterogeneous field e g jung et al 2011 and 3 adapting synthesis methods for the incorporation of more local details and hence more parameters in the estimation process e g tonkin and doherty 2009 the third approach inevitably includes developing strategies for solving the resulting computational challenges such as instability non convergence solution non uniqueness and solution non optimality 3 real time mdi cases for the use of automated field sensors that rely on communication technologies such as wsns have recently emerged in the groundwater literature these technologies allow for the monitoring of groundwater systems at much finer spatial and temporal resolutions than traditional manual sampling and analysis methods but the resulting data is prone to sensor and wsn faults e g stuck readings out of range errors abrupt shifts abnormal noise etc see szewczyk et al 2004 and hence requires the integration of fault detection methods in groundwater mdi techniques especially when sensor readings are fed automatically into models an example of studies addressing this issue is barnhart et al 2010 which employs a data reduction algorithm to identify and remove potentially faulty salinity data and then uses the remaining data for groundwater model parameter estimation by pest progress made in real time groundwater monitoring technologies have facilitated the development of real time or quasi real time decision support systems dsss the traditional and still widely used approach in groundwater dsss is to employ offline rules that optimizes the controls with the objective of minimizing the cost of operations e g rajabi and ketabchi 2017 but the emerging real time alternative also known as model predictive control mpc constantly revises and optimizes controls based on feedback from the system liu et al 2012 the ability to rapidly assimilate real time data and provide answers to imminent questions is gradually becoming an important part of groundwater modeling langevin and panday 2012 an example reference is drumheller et al 2017 the study uses hydraulic head and electrical conductivity data from a distributed sensor network for quasi real time model calibration and then performs simulation optimization with the aim of controlling aquifer recharge and recovery operations in a laboratory setup hendricks franssen et al 2011 use enkf for combining online observations of hydraulic head with numerical models for the real time characterization of groundwater flow in a real world urban aquifer their computational tool became operational at the water works zurich in 2009 4 developing codes and software for mdi despite the hugely valuable efforts by the groundwater and other research communities in developing software for mdi major gaps still remain these gaps which underpin future research and collaboration opportunities include 1 developing community supported open source data assimilations tools based on methods such as enkf smc etc development of such tools for instance the parallel data assimilation framework see http pdaf awi de trac wiki has helped other fields such as numerical weather prediction atmospheric sciences and more recently hydrology work on such tools has already started in the groundwater modeling community an example is pestpp ies which is an implementation of the iterative es lm algorithm of chen and oliver 2013 within the framework of pest pest model interface protocols see https github com dwelter pestpp 2 creating computer codes for groundwater model discrimination and structural uncertainty analysis progress in this regard depends greatly on developing algorithms that can automate this process and reduce its dependence on subjective expert opinion 3 developing codes for formal fusion of different types of groundwater related data e g geophysical and remote sensing data expert knowledge etc 5 bridging the gap between research and professional practice lastly the growing research practice gap has already been observed more generally in groundwater science simmons et al 2012 we also acknowledge that there is an existing gap between mdi practices in the research community and those in consulting industry and government and this gap seems to be growing this is evident from the fact that many of the more recent mdi methods are rarely applied outside of research settings closing this gap calls for more user friendly software guidelines for mdi method selection and application worked examples and case studies education and training acknowledgement the authors wish to thank the editor in chief professor geoff syme and two anonymous reviewers for their valuable comments which helped to improve the final manuscript behzad ataie ashtiani and craig t simmons acknowledge support from the national centre for groundwater research and training australia behzad ataie ashtiani also appreciates the support of the research office of the sharif university of technology iran 
6901,we define model data interaction mdi as a two way process between models and data in which on one hand data can serve the modeling purpose by supporting model discrimination parameter refinement uncertainty analysis etc and on the other hand models provide a tool for data fusion interpretation interpolation etc mdi has many applications in the realm of groundwater and has been the topic of extensive research in the groundwater community for the past several decades this has led to the development of a multitude of increasingly sophisticated methods the progress of data acquisition technologies and the evolution of models are continuously changing the landscape of groundwater mdi creating new challenges and opportunities that must be properly understood and addressed this paper aims to review analyze and classify research on mdi in groundwater applications and discusses several related aspects including 1 basic theoretical concepts and classification of methods 2 sources of uncertainty and how they are commonly addressed 3 specific characteristics of groundwater models and data that affect the choice of methods 4 how models and data can interact to provide added value in groundwater applications 5 software and codes for mdi and 6 key issues that will likely form future research directions the review shows that there are many tools and techniques for groundwater mdi and this diversity is needed to support different mdi objectives assumptions model and data types and computational constraints the study identifies eight categories of applications for mdi in the groundwater literature and highlights the growing gap between mdi practices in the research community and those in consulting industry and government keywords model data interaction groundwater modeling uncertainty analysis data assimilation data fusion 1 introduction the complexities of physics based numerical models of groundwater flow and contaminant transport have grown substantially since the 1990s moving from early two dimensional steady state homogeneous or layer cake models to dynamic three dimensional models capable of simulating highly heterogeneous formations and complex phenomena such as coupled and multiscale processes this growing sophistication has resulted in models with significantly more data requirements compared to the past in the last three decades we have also seen a significant increase in the role of groundwater models in decision making processes refsgaard et al 2010 models are now used throughout the world to assist decision making on issues such as optimal groundwater extraction e g ketabchi and ataie ashtiani 2015a b triki et al 2017 groundwater contamination response e g ritzel et al 1994 aquifer recharge and recovery drumheller et al 2017 groundwater remediation and cleanup e g bayer and finkel 2004 2007 singh and minsker 2008 and determination of wellhead protection areas e g wheater et al 2000 feyen et al 2001 the increasing role of models in decision making means that models are required to provide more reliable predictions with proper estimation of prediction uncertainties regardless of a model s level of complexity this can only be achieved if the appropriate data are available and effectively incorporated into the modeling process in parallel hydrogeology has also become increasingly data rich due to the significant progress made in technologies that enable the collection transfer and storage of data fasbender 2008 barnhart et al 2010 advances in geophysical remote sensing e g satellite imaging smart meter and field sensor technologies have led to a massive upsurge in data quantity and diversification of data types moreover thanks to the impressive developments in communication technologies such as wireless sensor networks wsns data can now be delivered at extremely higher rates the past two decades have also seen the creation and expansion of many national and regional databases for geologic and groundwater related data e g united states geological survey groundwater database https water usgs gov ogw data html south africa national groundwater archive http www dwa gov za groundwater nga aspx etc in which a massive amount of data is being continuously collected szalkai et al 2007 these data related developments have created new challenges such as online data heterogeneous data and massive data issues which are well known challenges in some other fields of science but were not previously encountered by the groundwater modeling community hayley 2017 these trends have changed our conception of the relationship between models and data traditionally this relationship was mainly concerned with employing data for model calibration and validation but in a broadened and increasingly popular perspective that we refer to as model data interaction mdi this relationship is viewed as a two way process in which on one hand data can serve the modeling purpose by supporting model refinement discrimination uncertainty analysis etc and on the other hand models can provide a framework for guidance of data collection and data analysis by assisting data fusion interpretation interpolation etc to the author s knowledge the term mdi has not been previously used in the groundwater literature to describe this two way process but it has been used in some other fields of science and engineering e g norby et al 2016 from this perspective mdi offers great potential a number of which we review below such as sources of data in groundwater studies are numerous but no single data source can provide a complete picture of a groundwater system linde et al 2017 and therefore multiple data sources must be integrated in many instances the nature and spatiotemporal scale of hydrogeologic data is so diverse that they are not readily related to one another making data integration very difficult porter et al 2000 in these increasingly familiar situations mdi provides a unique framework for integrating multiple types of data and for solving related problems such as data conflict detection and resolution and outlier detection brunner et al 2017 with the progress of measurement technologies we are approaching a state where we are no longer hindered by the power to collect more data but by our ability to extract valuable information from available data in these circumstances mdi opens new opportunities for information extraction from different data types mdi can improve the performance of groundwater models and open the model structure selection and parameter estimation processes to new and previously untapped sources of information rajabi and ataie ashtiani 2016 this can alleviate the data scarcity problem frequently encountered in model construction efforts moreover there is a growing recognition of the importance of characterizing the uncertainties in our models and data beven 2010 in this sense mdi provides a consistent tool for examining all sources of uncertainty in a common framework data collection in groundwater studies is currently guided mostly by intuition and expert knowledge or by practical considerations rather than a quantitative understanding of what data will most reduce uncertainties and how much data are required to do so kikuchi et al 2015 in this context mdi techniques can be valuable tools in the guidance of groundwater data collection setting the stage for a shift of paradigm in this area mdi has been the topic of extensive research in the groundwater community for the past several decades leading to the development of a large number of increasingly sophisticated algorithms these studies have transformed mdi from the simple direct insertion of data into models to advanced sequential data assimilation techniques moradkhani et al 2005 liu et al 2012 a significant portion of the progress in groundwater mdi has originated from developments in other fields of science and technology such as meteorology atmospheric sciences oceanography robotics defense aerospace etc examples of reviews in these fields include ghil and malanotte rizzoli 1991 wang et al 2009 peng et al 2011 several issues have motivated us to write a review paper on groundwater mdi these include 1 recent trends that have changed the landscape of mdi in the groundwater literature creating new challenges and opportunities that must be properly understood and addressed 2 the multitude of mathematical algorithms presented in the literature for mdi that have made the topic confusing and hard to penetrate even for the experienced modeler and 3 lack of a comprehensive review on the subject although a number of notable reviews on related terms such as inverse modeling e g carrera et al 2005 2010 zhou et al 2014 and uncertainty analysis e g refsgaard et al 2012 wu and zeng 2013 linde et al 2017 are available the more general topic of mdi in the groundwater literature has not been yet reviewed the key objectives of this paper can be summarized as follows 1 to review the basic theoretical concepts and present a reasonably simple classification of different frameworks and algorithms for anyone interested in obtaining an overview of mdi 2 to analyze the pros cons and underlying assumptions of key algorithms with the intention of helping researchers and practitioners choose appropriate algorithms for various situations 3 to highlight different ways that models and data can interact to provide added value in groundwater applications 4 to identify codes and software previously used for mdi in the groundwater literature and explain key trends in this regard and 5 to identify key issues and gaps that will likely form future directions the outline of the paper is demonstrated in fig 1 it should be noted that almost every groundwater modeling study in the literature involves some component of mdi because as in any other field of engineering models without data are fantasy nisbet et al 2014 so it is rather impossible to be exhaustive in this review but we focus our review on a number of significant papers published largely over the last two decades which deal with novel formal mathematical algorithms for mdi the number of citations and our subjective judgment of the quality and significance of these papers has played a key role in their selection 2 review of theoretical concepts and techniques groundwater models are generic computer codes that use numerical algorithms to solve the partial differential equations that govern groundwater flow and also often contaminant transport these generic codes become site specific models when data obtained from a particular geographical area is used to 1 characterize the structure and parameters of the model these tasks are referred to as model structure identification and parameter estimation or model calibration respectively 2 test or validate the model in a procedure often referred to as model verification or validation the term model selection is also used in this regard if alternative plausible models exist konikow and bredehoeft 1992 oreskes et al 1994 beven 2018 the resulting models are used by research government and consulting communities for a variety of objectives including understanding of hydrogeological systems and their interacting components across different scales replication of past system behavior forecast of system responses to potential future stresses and management practices or to guide future data collection endeavors beven and young 2013 doherty and simmons 2013 as it is not possible for models to characterize groundwater systems perfectly model outputs should be associated with uncertainty intervals making uncertainty analysis an important part of the entire modelling process freeze et al 1990 1992 data can be used in a systematic way to refine both model predictions and their uncertainty estimates within the framework of different modeling objectives this procedure is often called state estimation model verification or selection parameter estimation guidance of future data collection and state estimation encompass different aspects of mdi the mdi process results in transformation of the initial datasets into new sets of data for instance assume that we are using sparse hydraulic conductivity k data obtained from pumping tests in conjunction with hydraulic head h data measured in a number of observation wells to estimate k values for a groundwater model through model calibration the original k values obtained from the pumping tests are rarely left unchanged by the time the model is calibrated the calibration hides some of the unknowns e g heterogeneity but also affects the representative scales as k values for the pumping tests may for instance represent a smaller region than the one being used in the calibration process moreover the calibration process uses sparse measurements of k to generate estimates that cover the entire modeling domain it also combines the information contained in k and h data to estimate the hydraulic conductivity these inevitable outcomes of mdi can be leveraged for a variety of purposes including customizing data resolution improving data coverage and fusing different forms of data 2 1 framework of model data interaction from the above discussions we can infer that mdi is not a one time occurrence but a continuous process that has many aspects and applications regardless of the intended application mdi rests on three foundations forward model data and synthesis method raupach et al 2005 a forward model of the system denoted by f propagates the state e g piezometric heads chemical concentrations temperatures etc at time y t to time y t 1 based on 1 a set of often assumed to be time invariant input parameters θ which include physical descriptions of subsurface characteristics e g porosity hydraulic conductivity etc and contaminant transport and transformation characteristics e g dispersivity sorption factor chemical reaction rates etc and 2 time dependent external forcing terms u t which include surface recharge lateral inflow river aquifer interactions etc this notion can be formulated as leisenring and moradkhani 2011 1 y t 1 f y t u t θ ω t where the generally state dependent and stochastic model error vector is represented by ω t and the conceptual and mathematical model structure is embedded in f this notion is schematically illustrated in fig 2 data denoted by d can be related to direct or indirect measurements hard data or qualitative assessments soft data of state variables d y external forcing terms d u parameters d θ or model structure d f moradkhani et al 2005 liu and gupta 2007 table 1 summarizes common types of data in groundwater mdi the measurement model or observation equation h t is the mapping from the parameters states and external forcing terms to the various types of data liu et al 2012 formulated as 2 d h t y t u t θ η t where the stochastic term η t represents observation error which is an inherent part of the measurement model the mean values of ω t and η t denote systematic bias and their covariance signifies the uncertainty in the model predictions and observations liu and gupta 2007 the mean and covariance of ω t and η t are generally not directly observable and are also difficult to estimate by indirect methods hence they are often assigned presumptive values a common practice is to assign uncorrelated gaussian distribution with zero mean i e white noise to ω t and η t e g fu and gómez hernández 2009 laloy et al 2013 the synthesis method is a formal mathematical algorithm that combines the model f and data d by varying some properties of the model to give their optimal combination accounting for the associated uncertainties wang et al 2009 keenan et al 2011 in general a host of methods exist for synthesis with widely varying degrees of sophistication it is important to realize that due to the diversity of model and data types and the various objectives and simplifying assumptions that are subsumed under mdi no universally best synthesis method exists porter et al 2000 peng et al 2011 zhou et al 2014 however groundwater mdi has several specific characteristics that affect the choice of a synthesis method 1 groundwater models are moderately to highly nonlinear samuel and jha 2003 schöniger et al 2012 wallis et al 2014 siade et al 2017 2 they result in state variables e g heads and concentrations that are time dependent eigbe et al 1998 3 they are commonly cpu intensive and have high computational demands most notably in real world applications as they rely on large systems of equations that need to be solved for each model run carrera et al 2010 rajabi et al 2015b 4 they are inherently high dimensional with respect to parameters external forcing terms and states unless strict parameterization is employed siade et al 2017 5 their parameter and state variables exhibit non gaussianity in certain cases such as strong spatial heterogeneity of hydraulic conductivity contaminant transport with sharp fronts as in advection dominated processes and curvilinear crispy geometries e g river beds hendricks franssen et al 2009 hendricks franssen and kinzelbach 2009 schöniger et al 2012 crestani et al 2013 6 they are controlled by physical properties e g permeability that are characterized by a high degree of heterogeneity possess scales of variation spanning several orders of magnitude and are scale dependent hill and tiedeman 2006 kerrou et al 2008 7 complex interactions exist between different inputs of a groundwater model e g between hydraulic conductivity and dispersivity gelhar et al 1992 8 groundwater related observations are often sparse and incomplete as they include an inadequate set of points in space and time to fully characterize the groundwater system rajabi and ataie ashtiani 2016 and 9 groundwater related observations are commonly indirect and have scaling differences with model parameters states and external forcing terms carrera et al 2005 liu and gupta 2007 2 2 uncertainty in model data interaction mdi has proven to be promising in improving understanding quantification communication and reduction of uncertainty in both models and data freeze et al 1992 porter et al 2000 liu et al 2012 in many cases uncertainty analysis is embedded in the mdi process sources of uncertainty in groundwater modeling can be classified into the following four interconnected categories 1 structural uncertainty which arises from the fact that models are inherently simplified and imperfect approximations of complex real world processes neuman 2003 structural uncertainty includes conceptual uncertainty arising from e g characterization of heterogeneity patterns type of boundary conditions time regime etc and mathematical uncertainty arising from alternatives in the mathematical implementation of conceptual models bredehoeft 2005 ma and la pointe 2011 2 parameter uncertainty which results from the fact that groundwater model parameters are often aggregate quantities that should be estimated from sparse and sometimes indirect measurements or qualitative assessments across the heterogeneous geological domain yeh 1986 rajabi and ataie ashtiani 2014 3 data uncertainty which arises from instrument uncertainty due to imperfect measurement devices and representativeness uncertainty due to inconsistency in spatial and or temporal scales between the measured variables and the associated model variables liu and gupta 2007 4 extrapolation uncertainty which stems from the temporal prediction errors in the estimation of future external forcing terms from past data dessai and hulme 2007 when the past state of the groundwater system is being simulated structural parameter and data uncertainties collectively propagate through the model and result in model uncertainty alternatively when the future state is being predicted all four sources of uncertainty affect predictive uncertainty liu and gupta 2007 throughout this paper we will refer to both as model output uncertainty the above concepts are illustrated in fig 3 there is some dispute regarding which source dominates model uncertainty in groundwater simulations some references suggest parameter uncertainty e g smith and schwartz 1981 hendricks franssen and kinzelbach 2009 schöniger et al 2012 and others suggest structural uncertainty e g bredehoeft 2005 højberg and refsgaard 2005 refsgaard et al 2012 this dispute is partly due to the different approaches employed in handling uncertainty nevertheless there is a wide consensus that 1 structural uncertainty is the most difficult to quantify refsgaard et al 2006 2 ideally all sources of uncertainty should be simultaneously addressed to avoid misleading uncertainty predictions pappenberger and beven 2006 linde et al 2017 3 different uncertainty sources have distinct characteristics and hence require different approaches to deal with rajabi and ataie ashtiani 2016 and 4 a challenging and important aspect of quantifying model uncertainty is to account for the effect of interaction among different uncertainty sources liu et al 2012 a review of the literature shows that there are basically two approaches to handling different sources of uncertainty in groundwater mdi in the first approach different sources of uncertainty are explicitly lumped together and mapped into model parameters some have noted that this method can create bias in uncertainty estimation kerrou et al 2008 the second approach is to address different sources of uncertainty separately according to their specific characteristics the most common way to do this is to characterize parameter data and extrapolation uncertainties as continuous probability distributions often normal log normal or uniform rajabi et al 2015b structural uncertainty is commonly described by discrete scenarios for the model structure with probabilities assigned to the scenario s existence refsgaard et al 2012 this results in multi model ensembles which are formed for example by defining different parameterizations of the aquifer system e g feyen et al 2001 since the selection of individual models in the ensemble is mostly based on expert insight rather than formal methods this approach is quite subjective and the scenarios may not represent a complete sampling of the model space beven 1993 liu et al 2012 hence obtaining reliable uncertainty estimates becomes a matter of both chance and experience nonetheless since no other commonly accepted approach exists this remains the dominant approach 2 3 review of synthesis methods in this sub section we review and classify a number of key synthesis methods previously used in the groundwater literature for mdi a map of these methods is provided in fig 1 to guide the interested reader through this sub section the review is meant to provide an overview of methods and so the mathematical descriptions are kept to a minimum and references are provided for further reading 2 3 1 manual insertion direct and indirect methods in the simplest observation scenario the model structure and values of all model parameters θ external forcing terms u t and initial states y t are measured or inferred from data in other words adequate data is available to fully characterize the groundwater system perform model simulations by manual insertion and estimate the state variables at a later time y t 1 at all points in the discretized domain of the problem kerrou et al 2008 the resulting simulations can be augmented with forward uncertainty propagation analysis upa to characterize the effect of measurement noise on the uncertainty in state estimations e g rajabi and ataie ashtiani 2014 rajabi et al 2015a an alternative observation scenario is that data on some model parameters and external forcing terms is sparse but the state y is known exhaustively at all nodes of the discretized domain at times t and t 1 in this scenario the unknown variables of the model can be estimated by the direct approach of solving the inverse problem formulated simply as θ f 1 y t u t y t 1 often neglecting the stochastic ω t term neuman 1973 only if the relationship between model inputs and state variables are assumed to be linear can the solution be calculated by closed form matrix expressions wang et al 2009 even so a key challenge of the direct method is the ill posedness and the singularity of the matrices involved in the numerical formulation zhou et al 2014 some researchers have tried to alleviate this problem by building overdetermined systems of equations i e systems that have more equations than unknowns e g ponzini and lozej 1982 these two scenarios namely having adequate data to fully characterize either all model inputs or state variables are mostly relevant to hypothetical and laboratory scale problems and are rare if not nonexistent in real world cases where data on various model inputs and state variables are typically sparse due to physical and financial limitations rajabi and ataie ashtiani 2016 in the case of data scarcity the indirect approach should be applied there are two broad classes of indirect approaches in mdi frequentist also known as classical or non bayesian and bayesian or probabilistic we will use this classification in the subsequent sub sections although other classifications for indirect approaches also exist which include batch vs sequential methods e g wang et al 2009 and optimization vs sampling methods e g zhou et al 2014 2 3 2 frequentist approach the frequentist approach assumes that model variables e g parameters θ are possibly unknown but have deterministic values and the only source of randomness is data uncertainty based on this assumption the frequentist approach tries to construct a point estimate for each unknown variable often along with its confidence interval that quantifies the accuracy of the estimation process bernardo and smith 2001 these estimated values are then used for deterministic state reconstruction or prediction the frequentist approach assumes no prior distribution for the unknown variables but many algorithms used in the frequentist approach allow for use of prior information to provide initial values and lower or upper bounds on the variations of the unknown parameters or to penalize departures from prior estimates alcolea et al 2006 the most popular method in the framework of the frequentist approach and historically the first widely successful inverse method in groundwater applications is maximum likelihood estimation mle carrera and neuman 1986a mle it is not based on the linearity assumption and does not depend on any approximation for the relationship between the state variables and the model inputs and it can also incorporate many types of data mle estimates parameters θ or external forcing u t in such a way that the model response i e state variable fits the data dy in some optimal sense in other words the most likely parameter values are those that maximize the likelihood of observing the data 3 θ mle argmax θ l θ d y where argmax θ refers to the input parameters θ or similarly u t called arguments at which the function outputs are as large as possible and l denotes likelihood a common way to formulate the likelihood function can be expressed as follows zhou et al 2014 4 l θ d y e x p 1 2 i 1 n obs f i y t 1 u t θ d y i t c i 1 f i y t 1 u t θ d y i where c i 1 is the corresponding covariance of the observation errors and n obs is the number of measurements in order to facilitate statistical analysis the measurement error is often assumed to be gaussian in mle mclaughlin and townley 1996 least squares estimation lse is a special case of mle based on the assumption that errors in data are independent and normally distributed with constant unknown variance nonlinear lse algorithms were first applied to distributed parameter groundwater problems when numerical models became widely available in the 1960s and 1970s in lse the sum of squared errors l2 norm between the observed values and values predicted by the model are minimized the ordinary least squares estimator is defined as 5 θ les argmin θ i 1 n d y i f i y t 1 u t θ 2 partly due to its simplicity and ease of implementation lse is widely used for parameter estimation in groundwater modeling applications and has been employed in several highly popular inverse codes see section 4 in weighted lse weighting factors are used to express the relative magnitude of values and confidence in data a regularization or plausibility term can be included in the objective function above in order to ensure stability of the optimization problem medina and carrera 1996 lse is highly sensitive to outliers and hence some studies employ other frequentist objective functions such as absolute value of the difference between measured and computed values l1 norm woodbury et al 1987 nash sutcliffe index e g mugunthan et al 2005 and minkowski distance function e g zhou et al 2012 mle lse and other similar frequentist optimization methods fall in the field of calculus of variations and so they are sometimes referred to as variational methods rayner et al 2016 optimization algorithms used in the context of the frequentist approach include 1 local optimization methods which often quickly converge to the optimum if the search is started from a point in sufficient proximity of the optimum but only guarantee local convergence as they do not have a mechanism to escape from local optima mugunthan et al 2005 local methods used in the context of groundwater mdi include 1 1 derivative based or gradient based methods such as the widely used levenberg marquardt lm algorithm and its modifications e g nowak and cirpka 2004 and the conjugate gradient method e g carrera and neuman 1986b which are both highly efficient especially for low dimensional problems and have been widely incorporated in popular inverse codes these methods can fail if the objective function is discontinuous or their derivatives are discontinuous non smooth multi modal or ill conditioned 1 2 derivative free methods which are used when derivative information is unavailable unreliable or impractical to obtain due to the above mentioned problems rios and sahinidis 2013 examples of these methods are pattern search hooke and jeeves 1961 including generalized pattern search and mesh adaptive direct search e g zhou et al 2012 haddad et al 2013 and nelder mead simplex algorithm nelder and mead 1965 e g lambot et al 2002 2 global optimization methods which are more likely to find the global optima for the objective functions in comparison to local methods wang et al 2009 global methods can be further classified into 2 1 deterministic or exact methods such as multilevel coordinate search huyer and neumaier 1999 e g lambot et al 2002 2004 and branch and bound method huyer and neumaier 2008 e g sun et al 2006 2 2 stochastic search algorithms which rely on probabilistic search rules to find good solutions and can locate the neighborhood of the global optima relatively fast but their efficiency comes at the cost of computational effort and inability to guarantee global optimality stochastic optimization methods used in the context of groundwater mdi are mostly meta heuristic methods meta heuristics are a group of both local and global optimization algorithms that are inspired by natural processes ketabchi and ataie ashtiani 2015c these include evolution as in genetic algorithm holland 1975 e g samuel and jha 2003 and derandomized evolution strategies hansen and ostermeier 2001 e g bayer and finkel 2004 social behavior of biological organisms as in ant colony optimization dorigo and stützle 2004 e g abbaspour et al 2001 particle swarm optimization kennedy and eberhart 1995 e g haddad et al 2013 and controlled cooling associated with a physical process as in simulated annealing e g tsai et al 2003 meta heuristic algorithms can find acceptable solutions in a reasonable time in both complex and large search domains e g ketabchi and ataie ashtiani 2015c local and global methods can be hybridized into efficient optimization methods for example lm can be combined with a stochastic quasi monte carlo algorithm to search for global optimal values peng et al 2011 2 3 3 bayesian approach the bayesian approach also referred to as bayesian inference has two key distinctions with the frequentist approach first it formally considers model inputs and outputs as random variables and hence formulates the entire problem in a probabilistic framework fasbender et al 2008 and second it allows for formal consideration of prior information in the inference process wang et al 2009 as discussed throughout the rest of the paper these two key distinctions provide a convenient framework for uncertainty analysis data fusion regularization data worth analysis and incorporation of soft data in groundwater applications we shall first present the formulation of bayesian inference as a parameter estimation problem and then generalize it to other model components we denote the prior distribution of the parameter set θ with p θ which is prior beliefs on the parameter values before employing a specific dataset we also represent the likelihood function that characterizes the likelihood of the observation set d y given a certain parameter set θ by p d y θ the distribution of observation d y given θ is tied to the measurement model in bayesian inference the posterior distribution p θ d y is obtained through the application of bayes theorem gamerman and lopes 2006 6 p θ d y p d y θ p θ p d y where p d y is the proportionality or normalization constant which characterizes the evidence or the marginal probability of the data and can be computed from gamerman and lopes 2006 7 p d y p d y θ p θ d θ the lack of prior information can be expressed by using a non informative prior gelman et al 2013 in the case where there are multiple measurements e g measurements at different times 1 2 t denoted by d y 1 t the joint likelihood of all measurements is the product of distributions of individual measurements if the measurements are assumed to be conditionally independent the resulting posterior distribution is box and tiao 2011 8 p θ d y 1 t 1 z p θ k 1 t p d y k θ where z is the normalization constant given by 9 z p θ k 1 t p d y k θ d θ the predictive posterior distribution is the distribution of not yet observed state variables when all the information in the observed measurements and the model is used the predictive posterior distribution can be estimated as follows box and tiao 2011 10 p y t n d y 1 t p y t n θ p θ d y 1 t d θ the bayesian posterior distribution can be reduced to point estimates through a host of methods which include choosing the mean or maximum of the posterior distribution the latter approach is often called the maximum a posteriori map estimate e g kowalsky et al 2004 mle can be seen as a map estimate with uniform prior p θ 1 on the parameter set θ in other words the bayesian approach provides a formal way of including prior information and regularization terms into mle särkkä 2013 the same notion can be applied to the estimation of all model components based on the sequence of conditional dependence described as f θ a n d u t y t dependent variables appear at the end of the arrows liu and gupta 2007 11 1 p f d y p d y f p f p d y 11 2 p θ d y f p d y f θ p θ f p f p d y f 11 3 p u t d y f θ p d y u t f θ p u t f θ p θ f p f p d y f θ 11 4 p y t d y f θ u t p d y y t f θ u t p y t f θ u t p u t f θ p θ f p f p d y f θ u t 2 3 3 1 batch vs recursive bayesian inference when various types of data obtained at different time steps are simultaneously taken into account as a single whole dataset the resulting posterior distribution is denoted by batch bayesian estimation this type of solution to bayesian inference is very common in groundwater applications e g hassan et al 2009 laloy et al 2013 rajabi and ataie ashtiani 2016 however this full posterior formulation has the disadvantage that each time we obtain a new measurement the full posterior distribution must be recomputed this is particularly a problem in dynamic estimation where measurements are typically obtained one at a time and we would want to compute the best possible estimate after each measurement särkkä 2013 so alternatively if we treat the posterior distribution obtained from data for the previous time step as the prior for the current time step the result is called recursive or sequential bayesian estimation or bayesian filtering the recursive formulation of bayesian estimation has several useful properties 1 parameter estimates can be updated gradually as soon as new observations arrive paving the way for online learning this is particularly useful when the problem is sequential by nature wang et al 2009 as in a groundwater plume with time variable source or when data is collected gradually and it needs to be incorporated into model estimations without having to solve the problem from the start el gharamti et al 2013 zhou et al 2014 2 it allows for reducing the computational size of the problem when the problem is computationally expensive bruhwiler et al 2005 3 it allows for considering the temporal evolution of parameter values i e parameters are assumed to be time dependent stochastic processes hence θ t instead of θ särkkä 2013 4 it does not require storage of all past information about the states and parameters moradkhani et al 2005 el gharamti et al 2013 2 3 3 2 numerical methods for batch bayesian inference in practical problems involving the estimation of parameters external forcing terms or model states exact analytical solutions for the continuous posterior distribution in batch bayesian inference are available for very limited combinations of model forms and probability functions such as the normal linear model qian et al 2003 khaleghi et al 2013 this necessitates the use of numerical approximation techniques markov chain monte carlo mcmc methods or samplers are a general class of strategies that provide a powerful tool for numerical approximation of the posterior distribution in batch bayesian inference mcmc came into widespread use as a tool for bayesian inference in science and engineering with the work of tanner and wong 1987 and gelfand and smith 1990 they were introduced into the groundwater literature by oliver et al 1997 and have been the dominant method for numerical approximation of batch bayesian inference in groundwater modeling applications ever since as the name suggests mcmc methods employ monte carlo concepts in the framework of markov chains they attempt to generate monte carlo samples from the posterior distributions conditioned on the observations by a special sequential process in which each new sample depends on the properties of the sample drawn immediately before it and not the more early ones thus creating a markovian chain of samples in mcmc these samples can be drawn from a distribution even if all that is known about the distribution is how to estimate the probability density for the samples gamerman and lopes 2006 van ravenzwaaij et al 2016 which is a very beneficial aspect of mcmc as the posterior distributions are unknown at the onset of calculations if the markovian chain is sufficiently large often on the order of 103 to 105 samples in previous groundwater applications e g hassan et al 2009 laloy et al 2013 rajabi and ataie ashtiani 2016 it will eventually converge to the stationary posterior distribution of the parameters andrieu et al 2003 estimation of the probability density for each sample constitutes a forward model simulation and hence when dealing with cpu intensive groundwater numerical models mcmc methods become extremely demanding in terms of the required computations hendricks franssen and kinzelbach 2008 the main difference amongst various mcmc methods is how sampling is implemented based on these general concepts there are two central notions used for building samplers tierney and mira 1999 1 dimension reduction by conditioning which is the foundation of the gibbs sampler e g michalak 2008 and 2 proposal and rejection which is the basis of the metropolis hastings e g laloy et al 2013 and similar algorithms such as adaptive metropolis am e g hassan et al 2009 wu et al 2011 and delayed rejection adaptive metropolis dram e g rajabi and ataie ashtiani 2016 these two notions have also been combined into what is called metropolis within gibbs samplers e g cui et al 2013 generally speaking there is no universally optimal mcmc algorithm and the choice of an appropriate mcmc algorithm depends on the specific nature of the problem nevertheless some researchers have proposed mcmc algorithms that seem to offer great potential for increasing the computational efficiency in comparison with more traditional mcmc algorithms these novel mcmc algorithms often rely on increasing the acceptance rates of proposals e g vrugt et al 2009 dimensionality reduction of the forward simulations e g laloy et al 2013 or parallelization of mcmc computations e g laloy and vrugt 2012 joseph and guillaume 2013 an alternative to mcmc is importance sampling is e g ng et al 2009 is is an algorithm for generating weighted samples i e particles from the posterior distribution the main difference between is and mcmc is that each of the particles in is has an associated weight which reflects its ability to match observations lu and zhang 2003 särkkä 2013 similar to mcmc is does not rely on the implicit gaussian and linearity assumptions but is can be inefficient if the unconditional probability density of the states is a weak approximation of the conditional density and can especially become computationally infeasible when the state vector is high dimensional and particles are computationally demanding daum and huang 2003 2 3 3 3 bayesian filtering the objective of bayesian filtering is to estimate the time varying state of the system or parameters and external forcing terms as described in section 3 which is observed through sparse and noisy measurements chen 2003 in bayesian filtering the marginal posterior distributions or filtering distributions of the state variables at time step k i e y k are computed using the history of measurements up to and including the time step k bayesian filtering generally includes two stages a prediction stage and an update stage in the prediction stage the distribution of the state y k is computed based on measurements in previous time steps by doucet et al 2001 chen 2003 12 p y k d y 1 k 1 p y k y k 1 p y k 1 d y 1 k 1 d y k 1 in the update stage the new measurements d y k is used to update the distribution obtained in the prediction stage by applying bayes rule 13 p y k d y 1 k 1 z k p d y k y k p y k d y 1 k 1 where z k is the normalization constant given by 14 z k p d y k y k p y k d y 1 k 1 d y k 2 3 3 4 closed form solutions for the bayesian filter a few classes of filtering problems have closed form solutions with the kalman filter kf kalman 1960 being the most popular one kf is based on a linear and gaussian assumption for the state space models described as follows eigbe et al 1998 15 a y k φ k 1 y k 1 q k 1 15 b d y k h k y k r k where q k 1 n 0 q k 1 is the process noise r k n 0 r k is the measurement noise and the initial distribution is assumed to be y 0 n m 0 ψ 0 φ k 1 is the transition matrix describing the forward model and h k is the measurement model matrix starting from the initial distribution of the state the prediction stage of the kf tries to estimate the mean and covariance of the state for the next time step by eigbe et al 1998 16 a m k φ k 1 m k 1 16 b ψ k φ k 1 ψ k 1 φ k 1 t q k 1 the update stage subsequently revises these estimations by employing data for time step k d y k as follows eigbe et al 1998 17 a m k m k l k d y k h k m k 17 b ψ k ψ k l k h k ψ k h k t r k l k t where l k is the kalman gain matrix wang et al 2009 kf can be further simplified by empirical forcing of the model fields toward the observed values which is called nudging lahoz et al 2007 the use of kf in groundwater mdi problems dates back to the 1970s e g mclaughlin 1976 and it has been applied to a range of applications ever since however the popularity of the classic kf in groundwater literature is considerably less than the more general domain of hydrology where kf is commonly applied to rainfall runoff modeling flood forecasting rainfall prediction etc see liu et al 2012 the reason is that kf in its most basic form has several key limitations which are particularly problematic in groundwater applications 1 it is based on the linearity assumption whereas groundwater flow and solute transport models are nonlinear zhou et al 2014 2 it cannot break down the computations over space the way it does over time and hence cannot account for the spatial physical and statistical relationships of groundwater systems porter et al 2000 3 there is often not enough information about error structures to fill the large matrixes of eq 17 b with meaningful numbers reichle 2008 and 4 it is computationally expensive for high dimensional problems and is hence strongly restricted to small size problems hendricks franssen and kinzelbach 2008 variational bayesian methods vbms notably the sequential 4dvar method and its batch counterparts 1dvar and 3dvar where 1d and 3d refer to one or three spatial dimensions the 4th dimension in 4dvar is time reichle 2008 and var stands for variational can be viewed as simplifications of the kf as they do not propagate the state covariance matrix explicitly liu et al 2012 vbms have relatively low computational demand and are preferred for use with computationally expensive models and large dimensional problems with poorly related nonlinear observations rawlins et al 2007 however vbms do not provide an estimate of predictive uncertainty by themselves peng et al 2011 vbms have been used extensively in the numerical weather prediction community one of the rather few applications in groundwater mdi is kabir et al 2017 which employs 3dvar and 4dvar for state estimation in a hypothetical test case more applications of vbms are expected in future groundwater studies 2 3 3 5 numerical approximations for the bayesian filter due to the limiting nature of closed form solutions and the intractability of the bayesian filtering equations särkkä 2013 several numerical approximation techniques have been proposed the most popular of such techniques in the groundwater literature are briefly reviewed in the following paragraphs extended kalman filter exkf gelb 1974 is a numerical approximation method which forms a taylor series expansion at the nominal or map solution to provide a linear approximation of the nonlinear and non gaussian state space models exkf has been applied to groundwater mdi problems by e g leng and yeh 2003 and yeh and huang 2005 exkf has several major setbacks that affect its application to groundwater mdi 1 the covariance approximation deteriorates with time particularly when the taylor series approximation is poor as in highly heterogeneous fields zhou et al 2014 2 it can be computationally very demanding due to the error covariance propagation evensen 2003 especially for finely discretized groundwater models and 3 it can lead to unstable results or even divergence when the nonlinearity in the system is strong miller et al 1994 moradkhani et al 2005 due to these setbacks the exkf has lost popularity in the groundwater literature ensemble kalman filter enkf is another method which was first introduced by evensen 1994 and later modified by burgers et al 1998 and is a monte carlo variant of the kf in enkf the probability distribution of state y k is represented by ensemble of realizations y k 1 y k 2 y k n this ensemble is built by sampling from the known distribution of y 0 in the first step of computations each of these realizations is then separately propagated through time in the subsequent steps by a two stage prediction update procedure in each time step the mean and covariance can be explicitly computed based on the realizations noting that the prediction stage involves a model simulation for each realization in the ensemble observations are treated as random variables by generating an observation ensemble with a mean equal to the actual observation at each time and using a predefined covariance the enkf also represents the model errors by generating perturbations at each time step evensen 2003 2009 the enkf has a number of advantages which are particularly desirable in groundwater mdi problems 1 it can handle modestly nonlinear state space models reichle et al 2008 2 it can be used to deal with high dimensional problems peng et al 2011 3 it is flexible in its treatment of errors in model dynamics and parameters reichle 2008 and 4 the covariance between states at any given time step is estimated efficiently from a limited ensemble of stochastic realizations without requiring sensitivity analyses schöniger et al 2012 in general the performance of enkf is affected by the choice of the ensemble size and generation method model characteristics and analysis scheme moradkhani et al 2005 due to these advantages and ease of implementation model independence and robustness in solving different types of problems encountered in groundwater applications the enkf has become more popular than any other method in addressing problems of a sequential nature in the groundwater literature examples for the use of the enkf in groundwater applications include chen and zhang 2006 drécourt et al 2006 liu et al 2008 hendricks franssen et al 2011 el gharamti et al 2013 erdal and cirpka 2017 and xu and gómez hernández 2018 however the basic form of enkf has the key disadvantage of being based on the gaussian assumption moreover highly nonlinear dynamics can result in increasing underestimation of variance over time called filter inbreeding and filter divergence in the enkf hendricks franssen and kinzelbach 2009 a number of studies in the groundwater literature have tried to make enkf applicable to non gaussian models for example schöniger et al 2012 proposed the use of nonlinear monotonic transformations to the observed states rendering them gaussian xu and gómez hernández 2016b employed the normal score enkf to jointly estimate non gaussian aquifer parameters by assimilating three kinds of state variables another important disadvantage of enkf is that the size of the ensemble can be computationally prohibitive for cpu intensive groundwater models because hundreds of ensemble members are usually needed for reliable updating without filter inbreeding liu et al 2012 the enkf has a number of variants such as the ensemble square root kalman filter ensrf whitaker and hamill 2002 which uses the traditional kalman gain for updating the ensemble mean but uses a reduced kalman gain to update deviations leisenring and moradkhani 2011 the use of ensrf and other variants of the enkf such as the adaptive ensemble kalman filter and the hybrid adaptive ensemble kalman filter in the groundwater literature is rare as one of the few examples see rajib et al 2017 sequential monte carlo smc methods gordon et al 1993 also known as particle filters and bootstrap filters are another group of numerical approximation techniques that represent the posterior distribution in recursive bayesian inference as a set of monte carlo samples with associated weights which are termed particles the particles sample the state and or parameter and external forcing space according to a given prior distribution the particles are then propagated forward in time with smc performing updates on particle weights instead of state variables peng et al 2011 this has the advantage of reducing numerical instability ristic et al 2003 smc is applicable to any state space model with any format and statistical distribution whether linear or nonlinear and gaussian or non gaussian han and li 2008 this is a highly advantageous characteristic in certain groundwater problems such as the inverse estimation of hydraulic conductivities for non multi gaussian media however the basic form of smc has two key undesirable characteristics 1 smc tends to assign very large weights to the few particles with strong data support leading to severe reduction of the effective sample size and hence deterioration of the statistics and 2 applying smc to a high dimensional state and parameter space requires a very large number of particles and hence a very large amount of cpu time snyder et al 2008 hendricks franssen and kinzelbach 2009 schöniger et al 2012 resampling techniques like sequential importance resampling can reduce these problems to some extent van leeuwen 2009 leisenring and moradkhani 2011 smc may outperform enkf when the number of particles is sufficiently large 100 but the often larger number of simulations required by scm compared to enkf liu et al 2012 has limited its application to cpu intensive real world groundwater models example of smc application in groundwater mdi problems includes chang et al 2012 and abbaszadeh et al 2018 smc is popular in some engineering fields such as tracking and signal processing djuric et al 2003 and it has also been applied to many hydrologic problems zhou et al 2006 smith et al 2008 smc can be combined with mcmc see moradkhani et al 2012 so that a desirable performance can be achieved with a small manageable ensemble size apart from the three families of methods described above other techniques for numerical approximations of the bayesian filter exist but are rarely applied to groundwater mdi an example is the unscented kalman filter unkf e g chang and sayemuzzaman 2014 which presumes that the state space is unimodal symmetric and unbound despite the more relaxed assumptions of the unkf it has received little attention in the groundwater literature to date and so we expect more applications in the future 2 3 3 6 bayesian smoothing while bayesian filters in their basic form only compute estimates of the current state of the system given the history of measurements bayesian smoothers can be used to reconstruct states that happened before the current time smoothing distributions computed by the bayesian smoothers are the marginal distributions of the state y k given a certain interval of measurements d y 1 k k 1 2 t in which t k kitagawa 1987 18 p y k d y 1 t p y k d y 1 k p y k 1 y k p y k 1 d y 1 t p y k 1 d y 1 k d y k 1 where p y k d y 1 k is the filtering distribution of the time step k the integration is replaced with summation if some of the state components are discrete särkkä 2013 similar to bayesian filtering there are both closed form and numerical solutions for the bayesian smoothing equation closed form solutions include the kalman smoother ks or the rauch tung striebel smoother rtss rauch 1963 for linear gaussian state space models numerical solutions include the extended rauch tung striebel smoother exrtss cox 1964 sage and melsa 1971 which assumes gaussian approximation to the smoothing distribution and the ensemble smoother es van leeuwen and evensen 1996 among these the most commonly used method in the groundwater literature is es similar to enkf the es employs an ensemble of realizations obtained through mcs but it is based on one in all conditioning and can assimilate all the measurements at once using a single analysis step rather than the stepwise conditioning of the enkf so es and other bayesian smoothers are also classified as batch methods in some references however note that employing es instead of enkf increases the nonlinearity of the parameter update step during data assimilation and also increases the need for iterations of the algorithm chen and oliver 2013 examples for the use of es in the groundwater literature includes bailey and baù 2010 2012 chang et al 2017 and white 2018 3 applications applications of mdi in groundwater literature can be classified into eight categories parameter estimation and uncertainty quantification state estimation and uncertainty quantification state parameter estimation and uncertainty quantification model selection and structural uncertainty analysis guidance of data collection and data worth analysis improving data coverage customizing data resolution and fusion of heterogeneous data these applications are not mutually exclusive and two or more applications may be intended simultaneously in this section we review these applications considering their objectives basic theoretical concepts types of algorithms used in each application and significant trends in the groundwater literature 3 1 parameter estimation and uncertainty quantification parameter estimation is referred to as parameter fitting optimization inference or tuning model calibration or inverse modeling in the groundwater literature carrera et al 2005 2010 ataie ashtiani et al 2013 its objective is to employ available data either directly related to the parameter of interest or associated with state variables to provide reasonable estimates of model parameters and external forcing terms over a past period conditional on the specification of model structure so that the model makes sufficiently accurate predictions of the true state of the system liu and gupta 2007 parameter estimation often also includes approximation of associated uncertainties in both research and practical groundwater modeling studies parameter estimation has long been the dominant method for model improvement by conditioning to data and is often considered a necessary step in groundwater modeling hill and tiedeman 2006 it is by far the most explicitly mentioned application of mdi in the groundwater literature there are several reasons for this profound attention toward parameter estimation in the groundwater literature first no reliable prediction can be made without proper estimation of model parameters and external forcing terms zhou et al 2014 and second it is often much easier to condition parameter and external forcing values to data as compared to model structure refsgaard et al 2006 2012 groundwater parameter estimation often involves the estimation of hydraulic conductivity or related parameters such as permeability or transmissivity and its spatial distribution e g hendricks franssen and kinzelbach 2009 hendricks franssen et al 2009 ataie ashtiani et al 2013 as it highly affects model outputs for the prediction of both groundwater flow and transport of contaminants and also because it may vary over many orders of magnitude in a relatively small volume of the media mclaughlin and townley 1996 however parameter estimation may also focus on other parameters and external forcing terms such as recharge rates ng et al 2009 hendricks franssen et al 2004 2008 hendricks franssen and kinzelbach 2008 discharges fluxes leakage coefficients and piezometric heads on designated boundaries e g liu et al 2009 hendricks franssen et al 2011 irsa and zhang 2012 pollutant source location and release histories e g sun et al 2006 hendricks franssen et al 2011 and dispersivity e g ataie ashtiani et al 2013 or a combination of different parameters e g xu and gómez hernández 2016a b 2018 amongst these the estimation of recharge rate is of key interest in arid and semi arid regions due to its more unpredictable nature in these areas hendricks franssen et al 2008 parameter estimation has been a topic of intensive research for the past decades and several notable review papers are available on the subject including mclaughlin and townley 1996 carrera et al 2005 2010 vrugt et al 2008 and zhou et al 2014 as described in all these review papers historically the common approach for the estimation of groundwater model parameters until the end of the 1990s was trial and error in which parameter values are manually changed until a reasonable match between model predictions and data is achieved this approach is highly dependent on the subjective judgment of the modeler and by no means guarantees the optimal choice of parameter values ataie ashtiani et al 2013 these key setbacks have resulted in increasing use of automated parameter estimation based on frequentist nonlinear batch methods despite the many advantages of using these frequentist methods instead of trial and error parameter estimation they have several limitations 1 these methods employ objective functions that are based on collective measures of uncertainty and ignore the special characteristics of the individual components of uncertainty such as structural and data uncertainties liu et al 2012 zhou et al 2014 2 pursuing a single optimal parameter set can create bias in model predictions hendricks franssen et al 2009 and 3 they do not have the ability to gradually reduce parameter and hence prediction uncertainty as new data become available liu and gupta 2007 in recognition of these limitations there has been growing interest in the use of monte carlo based bayesian techniques for parameter estimation algorithms that have been of key interest include enkf e g hendricks franssen et al 2011 and es e g bailey and baù 2010 2012 in monte carlo based methods likely realizations of the input parameters are conditioned to the available measurements with geostatistical techniques such as sequential gaussian simulation gómez hernández and journel 1993 if local measurements of the desired parameters are available or co located co simulation almeida and frykman 1994 hendricks franssen et al 2008 the estimation of heterogeneous fields of hydraulic conductivity and other similar parameters e g transmissivity storage coefficient and recharge rate from sparse data is commonly a highly underdetermined problem and is prone to ill posedness non uniqueness and instability to alleviate these problems the estimation of such parameter fields is often done by employing a parameterization technique that limits the number of unknown variables and provides the modeler with only enough heterogeneity required to simulate observations of past system behavior sepúlveda and doherty 2015 these include non geostatistical methods such as the classical zonation method carrera and neuman 1986a b and geostatistics based methods such as the pilot point method de marsily 1978 regularized pilot point method alcolea et al 2006 sequential self calibration gómez hernánez et al 1997 hendricks franssen et al 1999 and ridge function mantoglou 2003 geostatistical methods may turn the parameter estimation problem into the estimation of the geostatistical variables of the unknown parameters e g range nugget sill etc using these techniques almost always results in loss of detail and may produce overly smoothed parameter fields moore and doherty 2006 hence much work is still being done by the groundwater research community to develop new methods 3 2 state estimation and uncertainty quantification state estimation involves characterization of the past retrospective present or future forecast state of the groundwater system and their uncertainties by combining state information from both the model and available data liu and gupta 2007 liu et al 2012 this may include for example reconstructing spatial flow and contaminant plume fields state estimation which is also commonly referred to as data assimilation is typically based on specification of the model structure and parameters in advance and the estimations are solely applied to the state variables hence state estimations are conditional on the specific model structure s and parameter values moradkhani et al 2005 schöniger et al 2012 in the groundwater literature state estimation is often formulated as a filtering or smoothing problem and is commonly interrelated with three other application of mdi improving data coverage customizing data resolution and data fusion the commonly applied methodologies for solving the problem via filtering in recent groundwater literature is the enkf and smc methods e g bailey and baù 2012 dual state state estimation is a term used for the concurrent estimation of groundwater flow and contaminant states el gharamti et al 2013 3 3 simultaneous state parameter estimation and uncertainty quantification there are basically two formulations for the simultaneous estimation of states and parameters in the groundwater literature 1 the joint or state augmentation approach and 2 the dual estimation approach the standard joint approach simultaneously estimates state and parameters as a single augmented vector e g chen and zhang 2006 hendricks franssen and kinzelbach 2008 2009 liu et al 2008 hendricks franssen et al 2011 the joint approach is very susceptible to instability and intractability as a result of increase in the number of unknown variables especially in highly nonlinear systems moradkhani et al 2005 the alternative dual formulation is based on two interactive parallel filters a filter for the parameters and another for the states with the parameters undergoing an artificial evolution i e random walk while waiting to be updated indirectly by the state variables data e g el gharamti et al 2013 an example of dual estimation is the dual extended kalman filter dual exkf thiemann et al 2001 3 4 model selection and structural uncertainty analysis model selection also known as model discrimination or identification is a key part of multi model approaches for the consideration of structural uncertainty höge et al 2018 it involves using data to choose amongst various independent plausible alternative model structures including governing equations heterogeneity patterns type of boundary conditions etc that best describe the relationship between model inputs and outputs refsgaard et al 2006 gupta et al 2012 model selection may also include assigning probabilities to the chosen model structures based on their ability to reproduce the available data and then combining predictions made by the chosen model structures to form a reliable description of the total prediction uncertainty mdi for model selection and structural uncertainty analysis in the groundwater literature is mostly performed using one of the following bayesian methods generalized likelihood uncertainty estimation glue beven and binley 1992 bayesian model averaging bma draper 1995 and maximum likelihood bayesian model averaging mlbma neuman 2003 or a hybridization of at least two of them e g rojas et al 2010a these methods and some of their applications are briefly reviewed in the following sub sections 3 4 1 generalized likelihood uncertainty estimation glue is a conditional mcs technique that involves sequential implementation of the following steps 1 defining alternative candidate model structures 2 assigning appropriate prior parameter uncertainty distributions for each model structure 3 performing mcs based on samples drawn from the parameter distributions of each candidate 4 using a likelihood measure such as the gaussian romanowicz et al 1994 efficiency freer et al 1996 and fuzzy type jensen 2003 measures to assess the resemblance of each simulation output with data on systems states 5 selecting candidates with likelihoods above a specified threshold as behavioral models and setting the other candidates aside 6 calculating weights for each behavioral model by normalizing the corresponding likelihood values in a way that all the weights sum up to one and 7 estimating the likelihood weighted probability distribution of model outputs beven and freer 2001 liu and gupta 2007 in glue the likelihoods can be updated sequentially as new data becomes available glue allows for the explicit assessment of model structure and parameter uncertainties but does not account for data uncertainty applications of glue in groundwater mdi are numerous with the majority of applications focusing on the uncertainty in geological structures and hydraulic conductivity patterns and to a lesser extent on recharge patterns assuming that other components of the model structure e g governing equations are without uncertainty e g feyen et al 2001 morse et al 2003 hassan et al 2008 this is also the case for the other two methods discussed in this sub section bma and mlbma the glue methodology has been criticized for not having a likelihood function that is consistent with probability theory and instead relying on less formal likelihoods that are defined by the user without satisfying bayes theorem resulting in a loss of consistency in learning mantovan and todini 2006 montanari et al 2009 3 4 2 bayesian model averaging bma is a more formal bayesian approach for combining predictions made by multiple model structures the bma predictive distribution of an output of interest y given data d is estimated by hoeting et al 1999 19 p y d i 1 n m p y d f p f d where n m is the number of alternative model structures in bma the predictive distribution of y is an average of its prediction distributions for each alternative model structure p y d f weighted by its posterior model probability p f d bma can be used to differentiate between prediction uncertainties arising from individual models and is able to identify unfavorable models for model selection examples for the use of bma for mdi in the groundwater literature include tsai and li 2008 li and tsai 2009 ye et al 2010 and tsai 2010 bma is computationally very demanding especially when applied to cpu intensive groundwater models 3 4 3 maximum likelihood bayesian model averaging mlbma was developed in an attempt to make bma computationally feasible neuman 2003 it is in fact an approximation to bma that relies on producing maximum likelihood parameter estimations and then expanding around these values by mcs mlbma subsequently approximates the posterior model probabilities using e g the kashyap information criterion kashyap 1982 or the bayesian information criterion bic schwarz 1978 mlbma is capable of dealing with lack of prior information on model parameters ye et al 2005 examples of groundwater studies using mlbma for mdi include neuman 2003 ye et al 2004 2005 and lu et al 2015 despite the computational convenience several shortcomings have been mentioned for mlbma in the literature these include 1 it relies on the calibration of parameters for each alternative model structure hence creating the risk of biased parameter estimates that tend to compensate for errors in the model structure rojas et al 2010b and 2 prediction of state variables not included in the data used for calibration may become biased and may underestimate the effects of model structural uncertainty refsgaard et al 2006 troldborg et al 2007 3 5 guidance of data collection and data worth analysis groundwater data collection campaigns are costly and almost always prone to logistical and financial constraints this implies the need to develop vigorous methodologies for the optimal collection of data besides or complementary to the informal or subjective methods guided by professional experience and judgment and the formal or objective methods based on pure geostatistics e g kriging frameworks simulation based methods can play a key role in the guidance of data collection in groundwater studies in this regard models help in the identification of the most informative data to collect with respect to a specific set of objectives this process is referred to as experimental design value of information or data worth analyses dwa simulation based dwa has been used in the literature for the identification of the optimal number e g norberg and rosén 2006 and location of observation wells e g siade et al 2017 frequency of sampling e g kollat et al 2011 tracer test design including choice of the injection rate duration of test and type of tracer e g wallis et al 2014 and choosing between different types of data e g choosing between conductivity piezometric heads and travel times data as in fu and gómez hernández 2009 or between concentration and temperature data as in dausman et al 2010 in the latter case the worth of different types of data with different measurement accuracies can be analyzed by using simulation based pareto methodology see brunner et al 2012 simulation based dwa can be carried out in at least two contexts 1 it can be used to compare alternative future data collection schemes at a given stage in a phased survey and 2 it can be used to decide when to stop or limit a staged data collection program to reduce data redundancy i e observations having similar information content freeze et al 1992 khader and mckee 2014 in both of these contexts a precondition for the use of model based dwa is that some minimal groundwater exploration that allows for the development of a justifiable model has taken place kikuchi 2017 simulation based dwa is essentially built on a strategy to quantify the worth of measurements the most common strategy is to compute a measurement s ability to reduce the uncertainty or error variance of key model predictions e g heads contaminant concentrations or travel times magnitude of plume spreading etc which affect management decisions e g freeze et al 1992 cirpka et al 2004 dausman et al 2010 wallis et al 2014 kikuchi et al 2015 wöhling et al 2016 siade et al 2017 in context 1 above this is often done in the following two steps which are built upon bayesian statistics and are referred to as bayesian dwa or bayesian experimental design in the first step a prior analysis is performed where the uncertainty in key model predictions is quantified on the basis of currently available data in the second step which is called pre posterior analysis the uncertainty in key model predictions is re calculated by assuming that new measurements are carried out in a specific timeframe on a set of locations in the proposed data collection program obviously the values that are actually going to be measured at the proposed locations are unknown but what is known is that measurement will reduce the uncertainty at the proposed points to zero or to some measurement uncertainty for the intended parameters or state variables this is sufficient to allow for the calculation of the uncertainty reduction resulting from the proposed measurements with respect to the uncertainties calculated in the prior analysis hence in the pre posterior analysis the magnitude of predictive uncertainties are considered in a relative rather than absolute sense some references refer to this procedure as a form of sensitivity analysis finsterle 2015 the pre posterior probabilities are often calculated through linear uncertainty analysis e g dausman et al 2010 numerous variants of mcmc e g fu and gómez hernández 2009 null space monte carlo nsmc e g siade et al 2017 or enkf e g kollat et al 2011 repeating pre posterior analysis for various data collection alternatives in the framework of optimization e g by ga as in wöhling et al 2016 or scenario analysis e g fu and gómez hernández 2009 allows for the selection of the optimal design in the context 2 above a prior analysis is performed based on data collected in some initial stages of the data collection program initial dataset then pre posterior analysis is replaced by posterior analysis in which uncertainty in key model predictions is calculated based upon augmenting different subsets of data collected in the subsequent stages with known measurement values to the initial dataset by comparing the outcome of posterior analysis for different subsets of data one can choose to stop parts of the measurement program that result in the least impact on reducing model prediction uncertainties note that prior pre posterior and posterior analysis all require propagation of uncertainty from model parameters and observation data to model forecasts leaf 2017 some studies go a step further and characterize the worth of data by quantifying the benefits of reducing model prediction uncertainty in terms of risk reduction or monetary costs of economic regret resulting from making wrong decisions in the context of remedial or aquifer exploitation decision making e g feyen and gorelick 2005 norberg and rosén 2006 neuman et al 2012 a common formulation for this notion is to maximize some form of the following objective function ς 20 ς b c i γ p f c f where b is the benefit e g profit from water sales etc c i is the investment cost including the cost of measurements γ is the risk aversion factor p f is the probability of failure e g failing to abide by a regulation policy etc and c f is the cost of failure e g fines waste of groundwater resources etc this strategy has two key interconnected advantages first it is based on a more direct assessment of cost effectiveness and second communicating the results with stakeholders often becomes easier the downside to such an approach is that it requires a quantitative definition of the cost of being wrong due to lack of data which may not always be known or easy to quantify in simulation based methods dwa can be done based on a measurements ability to improve the estimation of unmeasurable or hard to measure parameters this can be done by assessing the sensitivity of potential measurements i e states to model parameters through model sensitivity analysis e g ataie ashtiani et al 2013 an alternative approach is to analyze the measurements ability to reduce parameter estimation uncertainty in a bayesian framework in the latter case the objective function is usually derived from the covariance matrix of the parameters based on a optimality minimizing the trace of the covariance matrix e g hsu and yeh 1989 d optimality minimizing the determinant of the covariance matrix e g catania and paladino 2009 siade et al 2017 e optimality minimizing the eigenvalue of the covariance matrix e g nordqvist 2000 or expected shannon information gain i e relative entropy e g zhang et al 2016 see nowak 2010 for a review of these criteria traditionally dwa studies have relied on a single conceptual mathematical model of the groundwater system making the predictions prone to statistical bias and underestimation of uncertainty xue et al 2014 a more recent approach in the literature is to perform predictions by means of multiple models and then characterize data worth as the contribution of a set of measurements to 1 the resulting multi model prediction uncertainty or 2 model selection discrimination among a set of viable alternative models this is often done within a bma e g pham and tsai 2016 or mlbma e g neuman et al 2012 xue et al 2014 framework in case 1 data worth can be defined for example as the difference between the trace of the posterior covariance with and without a set of real measurements in posterior analysis or randomly chosen estimates of potential measurements in pre posterior analysis neuman et al 2012 xue et al 2014 in 2 the worth of data can be assessed for example based on the number of conceptualizations retained in the ensemble after a specific subset of data is considered 3 6 improving data coverage in groundwater studies models can be used to interpolate and extrapolate data to provide spatial and temporal coverage of the desired domain a classic example is the use of groundwater models for the creation of water table or concentration contour maps from sparse and irregularly distributed field measurements although the use of classic geostatistical interpolation methods such as inverse distance weighting and kriging variants are common for this purpose these methods are known to be vulnerable to outliers may contradict obvious characteristics of the groundwater system and often fail to represent complex variations between relatively distant measurement points fasbender et al 2008 buchanan and triantafilis 2009 these shortcomings can be alleviated through the use of models because the physical constraints imposed by models offer additional valuable information in the development of contour maps the methodology is straightforward the model is calibrated using the sparse field measurements of water table and or concentration then the current state of the groundwater system is reconstructed by the model and the results are used to generate the contour maps data generalization can also be performed by solving bayesian filtering or smoothing state estimation problems use of models in such bayesian frameworks allows for the incorporation of auxiliary data and geostatistics in the data generalization process for example see peeters et al 2010 despite these advantages models are rarely developed for the single purpose of creating a groundwater contour map for two main reasons first the time and effort needed to create and calibrate the model compared to the use of pure geostatistics are considerably higher and second commonly a mismatch remains between observed and simulated values in the measurement points 3 7 customizing data resolution models can be used to upscale or similarly downscale data upscaling refers to the transformation of data collected at a fine scale onto a coarser scale a typical example in groundwater studies is the upscaling of hydraulic conductivity data also referred to as the estimation of effective equivalent interpreted homogenized or block hydraulic conductivity sanchez vila et al 2006 another parameter commonly upscaled in groundwater studies is dispersivity de barros and dentz 2016 the basic notion behind model based data upscaling in groundwater studies is that quantities such as flows and hydraulic head gradients computed by a model at a coarse scale block should match the corresponding average values of these quantities modeled at the fine scale blocks that form the course block and pertain to the scale of data acquisition in other words the upscaled quantity is chosen so that the upscaled blocks can reproduce the behavior of the heterogeneous medium through modeling the advantage of this model based method in comparison to pure geostatistics is that it is not limited to a specific spatial distribution pattern degree of variability or aquifer geometry a pioneering study in this regard is gómez hernández 1991 followed by studies such as zhou et al 2010 who extended the methodology of gómez hernández 1991 to three dimensions li et al 2012 which coupled this upscaling method with inverse modeling through the enkf fernàndez garcia et al 2009 and li et al 2011 who applied transport models to upscaling and godoy et al 2018 which employed the laplacian with skin method for upscaling of hydraulic conductivity 3 8 fusion of heterogeneous data hydrogeological site investigations involve the collection of an array of different types of data which should be combined to form a unified picture of the aquifer for several reasons hydrogeological data fusion is often a difficult task 1 various types of data may relate to different aspects of the system and hence do not share the same nature these inherently different forms of data cannot be readily related to each other a typical example of this notion is pollutant concentration and hydraulic conductivity data 2 even data of the same nature generally do not share the same quality and may have dissimilar spatial and temporal scales and degrees of uncertainty and imperfection for example in many site investigations data from traditional characterization and monitoring methods such as core analyses and hydraulic tests are supplemented with coverage of greater density from indirect geophysical surveys and soft data based on expert knowledge and field questionnaires the degree of uncertainty associated with each of these types of data is very different from the other this is known as data heterogeneity khaleghi et al 2013 3 there is the typical problem of handling inconsistency and conflict in temporally or spatially overlapping data for decades hydrogeologists have relied on a combination of expert knowledge and geostatistical methods for formal data fusion but most existing geostatistical methods such as classical kriging and cokriging are limited in their ability to simultaneously account for large numbers of information sources porter et al 2000 fasbender 2008 and hence research on the improvement of geostatistical data fusion methods is ongoing e g hosseini and kerachian 2017 model based data fusion also called data fusion modeling in the groundwater literature e g porter et al 2000 is a very powerful tool for solving the problems associated with data fusion in hydrogeology models provide prior knowledge of the physical relationships between dissimilar datasets and data fusion algorithms use these relationships to extract integrated information from the measured data we classify previous work on model based data fusion in the groundwater literature into three categories which are described in the following sub sections 3 8 1 fusion of different types of direct measurements this is the most common form of data fusion in groundwater studies partly because traditional frequentist parameter estimation methods implemented in codes such as pest modflowp ucode ithough2 etc embody this form of data fusion these frequentist methods use direct measurements of model parameters e g hydraulic conductivity porosity dispersivity etc to provide initial estimates and bounds for each of these parameters and then simultaneously employ different forms of data related to direct measurements of model state variables e g head concentration travel time etc to update these initial estimates hence both the resulting parameter estimates and model predictions are based on the integration of different forms of data but as previously discussed these methods do not provide a proper estimation of uncertainties the use of bayesian fusion techniques alleviates this problem in bayesian fusion data on model parameters is employed to build prior estimates for these parameters in the form of probability distributions and the data on state variables are used to update these priors and obtain the posterior probability distributions of model parameters bayesian fusion has been implemented through mcmc algorithms for the fusion of non sequential data e g hassan et al 2009 laloy et al 2013 and variants of the kf have been employed for the fusion of sequential data e g porter et al 2000 bailey and baù 2012 in the groundwater literature 3 8 2 fusion of direct and indirect measurements direct point measurements of hydrogeologic data are commonly limited because their acquisition is expensive time consuming and invasive rajabi and ataie ashtiani 2016 several types of indirect measurement data can be used to alleviate this problem two of the most commonly used are geophysical data and remote sensing rs data it is well known that the use of geophysical data such as ground penetrating radar data electrical resistance tomography data etc in conjunction with direct measurement of hydrogeologic variables can substantially improve characterization of subsurface variability kowalsky et al 2005 2006 yeh et al 2007 however geophysical methods provide data on geophysical properties in the subsurface that are nonlinearly related to the variables of interest and the standard relationships commonly used to infer these variables from geophysical data may induce artifacts that cannot be interpreted from a hydraulic viewpoint camporese et al 2011 groundwater models can be used to solve this problem through for example coupled hydrogeophysical inversion where the hydraulic and geophysical equations are considered as a coupled system pollock and cirpka 2012 a common approach for fusing geophysical data with direct measurements of hydrogeologic variables in this context is to employ geophysical data as part of the measurement model as follows kowalsky et al 2004 21 d aug d h d gp h t h y t u t θ h t gp y t u t θ η t h η t gp where d aug is an augmented vector of all observational data h t h is the measurement model that maps y t u t θ to the hydrological measurements d h h t gp is the measurement model that maps y t u t θ to the geophysical data d gp and η t h and η t gp are the observation stochastic error vectors for the hydrological and geophysical data respectively rs data usually combined with geographic information systems can also be a potentially useful source of information for groundwater modeling this is especially true in regional scale modeling in areas where other forms of data are scarce current air and satellite based rs technologies can penetrate the ground for only a few centimeters but this is enough to provide data for the inference of surface forcing and some geologic properties making rs a potentially valuable source of information in the study of shallow groundwater becker 2006 rs data is often supplemented with ground control measurements in order to scale rs data to the variable of interest or to estimate the error statistics i e uncertainty of the rs data hendricks franssen et al 2008 examples for the use of rs data in groundwater mdi include estimates of values and spatial patterns of groundwater model recharge rates from satellite images pertaining to precipitation actual evapotranspiration etc e g brunner et al 2004 hendricks franssen et al 2008 use of rs based digital elevation models dems to constrain groundwater flow model outputs and avoid erroneous artesian piezometric head values hendricks franssen et al 2008 employing geologic maps derived from rs data for groundwater prospecting e g providing information about hydraulic conductivities water reserves of water bearing formations and identification of faults and fracturing for groundwater modeling waters et al 1990 using rs imagery to identify and characterize boundary conditions for groundwater models this may include identification of streams lakes wetlands seepage areas recharge and evapotranspiration zones or dynamic monitoring of stream headwater becker 2006 3 8 3 fusion of field measurements and expert knowledge expert knowledge has long been identified as a key source of information for groundwater modeling because experts have the ability to interpret complex and ambiguous evidence based on their broader experiences o hagan 2012 this has made the fusion of soft data pertaining to expert knowledge and hard data obtained from field measurements an important topic in groundwater studies the informal use of expert knowledge in groundwater model conceptualization and parameter estimation is highly common formal mechanisms in this context are mostly based on the bayesian approach krueger et al 2012 in the bayesian approach the subjective belief of an individual expert or the inter subjective belief of several experts about the value of parameters or plausibility of alternative model structures can be represented by prior probability distributions through expert elicitation techniques beer et al 2013 rinderknecht et al 2014 these priors are then updated based on hard field measurement data this approach has been used in many previous groundwater studies for parameter estimation or model selection and structural uncertainty analysis e g hassan et al 2009 however this approach has been criticized for a number of reasons including the following 1 it neglects the imprecision essentially embedded in expert provided soft data which may lead to biased result lele and allen 2006 stein et al 2013 2 expressing expert knowledge in the form of probability distributions is often very difficult ross et al 2009 and 3 it is bound to the incorporation of expert knowledge regarding model parameters and structures and does not provide the means to include expert knowledge on other aspects of groundwater models such as state variables to solve these problems rajabi and ataie ashtiani 2016 proposed the use of fuzzy bayesian inference based on mcmc for incorporating expert knowledge in parameter estimation their method uses the power of fuzzy logic to provide a convenient framework for the representation of expert provided information regarding the various inputs to the bayesian inference algorithm furthermore it allows one to distinguishably model both uncertainty and imprecision in the fusion process 4 software and codes the mdi algorithms described in section 2 commonly involve large computational effort and hence their implementation inevitably requires computer programming while many mdi efforts in the groundwater literature rely on codes that are developed for the specific problems at hand and are not made available to the public some researchers institutions have focused their efforts on developing generic codes for this purpose these efforts have resulted in the development of several mdi software since the 1990s some of which are reviewed in table 2 these software have essentially transformed the way mdi is conducted in groundwater studies by paving the way for a mainstream change from trial and error techniques to automated mdi procedures mdi software used in the groundwater literature include 1 model dependent software that are developed for application in conjunction with specific groundwater models an example is modflowp hill 1992 2 model independent generic software such as pest doherty 1994 pest welter et al 2015 and ucode poeter and hill 1999 3 code packages mostly in r e g mcmc see http www stat umn edu geyer mcmc python e g pynsmc white and brakefield 2015 pyemu white et al 2016 and pymc patil et al 2010 and matlab e g dream vrugt 2016 the second and third categories can be used with any model often the only requirement is that the input and output files of the model are numerical ascii or text only these two categories are mostly community supported and open source and are also being used in other engineering fields most available codes and software are intended for parameter estimation and the absolute majority employ batch frequentist weighted lse with local derivative based optimization methods e g lm optimization the widespread use of these algorithms can be attributed to their ease of coding and affordability of computations in low dimensional problems there are also several codes available that are based on mcmc algorithms for bayesian parameter estimation e g dream in matlab mcmc in r and ucode mcmc lu et al 2014 the reason for such focus on parameter estimation as compared to model identification or state estimation is twofold 1 parameter estimation can often be performed by relatively simple automated modifications to the model input files while model structure or state updating requires a high level of interaction with the numerical model liu et al 2012 and 2 currently the generation of model structure realizations is mostly based on expert insight rather than formal methods making the development of automated model structure updating software difficult recent developments in mdi software for groundwater applications include developing parallel computing abilities e g parallel pest as in tang et al 2010 beopest see hunt et al 2010 and mcmc ucode see lu et al 2014 enabling cloud computing e g pest cloud see https pest cloud incorporating advanced regularization see http www pesthomepage org highly parameterized inversion php about pest using state of the art global optimization schemes see finsterle 2010 regarding itough2 and integrating mdi into risk based environmental management optimization e g estpp opt see white et al 2018 the pest suite will likely play a key role in the future of groundwater mdi one reason is that with the new modular nonintrusive parallel run manager named panther it is becoming easy for people to add programs to the pest suite and to run parallel computations on the cloud 5 discussion and prognosis for future work we defined mdi as a two way process between models and data and reviewed recent advances in mdi methods and applications in the groundwater literature the review shows that frequentist weighted lse is still the most widely used method for mdi in groundwater scientific literature and professional practice which is mostly due to the availability of open source user friendly software a multitude of case studies and a number of well established guidelines for its implementation however aided by advances in computing power and data handling there is a trend toward more extensive use of monte carlo based methods such as mcmc enkf smc and es in the literature and these methods are also gradually finding their way into professional practice the classic kf became popular in the groundwater scientific literature in 1990s and early 2000s but due to a number of limitations failed to become a mainstream practical method and is now mostly replaced by the enkf in the literature the exkf and vbms although popular in other fields e g weather prediction and atmospheric sciences have been given much less attention in the groundwater modeling community it is clear from this review that there are many tools and techniques for groundwater mdi and this diversity is needed for supporting different mdi objectives model and data types and computational constraints it is important to understand that the success of groundwater mdi does not necessarily depend on providing more data or using more sophisticated models but is mainly governed by their optimal synthesis and properly addressing the associated uncertainties this is an important reason for the significant interest in improving mdi methods in the literature the continuing progress of data acquisition technologies and the evolution of models means that the landscape of mdi in groundwater applications will continue to evolve in the future here we discuss a number of key issues that will likely form future directions 1 addressing computational challenges several key synthesis approaches used in mdi require a large number of model simulations this is most notably true for methods that rely on mcs such as mcmc enkf smc and es or stochastic meta heuristic optimization algorithms these synthesis approaches become computationally very expensive when the computational demand of a single model run is substantially high this has been an issue for the past several decades and interestingly the enormous increase of computer processing speed in recent years has not solved this problem the fact that computational demand remains to be an important issue to date and probably for the mid term future has mainly two reasons first recent advances in groundwater simulation software have mostly focused on increasing model fidelity i e improving the degree to which the model reproduces the behavior of the real world system resulting in continuous increase in their execution times carrera et al 2005 second we are seeing a constant shift from theoretical research on mdi using synthetic toy problems with limited computational demand e g henry problem henry 1964 to real world mdi applications involving computationally expensive groundwater models due to these reasons the computational challenge must be somehow confronted within the groundwater community in order to facilitate the success of mdi a review of literature shows that four main strategies are being pursued to address this problem 1 parallelization and grid computing applied to either or both the model and the synthesis approach for example see the parallel parflow model for simulating surface and subsurface flow kollet et al 2010 bürger et al 2012 see https parflow org xu et al 2013 for parallel mcmc joseph and guillaume 2013 for parallel enkf 2 replacing the model with data driven and physics free meta models such as polynomial chaos expansion pce e g laloy et al 2013 rajabi and ataie ashtiani 2016 3 improving the computational efficiency of synthesis methods e g vrugt et al 2009 and 4 employing cloud computing e g kurtz et al 2017 see hayley 2017 research on all four strategies is expected to continue in the future and it is expected that cloud computing will play an increasingly important role in solving the computational challenges of mdi in groundwater 2 accounting for local heterogeneities every technique currently available for the estimation of heterogeneous groundwater model parameters from data employs some level of averaging or smoothing through parameterization and regularization the consequence is that the results of parameter estimation may be locally quite flawed and this reduces the accuracy of model predictions that are sensitive to these local values hence much work is being currently done and will continue in the future on several fronts to alleviate these problems this includes developing methods for 1 use of by product information of regularized parameter estimation such as spatial covariance structure of the estimated field to identify misrepresented local details moore and doherty 2006 2 optimizing the choice of the limited number of parameters that are used for the reconstruction of the heterogeneous field e g jung et al 2011 and 3 adapting synthesis methods for the incorporation of more local details and hence more parameters in the estimation process e g tonkin and doherty 2009 the third approach inevitably includes developing strategies for solving the resulting computational challenges such as instability non convergence solution non uniqueness and solution non optimality 3 real time mdi cases for the use of automated field sensors that rely on communication technologies such as wsns have recently emerged in the groundwater literature these technologies allow for the monitoring of groundwater systems at much finer spatial and temporal resolutions than traditional manual sampling and analysis methods but the resulting data is prone to sensor and wsn faults e g stuck readings out of range errors abrupt shifts abnormal noise etc see szewczyk et al 2004 and hence requires the integration of fault detection methods in groundwater mdi techniques especially when sensor readings are fed automatically into models an example of studies addressing this issue is barnhart et al 2010 which employs a data reduction algorithm to identify and remove potentially faulty salinity data and then uses the remaining data for groundwater model parameter estimation by pest progress made in real time groundwater monitoring technologies have facilitated the development of real time or quasi real time decision support systems dsss the traditional and still widely used approach in groundwater dsss is to employ offline rules that optimizes the controls with the objective of minimizing the cost of operations e g rajabi and ketabchi 2017 but the emerging real time alternative also known as model predictive control mpc constantly revises and optimizes controls based on feedback from the system liu et al 2012 the ability to rapidly assimilate real time data and provide answers to imminent questions is gradually becoming an important part of groundwater modeling langevin and panday 2012 an example reference is drumheller et al 2017 the study uses hydraulic head and electrical conductivity data from a distributed sensor network for quasi real time model calibration and then performs simulation optimization with the aim of controlling aquifer recharge and recovery operations in a laboratory setup hendricks franssen et al 2011 use enkf for combining online observations of hydraulic head with numerical models for the real time characterization of groundwater flow in a real world urban aquifer their computational tool became operational at the water works zurich in 2009 4 developing codes and software for mdi despite the hugely valuable efforts by the groundwater and other research communities in developing software for mdi major gaps still remain these gaps which underpin future research and collaboration opportunities include 1 developing community supported open source data assimilations tools based on methods such as enkf smc etc development of such tools for instance the parallel data assimilation framework see http pdaf awi de trac wiki has helped other fields such as numerical weather prediction atmospheric sciences and more recently hydrology work on such tools has already started in the groundwater modeling community an example is pestpp ies which is an implementation of the iterative es lm algorithm of chen and oliver 2013 within the framework of pest pest model interface protocols see https github com dwelter pestpp 2 creating computer codes for groundwater model discrimination and structural uncertainty analysis progress in this regard depends greatly on developing algorithms that can automate this process and reduce its dependence on subjective expert opinion 3 developing codes for formal fusion of different types of groundwater related data e g geophysical and remote sensing data expert knowledge etc 5 bridging the gap between research and professional practice lastly the growing research practice gap has already been observed more generally in groundwater science simmons et al 2012 we also acknowledge that there is an existing gap between mdi practices in the research community and those in consulting industry and government and this gap seems to be growing this is evident from the fact that many of the more recent mdi methods are rarely applied outside of research settings closing this gap calls for more user friendly software guidelines for mdi method selection and application worked examples and case studies education and training acknowledgement the authors wish to thank the editor in chief professor geoff syme and two anonymous reviewers for their valuable comments which helped to improve the final manuscript behzad ataie ashtiani and craig t simmons acknowledge support from the national centre for groundwater research and training australia behzad ataie ashtiani also appreciates the support of the research office of the sharif university of technology iran 
6902,although rainfall characteristics play important roles in runoff generation and soil erosion our understanding about how rainfall moving direction impacts surface flow and soil erosion on slopes considering spatial process of soil surface sealing is still poor in this study a series of laboratory experiments was conducted using a soil flume and a movable rainfall simulator to investigate this impact two rainfall moving directions i e upslope moving and downslope moving and two soil surface moisture conditions i e dry runs with no antecedent rainfall and wet runs with antecedent rainfall were considered in the experiments with different slope gradients and rainfall intensities the results showed that the upslope moving rainfalls generated more surface flow from 25 to 700 and less soil erosion than the downslope moving rainfalls in the dry runs due to the different spatial developing processes of soil surface sealing the difference between the runoff coefficients of the two moving direction rainfalls decreased remarkably more than 50 with slope gradient increasing from 15 to 25 in the wet runs surface flow was similar for the upslope moving and downslope moving rainfalls as all of the soil surface had been sealed before the experiments soil erosion in the downslope moving rainfalls was larger than that in the upslope moving rainfalls due to higher sediment transport capability of the surface flow for both rainfall moving directions with same rainfall conditions the total soil erosion in a dry run was mostly larger than that in a wet run because of less erodible soil particles on the sealed slope in the wet run the result of this study implied that different rainfall moving directions can lead to distinct spatial processes of soil surface sealing and caused large differences in surface flow and soil erosion processes on slopes keywords rainfall moving direction soil surface sealing rainfall simulation surface flow soil erosion slope gradient 1 introduction rainfall runoff and soil erosion processes on hillslopes are important in hillslope hydrology and extensively concerned in many aspects including soil and water conservation landform protection and agricultural management iverson 2000 quinton et al 2010 zhao et al 2013 rainfall characteristics are the fundamental factors for these processes dunkerley 2008 seeger et al 2004 although the influence of rainfall characteristics such as rainfall intensity and pattern has been widely studied e g an et al 2014 berger et al 2010 nicótina et al 2008 parsons and stone 2006 many studies employed stationary rainfall and did not take rainfall movement into account e g assouline et al 2007 defersha and melesse 2012 dunkerley 2012 rainfall movement is normal rather than exceptional in natural catchments marshall 1980 nikolopoulos et al 2014 singh 1998 a majority of the storms are likely to be moving storms with preferential directions in different seasons seo et al 2012 even at small scale within hundreds meters the spatial and temporal variability of rainfall was still observed e g goodrich et al 1995 sharon and arazi 1997 both laboratory and numerical studies have shown that rainfall moving direction strongly impacts surface flow and soil erosion processes e g de lima et al 2008 lee et al 2015 surface flow and soil erosion could be under or over estimated if the impact of rainfall movement is neglected de lima et al 2003 liang and melching 2015 sigaroodi and chen 2016 laboratory studies on soil flume have shown that peak discharge and erosion rate are higher under downslope moving rainfall i e rainfall moved from the top of a slope to the downslope outlet than upslope moving rainfall i e rainfall moved from the downslope outlet to the top of a slope e g de lima and singh 2003 de lima et al 2008 the shapes of hydrograph and sedigraph are also largely affected by rainfall movement in particular those of upslope moving rainfalls have early rises gentler rising limbs and longer recession than downslope rainfalls de lima et al 2011 mizumura and ito 2011 similar results have been derived from numerical model simulation at both the plot scale and catchment scale e g chang 2007 nunes et al 2006 seo et al 2012 volpi et al 2013 however in these studies soil surface sealing process which may largely influence dynamics of surface flow and soil erosion was not considered on a bare soil surface soil surface sealing is commonly developed during rainfall events there are two major types of rainfall induced soil surface sealing i structural seals due to raindrop hitting and ii depositional seals led by deposition of fine soil particles assouline 2004 lu et al 2017 morin and benyamini 1977 the seal layer normally has lower porosity finer pores lower hydraulic conductivity and higher shear strength than unsealed soil han et al 2016 zhou et al 2013 so soil sealing decreases soil surface infiltration and consequently increase surface flow liu et al 2011 sela et al 2012 also the detachability of soil surface is reduced by sealing as the soil aggregate structure is strengthened by embedded fine soil particles luk et al 1993 although the important role of soil surface sealing in runoff generation and soil erosion processes has been commonly accepted e g assouline and mualem 1997 chen et al 2013 zhou et al 2013 it is remained unclear that how different spatial processes of soil sealing which caused by different rainfall moving directions impact runoff and soil erosion on hillslopes additionally as most studies related to sealing e g armenise et al 2018 assouline and ben hur 2006 zhou et al 2013 did not take impacts of antecedent rainfall on soil surface condition into account it is worthwhile to study these impacts on surface flow and soil erosion processes although a few experimental studies focusing on rainfall movement have taken slope gradients into account the slopes in these experiments were flat generally less than 15 e g liang and melching 2015 nunes et al 2006 at the hillslope scale opposite trends were reported regarding the effect of slope steepness on infiltration depending on soil and slope conditions that were considered e g chen and young 2006 essig et al 2009 philip 1991 ribolzi et al 2011 there is a lack of understanding the effect of rainfall moving directions on runoff and soil erosion processes with different steep slopes rainfall simulation is one of the most useful and beneficial tools for the study on surface flow and soil erosion which have been widely used since the 1930s cerdà et al 1997 iserloh et al 2010 martínez murillo et al 2013 meyer 1965 tauro et al 2017 with accurate control of initial conditions such as soil properties and surface roughness laboratory rainfall simulations are capable of focusing on effect of a single specific factor such as slope geometry and rainfall characteristics ben hur and wakindiki 2004 cuomo et al 2016 it can effectively gain insights into the dynamic change of runoff generation and soil erosion processes bryan and poesen 1989 cuomo et al 2016 jomaa et al 2010 conducting rainfall simulation experiments in laboratory this study aims to understand the impacts of rainfall moving directions on surface flow and soil erosion processes on bare soil slopes with soil sealing in terms of peak and total volume of surface flow and sediment at slope outlet under rainfalls 2 methodology 2 1 experiment setup the equipment of the rainfall experiments in this study included a movable rainfall simulator a tilted soil flume and an overland flow collector fig 1 similar to the devices employed in ran et al 2012 the rainfall simulator fig 1a was comprised of a constant head tank a water supply pipe a raindrop generator and an electric motor with a control pane which moved the raindrop generator back and forth along a horizontal track way different rainfall intensities were obtained by a flow controller on the pipe the maintenance of a stable pressure by the constant head tank held the steadiness of rain intensity during the simulated rainfall events the raindrop generator fig 1c was an 1 m 1 m sealed tank with uniformly attached more than 1300 syringe needles which produced raindrops in experiments the needle matrix had an average spacing distance of 28 mm between needles and each needle had an internal diameter of 0 58 mm the uniformity coefficients of simulated rainfall in this study were around 90 which was similar to natural rainfall neff 1979 the average raindrop diameter was 5 51 mm which was consistent with the raindrop size distribution of convective rains in loess plateau china niu et al 2010 the generator was set 12 m above the soil flume which was sufficient for the raindrop to reach the terminal speed andsager et al 1999 the experimental plot was a steel soil flume fig 1d which had 4 m length 1 m width and 0 3 m depth fig 1 the soil used in this experiment was a silt loam consisting of 13 clay 2 μm 44 fine silt 2 20 μm 32 coarse silt 20 50 μm and 11 sand 50 μm which was collected in loess plateau the organic matter content was 2 0 g kg 1 soil was crushed to pass through a 4 0 mm sieve and mixed thoroughly the soil was packed in the flume with six 5 cm layers upon a 0 05 m thick sand layer to facilitate drainage in experiment each soil layer was uniformly spread the flume bed then by scraping the surface to a flat and smooth surface subsequently the soil surface was tamped by dropping a wooden block 5 times from a height of 0 4 m to give an identical initial soil bulk density and permeability the soil bulk density was 1 31 0 04 103 kg m 3 which was calculated by weighting the dried soil samples with the cutting ring volume 100 cm3 the volumetric water content of the soil was set to 0 24 0 02 a metal runoff collector was set at the outlet of the soil flume which directed surface flow into a container for measurement surface flow and sediment samples were taken every minute at the outlet of the flume during each rainfall experiment the sediment samples from the collector were dried at 110 c for more than 24 h and then weighed and recorded the particle size distribution of the collected samples was measured using a malvern mastersizer 2000 laser diffraction device 2 2 rainfall experiment design in this study two rainfall moving directions i e upslope moving rainfall and downslope moving rainfall see fig 1 and three slope gradients i e 15 20 and 25 were involved as mentioned above 15 slope was steeper than those used in previous studies focused on rainfall movement e g liang and melching 2015 nunes et al 2006 the rainfall movement was implemented by moving the rainfall generator driven by an electric motor the movement of rainfall was only in one direction during each event the rainfall moving velocity was operated manually by a step to step movement in which the rainfall generator moved 0 2 m slope length at a regular time interval taking a rainfall with one hour duration as example the rainfall generator moved 0 2 m in every 200 s with 5 s moving time and 195 s time interval the time averaged velocities of rainfall movement are showed in table 1 the rainfall position was defined by the slope length between the upslope end of the raindrop generator and the downslope end of the soil flume fig 1 the movement of the upslope moving rainfalls was from rainfall position 0 4 m to 4 m and that of the downslope moving rainfalls was from rainfall position 4 m to 0 4 m there were four rainfall scenarios in this study which fell into two types of rainfall intensity ranges table 1 m stood for moderate rainfall intensity 60 90 mm h 1 which are typical intense storms in loess plateau fang et al 2015 shi et al 2012 e stood for extreme rainfall intensity 120 180 mm h 1 representing extreme storms these rainfall intensities were frequently used in rainfall experiment studies on loess slopes e g chen et al 2008 han et al 2011 pan and shangguan 2006 shi et al 2012 the rainfall intensity was calibrated before and after running each rainfall experiment the calibration was conducted using a plastic sheet covered the flume and collected the runoff at the outlet for 1 min 3 times to compare with the desire rainfall intensity in this experiment structural seal was mainly considered rather than depositional seal in this study because of large velocity of surface flow under the high rainfall intensities on the steep slope for each rainfall scenario there was a dry run and a wet run with identical rainfall intensity and duration representing different initial soil surface and soil water content conditions for the dry run the dry soil was freshly packed in the flume after the dry run and a no rainfall time interval see table 1 the wet run was conducted with the wet soil after each wet run the soil in the flume was replaced with new soil in this study no extra replication of each rainfall scenario was conducted although all the rainfall experiments were replicable because of the well controlled factors in the experiments soil surface samples were collected using a cutting ring with the diameter of 79 8 mm from a depth of 20 mm to the soil surface before and after each rainfall series i e including a dry run and a wet run the thickness of the soil sample was appropriate as a wide range of studies reported that the seal thickness obtained under laboratory conditions was within 20 mm e g assouline 2004 mcintyre 1958 because there was no suitable equipment to accurately measure the saturated hydraulic conductivity of the soil surface samples on slopes just at the end of a simulated rainfall event in the laboratory the bulk density and porosity of the soil surface samples were measured to investigate the change of saturated hydraulic conductivity after formation of soil surface seal the ratio between the saturated hydraulic conductivity of the sealed soil ksc and that of the initial soil ks can be estimated by 1 k sc k s n c 3 1 n 2 n 3 1 n c 2 where n and nc are the porosity of the initial and the sealed soils respectively eq 1 is a kozeny carmen derived relationship carman 1937 which is widely used to estimate soil saturated hydraulic conductivity in many experiments e g assouline 2006 assouline and or 2013 or et al 2000 rahimi et al 2011 3 results 3 1 soil surface sealing according to the experiment arrangement described above 48 rainfall events were conducted on the soil flume infiltration excess surface flow was observed on the slope during the experiment the porosity of the surface soil decreased around 25 after each rainfall series indicating that the surface seal was generated and the saturated hydraulic conductivity of sealed soil surface dropped to around 1 4 of the initial soil surface according to eq 1 table 2 in addition as the depth of the soil surface sample was larger than the thickness of the soil surface seal derived by previous research e g assouline 2004 mcintyre 1958 the actual saturated hydraulic conductivity of the soil seal layer in this experiment should be less than the values in table 2 in all dry runs soil surface became smooth and compacted as the sealed soil surface shown in fig 2 b just after 3 5 min hitting by raindrops which mainly due to the high silt content 76 of the soil and the high rainfall intensity during the upslope moving rainfalls structural seal formed gradually from downslope to upslope after soil surface was hit by the raindrops while during the downslope moving rainfalls structural seal formed from upslope to downslope and surface flow moved onto dry soil ahead of the simulator fig 2a shows the unsealed soil surface when rainfall had not arrived but surface flow just arrived from upslope in a downslope moving rainfall and fig 2b shows the sealed soil surface after raindrop hitting 3 2 surface flow with different soil surface conditions impacts of rainfall moving direction on surface flow processes was in different way on the slope the differences between the hydrographs under upslope moving rainfall and downslope moving rainfall in a dry run were large while that in a wet run is slight taking the m 1 rainfall pattern as example hydrographs with different rainfall moving directions and slopes were presented in fig 3 in the dry runs the hydrographs under the upslope moving rainfalls at the outlet had rapid rising limbs during the first 13 15 min and then slightly decreased until the rainfalls stopped fig 3 the hydrographs under the downslope moving rainfalls started later and had gentler rising limbs compared to the upslope moving rainfalls generally there was less than 7 of difference between the peak runoff rates of the two moving rainfalls e g for rainfall m 1 on the 20 slope 14 6 10 6 m3 s for the upslope moving rainfall and 15 2 10 6 m3 s for the downslope moving rainfall the reduction in the difference between the surface flow start time at the outlet of upslope moving and downslope moving rainfall from 15 to 25 slope is considerable e g in fig 3 for rainfall m 1 it is from 37 min to 12 min in the wet runs the surface flow of both the upslope moving and downslope moving rainfalls started and raised more quickly than in the dry run and their peak runoff rates became closer e g for rainfall m 1 on the 15 slope 15 6 10 6 m3 s for the upslope moving rainfall and 15 9 10 6 m3 s for the downslope moving rainfall the surface flow processes of the experiments are summarized in tables 3 and 4 the runoff coefficient was estimated as the ratio of the total amount of surface flow to the total rainfall amount for a rainfall event in the dry runs the runoff coefficients of the upslope moving rainfalls were 25 700 higher than those of the downslope moving rainfalls fig 4 a as the slope gradient increased from 15 to 25 the difference between the runoff coefficients of upslope moving rainfall and downslope moving rainfall decreased more than 50 under the same experimental condition fig 4a in the wet runs there was limited difference in runoff coefficient between the two rainfall moving directions fig 4b 3 3 soil erosion in this study the dominant erosion process was interrill erosion because no rills were observed during the experiments the total soil erosion and peak erosion rate of a dry run was mostly larger than that of a wet run under the same rainfall condition for both rainfall moving directions tables 5 and 6 summarize the characteristics of the soil erosion processes of all experimental runs as an example the sedigraphs of rainfall m 1 which are corresponding to the hydrographs in fig 3 are presented in fig 5 in the dry runs the temporal changing pattern of erosion rate fig 5 was similar to the surface flow rate fig 3 in the wet runs the erosion rate was lower than that in the dry runs especially under the downslope moving rainfalls for both the dry and wet runs the peak erosion rates of the downslope moving rainfalls were larger than those under the upslope moving rainfalls fig 5 e g for rainfall m 1 on the 20 slope 0 37 g s and 0 32 g s for the dry run and wet run of the upslope moving rainfall while 0 64 g s and 0 44 g s for the dry run and wet run of the downslope moving rainfall the soil erosion rate on the steep slope was larger than that on the gentle slope for most time points during all rainfalls fig 5 as the rainfall intensities and durations varied among the four rainfall scenarios the flow weighted sediment concentration defined as the ratio of the soil erosion mass to the surface flow volume in one rainfall event was adopted to quantitatively estimate soil erosion in each run in the dry runs the flow weighted sediment concentrations under the downslope moving rainfalls were larger than those of the upslope moving rainfalls at the 20 and 25 slopes but slightly lower than those at the 15 slope fig 6 a in the wet runs the flow weighted sediment concentrations of the downslope moving rainfalls greatly reduced but were still larger than those of the upslope moving rainfalls fig 6b for both the dry and wet runs the differences between the flow weighted sediment concentrations and the peak erosion rates of the upslope moving and downslope moving rainfalls increased rapidly from 15 to 20 and gently from 20 to 25 figs 6 7 generally the mean weight diameter of the transported sediments under the downslope moving rainfalls was similar with that of the upslope moving rainfalls in the dry runs but was larger than that in the wet runs taking rainfall m 1 on the 20 slope as example in the dry runs the mean weight diameter under the upslope moving rainfalls declined slightly around 10 with time fig 8 a note that the runoff during the downslope moving rainfall started at 30 min the mean weight diameter of sediments under the downslope moving rainfall was close to that under the upslope moving rainfall until the last 5 min when rainfall moved near the outlet and transported more coarse soil particles than the upslope moving rainfall in the wet runs the mean weight diameter of sediments under the upslope moving rainfalls decreased with time as rainfall moved to the upslope indicating a decrease of coarser soil particles in the transported sediments however the mean weight diameter of downslope moving rainfall increased more than 50 with time and was larger than that of the upslope moving rainfall from 20 min after rainfall fig 8b 4 discussion 4 1 effect of rainfall moving directions on surface flow and soil erosion at dry slopes the upslope moving rainfalls generated more total surface flow than the downslope moving rainfalls even though their peak runoff rates were close in which the spatial processes of soil surface sealing were distinct for the two moving directions of rainfall for the upslope moving rainfalls soil surface sealing was initially generated on the downslope areas between the raining zone and the flume outlet by the raindrop impact e g fig 2b and resulted in low surface infiltration capacity e g table 2 thus the surface flow from the upslope areas moving on the sealed downslope areas had small infiltration conversely for the downslope moving rainfalls surface flow moved on unsealed soil surface where more water infiltrated than on sealed soil surface e g fig 2a thus there was less surface flow delivered to the outlet of the flume than those during the upslope moving rainfalls in addition more infiltration in the downslope moving rainfall decreased the gap between the peak runoff rate of the upslope moving rainfall and downslope moving rainfalls this was not consistent with previous studies without consideration of soil sealing which reported that the total runoff in downslope moving rainfall was usually close to or larger than that in upslope moving rainfall while peak runoff rate was much higher in downslope moving rainfall e g de lima et al 2011 nunes et al 2006 the differences between the runoff coefficients of the upslope moving and downslope moving rainfalls on a same slope decreased with slope gradient increase slope gradient had considerable impact on surface flow processes in the downslope moving rainfalls but had slight impact in the upslope moving rainfalls during the downslope moving rainfalls runoff coefficient increased remarkably from 15 to 25 slope fig 4 because low surface flow velocity increased infiltration volume on gentle slopes and the gravitational effect was reduced to limit infiltration as slope gradient increased chow et al 1988 philip 1991 similar findings have been derived by many researchers through laboratory experiments and numerical analysis e g fox et al 1997 essig et al 2009 in the upslope moving rainfalls soil surface seal greatly reduced total infiltration volume on slopes and thus attenuated slope gradient impacts on surface flow generation on steep 10 and sealed soil slopes shi et al 2012 also found that the slope gradient had little impact on runoff coefficient because of the different spatial processes of soil sealing between the two moving rainfalls the flow weighted sediment concentrations and peak erosion rates of the downslope moving rainfalls were higher than those of the upslope moving rainfalls over 70 with the same rainfall intensity on the 20 and 25 slopes figs 6a and 7a some laboratory experiments which conducted on the slopes 2 to 14 with dry soils e g de lima et al 2008 nunes et al 2006 also reported that downslope moving rainfall caused more soil loss than upslope moving rainfall and it was concluded that the reason was downslope moving rainfall had much higher peak which led to higher stream power for erosion in this study however the peak runoff rates of the upslope moving and downslope moving rainfalls were close the cause was that the unsealed downslope soil was more vulnerable to erosion during the downslope moving rainfalls on slopes compared to the upslope moving rainfalls however for the 15 slope the flow weighted sediment concentrations and peak erosion rates in the downslope moving rainfalls were slightly lower than or close to those under the upslope moving rainfalls fig 6a and 7a this is mainly due to the fact that the large infiltration of the unsealed downslope surface greatly reduced surface flow generation on the 15 slope in the downslope moving rainfall which limited soil detachment of surface flow fox et al 1997 huang 1998 compared to 20 and 25 slope 4 2 effect of rainfall moving directions on surface flow and soil erosion at wet slopes all the soil surface has been sealed before the wet runs on the slopes the runoff coefficients of the upslope moving rainfalls were close to that of the downslope moving rainfalls fig 4b because most precipitation became surface flow for both the upslope moving and downslope moving rainfalls with small infiltration due to sealed soil surface and large soil water content as soil surface seal attenuated slope gradient impacts on surface flow generation the runoff coefficient remained stable at different slope gradients the flow weighted sediment concentration and peak erosion rates of a downslope moving rainfall in a wet run were much lower than those in a dry run figs 6 and 7 even though there was less surface flow in a dry run this is because there were surface seals and less erodible soil particles on the slope the flow weighted sediment concentration and peak erosion rates in downslope moving rainfalls were still larger than those in the upslope moving rainfalls although the soil surface was sealed for both rainfall directions figs 6b and 7b the reason was related to the different spatial variation of surface flow sediment transport capability on slopes between the two moving rainfalls during the upslope moving rainfalls the path length of the surface flow was increasing as rainfall moved upslope so the surface flow depth and rate decreased slightly due to increased infiltration thus many large detached particles cannot be transported to the outlet by decreasing surface flow which had low capability of sediment transport fig 8b however during the downslope moving rainfalls the depth of the surface flow increased gradually as rainfall moving downslope thus a proportion of the large particles which deposited on the downslope area when the surface flow was shallow in the early stage of the rainfall can be transported again as rainfall approaching the outlet for this reason more sediment with larger mean weight diameter were collected at the outlet during the downslope moving rainfalls than the upslope moving rainfalls fig 8b besides the difference in soil erosion between the upslope moving and downslope moving rainfalls increased with slope gradient which was consistent with the findings of de lima et al 2003 indicating that the difference in sediment transport capability increased with increasing slope gradient 4 3 connect to nature catchments in this study an experiment work in laboratory was presented and implied that the different spatial processes of soil surface sealing which caused by rainfalls with different moving directions can lead to large differences in surface flow and soil erosion processes even the laboratory scale is relatively small compared with the real hillslope or catchment this study observed some fundamental impacts of rainfall moving directions for a natural catchment having moving storms with typically preferred directions which is normal seo et al 2012 the differently orientating hillslopes may present distinct runoff and soil erosion processes to impact river hydrographs and sedigraphs in the catchment scale in floods moreover the result of this research can be directly applied to predicting runoff and erosion in farms with moving irrigation systems e g center pivots which often travel up and down slopes and generate surface seal by high energy water drops in fields where overland flow move on dry or wet soil ortiz et al 2009 trout and neibling 1993 this study will be the first step of investigation concerning impacts of the interactions between rainfall moving directions and soil sealing on runoff and soil erosion in nature catchments the mechanisms derived from this experiment study can effectively guide further experimental and numerical research works in the future study moreover the much smaller differences of runoff and sediment between different rainfall moving directions in the wet runs than in the dry runs implied that antecedent rainfall condition can largely change the impacts of rainfall directions in nature catchments however a few things should be prepared before combining the findings of this study to the future study on effects of rainfall moving direction in a nature catchment for instance varying types of soil have different formation processes and characteristics of surface sealing and these need to be tested by laboratory and field experiments on the other hand vegetation cover in real catchment can also influence the impacts of soil surface sealing processes the spatial distribution of vegetation cover at natural catchment requires investigation to identify its interactive effect with rainfall moving directions more importantly surface flow generation and concentration in nature catchments are complicated due to heterogeneity of topography which is much more complex than the plane slope in this study thus a comprehensive method considering all these factors should be utilized to investigate the impact of rainfall moving directions in nature catchments finally the detailed information of well monitored moving rainfalls is required for a better understanding of the effects at catchment scale under natural conditions 5 conclusions in this study the impact of rainfall moving direction on surface flow generation and soil erosion process on slopes with sealing was investigated through a series of rainfall experiments on a soil flume the results indicated that the two different rainfall moving directions can lead to different spatial processes of soil surface sealing and cause large differences in surface flow and soil erosion processes more surface flow was generated under the upslope moving rainfalls than the downslope moving rainfalls in the dry runs this is mainly because the downslope soil seal which formed early during the upslope moving rainfalls decreased infiltration the difference between the runoff coefficients of the two moving direction rainfalls decreased remarkably with slope gradient increasing from 15 to 25 in the wet runs the runoff coefficients of the upslope moving rainfalls were close to those of the downslope moving rainfalls as the surface was sealed before the runs soil erosion in the downslope moving rainfalls was more severe than that in the upslope moving rainfalls for all dry and wet runs in the dry runs the prime reason was that under downslope moving rainfalls the unsealed downslope soil was more vulnerable for erosion on slopes compared to upslope moving rainfalls leading to remarkable differences between the flow weighted sediment concentrations and peak erosion rates of the two moving rainfalls in the wet runs the reason for the difference of soil erosion was due that during upslope moving rainfall the surface flow moving on downslope extending flow path decreased because of infiltration thus the sediment transport capability of surface flow reduced however the differences in flow weighted sediment concentrations and peak erosion rates between the upslope moving and downslope moving rainfalls were much lower than those in the dry runs this study provided detailed information and understanding of how rainfall moving direction affect surface flow and soil erosion processes at plot scale which is useful in the future study to investigate impacts of rainfall movement on runoff and soil erosion process at catchment scale acknowledgements this research was financially supported by national key research and development program of china nkrdp grant no 2016yfc0402404 and national natural scientific foundation of china grant nos 51379184 51679209 and 51509218 
6902,although rainfall characteristics play important roles in runoff generation and soil erosion our understanding about how rainfall moving direction impacts surface flow and soil erosion on slopes considering spatial process of soil surface sealing is still poor in this study a series of laboratory experiments was conducted using a soil flume and a movable rainfall simulator to investigate this impact two rainfall moving directions i e upslope moving and downslope moving and two soil surface moisture conditions i e dry runs with no antecedent rainfall and wet runs with antecedent rainfall were considered in the experiments with different slope gradients and rainfall intensities the results showed that the upslope moving rainfalls generated more surface flow from 25 to 700 and less soil erosion than the downslope moving rainfalls in the dry runs due to the different spatial developing processes of soil surface sealing the difference between the runoff coefficients of the two moving direction rainfalls decreased remarkably more than 50 with slope gradient increasing from 15 to 25 in the wet runs surface flow was similar for the upslope moving and downslope moving rainfalls as all of the soil surface had been sealed before the experiments soil erosion in the downslope moving rainfalls was larger than that in the upslope moving rainfalls due to higher sediment transport capability of the surface flow for both rainfall moving directions with same rainfall conditions the total soil erosion in a dry run was mostly larger than that in a wet run because of less erodible soil particles on the sealed slope in the wet run the result of this study implied that different rainfall moving directions can lead to distinct spatial processes of soil surface sealing and caused large differences in surface flow and soil erosion processes on slopes keywords rainfall moving direction soil surface sealing rainfall simulation surface flow soil erosion slope gradient 1 introduction rainfall runoff and soil erosion processes on hillslopes are important in hillslope hydrology and extensively concerned in many aspects including soil and water conservation landform protection and agricultural management iverson 2000 quinton et al 2010 zhao et al 2013 rainfall characteristics are the fundamental factors for these processes dunkerley 2008 seeger et al 2004 although the influence of rainfall characteristics such as rainfall intensity and pattern has been widely studied e g an et al 2014 berger et al 2010 nicótina et al 2008 parsons and stone 2006 many studies employed stationary rainfall and did not take rainfall movement into account e g assouline et al 2007 defersha and melesse 2012 dunkerley 2012 rainfall movement is normal rather than exceptional in natural catchments marshall 1980 nikolopoulos et al 2014 singh 1998 a majority of the storms are likely to be moving storms with preferential directions in different seasons seo et al 2012 even at small scale within hundreds meters the spatial and temporal variability of rainfall was still observed e g goodrich et al 1995 sharon and arazi 1997 both laboratory and numerical studies have shown that rainfall moving direction strongly impacts surface flow and soil erosion processes e g de lima et al 2008 lee et al 2015 surface flow and soil erosion could be under or over estimated if the impact of rainfall movement is neglected de lima et al 2003 liang and melching 2015 sigaroodi and chen 2016 laboratory studies on soil flume have shown that peak discharge and erosion rate are higher under downslope moving rainfall i e rainfall moved from the top of a slope to the downslope outlet than upslope moving rainfall i e rainfall moved from the downslope outlet to the top of a slope e g de lima and singh 2003 de lima et al 2008 the shapes of hydrograph and sedigraph are also largely affected by rainfall movement in particular those of upslope moving rainfalls have early rises gentler rising limbs and longer recession than downslope rainfalls de lima et al 2011 mizumura and ito 2011 similar results have been derived from numerical model simulation at both the plot scale and catchment scale e g chang 2007 nunes et al 2006 seo et al 2012 volpi et al 2013 however in these studies soil surface sealing process which may largely influence dynamics of surface flow and soil erosion was not considered on a bare soil surface soil surface sealing is commonly developed during rainfall events there are two major types of rainfall induced soil surface sealing i structural seals due to raindrop hitting and ii depositional seals led by deposition of fine soil particles assouline 2004 lu et al 2017 morin and benyamini 1977 the seal layer normally has lower porosity finer pores lower hydraulic conductivity and higher shear strength than unsealed soil han et al 2016 zhou et al 2013 so soil sealing decreases soil surface infiltration and consequently increase surface flow liu et al 2011 sela et al 2012 also the detachability of soil surface is reduced by sealing as the soil aggregate structure is strengthened by embedded fine soil particles luk et al 1993 although the important role of soil surface sealing in runoff generation and soil erosion processes has been commonly accepted e g assouline and mualem 1997 chen et al 2013 zhou et al 2013 it is remained unclear that how different spatial processes of soil sealing which caused by different rainfall moving directions impact runoff and soil erosion on hillslopes additionally as most studies related to sealing e g armenise et al 2018 assouline and ben hur 2006 zhou et al 2013 did not take impacts of antecedent rainfall on soil surface condition into account it is worthwhile to study these impacts on surface flow and soil erosion processes although a few experimental studies focusing on rainfall movement have taken slope gradients into account the slopes in these experiments were flat generally less than 15 e g liang and melching 2015 nunes et al 2006 at the hillslope scale opposite trends were reported regarding the effect of slope steepness on infiltration depending on soil and slope conditions that were considered e g chen and young 2006 essig et al 2009 philip 1991 ribolzi et al 2011 there is a lack of understanding the effect of rainfall moving directions on runoff and soil erosion processes with different steep slopes rainfall simulation is one of the most useful and beneficial tools for the study on surface flow and soil erosion which have been widely used since the 1930s cerdà et al 1997 iserloh et al 2010 martínez murillo et al 2013 meyer 1965 tauro et al 2017 with accurate control of initial conditions such as soil properties and surface roughness laboratory rainfall simulations are capable of focusing on effect of a single specific factor such as slope geometry and rainfall characteristics ben hur and wakindiki 2004 cuomo et al 2016 it can effectively gain insights into the dynamic change of runoff generation and soil erosion processes bryan and poesen 1989 cuomo et al 2016 jomaa et al 2010 conducting rainfall simulation experiments in laboratory this study aims to understand the impacts of rainfall moving directions on surface flow and soil erosion processes on bare soil slopes with soil sealing in terms of peak and total volume of surface flow and sediment at slope outlet under rainfalls 2 methodology 2 1 experiment setup the equipment of the rainfall experiments in this study included a movable rainfall simulator a tilted soil flume and an overland flow collector fig 1 similar to the devices employed in ran et al 2012 the rainfall simulator fig 1a was comprised of a constant head tank a water supply pipe a raindrop generator and an electric motor with a control pane which moved the raindrop generator back and forth along a horizontal track way different rainfall intensities were obtained by a flow controller on the pipe the maintenance of a stable pressure by the constant head tank held the steadiness of rain intensity during the simulated rainfall events the raindrop generator fig 1c was an 1 m 1 m sealed tank with uniformly attached more than 1300 syringe needles which produced raindrops in experiments the needle matrix had an average spacing distance of 28 mm between needles and each needle had an internal diameter of 0 58 mm the uniformity coefficients of simulated rainfall in this study were around 90 which was similar to natural rainfall neff 1979 the average raindrop diameter was 5 51 mm which was consistent with the raindrop size distribution of convective rains in loess plateau china niu et al 2010 the generator was set 12 m above the soil flume which was sufficient for the raindrop to reach the terminal speed andsager et al 1999 the experimental plot was a steel soil flume fig 1d which had 4 m length 1 m width and 0 3 m depth fig 1 the soil used in this experiment was a silt loam consisting of 13 clay 2 μm 44 fine silt 2 20 μm 32 coarse silt 20 50 μm and 11 sand 50 μm which was collected in loess plateau the organic matter content was 2 0 g kg 1 soil was crushed to pass through a 4 0 mm sieve and mixed thoroughly the soil was packed in the flume with six 5 cm layers upon a 0 05 m thick sand layer to facilitate drainage in experiment each soil layer was uniformly spread the flume bed then by scraping the surface to a flat and smooth surface subsequently the soil surface was tamped by dropping a wooden block 5 times from a height of 0 4 m to give an identical initial soil bulk density and permeability the soil bulk density was 1 31 0 04 103 kg m 3 which was calculated by weighting the dried soil samples with the cutting ring volume 100 cm3 the volumetric water content of the soil was set to 0 24 0 02 a metal runoff collector was set at the outlet of the soil flume which directed surface flow into a container for measurement surface flow and sediment samples were taken every minute at the outlet of the flume during each rainfall experiment the sediment samples from the collector were dried at 110 c for more than 24 h and then weighed and recorded the particle size distribution of the collected samples was measured using a malvern mastersizer 2000 laser diffraction device 2 2 rainfall experiment design in this study two rainfall moving directions i e upslope moving rainfall and downslope moving rainfall see fig 1 and three slope gradients i e 15 20 and 25 were involved as mentioned above 15 slope was steeper than those used in previous studies focused on rainfall movement e g liang and melching 2015 nunes et al 2006 the rainfall movement was implemented by moving the rainfall generator driven by an electric motor the movement of rainfall was only in one direction during each event the rainfall moving velocity was operated manually by a step to step movement in which the rainfall generator moved 0 2 m slope length at a regular time interval taking a rainfall with one hour duration as example the rainfall generator moved 0 2 m in every 200 s with 5 s moving time and 195 s time interval the time averaged velocities of rainfall movement are showed in table 1 the rainfall position was defined by the slope length between the upslope end of the raindrop generator and the downslope end of the soil flume fig 1 the movement of the upslope moving rainfalls was from rainfall position 0 4 m to 4 m and that of the downslope moving rainfalls was from rainfall position 4 m to 0 4 m there were four rainfall scenarios in this study which fell into two types of rainfall intensity ranges table 1 m stood for moderate rainfall intensity 60 90 mm h 1 which are typical intense storms in loess plateau fang et al 2015 shi et al 2012 e stood for extreme rainfall intensity 120 180 mm h 1 representing extreme storms these rainfall intensities were frequently used in rainfall experiment studies on loess slopes e g chen et al 2008 han et al 2011 pan and shangguan 2006 shi et al 2012 the rainfall intensity was calibrated before and after running each rainfall experiment the calibration was conducted using a plastic sheet covered the flume and collected the runoff at the outlet for 1 min 3 times to compare with the desire rainfall intensity in this experiment structural seal was mainly considered rather than depositional seal in this study because of large velocity of surface flow under the high rainfall intensities on the steep slope for each rainfall scenario there was a dry run and a wet run with identical rainfall intensity and duration representing different initial soil surface and soil water content conditions for the dry run the dry soil was freshly packed in the flume after the dry run and a no rainfall time interval see table 1 the wet run was conducted with the wet soil after each wet run the soil in the flume was replaced with new soil in this study no extra replication of each rainfall scenario was conducted although all the rainfall experiments were replicable because of the well controlled factors in the experiments soil surface samples were collected using a cutting ring with the diameter of 79 8 mm from a depth of 20 mm to the soil surface before and after each rainfall series i e including a dry run and a wet run the thickness of the soil sample was appropriate as a wide range of studies reported that the seal thickness obtained under laboratory conditions was within 20 mm e g assouline 2004 mcintyre 1958 because there was no suitable equipment to accurately measure the saturated hydraulic conductivity of the soil surface samples on slopes just at the end of a simulated rainfall event in the laboratory the bulk density and porosity of the soil surface samples were measured to investigate the change of saturated hydraulic conductivity after formation of soil surface seal the ratio between the saturated hydraulic conductivity of the sealed soil ksc and that of the initial soil ks can be estimated by 1 k sc k s n c 3 1 n 2 n 3 1 n c 2 where n and nc are the porosity of the initial and the sealed soils respectively eq 1 is a kozeny carmen derived relationship carman 1937 which is widely used to estimate soil saturated hydraulic conductivity in many experiments e g assouline 2006 assouline and or 2013 or et al 2000 rahimi et al 2011 3 results 3 1 soil surface sealing according to the experiment arrangement described above 48 rainfall events were conducted on the soil flume infiltration excess surface flow was observed on the slope during the experiment the porosity of the surface soil decreased around 25 after each rainfall series indicating that the surface seal was generated and the saturated hydraulic conductivity of sealed soil surface dropped to around 1 4 of the initial soil surface according to eq 1 table 2 in addition as the depth of the soil surface sample was larger than the thickness of the soil surface seal derived by previous research e g assouline 2004 mcintyre 1958 the actual saturated hydraulic conductivity of the soil seal layer in this experiment should be less than the values in table 2 in all dry runs soil surface became smooth and compacted as the sealed soil surface shown in fig 2 b just after 3 5 min hitting by raindrops which mainly due to the high silt content 76 of the soil and the high rainfall intensity during the upslope moving rainfalls structural seal formed gradually from downslope to upslope after soil surface was hit by the raindrops while during the downslope moving rainfalls structural seal formed from upslope to downslope and surface flow moved onto dry soil ahead of the simulator fig 2a shows the unsealed soil surface when rainfall had not arrived but surface flow just arrived from upslope in a downslope moving rainfall and fig 2b shows the sealed soil surface after raindrop hitting 3 2 surface flow with different soil surface conditions impacts of rainfall moving direction on surface flow processes was in different way on the slope the differences between the hydrographs under upslope moving rainfall and downslope moving rainfall in a dry run were large while that in a wet run is slight taking the m 1 rainfall pattern as example hydrographs with different rainfall moving directions and slopes were presented in fig 3 in the dry runs the hydrographs under the upslope moving rainfalls at the outlet had rapid rising limbs during the first 13 15 min and then slightly decreased until the rainfalls stopped fig 3 the hydrographs under the downslope moving rainfalls started later and had gentler rising limbs compared to the upslope moving rainfalls generally there was less than 7 of difference between the peak runoff rates of the two moving rainfalls e g for rainfall m 1 on the 20 slope 14 6 10 6 m3 s for the upslope moving rainfall and 15 2 10 6 m3 s for the downslope moving rainfall the reduction in the difference between the surface flow start time at the outlet of upslope moving and downslope moving rainfall from 15 to 25 slope is considerable e g in fig 3 for rainfall m 1 it is from 37 min to 12 min in the wet runs the surface flow of both the upslope moving and downslope moving rainfalls started and raised more quickly than in the dry run and their peak runoff rates became closer e g for rainfall m 1 on the 15 slope 15 6 10 6 m3 s for the upslope moving rainfall and 15 9 10 6 m3 s for the downslope moving rainfall the surface flow processes of the experiments are summarized in tables 3 and 4 the runoff coefficient was estimated as the ratio of the total amount of surface flow to the total rainfall amount for a rainfall event in the dry runs the runoff coefficients of the upslope moving rainfalls were 25 700 higher than those of the downslope moving rainfalls fig 4 a as the slope gradient increased from 15 to 25 the difference between the runoff coefficients of upslope moving rainfall and downslope moving rainfall decreased more than 50 under the same experimental condition fig 4a in the wet runs there was limited difference in runoff coefficient between the two rainfall moving directions fig 4b 3 3 soil erosion in this study the dominant erosion process was interrill erosion because no rills were observed during the experiments the total soil erosion and peak erosion rate of a dry run was mostly larger than that of a wet run under the same rainfall condition for both rainfall moving directions tables 5 and 6 summarize the characteristics of the soil erosion processes of all experimental runs as an example the sedigraphs of rainfall m 1 which are corresponding to the hydrographs in fig 3 are presented in fig 5 in the dry runs the temporal changing pattern of erosion rate fig 5 was similar to the surface flow rate fig 3 in the wet runs the erosion rate was lower than that in the dry runs especially under the downslope moving rainfalls for both the dry and wet runs the peak erosion rates of the downslope moving rainfalls were larger than those under the upslope moving rainfalls fig 5 e g for rainfall m 1 on the 20 slope 0 37 g s and 0 32 g s for the dry run and wet run of the upslope moving rainfall while 0 64 g s and 0 44 g s for the dry run and wet run of the downslope moving rainfall the soil erosion rate on the steep slope was larger than that on the gentle slope for most time points during all rainfalls fig 5 as the rainfall intensities and durations varied among the four rainfall scenarios the flow weighted sediment concentration defined as the ratio of the soil erosion mass to the surface flow volume in one rainfall event was adopted to quantitatively estimate soil erosion in each run in the dry runs the flow weighted sediment concentrations under the downslope moving rainfalls were larger than those of the upslope moving rainfalls at the 20 and 25 slopes but slightly lower than those at the 15 slope fig 6 a in the wet runs the flow weighted sediment concentrations of the downslope moving rainfalls greatly reduced but were still larger than those of the upslope moving rainfalls fig 6b for both the dry and wet runs the differences between the flow weighted sediment concentrations and the peak erosion rates of the upslope moving and downslope moving rainfalls increased rapidly from 15 to 20 and gently from 20 to 25 figs 6 7 generally the mean weight diameter of the transported sediments under the downslope moving rainfalls was similar with that of the upslope moving rainfalls in the dry runs but was larger than that in the wet runs taking rainfall m 1 on the 20 slope as example in the dry runs the mean weight diameter under the upslope moving rainfalls declined slightly around 10 with time fig 8 a note that the runoff during the downslope moving rainfall started at 30 min the mean weight diameter of sediments under the downslope moving rainfall was close to that under the upslope moving rainfall until the last 5 min when rainfall moved near the outlet and transported more coarse soil particles than the upslope moving rainfall in the wet runs the mean weight diameter of sediments under the upslope moving rainfalls decreased with time as rainfall moved to the upslope indicating a decrease of coarser soil particles in the transported sediments however the mean weight diameter of downslope moving rainfall increased more than 50 with time and was larger than that of the upslope moving rainfall from 20 min after rainfall fig 8b 4 discussion 4 1 effect of rainfall moving directions on surface flow and soil erosion at dry slopes the upslope moving rainfalls generated more total surface flow than the downslope moving rainfalls even though their peak runoff rates were close in which the spatial processes of soil surface sealing were distinct for the two moving directions of rainfall for the upslope moving rainfalls soil surface sealing was initially generated on the downslope areas between the raining zone and the flume outlet by the raindrop impact e g fig 2b and resulted in low surface infiltration capacity e g table 2 thus the surface flow from the upslope areas moving on the sealed downslope areas had small infiltration conversely for the downslope moving rainfalls surface flow moved on unsealed soil surface where more water infiltrated than on sealed soil surface e g fig 2a thus there was less surface flow delivered to the outlet of the flume than those during the upslope moving rainfalls in addition more infiltration in the downslope moving rainfall decreased the gap between the peak runoff rate of the upslope moving rainfall and downslope moving rainfalls this was not consistent with previous studies without consideration of soil sealing which reported that the total runoff in downslope moving rainfall was usually close to or larger than that in upslope moving rainfall while peak runoff rate was much higher in downslope moving rainfall e g de lima et al 2011 nunes et al 2006 the differences between the runoff coefficients of the upslope moving and downslope moving rainfalls on a same slope decreased with slope gradient increase slope gradient had considerable impact on surface flow processes in the downslope moving rainfalls but had slight impact in the upslope moving rainfalls during the downslope moving rainfalls runoff coefficient increased remarkably from 15 to 25 slope fig 4 because low surface flow velocity increased infiltration volume on gentle slopes and the gravitational effect was reduced to limit infiltration as slope gradient increased chow et al 1988 philip 1991 similar findings have been derived by many researchers through laboratory experiments and numerical analysis e g fox et al 1997 essig et al 2009 in the upslope moving rainfalls soil surface seal greatly reduced total infiltration volume on slopes and thus attenuated slope gradient impacts on surface flow generation on steep 10 and sealed soil slopes shi et al 2012 also found that the slope gradient had little impact on runoff coefficient because of the different spatial processes of soil sealing between the two moving rainfalls the flow weighted sediment concentrations and peak erosion rates of the downslope moving rainfalls were higher than those of the upslope moving rainfalls over 70 with the same rainfall intensity on the 20 and 25 slopes figs 6a and 7a some laboratory experiments which conducted on the slopes 2 to 14 with dry soils e g de lima et al 2008 nunes et al 2006 also reported that downslope moving rainfall caused more soil loss than upslope moving rainfall and it was concluded that the reason was downslope moving rainfall had much higher peak which led to higher stream power for erosion in this study however the peak runoff rates of the upslope moving and downslope moving rainfalls were close the cause was that the unsealed downslope soil was more vulnerable to erosion during the downslope moving rainfalls on slopes compared to the upslope moving rainfalls however for the 15 slope the flow weighted sediment concentrations and peak erosion rates in the downslope moving rainfalls were slightly lower than or close to those under the upslope moving rainfalls fig 6a and 7a this is mainly due to the fact that the large infiltration of the unsealed downslope surface greatly reduced surface flow generation on the 15 slope in the downslope moving rainfall which limited soil detachment of surface flow fox et al 1997 huang 1998 compared to 20 and 25 slope 4 2 effect of rainfall moving directions on surface flow and soil erosion at wet slopes all the soil surface has been sealed before the wet runs on the slopes the runoff coefficients of the upslope moving rainfalls were close to that of the downslope moving rainfalls fig 4b because most precipitation became surface flow for both the upslope moving and downslope moving rainfalls with small infiltration due to sealed soil surface and large soil water content as soil surface seal attenuated slope gradient impacts on surface flow generation the runoff coefficient remained stable at different slope gradients the flow weighted sediment concentration and peak erosion rates of a downslope moving rainfall in a wet run were much lower than those in a dry run figs 6 and 7 even though there was less surface flow in a dry run this is because there were surface seals and less erodible soil particles on the slope the flow weighted sediment concentration and peak erosion rates in downslope moving rainfalls were still larger than those in the upslope moving rainfalls although the soil surface was sealed for both rainfall directions figs 6b and 7b the reason was related to the different spatial variation of surface flow sediment transport capability on slopes between the two moving rainfalls during the upslope moving rainfalls the path length of the surface flow was increasing as rainfall moved upslope so the surface flow depth and rate decreased slightly due to increased infiltration thus many large detached particles cannot be transported to the outlet by decreasing surface flow which had low capability of sediment transport fig 8b however during the downslope moving rainfalls the depth of the surface flow increased gradually as rainfall moving downslope thus a proportion of the large particles which deposited on the downslope area when the surface flow was shallow in the early stage of the rainfall can be transported again as rainfall approaching the outlet for this reason more sediment with larger mean weight diameter were collected at the outlet during the downslope moving rainfalls than the upslope moving rainfalls fig 8b besides the difference in soil erosion between the upslope moving and downslope moving rainfalls increased with slope gradient which was consistent with the findings of de lima et al 2003 indicating that the difference in sediment transport capability increased with increasing slope gradient 4 3 connect to nature catchments in this study an experiment work in laboratory was presented and implied that the different spatial processes of soil surface sealing which caused by rainfalls with different moving directions can lead to large differences in surface flow and soil erosion processes even the laboratory scale is relatively small compared with the real hillslope or catchment this study observed some fundamental impacts of rainfall moving directions for a natural catchment having moving storms with typically preferred directions which is normal seo et al 2012 the differently orientating hillslopes may present distinct runoff and soil erosion processes to impact river hydrographs and sedigraphs in the catchment scale in floods moreover the result of this research can be directly applied to predicting runoff and erosion in farms with moving irrigation systems e g center pivots which often travel up and down slopes and generate surface seal by high energy water drops in fields where overland flow move on dry or wet soil ortiz et al 2009 trout and neibling 1993 this study will be the first step of investigation concerning impacts of the interactions between rainfall moving directions and soil sealing on runoff and soil erosion in nature catchments the mechanisms derived from this experiment study can effectively guide further experimental and numerical research works in the future study moreover the much smaller differences of runoff and sediment between different rainfall moving directions in the wet runs than in the dry runs implied that antecedent rainfall condition can largely change the impacts of rainfall directions in nature catchments however a few things should be prepared before combining the findings of this study to the future study on effects of rainfall moving direction in a nature catchment for instance varying types of soil have different formation processes and characteristics of surface sealing and these need to be tested by laboratory and field experiments on the other hand vegetation cover in real catchment can also influence the impacts of soil surface sealing processes the spatial distribution of vegetation cover at natural catchment requires investigation to identify its interactive effect with rainfall moving directions more importantly surface flow generation and concentration in nature catchments are complicated due to heterogeneity of topography which is much more complex than the plane slope in this study thus a comprehensive method considering all these factors should be utilized to investigate the impact of rainfall moving directions in nature catchments finally the detailed information of well monitored moving rainfalls is required for a better understanding of the effects at catchment scale under natural conditions 5 conclusions in this study the impact of rainfall moving direction on surface flow generation and soil erosion process on slopes with sealing was investigated through a series of rainfall experiments on a soil flume the results indicated that the two different rainfall moving directions can lead to different spatial processes of soil surface sealing and cause large differences in surface flow and soil erosion processes more surface flow was generated under the upslope moving rainfalls than the downslope moving rainfalls in the dry runs this is mainly because the downslope soil seal which formed early during the upslope moving rainfalls decreased infiltration the difference between the runoff coefficients of the two moving direction rainfalls decreased remarkably with slope gradient increasing from 15 to 25 in the wet runs the runoff coefficients of the upslope moving rainfalls were close to those of the downslope moving rainfalls as the surface was sealed before the runs soil erosion in the downslope moving rainfalls was more severe than that in the upslope moving rainfalls for all dry and wet runs in the dry runs the prime reason was that under downslope moving rainfalls the unsealed downslope soil was more vulnerable for erosion on slopes compared to upslope moving rainfalls leading to remarkable differences between the flow weighted sediment concentrations and peak erosion rates of the two moving rainfalls in the wet runs the reason for the difference of soil erosion was due that during upslope moving rainfall the surface flow moving on downslope extending flow path decreased because of infiltration thus the sediment transport capability of surface flow reduced however the differences in flow weighted sediment concentrations and peak erosion rates between the upslope moving and downslope moving rainfalls were much lower than those in the dry runs this study provided detailed information and understanding of how rainfall moving direction affect surface flow and soil erosion processes at plot scale which is useful in the future study to investigate impacts of rainfall movement on runoff and soil erosion process at catchment scale acknowledgements this research was financially supported by national key research and development program of china nkrdp grant no 2016yfc0402404 and national natural scientific foundation of china grant nos 51379184 51679209 and 51509218 
6903,projected droughts for 21st century over india have been analysed using precipitation and temperature data obtained from regional climate models rcms under representative concentration pathways rcps 4 5 and 8 5 standardized precipitation index spi standardized effective precipitation evapo transpiration index sp eti and standardized precipitation evapotranspiration index spei at the timescale of 12 months have been used for drought characterization the k means clustering algorithm has been utilized to delineate distinct drought homogeneous regions in india trends and periodicities in drought characteristics have also been analysed the results of this study reveal that increase in evapotranspiration due to projected rise in temperature would play a major role in affecting future drought dynamics in most parts of india analysis indicates that computed magnitude of drought intensity duration and frequency depends on the choice of drought indicator spei drought index has been found to project highest drought risk as compared to other two indices used in this study north india is more vulnerable to increase in drought severity and frequency in near future however in far future most parts of the country except few southeastern states are likely to face an escalation in drought severity and frequency a shift in drought hazard from central india toward southeast central india is likely to happen with increase in greenhouse gas ghg concentration the areal extent of droughts has been found to be increasing historically which is expected to increase further in future for most parts of the country historically drought dynamics were more influenced by decrease in precipitation however in future the drought dynamics will be significantly influenced by increased evapotranspiration resulting from increase in temperature in spite of likely increase in precipitation the periodicity analysis indicates inter annual periodicities influencing monsoon months to be distributed uniformly across all clusters of the indian subcontinent with dominant cycles of 2 3 6 years further change in periodic cycles of drought due to climate change is found to be insignificant keywords droughts climate change k means clustering spatiotemporal analysis fourier periodicity analysis 1 introduction drought is one of the costliest and widespread long term persistent natural phenomena that may last for weeks months years or even decades xu et al 2015 more than one million lives have been lost globally since 1974 due to droughts un 2008 therefore systematic information about likely occurrence and distribution of droughts may assist in preparedness and mitigation against drought disasters lloyd hughes 2012 the preparedness and planning to cope with adverse impacts of a drought event depend on the information about its areal extent severity and duration this information could be obtained through drought monitoring using various drought indices that provide quantitative information to the decision makers about drought characteristics dogan et al 2012 a variety of meteorological drought indicators such as palmer drought severity index pdsi palmer 1965 rainfall decile based drought index rddi gibbs and maher 1967 bhalme and mooly drought index bmdi bhalme and mooley 1980 standard precipitation index spi mckee et al 1993 effective drought index edi byun and wilhite 1999 etc have been developed to monitor and quantify meteorological droughts the choice of drought index depends on the perspective and the scope of the problem at hand india is one of the most drought affected countries in the world mishra and singh 2011 and faces drought in almost every three years in different parts of the country goyal et al 2017 about 94 million hectares area of the country is drought prone with more than 300 million people being impacted gupta et al 2011 in previous few decades india experienced prolonged and widespread droughts in different parts of the country and the frequency of droughts has also increased in the recent times may 2002 the drought of 2002 alone resulted in the reduction of the net sown area by 12 million hectares and the consequent reduction in food grain production by 38 million tons which resulted in a 3 2 percent decline in agricultural gdp rathore et al 2014 a major amount of annual rainfall about 70 90 in india occur due to southwest monsoon during the months of june to september a large deficit in monsoon rainfall may lead to drought conditions over india kumar et al 2013 numerous studies can be found in the literature that bring out the analyses of occurrence and distribution of different types of droughts that had occurred in the past in india das et al 2016 jain et al 2015 janga reddy and ganguli 2012 naresh kumar et al 2012 guhathakurta and rajeevan 2008 chowdhury et al 1989 droughts in india are becoming more regional and a spatial shift toward coastal south india central maharashtra and indo gangetic plains have been observed mallya et al 2016 number of wet days during monsoon along the east coast have decreased significantly during monsoon pointing to more intense rainfall events and prolonged dry spells sen roy and balling 2004 upper and middle gangetic plains central and eastern plateau and central and eastern hills have witnessed significantly drying trends during the whole duration of summer in the previous decades jha et al 2013 however global warming and subsequent climate change may further affect the drought vulnerability profile of a country o brien et al 2004 increase in temperature of the order of 0 57 c per 100 years has been observed in india kumar et al 1994 lal and singh 2001 therefore knowledge of probable drought scenarios in the near future could be of immense use for decision makers and planners to formulate appropriate policy framework to minimize the impacts of drought hazard on the overall development of the country climate projections are being used widely for assessing drought conditions for the 21st century on global as well as regional scales strzepek et al 2010 orlowsky and seneviratne 2013 dai 2013 xu et al 2015 wang and chen 2014 masud et al 2017 thilakarathne and sridhar 2017 however the uncertainty associated with climate projections should be kept in view during the examination of future drought scenarios sheffield et al 2012 concluded that the changes in drought climatology in recent years are insignificant however dai 2013 found that droughts are intensifying due to global warming these contrasting results may be attributed to the limitations of the current climate models in capturing the regional rainfall turner and annamalai 2012 lin et al 2015 found drying tendency in south western china in the 21st century which may intensify due to augmented carbon emissions cook et al 1999 argued that the drought risk in the 21st century is going to exceed the driest century of medieval climate anomaly for both moderate and high emission scenarios in southwest and western north america swain and hayhoe 2015 reported that northern regions of north america show consistent trends of wetting and at the same time the south western parts of continent show trends of drying which may further intensify due to increased warming in the indian context very few studies have been reported on the analysis of drought scenarios incorporating climate projections but many studies have been conducted on the spatiotemporal distribution of indian monsoon rainfall with contrasting outcomes some studies have established an increase in the average monsoon precipitation along with an inter annual variability of precipitation chaturvedi et al 2012 fan et al 2012 may 2002 cubasch et al 2001 lal et al 2001 however other studies have established a suppression in monsoon rainfall in future due to weakening of monsoon circulation and reduction in intra seasonal modes ashfaq et al 2009 tanaka et al 2005 ueda et al 2006 the present study is aimed at an investigation of the spatial and temporal projections of droughts for different climate change scenarios over india changes in the trends and periodicities of the severity and frequency of drought over india with climate change is investigated influence of increasing evapotranspiration because of rising trend in temperature due to climate change on the drought dynamics has also been investigated finally the spatial distribution of drought hazard for 21st century is examined 2 data and methodology 2 1 selection of rcms for the future projected precipitation data regional climate models rcm are the physics based higher spatial resolution models which are derived from the gcm models by dynamic downscaling of the gcm data however the selection of gcms impose great uncertainty on the final climatic projection for a particular region knutti and sedláček 2013 chaturvedi et al 2012 found that the gfdl cm3 model is the best among individual models for simulating historical precipitation followed closely by the several other models such as gfdl esm2g gfdl esm2m hadgem2 es hadgem2 ao etc for the asian summer monsoon sperber et al 2013 developed skill metric for 25 cmip5 and 23 cmip3 gcm models and found that top five skill scorers for precipitation are cnrm cm5 ncar ccsm4 noresm1 m gfdl cm3 and gfdl cm2 1 sengupta and rajeevan 2013 analyzed the performance of various gcms using reliability ensemble averaging technique rea and found gfdl cm3 mpi esm lr noresm 1 m lasg fgoals g2 cnrm cm5 among the top five performing model with least bias for precipitation mcsweeney et al 2015 categorized hadgem2 es ccsm4 cnrm cm5 mpi esm lr mpi esm mr gfdl esm2g gfdl esm2m and gfdl cm3 models as satisfactory for the south asian region for simulating the northeast monsoon annual cycles of temperature and precipitation summer monsoon and summer monsoon indices based on the suitability of different gcms corresponding rcm models have been selected for this study for further analysis as shown in table 1 outputs of most of the rcms are generally available at 50 km spatial resolution however the observed data is available at 0 5 degree spatial grid therefore it is necessary to bring all the datasets under the same resolution spatial and temporal for analyzing the historical and future projected precipitation therefore all the model outputs have been converted to the reference 0 5 grid using bilinear interpolation observed precipitation data originally available for 0 25 grid pai et al 2014 have also been aggregated to 0 5 reference grid resolution 2 2 drought indices drought events and their characteristics drought indices di are the numeric indicators which assimilate one or more climatic variables such as precipitation and evapotranspiration into a single numerical value to quantify the drought characteristics various drought indices are available in the literature to quantify droughts however the selection of drought indices depends on their suitability to the local climatic scenario and the goals of a particular study for analysing meteorological droughts palmer drought severity index pdsi standardized precipitation index spi mckee et al 1993 and standardized precipitation evapotranspiration index spei vicente serrano et al 2010 are the most commonly used indices mishra and singh 2011 pdsi was mainly developed for the united states thus it is mainly used in the united states it has little applicability outside the united states kogan 1995 because pdsi does not perform well in the regions where the variability in rainfall extremes is more burke et al 2006 wang et al 2017 spi gained popularity because it is simple to compute and require less data the spi can be estimated at different time scales and therefore it provides flexibility to account for the impact of rainfall deficit of different durations on different water resource components mckee et al 1993 however spi does not take evapotranspiration et into account and therefore it does not consider the true availability of water spei takes advantage of both the pdsi and spi indices it takes advantage of pdsi s sensitivity to the evaporation demand due to temperature fluctuation as well as of that of spi s multi temporal nature in its estimation however spei has been found to show stronger drying as compared to its hydrologic benchmark since it takes et at the potential rate which is less practical joetzjer et al 2013 considering actual evapotranspiration in the estimation of spei shows consistency in drought index with standardized runoff index joetzjer et al 2013 therefore maccioni et al 2014 developed a new standardized effective precipitation evapotranspiration index sp eti which not only considers et but also effective precipitation i e precipitation available for et and losses of water due to runoff and thereby representing the realistic et scenario maccioni et al 2014 in this study three drought indices namely the spi sp eti and spei have been used to investigate the spatio temporal characteristics of droughts in india for the 21st century all these indicators can be assessed on a time scale ranging from 1 month to as long as 48 months thus representing the short term water deficit to multi year storage deficit causing the overall meteorological hydrological and agricultural drought jain et al 2015 livada and assimakopoulos 2007 mckee et al 1993 maccioni et al 2014 longer time scales such as 12 or 24 months identify dry periods of relatively longer durations for analyzing the hydrological impacts of drought on streamflow reservoir levels and groundwater levels vicente serrano 2006 procedure for estimating the spi sp eti and spei are similar the first step is to calculate reference variable x for spi the reference variable is the average monthly precipitation however for spei the reference variable is estimated using the following equation 1 x i p i p e t i where p is the monthly precipitation and pet is the monthly evapotranspiration for the ith month vicente serrano 2006 suggested the estimation of pet using thornthwaite method thornthwaite 1948 due to its simplicity and requirement of only average monthly temperature as input however for sp eti reference variable can be estimated using following equation 2 x i p i e p i where ep is the effective precipitation which can be estimated using the soil conservation service scs formula usda 1970 which is used widely in agricultural water management practices reference variable is cumulatively added for a time window of t months and a resulting series x t is prepared for the indian condition where most of the rainfall is received during the monsoon lasting for four months followed by a nearly dry period of eight months hydrologic regimes in the context of drought analysis would be better assessed using 12 month time scale many studies have also used the 12 month time scale for examining the drought characteristics in india praveen et al 2016 saha et al 2015 shah et al 2015 therefore a 12 month running time series x 12 is used to evaluate the spi sp eti and spei indices next step of drought computation involves identifying the best fit distribution for the reference variable and estimation of parameters of the distribution method of moments mom is the most widely used method for the estimation of parameter of a probability distribution but parameters obtained using the mom have been found to be less accurate than other methods such as maximum likelihood estimation mle method of probability weighted moments pwm and method of l moments mlo mle is also very widely used method due to its invariance properties of sufficiency consistency efficiency and parameterization invariance properties myung 2003 but mle can be trapped with local minima if provided with the wrong initial guess of parameters the parameters estimated using the l moments method provides a robust estimation and are less sensitive to outliers therefore method of l moments is used in this study to identify the best fit distribution with the help of bayesian information criteria bic the identified drought indices for this study are computed for individual grid cells and later used to obtain the regional characteristics using the regionalization analysis distributions with two parameters such as gamma gumbel logistic and normal distributions can be used for the computation of spi since cumulative values of precipitation do not contain negative values and choosing an extra location parameter may truncate the distribution at zero however for the estimation of spei and sp eti indices distributions with location parameter such as the generalized extreme value generalized logistic normal and pearson type 3 distribution have been used since the climatic water balance is not bounded by zero and may take negative values therefore a location parameter is required python lmoments3 library has been employed to identify the best distribution for finding the cumulative probability for selected distribution the parameters obtained from l moments are used to initialize the maximum likelihood optimization using sci package in r further the estimated probabilities have been converted to normally distributed series with zero mean and unit variance using inverse gaussian function farahmand and aghakouchak 2015 for defining various drought characteristics the theory of run yevjevich 1967 is used considering the time series of all drought indices runs approach identifies drought severity duration frequency and interval above the chosen values of thresholds a sequence of consecutive drought indices values below 0 5 is considered as a run each run is denoted as an individual drought event as shown in fig 1 length of the run which is a measure of drought duration is the time between the beginning and the onset of a drought event severity of a drought event is defined based on the cumulative value of spi sp eti or spei series estimated for the drought event 2 3 regionalization of droughts generally regionalization methods are used in hydrology for drought and flood frequency analysis drought is a regional phenomenon and therefore it is appropriate to study the droughts in a regional perspective cluster analysis is a broader term applicable for a range of statistical approaches used to estimate the similarity between various individual objects in a group based on certain characteristics many methods are available for delineating homogeneous regions such as region of influence method burn 1990 entropy based method ridolfi et al 2016 hierarchical clustering fuzzy clustering and k means clustering rao and srinivas 2006a b machine learning algorithms are easy to implement and provide homogeneous results as compared to other traditional methods rao and srinivas 2006a goyal and gupta 2014 therefore in this study k means clustering algorithm is used for identifying the homogeneous drought regions in india k means is a divisive unsupervised learning algorithm developed by macqueen 1967 for classifying the multivariate data eq 3 shows the objective function which k means algorithm attempts to minimize 3 j j 1 k i 1 m y i c j 2 where y i c j 2 is squared euclidean distance between the ith data point and jth cluster centre in multidimensional space of data attributes m is the total number of data points and k is the number of clusters initially the co ordinates of k cluster centres are guessed randomly and each point is assigned to the nearest cluster centre cluster centres are updated by averaging the coordinates in a particular clusters and reassignment is made to obtain new clusters this process is repeated until the convergence is reached since the final result is very sensitive to the initial used cluster centre the algorithm is repeated again and again with different initial random cluster centres for obtaining the best results dalton et al 2009 a priori estimate of the optimum number of clusters is worked out before applying the k means clustering algorithm for getting the well separated compact clusters cluster validity indices such as dunn index dunn 1974 average silhouette width index rousseeuw 1987 and davies and bouldin index davies and bouldin 1979 are generally used to obtain an optimum number of clusters in this study we have used average silhouette width index aswi and davies and bouldin index dbi for validation of clusters details of these indices can be found in goyal and gupta 2014 in this study the drought severity duration and interval along with the latitude and longitude of grid centre are used as characteristics vector to segregate homogeneous clusters in india 2 4 trend analysis trend analysis is a widely used nonparametric method for identifying trends in hydrology and climatology maidment 1992 recommended the use of the mann kendall non parametric test as an excellent tool for the detection of trend in a hydroclimatic time series mann kendall test is a nonparametric test which tests a hypothesis that data comes from independent realization and are identically distributed however this test is only applicable for the data series which is not serially correlated but most of the times hydro climatic data series violate this assumption razavi and vogel 2018 therefore von storch 1999 suggested the prewhitening of the time series to tackle this issue yue and wang 2004 suggested an approach based on ar1 model to remove the serial correlation which is used in this study the mann kendall test while removing serial correlation is commonly known as the modified mann kendall test the sen s slope is generally used for assessing the magnitude of trend based on the median of incremental slopes more details on these tests can be found elsewhere razavi and vogel 2018 gocic and trajkovic 2013 mondal et al 2012 tabari et al 2011 in this study the trend analysis is performed on severity and frequency of droughts at various grid points trends above 95 confidence interval is considered as significant therein 2 5 drought hazard index dhi quantification of drought hazard requires knowledge of drought severity duration frequency and interval of different drought events daneshvar et al 2013 maccioni et al 2014 proposed a comprehensive drought hazard assessment index called the drought hazard index dhi computation of dhi involves meta analysis of drought characteristics of a region derived based on different drought indices such as spi 12 sp eti 12 or spei 12 for the computation of dhi the following four sub indicators are estimated maccioni et al 2014 1 the number of drought events observed in a particular period frq 2 the number of drought events with duration greater than 24 months frq24 3 the maximum observed severity across the observed episodes smax 4 the maximum duration in months across the drought episodes dmax each sub indicator is divided into four classes assigned with relative scores from 1 to 4 by defining certain thresholds thresholds are generally obtained by dividing all the values of a sub indicator for all the spatial points in equal parts then eq 4 is used to compute the dhi 4 dhi w 1 s c o r e d m a x w 2 s c o r e s m a x w 3 s c o r e f r q 24 w 4 s c o r e f r q where w i are the relevant weights which are estimated using an analytical hierarchical process ahp saaty 1977 maccioni et al 2014 in the present study the dhi is computed for the spi 12 sp eti 12 and spei 12 for inter comparison purposes 2 6 periodicity analysis almost all climatic time series possess inherent cycles of different periods cyclicity analysis may provide an insight into the hidden periodicities of the climatological data series various methods have been used to find cyclicity in hydro climatic variables salamalikis et al 2016 pathak et al 2016 yuan et al 2015 zhang et al 2014 wu et al 2013 different approaches of fourier transform also called spectral analysis and wavelet transform analysis are the most widely used techniques for periodicity analysis moreira et al 2015 telesca et al 2013 yadava and ramesh 2007 bordi et al 2004 fourier analysis is generally utilized for extracting regular cyclical component and finding the periodicities in time series fourier analysis comprises of decomposition of a time series as various sinusoidal functions bloomfield 2004 pollock et al 1999 therefore a cyclic time series is written in the form 5 y t j 0 m a j sin ω j t b j sin ω j t t where t is time a j and b j j 0 m are the parameters and t t 1 n are the identically independent random variables with zero mean and unit variance value of m n 2 if n is even and n 1 2 if n is odd and ω j 2 π j n denotes frequency included in the cyclic fluctuation parameters a j and b j can be estimated by using the linear regression more details on estimating the significant peaks of the periodograms are provided by moreira et al 2015 moreira et al 2015 argued that considering drier months for periodicity might reflect the dryness which is insignificant for drought monitoring even though spi 12 of dry month contains the effect of preceding 11 months however on the other hand when we consider the months with significant precipitation spi 12 values reflect a lack of precipitation in the previous months because more than 75 of rainfall occurs during the monsoon months in india therefore in this study all the drought indices have been used for only four monsoon months for detecting the hidden periodicities in the projected drought time series further periodicity generally changes with time and space so the periodicity analysis has been performed for different time periods to calculate the temporal change in periodicities therefore the periodicity analysis has been performed for three different time periods historical period 1951 2005 future period 1 2020 2050 and future period 2 2051 2100 to identify the changes in significant periodicities for these time periods 3 results and discussion 3 1 identification of homogeneous drought regions to identify the homogeneous drought prone regions drought characteristics such as average severity duration and interval for each grid cell have been obtained using the historical gridded rainfall data for the period 1951 to 2005 based on the method of run approach therefore for each grid cell latitude and longitude of grid centre average severity duration and interval are used as the feature vectors for clustering values of dbi and aswi have been examined for identifying the optimum number of clusters urcid and ritter 2012 suggested checking the values of the validity indices for number of clusters varying from 2 to n therefore values of aswi and dbi have been examined by varying the number of clusters from 2 to 35 for 1232 feature vectors lower values of dbi and higher values of aswi corresponds to well separated clusters thus optimum number of clusters are generally taken as the number at which dbi is minimum and aswi is maximum it can be noticed from fig 2 that both dbi and aswi estimates indicate the optimum number of clusters as 2 however considering only two homogeneous regions for the entire india is not justifiable on the physical considerations as indian climate is very diverse and contains at least 6 sub climatic zones bharati et al 2001 moreover considering only two clusters will not serve the purpose of analysing spatial heterogeneity in the droughts therefore for identifying the optimum number of clusters second best values of dbi and aswi have been examined second best value of the aswi is for 9 clusters however it should be noted that the difference between the second and third best values i e 10 clusters is very less which suggests that the separation between clusters is almost similar for 9 and 10 clusters similarly for dbi the second best value is for 11 clusters and the difference between the separation of 10 and 11 clusters is approximately the same therefore it is reasonable to select 10 as optimum number of clusters therefore in this study we considered 10 number of clusters as optimum number spatial analysis of the delineated clusters reveals that only 1 6 and 1 grid points have been classified into cluster 2 cluster 3 and cluster 4 respectively therefore these grid points have been merged with cluster 9 which is the largest cluster in their vicinity as suggested by hosking and wallis 1993 merged final clusters renumbered from 1 to 6 are shown in fig 3 final formed clusters are showing broader resemblance with different climate zones in india and also with precipitation homogeneous regions used by pattanaik 2007 and parthasarathy et al 1996 cluster 1 is mainly mountainous region with most of the area containing cold deserts of jammu and kashmir the annual average historic 1951 2013 precipitation and temperature are 687 mm and 1 c respectively cluster 2 is the tropic wet climatic region which receives a very high average annual rainfall of 3167 mm with an average temperature of 25 6 c cluster 3 which is southern indian region falls under the semi arid and tropical wet and dry climate class the average annual temperature and precipitation for cluster 3 are 868 mm and 26 6 c respectively cluster 4 which consists of humid subtropic climatic region is having an average annual precipitation and temperature values of 1276 mm and 25 6 c cluster 5 is spread over the arid and the semi arid climatic regions of india and receives an annual average rainfall of 704 mm with average temperature being 23 c cluster 6 covers north eastern parts of india which are characterized by humid subtropical climate and receives a high average annual precipitation of 2542 mm with an annual average temperature of 18 4 c 3 2 performance evaluation of rcm models for drought simulation performance of various rcms have been examined using taylor diagram method fig 4 shows the spatial taylor diagram for performance comparison of seven rcms and their ensemble average for the simulation of observed average monthly precipitation and temperature of past data in terms of their pattern correlation root mean square difference rmsd and standard deviation for precipitation simulation spatial pattern correlation varies between 0 415 for rcm5 and 0 682 for rcm2 correlation coefficient for ensemble average is found to be 0 656 however best value of rmsd is found to be 49 75 for the ensemble average followed by the rcm2 with a value of 50 566 further rcm2 is found to have the nearest standard deviation of 64 579 as compared to 62 072 for the observed gridded precipitation so for precipitation simulation rcm2 is found to be outperforming other models followed by ensemble average rcm7 rcm6 and rcm1 etc all rcms simulate better pattern correlation for temperature than that of precipitation rcm1 rcm2 rcm3 and rcm7 have been found to have correlation values in a very close range of 0 887 to 0 897 rcm2 is found to have minimum value of rmsd 5 024 thus representing the best performance compared to other rcms further for temperature simulation rcm2 is also found to have the nearest values of standard deviation as compared to observed since rcm2 performs better than other rcms individually and their ensemble average for simulating precipitation and temperature therefore rcm2 is selected for further analysis for the examination of spatial variability in average precipitation and temperature spatial maps of precipitation and temperature has been prepared as shown in fig 5a a fig 5 b shows the spatial distribution of precipitation and temperature bias for various parts of india it was observed that rcm2 overestimates the precipitation mostly in drier regions of india such as rajasthan parts of maharashtra andhra pradesh telangana karnataka and tamil nadu however it underestimates the precipitation in high precipitation regions such as western ghats and meghalaya in north east of india model consistently underestimates the temperature values throughout india however higher underestimation up to 5 10 c can also be observed for the himalayan region as can be seen from fig 5 b due to high variability of temperature in this region to remove the bias in precipitation and temperature many approaches for bias correction are available in the literature lenderink et al 2007 singh et al 2017 shivam et al 2017 for correcting the bias in data obtained from rcm a linear bias correction lenderink et al 2007 approach has been used for further analysis in this study the time series of cluster averages of bias corrected precipitation and temperature with corresponding cluster averaged observed data has been shown in figs 6a and 6b rcm2 simulates both the precipitation and temperature well for all the clusters except cluster 1 for the case of precipitation low performance of simulated precipitation for cluster 1 may be attributed to very small size of cluster and its mountainous topography further for examining the capability of rcm2 to identify important drought events three drought indicators namely spi spei and sp eti have been estimated for the randomly selected points in each drought homogeneous clusters after correcting the bias in modelled temperature and precipitation the comparison of three drought indicators for the modelled and observed climate in various homogeneous clusters is given in fig 7 as illustration as it can be observed from fig 7 that the rcm2 is able to catch most of the major drought events in each cluster which indicate its capability toward simulating drought in various regions of india annual precipitation temperature and potential evapotranspiration pet have been computed for each of the regions as shown in fig 8 temperature and pet are found to have increasing trend for all the clusters under both the rcps as shown in table 2 precipitation is also projected to have an increasing trend for cluster 1 2 and 3 under both the scenarios however for cluster 4 a significant increasing trend has been projected for only the rcp 8 5 further under the rcp 4 5 projected sen s slope for pet is found be higher than of the precipitation for all the clusters except cluster 2 and 6 for the rcp 8 5 the rate of change of pet is significantly higher than rate of change of precipitation for all except that of cluster 2 for which the rate of increase in precipitation is of very higher order 3 3 trends in severity and frequency of droughts drought characteristics such as the severity and frequency have been estimated for each grid point as described in section 2 5 for the spi sp eti and spei series modified mann kendall and sen s slope test have been performed on the computed series of annual drought severity and frequency at each grid point for the period 1951 to 2100 by dividing total periods in three sub periods historical period hist 1951 2005 near future nf 2021 2050 and far future ff 2071 2100 the results obtained for both the tests are shown in figs 9a 9b and 9c severity values multiplied by 1 have been used to get the positive trends for the increasing drought severity and vice versa average values of the sen s slope for drought severity and frequency are shown in table 3 and the spatial distribution of sen s slope and modified mann kendall tests are shown in figs 9a 9b and 9c for cluster 1 i e jammu and kashmir almost all drought indices project a decreasing trend in severity and frequency under the rcp 4 5 for all three analysed periods however for rcp 8 5 drought severity obtained from the spi shows decreasing trend whereas both the precipitation evapotranspiration based drought indices show an increasing trend in cluster 1 for nf and ff period indicating a significant impact of et on drought occurrence in this region cluster 2 i e western ghats shows a positive average sen s slope of severity and frequency for the historical period as well as for both the future periods under rcp 4 5 however under rcp 8 5 a decline in overall slopes of severity and frequency is projected for nf period which may escalate in the ff period cluster 3 i e the southern indian region shows an increasing trend in drought severity and frequency for historical droughts for all the drought indicators the modified mann kendall and sen s slope tests suggest decreasing trends in severity and frequency for spi under both the concentration pathways during both nf and ff periods however increasing trends in severity and frequency in northern parts of cluster 3 maharashtra telangana and chhattisgarh etc are projected for both the evapotranspiration based drought indices under the rcp 4 5 whereas increasing trends can be observed for almost the whole cluster 3 for the rcp 8 5 for cluster 4 which consists of central and eastern states such as uttarakhand parts of uttar pradesh up chhattisgarh parts of madhya pradesh jharkhand bihar and odisha the average sen s slope values for drought severity and frequency have been found to have an increasing trend which may continue under rcp 4 5 for the near future nf for the west bengal region of this cluster decreasing trends in drought severity and frequency have been observed in the past which are also expected to continue for the rcp 4 5 further for ff under rcp 4 5 drought intensification is expected to take place since drought severity is projected to increase and drought frequency is expected to decrease in this region for cluster 5 both the evapotranspiration based drought indices suggest a likeliness of increasing trends in drought severity and duration under both the rcps for all analysed periods including the historical period it is noteworthy that the average slope values for the ff period are marginally higher for rcp 8 5 than for rcp 4 5 which suggests a significant impact of gh concentration in this region for far future further spi index shows a decreasing trend in drought severity and frequency for the ff period in cluster 5 which may be attributed to the projected increase in monsoon precipitation in ff cluster 6 which consists of north eastern states of india shows decreasing trends in drought severity and frequency for ff for all the drought indicators under the rcp 4 5 projected spi exhibits an average decreasing slope of drought severity and frequency for the rcp 8 5 however other two evapotranspiration based indices indicate a possibility of increasing trend for both the nf and ff periods overall for the historic droughts similar pattern of significant trends have been observed for all the drought indices which suggests increasing trends in drouht severity and frequency over the northen states such as punjab haryana rajasthan and uttar pradesh and over almost all the southern indian states however decreasiging trends have been observed over the jammu and kashmir region west bengal bihar and northeastern states for historic droughts for the rcp 4 5 increasing trends of drought severity and frequency are mostly distributed around the central and western states in the near future nf however for far future ff a spatial southward shift can be seen in increasing trends for the regions strtetching from rajasthan to andhra pradesh including the parts of madhya pradesh maharashtra chattisgarh telangana and odisha drought severity and frequency are expected to increase in ff which can be attributed to the dominance of evapotranspiration on droughts in these regions which is rising due to the increase in temperature under the rcp 8 5 the drought escalating trends are mostly concentrated to western parts of the country in the nf period however for the ff period evapotranspiration is projected to have pronounced effects on droughts since values of spei shows higher magnitude of increasing trends in most parts of the country under the rcp8 5 in ff under the rcp 8 5 droughts are expected to decrease in eastern parts of the country such as odisha chattisgarh and telangana however for the rest of the country droughts are likely to escalate quickly during this period 3 4 analysis of annual minimum spi sp eti and spei temporal variation in regional cluster average values of spi sp eti and spei have been analyzed using annual minimum spi sp eti and spei values obtained from an averaged series estimated by spatially averaging the monthly spi sp eti and spei values for the grids falling in a cluster as shown in fig 10 results of the modified mann kendall trend test of annual minimum spi sp eti and spei are summarized in table 4 it can be observed from figs 10 b and 8 c that the spei indicates lesser drought intensity annual minimum drought index value in the first half of the century for most of the clusters except cluster 2 and 6 however the spi index shows more droughts intensity in the first half of the century than that of the second half of the century difference in drought intensities represented by the drought indicators is higher for the extreme scenario of rcp 8 5 than that of rcp 4 5 higher drought intensities shown by the spi in the first half and spei in the second half suggest that the cause of droughts in the first half of the century is attributed to precipitation deficit however in the second half of the century it is due to the increase in evapotranspiration owing to the rise in temperature further for cluster 2 western ghats and cluster 6 northeast india all the indices show a high correlation with each other and almost similar values throughout the century this can be attributed to a high precipitation in these regions that could probably eclipse the effect of rise in evapotranspiration due to climate change in these regions thus negating the effect of increase in evapotranspiration for drought formation from table 4 it can be observed that for the cluster 1 the annual minimum spei shows a significant decreasing trend under the rcp 8 5 for the nf however no such significant trends could be envisaged for the ff also a decreasing overall trend has been projected for both the et based drought indices which can be attributed to the rate of change of pet being more than the rate of change of precipitation in the nf a negative trend is projected for the cluster 2 under the rcp 8 5 which suggests an increase in the drought intensity however an overall increasing trend of drought indices for the period 2021 2100 is likely possible which indicates a decreasing trend in the drought intensities cluster 3 shows a significant increasing trends in drought intensities under the higher temperature change only drought intensities may decrease for short periods in the nf and ff under the rcp 8 5 however an overall increasing trend can be expected in drought severity since dis show decreasing trends in cluster 3 for cluster 4 the spei and sp eti are found to have an overall negative trend thus representing an increase in droughts over this region cluster 5 which includes mostly drier region of india is expected to experience a decreasing trend in drought intensities for a short term in the nf however for a long term period of 2021 2100 increasing trends in drought intensities can be expected for this region for the cluster 6 no significant trends have been observed for the nf and ff however a decreasing trend of spei is expected under the rcp 8 5 all the indicators have been found to project different drought peaks for different time periods under different rcp scenario but common incidences such as drought peak in 2060 and 2080 can also be noticed further it is important to notice that a sudden fall in the drought indicator values could be observed after the year 2050 for cluster 3 4 and 5 thus indicating a possibility of droughts becoming severe for these clusters 3 5 analysis of the areal extent of drought affected area with time the extent of the drought affected area at a given instance of time for each of the clusters and india as a whole defined as the ratio of the area of the grid cells exhibiting the spi sp eti or spei indices value below 0 5 to the total area of all the grids falling into the region of interest have been computed for the rcp4 5 and rcp8 5 and the same has been plotted as shown in fig 11 the modified mann kendall trend test on the maximum annual drought affected areas has also been performed to identify the statistically significant trends results of trend analysis are presented in table 5 fig 11 also shows the temporal extent of drought affected areas as the percentage of the total area falling in different clusters for rcp4 5 and rcp8 5 as can be seen from fig 11 all the drought indicators show a higher correlation for the time series of annual maximum drought affected areas under the rcp 4 5 than that of the rcp 8 5 which indicate that the temperature change may significantly affect larger areal extent under the rcp 8 5 also the effect of et on the projected droughts is likely to be more dominant especially in clusters 3 4 and 5 under the rcp8 5 during the second half of the 21st century the spei projects a substantial increase in the drought affected area compared to the other two indices for the rcp 8 5 it is interesting to notice that the spi projects larger drought affected area in the first half of the 21st century for almost all the clusters and smaller drought affected areas in the second half of the century as compared to the spei the maximum drought affected area computed using the spi shows decreasing trend at a higher rate for the rcp8 5 than that for the rcp4 5 which indicates that the precipitation based drought affected area may decrease at a higher rate under the extreme greenhouse gas concentration pathway however the drought affected areas computed by the other two drought indices considering the et in the computation show that the widespread droughts are expected under the rcp 8 5 for the second half of the century highlighting the impact of temperature change in the development of droughts in various regions of india the projected extent of the area under severe droughts for the cluster 2 is found to be decreasing for the spi and sp eti under both the rcps whereas for the spei significant increasing trends in the drought affected areas have been found clusters 3 4 and 5 are found to have significantly increasing trends in the maximum annual drought affected area for both the et based drought indicators i e sp eti and spei which can be attributed to the dominance of et over precipitation in these regions 3 6 mapping of spatial variability of drought hazard drought characteristics obtained using the indices spi sp eti and spei under the rcp 4 5 and 8 5 have been further post processed to compute the dhi using eq 4 for the estimation of weights used in eq 4 a value of 1 which represents the equal importance for all the sub indicators has been taken while calculating the eigenvalues and the eigenvectors of the square preferential matrix of analytical hierarchical processing ahp saaty 1977 maccioni et al 2014 also suggested to give equal importance to sub indicators such as frequency duration and magnitude while computing drought hazard index weights of each sub indicator is found to be 0 25 from the ahp analysis fig 12 shows the spatial distribution of drought hazard index for different drought indices and rcps since the sub indicators have been assigned scores varying from 1 to 4 based on the threshold values the dhi values also vary between 1 and 4 where 1 represents a least drought hazard and 4 represents a highest drought hazard threshold values for all sub indicators are obtained by equally dividing the number of events in all the drought events generated by all the indicators under all the scenario for better comparability among the drought indices and rcps it is interesting to notice from fig 12 that the spei projects the highest drought hazard as compared to the other two drought indicators which suggests that considering evapotranspiration at potential rate results in projection of more drying leading to more projected drought risk further the spatial variability of the dhi values for all the drought indices estimated for the historical period are found to be smaller as compared to the dhi estimated for the future under both the rcps as it can be observed from table 6 that for each of the clusters all the drought indices estimate similar values of hazard for the historical period which suggests that for the historical period considered in this study a rise in temperature if any has not altered the evapo transpiration in a significant way to influence the drought characteristics estimated using the et based drought indicators spei and sp eti however during the future time periods the dominance of evapotranspiration can be observed from the fact that cluster averages of the dhi for spei are marginally higher than the other two drought indices the estimate of spi projects lesser drought hazard for all the clusters except for clusters 4 and 6 which implies that a higher emission concentration may decrease the precipitation based drought hazard however both precipitation and evapotranspiration based indices show an escalated drought hazard for the rcp 8 5 the spatial distribution of dhi indicates the likelihood of severe drought hazard in central india for the rcp 4 5 which is likely to escalate with an increase in the evapotranspiration however for the rcp 8 5 the area with severe drought hazard is likely to increase and a shift towards south eastern states is also expected 3 7 periodicity of droughts periodicity analysis of droughts for the monsoon months has been carried out using the fourier analysis significant periodicities which are above 90 confidence interval have only been considered periodograms of spi sp eti and spei series have been calculated for examining the hidden cycles of drought in different clusters for all the four monsoon months for each grid point across all over india for analysing the change in periodicity over time three time periods historic 1951 2005 future period 1 2020 to 2050 and future period 2 2051 to 2100 have been used fig 13 summarizes the results of significant peaks of the periodograms averaged over four months for different clusters and as well as for the whole india it is inferred from this figure that in general the percentage of area for all the significant peaks and for all the clusters and time periods exhibits almost similar values implying least impact of climate change on the periodic cycles of drought in india periodicities of the order of 2 years to 3 6 years dominate in more than 30 percent area of the clusters and as well as for the whole country moreover inter annual cycles of 5 10 years also show a relatively higher percentage of the area across all the clusters another interesting point which could be observed from fig 13 is that the percentage of area under significant peaks have almost similar value for all the clusters which imply that the significant periodicities would spread uniformly across all the regions of india further in future both the rcps shows almost similar values of periodicity which suggests that the impact of climate change on the periodicity will be insignificant 3 8 discussion close scrutiny of the results presented above indicates that the cerfacs cnrm cm5 iitm regcm4 performs better than other individual models and that of the ensemble average in simulating the past observed precipitation and temperature also selected rcm model is found to capture the drought trends in various regions of india satisfactorily for most of the clusters the rate of increase of the potential evapotranspiration pet is expected to be higher than the rate of increase in precipitation however the magnitude of increase in precipitation is much higher than the evapotranspiration in clusters 2 and 6 and therefore the change in evapotranspiration does not affect the drought dynamics which makes it inefficient for causing drought in these regions furthermore trend analysis reveals that the historical increasing severity trend are concentrated over northcentral and southcentral regions of india which may continue to remain same in near future for rcp 4 5 however a westward shift may be expected for higher ghg concentration a decreasing trend in the severity and frequency under rcp 8 5 is likely in eastern states such as odisha and chhattisgarh in the far future the results of analysis of annual maximum drought affected area reveals the dominance of the evapotranspiration in forming the droughts in clusters 3 4 and 5 which spreads over most parts of the country moreover rcp 8 5 may cause more risk over most parts of india since the drought hazard projected using this rcp is significantly higher than that of the rcp 4 5 findings of drought periodicity analysis reveal the presence of dominant drought cycles of 2 3 6 years during the 1st half as well as the 2nd half of the 21st century indicating insignificant impact of climate change on drought periodicity past studies suggest that droughts are having positive trends of intensity frequency and severity owing to declining trends in precipitation mallya et al 2016 naresh kumar et al 2012 jain and kumar 2012 which also validates the findings of this study however studies based on analysis of future projected cmip5 multi model data suggest that the indian monsoon precipitation may increase in the 21st century due to the favourable relationship between warming and the amount of indian summer monsoon turner and annamalai 2012 also it is expected that the increase in precipitation for rcp 8 5 would be greater than lower emission rcps menon et al 2013 kundu et al 2014 chaturvedi et al 2012 freychet et al 2015 this corroborates favourably with findings such as existence of positive correlation between the indian summer monsoon for most of the clusters and global warming fu et al 1999 increase in the seasonal precipitation due to changes in inter tropical convergence zone hu et al 2000 and warming of the sea surface combined with the amplified vapour holding capacity would lead to more water vapour content in the atmosphere resulting in enhanced precipitation in the tropics trenberth 1998 meehl et al 2005 alam et al 2017 used the spei and found an increment in the probability of occurrence of drought in the six different ecological regions of india furthermore nath et al 2017 found a consistent increase in the precipitation and evapotranspiration however the increase in pet for a higher emission scenario will be much higher than the projected increase in the precipitation for the 21st century the mitigating effect of the increased precipitation on drought in rcp 4 5 will be overridden by the intensification in pet nath et al 2017 it is important to notice that the drought intensification in the past over india was driven by the decreasing trend in precipitation however in the future the drought intensification would be driven by the escalation of evapotranspiration this study establishes a clear link between the alteration in precipitation and temperature and changes in the drought characteristics for different regions of india for various carbon emission scenarios findings of this study also underscore the need to choose drought index carefully for drought characterisation under the climate change scenario because the rise in temperature has different effects on precipitation as well as on evapotranspiration which may result in different drought scenarios special care should be exercised in interpreting the results obtained based on the spei when the rise in temperature of higher order have been predicted due to global warming as it may project extreme drought scenario due to the assumption of et to take place at the potential rate therefore drought indices which consider the realistic representation of increase in the et should be preferred the findings of our study are in conformity with the previous studies referred above because the projected increase in the amount of precipitation may lead to reduced drought risk however an increase in the evapotranspiration due to the projected increase in temperature is likely to surpass projected increase in precipitation over most parts of the country that may result in increased drought risk the periodicity analysis indicates inter annual periodicities influencing monsoon months to be distributed uniformly across all clusters of the indian subcontinent with an average cycle of 2 3 6 years dominating the country inter annual periodicities of short and long durations such as 2 4 years and 4 8 years may be correlated with quasi biennial oscillation qbo and el niño southern oscillation enso phenomenon adarsh and janga reddy 2015 kumar et al 2013 gadgil et al 2007 because qbo and enso affects the indian summer monsoon rainfall kumar et al 2013 however long term inter decadal periodicities may be correlated to pacific decadal oscillation pdo and atlantic multidecadal oscillation joshi and kucharski 2017 kripalani et al 2003 found enso phenomenon to be negatively correlated with indian summer monsoon rainfall moreover kumar et al 2013 suggested that enso plays an important role in causing monsoon drought in the indian region results of this study may have serious implications on the policy making and water resource planning and management of india the results suggest an increment in drought affected area especially in clusters 3 4 and 5 where the population is much higher than in the other clusters according to the un population projection 2017 the total population of india may increase up to 1 8 billion by the year 2050 and to 2 billion by the year 2100 increase in the population will increase the stress on the resources of water and food further as previously reported by jülich 2011 drought trigger migration has been taking place from eastern villages of the country to the south indian cities the drought triggered migration may intensify in future the agricultural gdp has reduced from 39 in 1983 to 14 in 2014 goi 2016 reduced agricultural area and increased population along with the severe droughts in the regions where most people live may pose serious risk to food security in india out of 33 23 of installed renewable power generation hydropower contributes toward almost 13 17 of total installed capacity hydropower plants installed in clusters 3 and 4 alone contributes around 32 of total hydropower reduction in the water availability in reservoirs due to longer and severe droughts in these regions may drastically reduce the amount of hydropower generation therefore enhanced preparedness is needed in the light of these results to alleviate the drought risk in these regions in the future policies should be framed while considering regional vulnerabilities and projected hazard further it is important to mention various uncertainties which are inherent in almost all studies based on the projected future climatic scenarios and the same are also involved in the presented analysis as well uncertainty related to gcm simulation such as uncertainty in simulating large scale atmospheric circulation inter gcm projection uncertainty emission scenario uncertainty and downscaling model uncertainty may lead to lesser confidence in the obtained drought results spatial resolution and choice of drought indices and its scale may also affect the drought projections however in the future a better understanding of hydrological cycle may lead to better and less uncertain projections thus leading to better future climatic predictions that may reduce uncertainty in drought analysis 4 conclusions spatiotemporal analysis of likely occurrence and distribution of droughts was performed over india using 81 years 2021 2100 of projected precipitation and temperature data obtained from cerfacs cnrm cm5 iitm regcm4 rcm for two rcp scenarios rcp 4 5 and rcp 8 5 and historical observed data 1951 2005 obtained from the imd in gridded form respectively temporal trends of drought severity and frequency were also analyzed drought hazard maps were prepared using the drought hazard index dhi periodicity analysis was also carried out using fourier transform to find the hidden periodicities in spi sp eti and spei series of monsoon months results of regionalization in india suggest the presence of 6 distinct homogeneous drought regions in india precipitation temperature and pet are found to be increasing in the 21st century for almost all the clusters analysis of projected scenarios of drought based on multiple indices for 21st century reveals that global warming may have severe impact on the drought scenario in india analysis of results indicates that the spi projects least drought risk in the far future due to increasing precipitation a significant correlation between all studied drought indicators have been found for historical period however for future et based drought indices such as sp eti and spei shows a more intense drought especially in the later part of the 21st century interestingly comparison of results obtained using different drought indices for various climate change scenarios underscore the importance of considering rise in evapotranspiration due to increase in temperature in drought characterisation failure to do so may result in the introduction of uncertainty in the end results however special care should be exercised in interpreting results obtained based on spei when the rise in temperature of higher order have been projected due to global warming because it may predict extreme drought scenario due to the assumption of et to take place at potential rate therefore drought indices which consider the realistic representation of increase in et should be preferred therefore for drought characteristics investigation under the climate change this study clearly recommends to use the multiple et based drought indices to arrive at the final conclusion results of trend analysis suggest that northern and north western india may face increasing trends in severity and frequency of drought in the near future nf however in the far future ff most parts of the india are expected to face increasing severity and frequency of drought except south eastern regions such as odisha chhattisgarh and parts of maharashtra madhya pradesh and telangana these increasing trends relies solely on increase in et values in these regions analysis of drought hazard index dhi reveals a shift in drought hazard from central india towards southeast central india with an increase in ghg concentration considering all the drought indices impact of increase in evapotranspiration would be more pronounced on the occurrence of drought in cluster 3 southern india cluster 4 central and southeast region and cluster 5 north western and western india because in these clusters both the et based drought indices show a larger areal extent under drought for these regions in the far future further for these regions average drought hazard index has also been found to be larger than other regions interannual significant periodicities of 2 3 6 years are likely to be distributed uniformly across all clusters of drought regions of india during the 21st century moreover change in drought periodicity due to climate change in most of the regions has been found to be insignificant acknowledgements this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors however authors are very thankful to indian institute of technology roorkee india for providing the necessary resources to conduct this research and ministry of human resources govt of india for supporting first author through senior research fellowship 
6903,projected droughts for 21st century over india have been analysed using precipitation and temperature data obtained from regional climate models rcms under representative concentration pathways rcps 4 5 and 8 5 standardized precipitation index spi standardized effective precipitation evapo transpiration index sp eti and standardized precipitation evapotranspiration index spei at the timescale of 12 months have been used for drought characterization the k means clustering algorithm has been utilized to delineate distinct drought homogeneous regions in india trends and periodicities in drought characteristics have also been analysed the results of this study reveal that increase in evapotranspiration due to projected rise in temperature would play a major role in affecting future drought dynamics in most parts of india analysis indicates that computed magnitude of drought intensity duration and frequency depends on the choice of drought indicator spei drought index has been found to project highest drought risk as compared to other two indices used in this study north india is more vulnerable to increase in drought severity and frequency in near future however in far future most parts of the country except few southeastern states are likely to face an escalation in drought severity and frequency a shift in drought hazard from central india toward southeast central india is likely to happen with increase in greenhouse gas ghg concentration the areal extent of droughts has been found to be increasing historically which is expected to increase further in future for most parts of the country historically drought dynamics were more influenced by decrease in precipitation however in future the drought dynamics will be significantly influenced by increased evapotranspiration resulting from increase in temperature in spite of likely increase in precipitation the periodicity analysis indicates inter annual periodicities influencing monsoon months to be distributed uniformly across all clusters of the indian subcontinent with dominant cycles of 2 3 6 years further change in periodic cycles of drought due to climate change is found to be insignificant keywords droughts climate change k means clustering spatiotemporal analysis fourier periodicity analysis 1 introduction drought is one of the costliest and widespread long term persistent natural phenomena that may last for weeks months years or even decades xu et al 2015 more than one million lives have been lost globally since 1974 due to droughts un 2008 therefore systematic information about likely occurrence and distribution of droughts may assist in preparedness and mitigation against drought disasters lloyd hughes 2012 the preparedness and planning to cope with adverse impacts of a drought event depend on the information about its areal extent severity and duration this information could be obtained through drought monitoring using various drought indices that provide quantitative information to the decision makers about drought characteristics dogan et al 2012 a variety of meteorological drought indicators such as palmer drought severity index pdsi palmer 1965 rainfall decile based drought index rddi gibbs and maher 1967 bhalme and mooly drought index bmdi bhalme and mooley 1980 standard precipitation index spi mckee et al 1993 effective drought index edi byun and wilhite 1999 etc have been developed to monitor and quantify meteorological droughts the choice of drought index depends on the perspective and the scope of the problem at hand india is one of the most drought affected countries in the world mishra and singh 2011 and faces drought in almost every three years in different parts of the country goyal et al 2017 about 94 million hectares area of the country is drought prone with more than 300 million people being impacted gupta et al 2011 in previous few decades india experienced prolonged and widespread droughts in different parts of the country and the frequency of droughts has also increased in the recent times may 2002 the drought of 2002 alone resulted in the reduction of the net sown area by 12 million hectares and the consequent reduction in food grain production by 38 million tons which resulted in a 3 2 percent decline in agricultural gdp rathore et al 2014 a major amount of annual rainfall about 70 90 in india occur due to southwest monsoon during the months of june to september a large deficit in monsoon rainfall may lead to drought conditions over india kumar et al 2013 numerous studies can be found in the literature that bring out the analyses of occurrence and distribution of different types of droughts that had occurred in the past in india das et al 2016 jain et al 2015 janga reddy and ganguli 2012 naresh kumar et al 2012 guhathakurta and rajeevan 2008 chowdhury et al 1989 droughts in india are becoming more regional and a spatial shift toward coastal south india central maharashtra and indo gangetic plains have been observed mallya et al 2016 number of wet days during monsoon along the east coast have decreased significantly during monsoon pointing to more intense rainfall events and prolonged dry spells sen roy and balling 2004 upper and middle gangetic plains central and eastern plateau and central and eastern hills have witnessed significantly drying trends during the whole duration of summer in the previous decades jha et al 2013 however global warming and subsequent climate change may further affect the drought vulnerability profile of a country o brien et al 2004 increase in temperature of the order of 0 57 c per 100 years has been observed in india kumar et al 1994 lal and singh 2001 therefore knowledge of probable drought scenarios in the near future could be of immense use for decision makers and planners to formulate appropriate policy framework to minimize the impacts of drought hazard on the overall development of the country climate projections are being used widely for assessing drought conditions for the 21st century on global as well as regional scales strzepek et al 2010 orlowsky and seneviratne 2013 dai 2013 xu et al 2015 wang and chen 2014 masud et al 2017 thilakarathne and sridhar 2017 however the uncertainty associated with climate projections should be kept in view during the examination of future drought scenarios sheffield et al 2012 concluded that the changes in drought climatology in recent years are insignificant however dai 2013 found that droughts are intensifying due to global warming these contrasting results may be attributed to the limitations of the current climate models in capturing the regional rainfall turner and annamalai 2012 lin et al 2015 found drying tendency in south western china in the 21st century which may intensify due to augmented carbon emissions cook et al 1999 argued that the drought risk in the 21st century is going to exceed the driest century of medieval climate anomaly for both moderate and high emission scenarios in southwest and western north america swain and hayhoe 2015 reported that northern regions of north america show consistent trends of wetting and at the same time the south western parts of continent show trends of drying which may further intensify due to increased warming in the indian context very few studies have been reported on the analysis of drought scenarios incorporating climate projections but many studies have been conducted on the spatiotemporal distribution of indian monsoon rainfall with contrasting outcomes some studies have established an increase in the average monsoon precipitation along with an inter annual variability of precipitation chaturvedi et al 2012 fan et al 2012 may 2002 cubasch et al 2001 lal et al 2001 however other studies have established a suppression in monsoon rainfall in future due to weakening of monsoon circulation and reduction in intra seasonal modes ashfaq et al 2009 tanaka et al 2005 ueda et al 2006 the present study is aimed at an investigation of the spatial and temporal projections of droughts for different climate change scenarios over india changes in the trends and periodicities of the severity and frequency of drought over india with climate change is investigated influence of increasing evapotranspiration because of rising trend in temperature due to climate change on the drought dynamics has also been investigated finally the spatial distribution of drought hazard for 21st century is examined 2 data and methodology 2 1 selection of rcms for the future projected precipitation data regional climate models rcm are the physics based higher spatial resolution models which are derived from the gcm models by dynamic downscaling of the gcm data however the selection of gcms impose great uncertainty on the final climatic projection for a particular region knutti and sedláček 2013 chaturvedi et al 2012 found that the gfdl cm3 model is the best among individual models for simulating historical precipitation followed closely by the several other models such as gfdl esm2g gfdl esm2m hadgem2 es hadgem2 ao etc for the asian summer monsoon sperber et al 2013 developed skill metric for 25 cmip5 and 23 cmip3 gcm models and found that top five skill scorers for precipitation are cnrm cm5 ncar ccsm4 noresm1 m gfdl cm3 and gfdl cm2 1 sengupta and rajeevan 2013 analyzed the performance of various gcms using reliability ensemble averaging technique rea and found gfdl cm3 mpi esm lr noresm 1 m lasg fgoals g2 cnrm cm5 among the top five performing model with least bias for precipitation mcsweeney et al 2015 categorized hadgem2 es ccsm4 cnrm cm5 mpi esm lr mpi esm mr gfdl esm2g gfdl esm2m and gfdl cm3 models as satisfactory for the south asian region for simulating the northeast monsoon annual cycles of temperature and precipitation summer monsoon and summer monsoon indices based on the suitability of different gcms corresponding rcm models have been selected for this study for further analysis as shown in table 1 outputs of most of the rcms are generally available at 50 km spatial resolution however the observed data is available at 0 5 degree spatial grid therefore it is necessary to bring all the datasets under the same resolution spatial and temporal for analyzing the historical and future projected precipitation therefore all the model outputs have been converted to the reference 0 5 grid using bilinear interpolation observed precipitation data originally available for 0 25 grid pai et al 2014 have also been aggregated to 0 5 reference grid resolution 2 2 drought indices drought events and their characteristics drought indices di are the numeric indicators which assimilate one or more climatic variables such as precipitation and evapotranspiration into a single numerical value to quantify the drought characteristics various drought indices are available in the literature to quantify droughts however the selection of drought indices depends on their suitability to the local climatic scenario and the goals of a particular study for analysing meteorological droughts palmer drought severity index pdsi standardized precipitation index spi mckee et al 1993 and standardized precipitation evapotranspiration index spei vicente serrano et al 2010 are the most commonly used indices mishra and singh 2011 pdsi was mainly developed for the united states thus it is mainly used in the united states it has little applicability outside the united states kogan 1995 because pdsi does not perform well in the regions where the variability in rainfall extremes is more burke et al 2006 wang et al 2017 spi gained popularity because it is simple to compute and require less data the spi can be estimated at different time scales and therefore it provides flexibility to account for the impact of rainfall deficit of different durations on different water resource components mckee et al 1993 however spi does not take evapotranspiration et into account and therefore it does not consider the true availability of water spei takes advantage of both the pdsi and spi indices it takes advantage of pdsi s sensitivity to the evaporation demand due to temperature fluctuation as well as of that of spi s multi temporal nature in its estimation however spei has been found to show stronger drying as compared to its hydrologic benchmark since it takes et at the potential rate which is less practical joetzjer et al 2013 considering actual evapotranspiration in the estimation of spei shows consistency in drought index with standardized runoff index joetzjer et al 2013 therefore maccioni et al 2014 developed a new standardized effective precipitation evapotranspiration index sp eti which not only considers et but also effective precipitation i e precipitation available for et and losses of water due to runoff and thereby representing the realistic et scenario maccioni et al 2014 in this study three drought indices namely the spi sp eti and spei have been used to investigate the spatio temporal characteristics of droughts in india for the 21st century all these indicators can be assessed on a time scale ranging from 1 month to as long as 48 months thus representing the short term water deficit to multi year storage deficit causing the overall meteorological hydrological and agricultural drought jain et al 2015 livada and assimakopoulos 2007 mckee et al 1993 maccioni et al 2014 longer time scales such as 12 or 24 months identify dry periods of relatively longer durations for analyzing the hydrological impacts of drought on streamflow reservoir levels and groundwater levels vicente serrano 2006 procedure for estimating the spi sp eti and spei are similar the first step is to calculate reference variable x for spi the reference variable is the average monthly precipitation however for spei the reference variable is estimated using the following equation 1 x i p i p e t i where p is the monthly precipitation and pet is the monthly evapotranspiration for the ith month vicente serrano 2006 suggested the estimation of pet using thornthwaite method thornthwaite 1948 due to its simplicity and requirement of only average monthly temperature as input however for sp eti reference variable can be estimated using following equation 2 x i p i e p i where ep is the effective precipitation which can be estimated using the soil conservation service scs formula usda 1970 which is used widely in agricultural water management practices reference variable is cumulatively added for a time window of t months and a resulting series x t is prepared for the indian condition where most of the rainfall is received during the monsoon lasting for four months followed by a nearly dry period of eight months hydrologic regimes in the context of drought analysis would be better assessed using 12 month time scale many studies have also used the 12 month time scale for examining the drought characteristics in india praveen et al 2016 saha et al 2015 shah et al 2015 therefore a 12 month running time series x 12 is used to evaluate the spi sp eti and spei indices next step of drought computation involves identifying the best fit distribution for the reference variable and estimation of parameters of the distribution method of moments mom is the most widely used method for the estimation of parameter of a probability distribution but parameters obtained using the mom have been found to be less accurate than other methods such as maximum likelihood estimation mle method of probability weighted moments pwm and method of l moments mlo mle is also very widely used method due to its invariance properties of sufficiency consistency efficiency and parameterization invariance properties myung 2003 but mle can be trapped with local minima if provided with the wrong initial guess of parameters the parameters estimated using the l moments method provides a robust estimation and are less sensitive to outliers therefore method of l moments is used in this study to identify the best fit distribution with the help of bayesian information criteria bic the identified drought indices for this study are computed for individual grid cells and later used to obtain the regional characteristics using the regionalization analysis distributions with two parameters such as gamma gumbel logistic and normal distributions can be used for the computation of spi since cumulative values of precipitation do not contain negative values and choosing an extra location parameter may truncate the distribution at zero however for the estimation of spei and sp eti indices distributions with location parameter such as the generalized extreme value generalized logistic normal and pearson type 3 distribution have been used since the climatic water balance is not bounded by zero and may take negative values therefore a location parameter is required python lmoments3 library has been employed to identify the best distribution for finding the cumulative probability for selected distribution the parameters obtained from l moments are used to initialize the maximum likelihood optimization using sci package in r further the estimated probabilities have been converted to normally distributed series with zero mean and unit variance using inverse gaussian function farahmand and aghakouchak 2015 for defining various drought characteristics the theory of run yevjevich 1967 is used considering the time series of all drought indices runs approach identifies drought severity duration frequency and interval above the chosen values of thresholds a sequence of consecutive drought indices values below 0 5 is considered as a run each run is denoted as an individual drought event as shown in fig 1 length of the run which is a measure of drought duration is the time between the beginning and the onset of a drought event severity of a drought event is defined based on the cumulative value of spi sp eti or spei series estimated for the drought event 2 3 regionalization of droughts generally regionalization methods are used in hydrology for drought and flood frequency analysis drought is a regional phenomenon and therefore it is appropriate to study the droughts in a regional perspective cluster analysis is a broader term applicable for a range of statistical approaches used to estimate the similarity between various individual objects in a group based on certain characteristics many methods are available for delineating homogeneous regions such as region of influence method burn 1990 entropy based method ridolfi et al 2016 hierarchical clustering fuzzy clustering and k means clustering rao and srinivas 2006a b machine learning algorithms are easy to implement and provide homogeneous results as compared to other traditional methods rao and srinivas 2006a goyal and gupta 2014 therefore in this study k means clustering algorithm is used for identifying the homogeneous drought regions in india k means is a divisive unsupervised learning algorithm developed by macqueen 1967 for classifying the multivariate data eq 3 shows the objective function which k means algorithm attempts to minimize 3 j j 1 k i 1 m y i c j 2 where y i c j 2 is squared euclidean distance between the ith data point and jth cluster centre in multidimensional space of data attributes m is the total number of data points and k is the number of clusters initially the co ordinates of k cluster centres are guessed randomly and each point is assigned to the nearest cluster centre cluster centres are updated by averaging the coordinates in a particular clusters and reassignment is made to obtain new clusters this process is repeated until the convergence is reached since the final result is very sensitive to the initial used cluster centre the algorithm is repeated again and again with different initial random cluster centres for obtaining the best results dalton et al 2009 a priori estimate of the optimum number of clusters is worked out before applying the k means clustering algorithm for getting the well separated compact clusters cluster validity indices such as dunn index dunn 1974 average silhouette width index rousseeuw 1987 and davies and bouldin index davies and bouldin 1979 are generally used to obtain an optimum number of clusters in this study we have used average silhouette width index aswi and davies and bouldin index dbi for validation of clusters details of these indices can be found in goyal and gupta 2014 in this study the drought severity duration and interval along with the latitude and longitude of grid centre are used as characteristics vector to segregate homogeneous clusters in india 2 4 trend analysis trend analysis is a widely used nonparametric method for identifying trends in hydrology and climatology maidment 1992 recommended the use of the mann kendall non parametric test as an excellent tool for the detection of trend in a hydroclimatic time series mann kendall test is a nonparametric test which tests a hypothesis that data comes from independent realization and are identically distributed however this test is only applicable for the data series which is not serially correlated but most of the times hydro climatic data series violate this assumption razavi and vogel 2018 therefore von storch 1999 suggested the prewhitening of the time series to tackle this issue yue and wang 2004 suggested an approach based on ar1 model to remove the serial correlation which is used in this study the mann kendall test while removing serial correlation is commonly known as the modified mann kendall test the sen s slope is generally used for assessing the magnitude of trend based on the median of incremental slopes more details on these tests can be found elsewhere razavi and vogel 2018 gocic and trajkovic 2013 mondal et al 2012 tabari et al 2011 in this study the trend analysis is performed on severity and frequency of droughts at various grid points trends above 95 confidence interval is considered as significant therein 2 5 drought hazard index dhi quantification of drought hazard requires knowledge of drought severity duration frequency and interval of different drought events daneshvar et al 2013 maccioni et al 2014 proposed a comprehensive drought hazard assessment index called the drought hazard index dhi computation of dhi involves meta analysis of drought characteristics of a region derived based on different drought indices such as spi 12 sp eti 12 or spei 12 for the computation of dhi the following four sub indicators are estimated maccioni et al 2014 1 the number of drought events observed in a particular period frq 2 the number of drought events with duration greater than 24 months frq24 3 the maximum observed severity across the observed episodes smax 4 the maximum duration in months across the drought episodes dmax each sub indicator is divided into four classes assigned with relative scores from 1 to 4 by defining certain thresholds thresholds are generally obtained by dividing all the values of a sub indicator for all the spatial points in equal parts then eq 4 is used to compute the dhi 4 dhi w 1 s c o r e d m a x w 2 s c o r e s m a x w 3 s c o r e f r q 24 w 4 s c o r e f r q where w i are the relevant weights which are estimated using an analytical hierarchical process ahp saaty 1977 maccioni et al 2014 in the present study the dhi is computed for the spi 12 sp eti 12 and spei 12 for inter comparison purposes 2 6 periodicity analysis almost all climatic time series possess inherent cycles of different periods cyclicity analysis may provide an insight into the hidden periodicities of the climatological data series various methods have been used to find cyclicity in hydro climatic variables salamalikis et al 2016 pathak et al 2016 yuan et al 2015 zhang et al 2014 wu et al 2013 different approaches of fourier transform also called spectral analysis and wavelet transform analysis are the most widely used techniques for periodicity analysis moreira et al 2015 telesca et al 2013 yadava and ramesh 2007 bordi et al 2004 fourier analysis is generally utilized for extracting regular cyclical component and finding the periodicities in time series fourier analysis comprises of decomposition of a time series as various sinusoidal functions bloomfield 2004 pollock et al 1999 therefore a cyclic time series is written in the form 5 y t j 0 m a j sin ω j t b j sin ω j t t where t is time a j and b j j 0 m are the parameters and t t 1 n are the identically independent random variables with zero mean and unit variance value of m n 2 if n is even and n 1 2 if n is odd and ω j 2 π j n denotes frequency included in the cyclic fluctuation parameters a j and b j can be estimated by using the linear regression more details on estimating the significant peaks of the periodograms are provided by moreira et al 2015 moreira et al 2015 argued that considering drier months for periodicity might reflect the dryness which is insignificant for drought monitoring even though spi 12 of dry month contains the effect of preceding 11 months however on the other hand when we consider the months with significant precipitation spi 12 values reflect a lack of precipitation in the previous months because more than 75 of rainfall occurs during the monsoon months in india therefore in this study all the drought indices have been used for only four monsoon months for detecting the hidden periodicities in the projected drought time series further periodicity generally changes with time and space so the periodicity analysis has been performed for different time periods to calculate the temporal change in periodicities therefore the periodicity analysis has been performed for three different time periods historical period 1951 2005 future period 1 2020 2050 and future period 2 2051 2100 to identify the changes in significant periodicities for these time periods 3 results and discussion 3 1 identification of homogeneous drought regions to identify the homogeneous drought prone regions drought characteristics such as average severity duration and interval for each grid cell have been obtained using the historical gridded rainfall data for the period 1951 to 2005 based on the method of run approach therefore for each grid cell latitude and longitude of grid centre average severity duration and interval are used as the feature vectors for clustering values of dbi and aswi have been examined for identifying the optimum number of clusters urcid and ritter 2012 suggested checking the values of the validity indices for number of clusters varying from 2 to n therefore values of aswi and dbi have been examined by varying the number of clusters from 2 to 35 for 1232 feature vectors lower values of dbi and higher values of aswi corresponds to well separated clusters thus optimum number of clusters are generally taken as the number at which dbi is minimum and aswi is maximum it can be noticed from fig 2 that both dbi and aswi estimates indicate the optimum number of clusters as 2 however considering only two homogeneous regions for the entire india is not justifiable on the physical considerations as indian climate is very diverse and contains at least 6 sub climatic zones bharati et al 2001 moreover considering only two clusters will not serve the purpose of analysing spatial heterogeneity in the droughts therefore for identifying the optimum number of clusters second best values of dbi and aswi have been examined second best value of the aswi is for 9 clusters however it should be noted that the difference between the second and third best values i e 10 clusters is very less which suggests that the separation between clusters is almost similar for 9 and 10 clusters similarly for dbi the second best value is for 11 clusters and the difference between the separation of 10 and 11 clusters is approximately the same therefore it is reasonable to select 10 as optimum number of clusters therefore in this study we considered 10 number of clusters as optimum number spatial analysis of the delineated clusters reveals that only 1 6 and 1 grid points have been classified into cluster 2 cluster 3 and cluster 4 respectively therefore these grid points have been merged with cluster 9 which is the largest cluster in their vicinity as suggested by hosking and wallis 1993 merged final clusters renumbered from 1 to 6 are shown in fig 3 final formed clusters are showing broader resemblance with different climate zones in india and also with precipitation homogeneous regions used by pattanaik 2007 and parthasarathy et al 1996 cluster 1 is mainly mountainous region with most of the area containing cold deserts of jammu and kashmir the annual average historic 1951 2013 precipitation and temperature are 687 mm and 1 c respectively cluster 2 is the tropic wet climatic region which receives a very high average annual rainfall of 3167 mm with an average temperature of 25 6 c cluster 3 which is southern indian region falls under the semi arid and tropical wet and dry climate class the average annual temperature and precipitation for cluster 3 are 868 mm and 26 6 c respectively cluster 4 which consists of humid subtropic climatic region is having an average annual precipitation and temperature values of 1276 mm and 25 6 c cluster 5 is spread over the arid and the semi arid climatic regions of india and receives an annual average rainfall of 704 mm with average temperature being 23 c cluster 6 covers north eastern parts of india which are characterized by humid subtropical climate and receives a high average annual precipitation of 2542 mm with an annual average temperature of 18 4 c 3 2 performance evaluation of rcm models for drought simulation performance of various rcms have been examined using taylor diagram method fig 4 shows the spatial taylor diagram for performance comparison of seven rcms and their ensemble average for the simulation of observed average monthly precipitation and temperature of past data in terms of their pattern correlation root mean square difference rmsd and standard deviation for precipitation simulation spatial pattern correlation varies between 0 415 for rcm5 and 0 682 for rcm2 correlation coefficient for ensemble average is found to be 0 656 however best value of rmsd is found to be 49 75 for the ensemble average followed by the rcm2 with a value of 50 566 further rcm2 is found to have the nearest standard deviation of 64 579 as compared to 62 072 for the observed gridded precipitation so for precipitation simulation rcm2 is found to be outperforming other models followed by ensemble average rcm7 rcm6 and rcm1 etc all rcms simulate better pattern correlation for temperature than that of precipitation rcm1 rcm2 rcm3 and rcm7 have been found to have correlation values in a very close range of 0 887 to 0 897 rcm2 is found to have minimum value of rmsd 5 024 thus representing the best performance compared to other rcms further for temperature simulation rcm2 is also found to have the nearest values of standard deviation as compared to observed since rcm2 performs better than other rcms individually and their ensemble average for simulating precipitation and temperature therefore rcm2 is selected for further analysis for the examination of spatial variability in average precipitation and temperature spatial maps of precipitation and temperature has been prepared as shown in fig 5a a fig 5 b shows the spatial distribution of precipitation and temperature bias for various parts of india it was observed that rcm2 overestimates the precipitation mostly in drier regions of india such as rajasthan parts of maharashtra andhra pradesh telangana karnataka and tamil nadu however it underestimates the precipitation in high precipitation regions such as western ghats and meghalaya in north east of india model consistently underestimates the temperature values throughout india however higher underestimation up to 5 10 c can also be observed for the himalayan region as can be seen from fig 5 b due to high variability of temperature in this region to remove the bias in precipitation and temperature many approaches for bias correction are available in the literature lenderink et al 2007 singh et al 2017 shivam et al 2017 for correcting the bias in data obtained from rcm a linear bias correction lenderink et al 2007 approach has been used for further analysis in this study the time series of cluster averages of bias corrected precipitation and temperature with corresponding cluster averaged observed data has been shown in figs 6a and 6b rcm2 simulates both the precipitation and temperature well for all the clusters except cluster 1 for the case of precipitation low performance of simulated precipitation for cluster 1 may be attributed to very small size of cluster and its mountainous topography further for examining the capability of rcm2 to identify important drought events three drought indicators namely spi spei and sp eti have been estimated for the randomly selected points in each drought homogeneous clusters after correcting the bias in modelled temperature and precipitation the comparison of three drought indicators for the modelled and observed climate in various homogeneous clusters is given in fig 7 as illustration as it can be observed from fig 7 that the rcm2 is able to catch most of the major drought events in each cluster which indicate its capability toward simulating drought in various regions of india annual precipitation temperature and potential evapotranspiration pet have been computed for each of the regions as shown in fig 8 temperature and pet are found to have increasing trend for all the clusters under both the rcps as shown in table 2 precipitation is also projected to have an increasing trend for cluster 1 2 and 3 under both the scenarios however for cluster 4 a significant increasing trend has been projected for only the rcp 8 5 further under the rcp 4 5 projected sen s slope for pet is found be higher than of the precipitation for all the clusters except cluster 2 and 6 for the rcp 8 5 the rate of change of pet is significantly higher than rate of change of precipitation for all except that of cluster 2 for which the rate of increase in precipitation is of very higher order 3 3 trends in severity and frequency of droughts drought characteristics such as the severity and frequency have been estimated for each grid point as described in section 2 5 for the spi sp eti and spei series modified mann kendall and sen s slope test have been performed on the computed series of annual drought severity and frequency at each grid point for the period 1951 to 2100 by dividing total periods in three sub periods historical period hist 1951 2005 near future nf 2021 2050 and far future ff 2071 2100 the results obtained for both the tests are shown in figs 9a 9b and 9c severity values multiplied by 1 have been used to get the positive trends for the increasing drought severity and vice versa average values of the sen s slope for drought severity and frequency are shown in table 3 and the spatial distribution of sen s slope and modified mann kendall tests are shown in figs 9a 9b and 9c for cluster 1 i e jammu and kashmir almost all drought indices project a decreasing trend in severity and frequency under the rcp 4 5 for all three analysed periods however for rcp 8 5 drought severity obtained from the spi shows decreasing trend whereas both the precipitation evapotranspiration based drought indices show an increasing trend in cluster 1 for nf and ff period indicating a significant impact of et on drought occurrence in this region cluster 2 i e western ghats shows a positive average sen s slope of severity and frequency for the historical period as well as for both the future periods under rcp 4 5 however under rcp 8 5 a decline in overall slopes of severity and frequency is projected for nf period which may escalate in the ff period cluster 3 i e the southern indian region shows an increasing trend in drought severity and frequency for historical droughts for all the drought indicators the modified mann kendall and sen s slope tests suggest decreasing trends in severity and frequency for spi under both the concentration pathways during both nf and ff periods however increasing trends in severity and frequency in northern parts of cluster 3 maharashtra telangana and chhattisgarh etc are projected for both the evapotranspiration based drought indices under the rcp 4 5 whereas increasing trends can be observed for almost the whole cluster 3 for the rcp 8 5 for cluster 4 which consists of central and eastern states such as uttarakhand parts of uttar pradesh up chhattisgarh parts of madhya pradesh jharkhand bihar and odisha the average sen s slope values for drought severity and frequency have been found to have an increasing trend which may continue under rcp 4 5 for the near future nf for the west bengal region of this cluster decreasing trends in drought severity and frequency have been observed in the past which are also expected to continue for the rcp 4 5 further for ff under rcp 4 5 drought intensification is expected to take place since drought severity is projected to increase and drought frequency is expected to decrease in this region for cluster 5 both the evapotranspiration based drought indices suggest a likeliness of increasing trends in drought severity and duration under both the rcps for all analysed periods including the historical period it is noteworthy that the average slope values for the ff period are marginally higher for rcp 8 5 than for rcp 4 5 which suggests a significant impact of gh concentration in this region for far future further spi index shows a decreasing trend in drought severity and frequency for the ff period in cluster 5 which may be attributed to the projected increase in monsoon precipitation in ff cluster 6 which consists of north eastern states of india shows decreasing trends in drought severity and frequency for ff for all the drought indicators under the rcp 4 5 projected spi exhibits an average decreasing slope of drought severity and frequency for the rcp 8 5 however other two evapotranspiration based indices indicate a possibility of increasing trend for both the nf and ff periods overall for the historic droughts similar pattern of significant trends have been observed for all the drought indices which suggests increasing trends in drouht severity and frequency over the northen states such as punjab haryana rajasthan and uttar pradesh and over almost all the southern indian states however decreasiging trends have been observed over the jammu and kashmir region west bengal bihar and northeastern states for historic droughts for the rcp 4 5 increasing trends of drought severity and frequency are mostly distributed around the central and western states in the near future nf however for far future ff a spatial southward shift can be seen in increasing trends for the regions strtetching from rajasthan to andhra pradesh including the parts of madhya pradesh maharashtra chattisgarh telangana and odisha drought severity and frequency are expected to increase in ff which can be attributed to the dominance of evapotranspiration on droughts in these regions which is rising due to the increase in temperature under the rcp 8 5 the drought escalating trends are mostly concentrated to western parts of the country in the nf period however for the ff period evapotranspiration is projected to have pronounced effects on droughts since values of spei shows higher magnitude of increasing trends in most parts of the country under the rcp8 5 in ff under the rcp 8 5 droughts are expected to decrease in eastern parts of the country such as odisha chattisgarh and telangana however for the rest of the country droughts are likely to escalate quickly during this period 3 4 analysis of annual minimum spi sp eti and spei temporal variation in regional cluster average values of spi sp eti and spei have been analyzed using annual minimum spi sp eti and spei values obtained from an averaged series estimated by spatially averaging the monthly spi sp eti and spei values for the grids falling in a cluster as shown in fig 10 results of the modified mann kendall trend test of annual minimum spi sp eti and spei are summarized in table 4 it can be observed from figs 10 b and 8 c that the spei indicates lesser drought intensity annual minimum drought index value in the first half of the century for most of the clusters except cluster 2 and 6 however the spi index shows more droughts intensity in the first half of the century than that of the second half of the century difference in drought intensities represented by the drought indicators is higher for the extreme scenario of rcp 8 5 than that of rcp 4 5 higher drought intensities shown by the spi in the first half and spei in the second half suggest that the cause of droughts in the first half of the century is attributed to precipitation deficit however in the second half of the century it is due to the increase in evapotranspiration owing to the rise in temperature further for cluster 2 western ghats and cluster 6 northeast india all the indices show a high correlation with each other and almost similar values throughout the century this can be attributed to a high precipitation in these regions that could probably eclipse the effect of rise in evapotranspiration due to climate change in these regions thus negating the effect of increase in evapotranspiration for drought formation from table 4 it can be observed that for the cluster 1 the annual minimum spei shows a significant decreasing trend under the rcp 8 5 for the nf however no such significant trends could be envisaged for the ff also a decreasing overall trend has been projected for both the et based drought indices which can be attributed to the rate of change of pet being more than the rate of change of precipitation in the nf a negative trend is projected for the cluster 2 under the rcp 8 5 which suggests an increase in the drought intensity however an overall increasing trend of drought indices for the period 2021 2100 is likely possible which indicates a decreasing trend in the drought intensities cluster 3 shows a significant increasing trends in drought intensities under the higher temperature change only drought intensities may decrease for short periods in the nf and ff under the rcp 8 5 however an overall increasing trend can be expected in drought severity since dis show decreasing trends in cluster 3 for cluster 4 the spei and sp eti are found to have an overall negative trend thus representing an increase in droughts over this region cluster 5 which includes mostly drier region of india is expected to experience a decreasing trend in drought intensities for a short term in the nf however for a long term period of 2021 2100 increasing trends in drought intensities can be expected for this region for the cluster 6 no significant trends have been observed for the nf and ff however a decreasing trend of spei is expected under the rcp 8 5 all the indicators have been found to project different drought peaks for different time periods under different rcp scenario but common incidences such as drought peak in 2060 and 2080 can also be noticed further it is important to notice that a sudden fall in the drought indicator values could be observed after the year 2050 for cluster 3 4 and 5 thus indicating a possibility of droughts becoming severe for these clusters 3 5 analysis of the areal extent of drought affected area with time the extent of the drought affected area at a given instance of time for each of the clusters and india as a whole defined as the ratio of the area of the grid cells exhibiting the spi sp eti or spei indices value below 0 5 to the total area of all the grids falling into the region of interest have been computed for the rcp4 5 and rcp8 5 and the same has been plotted as shown in fig 11 the modified mann kendall trend test on the maximum annual drought affected areas has also been performed to identify the statistically significant trends results of trend analysis are presented in table 5 fig 11 also shows the temporal extent of drought affected areas as the percentage of the total area falling in different clusters for rcp4 5 and rcp8 5 as can be seen from fig 11 all the drought indicators show a higher correlation for the time series of annual maximum drought affected areas under the rcp 4 5 than that of the rcp 8 5 which indicate that the temperature change may significantly affect larger areal extent under the rcp 8 5 also the effect of et on the projected droughts is likely to be more dominant especially in clusters 3 4 and 5 under the rcp8 5 during the second half of the 21st century the spei projects a substantial increase in the drought affected area compared to the other two indices for the rcp 8 5 it is interesting to notice that the spi projects larger drought affected area in the first half of the 21st century for almost all the clusters and smaller drought affected areas in the second half of the century as compared to the spei the maximum drought affected area computed using the spi shows decreasing trend at a higher rate for the rcp8 5 than that for the rcp4 5 which indicates that the precipitation based drought affected area may decrease at a higher rate under the extreme greenhouse gas concentration pathway however the drought affected areas computed by the other two drought indices considering the et in the computation show that the widespread droughts are expected under the rcp 8 5 for the second half of the century highlighting the impact of temperature change in the development of droughts in various regions of india the projected extent of the area under severe droughts for the cluster 2 is found to be decreasing for the spi and sp eti under both the rcps whereas for the spei significant increasing trends in the drought affected areas have been found clusters 3 4 and 5 are found to have significantly increasing trends in the maximum annual drought affected area for both the et based drought indicators i e sp eti and spei which can be attributed to the dominance of et over precipitation in these regions 3 6 mapping of spatial variability of drought hazard drought characteristics obtained using the indices spi sp eti and spei under the rcp 4 5 and 8 5 have been further post processed to compute the dhi using eq 4 for the estimation of weights used in eq 4 a value of 1 which represents the equal importance for all the sub indicators has been taken while calculating the eigenvalues and the eigenvectors of the square preferential matrix of analytical hierarchical processing ahp saaty 1977 maccioni et al 2014 also suggested to give equal importance to sub indicators such as frequency duration and magnitude while computing drought hazard index weights of each sub indicator is found to be 0 25 from the ahp analysis fig 12 shows the spatial distribution of drought hazard index for different drought indices and rcps since the sub indicators have been assigned scores varying from 1 to 4 based on the threshold values the dhi values also vary between 1 and 4 where 1 represents a least drought hazard and 4 represents a highest drought hazard threshold values for all sub indicators are obtained by equally dividing the number of events in all the drought events generated by all the indicators under all the scenario for better comparability among the drought indices and rcps it is interesting to notice from fig 12 that the spei projects the highest drought hazard as compared to the other two drought indicators which suggests that considering evapotranspiration at potential rate results in projection of more drying leading to more projected drought risk further the spatial variability of the dhi values for all the drought indices estimated for the historical period are found to be smaller as compared to the dhi estimated for the future under both the rcps as it can be observed from table 6 that for each of the clusters all the drought indices estimate similar values of hazard for the historical period which suggests that for the historical period considered in this study a rise in temperature if any has not altered the evapo transpiration in a significant way to influence the drought characteristics estimated using the et based drought indicators spei and sp eti however during the future time periods the dominance of evapotranspiration can be observed from the fact that cluster averages of the dhi for spei are marginally higher than the other two drought indices the estimate of spi projects lesser drought hazard for all the clusters except for clusters 4 and 6 which implies that a higher emission concentration may decrease the precipitation based drought hazard however both precipitation and evapotranspiration based indices show an escalated drought hazard for the rcp 8 5 the spatial distribution of dhi indicates the likelihood of severe drought hazard in central india for the rcp 4 5 which is likely to escalate with an increase in the evapotranspiration however for the rcp 8 5 the area with severe drought hazard is likely to increase and a shift towards south eastern states is also expected 3 7 periodicity of droughts periodicity analysis of droughts for the monsoon months has been carried out using the fourier analysis significant periodicities which are above 90 confidence interval have only been considered periodograms of spi sp eti and spei series have been calculated for examining the hidden cycles of drought in different clusters for all the four monsoon months for each grid point across all over india for analysing the change in periodicity over time three time periods historic 1951 2005 future period 1 2020 to 2050 and future period 2 2051 to 2100 have been used fig 13 summarizes the results of significant peaks of the periodograms averaged over four months for different clusters and as well as for the whole india it is inferred from this figure that in general the percentage of area for all the significant peaks and for all the clusters and time periods exhibits almost similar values implying least impact of climate change on the periodic cycles of drought in india periodicities of the order of 2 years to 3 6 years dominate in more than 30 percent area of the clusters and as well as for the whole country moreover inter annual cycles of 5 10 years also show a relatively higher percentage of the area across all the clusters another interesting point which could be observed from fig 13 is that the percentage of area under significant peaks have almost similar value for all the clusters which imply that the significant periodicities would spread uniformly across all the regions of india further in future both the rcps shows almost similar values of periodicity which suggests that the impact of climate change on the periodicity will be insignificant 3 8 discussion close scrutiny of the results presented above indicates that the cerfacs cnrm cm5 iitm regcm4 performs better than other individual models and that of the ensemble average in simulating the past observed precipitation and temperature also selected rcm model is found to capture the drought trends in various regions of india satisfactorily for most of the clusters the rate of increase of the potential evapotranspiration pet is expected to be higher than the rate of increase in precipitation however the magnitude of increase in precipitation is much higher than the evapotranspiration in clusters 2 and 6 and therefore the change in evapotranspiration does not affect the drought dynamics which makes it inefficient for causing drought in these regions furthermore trend analysis reveals that the historical increasing severity trend are concentrated over northcentral and southcentral regions of india which may continue to remain same in near future for rcp 4 5 however a westward shift may be expected for higher ghg concentration a decreasing trend in the severity and frequency under rcp 8 5 is likely in eastern states such as odisha and chhattisgarh in the far future the results of analysis of annual maximum drought affected area reveals the dominance of the evapotranspiration in forming the droughts in clusters 3 4 and 5 which spreads over most parts of the country moreover rcp 8 5 may cause more risk over most parts of india since the drought hazard projected using this rcp is significantly higher than that of the rcp 4 5 findings of drought periodicity analysis reveal the presence of dominant drought cycles of 2 3 6 years during the 1st half as well as the 2nd half of the 21st century indicating insignificant impact of climate change on drought periodicity past studies suggest that droughts are having positive trends of intensity frequency and severity owing to declining trends in precipitation mallya et al 2016 naresh kumar et al 2012 jain and kumar 2012 which also validates the findings of this study however studies based on analysis of future projected cmip5 multi model data suggest that the indian monsoon precipitation may increase in the 21st century due to the favourable relationship between warming and the amount of indian summer monsoon turner and annamalai 2012 also it is expected that the increase in precipitation for rcp 8 5 would be greater than lower emission rcps menon et al 2013 kundu et al 2014 chaturvedi et al 2012 freychet et al 2015 this corroborates favourably with findings such as existence of positive correlation between the indian summer monsoon for most of the clusters and global warming fu et al 1999 increase in the seasonal precipitation due to changes in inter tropical convergence zone hu et al 2000 and warming of the sea surface combined with the amplified vapour holding capacity would lead to more water vapour content in the atmosphere resulting in enhanced precipitation in the tropics trenberth 1998 meehl et al 2005 alam et al 2017 used the spei and found an increment in the probability of occurrence of drought in the six different ecological regions of india furthermore nath et al 2017 found a consistent increase in the precipitation and evapotranspiration however the increase in pet for a higher emission scenario will be much higher than the projected increase in the precipitation for the 21st century the mitigating effect of the increased precipitation on drought in rcp 4 5 will be overridden by the intensification in pet nath et al 2017 it is important to notice that the drought intensification in the past over india was driven by the decreasing trend in precipitation however in the future the drought intensification would be driven by the escalation of evapotranspiration this study establishes a clear link between the alteration in precipitation and temperature and changes in the drought characteristics for different regions of india for various carbon emission scenarios findings of this study also underscore the need to choose drought index carefully for drought characterisation under the climate change scenario because the rise in temperature has different effects on precipitation as well as on evapotranspiration which may result in different drought scenarios special care should be exercised in interpreting the results obtained based on the spei when the rise in temperature of higher order have been predicted due to global warming as it may project extreme drought scenario due to the assumption of et to take place at the potential rate therefore drought indices which consider the realistic representation of increase in the et should be preferred the findings of our study are in conformity with the previous studies referred above because the projected increase in the amount of precipitation may lead to reduced drought risk however an increase in the evapotranspiration due to the projected increase in temperature is likely to surpass projected increase in precipitation over most parts of the country that may result in increased drought risk the periodicity analysis indicates inter annual periodicities influencing monsoon months to be distributed uniformly across all clusters of the indian subcontinent with an average cycle of 2 3 6 years dominating the country inter annual periodicities of short and long durations such as 2 4 years and 4 8 years may be correlated with quasi biennial oscillation qbo and el niño southern oscillation enso phenomenon adarsh and janga reddy 2015 kumar et al 2013 gadgil et al 2007 because qbo and enso affects the indian summer monsoon rainfall kumar et al 2013 however long term inter decadal periodicities may be correlated to pacific decadal oscillation pdo and atlantic multidecadal oscillation joshi and kucharski 2017 kripalani et al 2003 found enso phenomenon to be negatively correlated with indian summer monsoon rainfall moreover kumar et al 2013 suggested that enso plays an important role in causing monsoon drought in the indian region results of this study may have serious implications on the policy making and water resource planning and management of india the results suggest an increment in drought affected area especially in clusters 3 4 and 5 where the population is much higher than in the other clusters according to the un population projection 2017 the total population of india may increase up to 1 8 billion by the year 2050 and to 2 billion by the year 2100 increase in the population will increase the stress on the resources of water and food further as previously reported by jülich 2011 drought trigger migration has been taking place from eastern villages of the country to the south indian cities the drought triggered migration may intensify in future the agricultural gdp has reduced from 39 in 1983 to 14 in 2014 goi 2016 reduced agricultural area and increased population along with the severe droughts in the regions where most people live may pose serious risk to food security in india out of 33 23 of installed renewable power generation hydropower contributes toward almost 13 17 of total installed capacity hydropower plants installed in clusters 3 and 4 alone contributes around 32 of total hydropower reduction in the water availability in reservoirs due to longer and severe droughts in these regions may drastically reduce the amount of hydropower generation therefore enhanced preparedness is needed in the light of these results to alleviate the drought risk in these regions in the future policies should be framed while considering regional vulnerabilities and projected hazard further it is important to mention various uncertainties which are inherent in almost all studies based on the projected future climatic scenarios and the same are also involved in the presented analysis as well uncertainty related to gcm simulation such as uncertainty in simulating large scale atmospheric circulation inter gcm projection uncertainty emission scenario uncertainty and downscaling model uncertainty may lead to lesser confidence in the obtained drought results spatial resolution and choice of drought indices and its scale may also affect the drought projections however in the future a better understanding of hydrological cycle may lead to better and less uncertain projections thus leading to better future climatic predictions that may reduce uncertainty in drought analysis 4 conclusions spatiotemporal analysis of likely occurrence and distribution of droughts was performed over india using 81 years 2021 2100 of projected precipitation and temperature data obtained from cerfacs cnrm cm5 iitm regcm4 rcm for two rcp scenarios rcp 4 5 and rcp 8 5 and historical observed data 1951 2005 obtained from the imd in gridded form respectively temporal trends of drought severity and frequency were also analyzed drought hazard maps were prepared using the drought hazard index dhi periodicity analysis was also carried out using fourier transform to find the hidden periodicities in spi sp eti and spei series of monsoon months results of regionalization in india suggest the presence of 6 distinct homogeneous drought regions in india precipitation temperature and pet are found to be increasing in the 21st century for almost all the clusters analysis of projected scenarios of drought based on multiple indices for 21st century reveals that global warming may have severe impact on the drought scenario in india analysis of results indicates that the spi projects least drought risk in the far future due to increasing precipitation a significant correlation between all studied drought indicators have been found for historical period however for future et based drought indices such as sp eti and spei shows a more intense drought especially in the later part of the 21st century interestingly comparison of results obtained using different drought indices for various climate change scenarios underscore the importance of considering rise in evapotranspiration due to increase in temperature in drought characterisation failure to do so may result in the introduction of uncertainty in the end results however special care should be exercised in interpreting results obtained based on spei when the rise in temperature of higher order have been projected due to global warming because it may predict extreme drought scenario due to the assumption of et to take place at potential rate therefore drought indices which consider the realistic representation of increase in et should be preferred therefore for drought characteristics investigation under the climate change this study clearly recommends to use the multiple et based drought indices to arrive at the final conclusion results of trend analysis suggest that northern and north western india may face increasing trends in severity and frequency of drought in the near future nf however in the far future ff most parts of the india are expected to face increasing severity and frequency of drought except south eastern regions such as odisha chhattisgarh and parts of maharashtra madhya pradesh and telangana these increasing trends relies solely on increase in et values in these regions analysis of drought hazard index dhi reveals a shift in drought hazard from central india towards southeast central india with an increase in ghg concentration considering all the drought indices impact of increase in evapotranspiration would be more pronounced on the occurrence of drought in cluster 3 southern india cluster 4 central and southeast region and cluster 5 north western and western india because in these clusters both the et based drought indices show a larger areal extent under drought for these regions in the far future further for these regions average drought hazard index has also been found to be larger than other regions interannual significant periodicities of 2 3 6 years are likely to be distributed uniformly across all clusters of drought regions of india during the 21st century moreover change in drought periodicity due to climate change in most of the regions has been found to be insignificant acknowledgements this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors however authors are very thankful to indian institute of technology roorkee india for providing the necessary resources to conduct this research and ministry of human resources govt of india for supporting first author through senior research fellowship 
6904,numerous large river basins of the world have few and irregular observations of the components of the terrestrial hydrological cycle with the exception of stream gauges at a few locations and at the outlet along with sparsely distributed rain gauges using observations from satellite sensors and output from global land surface models it is possible to study these under observed river basins with populations greater than a billion people some of these rivers e g the ganga brahmaputra the yangtze the nile and the mekong are the economic engines of the countries they transect yet thorough assessment of their flow dynamics and variability in regard to water resource management is still lacking in this paper we use soil moisture 0 2 m and surface runoff from the nasa global land data assimilation system gldas evapotranspiration and normalized difference vegetation index ndvi from the moderate resolution imaging spectroradiometer modis and rainfall from the tropical rainfall measuring mission trmm and total water storage anomaly from the gravity recovery and climate experiment grace to examine variability of individual water balance components to this end understanding the inter annual and intra seasonal variability and the spatial variability of the water balance components in the major river basins of the world will help to plan for improved management of water resources for the future keywords water resources hydrological balance models satellite data droughts and floods 1 introduction the water availability per capita in many locations of the world is constantly decreasing one explanation is the increasing proportion of global population relative to the available water in many parts of the world the global population has increased from 2 billion in 1950 to a current population of 7 4 billion for essentially the same water availability the global per capita water availability has an inverse relationship decreasing by a factor greater than 3 during this period however there are two reasons that this conclusion is not global firstly the distribution of population increase is not uniform for example urban growth is significantly different in areas in asia and africa as compared to europe and australia and secondly in many regions of the world the groundwater is a predominant source of water and is being exploited and it has only recently become obvious that withdrawal rates from these aquifers are unsustainable for example groundwater in the high plains of the united states and in northern india are over utilized the united nations world water development report 2016 points out that three out of four jobs globally are dependent on water un water 2016 there are numerous areas such as agriculture power production industrial applications fishing and health which involve water illustrating the societal dependence on water numerous studies have pointed out the impacts of climate change and or population growth on water resources arnell 1999 alcamo et al 2007 kundzewicz et al 2007 oki and kanae 2006 piao et al 2010 ragab and prudhomme 2002 vorosmarty et al 2000 other studies have addressed more specific changes such as groundwater recharge under various climate change scenarios herrera pantoja and hiscock 2008 scanlon et al 2006 taylor et al 2013 one common conclusion from all these studies is that the amount of water available is decreasing with both climate change and increasing population the major river basins of the world play a big role in supporting over 70 of the global population many of these hydrological studies are specific to a river basin but there are a few comparative studies across river basins aerts et al 2006 dai et al 2009 nijssen et al 2001 oki and kanae 2006 vorosmarty et al 2000 in their study of global rivers using various climate models under different scenarios of climate change nijssen et al 2001 found that the largest changes were observed in the spring time period that corresponds to the snowmelt aerts et al 2006 found that the future discharges in some of the major river basins could increase by 6 16 due to changes in climate the analysis of the annual stream flows for the 200 largest rivers of the world from 1948 to 2004 showed that more rivers exhibited decreasing trends than increasing trends dai et al 2009 vorosmarty et al 2000 and oki and kanae 2006 both showed that the water scarcity index showed higher values in western united states northern africa south asia and the middle east regions and that the population living in the area of high water stress and relative demand for water would increase with the changes in climate observations of the water cycle using in situ sensors are very difficult due to two reasons firstly the water cycle is highly heterogeneous in space and varies temporally at short time scales maintenance and operation of a high density in situ network for example rain gauges is very expensive secondly obtaining data from river basins in countries other than united states is at times very difficult since many countries may not freely distribute or share data given these reasons satellite remote sensing observations and hydrological model outputs are an attractive solution that can overcome spatial heterogeneity and temporal consistency issues in addition the quasi global coverage provided by satellite observations combined with open data policies can help avoid the issues related to data access and continuity the motivation of this study is two fold firstly the lack of in situ water data from most of the large river basins of the world implies that we can only use the readily available satellite data sets and global land model outputs secondly most of the studies that involved these major river basins were published at least a decade or so ago and current up to date studies do not exist we currently have about 15 years of data from satellite sensors that can bridge this gap in this work we mostly use satellite data from nasa satellite sensors as they have long data records over 10 years in all cases and are freely and publicly available the model outputs also come from a nasa model system the global land data assimilation system which is also publicly available here we use publicly available data sets to construct the water balance of eleven large continental scale river basins of the world we analyze each of the components of the water budget precipitation evapotranspiration runoff and total water for seasonality and study the spatial and temporal correlations between components in this way we envisage that this study will help water resource managers with future planning of water resources and land use in these highly important and widely utilized river basins this paper is organized as follows section 2 describes the data sets satellite and model derived for the variables in the hydrological cycle section 3 highlights the results for the hydrological cycle for the major river basins using the data described in section 2 and identify key processes in time and space finally section 4 delves into the conclusions and discussions of this work 2 data all the data sets used in this study are the monthly averaged or cumulative precipitation values and at their inherent spatial resolution all of the data sources are listed in table 1 time series are calculated from the spatial average within the respective basins no attempt has been made to re grid the data to a common spatial resolution in the figures tables and analyses in this paper 2 1 trmm tropical rainfall measuring mission trmm was launched in 1997 kummerow et al 1998 2000 and ended its mission in 2015 the most widely used satellite precipitation data are the tmpa trmm multi satellite precipitation analysis 3b42 v 7 precipitation dataset that are obtained combining trmm precipitation radar pr passive microwave pmw and infrared ir estimates at a three hourly interval and 0 25 spatial resolution in the 50 s 50 n area bolvin and huffman 2015 the tmpa rainfall is widely applied in different branches of the earth sciences especially in data sparse regions e g awadallah and awadallah 2013 khan et al 2011 asante et al 2008 bindlish et al 2003 details on the data product can be found in huffman et al 2007 2010 2 2 modis moderate resolution imaging spectroradiometer normalized difference vegetation index ndvi and evapotranspiration et are available from the moderate resolution imaging spectroradiometer modis the modis sensor is onboard both the terra and aqua satellite platforms which were launched on december 1999 and on may 2002 respectively in a sun synchronous polar orbit with estimated equatorial crossing times of 10 30 am terra and at 1 30 pm aqua modis provides 44 global data products for land ocean and atmospheric variables details of the modis land data are available at the modis website http modis gsfc nasa gov and the products used in this study ndvi and evapotranspiration are available as mod13c2 and mod16 respectively from the land processes distributed active archive center website http lpdaac usgs gov and the numerical terradynamic simulation group at the university of montana http www ntsg umt edu project mod16 the algorithms to derive these products are well established and extensively evaluated ndvi rouse et al 1973 tucker 1979 myneni et al 1995 and evapotranspiration mu et al 2007 2011 the monthly composite global products are available from lpdaac on a 5 6 km global climate modeling grid cmg although local tiled versions are available from some products at higher spatial resolutions for example ndvi at a 1 km resolution not used in this study the modis et product is based on the penman monteith method mu et al 2011 there have been numerous validations of modis evapotranspiration estimates in many regions of the world kim et al 2012 have carried out validation of the modis et products over different land cover and climate in asia and found that it resembled closely to the et measured from flux towers in australia cleugh et al 2007 and pan arctic mu et al 2009 2 3 grace gravity recovery and climate experiment the u s german gravity recovery and climate experiment grace satellite mission was launched in 2002 to provide estimates of changes in total terrestrial water storage represented as the sum of groundwater soil moisture snow and surface waters at large spatial scales and on a monthly basis tapley et al 2004 while this mission provided monthly tws estimates through jan 2017 the grace follow on mission is expected to support future research using this data variable members of our team have developed and applied an approach for assimilating observations of soil moisture and terrestrial water storage from satellite based sensors including grace into a land surface models which have been shown to produce estimates of variations in the components of terrestrial water storage that are both accurate and as high resolution as the model grid bolten et al 2010 bolten and crow 2012 gupta et al 2015 the grace assimilation approach has been used to provide enhanced estimates of hydrological monitoring and groundwater storage by constraining terrestrial water balance zaitchik et al 2008 forman et al 2012 houborg et al 2012 li et al 2012 eicker et al 2014 by including monthly observations of the terrestrial water storage in our land surface modeling scheme it is possible to more accurately monitor regional hydrological states and fluxes and thus calculate with more certainty the anomalies of these states and fluxes for enhanced monitoring of hydrological and agricultural drought grace has been instrumental in numerous water balance studies pointing to declines in the water storages specifically the decline in groundwater in many parts of the world rodell et al 2004 2007 2009 tiwari et al 2009 landerer and swenson 2012 but studies cannot be conducted at smaller scales due to the coarse resolution of the sensor alley and konikow 2015 lakshmi 2016 2 4 gldas global land data assimilation system the global land data assimilation system gldas provides high resolution maps of land surface states and fluxes by forcing modern offline land surface models e g noah ek et al 2003 with high quality observational data mitchell et al 2004 the forcing data cosgrove et al 2003 luo et al 2007 and outputs have been extensively validated lohmann et al 2004 robock et al 2003 schaake et al 2004 the outputs are available at a 1 8 spatial resolution and hourly time step for the north american nldas version not used in this study and at a 1 4 spatial resolution and 3 hourly time step for gldas the data for both n g ldas are available at monthly timescales which will be used here the ldas data sets are described in detail at http ldas gsfc nasa gov and http disc sci gsfc nasa gov hydrology we use the root zone soil moisture 0 2 m and runoff from the improved gldas version 2 product in this study 2 5 major river basins of the world the major river basins of the world are shown in fig 1 these basins were extracted from the food and agriculture organization of the united nations major hydrological basins shapefile derived from the usgs hydrosheds and hydro1k elevation products fao un 2015 previous studies about the basins as well as climate area latitudinal location annual average precipitation and air temperature are listed in table 2 this table enables us to understand on a comparative basis the physical and climatological differences between the large river basins distributed between all continents these basins were chosen for this study because of they represent a diverse climatology such as tropical humid semi arid arid and marine and the fact that the hydrology and availability of water in these basins is an issue for millions of its inhabitants for agriculture hydropower transportation and domestic and industrial uses the annual average precipitation ranges from a low of 160 mm in the colorado river basin to a high of 2110 mm for the ganga brahmaputra river basin the average annual air temperature varies between 284 k in the danube river basin to 300 k in the nile river basin there is also a large variability in the size the smallest basin california basin california is the integrated basin for sacramento san joaquin river tulare lake san francisco bay part of north and south coast north and south lahontan and the colorado river 400 000 km2 to the largest the amazon river basin 5 000 000 km2 such diversity in location and climate result in a different distribution of precipitation into evapotranspiration infiltration recharge runoff and soil moisture the previous studies for each basin focus on the variability of these hydrological components and some of these have already been referenced in the introduction section 3 application of the remotely sensed and modeled data to estimate water storage 3 1 validation of the precipitation evapotranspiration and runoff data before and after the launch of earth observing satellites studies are conducted to ensure the quality of the observations often consisting of field studies and comparison with in situ measurements as well as comparisons with other remotely sensed products and modeled outputs the trmm retrieved precipitation modis derived evapotranspiration and the gldas modeled runoff have been independently validated as shown in table 3 and can be used as proxies for direct ground measurements to demonstrate their local efficacy we compare the satellite based data sets with point based in situ measurements and assess the correlations by latitude showing spatial variations of ground data in fig 2 in the analysis three data sets i e precipitation runoff and et were used the global historical climatology network gchn was compared with trmm precipitation runoff data from the global runoff data centre grdc was compared with gldas noah runoff and fluxnet station data were converted into et using the penman monteith equation to compare with modis et lawrimore et al 2011 grdc 2017 fluxnet 2015 zotarelli et al 2010 each of the data sources available had data that were outside of the temporal study domain and therefore some stations could not be included in the comparison of the 72 882 total precipitation stations available from gchn only 11 286 stations had at least ten years of data within 1998 2015 to match the trmm data of the 9236 discharge stations available from grdc only 3540 stations could be used finally there are approximately 166 fluxnet stations available globally but only 36 stations could be compared with the modis evapotranspiration fig 2 demonstrates how well the satellite measurements compare with traditional ground measurements trmm provides precipitation data from 50 n 50 s the areas outside this range are masked out the satellite direct and indirect observations closely align with measurements from ground stations the modeled runoff data suffers drawbacks due to large grid sizes and largely ignore water management practices in spite of these drawbacks modeled runoff data are used in this analysis to leverage their global coverage and temporal continuity 3 2 hydrological balance we carried out a basin averaged water balance and compared it to the grace water equivalent thickness anomaly 1 p et r δ s where precipitation p evapotranspiration et runoff r and change in surface and subsurface water storage δs are monthly and basin averaged values for each of the basins quantities enhanced or reduced due to water withdrawals due to irrigation domestic and industrial uses are not explicitly included on either side of this equation as there was not a globally consistent method of estimation for them all the variables on the left hand side of eq 1 can be estimated using either satellite p et or model r data sets the total change in water storage total water on the right hand side of the equation δs can be estimated by grace observations the difference between p et r and δs would represent the amount of withdrawal of groundwater in the basin there does not exist any database for estimation of w and the value of w differs between basins in regions of sufficient water supply there is not much water withdrawal as w is seldom measured and is much smaller compared to δs we have not included it in eq 1 we provide a discussion of this in section 4 figs 3a and 3b represent spatial average monthly p et r and the grace water equivalent thickness anomalies as water storage anomalies for grace the anomalies were calculated with the 2004 2010 baseline for all other variable the anomalies were calculated for the length of record 2001 2015 for all the river basins studied in this paper in time series and scatter plots there are two common features in all these basin trends firstly there is a marked seasonal variability of both p et r and the total water for most of the river basins but there are a few exceptions for example the congo the colorado and the murray darling river basins do not show the seasonal signal for p et r and grace water equivalent thickness as compared to the amazon or the ganga brahmaputra river basin the time period of the lag varies between one to 3 months and is dependent on the size and climate of the basin and the transport and storage of water the magnitude of the p et r is strongly dependent on the climate and ecosystem and this magnitude is much larger for the amazon and the mekong river basins as compared to the colorado the murray darling and the danube river basins direct comparison of the magnitudes of p et r and the grace water equivalent thickness anomaly as total water is not possible as the former is a direct measure and the latter is an anomaly however the temporal variability changes between month to month between p et r and the grace water equivalent thickness anomaly is justified as they both reflect the increase or decrease in the storage a positive p et r corresponds to a positive value of the grace water equivalent thickness anomaly and vice versa examination of the correlation statistics in table 4 all values are significant at p value of 0 05 shows that the high correlation between p et r and total water is seen for the tropical watersheds of the amazon the ganga brahmaputra and the mekong river basins of 0 8 or higher and a lag of 1 month the next group is the urban california and the danube river basins at 0 7 or higher with 0 lags the other basins have lower r2 and the time lag corresponding to the maximum r2 at 3 months in the case of the colorado 3 3 co variability of hydrological cycle components five variables are derived from three different sources precipitation from trmm total water from grace evapotranspiration and ndvi from modis and runoff and soil moisture from gldas the spatial resolution for precipitation trmm runoff gldas and soil moisture 0 2 m gldas is 0 25 et and ndvi modis is 0 05 and that of total water grace is 1 figs 4 and 5 represent the monthly time series of the water balance components for the mekong and the murray darling river basins respectively these include monthly anomaly time series for a precipitation b runoff c soil moisture d et and e total water as grace water equivalent thickness anomaly the anomalies for precipitation et runoff and soil moisture are calculated using january 2001 to december 2014 period as a baseline the figures highlight the seasonal and annual variability of the hydrological cycle between january 2001 and december 2014 the total water time series starts in april 2002 corresponding to the grace launch also indicated in these figures are the high negative and positive anomalies that correspond to dry drought and wet flood conditions in the basin examination of these time series shows that the co variability of these four components of the hydrological cycle follows the water balance we chose for the mekong river basin fig 4 and the murray darling river basin fig 5 dry and wet months based on low and high grace water equivalent thickness anomaly if we examine fig 4 a e we observe that one of the periods of lowest precipitation in the mekong river basin corresponds to january 2005 with a precipitation anomaly of 0 5 mm corresponding to a 0 mm and 7 5 mm for the runoff anomaly and et anomaly respectively in march 2005 lags rainfall by 2 months and 3 5 mm for soil moisture and 100 mm for the total water in may 2005 the other extreme corresponds to the extremely wet month of september 2011 with a positive anomaly for rainfall of 100 mm and a corresponding positive anomaly of runoff of 5 mm soil moisture of 5 mm and lagged by one month october 2011 total water anomaly of 100 mm november 2011 lag of two months and the et shows generally positive anomalies a few months later starting in december 2011 for a period of over 12 months the correspondence of the rainfall to runoff soil moisture and total water is well displayed in this figure the same findings hold for the murray darling river basin the dry and wet periods are related between all of the variables displayed in fig 5 the dry period of low rainfall 75 mm and runoff 0 mm in august 2009 corresponds to low soil moisture 3 mm et 10 mm and low total water 50 mm in november 2009 the wet period with above normal rainfall 70 mm corresponds to december 2010 and positive runoff 2mm and soil moisture 15 mm in february 2011 and high total water 100 mm in march 2011 the et shows a high positive anomaly of 25 mm for december 2010 and remains positive for several months in fig 4a we observe that the precipitation has a negative anomaly throughout the mekong river basin for january 2005 and as a result both the soil moisture and runoff two months later march 2005 show negative anomalies and the total water in may 2005 shows negative anomalies ranging from 100 mm to 500 mm throughout the catchment the same is true for the spatial distribution of the positive anomalies for precipitation extends to soil moisture runoff et and total water that has a positive anomaly ranging from 200 mm to 500 mm in the southern part of the mekong river basin similar spatial patterns are seen for the murray darling river basin on examination of the total water for the murray darling basin fig 5e it is seen that it shifts from mostly negative to positive values at the beginning of 2010 this is expected as the rainfall fig 5a exhibits high values positive anomalies in six months of 2010 60 mm as well as in january and february 2012 these high positive anomalies in rainfall during 2010 coupled with lower values of et keep the water balance positive in the basin one of the most important observations that can be seen from figs 4 a e and 5 a e in the spatial maps of the catchment for the hydrological cycle variables is the sharp contrast between the dry and the wet periods the spatial pattern of the variables for the wet month are dominated by positive rainfall soil moisture runoff et and total water anomalies and vice versa for the dry months 3 4 spatial variability examination of the spatial variability of the hydrological cycle variables in two river basins the amazon and the colorado fig 6 yields interesting and contrasting results fig 6 displays the monthly spatial standard deviation of precipitation trmm runoff gldas et modis soil moisture gldas and total water anomaly grace all in mm the differences between the amazon and the colorado with respect to spatial variability are very apparent to begin with the spatial variability of the precipitation in the colorado river basin varies between 0 and 30 mm whereas for the amazon river basin the range is between 60 and 180 mm this spatial variability in precipitation translates to a larger spatial variability in runoff for the amazon river basin 2 30 mm as compared to the colorado river basin 0 10 mm the standard deviation of the precipitation for the amazon river basin generally shows a minimum in months of august and september around 60 mm a maximum in the month of may between 150 and 180 mm the spatial variability of runoff for the amazon river basin is lowest in july and august standard deviation of around 5 mm and highest in january march 20 30 mm the spatial variability of evapotranspiration shows a distinctive seasonal signature for both the amazon and the colorado river basins for the amazon there is a variation between a minimum in the month of february of 15 mm and a maximum in the months of august and september of around 35 mm in the case of the colorado river basin the minimum spatial variability is in the winter months december to february of 5 mm and a maximum during the summer months of june and july of 20 mm it can be noticed that in the case of the amazon river basin the maximum standard deviation for runoff corresponds to the minimum standard deviation for et the spatial variability for soil moisture for both the amazon and the colorado river basins does not show any seasonal variability with the spatial standard deviation for the amazon river basin being higher between 13 and 22 m as compared to the colorado river basin between 6 and 12 mm the variability of total water for the amazon river basin shows a very large range between 100 mm and 400 mm as compared to the colorado river basin between 0 and 80 mm examination of the spatial variability of precipitation ndvi and et in january 2005 and june 2005 for the colorado river basin and january 2005 and august 2005 for the amazon river basin shows remarkable differences between the two basins figs 7 and 8 respectively whereas most of the colorado river basin has little or no vegetation in january 2005 ndvi around 0 15 and only a small region in the southern part with any vegetation the amazon river basin shows larger extent of greenness large region ndvi around 0 7 there is a large spatial variability in et for the amazon river basin between 0 and 150 mm and much lower range for the colorado river basin between 10 and 40 mm the difference in et in august 2005 for the amazon river basin between the south and the north is evident from the very low et in the southern part of the basin 0 20 mm contrasting with the high et 120 150 mm in the northern part of the basin in the amazon river basin this is strongly related to the higher amount of vegetation and the rainfall in the north ndvi 0 7 0 9 in the north and 0 5 0 8 in the south rainfall of 150 250 mm in the north and 0 75 mm in the southern part of the basin this is in stark contrast to the spatial pattern of et for the amazon river basin which is much more uniform across the region as also reflected in rainfall and vegetation the large difference in et in june 2005 in the colorado river basin between the northeast and the south is also seen fig 7 and it varies between 0 and 80 mm across the basin and is strongly related to the variation of ndvi 0 15 0 75 with higher ndvi in the northeast 0 70 and much lower in the south 0 15 and rainfall is much higher in the northeast 60 mm and much lower in the south less than 10 mm 3 5 temporal variability anomaly index analysis the data analyzed in this paper spans over 15 years and 11 river basins of the world whereas each of these river basins has been studied in considerable detail in many past studies table 2 a comprehensive comparison has never been undertaken in considering locations with differing annual rainfall temperature and land cover direct comparisons will not yield quantitative results due to obvious differences between basins for example there is always greater rainfall and runoff in the amazon river basin as compared to the murray darling river basin in order to overcome this problem we have constructed the anomaly index defined as the monthly anomaly divided by the monthly climatology as the anomaly index normalizes the monthly anomaly by dividing by the monthly climatology the regions with anomaly index would measure the variability of the monthly anomaly as a fraction of the monthly climatology value for example when we compare the amazon with high monthly rainfall to the murray darling basin with much lower rainfall using the precipitation anomaly index we are only comparing the fraction of variability the minimum and maximum monthly anomaly index values are presented in table 5 fig 9 shows the comparison of precipitation using the anomaly index for the amazon river basin and the murray darling basin whereas the index values in the amazon river basin range from 0 4 to 0 61 the index values for the murray darling basin varies between 0 95 and 1 73 table 5 the temporal variability of this index for the amazon is 0 11 and for the murray darling is 0 52 both these statistics show that the variability of the monthly rainfall as a ratio of the monthly rainfall climatology is much higher in the murray darling basin and is subject to greater extremes in precipitation these are periods when the rainfall is below normal negative precipitation anomaly index which is seen between 2001 and 2009 and this period corresponds to a severe drought in the region we observe a period of high monthly precipitation compared to the climatology for 2010 and 2012 and november 2010 corresponds to a large scale flood in this region in the case of the amazon river basin there is very little deviation of the precipitation anomaly index from zero zero indicates no departure from the monthly climatology and hence the river basin is not subject to extremes a few other river basins with large negative precipitation anomaly index and hence subject to droughts are the california the colorado the danube and the ganga brahmaputra river basins the monthly anomaly indices between different variables capture the connection between the land surface variables the variability in vegetation index is connected to the variability of the evapotranspiration the amazon river basin shows a low range of ndvi 0 04 to 0 08 and a corresponding low range for et 0 17 to 0 29 however the murray darling basin shows a much larger range for ndvi variation 0 23 to 0 38 and a corresponding higher range for et 0 63 to 1 7 this is shown in fig 9 and table 5 table 5 shows the minimum and maximum monthly values for the anomaly index the temporal standard deviation for monthly ndvi anomaly index is 0 02and 0 12 and monthly et anomaly index is 0 04 and 0 29 for the amazon river basin and the murray darling basin respectively larger variability in precipitation translates to greater variability in ndvi and et for the murray darling basin as compared to the amazon river basin 4 conclusions and discussion we have examined the water balance components for eleven global river basins using publicly available monthly satellite data and model output products for a period of 15 years between 2001 and 2015 the water balance components of the hydrological cycle include precipitation et soil moisture runoff and total water the river basins are located in contrasting climate topography and ecosystems across the globe in all continents with the exception of antarctica in comparing the output of p et r to the changes associated with the total water from grace we observe a distinct seasonal cycle with a maximum lag of a few months between the two quantities p et r and δs the correlation between p et r and total water change shows a large variability among basins with the highest being the amazon river basin at r2 of 0 9 and lowest at r2 of 0 35 for the colorado river and the murray darling river basins the differences between the basins may stem from the human engineering of the water systems in the basin the amazon river basin has been subject to much less human intervention compared to the colorado and the murray darling river basins another factor in this difference is the storage and melting of snow in some basins we compared a month of wet with a dry month for the mekong river and the murray darling river basin on comparison of precipitation runoff soil moisture et and total water we find a consistency in the hydrological cycle with respect to the water balance i e we find for wet flood periods a large positive anomaly of precipitation from trmm corresponding to positive anomalies of et from modis runoff and soil moisture from gldas and total water from grace and vice versa for negative anomaly or dry drought conditions finally we compute the anomaly index and compare these variables across river basins the precipitation anomaly index for the amazon river basin has a much lower variability compared to the murray darling river basin the anomaly indices of the other hydrological variables are also compared with each other and across basins and this leads to very consistent relationship eq 1 in section 3 2 has an implicit withdrawal term which presents us with a problem whereas in principle eq 1 should be balanced if all the individual variables are perfect maintaining a water balance this is not the case as seen in the results in figs 3 a k we therefore conclude that the problem in this balance equation is the fact that the individual variables are not perfect and compounding the fact is that the withdrawal terms on both sides of the equation are seldom known the dynamics of withdrawal is very complicated withdrawal due to irrigation can either a leave the watershed as evapotranspiration or runoff and this is accounted for in the equation b infiltrate into the soil and recharge the groundwater or c leave the system through domestic water withdrawal and subsequent transport elsewhere each of these has to be treated separately and one treatment would not address all physical mechanisms therefore we have removed the withdrawal term in eq 1 as we have realized that the accuracies of the individual terms in eq 1 probably account for withdrawal however a much more involved analysis needs to be undertaken and this would need to be done at a the whole river basin scale and b sub basins to determine the actual dynamics we hope that this will be the subject of further studies in this paper we utilize monthly data from satellites and models over a 15 year period for analysis this study is unique as it is a multi year period using a combination of publicly available satellite data and model output b comparison of river basins across the globe located in a range of climate topography and ecosystems though the data come from different sources they display the required relationship with each other to complete a hydrological balance in addition the hydrological variables display very interesting spatial and temporal patterns that are consistent with hydrological extremes of floods and droughts in the future such studies will be very important to determine availability of water resources under the growing pressures of an ever increasing population studies like this present work when carried out at higher spatial resolution will aid and assist local agencies for improved land use and water use management understanding variability of the different components of the water budgets for the past 20 years will help in the planning for the net 20 years in many countries of the world where these major river basins are located the rivers are the economic engine of the communities agriculture industry transportation power production and water supply and predicting the water resources including their inter annual and inter seasonal variability is essential to assessing water availability and is useful for planning in case of extreme hydrological events of floods and droughts observations of water in many developing countries of the world are constrained by lack of adequate gauge stations many agencies that collect the streamflow or precipitation data internationally are not likely to share this data with others due to national security policies of their respective governments which makes comprehensive analysis using these data sets very difficult satellite remote sensing and use of global land model data sets can help in this regard this study showed several examples of how satellite remote sensing can be used over large areas and long time periods to identify spatial and temporal variation as well as how to estimate total water fluctuations using a simple water balance model and how to compare hydrologic phenomena across hydrologic regions however we stress two important points in this regard one there is no substitute for in situ observations of precipitation evapotranspiration and stream flow especially for small catchments to perform water balance as well as test theories and equations that can be used for larger spatial scales two validation studies are usually carried out at smaller scales catchments on the order of a few 1000 km2 and for the large catchments such as those in this present study there are really no distributed validation studies for these reasons we rely on the use of standard validated data sets future studies seek to develop models to complete these analyses at even finer spatial resolution which will serve the international community at more local scales acknowledgements the authors wish to acknowledge the support of dr bradley doorn program manager water resources applied sciences program award number 80nssc18k0433 and dr jared entin program manager terrestrial hydrology award number nnx12ap75g at nasa headquarters for funding this research this work used eddy covariance data acquired and shared by the fluxnet community including these networks ameriflux afriflux asiaflux carboafrica carboeuropeip carboitaly carbomont chinaflux fluxnet canada greengrass icos koflux lba necc ozflux tern tcos siberia and usccc the era interim reanalysis data are provided by ecmwf and processed by lsce the fluxnet eddy covariance data processing and harmonization was carried out by the european fluxes database cluster ameriflux management project and fluxdata project of fluxnet with the support of cdiac and icos ecosystem thematic center and the ozflux chinaflux and asiaflux offices data from the following site ids were used in this study au how au tum be bra be vie ca man ch dav de geb de hai de tha dk sor dk za hfi hyy fi sod fr lbr fr pue it coli t cpz it lav it ren it sro nl loo ru cok us ha1 us los us me2 us mms us ne1 us ne2 us ne3 us nr1 us pfa us syv us ton us umb us var us wcr 
6904,numerous large river basins of the world have few and irregular observations of the components of the terrestrial hydrological cycle with the exception of stream gauges at a few locations and at the outlet along with sparsely distributed rain gauges using observations from satellite sensors and output from global land surface models it is possible to study these under observed river basins with populations greater than a billion people some of these rivers e g the ganga brahmaputra the yangtze the nile and the mekong are the economic engines of the countries they transect yet thorough assessment of their flow dynamics and variability in regard to water resource management is still lacking in this paper we use soil moisture 0 2 m and surface runoff from the nasa global land data assimilation system gldas evapotranspiration and normalized difference vegetation index ndvi from the moderate resolution imaging spectroradiometer modis and rainfall from the tropical rainfall measuring mission trmm and total water storage anomaly from the gravity recovery and climate experiment grace to examine variability of individual water balance components to this end understanding the inter annual and intra seasonal variability and the spatial variability of the water balance components in the major river basins of the world will help to plan for improved management of water resources for the future keywords water resources hydrological balance models satellite data droughts and floods 1 introduction the water availability per capita in many locations of the world is constantly decreasing one explanation is the increasing proportion of global population relative to the available water in many parts of the world the global population has increased from 2 billion in 1950 to a current population of 7 4 billion for essentially the same water availability the global per capita water availability has an inverse relationship decreasing by a factor greater than 3 during this period however there are two reasons that this conclusion is not global firstly the distribution of population increase is not uniform for example urban growth is significantly different in areas in asia and africa as compared to europe and australia and secondly in many regions of the world the groundwater is a predominant source of water and is being exploited and it has only recently become obvious that withdrawal rates from these aquifers are unsustainable for example groundwater in the high plains of the united states and in northern india are over utilized the united nations world water development report 2016 points out that three out of four jobs globally are dependent on water un water 2016 there are numerous areas such as agriculture power production industrial applications fishing and health which involve water illustrating the societal dependence on water numerous studies have pointed out the impacts of climate change and or population growth on water resources arnell 1999 alcamo et al 2007 kundzewicz et al 2007 oki and kanae 2006 piao et al 2010 ragab and prudhomme 2002 vorosmarty et al 2000 other studies have addressed more specific changes such as groundwater recharge under various climate change scenarios herrera pantoja and hiscock 2008 scanlon et al 2006 taylor et al 2013 one common conclusion from all these studies is that the amount of water available is decreasing with both climate change and increasing population the major river basins of the world play a big role in supporting over 70 of the global population many of these hydrological studies are specific to a river basin but there are a few comparative studies across river basins aerts et al 2006 dai et al 2009 nijssen et al 2001 oki and kanae 2006 vorosmarty et al 2000 in their study of global rivers using various climate models under different scenarios of climate change nijssen et al 2001 found that the largest changes were observed in the spring time period that corresponds to the snowmelt aerts et al 2006 found that the future discharges in some of the major river basins could increase by 6 16 due to changes in climate the analysis of the annual stream flows for the 200 largest rivers of the world from 1948 to 2004 showed that more rivers exhibited decreasing trends than increasing trends dai et al 2009 vorosmarty et al 2000 and oki and kanae 2006 both showed that the water scarcity index showed higher values in western united states northern africa south asia and the middle east regions and that the population living in the area of high water stress and relative demand for water would increase with the changes in climate observations of the water cycle using in situ sensors are very difficult due to two reasons firstly the water cycle is highly heterogeneous in space and varies temporally at short time scales maintenance and operation of a high density in situ network for example rain gauges is very expensive secondly obtaining data from river basins in countries other than united states is at times very difficult since many countries may not freely distribute or share data given these reasons satellite remote sensing observations and hydrological model outputs are an attractive solution that can overcome spatial heterogeneity and temporal consistency issues in addition the quasi global coverage provided by satellite observations combined with open data policies can help avoid the issues related to data access and continuity the motivation of this study is two fold firstly the lack of in situ water data from most of the large river basins of the world implies that we can only use the readily available satellite data sets and global land model outputs secondly most of the studies that involved these major river basins were published at least a decade or so ago and current up to date studies do not exist we currently have about 15 years of data from satellite sensors that can bridge this gap in this work we mostly use satellite data from nasa satellite sensors as they have long data records over 10 years in all cases and are freely and publicly available the model outputs also come from a nasa model system the global land data assimilation system which is also publicly available here we use publicly available data sets to construct the water balance of eleven large continental scale river basins of the world we analyze each of the components of the water budget precipitation evapotranspiration runoff and total water for seasonality and study the spatial and temporal correlations between components in this way we envisage that this study will help water resource managers with future planning of water resources and land use in these highly important and widely utilized river basins this paper is organized as follows section 2 describes the data sets satellite and model derived for the variables in the hydrological cycle section 3 highlights the results for the hydrological cycle for the major river basins using the data described in section 2 and identify key processes in time and space finally section 4 delves into the conclusions and discussions of this work 2 data all the data sets used in this study are the monthly averaged or cumulative precipitation values and at their inherent spatial resolution all of the data sources are listed in table 1 time series are calculated from the spatial average within the respective basins no attempt has been made to re grid the data to a common spatial resolution in the figures tables and analyses in this paper 2 1 trmm tropical rainfall measuring mission trmm was launched in 1997 kummerow et al 1998 2000 and ended its mission in 2015 the most widely used satellite precipitation data are the tmpa trmm multi satellite precipitation analysis 3b42 v 7 precipitation dataset that are obtained combining trmm precipitation radar pr passive microwave pmw and infrared ir estimates at a three hourly interval and 0 25 spatial resolution in the 50 s 50 n area bolvin and huffman 2015 the tmpa rainfall is widely applied in different branches of the earth sciences especially in data sparse regions e g awadallah and awadallah 2013 khan et al 2011 asante et al 2008 bindlish et al 2003 details on the data product can be found in huffman et al 2007 2010 2 2 modis moderate resolution imaging spectroradiometer normalized difference vegetation index ndvi and evapotranspiration et are available from the moderate resolution imaging spectroradiometer modis the modis sensor is onboard both the terra and aqua satellite platforms which were launched on december 1999 and on may 2002 respectively in a sun synchronous polar orbit with estimated equatorial crossing times of 10 30 am terra and at 1 30 pm aqua modis provides 44 global data products for land ocean and atmospheric variables details of the modis land data are available at the modis website http modis gsfc nasa gov and the products used in this study ndvi and evapotranspiration are available as mod13c2 and mod16 respectively from the land processes distributed active archive center website http lpdaac usgs gov and the numerical terradynamic simulation group at the university of montana http www ntsg umt edu project mod16 the algorithms to derive these products are well established and extensively evaluated ndvi rouse et al 1973 tucker 1979 myneni et al 1995 and evapotranspiration mu et al 2007 2011 the monthly composite global products are available from lpdaac on a 5 6 km global climate modeling grid cmg although local tiled versions are available from some products at higher spatial resolutions for example ndvi at a 1 km resolution not used in this study the modis et product is based on the penman monteith method mu et al 2011 there have been numerous validations of modis evapotranspiration estimates in many regions of the world kim et al 2012 have carried out validation of the modis et products over different land cover and climate in asia and found that it resembled closely to the et measured from flux towers in australia cleugh et al 2007 and pan arctic mu et al 2009 2 3 grace gravity recovery and climate experiment the u s german gravity recovery and climate experiment grace satellite mission was launched in 2002 to provide estimates of changes in total terrestrial water storage represented as the sum of groundwater soil moisture snow and surface waters at large spatial scales and on a monthly basis tapley et al 2004 while this mission provided monthly tws estimates through jan 2017 the grace follow on mission is expected to support future research using this data variable members of our team have developed and applied an approach for assimilating observations of soil moisture and terrestrial water storage from satellite based sensors including grace into a land surface models which have been shown to produce estimates of variations in the components of terrestrial water storage that are both accurate and as high resolution as the model grid bolten et al 2010 bolten and crow 2012 gupta et al 2015 the grace assimilation approach has been used to provide enhanced estimates of hydrological monitoring and groundwater storage by constraining terrestrial water balance zaitchik et al 2008 forman et al 2012 houborg et al 2012 li et al 2012 eicker et al 2014 by including monthly observations of the terrestrial water storage in our land surface modeling scheme it is possible to more accurately monitor regional hydrological states and fluxes and thus calculate with more certainty the anomalies of these states and fluxes for enhanced monitoring of hydrological and agricultural drought grace has been instrumental in numerous water balance studies pointing to declines in the water storages specifically the decline in groundwater in many parts of the world rodell et al 2004 2007 2009 tiwari et al 2009 landerer and swenson 2012 but studies cannot be conducted at smaller scales due to the coarse resolution of the sensor alley and konikow 2015 lakshmi 2016 2 4 gldas global land data assimilation system the global land data assimilation system gldas provides high resolution maps of land surface states and fluxes by forcing modern offline land surface models e g noah ek et al 2003 with high quality observational data mitchell et al 2004 the forcing data cosgrove et al 2003 luo et al 2007 and outputs have been extensively validated lohmann et al 2004 robock et al 2003 schaake et al 2004 the outputs are available at a 1 8 spatial resolution and hourly time step for the north american nldas version not used in this study and at a 1 4 spatial resolution and 3 hourly time step for gldas the data for both n g ldas are available at monthly timescales which will be used here the ldas data sets are described in detail at http ldas gsfc nasa gov and http disc sci gsfc nasa gov hydrology we use the root zone soil moisture 0 2 m and runoff from the improved gldas version 2 product in this study 2 5 major river basins of the world the major river basins of the world are shown in fig 1 these basins were extracted from the food and agriculture organization of the united nations major hydrological basins shapefile derived from the usgs hydrosheds and hydro1k elevation products fao un 2015 previous studies about the basins as well as climate area latitudinal location annual average precipitation and air temperature are listed in table 2 this table enables us to understand on a comparative basis the physical and climatological differences between the large river basins distributed between all continents these basins were chosen for this study because of they represent a diverse climatology such as tropical humid semi arid arid and marine and the fact that the hydrology and availability of water in these basins is an issue for millions of its inhabitants for agriculture hydropower transportation and domestic and industrial uses the annual average precipitation ranges from a low of 160 mm in the colorado river basin to a high of 2110 mm for the ganga brahmaputra river basin the average annual air temperature varies between 284 k in the danube river basin to 300 k in the nile river basin there is also a large variability in the size the smallest basin california basin california is the integrated basin for sacramento san joaquin river tulare lake san francisco bay part of north and south coast north and south lahontan and the colorado river 400 000 km2 to the largest the amazon river basin 5 000 000 km2 such diversity in location and climate result in a different distribution of precipitation into evapotranspiration infiltration recharge runoff and soil moisture the previous studies for each basin focus on the variability of these hydrological components and some of these have already been referenced in the introduction section 3 application of the remotely sensed and modeled data to estimate water storage 3 1 validation of the precipitation evapotranspiration and runoff data before and after the launch of earth observing satellites studies are conducted to ensure the quality of the observations often consisting of field studies and comparison with in situ measurements as well as comparisons with other remotely sensed products and modeled outputs the trmm retrieved precipitation modis derived evapotranspiration and the gldas modeled runoff have been independently validated as shown in table 3 and can be used as proxies for direct ground measurements to demonstrate their local efficacy we compare the satellite based data sets with point based in situ measurements and assess the correlations by latitude showing spatial variations of ground data in fig 2 in the analysis three data sets i e precipitation runoff and et were used the global historical climatology network gchn was compared with trmm precipitation runoff data from the global runoff data centre grdc was compared with gldas noah runoff and fluxnet station data were converted into et using the penman monteith equation to compare with modis et lawrimore et al 2011 grdc 2017 fluxnet 2015 zotarelli et al 2010 each of the data sources available had data that were outside of the temporal study domain and therefore some stations could not be included in the comparison of the 72 882 total precipitation stations available from gchn only 11 286 stations had at least ten years of data within 1998 2015 to match the trmm data of the 9236 discharge stations available from grdc only 3540 stations could be used finally there are approximately 166 fluxnet stations available globally but only 36 stations could be compared with the modis evapotranspiration fig 2 demonstrates how well the satellite measurements compare with traditional ground measurements trmm provides precipitation data from 50 n 50 s the areas outside this range are masked out the satellite direct and indirect observations closely align with measurements from ground stations the modeled runoff data suffers drawbacks due to large grid sizes and largely ignore water management practices in spite of these drawbacks modeled runoff data are used in this analysis to leverage their global coverage and temporal continuity 3 2 hydrological balance we carried out a basin averaged water balance and compared it to the grace water equivalent thickness anomaly 1 p et r δ s where precipitation p evapotranspiration et runoff r and change in surface and subsurface water storage δs are monthly and basin averaged values for each of the basins quantities enhanced or reduced due to water withdrawals due to irrigation domestic and industrial uses are not explicitly included on either side of this equation as there was not a globally consistent method of estimation for them all the variables on the left hand side of eq 1 can be estimated using either satellite p et or model r data sets the total change in water storage total water on the right hand side of the equation δs can be estimated by grace observations the difference between p et r and δs would represent the amount of withdrawal of groundwater in the basin there does not exist any database for estimation of w and the value of w differs between basins in regions of sufficient water supply there is not much water withdrawal as w is seldom measured and is much smaller compared to δs we have not included it in eq 1 we provide a discussion of this in section 4 figs 3a and 3b represent spatial average monthly p et r and the grace water equivalent thickness anomalies as water storage anomalies for grace the anomalies were calculated with the 2004 2010 baseline for all other variable the anomalies were calculated for the length of record 2001 2015 for all the river basins studied in this paper in time series and scatter plots there are two common features in all these basin trends firstly there is a marked seasonal variability of both p et r and the total water for most of the river basins but there are a few exceptions for example the congo the colorado and the murray darling river basins do not show the seasonal signal for p et r and grace water equivalent thickness as compared to the amazon or the ganga brahmaputra river basin the time period of the lag varies between one to 3 months and is dependent on the size and climate of the basin and the transport and storage of water the magnitude of the p et r is strongly dependent on the climate and ecosystem and this magnitude is much larger for the amazon and the mekong river basins as compared to the colorado the murray darling and the danube river basins direct comparison of the magnitudes of p et r and the grace water equivalent thickness anomaly as total water is not possible as the former is a direct measure and the latter is an anomaly however the temporal variability changes between month to month between p et r and the grace water equivalent thickness anomaly is justified as they both reflect the increase or decrease in the storage a positive p et r corresponds to a positive value of the grace water equivalent thickness anomaly and vice versa examination of the correlation statistics in table 4 all values are significant at p value of 0 05 shows that the high correlation between p et r and total water is seen for the tropical watersheds of the amazon the ganga brahmaputra and the mekong river basins of 0 8 or higher and a lag of 1 month the next group is the urban california and the danube river basins at 0 7 or higher with 0 lags the other basins have lower r2 and the time lag corresponding to the maximum r2 at 3 months in the case of the colorado 3 3 co variability of hydrological cycle components five variables are derived from three different sources precipitation from trmm total water from grace evapotranspiration and ndvi from modis and runoff and soil moisture from gldas the spatial resolution for precipitation trmm runoff gldas and soil moisture 0 2 m gldas is 0 25 et and ndvi modis is 0 05 and that of total water grace is 1 figs 4 and 5 represent the monthly time series of the water balance components for the mekong and the murray darling river basins respectively these include monthly anomaly time series for a precipitation b runoff c soil moisture d et and e total water as grace water equivalent thickness anomaly the anomalies for precipitation et runoff and soil moisture are calculated using january 2001 to december 2014 period as a baseline the figures highlight the seasonal and annual variability of the hydrological cycle between january 2001 and december 2014 the total water time series starts in april 2002 corresponding to the grace launch also indicated in these figures are the high negative and positive anomalies that correspond to dry drought and wet flood conditions in the basin examination of these time series shows that the co variability of these four components of the hydrological cycle follows the water balance we chose for the mekong river basin fig 4 and the murray darling river basin fig 5 dry and wet months based on low and high grace water equivalent thickness anomaly if we examine fig 4 a e we observe that one of the periods of lowest precipitation in the mekong river basin corresponds to january 2005 with a precipitation anomaly of 0 5 mm corresponding to a 0 mm and 7 5 mm for the runoff anomaly and et anomaly respectively in march 2005 lags rainfall by 2 months and 3 5 mm for soil moisture and 100 mm for the total water in may 2005 the other extreme corresponds to the extremely wet month of september 2011 with a positive anomaly for rainfall of 100 mm and a corresponding positive anomaly of runoff of 5 mm soil moisture of 5 mm and lagged by one month october 2011 total water anomaly of 100 mm november 2011 lag of two months and the et shows generally positive anomalies a few months later starting in december 2011 for a period of over 12 months the correspondence of the rainfall to runoff soil moisture and total water is well displayed in this figure the same findings hold for the murray darling river basin the dry and wet periods are related between all of the variables displayed in fig 5 the dry period of low rainfall 75 mm and runoff 0 mm in august 2009 corresponds to low soil moisture 3 mm et 10 mm and low total water 50 mm in november 2009 the wet period with above normal rainfall 70 mm corresponds to december 2010 and positive runoff 2mm and soil moisture 15 mm in february 2011 and high total water 100 mm in march 2011 the et shows a high positive anomaly of 25 mm for december 2010 and remains positive for several months in fig 4a we observe that the precipitation has a negative anomaly throughout the mekong river basin for january 2005 and as a result both the soil moisture and runoff two months later march 2005 show negative anomalies and the total water in may 2005 shows negative anomalies ranging from 100 mm to 500 mm throughout the catchment the same is true for the spatial distribution of the positive anomalies for precipitation extends to soil moisture runoff et and total water that has a positive anomaly ranging from 200 mm to 500 mm in the southern part of the mekong river basin similar spatial patterns are seen for the murray darling river basin on examination of the total water for the murray darling basin fig 5e it is seen that it shifts from mostly negative to positive values at the beginning of 2010 this is expected as the rainfall fig 5a exhibits high values positive anomalies in six months of 2010 60 mm as well as in january and february 2012 these high positive anomalies in rainfall during 2010 coupled with lower values of et keep the water balance positive in the basin one of the most important observations that can be seen from figs 4 a e and 5 a e in the spatial maps of the catchment for the hydrological cycle variables is the sharp contrast between the dry and the wet periods the spatial pattern of the variables for the wet month are dominated by positive rainfall soil moisture runoff et and total water anomalies and vice versa for the dry months 3 4 spatial variability examination of the spatial variability of the hydrological cycle variables in two river basins the amazon and the colorado fig 6 yields interesting and contrasting results fig 6 displays the monthly spatial standard deviation of precipitation trmm runoff gldas et modis soil moisture gldas and total water anomaly grace all in mm the differences between the amazon and the colorado with respect to spatial variability are very apparent to begin with the spatial variability of the precipitation in the colorado river basin varies between 0 and 30 mm whereas for the amazon river basin the range is between 60 and 180 mm this spatial variability in precipitation translates to a larger spatial variability in runoff for the amazon river basin 2 30 mm as compared to the colorado river basin 0 10 mm the standard deviation of the precipitation for the amazon river basin generally shows a minimum in months of august and september around 60 mm a maximum in the month of may between 150 and 180 mm the spatial variability of runoff for the amazon river basin is lowest in july and august standard deviation of around 5 mm and highest in january march 20 30 mm the spatial variability of evapotranspiration shows a distinctive seasonal signature for both the amazon and the colorado river basins for the amazon there is a variation between a minimum in the month of february of 15 mm and a maximum in the months of august and september of around 35 mm in the case of the colorado river basin the minimum spatial variability is in the winter months december to february of 5 mm and a maximum during the summer months of june and july of 20 mm it can be noticed that in the case of the amazon river basin the maximum standard deviation for runoff corresponds to the minimum standard deviation for et the spatial variability for soil moisture for both the amazon and the colorado river basins does not show any seasonal variability with the spatial standard deviation for the amazon river basin being higher between 13 and 22 m as compared to the colorado river basin between 6 and 12 mm the variability of total water for the amazon river basin shows a very large range between 100 mm and 400 mm as compared to the colorado river basin between 0 and 80 mm examination of the spatial variability of precipitation ndvi and et in january 2005 and june 2005 for the colorado river basin and january 2005 and august 2005 for the amazon river basin shows remarkable differences between the two basins figs 7 and 8 respectively whereas most of the colorado river basin has little or no vegetation in january 2005 ndvi around 0 15 and only a small region in the southern part with any vegetation the amazon river basin shows larger extent of greenness large region ndvi around 0 7 there is a large spatial variability in et for the amazon river basin between 0 and 150 mm and much lower range for the colorado river basin between 10 and 40 mm the difference in et in august 2005 for the amazon river basin between the south and the north is evident from the very low et in the southern part of the basin 0 20 mm contrasting with the high et 120 150 mm in the northern part of the basin in the amazon river basin this is strongly related to the higher amount of vegetation and the rainfall in the north ndvi 0 7 0 9 in the north and 0 5 0 8 in the south rainfall of 150 250 mm in the north and 0 75 mm in the southern part of the basin this is in stark contrast to the spatial pattern of et for the amazon river basin which is much more uniform across the region as also reflected in rainfall and vegetation the large difference in et in june 2005 in the colorado river basin between the northeast and the south is also seen fig 7 and it varies between 0 and 80 mm across the basin and is strongly related to the variation of ndvi 0 15 0 75 with higher ndvi in the northeast 0 70 and much lower in the south 0 15 and rainfall is much higher in the northeast 60 mm and much lower in the south less than 10 mm 3 5 temporal variability anomaly index analysis the data analyzed in this paper spans over 15 years and 11 river basins of the world whereas each of these river basins has been studied in considerable detail in many past studies table 2 a comprehensive comparison has never been undertaken in considering locations with differing annual rainfall temperature and land cover direct comparisons will not yield quantitative results due to obvious differences between basins for example there is always greater rainfall and runoff in the amazon river basin as compared to the murray darling river basin in order to overcome this problem we have constructed the anomaly index defined as the monthly anomaly divided by the monthly climatology as the anomaly index normalizes the monthly anomaly by dividing by the monthly climatology the regions with anomaly index would measure the variability of the monthly anomaly as a fraction of the monthly climatology value for example when we compare the amazon with high monthly rainfall to the murray darling basin with much lower rainfall using the precipitation anomaly index we are only comparing the fraction of variability the minimum and maximum monthly anomaly index values are presented in table 5 fig 9 shows the comparison of precipitation using the anomaly index for the amazon river basin and the murray darling basin whereas the index values in the amazon river basin range from 0 4 to 0 61 the index values for the murray darling basin varies between 0 95 and 1 73 table 5 the temporal variability of this index for the amazon is 0 11 and for the murray darling is 0 52 both these statistics show that the variability of the monthly rainfall as a ratio of the monthly rainfall climatology is much higher in the murray darling basin and is subject to greater extremes in precipitation these are periods when the rainfall is below normal negative precipitation anomaly index which is seen between 2001 and 2009 and this period corresponds to a severe drought in the region we observe a period of high monthly precipitation compared to the climatology for 2010 and 2012 and november 2010 corresponds to a large scale flood in this region in the case of the amazon river basin there is very little deviation of the precipitation anomaly index from zero zero indicates no departure from the monthly climatology and hence the river basin is not subject to extremes a few other river basins with large negative precipitation anomaly index and hence subject to droughts are the california the colorado the danube and the ganga brahmaputra river basins the monthly anomaly indices between different variables capture the connection between the land surface variables the variability in vegetation index is connected to the variability of the evapotranspiration the amazon river basin shows a low range of ndvi 0 04 to 0 08 and a corresponding low range for et 0 17 to 0 29 however the murray darling basin shows a much larger range for ndvi variation 0 23 to 0 38 and a corresponding higher range for et 0 63 to 1 7 this is shown in fig 9 and table 5 table 5 shows the minimum and maximum monthly values for the anomaly index the temporal standard deviation for monthly ndvi anomaly index is 0 02and 0 12 and monthly et anomaly index is 0 04 and 0 29 for the amazon river basin and the murray darling basin respectively larger variability in precipitation translates to greater variability in ndvi and et for the murray darling basin as compared to the amazon river basin 4 conclusions and discussion we have examined the water balance components for eleven global river basins using publicly available monthly satellite data and model output products for a period of 15 years between 2001 and 2015 the water balance components of the hydrological cycle include precipitation et soil moisture runoff and total water the river basins are located in contrasting climate topography and ecosystems across the globe in all continents with the exception of antarctica in comparing the output of p et r to the changes associated with the total water from grace we observe a distinct seasonal cycle with a maximum lag of a few months between the two quantities p et r and δs the correlation between p et r and total water change shows a large variability among basins with the highest being the amazon river basin at r2 of 0 9 and lowest at r2 of 0 35 for the colorado river and the murray darling river basins the differences between the basins may stem from the human engineering of the water systems in the basin the amazon river basin has been subject to much less human intervention compared to the colorado and the murray darling river basins another factor in this difference is the storage and melting of snow in some basins we compared a month of wet with a dry month for the mekong river and the murray darling river basin on comparison of precipitation runoff soil moisture et and total water we find a consistency in the hydrological cycle with respect to the water balance i e we find for wet flood periods a large positive anomaly of precipitation from trmm corresponding to positive anomalies of et from modis runoff and soil moisture from gldas and total water from grace and vice versa for negative anomaly or dry drought conditions finally we compute the anomaly index and compare these variables across river basins the precipitation anomaly index for the amazon river basin has a much lower variability compared to the murray darling river basin the anomaly indices of the other hydrological variables are also compared with each other and across basins and this leads to very consistent relationship eq 1 in section 3 2 has an implicit withdrawal term which presents us with a problem whereas in principle eq 1 should be balanced if all the individual variables are perfect maintaining a water balance this is not the case as seen in the results in figs 3 a k we therefore conclude that the problem in this balance equation is the fact that the individual variables are not perfect and compounding the fact is that the withdrawal terms on both sides of the equation are seldom known the dynamics of withdrawal is very complicated withdrawal due to irrigation can either a leave the watershed as evapotranspiration or runoff and this is accounted for in the equation b infiltrate into the soil and recharge the groundwater or c leave the system through domestic water withdrawal and subsequent transport elsewhere each of these has to be treated separately and one treatment would not address all physical mechanisms therefore we have removed the withdrawal term in eq 1 as we have realized that the accuracies of the individual terms in eq 1 probably account for withdrawal however a much more involved analysis needs to be undertaken and this would need to be done at a the whole river basin scale and b sub basins to determine the actual dynamics we hope that this will be the subject of further studies in this paper we utilize monthly data from satellites and models over a 15 year period for analysis this study is unique as it is a multi year period using a combination of publicly available satellite data and model output b comparison of river basins across the globe located in a range of climate topography and ecosystems though the data come from different sources they display the required relationship with each other to complete a hydrological balance in addition the hydrological variables display very interesting spatial and temporal patterns that are consistent with hydrological extremes of floods and droughts in the future such studies will be very important to determine availability of water resources under the growing pressures of an ever increasing population studies like this present work when carried out at higher spatial resolution will aid and assist local agencies for improved land use and water use management understanding variability of the different components of the water budgets for the past 20 years will help in the planning for the net 20 years in many countries of the world where these major river basins are located the rivers are the economic engine of the communities agriculture industry transportation power production and water supply and predicting the water resources including their inter annual and inter seasonal variability is essential to assessing water availability and is useful for planning in case of extreme hydrological events of floods and droughts observations of water in many developing countries of the world are constrained by lack of adequate gauge stations many agencies that collect the streamflow or precipitation data internationally are not likely to share this data with others due to national security policies of their respective governments which makes comprehensive analysis using these data sets very difficult satellite remote sensing and use of global land model data sets can help in this regard this study showed several examples of how satellite remote sensing can be used over large areas and long time periods to identify spatial and temporal variation as well as how to estimate total water fluctuations using a simple water balance model and how to compare hydrologic phenomena across hydrologic regions however we stress two important points in this regard one there is no substitute for in situ observations of precipitation evapotranspiration and stream flow especially for small catchments to perform water balance as well as test theories and equations that can be used for larger spatial scales two validation studies are usually carried out at smaller scales catchments on the order of a few 1000 km2 and for the large catchments such as those in this present study there are really no distributed validation studies for these reasons we rely on the use of standard validated data sets future studies seek to develop models to complete these analyses at even finer spatial resolution which will serve the international community at more local scales acknowledgements the authors wish to acknowledge the support of dr bradley doorn program manager water resources applied sciences program award number 80nssc18k0433 and dr jared entin program manager terrestrial hydrology award number nnx12ap75g at nasa headquarters for funding this research this work used eddy covariance data acquired and shared by the fluxnet community including these networks ameriflux afriflux asiaflux carboafrica carboeuropeip carboitaly carbomont chinaflux fluxnet canada greengrass icos koflux lba necc ozflux tern tcos siberia and usccc the era interim reanalysis data are provided by ecmwf and processed by lsce the fluxnet eddy covariance data processing and harmonization was carried out by the european fluxes database cluster ameriflux management project and fluxdata project of fluxnet with the support of cdiac and icos ecosystem thematic center and the ozflux chinaflux and asiaflux offices data from the following site ids were used in this study au how au tum be bra be vie ca man ch dav de geb de hai de tha dk sor dk za hfi hyy fi sod fr lbr fr pue it coli t cpz it lav it ren it sro nl loo ru cok us ha1 us los us me2 us mms us ne1 us ne2 us ne3 us nr1 us pfa us syv us ton us umb us var us wcr 
